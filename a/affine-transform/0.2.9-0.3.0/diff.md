# Comparing `tmp/affine_transform-0.2.9.tar.gz` & `tmp/affine_transform-0.3.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "affine_transform-0.2.9.tar", last modified: Sat Apr 22 11:29:19 2023, max compression
+gzip compressed data, was "affine_transform-0.3.0.tar", last modified: Sun Apr 23 14:44:49 2023, max compression
```

## Comparing `affine_transform-0.2.9.tar` & `affine_transform-0.3.0.tar`

### file list

```diff
@@ -1,487 +1,505 @@
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.789102 affine_transform-0.2.9/
--rw-r--r--   0 runner    (1001) docker     (123)      504 2023-04-22 11:28:58.000000 affine_transform-0.2.9/.appveyor.yml
--rw-r--r--   0 runner    (1001) docker     (123)      306 2023-04-22 11:28:58.000000 affine_transform-0.2.9/.clang-format
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.713103 affine_transform-0.2.9/.github/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.733103 affine_transform-0.2.9/.github/workflows/
--rw-r--r--   0 runner    (1001) docker     (123)      731 2023-04-22 11:28:58.000000 affine_transform-0.2.9/.github/workflows/deploy.yml
--rw-r--r--   0 runner    (1001) docker     (123)      787 2023-04-22 11:28:58.000000 affine_transform-0.2.9/.github/workflows/deploy_test.yml
--rw-r--r--   0 runner    (1001) docker     (123)     1217 2023-04-22 11:28:58.000000 affine_transform-0.2.9/.github/workflows/test-package.yml
--rw-r--r--   0 runner    (1001) docker     (123)     2385 2023-04-22 11:28:58.000000 affine_transform-0.2.9/.gitignore
--rw-r--r--   0 runner    (1001) docker     (123)      201 2023-04-22 11:28:58.000000 affine_transform-0.2.9/.gitmodules
--rw-r--r--   0 runner    (1001) docker     (123)      656 2023-04-22 11:28:58.000000 affine_transform-0.2.9/CMakeLists.txt
--rw-r--r--   0 runner    (1001) docker     (123)     1074 2023-04-22 11:28:58.000000 affine_transform-0.2.9/LICENSE
--rw-r--r--   0 runner    (1001) docker     (123)      232 2023-04-22 11:28:58.000000 affine_transform-0.2.9/MANIFEST.in
--rw-r--r--   0 runner    (1001) docker     (123)     3516 2023-04-22 11:29:19.789102 affine_transform-0.2.9/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)     3019 2023-04-22 11:28:58.000000 affine_transform-0.2.9/README.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.733103 affine_transform-0.2.9/affine_transform/
--rw-r--r--   0 runner    (1001) docker     (123)      205 2023-04-22 11:28:58.000000 affine_transform-0.2.9/affine_transform/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)     6235 2023-04-22 11:28:58.000000 affine_transform-0.2.9/affine_transform/affine_transform.py
--rw-r--r--   0 runner    (1001) docker     (123)        5 2023-04-22 11:29:19.000000 affine_transform-0.2.9/affine_transform/version.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.733103 affine_transform-0.2.9/affine_transform.egg-info/
--rw-r--r--   0 runner    (1001) docker     (123)     3516 2023-04-22 11:29:19.000000 affine_transform-0.2.9/affine_transform.egg-info/PKG-INFO
--rw-r--r--   0 runner    (1001) docker     (123)    18664 2023-04-22 11:29:19.000000 affine_transform-0.2.9/affine_transform.egg-info/SOURCES.txt
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-04-22 11:29:19.000000 affine_transform-0.2.9/affine_transform.egg-info/dependency_links.txt
--rw-r--r--   0 runner    (1001) docker     (123)        1 2023-04-22 11:29:19.000000 affine_transform-0.2.9/affine_transform.egg-info/not-zip-safe
--rw-r--r--   0 runner    (1001) docker     (123)       26 2023-04-22 11:29:19.000000 affine_transform-0.2.9/affine_transform.egg-info/requires.txt
--rw-r--r--   0 runner    (1001) docker     (123)       17 2023-04-22 11:29:19.000000 affine_transform-0.2.9/affine_transform.egg-info/top_level.txt
--rw-r--r--   0 runner    (1001) docker     (123)       22 2023-04-22 11:28:58.000000 affine_transform-0.2.9/codecov.yml
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.733103 affine_transform-0.2.9/docs/
--rw-r--r--   0 runner    (1001) docker     (123)     6862 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/conf.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.733103 affine_transform-0.2.9/docs/cpp/
--rw-r--r--   0 runner    (1001) docker     (123)        5 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp/.gitignore
--rw-r--r--   0 runner    (1001) docker     (123)   112013 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp/Doxyfile
--rw-r--r--   0 runner    (1001) docker     (123)      759 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_doc.rst
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.737103 affine_transform-0.2.9/docs/cpp_docs/
--rw-r--r--   0 runner    (1001) docker     (123)      652 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_docs/affine_transform.rst
--rw-r--r--   0 runner    (1001) docker     (123)      120 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_docs/apply_interpolation.rst
--rw-r--r--   0 runner    (1001) docker     (123)      115 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_docs/constant_boundary.rst
--rw-r--r--   0 runner    (1001) docker     (123)      107 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_docs/cubic_interpolation.rst
--rw-r--r--   0 runner    (1001) docker     (123)      196 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_docs/data_struct.rst
--rw-r--r--   0 runner    (1001) docker     (123)       75 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_docs/extract.rst
--rw-r--r--   0 runner    (1001) docker     (123)     1287 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_docs/interpolation.rst
--rw-r--r--   0 runner    (1001) docker     (123)      110 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_docs/linear_interpolation.rst
--rw-r--r--   0 runner    (1001) docker     (123)      357 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_docs/python_bindings.rst
--rw-r--r--   0 runner    (1001) docker     (123)       84 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_docs/transform.rst
--rw-r--r--   0 runner    (1001) docker     (123)      107 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/cpp_docs/transform_loop.rst
--rw-r--r--   0 runner    (1001) docker     (123)      422 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/how_to_use.rst
--rw-r--r--   0 runner    (1001) docker     (123)      477 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/index.rst
--rw-r--r--   0 runner    (1001) docker     (123)      752 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/make.bat
--rw-r--r--   0 runner    (1001) docker     (123)      102 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/module_doc.rst
--rw-r--r--   0 runner    (1001) docker     (123)       64 2023-04-22 11:28:58.000000 affine_transform-0.2.9/docs/requirements.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.737103 affine_transform-0.2.9/examples/
--rw-r--r--   0 runner    (1001) docker     (123)     1867 2023-04-22 11:28:58.000000 affine_transform-0.2.9/examples/rotation_and_translation.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.729102 affine_transform-0.2.9/extern/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.717103 affine_transform-0.2.9/extern/eigen/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.741103 affine_transform-0.2.9/extern/eigen/Eigen/
--rw-r--r--   0 runner    (1001) docker     (123)      694 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/CMakeLists.txt
--rw-r--r--   0 runner    (1001) docker     (123)     1206 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/Cholesky
--rw-r--r--   0 runner    (1001) docker     (123)     1900 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/CholmodSupport
--rw-r--r--   0 runner    (1001) docker     (123)    11621 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/Core
--rw-r--r--   0 runner    (1001) docker     (123)      122 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/Dense
--rw-r--r--   0 runner    (1001) docker     (123)       35 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/Eigen
--rw-r--r--   0 runner    (1001) docker     (123)     1822 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/Eigenvalues
--rw-r--r--   0 runner    (1001) docker     (123)     1948 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/Geometry
--rw-r--r--   0 runner    (1001) docker     (123)      874 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/Householder
--rw-r--r--   0 runner    (1001) docker     (123)     2083 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/IterativeLinearSolvers
--rw-r--r--   0 runner    (1001) docker     (123)      939 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/Jacobi
--rw-r--r--   0 runner    (1001) docker     (123)     1389 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/KLUSupport
--rw-r--r--   0 runner    (1001) docker     (123)     1433 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/LU
--rw-r--r--   0 runner    (1001) docker     (123)      991 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/MetisSupport
--rw-r--r--   0 runner    (1001) docker     (123)     2451 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/OrderingMethods
--rw-r--r--   0 runner    (1001) docker     (123)     1751 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/PaStiXSupport
--rw-r--r--   0 runner    (1001) docker     (123)     1116 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/PardisoSupport
--rw-r--r--   0 runner    (1001) docker     (123)     1317 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/QR
--rw-r--r--   0 runner    (1001) docker     (123)      945 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/QtAlignedMalloc
--rw-r--r--   0 runner    (1001) docker     (123)     1162 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/SPQRSupport
--rw-r--r--   0 runner    (1001) docker     (123)     1629 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/SVD
--rw-r--r--   0 runner    (1001) docker     (123)      888 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/Sparse
--rw-r--r--   0 runner    (1001) docker     (123)     1235 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/SparseCholesky
--rw-r--r--   0 runner    (1001) docker     (123)     2240 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/SparseCore
--rw-r--r--   0 runner    (1001) docker     (123)     1814 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/SparseLU
--rw-r--r--   0 runner    (1001) docker     (123)     1195 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/SparseQR
--rw-r--r--   0 runner    (1001) docker     (123)      797 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/StdDeque
--rw-r--r--   0 runner    (1001) docker     (123)      726 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/StdList
--rw-r--r--   0 runner    (1001) docker     (123)      803 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/StdVector
--rw-r--r--   0 runner    (1001) docker     (123)     2243 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/SuperLUSupport
--rw-r--r--   0 runner    (1001) docker     (123)     1382 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/UmfPackSupport
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.729102 affine_transform-0.2.9/extern/eigen/Eigen/src/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.741103 affine_transform-0.2.9/extern/eigen/Eigen/src/Cholesky/
--rw-r--r--   0 runner    (1001) docker     (123)    24837 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Cholesky/LDLT.h
--rw-r--r--   0 runner    (1001) docker     (123)    18683 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Cholesky/LLT.h
--rw-r--r--   0 runner    (1001) docker     (123)     3974 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Cholesky/LLT_LAPACKE.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.741103 affine_transform-0.2.9/extern/eigen/Eigen/src/CholmodSupport/
--rw-r--r--   0 runner    (1001) docker     (123)    25441 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/CholmodSupport/CholmodSupport.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.749102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/
--rw-r--r--   0 runner    (1001) docker     (123)    19214 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ArithmeticSequence.h
--rw-r--r--   0 runner    (1001) docker     (123)    16713 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Array.h
--rw-r--r--   0 runner    (1001) docker     (123)     8159 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ArrayBase.h
--rw-r--r--   0 runner    (1001) docker     (123)     6775 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ArrayWrapper.h
--rw-r--r--   0 runner    (1001) docker     (123)     2738 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Assign.h
--rw-r--r--   0 runner    (1001) docker     (123)    40319 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/AssignEvaluator.h
--rwxr-xr-x   0 runner    (1001) docker     (123)    12488 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Assign_MKL.h
--rw-r--r--   0 runner    (1001) docker     (123)    13910 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/BandMatrix.h
--rw-r--r--   0 runner    (1001) docker     (123)    18400 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Block.h
--rw-r--r--   0 runner    (1001) docker     (123)     4301 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/BooleanRedux.h
--rw-r--r--   0 runner    (1001) docker     (123)     5725 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CommaInitializer.h
--rw-r--r--   0 runner    (1001) docker     (123)     6990 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ConditionEstimator.h
--rw-r--r--   0 runner    (1001) docker     (123)    63323 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CoreEvaluators.h
--rw-r--r--   0 runner    (1001) docker     (123)     4745 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CoreIterators.h
--rw-r--r--   0 runner    (1001) docker     (123)     7942 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CwiseBinaryOp.h
--rw-r--r--   0 runner    (1001) docker     (123)    33010 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CwiseNullaryOp.h
--rw-r--r--   0 runner    (1001) docker     (123)     8256 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CwiseTernaryOp.h
--rw-r--r--   0 runner    (1001) docker     (123)     3877 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CwiseUnaryOp.h
--rw-r--r--   0 runner    (1001) docker     (123)     5261 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CwiseUnaryView.h
--rw-r--r--   0 runner    (1001) docker     (123)    29874 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/DenseBase.h
--rw-r--r--   0 runner    (1001) docker     (123)    24220 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/DenseCoeffsBase.h
--rw-r--r--   0 runner    (1001) docker     (123)    22395 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/DenseStorage.h
--rw-r--r--   0 runner    (1001) docker     (123)     9705 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Diagonal.h
--rw-r--r--   0 runner    (1001) docker     (123)    14670 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/DiagonalMatrix.h
--rw-r--r--   0 runner    (1001) docker     (123)      988 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/DiagonalProduct.h
--rw-r--r--   0 runner    (1001) docker     (123)    11651 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Dot.h
--rw-r--r--   0 runner    (1001) docker     (123)     5751 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/EigenBase.h
--rw-r--r--   0 runner    (1001) docker     (123)     4769 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ForceAlignedAccess.h
--rw-r--r--   0 runner    (1001) docker     (123)     5759 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Fuzzy.h
--rw-r--r--   0 runner    (1001) docker     (123)    21847 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/GeneralProduct.h
--rw-r--r--   0 runner    (1001) docker     (123)    28139 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/GenericPacketMath.h
--rw-r--r--   0 runner    (1001) docker     (123)    11146 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/GlobalFunctions.h
--rw-r--r--   0 runner    (1001) docker     (123)     7434 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/IO.h
--rw-r--r--   0 runner    (1001) docker     (123)     8321 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/IndexedView.h
--rw-r--r--   0 runner    (1001) docker     (123)     3519 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Inverse.h
--rw-r--r--   0 runner    (1001) docker     (123)     7227 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Map.h
--rw-r--r--   0 runner    (1001) docker     (123)    10991 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/MapBase.h
--rw-r--r--   0 runner    (1001) docker     (123)    51671 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/MathFunctions.h
--rw-r--r--   0 runner    (1001) docker     (123)     3106 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/MathFunctionsImpl.h
--rw-r--r--   0 runner    (1001) docker     (123)    24287 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Matrix.h
--rw-r--r--   0 runner    (1001) docker     (123)    23793 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/MatrixBase.h
--rw-r--r--   0 runner    (1001) docker     (123)     2458 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/NestByValue.h
--rw-r--r--   0 runner    (1001) docker     (123)     3620 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/NoAlias.h
--rw-r--r--   0 runner    (1001) docker     (123)    10337 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/NumTraits.h
--rw-r--r--   0 runner    (1001) docker     (123)     9197 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/PartialReduxEvaluator.h
--rw-r--r--   0 runner    (1001) docker     (123)    21700 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/PermutationMatrix.h
--rw-r--r--   0 runner    (1001) docker     (123)    48524 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/PlainObjectBase.h
--rw-r--r--   0 runner    (1001) docker     (123)     7333 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Product.h
--rw-r--r--   0 runner    (1001) docker     (123)    53259 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ProductEvaluators.h
--rw-r--r--   0 runner    (1001) docker     (123)     6397 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Random.h
--rw-r--r--   0 runner    (1001) docker     (123)    18669 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Redux.h
--rw-r--r--   0 runner    (1001) docker     (123)    13060 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Ref.h
--rw-r--r--   0 runner    (1001) docker     (123)     5631 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Replicate.h
--rw-r--r--   0 runner    (1001) docker     (123)    17000 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Reshaped.h
--rw-r--r--   0 runner    (1001) docker     (123)     4218 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ReturnByValue.h
--rw-r--r--   0 runner    (1001) docker     (123)     7457 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Reverse.h
--rw-r--r--   0 runner    (1001) docker     (123)     6020 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Select.h
--rw-r--r--   0 runner    (1001) docker     (123)    14873 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/SelfAdjointView.h
--rw-r--r--   0 runner    (1001) docker     (123)     1697 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/SelfCwiseBinaryOp.h
--rw-r--r--   0 runner    (1001) docker     (123)     6797 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Solve.h
--rw-r--r--   0 runner    (1001) docker     (123)     9154 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/SolveTriangular.h
--rw-r--r--   0 runner    (1001) docker     (123)     6170 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/SolverBase.h
--rw-r--r--   0 runner    (1001) docker     (123)     8901 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/StableNorm.h
--rw-r--r--   0 runner    (1001) docker     (123)    14553 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/StlIterators.h
--rw-r--r--   0 runner    (1001) docker     (123)     3865 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Stride.h
--rw-r--r--   0 runner    (1001) docker     (123)     2765 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Swap.h
--rw-r--r--   0 runner    (1001) docker     (123)    15268 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Transpose.h
--rw-r--r--   0 runner    (1001) docker     (123)    14385 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Transpositions.h
--rw-r--r--   0 runner    (1001) docker     (123)    38039 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/TriangularMatrix.h
--rw-r--r--   0 runner    (1001) docker     (123)     3488 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/VectorBlock.h
--rw-r--r--   0 runner    (1001) docker     (123)    33275 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/VectorwiseOp.h
--rw-r--r--   0 runner    (1001) docker     (123)     9304 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Visitor.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.721103 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.749102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX/
--rw-r--r--   0 runner    (1001) docker     (123)    19172 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX/Complex.h
--rw-r--r--   0 runner    (1001) docker     (123)     5206 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX/MathFunctions.h
--rw-r--r--   0 runner    (1001) docker     (123)    36713 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX/PacketMath.h
--rw-r--r--   0 runner    (1001) docker     (123)     1453 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX/TypeCasting.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.757102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX512/
--rw-r--r--   0 runner    (1001) docker     (123)    19583 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX512/Complex.h
--rw-r--r--   0 runner    (1001) docker     (123)    15855 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX512/MathFunctions.h
--rw-r--r--   0 runner    (1001) docker     (123)    54439 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX512/PacketMath.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.757102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AltiVec/
--rw-r--r--   0 runner    (1001) docker     (123)    17442 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AltiVec/Complex.h
--rw-r--r--   0 runner    (1001) docker     (123)     2170 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AltiVec/MathFunctions.h
--rwxr-xr-x   0 runner    (1001) docker     (123)    42819 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AltiVec/PacketMath.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.757102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/CUDA/
--rw-r--r--   0 runner    (1001) docker     (123)     4244 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/CUDA/Complex.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.757102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/Default/
--rw-r--r--   0 runner    (1001) docker     (123)     1989 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/Default/ConjHelper.h
--rw-r--r--   0 runner    (1001) docker     (123)    19102 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h
--rw-r--r--   0 runner    (1001) docker     (123)     1746 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/Default/Settings.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.757102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/GPU/
--rw-r--r--   0 runner    (1001) docker     (123)    26865 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/GPU/Half.h
--rw-r--r--   0 runner    (1001) docker     (123)     2695 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/GPU/MathFunctions.h
--rw-r--r--   0 runner    (1001) docker     (123)    16855 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/GPU/PacketMath.h
--rw-r--r--   0 runner    (1001) docker     (123)    52270 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/GPU/PacketMathHalf.h
--rw-r--r--   0 runner    (1001) docker     (123)     5838 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/GPU/TypeCasting.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.721103 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/HIP/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.757102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/HIP/hcc/
--rw-r--r--   0 runner    (1001) docker     (123)      691 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/HIP/hcc/math_constants.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.757102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/MSA/
--rw-r--r--   0 runner    (1001) docker     (123)    20970 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/MSA/Complex.h
--rw-r--r--   0 runner    (1001) docker     (123)    16159 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/MSA/MathFunctions.h
--rw-r--r--   0 runner    (1001) docker     (123)    37020 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/MSA/PacketMath.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.757102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/NEON/
--rw-r--r--   0 runner    (1001) docker     (123)    19035 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/NEON/Complex.h
--rw-r--r--   0 runner    (1001) docker     (123)     1145 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/NEON/MathFunctions.h
--rw-r--r--   0 runner    (1001) docker     (123)    31150 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/NEON/PacketMath.h
--rw-r--r--   0 runner    (1001) docker     (123)     1338 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/NEON/TypeCasting.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.757102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SSE/
--rw-r--r--   0 runner    (1001) docker     (123)    20480 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SSE/Complex.h
--rw-r--r--   0 runner    (1001) docker     (123)     5738 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SSE/MathFunctions.h
--rwxr-xr-x   0 runner    (1001) docker     (123)    42840 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SSE/PacketMath.h
--rw-r--r--   0 runner    (1001) docker     (123)     2010 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SSE/TypeCasting.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.757102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SYCL/
--rw-r--r--   0 runner    (1001) docker     (123)     6779 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SYCL/InteropHeaders.h
--rw-r--r--   0 runner    (1001) docker     (123)    11407 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SYCL/MathFunctions.h
--rw-r--r--   0 runner    (1001) docker     (123)    23172 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SYCL/PacketMath.h
--rw-r--r--   0 runner    (1001) docker     (123)    21856 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SYCL/SyclMemoryModel.h
--rw-r--r--   0 runner    (1001) docker     (123)     2626 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SYCL/TypeCasting.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.757102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/ZVector/
--rw-r--r--   0 runner    (1001) docker     (123)    20514 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/ZVector/Complex.h
--rw-r--r--   0 runner    (1001) docker     (123)     8025 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/ZVector/MathFunctions.h
--rwxr-xr-x   0 runner    (1001) docker     (123)    40672 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/ZVector/PacketMath.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.761103 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/
--rw-r--r--   0 runner    (1001) docker     (123)     6686 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/AssignmentFunctors.h
--rw-r--r--   0 runner    (1001) docker     (123)    18317 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/BinaryFunctors.h
--rw-r--r--   0 runner    (1001) docker     (123)     8020 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/NullaryFunctors.h
--rw-r--r--   0 runner    (1001) docker     (123)     4400 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/StlFunctors.h
--rw-r--r--   0 runner    (1001) docker     (123)      607 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/TernaryFunctors.h
--rw-r--r--   0 runner    (1001) docker     (123)    34616 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/UnaryFunctors.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.761103 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/
--rw-r--r--   0 runner    (1001) docker     (123)   112678 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralBlockPanelKernel.h
--rw-r--r--   0 runner    (1001) docker     (123)    19887 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrix.h
--rw-r--r--   0 runner    (1001) docker     (123)    15244 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular.h
--rw-r--r--   0 runner    (1001) docker     (123)     6906 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular_BLAS.h
--rw-r--r--   0 runner    (1001) docker     (123)     5017 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h
--rw-r--r--   0 runner    (1001) docker     (123)    21724 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixVector.h
--rw-r--r--   0 runner    (1001) docker     (123)     6368 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixVector_BLAS.h
--rw-r--r--   0 runner    (1001) docker     (123)     5560 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/Parallelizer.h
--rw-r--r--   0 runner    (1001) docker     (123)    20883 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix.h
--rw-r--r--   0 runner    (1001) docker     (123)    11198 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix_BLAS.h
--rw-r--r--   0 runner    (1001) docker     (123)     9958 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixVector.h
--rw-r--r--   0 runner    (1001) docker     (123)     5209 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixVector_BLAS.h
--rw-r--r--   0 runner    (1001) docker     (123)     6123 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointProduct.h
--rw-r--r--   0 runner    (1001) docker     (123)     4104 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointRank2Update.h
--rw-r--r--   0 runner    (1001) docker     (123)    20511 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularMatrixMatrix.h
--rw-r--r--   0 runner    (1001) docker     (123)    13743 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularMatrixMatrix_BLAS.h
--rw-r--r--   0 runner    (1001) docker     (123)    14722 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularMatrixVector.h
--rw-r--r--   0 runner    (1001) docker     (123)    10571 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularMatrixVector_BLAS.h
--rw-r--r--   0 runner    (1001) docker     (123)    14051 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularSolverMatrix.h
--rw-r--r--   0 runner    (1001) docker     (123)     6513 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularSolverMatrix_BLAS.h
--rw-r--r--   0 runner    (1001) docker     (123)     5882 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularSolverVector.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.765102 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/
--rwxr-xr-x   0 runner    (1001) docker     (123)    15726 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/BlasUtil.h
--rw-r--r--   0 runner    (1001) docker     (123)    16738 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/ConfigureVectorization.h
--rw-r--r--   0 runner    (1001) docker     (123)    21806 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/Constants.h
--rwxr-xr-x   0 runner    (1001) docker     (123)     4514 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/DisableStupidWarnings.h
--rw-r--r--   0 runner    (1001) docker     (123)    14528 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/ForwardDeclarations.h
--rw-r--r--   0 runner    (1001) docker     (123)     6525 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/IndexedViewHelper.h
--rw-r--r--   0 runner    (1001) docker     (123)    10895 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/IntegralConstant.h
--rwxr-xr-x   0 runner    (1001) docker     (123)     4268 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/MKL_support.h
--rw-r--r--   0 runner    (1001) docker     (123)    44804 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/Macros.h
--rw-r--r--   0 runner    (1001) docker     (123)    45640 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/Memory.h
--rwxr-xr-x   0 runner    (1001) docker     (123)    24335 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/Meta.h
--rw-r--r--   0 runner    (1001) docker     (123)       85 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/NonMPL2.h
--rw-r--r--   0 runner    (1001) docker     (123)     1024 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/ReenableStupidWarnings.h
--rw-r--r--   0 runner    (1001) docker     (123)     1432 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/ReshapedHelper.h
--rw-r--r--   0 runner    (1001) docker     (123)    10643 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/StaticAssert.h
--rw-r--r--   0 runner    (1001) docker     (123)    11987 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/SymbolicIndex.h
--rw-r--r--   0 runner    (1001) docker     (123)    35678 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/XprHelper.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.765102 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/
--rw-r--r--   0 runner    (1001) docker     (123)    12559 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/ComplexEigenSolver.h
--rw-r--r--   0 runner    (1001) docker     (123)    17274 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/ComplexSchur.h
--rw-r--r--   0 runner    (1001) docker     (123)     4178 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/ComplexSchur_LAPACKE.h
--rw-r--r--   0 runner    (1001) docker     (123)    22970 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/EigenSolver.h
--rw-r--r--   0 runner    (1001) docker     (123)    17176 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/GeneralizedEigenSolver.h
--rw-r--r--   0 runner    (1001) docker     (123)     9716 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/GeneralizedSelfAdjointEigenSolver.h
--rw-r--r--   0 runner    (1001) docker     (123)    14339 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/HessenbergDecomposition.h
--rw-r--r--   0 runner    (1001) docker     (123)     5575 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/MatrixBaseEigenvalues.h
--rw-r--r--   0 runner    (1001) docker     (123)    23640 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/RealQZ.h
--rw-r--r--   0 runner    (1001) docker     (123)    21078 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/RealSchur.h
--rw-r--r--   0 runner    (1001) docker     (123)     3650 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/RealSchur_LAPACKE.h
--rw-r--r--   0 runner    (1001) docker     (123)    33949 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h
--rw-r--r--   0 runner    (1001) docker     (123)     4104 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver_LAPACKE.h
--rw-r--r--   0 runner    (1001) docker     (123)    22538 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/Tridiagonalization.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.769102 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/
--rw-r--r--   0 runner    (1001) docker     (123)    14840 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/AlignedBox.h
--rw-r--r--   0 runner    (1001) docker     (123)     8423 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/AngleAxis.h
--rw-r--r--   0 runner    (1001) docker     (123)     3639 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/EulerAngles.h
--rw-r--r--   0 runner    (1001) docker     (123)    20539 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Homogeneous.h
--rw-r--r--   0 runner    (1001) docker     (123)    11962 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Hyperplane.h
--rw-r--r--   0 runner    (1001) docker     (123)     8955 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/OrthoMethods.h
--rw-r--r--   0 runner    (1001) docker     (123)     9817 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/ParametrizedLine.h
--rw-r--r--   0 runner    (1001) docker     (123)    32995 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Quaternion.h
--rw-r--r--   0 runner    (1001) docker     (123)     6877 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Rotation2D.h
--rw-r--r--   0 runner    (1001) docker     (123)     8063 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/RotationBase.h
--rwxr-xr-x   0 runner    (1001) docker     (123)     6717 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Scaling.h
--rw-r--r--   0 runner    (1001) docker     (123)    61854 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Transform.h
--rw-r--r--   0 runner    (1001) docker     (123)     7773 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Translation.h
--rw-r--r--   0 runner    (1001) docker     (123)     6191 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Umeyama.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.769102 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/arch/
--rw-r--r--   0 runner    (1001) docker     (123)     5823 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/arch/Geometry_SSE.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.769102 affine_transform-0.2.9/extern/eigen/Eigen/src/Householder/
--rw-r--r--   0 runner    (1001) docker     (123)     4784 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Householder/BlockHouseholder.h
--rw-r--r--   0 runner    (1001) docker     (123)     5365 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Householder/Householder.h
--rw-r--r--   0 runner    (1001) docker     (123)    23569 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Householder/HouseholderSequence.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.769102 affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/
--rw-r--r--   0 runner    (1001) docker     (123)     6755 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/BasicPreconditioners.h
--rw-r--r--   0 runner    (1001) docker     (123)     6850 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/BiCGSTAB.h
--rw-r--r--   0 runner    (1001) docker     (123)     8875 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/ConjugateGradient.h
--rw-r--r--   0 runner    (1001) docker     (123)    15048 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/IncompleteCholesky.h
--rw-r--r--   0 runner    (1001) docker     (123)    14962 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/IncompleteLUT.h
--rw-r--r--   0 runner    (1001) docker     (123)    13349 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/IterativeSolverBase.h
--rw-r--r--   0 runner    (1001) docker     (123)     7349 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/LeastSquareConjugateGradient.h
--rw-r--r--   0 runner    (1001) docker     (123)     4158 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/SolveWithGuess.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.769102 affine_transform-0.2.9/extern/eigen/Eigen/src/Jacobi/
--rw-r--r--   0 runner    (1001) docker     (123)    16373 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/Jacobi/Jacobi.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.769102 affine_transform-0.2.9/extern/eigen/Eigen/src/KLUSupport/
--rw-r--r--   0 runner    (1001) docker     (123)    11534 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/KLUSupport/KLUSupport.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.769102 affine_transform-0.2.9/extern/eigen/Eigen/src/LU/
--rw-r--r--   0 runner    (1001) docker     (123)     3439 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/LU/Determinant.h
--rw-r--r--   0 runner    (1001) docker     (123)    32313 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/LU/FullPivLU.h
--rw-r--r--   0 runner    (1001) docker     (123)    15102 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/LU/InverseImpl.h
--rw-r--r--   0 runner    (1001) docker     (123)    21856 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/LU/PartialPivLU.h
--rw-r--r--   0 runner    (1001) docker     (123)     3555 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/LU/PartialPivLU_LAPACKE.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.769102 affine_transform-0.2.9/extern/eigen/Eigen/src/LU/arch/
--rw-r--r--   0 runner    (1001) docker     (123)    13662 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/LU/arch/Inverse_SSE.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.769102 affine_transform-0.2.9/extern/eigen/Eigen/src/MetisSupport/
--rw-r--r--   0 runner    (1001) docker     (123)     4588 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/MetisSupport/MetisSupport.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.769102 affine_transform-0.2.9/extern/eigen/Eigen/src/OrderingMethods/
--rw-r--r--   0 runner    (1001) docker     (123)    16105 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/OrderingMethods/Amd.h
--rw-r--r--   0 runner    (1001) docker     (123)    62265 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/OrderingMethods/Eigen_Colamd.h
--rw-r--r--   0 runner    (1001) docker     (123)     5204 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/OrderingMethods/Ordering.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.769102 affine_transform-0.2.9/extern/eigen/Eigen/src/PaStiXSupport/
--rw-r--r--   0 runner    (1001) docker     (123)    22249 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/PaStiXSupport/PaStiXSupport.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.773102 affine_transform-0.2.9/extern/eigen/Eigen/src/PardisoSupport/
--rw-r--r--   0 runner    (1001) docker     (123)    20091 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/PardisoSupport/PardisoSupport.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.773102 affine_transform-0.2.9/extern/eigen/Eigen/src/QR/
--rw-r--r--   0 runner    (1001) docker     (123)    25498 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/QR/ColPivHouseholderQR.h
--rw-r--r--   0 runner    (1001) docker     (123)     4662 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/QR/ColPivHouseholderQR_LAPACKE.h
--rw-r--r--   0 runner    (1001) docker     (123)    23029 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/QR/CompleteOrthogonalDecomposition.h
--rw-r--r--   0 runner    (1001) docker     (123)    26768 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/QR/FullPivHouseholderQR.h
--rw-r--r--   0 runner    (1001) docker     (123)    14641 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/QR/HouseholderQR.h
--rw-r--r--   0 runner    (1001) docker     (123)     2993 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/QR/HouseholderQR_LAPACKE.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.773102 affine_transform-0.2.9/extern/eigen/Eigen/src/SPQRSupport/
--rw-r--r--   0 runner    (1001) docker     (123)    11826 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SPQRSupport/SuiteSparseQRSupport.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.773102 affine_transform-0.2.9/extern/eigen/Eigen/src/SVD/
--rw-r--r--   0 runner    (1001) docker     (123)    53680 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SVD/BDCSVD.h
--rw-r--r--   0 runner    (1001) docker     (123)    32993 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SVD/JacobiSVD.h
--rw-r--r--   0 runner    (1001) docker     (123)     5099 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SVD/JacobiSVD_LAPACKE.h
--rw-r--r--   0 runner    (1001) docker     (123)    14266 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SVD/SVDBase.h
--rw-r--r--   0 runner    (1001) docker     (123)    15957 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SVD/UpperBidiagonalization.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.773102 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCholesky/
--rw-r--r--   0 runner    (1001) docker     (123)    24177 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCholesky/SimplicialCholesky.h
--rw-r--r--   0 runner    (1001) docker     (123)     5816 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCholesky/SimplicialCholesky_impl.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.777102 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/
--rw-r--r--   0 runner    (1001) docker     (123)    10537 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/AmbiVector.h
--rw-r--r--   0 runner    (1001) docker     (123)     8743 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/CompressedStorage.h
--rw-r--r--   0 runner    (1001) docker     (123)    13178 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/ConservativeSparseSparseProduct.h
--rw-r--r--   0 runner    (1001) docker     (123)     2191 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/MappedSparseMatrix.h
--rw-r--r--   0 runner    (1001) docker     (123)    11368 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseAssign.h
--rw-r--r--   0 runner    (1001) docker     (123)    23759 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseBlock.h
--rw-r--r--   0 runner    (1001) docker     (123)     6485 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseColEtree.h
--rw-r--r--   0 runner    (1001) docker     (123)    13606 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseCompressedBase.h
--rw-r--r--   0 runner    (1001) docker     (123)    25426 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseCwiseBinaryOp.h
--rw-r--r--   0 runner    (1001) docker     (123)     4711 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseCwiseUnaryOp.h
--rw-r--r--   0 runner    (1001) docker     (123)    13256 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseDenseProduct.h
--rw-r--r--   0 runner    (1001) docker     (123)     5808 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseDiagonalProduct.h
--rw-r--r--   0 runner    (1001) docker     (123)     3080 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseDot.h
--rw-r--r--   0 runner    (1001) docker     (123)     1107 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseFuzzy.h
--rw-r--r--   0 runner    (1001) docker     (123)    12589 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseMap.h
--rw-r--r--   0 runner    (1001) docker     (123)    57169 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseMatrix.h
--rw-r--r--   0 runner    (1001) docker     (123)    17451 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseMatrixBase.h
--rw-r--r--   0 runner    (1001) docker     (123)     7329 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparsePermutation.h
--rw-r--r--   0 runner    (1001) docker     (123)     7050 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseProduct.h
--rw-r--r--   0 runner    (1001) docker     (123)     1699 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseRedux.h
--rw-r--r--   0 runner    (1001) docker     (123)    15492 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseRef.h
--rw-r--r--   0 runner    (1001) docker     (123)    25715 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseSelfAdjointView.h
--rw-r--r--   0 runner    (1001) docker     (123)     4424 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseSolverBase.h
--rw-r--r--   0 runner    (1001) docker     (123)     8704 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseSparseProductWithPruning.h
--rw-r--r--   0 runner    (1001) docker     (123)     3175 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseTranspose.h
--rw-r--r--   0 runner    (1001) docker     (123)     6437 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseTriangularView.h
--rw-r--r--   0 runner    (1001) docker     (123)     6827 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseUtil.h
--rw-r--r--   0 runner    (1001) docker     (123)    14832 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseVector.h
--rw-r--r--   0 runner    (1001) docker     (123)     8110 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseView.h
--rw-r--r--   0 runner    (1001) docker     (123)     9657 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/TriangularSolver.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.777102 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/
--rw-r--r--   0 runner    (1001) docker     (123)    27954 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU.h
--rw-r--r--   0 runner    (1001) docker     (123)     4303 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLUImpl.h
--rw-r--r--   0 runner    (1001) docker     (123)     7602 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_Memory.h
--rw-r--r--   0 runner    (1001) docker     (123)     4974 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_Structs.h
--rw-r--r--   0 runner    (1001) docker     (123)    10034 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_SupernodalMatrix.h
--rw-r--r--   0 runner    (1001) docker     (123)     2049 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_Utils.h
--rw-r--r--   0 runner    (1001) docker     (123)     6712 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_column_bmod.h
--rw-r--r--   0 runner    (1001) docker     (123)     6584 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_column_dfs.h
--rw-r--r--   0 runner    (1001) docker     (123)     3681 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_copy_to_ucol.h
--rw-r--r--   0 runner    (1001) docker     (123)    10217 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_gemm_kernel.h
--rw-r--r--   0 runner    (1001) docker     (123)     4181 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_heap_relax_snode.h
--rw-r--r--   0 runner    (1001) docker     (123)     5723 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_kernel_bmod.h
--rw-r--r--   0 runner    (1001) docker     (123)     8485 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_panel_bmod.h
--rw-r--r--   0 runner    (1001) docker     (123)     9028 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_panel_dfs.h
--rw-r--r--   0 runner    (1001) docker     (123)     4979 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_pivotL.h
--rw-r--r--   0 runner    (1001) docker     (123)     4545 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_pruneL.h
--rw-r--r--   0 runner    (1001) docker     (123)     2889 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_relax_snode.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.777102 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseQR/
--rw-r--r--   0 runner    (1001) docker     (123)    29167 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SparseQR/SparseQR.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.777102 affine_transform-0.2.9/extern/eigen/Eigen/src/StlSupport/
--rw-r--r--   0 runner    (1001) docker     (123)     5125 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/StlSupport/StdDeque.h
--rw-r--r--   0 runner    (1001) docker     (123)     4155 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/StlSupport/StdList.h
--rw-r--r--   0 runner    (1001) docker     (123)     5338 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/StlSupport/StdVector.h
--rw-r--r--   0 runner    (1001) docker     (123)     2809 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/StlSupport/details.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.777102 affine_transform-0.2.9/extern/eigen/Eigen/src/SuperLUSupport/
--rw-r--r--   0 runner    (1001) docker     (123)    34346 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/SuperLUSupport/SuperLUSupport.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.781102 affine_transform-0.2.9/extern/eigen/Eigen/src/UmfPackSupport/
--rw-r--r--   0 runner    (1001) docker     (123)    24456 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/UmfPackSupport/UmfPackSupport.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.781102 affine_transform-0.2.9/extern/eigen/Eigen/src/misc/
--rw-r--r--   0 runner    (1001) docker     (123)     2913 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/misc/Image.h
--rw-r--r--   0 runner    (1001) docker     (123)     2742 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/misc/Kernel.h
--rw-r--r--   0 runner    (1001) docker     (123)     1748 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/misc/RealSvd2x2.h
--rw-r--r--   0 runner    (1001) docker     (123)    30560 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/misc/blas.h
--rw-r--r--   0 runner    (1001) docker     (123)     7834 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/misc/lapack.h
--rwxr-xr-x   0 runner    (1001) docker     (123)  1058369 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/misc/lapacke.h
--rw-r--r--   0 runner    (1001) docker     (123)      474 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/misc/lapacke_mangling.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.781102 affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/
--rw-r--r--   0 runner    (1001) docker     (123)    13132 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/ArrayCwiseBinaryOps.h
--rw-r--r--   0 runner    (1001) docker     (123)    19027 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/ArrayCwiseUnaryOps.h
--rw-r--r--   0 runner    (1001) docker     (123)    59005 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/BlockMethods.h
--rw-r--r--   0 runner    (1001) docker     (123)     4828 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/CommonCwiseBinaryOps.h
--rw-r--r--   0 runner    (1001) docker     (123)     6089 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/CommonCwiseUnaryOps.h
--rw-r--r--   0 runner    (1001) docker     (123)    12283 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/IndexedViewMethods.h
--rw-r--r--   0 runner    (1001) docker     (123)     6375 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/MatrixCwiseBinaryOps.h
--rw-r--r--   0 runner    (1001) docker     (123)     2937 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/MatrixCwiseUnaryOps.h
--rw-r--r--   0 runner    (1001) docker     (123)     6915 2023-04-22 11:29:06.000000 affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/ReshapedMethods.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.781102 affine_transform-0.2.9/extern/pybind11/
--rw-r--r--   0 runner    (1001) docker     (123)     6507 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/CMakeLists.txt
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.729102 affine_transform-0.2.9/extern/pybind11/include/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.785102 affine_transform-0.2.9/extern/pybind11/include/pybind11/
--rw-r--r--   0 runner    (1001) docker     (123)    19063 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/attr.h
--rw-r--r--   0 runner    (1001) docker     (123)     4326 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/buffer_info.h
--rw-r--r--   0 runner    (1001) docker     (123)    89522 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/cast.h
--rw-r--r--   0 runner    (1001) docker     (123)     6657 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/chrono.h
--rw-r--r--   0 runner    (1001) docker     (123)      120 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/common.h
--rw-r--r--   0 runner    (1001) docker     (123)     2001 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/complex.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.785102 affine_transform-0.2.9/extern/pybind11/include/pybind11/detail/
--rw-r--r--   0 runner    (1001) docker     (123)    24772 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/detail/class.h
--rw-r--r--   0 runner    (1001) docker     (123)    37068 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/detail/common.h
--rw-r--r--   0 runner    (1001) docker     (123)     3566 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/detail/descr.h
--rw-r--r--   0 runner    (1001) docker     (123)    16322 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/detail/init.h
--rw-r--r--   0 runner    (1001) docker     (123)    14022 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/detail/internals.h
--rw-r--r--   0 runner    (1001) docker     (123)     1450 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/detail/typeid.h
--rw-r--r--   0 runner    (1001) docker     (123)    29043 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/eigen.h
--rw-r--r--   0 runner    (1001) docker     (123)     7731 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/embed.h
--rw-r--r--   0 runner    (1001) docker     (123)     3865 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/eval.h
--rw-r--r--   0 runner    (1001) docker     (123)     3599 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/functional.h
--rw-r--r--   0 runner    (1001) docker     (123)     5655 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/iostream.h
--rw-r--r--   0 runner    (1001) docker     (123)    66163 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/numpy.h
--rw-r--r--   0 runner    (1001) docker     (123)     8749 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/operators.h
--rw-r--r--   0 runner    (1001) docker     (123)     2031 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/options.h
--rw-r--r--   0 runner    (1001) docker     (123)    96604 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/pybind11.h
--rw-r--r--   0 runner    (1001) docker     (123)    57794 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/pytypes.h
--rw-r--r--   0 runner    (1001) docker     (123)    14029 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/stl.h
--rw-r--r--   0 runner    (1001) docker     (123)    22528 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/include/pybind11/stl_bind.h
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.785102 affine_transform-0.2.9/extern/pybind11/tools/
--rw-r--r--   0 runner    (1001) docker     (123)     2100 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/FindCatch.cmake
--rw-r--r--   0 runner    (1001) docker     (123)     2995 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/FindEigen3.cmake
--rw-r--r--   0 runner    (1001) docker     (123)     8336 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/FindPythonLibsNew.cmake
--rwxr-xr-x   0 runner    (1001) docker     (123)     2528 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/check-style.sh
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.785102 affine_transform-0.2.9/extern/pybind11/tools/clang/
--rw-r--r--   0 runner    (1001) docker     (123)       69 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/clang/.git
--rw-r--r--   0 runner    (1001) docker     (123)       30 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/clang/.gitignore
--rw-r--r--   0 runner    (1001) docker     (123)     2749 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/clang/LICENSE.TXT
--rw-r--r--   0 runner    (1001) docker     (123)      172 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/clang/README.md
--rw-r--r--   0 runner    (1001) docker     (123)      565 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/clang/__init__.py
--rw-r--r--   0 runner    (1001) docker     (123)   115943 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/clang/cindex.py
--rw-r--r--   0 runner    (1001) docker     (123)     1077 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/clang/enumerations.py
--rw-r--r--   0 runner    (1001) docker     (123)     1098 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/libsize.py
--rwxr-xr-x   0 runner    (1001) docker     (123)    12534 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/mkdoc.py
--rw-r--r--   0 runner    (1001) docker     (123)     4153 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/pybind11Config.cmake.in
--rw-r--r--   0 runner    (1001) docker     (123)     9582 2023-04-22 11:29:07.000000 affine_transform-0.2.9/extern/pybind11/tools/pybind11Tools.cmake
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.729102 affine_transform-0.2.9/include/
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.789102 affine_transform-0.2.9/include/affine_transform/
--rw-r--r--   0 runner    (1001) docker     (123)     6268 2023-04-22 11:28:58.000000 affine_transform-0.2.9/include/affine_transform/affine_transform.hpp
--rw-r--r--   0 runner    (1001) docker     (123)    18132 2023-04-22 11:28:58.000000 affine_transform-0.2.9/include/affine_transform/interpolation.hpp
--rw-r--r--   0 runner    (1001) docker     (123)       99 2023-04-22 11:28:58.000000 affine_transform-0.2.9/pyproject.toml
--rw-r--r--   0 runner    (1001) docker     (123)      203 2023-04-22 11:28:58.000000 affine_transform-0.2.9/readthedocs.yml
--rw-r--r--   0 runner    (1001) docker     (123)       94 2023-04-22 11:29:19.789102 affine_transform-0.2.9/setup.cfg
--rw-r--r--   0 runner    (1001) docker     (123)     4362 2023-04-22 11:28:58.000000 affine_transform-0.2.9/setup.py
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.789102 affine_transform-0.2.9/src/
--rw-r--r--   0 runner    (1001) docker     (123)     5312 2023-04-22 11:28:58.000000 affine_transform-0.2.9/src/main.cpp
-drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-22 11:29:19.789102 affine_transform-0.2.9/tests/
--rw-r--r--   0 runner    (1001) docker     (123)     7301 2023-04-22 11:28:58.000000 affine_transform-0.2.9/tests/test_affine_transform.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.924751 affine_transform-0.3.0/
+-rw-r--r--   0 runner    (1001) docker     (123)      504 2023-04-23 14:44:18.000000 affine_transform-0.3.0/.appveyor.yml
+-rw-r--r--   0 runner    (1001) docker     (123)      306 2023-04-23 14:44:18.000000 affine_transform-0.3.0/.clang-format
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.812750 affine_transform-0.3.0/.github/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.824750 affine_transform-0.3.0/.github/workflows/
+-rw-r--r--   0 runner    (1001) docker     (123)      731 2023-04-23 14:44:18.000000 affine_transform-0.3.0/.github/workflows/deploy.yml
+-rw-r--r--   0 runner    (1001) docker     (123)      787 2023-04-23 14:44:18.000000 affine_transform-0.3.0/.github/workflows/deploy_test.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     1225 2023-04-23 14:44:18.000000 affine_transform-0.3.0/.github/workflows/test-package.yml
+-rw-r--r--   0 runner    (1001) docker     (123)     2385 2023-04-23 14:44:18.000000 affine_transform-0.3.0/.gitignore
+-rw-r--r--   0 runner    (1001) docker     (123)      217 2023-04-23 14:44:18.000000 affine_transform-0.3.0/.gitmodules
+-rw-r--r--   0 runner    (1001) docker     (123)      656 2023-04-23 14:44:18.000000 affine_transform-0.3.0/CMakeLists.txt
+-rw-r--r--   0 runner    (1001) docker     (123)     1074 2023-04-23 14:44:18.000000 affine_transform-0.3.0/LICENSE
+-rw-r--r--   0 runner    (1001) docker     (123)      232 2023-04-23 14:44:18.000000 affine_transform-0.3.0/MANIFEST.in
+-rw-r--r--   0 runner    (1001) docker     (123)     3567 2023-04-23 14:44:49.924751 affine_transform-0.3.0/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)     3019 2023-04-23 14:44:18.000000 affine_transform-0.3.0/README.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.824750 affine_transform-0.3.0/affine_transform/
+-rw-r--r--   0 runner    (1001) docker     (123)      205 2023-04-23 14:44:18.000000 affine_transform-0.3.0/affine_transform/__init__.py
+-rw-r--r--   0 runner    (1001) docker     (123)     6235 2023-04-23 14:44:18.000000 affine_transform-0.3.0/affine_transform/affine_transform.py
+-rw-r--r--   0 runner    (1001) docker     (123)        5 2023-04-23 14:44:49.000000 affine_transform-0.3.0/affine_transform/version.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.828750 affine_transform-0.3.0/affine_transform.egg-info/
+-rw-r--r--   0 runner    (1001) docker     (123)     3567 2023-04-23 14:44:49.000000 affine_transform-0.3.0/affine_transform.egg-info/PKG-INFO
+-rw-r--r--   0 runner    (1001) docker     (123)    19582 2023-04-23 14:44:49.000000 affine_transform-0.3.0/affine_transform.egg-info/SOURCES.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-04-23 14:44:49.000000 affine_transform-0.3.0/affine_transform.egg-info/dependency_links.txt
+-rw-r--r--   0 runner    (1001) docker     (123)        1 2023-04-23 14:44:49.000000 affine_transform-0.3.0/affine_transform.egg-info/not-zip-safe
+-rw-r--r--   0 runner    (1001) docker     (123)       26 2023-04-23 14:44:49.000000 affine_transform-0.3.0/affine_transform.egg-info/requires.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       17 2023-04-23 14:44:49.000000 affine_transform-0.3.0/affine_transform.egg-info/top_level.txt
+-rw-r--r--   0 runner    (1001) docker     (123)       22 2023-04-23 14:44:18.000000 affine_transform-0.3.0/codecov.yml
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.828750 affine_transform-0.3.0/docs/
+-rw-r--r--   0 runner    (1001) docker     (123)     6862 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/conf.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.828750 affine_transform-0.3.0/docs/cpp/
+-rw-r--r--   0 runner    (1001) docker     (123)        5 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp/.gitignore
+-rw-r--r--   0 runner    (1001) docker     (123)   112013 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp/Doxyfile
+-rw-r--r--   0 runner    (1001) docker     (123)      759 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_doc.rst
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.832750 affine_transform-0.3.0/docs/cpp_docs/
+-rw-r--r--   0 runner    (1001) docker     (123)      652 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_docs/affine_transform.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      120 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_docs/apply_interpolation.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      115 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_docs/constant_boundary.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      107 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_docs/cubic_interpolation.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      196 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_docs/data_struct.rst
+-rw-r--r--   0 runner    (1001) docker     (123)       75 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_docs/extract.rst
+-rw-r--r--   0 runner    (1001) docker     (123)     1287 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_docs/interpolation.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      110 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_docs/linear_interpolation.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      357 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_docs/python_bindings.rst
+-rw-r--r--   0 runner    (1001) docker     (123)       84 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_docs/transform.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      107 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/cpp_docs/transform_loop.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      422 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/how_to_use.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      477 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/index.rst
+-rw-r--r--   0 runner    (1001) docker     (123)      752 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/make.bat
+-rw-r--r--   0 runner    (1001) docker     (123)      102 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/module_doc.rst
+-rw-r--r--   0 runner    (1001) docker     (123)       64 2023-04-23 14:44:18.000000 affine_transform-0.3.0/docs/requirements.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.832750 affine_transform-0.3.0/examples/
+-rw-r--r--   0 runner    (1001) docker     (123)     1867 2023-04-23 14:44:18.000000 affine_transform-0.3.0/examples/rotation_and_translation.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.820750 affine_transform-0.3.0/extern/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.812750 affine_transform-0.3.0/extern/eigen/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.836750 affine_transform-0.3.0/extern/eigen/Eigen/
+-rw-r--r--   0 runner    (1001) docker     (123)     1161 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/Cholesky
+-rw-r--r--   0 runner    (1001) docker     (123)     1900 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/CholmodSupport
+-rw-r--r--   0 runner    (1001) docker     (123)    12876 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/Core
+-rw-r--r--   0 runner    (1001) docker     (123)      122 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/Dense
+-rw-r--r--   0 runner    (1001) docker     (123)       35 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/Eigen
+-rw-r--r--   0 runner    (1001) docker     (123)     1777 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/Eigenvalues
+-rw-r--r--   0 runner    (1001) docker     (123)     1940 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/Geometry
+-rw-r--r--   0 runner    (1001) docker     (123)      829 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/Householder
+-rw-r--r--   0 runner    (1001) docker     (123)     2083 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/IterativeLinearSolvers
+-rw-r--r--   0 runner    (1001) docker     (123)      894 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/Jacobi
+-rw-r--r--   0 runner    (1001) docker     (123)     1389 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/KLUSupport
+-rw-r--r--   0 runner    (1001) docker     (123)     1268 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/LU
+-rw-r--r--   0 runner    (1001) docker     (123)      991 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/MetisSupport
+-rw-r--r--   0 runner    (1001) docker     (123)     2451 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/OrderingMethods
+-rw-r--r--   0 runner    (1001) docker     (123)     1751 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/PaStiXSupport
+-rw-r--r--   0 runner    (1001) docker     (123)     1116 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/PardisoSupport
+-rw-r--r--   0 runner    (1001) docker     (123)     1272 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/QR
+-rw-r--r--   0 runner    (1001) docker     (123)      900 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/QtAlignedMalloc
+-rw-r--r--   0 runner    (1001) docker     (123)     1162 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/SPQRSupport
+-rw-r--r--   0 runner    (1001) docker     (123)     1584 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/SVD
+-rw-r--r--   0 runner    (1001) docker     (123)      888 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/Sparse
+-rw-r--r--   0 runner    (1001) docker     (123)     1235 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/SparseCholesky
+-rw-r--r--   0 runner    (1001) docker     (123)     2240 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/SparseCore
+-rw-r--r--   0 runner    (1001) docker     (123)     1814 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/SparseLU
+-rw-r--r--   0 runner    (1001) docker     (123)     1195 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/SparseQR
+-rw-r--r--   0 runner    (1001) docker     (123)      797 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/StdDeque
+-rw-r--r--   0 runner    (1001) docker     (123)      726 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/StdList
+-rw-r--r--   0 runner    (1001) docker     (123)      803 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/StdVector
+-rw-r--r--   0 runner    (1001) docker     (123)     2243 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/SuperLUSupport
+-rw-r--r--   0 runner    (1001) docker     (123)     1382 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/UmfPackSupport
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.816750 affine_transform-0.3.0/extern/eigen/Eigen/src/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.840750 affine_transform-0.3.0/extern/eigen/Eigen/src/Cholesky/
+-rw-r--r--   0 runner    (1001) docker     (123)    24934 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Cholesky/LDLT.h
+-rw-r--r--   0 runner    (1001) docker     (123)    18760 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Cholesky/LLT.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3974 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Cholesky/LLT_LAPACKE.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.840750 affine_transform-0.3.0/extern/eigen/Eigen/src/CholmodSupport/
+-rw-r--r--   0 runner    (1001) docker     (123)    25441 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/CholmodSupport/CholmodSupport.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.856750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/
+-rw-r--r--   0 runner    (1001) docker     (123)    19214 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ArithmeticSequence.h
+-rw-r--r--   0 runner    (1001) docker     (123)    16782 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Array.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8217 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ArrayBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7018 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ArrayWrapper.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2738 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Assign.h
+-rw-r--r--   0 runner    (1001) docker     (123)    41673 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/AssignEvaluator.h
+-rwxr-xr-x   0 runner    (1001) docker     (123)    12488 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Assign_MKL.h
+-rw-r--r--   0 runner    (1001) docker     (123)    14075 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/BandMatrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)    18720 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Block.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4429 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/BooleanRedux.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5981 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CommaInitializer.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6990 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ConditionEstimator.h
+-rw-r--r--   0 runner    (1001) docker     (123)    63841 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CoreEvaluators.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4745 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CoreIterators.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7909 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CwiseBinaryOp.h
+-rw-r--r--   0 runner    (1001) docker     (123)    36282 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CwiseNullaryOp.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8256 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CwiseTernaryOp.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3937 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CwiseUnaryOp.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5551 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CwiseUnaryView.h
+-rw-r--r--   0 runner    (1001) docker     (123)    31529 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/DenseBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)    24484 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/DenseCoeffsBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)    25360 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/DenseStorage.h
+-rw-r--r--   0 runner    (1001) docker     (123)     9870 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Diagonal.h
+-rw-r--r--   0 runner    (1001) docker     (123)    14670 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/DiagonalMatrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)      988 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/DiagonalProduct.h
+-rw-r--r--   0 runner    (1001) docker     (123)    11654 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Dot.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5841 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/EigenBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4909 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ForceAlignedAccess.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5759 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Fuzzy.h
+-rw-r--r--   0 runner    (1001) docker     (123)    21679 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/GeneralProduct.h
+-rw-r--r--   0 runner    (1001) docker     (123)    38812 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/GenericPacketMath.h
+-rw-r--r--   0 runner    (1001) docker     (123)    11543 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/GlobalFunctions.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8238 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/IO.h
+-rw-r--r--   0 runner    (1001) docker     (123)     9620 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/IndexedView.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3503 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Inverse.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7256 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Map.h
+-rw-r--r--   0 runner    (1001) docker     (123)    11281 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/MapBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)    60784 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/MathFunctions.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7156 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/MathFunctionsImpl.h
+-rw-r--r--   0 runner    (1001) docker     (123)    24343 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Matrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)    23856 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/MatrixBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2520 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/NestByValue.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3620 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/NoAlias.h
+-rw-r--r--   0 runner    (1001) docker     (123)    12884 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/NumTraits.h
+-rw-r--r--   0 runner    (1001) docker     (123)     9282 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/PartialReduxEvaluator.h
+-rw-r--r--   0 runner    (1001) docker     (123)    20748 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/PermutationMatrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)    49193 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/PlainObjectBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7336 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Product.h
+-rw-r--r--   0 runner    (1001) docker     (123)    53832 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ProductEvaluators.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7756 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Random.h
+-rw-r--r--   0 runner    (1001) docker     (123)    19195 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Redux.h
+-rw-r--r--   0 runner    (1001) docker     (123)    17821 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Ref.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5656 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Replicate.h
+-rw-r--r--   0 runner    (1001) docker     (123)    17033 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Reshaped.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4284 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ReturnByValue.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7522 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Reverse.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6143 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Select.h
+-rw-r--r--   0 runner    (1001) docker     (123)    14999 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/SelfAdjointView.h
+-rw-r--r--   0 runner    (1001) docker     (123)     1697 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/SelfCwiseBinaryOp.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6837 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Solve.h
+-rw-r--r--   0 runner    (1001) docker     (123)     9368 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/SolveTriangular.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6170 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/SolverBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8700 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/StableNorm.h
+-rw-r--r--   0 runner    (1001) docker     (123)    21641 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/StlIterators.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4414 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Stride.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2765 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Swap.h
+-rw-r--r--   0 runner    (1001) docker     (123)    17606 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Transpose.h
+-rw-r--r--   0 runner    (1001) docker     (123)    13567 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Transpositions.h
+-rw-r--r--   0 runner    (1001) docker     (123)    38277 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/TriangularMatrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3488 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/VectorBlock.h
+-rw-r--r--   0 runner    (1001) docker     (123)    35168 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/VectorwiseOp.h
+-rw-r--r--   0 runner    (1001) docker     (123)    11997 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Visitor.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.816750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.856750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX/
+-rw-r--r--   0 runner    (1001) docker     (123)    15268 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX/Complex.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8102 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX/MathFunctions.h
+-rw-r--r--   0 runner    (1001) docker     (123)    64608 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX/PacketMath.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2564 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX/TypeCasting.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.856750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX512/
+-rw-r--r--   0 runner    (1001) docker     (123)    17240 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX512/Complex.h
+-rw-r--r--   0 runner    (1001) docker     (123)    13344 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX512/MathFunctions.h
+-rw-r--r--   0 runner    (1001) docker     (123)    87891 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX512/PacketMath.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2134 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX512/TypeCasting.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.860750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AltiVec/
+-rw-r--r--   0 runner    (1001) docker     (123)    16536 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AltiVec/Complex.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2323 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AltiVec/MathFunctions.h
+-rw-r--r--   0 runner    (1001) docker     (123)   110097 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AltiVec/MatrixProduct.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5339 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AltiVec/MatrixProductCommon.h
+-rw-r--r--   0 runner    (1001) docker     (123)    23627 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AltiVec/MatrixProductMMA.h
+-rwxr-xr-x   0 runner    (1001) docker     (123)   102394 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AltiVec/PacketMath.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.860750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/CUDA/
+-rw-r--r--   0 runner    (1001) docker     (123)    17955 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/CUDA/Complex.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.860750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/Default/
+-rw-r--r--   0 runner    (1001) docker     (123)    26656 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/Default/BFloat16.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5251 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/Default/ConjHelper.h
+-rw-r--r--   0 runner    (1001) docker     (123)    67696 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3770 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctionsFwd.h
+-rw-r--r--   0 runner    (1001) docker     (123)    35534 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/Default/Half.h
+-rw-r--r--   0 runner    (1001) docker     (123)     1746 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/Default/Settings.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3746 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/Default/TypeCasting.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.860750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/GPU/
+-rw-r--r--   0 runner    (1001) docker     (123)     2695 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/GPU/MathFunctions.h
+-rw-r--r--   0 runner    (1001) docker     (123)    55779 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/GPU/PacketMath.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2257 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/GPU/TypeCasting.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.812750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/HIP/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.860750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/HIP/hcc/
+-rw-r--r--   0 runner    (1001) docker     (123)      691 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/HIP/hcc/math_constants.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.864750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/MSA/
+-rw-r--r--   0 runner    (1001) docker     (123)    17541 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/MSA/Complex.h
+-rw-r--r--   0 runner    (1001) docker     (123)    16159 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/MSA/MathFunctions.h
+-rw-r--r--   0 runner    (1001) docker     (123)    33615 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/MSA/PacketMath.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.864750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/NEON/
+-rw-r--r--   0 runner    (1001) docker     (123)    22503 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/NEON/Complex.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6815 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/NEON/GeneralBlockPanelKernel.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3083 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/NEON/MathFunctions.h
+-rw-r--r--   0 runner    (1001) docker     (123)   189523 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/NEON/PacketMath.h
+-rw-r--r--   0 runner    (1001) docker     (123)    51286 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/NEON/TypeCasting.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.864750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SSE/
+-rw-r--r--   0 runner    (1001) docker     (123)    14101 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SSE/Complex.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6765 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SSE/MathFunctions.h
+-rwxr-xr-x   0 runner    (1001) docker     (123)    64465 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SSE/PacketMath.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3650 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SSE/TypeCasting.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.864750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SVE/
+-rw-r--r--   0 runner    (1001) docker     (123)     1194 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SVE/MathFunctions.h
+-rw-r--r--   0 runner    (1001) docker     (123)    21200 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SVE/PacketMath.h
+-rw-r--r--   0 runner    (1001) docker     (123)     1351 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SVE/TypeCasting.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.868750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SYCL/
+-rw-r--r--   0 runner    (1001) docker     (123)     7428 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SYCL/InteropHeaders.h
+-rw-r--r--   0 runner    (1001) docker     (123)    12539 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SYCL/MathFunctions.h
+-rw-r--r--   0 runner    (1001) docker     (123)    27786 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SYCL/PacketMath.h
+-rw-r--r--   0 runner    (1001) docker     (123)    21856 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SYCL/SyclMemoryModel.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2626 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SYCL/TypeCasting.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.868750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/ZVector/
+-rw-r--r--   0 runner    (1001) docker     (123)    16796 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/ZVector/Complex.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8024 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/ZVector/MathFunctions.h
+-rwxr-xr-x   0 runner    (1001) docker     (123)    36895 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/ZVector/PacketMath.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.868750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/
+-rw-r--r--   0 runner    (1001) docker     (123)     6686 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/AssignmentFunctors.h
+-rw-r--r--   0 runner    (1001) docker     (123)    20921 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/BinaryFunctors.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8334 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/NullaryFunctors.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4998 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/StlFunctors.h
+-rw-r--r--   0 runner    (1001) docker     (123)      607 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/TernaryFunctors.h
+-rw-r--r--   0 runner    (1001) docker     (123)    40146 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/UnaryFunctors.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.872750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/
+-rw-r--r--   0 runner    (1001) docker     (123)   108448 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralBlockPanelKernel.h
+-rw-r--r--   0 runner    (1001) docker     (123)    20104 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)    15948 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6936 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular_BLAS.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5106 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h
+-rw-r--r--   0 runner    (1001) docker     (123)    21724 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixVector.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6368 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixVector_BLAS.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5582 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/Parallelizer.h
+-rw-r--r--   0 runner    (1001) docker     (123)    21354 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)    11570 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix_BLAS.h
+-rw-r--r--   0 runner    (1001) docker     (123)     9958 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixVector.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5209 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixVector_BLAS.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6164 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointProduct.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4126 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointRank2Update.h
+-rw-r--r--   0 runner    (1001) docker     (123)    20987 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularMatrixMatrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)    13867 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularMatrixMatrix_BLAS.h
+-rw-r--r--   0 runner    (1001) docker     (123)    14722 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularMatrixVector.h
+-rw-r--r--   0 runner    (1001) docker     (123)    10571 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularMatrixVector_BLAS.h
+-rw-r--r--   0 runner    (1001) docker     (123)    14678 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularSolverMatrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6707 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularSolverMatrix_BLAS.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5882 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularSolverVector.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.876750 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/
+-rwxr-xr-x   0 runner    (1001) docker     (123)    23156 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/BlasUtil.h
+-rw-r--r--   0 runner    (1001) docker     (123)    19972 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/ConfigureVectorization.h
+-rw-r--r--   0 runner    (1001) docker     (123)    21931 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/Constants.h
+-rwxr-xr-x   0 runner    (1001) docker     (123)     6192 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/DisableStupidWarnings.h
+-rw-r--r--   0 runner    (1001) docker     (123)    15555 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/ForwardDeclarations.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6696 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/IndexedViewHelper.h
+-rw-r--r--   0 runner    (1001) docker     (123)    11006 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/IntegralConstant.h
+-rwxr-xr-x   0 runner    (1001) docker     (123)     4268 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/MKL_support.h
+-rw-r--r--   0 runner    (1001) docker     (123)    53413 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/Macros.h
+-rw-r--r--   0 runner    (1001) docker     (123)    46661 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/Memory.h
+-rwxr-xr-x   0 runner    (1001) docker     (123)    29336 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/Meta.h
+-rw-r--r--   0 runner    (1001) docker     (123)       85 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/NonMPL2.h
+-rw-r--r--   0 runner    (1001) docker     (123)     1024 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/ReenableStupidWarnings.h
+-rw-r--r--   0 runner    (1001) docker     (123)     1432 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/ReshapedHelper.h
+-rw-r--r--   0 runner    (1001) docker     (123)    10676 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/StaticAssert.h
+-rw-r--r--   0 runner    (1001) docker     (123)    12003 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/SymbolicIndex.h
+-rw-r--r--   0 runner    (1001) docker     (123)    35762 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/XprHelper.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.880750 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/
+-rw-r--r--   0 runner    (1001) docker     (123)    12559 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/ComplexEigenSolver.h
+-rw-r--r--   0 runner    (1001) docker     (123)    17274 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/ComplexSchur.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4178 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/ComplexSchur_LAPACKE.h
+-rw-r--r--   0 runner    (1001) docker     (123)    22970 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/EigenSolver.h
+-rw-r--r--   0 runner    (1001) docker     (123)    17176 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/GeneralizedEigenSolver.h
+-rw-r--r--   0 runner    (1001) docker     (123)     9716 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/GeneralizedSelfAdjointEigenSolver.h
+-rw-r--r--   0 runner    (1001) docker     (123)    14349 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/HessenbergDecomposition.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5575 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/MatrixBaseEigenvalues.h
+-rw-r--r--   0 runner    (1001) docker     (123)    23640 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/RealQZ.h
+-rw-r--r--   0 runner    (1001) docker     (123)    21078 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/RealSchur.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3650 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/RealSchur_LAPACKE.h
+-rw-r--r--   0 runner    (1001) docker     (123)    35182 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4104 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver_LAPACKE.h
+-rw-r--r--   0 runner    (1001) docker     (123)    22706 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/Tridiagonalization.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.884750 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/
+-rw-r--r--   0 runner    (1001) docker     (123)    18939 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/AlignedBox.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8403 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/AngleAxis.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3624 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/EulerAngles.h
+-rw-r--r--   0 runner    (1001) docker     (123)    20726 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Homogeneous.h
+-rw-r--r--   0 runner    (1001) docker     (123)    11962 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Hyperplane.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8955 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/OrthoMethods.h
+-rw-r--r--   0 runner    (1001) docker     (123)     9812 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/ParametrizedLine.h
+-rw-r--r--   0 runner    (1001) docker     (123)    34367 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Quaternion.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6862 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Rotation2D.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8063 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/RotationBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6724 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Scaling.h
+-rw-r--r--   0 runner    (1001) docker     (123)    61930 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Transform.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7664 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Translation.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6190 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Umeyama.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.884750 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/arch/
+-rw-r--r--   0 runner    (1001) docker     (123)     5945 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/arch/Geometry_SIMD.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.884750 affine_transform-0.3.0/extern/eigen/Eigen/src/Householder/
+-rw-r--r--   0 runner    (1001) docker     (123)     4784 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Householder/BlockHouseholder.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5365 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Householder/Householder.h
+-rw-r--r--   0 runner    (1001) docker     (123)    23611 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Householder/HouseholderSequence.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.888750 affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/
+-rw-r--r--   0 runner    (1001) docker     (123)     6771 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/BasicPreconditioners.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6850 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/BiCGSTAB.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8887 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/ConjugateGradient.h
+-rw-r--r--   0 runner    (1001) docker     (123)    15036 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/IncompleteCholesky.h
+-rw-r--r--   0 runner    (1001) docker     (123)    14940 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/IncompleteLUT.h
+-rw-r--r--   0 runner    (1001) docker     (123)    13379 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/IterativeSolverBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7349 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/LeastSquareConjugateGradient.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4212 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/SolveWithGuess.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.888750 affine_transform-0.3.0/extern/eigen/Eigen/src/Jacobi/
+-rw-r--r--   0 runner    (1001) docker     (123)    16383 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/Jacobi/Jacobi.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.888750 affine_transform-0.3.0/extern/eigen/Eigen/src/KLUSupport/
+-rw-r--r--   0 runner    (1001) docker     (123)    11555 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/KLUSupport/KLUSupport.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.888750 affine_transform-0.3.0/extern/eigen/Eigen/src/LU/
+-rw-r--r--   0 runner    (1001) docker     (123)     3439 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/LU/Determinant.h
+-rw-r--r--   0 runner    (1001) docker     (123)    32383 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/LU/FullPivLU.h
+-rw-r--r--   0 runner    (1001) docker     (123)    15727 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/LU/InverseImpl.h
+-rw-r--r--   0 runner    (1001) docker     (123)    22069 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/LU/PartialPivLU.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3555 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/LU/PartialPivLU_LAPACKE.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.888750 affine_transform-0.3.0/extern/eigen/Eigen/src/LU/arch/
+-rw-r--r--   0 runner    (1001) docker     (123)    13693 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/LU/arch/InverseSize4.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.888750 affine_transform-0.3.0/extern/eigen/Eigen/src/MetisSupport/
+-rw-r--r--   0 runner    (1001) docker     (123)     4588 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/MetisSupport/MetisSupport.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.888750 affine_transform-0.3.0/extern/eigen/Eigen/src/OrderingMethods/
+-rw-r--r--   0 runner    (1001) docker     (123)    16105 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/OrderingMethods/Amd.h
+-rw-r--r--   0 runner    (1001) docker     (123)    61681 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/OrderingMethods/Eigen_Colamd.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5248 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/OrderingMethods/Ordering.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.888750 affine_transform-0.3.0/extern/eigen/Eigen/src/PaStiXSupport/
+-rw-r--r--   0 runner    (1001) docker     (123)    22249 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/PaStiXSupport/PaStiXSupport.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.892750 affine_transform-0.3.0/extern/eigen/Eigen/src/PardisoSupport/
+-rw-r--r--   0 runner    (1001) docker     (123)    20092 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/PardisoSupport/PardisoSupport.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.892750 affine_transform-0.3.0/extern/eigen/Eigen/src/QR/
+-rw-r--r--   0 runner    (1001) docker     (123)    25498 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/QR/ColPivHouseholderQR.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4662 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/QR/ColPivHouseholderQR_LAPACKE.h
+-rw-r--r--   0 runner    (1001) docker     (123)    23429 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/QR/CompleteOrthogonalDecomposition.h
+-rw-r--r--   0 runner    (1001) docker     (123)    26768 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/QR/FullPivHouseholderQR.h
+-rw-r--r--   0 runner    (1001) docker     (123)    14641 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/QR/HouseholderQR.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2993 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/QR/HouseholderQR_LAPACKE.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.892750 affine_transform-0.3.0/extern/eigen/Eigen/src/SPQRSupport/
+-rw-r--r--   0 runner    (1001) docker     (123)    11826 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SPQRSupport/SuiteSparseQRSupport.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.892750 affine_transform-0.3.0/extern/eigen/Eigen/src/SVD/
+-rw-r--r--   0 runner    (1001) docker     (123)    54537 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SVD/BDCSVD.h
+-rw-r--r--   0 runner    (1001) docker     (123)    32988 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SVD/JacobiSVD.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5099 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SVD/JacobiSVD_LAPACKE.h
+-rw-r--r--   0 runner    (1001) docker     (123)    14743 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SVD/SVDBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)    15957 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SVD/UpperBidiagonalization.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.892750 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCholesky/
+-rw-r--r--   0 runner    (1001) docker     (123)    24216 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCholesky/SimplicialCholesky.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5830 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCholesky/SimplicialCholesky_impl.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.900750 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/
+-rw-r--r--   0 runner    (1001) docker     (123)    10670 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/AmbiVector.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8743 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/CompressedStorage.h
+-rw-r--r--   0 runner    (1001) docker     (123)    13166 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/ConservativeSparseSparseProduct.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2191 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/MappedSparseMatrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)    11368 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseAssign.h
+-rw-r--r--   0 runner    (1001) docker     (123)    24360 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseBlock.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6485 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseColEtree.h
+-rw-r--r--   0 runner    (1001) docker     (123)    13606 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseCompressedBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)    25524 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseCwiseBinaryOp.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4757 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseCwiseUnaryOp.h
+-rw-r--r--   0 runner    (1001) docker     (123)    13256 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseDenseProduct.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5808 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseDiagonalProduct.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3080 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseDot.h
+-rw-r--r--   0 runner    (1001) docker     (123)     1107 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseFuzzy.h
+-rw-r--r--   0 runner    (1001) docker     (123)    12589 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseMap.h
+-rw-r--r--   0 runner    (1001) docker     (123)    57475 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseMatrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)    17451 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseMatrixBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7329 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparsePermutation.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7593 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseProduct.h
+-rw-r--r--   0 runner    (1001) docker     (123)     1699 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseRedux.h
+-rw-r--r--   0 runner    (1001) docker     (123)    15600 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseRef.h
+-rw-r--r--   0 runner    (1001) docker     (123)    25889 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseSelfAdjointView.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4424 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseSolverBase.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8704 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseSparseProductWithPruning.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3175 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseTranspose.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6437 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseTriangularView.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6827 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseUtil.h
+-rw-r--r--   0 runner    (1001) docker     (123)    14832 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseVector.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8127 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseView.h
+-rw-r--r--   0 runner    (1001) docker     (123)     9657 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/TriangularSolver.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.904750 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/
+-rw-r--r--   0 runner    (1001) docker     (123)    33316 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4303 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLUImpl.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7602 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_Memory.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4974 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_Structs.h
+-rw-r--r--   0 runner    (1001) docker     (123)    12837 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_SupernodalMatrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2049 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_Utils.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6712 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_column_bmod.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6584 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_column_dfs.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3681 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_copy_to_ucol.h
+-rw-r--r--   0 runner    (1001) docker     (123)    10217 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_gemm_kernel.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4181 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_heap_relax_snode.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5723 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_kernel_bmod.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8485 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_panel_bmod.h
+-rw-r--r--   0 runner    (1001) docker     (123)     9028 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_panel_dfs.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4979 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_pivotL.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4545 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_pruneL.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2889 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_relax_snode.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.904750 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseQR/
+-rw-r--r--   0 runner    (1001) docker     (123)    29167 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SparseQR/SparseQR.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.904750 affine_transform-0.3.0/extern/eigen/Eigen/src/StlSupport/
+-rw-r--r--   0 runner    (1001) docker     (123)     4730 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/StlSupport/StdDeque.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4155 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/StlSupport/StdList.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5338 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/StlSupport/StdVector.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2809 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/StlSupport/details.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.904750 affine_transform-0.3.0/extern/eigen/Eigen/src/SuperLUSupport/
+-rw-r--r--   0 runner    (1001) docker     (123)    34324 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/SuperLUSupport/SuperLUSupport.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.904750 affine_transform-0.3.0/extern/eigen/Eigen/src/UmfPackSupport/
+-rw-r--r--   0 runner    (1001) docker     (123)    24456 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/UmfPackSupport/UmfPackSupport.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.908750 affine_transform-0.3.0/extern/eigen/Eigen/src/misc/
+-rw-r--r--   0 runner    (1001) docker     (123)     2913 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/misc/Image.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2742 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/misc/Kernel.h
+-rw-r--r--   0 runner    (1001) docker     (123)     1748 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/misc/RealSvd2x2.h
+-rw-r--r--   0 runner    (1001) docker     (123)    30560 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/misc/blas.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7834 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/misc/lapack.h
+-rwxr-xr-x   0 runner    (1001) docker     (123)  1058369 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/misc/lapacke.h
+-rw-r--r--   0 runner    (1001) docker     (123)      474 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/misc/lapacke_mangling.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.912751 affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/
+-rw-r--r--   0 runner    (1001) docker     (123)    16430 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/ArrayCwiseBinaryOps.h
+-rw-r--r--   0 runner    (1001) docker     (123)    21431 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/ArrayCwiseUnaryOps.h
+-rw-r--r--   0 runner    (1001) docker     (123)    59020 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/BlockMethods.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4828 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/CommonCwiseBinaryOps.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6089 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/CommonCwiseUnaryOps.h
+-rw-r--r--   0 runner    (1001) docker     (123)    12283 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/IndexedViewMethods.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7749 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/MatrixCwiseBinaryOps.h
+-rw-r--r--   0 runner    (1001) docker     (123)     3350 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/MatrixCwiseUnaryOps.h
+-rw-r--r--   0 runner    (1001) docker     (123)     6915 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/ReshapedMethods.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.912751 affine_transform-0.3.0/extern/pybind11/
+-rw-r--r--   0 runner    (1001) docker     (123)    11983 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/CMakeLists.txt
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.820750 affine_transform-0.3.0/extern/pybind11/include/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.916751 affine_transform-0.3.0/extern/pybind11/include/pybind11/
+-rw-r--r--   0 runner    (1001) docker     (123)    23959 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/attr.h
+-rw-r--r--   0 runner    (1001) docker     (123)     7069 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/buffer_info.h
+-rw-r--r--   0 runner    (1001) docker     (123)    65660 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/cast.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8458 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/chrono.h
+-rw-r--r--   0 runner    (1001) docker     (123)      120 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/common.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2096 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/complex.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.916751 affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/
+-rw-r--r--   0 runner    (1001) docker     (123)    28518 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/class.h
+-rw-r--r--   0 runner    (1001) docker     (123)    52930 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/common.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5491 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/descr.h
+-rw-r--r--   0 runner    (1001) docker     (123)    17869 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/init.h
+-rw-r--r--   0 runner    (1001) docker     (123)    26305 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/internals.h
+-rw-r--r--   0 runner    (1001) docker     (123)    42613 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/type_caster_base.h
+-rw-r--r--   0 runner    (1001) docker     (123)     1625 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/typeid.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.916751 affine_transform-0.3.0/extern/pybind11/include/pybind11/eigen/
+-rw-r--r--   0 runner    (1001) docker     (123)    31450 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/eigen/matrix.h
+-rw-r--r--   0 runner    (1001) docker     (123)    18140 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/eigen/tensor.h
+-rw-r--r--   0 runner    (1001) docker     (123)      316 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/eigen.h
+-rw-r--r--   0 runner    (1001) docker     (123)    13471 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/embed.h
+-rw-r--r--   0 runner    (1001) docker     (123)     4731 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/eval.h
+-rw-r--r--   0 runner    (1001) docker     (123)     5002 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/functional.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8262 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/gil.h
+-rw-r--r--   0 runner    (1001) docker     (123)     8862 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/iostream.h
+-rw-r--r--   0 runner    (1001) docker     (123)    79416 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/numpy.h
+-rw-r--r--   0 runner    (1001) docker     (123)     9103 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/operators.h
+-rw-r--r--   0 runner    (1001) docker     (123)     2734 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/options.h
+-rw-r--r--   0 runner    (1001) docker     (123)   126420 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/pybind11.h
+-rw-r--r--   0 runner    (1001) docker     (123)    94641 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/pytypes.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.916751 affine_transform-0.3.0/extern/pybind11/include/pybind11/stl/
+-rw-r--r--   0 runner    (1001) docker     (123)     4185 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/stl/filesystem.h
+-rw-r--r--   0 runner    (1001) docker     (123)    15337 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/stl.h
+-rw-r--r--   0 runner    (1001) docker     (123)    29747 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/include/pybind11/stl_bind.h
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.920750 affine_transform-0.3.0/extern/pybind11/tools/
+-rw-r--r--   0 runner    (1001) docker     (123)     2350 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/FindCatch.cmake
+-rw-r--r--   0 runner    (1001) docker     (123)     3105 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/FindEigen3.cmake
+-rw-r--r--   0 runner    (1001) docker     (123)    11190 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/FindPythonLibsNew.cmake
+-rw-r--r--   0 runner    (1001) docker     (123)      817 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/JoinPaths.cmake
+-rwxr-xr-x   0 runner    (1001) docker     (123)     1423 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/check-style.sh
+-rw-r--r--   0 runner    (1001) docker     (123)      952 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/cmake_uninstall.cmake.in
+-rw-r--r--   0 runner    (1001) docker     (123)     1040 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/codespell_ignore_lines_from_errors.py
+-rw-r--r--   0 runner    (1001) docker     (123)     1031 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/libsize.py
+-rwxr-xr-x   0 runner    (1001) docker     (123)     1311 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/make_changelog.py
+-rw-r--r--   0 runner    (1001) docker     (123)      196 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/pybind11.pc.in
+-rw-r--r--   0 runner    (1001) docker     (123)    14033 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/pybind11Common.cmake
+-rw-r--r--   0 runner    (1001) docker     (123)     6930 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/pybind11Config.cmake.in
+-rw-r--r--   0 runner    (1001) docker     (123)     8960 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/pybind11NewTools.cmake
+-rw-r--r--   0 runner    (1001) docker     (123)     8361 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/pybind11Tools.cmake
+-rw-r--r--   0 runner    (1001) docker     (123)       94 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (123)     2104 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/setup_global.py.in
+-rw-r--r--   0 runner    (1001) docker     (123)     1234 2023-04-23 14:44:30.000000 affine_transform-0.3.0/extern/pybind11/tools/setup_main.py.in
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.820750 affine_transform-0.3.0/include/
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.920750 affine_transform-0.3.0/include/affine_transform/
+-rw-r--r--   0 runner    (1001) docker     (123)     6268 2023-04-23 14:44:18.000000 affine_transform-0.3.0/include/affine_transform/affine_transform.hpp
+-rw-r--r--   0 runner    (1001) docker     (123)    18132 2023-04-23 14:44:18.000000 affine_transform-0.3.0/include/affine_transform/interpolation.hpp
+-rw-r--r--   0 runner    (1001) docker     (123)       99 2023-04-23 14:44:18.000000 affine_transform-0.3.0/pyproject.toml
+-rw-r--r--   0 runner    (1001) docker     (123)      203 2023-04-23 14:44:18.000000 affine_transform-0.3.0/readthedocs.yml
+-rw-r--r--   0 runner    (1001) docker     (123)       94 2023-04-23 14:44:49.924751 affine_transform-0.3.0/setup.cfg
+-rw-r--r--   0 runner    (1001) docker     (123)     4412 2023-04-23 14:44:18.000000 affine_transform-0.3.0/setup.py
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.924751 affine_transform-0.3.0/src/
+-rw-r--r--   0 runner    (1001) docker     (123)     5312 2023-04-23 14:44:18.000000 affine_transform-0.3.0/src/main.cpp
+drwxr-xr-x   0 runner    (1001) docker     (123)        0 2023-04-23 14:44:49.924751 affine_transform-0.3.0/tests/
+-rw-r--r--   0 runner    (1001) docker     (123)     7301 2023-04-23 14:44:18.000000 affine_transform-0.3.0/tests/test_affine_transform.py
```

### Comparing `affine_transform-0.2.9/.github/workflows/deploy.yml` & `affine_transform-0.3.0/.github/workflows/deploy.yml`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/.github/workflows/deploy_test.yml` & `affine_transform-0.3.0/.github/workflows/deploy_test.yml`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/.github/workflows/test-package.yml` & `affine_transform-0.3.0/.github/workflows/test-package.yml`

 * *Files 9% similar despite different names*

```diff
@@ -2,15 +2,15 @@
 on: [push]
 jobs:
   Build-and-Test:
     name: Build and test using Python ${{ matrix.python-version }} / gcc ${{ matrix.gcc-version }}
     runs-on: ubuntu-latest
     strategy:
       matrix:
-        python-version: ["3.8", "3.9", "3.10"]
+        python-version: ["3.8", "3.9", "3.10", "3.11"]
         gcc-version: ["9", "10", "11", "12"]
 
     steps:
       - name: Checkout Repository
         uses: actions/checkout@v3
         with:
           submodules: recursive
```

### Comparing `affine_transform-0.2.9/.gitignore` & `affine_transform-0.3.0/.gitignore`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/CMakeLists.txt` & `affine_transform-0.3.0/CMakeLists.txt`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/LICENSE` & `affine_transform-0.3.0/LICENSE`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/PKG-INFO` & `affine_transform-0.3.0/PKG-INFO`

 * *Files 2% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 Metadata-Version: 2.1
 Name: affine_transform
-Version: 0.2.9
+Version: 0.3.0
 Summary: Easy to use multi-core affine transformations
 Home-page: https://github.com/NOhs/affine_transform_nd
 Author: NOhs, TobelRunner
 License: MIT
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: C++
 Classifier: License :: OSI Approved :: MIT License
 Requires-Python: >=3.8
 License-File: LICENSE
 
 Affine Transformation: C++17, OpenMP, Python
 ============================================
```

### Comparing `affine_transform-0.2.9/README.rst` & `affine_transform-0.3.0/README.rst`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/affine_transform/affine_transform.py` & `affine_transform-0.3.0/affine_transform/affine_transform.py`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/affine_transform.egg-info/PKG-INFO` & `affine_transform-0.3.0/affine_transform.egg-info/PKG-INFO`

 * *Files 5% similar despite different names*

```diff
@@ -1,17 +1,18 @@
 Metadata-Version: 2.1
 Name: affine-transform
-Version: 0.2.9
+Version: 0.3.0
 Summary: Easy to use multi-core affine transformations
 Home-page: https://github.com/NOhs/affine_transform_nd
 Author: NOhs, TobelRunner
 License: MIT
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
+Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: C++
 Classifier: License :: OSI Approved :: MIT License
 Requires-Python: >=3.8
 License-File: LICENSE
 
 Affine Transformation: C++17, OpenMP, Python
 ============================================
```

### Comparing `affine_transform-0.2.9/affine_transform.egg-info/SOURCES.txt` & `affine_transform-0.3.0/affine_transform.egg-info/SOURCES.txt`

 * *Files 6% similar despite different names*

```diff
@@ -40,15 +40,14 @@
 docs/cpp_docs/extract.rst
 docs/cpp_docs/interpolation.rst
 docs/cpp_docs/linear_interpolation.rst
 docs/cpp_docs/python_bindings.rst
 docs/cpp_docs/transform.rst
 docs/cpp_docs/transform_loop.rst
 examples/rotation_and_translation.py
-extern/eigen/Eigen/CMakeLists.txt
 extern/eigen/Eigen/Cholesky
 extern/eigen/Eigen/CholmodSupport
 extern/eigen/Eigen/Core
 extern/eigen/Eigen/Dense
 extern/eigen/Eigen/Eigen
 extern/eigen/Eigen/Eigenvalues
 extern/eigen/Eigen/Geometry
@@ -154,38 +153,48 @@
 extern/eigen/Eigen/src/Core/arch/AVX/Complex.h
 extern/eigen/Eigen/src/Core/arch/AVX/MathFunctions.h
 extern/eigen/Eigen/src/Core/arch/AVX/PacketMath.h
 extern/eigen/Eigen/src/Core/arch/AVX/TypeCasting.h
 extern/eigen/Eigen/src/Core/arch/AVX512/Complex.h
 extern/eigen/Eigen/src/Core/arch/AVX512/MathFunctions.h
 extern/eigen/Eigen/src/Core/arch/AVX512/PacketMath.h
+extern/eigen/Eigen/src/Core/arch/AVX512/TypeCasting.h
 extern/eigen/Eigen/src/Core/arch/AltiVec/Complex.h
 extern/eigen/Eigen/src/Core/arch/AltiVec/MathFunctions.h
+extern/eigen/Eigen/src/Core/arch/AltiVec/MatrixProduct.h
+extern/eigen/Eigen/src/Core/arch/AltiVec/MatrixProductCommon.h
+extern/eigen/Eigen/src/Core/arch/AltiVec/MatrixProductMMA.h
 extern/eigen/Eigen/src/Core/arch/AltiVec/PacketMath.h
 extern/eigen/Eigen/src/Core/arch/CUDA/Complex.h
+extern/eigen/Eigen/src/Core/arch/Default/BFloat16.h
 extern/eigen/Eigen/src/Core/arch/Default/ConjHelper.h
 extern/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctions.h
+extern/eigen/Eigen/src/Core/arch/Default/GenericPacketMathFunctionsFwd.h
+extern/eigen/Eigen/src/Core/arch/Default/Half.h
 extern/eigen/Eigen/src/Core/arch/Default/Settings.h
-extern/eigen/Eigen/src/Core/arch/GPU/Half.h
+extern/eigen/Eigen/src/Core/arch/Default/TypeCasting.h
 extern/eigen/Eigen/src/Core/arch/GPU/MathFunctions.h
 extern/eigen/Eigen/src/Core/arch/GPU/PacketMath.h
-extern/eigen/Eigen/src/Core/arch/GPU/PacketMathHalf.h
 extern/eigen/Eigen/src/Core/arch/GPU/TypeCasting.h
 extern/eigen/Eigen/src/Core/arch/HIP/hcc/math_constants.h
 extern/eigen/Eigen/src/Core/arch/MSA/Complex.h
 extern/eigen/Eigen/src/Core/arch/MSA/MathFunctions.h
 extern/eigen/Eigen/src/Core/arch/MSA/PacketMath.h
 extern/eigen/Eigen/src/Core/arch/NEON/Complex.h
+extern/eigen/Eigen/src/Core/arch/NEON/GeneralBlockPanelKernel.h
 extern/eigen/Eigen/src/Core/arch/NEON/MathFunctions.h
 extern/eigen/Eigen/src/Core/arch/NEON/PacketMath.h
 extern/eigen/Eigen/src/Core/arch/NEON/TypeCasting.h
 extern/eigen/Eigen/src/Core/arch/SSE/Complex.h
 extern/eigen/Eigen/src/Core/arch/SSE/MathFunctions.h
 extern/eigen/Eigen/src/Core/arch/SSE/PacketMath.h
 extern/eigen/Eigen/src/Core/arch/SSE/TypeCasting.h
+extern/eigen/Eigen/src/Core/arch/SVE/MathFunctions.h
+extern/eigen/Eigen/src/Core/arch/SVE/PacketMath.h
+extern/eigen/Eigen/src/Core/arch/SVE/TypeCasting.h
 extern/eigen/Eigen/src/Core/arch/SYCL/InteropHeaders.h
 extern/eigen/Eigen/src/Core/arch/SYCL/MathFunctions.h
 extern/eigen/Eigen/src/Core/arch/SYCL/PacketMath.h
 extern/eigen/Eigen/src/Core/arch/SYCL/SyclMemoryModel.h
 extern/eigen/Eigen/src/Core/arch/SYCL/TypeCasting.h
 extern/eigen/Eigen/src/Core/arch/ZVector/Complex.h
 extern/eigen/Eigen/src/Core/arch/ZVector/MathFunctions.h
@@ -258,15 +267,15 @@
 extern/eigen/Eigen/src/Geometry/Quaternion.h
 extern/eigen/Eigen/src/Geometry/Rotation2D.h
 extern/eigen/Eigen/src/Geometry/RotationBase.h
 extern/eigen/Eigen/src/Geometry/Scaling.h
 extern/eigen/Eigen/src/Geometry/Transform.h
 extern/eigen/Eigen/src/Geometry/Translation.h
 extern/eigen/Eigen/src/Geometry/Umeyama.h
-extern/eigen/Eigen/src/Geometry/arch/Geometry_SSE.h
+extern/eigen/Eigen/src/Geometry/arch/Geometry_SIMD.h
 extern/eigen/Eigen/src/Householder/BlockHouseholder.h
 extern/eigen/Eigen/src/Householder/Householder.h
 extern/eigen/Eigen/src/Householder/HouseholderSequence.h
 extern/eigen/Eigen/src/IterativeLinearSolvers/BasicPreconditioners.h
 extern/eigen/Eigen/src/IterativeLinearSolvers/BiCGSTAB.h
 extern/eigen/Eigen/src/IterativeLinearSolvers/ConjugateGradient.h
 extern/eigen/Eigen/src/IterativeLinearSolvers/IncompleteCholesky.h
@@ -277,15 +286,15 @@
 extern/eigen/Eigen/src/Jacobi/Jacobi.h
 extern/eigen/Eigen/src/KLUSupport/KLUSupport.h
 extern/eigen/Eigen/src/LU/Determinant.h
 extern/eigen/Eigen/src/LU/FullPivLU.h
 extern/eigen/Eigen/src/LU/InverseImpl.h
 extern/eigen/Eigen/src/LU/PartialPivLU.h
 extern/eigen/Eigen/src/LU/PartialPivLU_LAPACKE.h
-extern/eigen/Eigen/src/LU/arch/Inverse_SSE.h
+extern/eigen/Eigen/src/LU/arch/InverseSize4.h
 extern/eigen/Eigen/src/MetisSupport/MetisSupport.h
 extern/eigen/Eigen/src/OrderingMethods/Amd.h
 extern/eigen/Eigen/src/OrderingMethods/Eigen_Colamd.h
 extern/eigen/Eigen/src/OrderingMethods/Ordering.h
 extern/eigen/Eigen/src/PaStiXSupport/PaStiXSupport.h
 extern/eigen/Eigen/src/PardisoSupport/PardisoSupport.h
 extern/eigen/Eigen/src/QR/ColPivHouseholderQR.h
@@ -379,40 +388,47 @@
 extern/pybind11/include/pybind11/chrono.h
 extern/pybind11/include/pybind11/common.h
 extern/pybind11/include/pybind11/complex.h
 extern/pybind11/include/pybind11/eigen.h
 extern/pybind11/include/pybind11/embed.h
 extern/pybind11/include/pybind11/eval.h
 extern/pybind11/include/pybind11/functional.h
+extern/pybind11/include/pybind11/gil.h
 extern/pybind11/include/pybind11/iostream.h
 extern/pybind11/include/pybind11/numpy.h
 extern/pybind11/include/pybind11/operators.h
 extern/pybind11/include/pybind11/options.h
 extern/pybind11/include/pybind11/pybind11.h
 extern/pybind11/include/pybind11/pytypes.h
 extern/pybind11/include/pybind11/stl.h
 extern/pybind11/include/pybind11/stl_bind.h
 extern/pybind11/include/pybind11/detail/class.h
 extern/pybind11/include/pybind11/detail/common.h
 extern/pybind11/include/pybind11/detail/descr.h
 extern/pybind11/include/pybind11/detail/init.h
 extern/pybind11/include/pybind11/detail/internals.h
+extern/pybind11/include/pybind11/detail/type_caster_base.h
 extern/pybind11/include/pybind11/detail/typeid.h
+extern/pybind11/include/pybind11/eigen/matrix.h
+extern/pybind11/include/pybind11/eigen/tensor.h
+extern/pybind11/include/pybind11/stl/filesystem.h
 extern/pybind11/tools/FindCatch.cmake
 extern/pybind11/tools/FindEigen3.cmake
 extern/pybind11/tools/FindPythonLibsNew.cmake
+extern/pybind11/tools/JoinPaths.cmake
 extern/pybind11/tools/check-style.sh
+extern/pybind11/tools/cmake_uninstall.cmake.in
+extern/pybind11/tools/codespell_ignore_lines_from_errors.py
 extern/pybind11/tools/libsize.py
-extern/pybind11/tools/mkdoc.py
+extern/pybind11/tools/make_changelog.py
+extern/pybind11/tools/pybind11.pc.in
+extern/pybind11/tools/pybind11Common.cmake
 extern/pybind11/tools/pybind11Config.cmake.in
+extern/pybind11/tools/pybind11NewTools.cmake
 extern/pybind11/tools/pybind11Tools.cmake
-extern/pybind11/tools/clang/.git
-extern/pybind11/tools/clang/.gitignore
-extern/pybind11/tools/clang/LICENSE.TXT
-extern/pybind11/tools/clang/README.md
-extern/pybind11/tools/clang/__init__.py
-extern/pybind11/tools/clang/cindex.py
-extern/pybind11/tools/clang/enumerations.py
+extern/pybind11/tools/pyproject.toml
+extern/pybind11/tools/setup_global.py.in
+extern/pybind11/tools/setup_main.py.in
 include/affine_transform/affine_transform.hpp
 include/affine_transform/interpolation.hpp
 src/main.cpp
 tests/test_affine_transform.py
```

### Comparing `affine_transform-0.2.9/docs/conf.py` & `affine_transform-0.3.0/docs/conf.py`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/docs/cpp/Doxyfile` & `affine_transform-0.3.0/docs/cpp/Doxyfile`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/docs/cpp_doc.rst` & `affine_transform-0.3.0/docs/cpp_doc.rst`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/docs/cpp_docs/affine_transform.rst` & `affine_transform-0.3.0/docs/cpp_docs/affine_transform.rst`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/docs/cpp_docs/interpolation.rst` & `affine_transform-0.3.0/docs/cpp_docs/interpolation.rst`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/docs/make.bat` & `affine_transform-0.3.0/docs/make.bat`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/examples/rotation_and_translation.py` & `affine_transform-0.3.0/examples/rotation_and_translation.py`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/Cholesky` & `affine_transform-0.3.0/extern/eigen/Eigen/Cholesky`

 * *Files 20% similar despite different names*

```diff
@@ -39,8 +39,7 @@
 #endif
 #include "src/Cholesky/LLT_LAPACKE.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_CHOLESKY_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/CholmodSupport` & `affine_transform-0.3.0/extern/eigen/Eigen/CholmodSupport`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/Core` & `affine_transform-0.3.0/extern/eigen/Eigen/Core`

 * *Files 6% similar despite different names*

```diff
@@ -7,54 +7,65 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_CORE_H
 #define EIGEN_CORE_H
 
-// first thing Eigen does: stop the compiler from committing suicide
+// first thing Eigen does: stop the compiler from reporting useless warnings.
 #include "src/Core/util/DisableStupidWarnings.h"
 
 // then include this file where all our macros are defined. It's really important to do it first because
 // it's where we do all the compiler/OS/arch detections and define most defaults.
 #include "src/Core/util/Macros.h"
 
 // This detects SSE/AVX/NEON/etc. and configure alignment settings
 #include "src/Core/util/ConfigureVectorization.h"
 
 // We need cuda_runtime.h/hip_runtime.h to ensure that
-// the EIGEN_USING_STD_MATH macro works properly on the device side
+// the EIGEN_USING_STD macro works properly on the device side
 #if defined(EIGEN_CUDACC)
   #include <cuda_runtime.h>
 #elif defined(EIGEN_HIPCC)
   #include <hip/hip_runtime.h>
 #endif
 
 
 #ifdef EIGEN_EXCEPTIONS
   #include <new>
 #endif
 
 // Disable the ipa-cp-clone optimization flag with MinGW 6.x or newer (enabled by default with -O3)
 // See http://eigen.tuxfamily.org/bz/show_bug.cgi?id=556 for details.
-#if EIGEN_COMP_MINGW && EIGEN_GNUC_AT_LEAST(4,6)
+#if EIGEN_COMP_MINGW && EIGEN_GNUC_AT_LEAST(4,6) && EIGEN_GNUC_AT_MOST(5,5)
   #pragma GCC optimize ("-fno-ipa-cp-clone")
 #endif
 
+// Prevent ICC from specializing std::complex operators that silently fail
+// on device. This allows us to use our own device-compatible specializations
+// instead.
+#if defined(EIGEN_COMP_ICC) && defined(EIGEN_GPU_COMPILE_PHASE) \
+    && !defined(_OVERRIDE_COMPLEX_SPECIALIZATION_)
+#define _OVERRIDE_COMPLEX_SPECIALIZATION_ 1
+#endif
 #include <complex>
 
 // this include file manages BLAS and MKL related macros
 // and inclusion of their respective header files
 #include "src/Core/util/MKL_support.h"
 
 
 #if defined(EIGEN_HAS_CUDA_FP16) || defined(EIGEN_HAS_HIP_FP16)
   #define EIGEN_HAS_GPU_FP16
 #endif
 
+#if defined(EIGEN_HAS_CUDA_BF16) || defined(EIGEN_HAS_HIP_BF16)
+  #define EIGEN_HAS_GPU_BF16
+#endif
+
 #if (defined _OPENMP) && (!defined EIGEN_DONT_PARALLELIZE)
   #define EIGEN_HAS_OPENMP
 #endif
 
 #ifdef EIGEN_HAS_OPENMP
 #include <omp.h>
 #endif
@@ -68,14 +79,15 @@
 #include <cerrno>
 #endif
 #include <cstddef>
 #include <cstdlib>
 #include <cmath>
 #include <cassert>
 #include <functional>
+#include <sstream>
 #ifndef EIGEN_NO_IO
   #include <iosfwd>
 #endif
 #include <cstring>
 #include <string>
 #include <limits>
 #include <climits> // for CHAR_BIT
@@ -93,25 +105,26 @@
 
 // for outputting debug info
 #ifdef EIGEN_DEBUG_ASSIGN
 #include <iostream>
 #endif
 
 // required for __cpuid, needs to be included after cmath
-#if EIGEN_COMP_MSVC && EIGEN_ARCH_i386_OR_x86_64 && !EIGEN_OS_WINCE
+// also required for _BitScanReverse on Windows on ARM
+#if EIGEN_COMP_MSVC && (EIGEN_ARCH_i386_OR_x86_64 || EIGEN_ARCH_ARM64) && !EIGEN_OS_WINCE
   #include <intrin.h>
 #endif
 
 #if defined(EIGEN_USE_SYCL)
   #undef min
   #undef max
   #undef isnan
   #undef isinf
   #undef isfinite
-  #include <SYCL/sycl.hpp>
+  #include <CL/sycl.hpp>
   #include <map>
   #include <memory>
   #include <utility>
   #include <thread>
   #ifndef EIGEN_SYCL_LOCAL_THREAD_DIM0
   #define EIGEN_SYCL_LOCAL_THREAD_DIM0 16
   #endif
@@ -156,23 +169,29 @@
 #include "src/Core/util/SymbolicIndex.h"
 
 #include "src/Core/NumTraits.h"
 #include "src/Core/MathFunctions.h"
 #include "src/Core/GenericPacketMath.h"
 #include "src/Core/MathFunctionsImpl.h"
 #include "src/Core/arch/Default/ConjHelper.h"
+// Generic half float support
+#include "src/Core/arch/Default/Half.h"
+#include "src/Core/arch/Default/BFloat16.h"
+#include "src/Core/arch/Default/TypeCasting.h"
+#include "src/Core/arch/Default/GenericPacketMathFunctionsFwd.h"
 
 #if defined EIGEN_VECTORIZE_AVX512
   #include "src/Core/arch/SSE/PacketMath.h"
   #include "src/Core/arch/SSE/TypeCasting.h"
   #include "src/Core/arch/SSE/Complex.h"
   #include "src/Core/arch/AVX/PacketMath.h"
   #include "src/Core/arch/AVX/TypeCasting.h"
   #include "src/Core/arch/AVX/Complex.h"
   #include "src/Core/arch/AVX512/PacketMath.h"
+  #include "src/Core/arch/AVX512/TypeCasting.h"
   #include "src/Core/arch/AVX512/Complex.h"
   #include "src/Core/arch/SSE/MathFunctions.h"
   #include "src/Core/arch/AVX/MathFunctions.h"
   #include "src/Core/arch/AVX512/MathFunctions.h"
 #elif defined EIGEN_VECTORIZE_AVX
   // Use AVX for floats and doubles, SSE for integers
   #include "src/Core/arch/SSE/PacketMath.h"
@@ -193,44 +212,47 @@
   #include "src/Core/arch/AltiVec/MathFunctions.h"
   #include "src/Core/arch/AltiVec/Complex.h"
 #elif defined EIGEN_VECTORIZE_NEON
   #include "src/Core/arch/NEON/PacketMath.h"
   #include "src/Core/arch/NEON/TypeCasting.h"
   #include "src/Core/arch/NEON/MathFunctions.h"
   #include "src/Core/arch/NEON/Complex.h"
+#elif defined EIGEN_VECTORIZE_SVE
+  #include "src/Core/arch/SVE/PacketMath.h"
+  #include "src/Core/arch/SVE/TypeCasting.h"
+  #include "src/Core/arch/SVE/MathFunctions.h"
 #elif defined EIGEN_VECTORIZE_ZVECTOR
   #include "src/Core/arch/ZVector/PacketMath.h"
   #include "src/Core/arch/ZVector/MathFunctions.h"
   #include "src/Core/arch/ZVector/Complex.h"
 #elif defined EIGEN_VECTORIZE_MSA
   #include "src/Core/arch/MSA/PacketMath.h"
   #include "src/Core/arch/MSA/MathFunctions.h"
   #include "src/Core/arch/MSA/Complex.h"
 #endif
 
-// Half float support
-#include "src/Core/arch/GPU/Half.h"
-#include "src/Core/arch/GPU/PacketMathHalf.h"
-#include "src/Core/arch/GPU/TypeCasting.h"
-
 #if defined EIGEN_VECTORIZE_GPU
   #include "src/Core/arch/GPU/PacketMath.h"
   #include "src/Core/arch/GPU/MathFunctions.h"
+  #include "src/Core/arch/GPU/TypeCasting.h"
 #endif
 
 #if defined(EIGEN_USE_SYCL)
   #include "src/Core/arch/SYCL/SyclMemoryModel.h"
   #include "src/Core/arch/SYCL/InteropHeaders.h"
 #if !defined(EIGEN_DONT_VECTORIZE_SYCL)
   #include "src/Core/arch/SYCL/PacketMath.h"
   #include "src/Core/arch/SYCL/MathFunctions.h"
   #include "src/Core/arch/SYCL/TypeCasting.h"
 #endif
 #endif
+
 #include "src/Core/arch/Default/Settings.h"
+// This file provides generic implementations valid for scalar as well
+#include "src/Core/arch/Default/GenericPacketMathFunctions.h"
 
 #include "src/Core/functors/TernaryFunctors.h"
 #include "src/Core/functors/BinaryFunctors.h"
 #include "src/Core/functors/UnaryFunctors.h"
 #include "src/Core/functors/NullaryFunctors.h"
 #include "src/Core/functors/StlFunctors.h"
 #include "src/Core/functors/AssignmentFunctors.h"
@@ -321,14 +343,20 @@
 #include "src/Core/products/TriangularMatrixMatrix.h"
 #include "src/Core/products/TriangularSolverMatrix.h"
 #include "src/Core/products/TriangularSolverVector.h"
 #include "src/Core/BandMatrix.h"
 #include "src/Core/CoreIterators.h"
 #include "src/Core/ConditionEstimator.h"
 
+#if defined(EIGEN_VECTORIZE_ALTIVEC) || defined(EIGEN_VECTORIZE_VSX)
+  #include "src/Core/arch/AltiVec/MatrixProduct.h"
+#elif defined EIGEN_VECTORIZE_NEON
+  #include "src/Core/arch/NEON/GeneralBlockPanelKernel.h"
+#endif
+
 #include "src/Core/BooleanRedux.h"
 #include "src/Core/Select.h"
 #include "src/Core/VectorwiseOp.h"
 #include "src/Core/PartialReduxEvaluator.h"
 #include "src/Core/Random.h"
 #include "src/Core/Replicate.h"
 #include "src/Core/Reverse.h"
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/Eigenvalues` & `affine_transform-0.3.0/extern/eigen/Eigen/Eigenvalues`

 * *Files 2% similar despite different names*

```diff
@@ -54,8 +54,7 @@
 #include "src/Eigenvalues/ComplexSchur_LAPACKE.h"
 #include "src/Eigenvalues/SelfAdjointEigenSolver_LAPACKE.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_EIGENVALUES_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/Geometry` & `affine_transform-0.3.0/extern/eigen/Eigen/Geometry`

 * *Files 24% similar despite different names*

```diff
@@ -46,15 +46,14 @@
 #include "src/Geometry/Scaling.h"
 #include "src/Geometry/Hyperplane.h"
 #include "src/Geometry/ParametrizedLine.h"
 #include "src/Geometry/AlignedBox.h"
 #include "src/Geometry/Umeyama.h"
 
 // Use the SSE optimized version whenever possible.
-#if defined EIGEN_VECTORIZE_SSE
-#include "src/Geometry/arch/Geometry_SSE.h"
+#if (defined EIGEN_VECTORIZE_SSE) || (defined EIGEN_VECTORIZE_NEON)
+#include "src/Geometry/arch/Geometry_SIMD.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_GEOMETRY_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/Householder` & `affine_transform-0.3.0/extern/eigen/Eigen/Householder`

 * *Files 13% similar despite different names*

```diff
@@ -23,8 +23,7 @@
 #include "src/Householder/Householder.h"
 #include "src/Householder/HouseholderSequence.h"
 #include "src/Householder/BlockHouseholder.h"
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_HOUSEHOLDER_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/IterativeLinearSolvers` & `affine_transform-0.3.0/extern/eigen/Eigen/IterativeLinearSolvers`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/Jacobi` & `affine_transform-0.3.0/extern/eigen/Eigen/Jacobi`

 * *Files 5% similar despite different names*

```diff
@@ -25,9 +25,8 @@
   */
 
 #include "src/Jacobi/Jacobi.h"
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_JACOBI_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/KLUSupport` & `affine_transform-0.3.0/extern/eigen/Eigen/KLUSupport`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/LU` & `affine_transform-0.3.0/extern/eigen/Eigen/LU`

 * *Files 11% similar despite different names*

```diff
@@ -34,17 +34,14 @@
 #include "src/misc/lapacke.h"
 #endif
 #include "src/LU/PartialPivLU_LAPACKE.h"
 #endif
 #include "src/LU/Determinant.h"
 #include "src/LU/InverseImpl.h"
 
-// Use the SSE optimized version whenever possible. At the moment the
-// SSE version doesn't compile when AVX is enabled
-#if defined EIGEN_VECTORIZE_SSE && !defined EIGEN_VECTORIZE_AVX
-  #include "src/LU/arch/Inverse_SSE.h"
+#if defined EIGEN_VECTORIZE_SSE || defined EIGEN_VECTORIZE_NEON
+  #include "src/LU/arch/InverseSize4.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_LU_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/MetisSupport` & `affine_transform-0.3.0/extern/eigen/Eigen/MetisSupport`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/OrderingMethods` & `affine_transform-0.3.0/extern/eigen/Eigen/OrderingMethods`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/PaStiXSupport` & `affine_transform-0.3.0/extern/eigen/Eigen/PaStiXSupport`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/PardisoSupport` & `affine_transform-0.3.0/extern/eigen/Eigen/PardisoSupport`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/QR` & `affine_transform-0.3.0/extern/eigen/Eigen/QR`

 * *Files 10% similar despite different names*

```diff
@@ -44,8 +44,7 @@
 #include "src/QR/HouseholderQR_LAPACKE.h"
 #include "src/QR/ColPivHouseholderQR_LAPACKE.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_QR_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/QtAlignedMalloc` & `affine_transform-0.3.0/extern/eigen/Eigen/QtAlignedMalloc`

 * *Files 5% similar despite different names*

```diff
@@ -33,8 +33,7 @@
 }
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif
 
 #endif // EIGEN_QTMALLOC_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/SPQRSupport` & `affine_transform-0.3.0/extern/eigen/Eigen/SPQRSupport`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/SVD` & `affine_transform-0.3.0/extern/eigen/Eigen/SVD`

 * *Files 2% similar despite different names*

```diff
@@ -44,8 +44,7 @@
 #endif
 #include "src/SVD/JacobiSVD_LAPACKE.h"
 #endif
 
 #include "src/Core/util/ReenableStupidWarnings.h"
 
 #endif // EIGEN_SVD_MODULE_H
-/* vim: set filetype=cpp et sw=2 ts=2 ai: */
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/Sparse` & `affine_transform-0.3.0/extern/eigen/Eigen/Sparse`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/SparseCholesky` & `affine_transform-0.3.0/extern/eigen/Eigen/SparseCholesky`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/SparseCore` & `affine_transform-0.3.0/extern/eigen/Eigen/SparseCore`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/SparseLU` & `affine_transform-0.3.0/extern/eigen/Eigen/SparseLU`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/SparseQR` & `affine_transform-0.3.0/extern/eigen/Eigen/SparseQR`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/StdDeque` & `affine_transform-0.3.0/extern/eigen/Eigen/StdDeque`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/StdList` & `affine_transform-0.3.0/extern/eigen/Eigen/StdList`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/StdVector` & `affine_transform-0.3.0/extern/eigen/Eigen/StdVector`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/SuperLUSupport` & `affine_transform-0.3.0/extern/eigen/Eigen/SuperLUSupport`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/UmfPackSupport` & `affine_transform-0.3.0/extern/eigen/Eigen/UmfPackSupport`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Cholesky/LDLT.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Cholesky/LDLT.h`

 * *Files 1% similar despite different names*

```diff
@@ -41,23 +41,23 @@
   * \tparam _UpLo the triangular part that will be used for the decompositon: Lower (default) or Upper.
   *             The other triangular part won't be read.
   *
   * Perform a robust Cholesky decomposition of a positive semidefinite or negative semidefinite
   * matrix \f$ A \f$ such that \f$ A =  P^TLDL^*P \f$, where P is a permutation matrix, L
   * is lower triangular with a unit diagonal and D is a diagonal matrix.
   *
-  * The decomposition uses pivoting to ensure stability, so that L will have
+  * The decomposition uses pivoting to ensure stability, so that D will have
   * zeros in the bottom right rank(A) - n submatrix. Avoiding the square root
   * on D also stabilizes the computation.
   *
   * Remember that Cholesky decompositions are not rank-revealing. Also, do not use a Cholesky
   * decomposition to determine whether a system of equations has a solution.
   *
   * This class supports the \link InplaceDecomposition inplace decomposition \endlink mechanism.
-  * 
+  *
   * \sa MatrixBase::ldlt(), SelfAdjointView::ldlt(), class LLT
   */
 template<typename _MatrixType, int _UpLo> class LDLT
         : public SolverBase<LDLT<_MatrixType, _UpLo> >
 {
   public:
     typedef _MatrixType MatrixType;
@@ -196,15 +196,15 @@
       * \note_about_checking_solutions
       *
       * More precisely, this method solves \f$ A x = b \f$ using the decomposition \f$ A = P^T L D L^* P \f$
       * by solving the systems \f$ P^T y_1 = b \f$, \f$ L y_2 = y_1 \f$, \f$ D y_3 = y_2 \f$,
       * \f$ L^* y_4 = y_3 \f$ and \f$ P x = y_4 \f$ in succession. If the matrix \f$ A \f$ is singular, then
       * \f$ D \f$ will also be singular (all the other matrices are invertible). In that case, the
       * least-square solution of \f$ D y_3 = y_2 \f$ is computed. This does not mean that this function
-      * computes the least-square solution of \f$ A x = b \f$ is \f$ A \f$ is singular.
+      * computes the least-square solution of \f$ A x = b \f$ if \f$ A \f$ is singular.
       *
       * \sa MatrixBase::ldlt(), SelfAdjointView::ldlt()
       */
     template<typename Rhs>
     inline const Solve<LDLT, Rhs>
     solve(const MatrixBase<Rhs>& b) const;
     #endif
@@ -242,16 +242,16 @@
     /** \returns the adjoint of \c *this, that is, a const reference to the decomposition itself as the underlying matrix is self-adjoint.
       *
       * This method is provided for compatibility with other matrix decompositions, thus enabling generic code such as:
       * \code x = decomposition.adjoint().solve(b) \endcode
       */
     const LDLT& adjoint() const { return *this; };
 
-    inline Index rows() const { return m_matrix.rows(); }
-    inline Index cols() const { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC inline EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC inline EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
     /** \brief Reports whether previous computation was successful.
       *
       * \returns \c Success if computation was successful,
       *          \c NumericalIssue if the factorization failed because of a zero pivot.
       */
     ComputationInfo info() const
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Cholesky/LLT.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Cholesky/LLT.h`

 * *Files 2% similar despite different names*

```diff
@@ -195,18 +195,18 @@
     }
 
     /** \returns the adjoint of \c *this, that is, a const reference to the decomposition itself as the underlying matrix is self-adjoint.
       *
       * This method is provided for compatibility with other matrix decompositions, thus enabling generic code such as:
       * \code x = decomposition.adjoint().solve(b) \endcode
       */
-    const LLT& adjoint() const { return *this; };
+    const LLT& adjoint() const EIGEN_NOEXCEPT { return *this; };
 
-    inline Index rows() const { return m_matrix.rows(); }
-    inline Index cols() const { return m_matrix.cols(); }
+    inline EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    inline EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
     template<typename VectorType>
     LLT & rankUpdate(const VectorType& vec, const RealScalar& sigma = 1);
 
     #ifndef EIGEN_PARSED_BY_DOXYGEN
     template<typename RhsType, typename DstType>
     void _solve_impl(const RhsType &rhs, DstType &dst) const;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Cholesky/LLT_LAPACKE.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Cholesky/LLT_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/CholmodSupport/CholmodSupport.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/CholmodSupport/CholmodSupport.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ArithmeticSequence.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ArithmeticSequence.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Array.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Array.h`

 * *Files 0% similar despite different names*

```diff
@@ -113,15 +113,15 @@
       * prevent a default operator= from hiding the templated operator=.
       */
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE Array& operator=(const Array& other)
     {
       return Base::_set(other);
     }
-    
+
     /** Default constructor.
       *
       * For fixed-size matrices, does nothing.
       *
       * For dynamic-size matrices, creates an empty matrix of size 0. Does not allocate any array. Such a matrix
       * is called a null matrix. This constructor is the unique way to create null matrices: resizing
       * a matrix to 0 is not supported.
@@ -153,15 +153,15 @@
       : Base(std::move(other))
     {
       Base::_check_template_params();
     }
     EIGEN_DEVICE_FUNC
     Array& operator=(Array&& other) EIGEN_NOEXCEPT_IF(std::is_nothrow_move_assignable<Scalar>::value)
     {
-      other.swap(*this);
+      Base::operator=(std::move(other));
       return *this;
     }
 #endif
 
     #if EIGEN_HAS_CXX11
     /** \copydoc PlainObjectBase(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args)
      *
@@ -173,32 +173,32 @@
      */
     template <typename... ArgTypes>
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     Array(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args)
       : Base(a0, a1, a2, a3, args...) {}
 
     /** \brief Constructs an array and initializes it from the coefficients given as initializer-lists grouped by row. \cpp11
-      * 
+      *
       * In the general case, the constructor takes a list of rows, each row being represented as a list of coefficients:
-      * 
+      *
       * Example: \include Array_initializer_list_23_cxx11.cpp
       * Output: \verbinclude Array_initializer_list_23_cxx11.out
-      * 
+      *
       * Each of the inner initializer lists must contain the exact same number of elements, otherwise an assertion is triggered.
-      * 
+      *
       * In the case of a compile-time column 1D array, implicit transposition from a single row is allowed.
       * Therefore <code> Array<int,Dynamic,1>{{1,2,3,4,5}}</code> is legal and the more verbose syntax
       * <code>Array<int,Dynamic,1>{{1},{2},{3},{4},{5}}</code> can be avoided:
-      * 
+      *
       * Example: \include Array_initializer_list_vector_cxx11.cpp
       * Output: \verbinclude Array_initializer_list_vector_cxx11.out
-      * 
+      *
       * In the case of fixed-sized arrays, the initializer list sizes must exactly match the array sizes,
       * and implicit transposition is allowed for compile-time 1D arrays only.
-      * 
+      *
       * \sa  Array(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args)
       */
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE Array(const std::initializer_list<std::initializer_list<Scalar>>& list) : Base(list) {}
     #endif // end EIGEN_HAS_CXX11
 
     #ifndef EIGEN_PARSED_BY_DOXYGEN
@@ -237,15 +237,15 @@
       * This is useful for dynamic-size arrays. For fixed-size arrays,
       * it is redundant to pass these parameters, so one should use the default constructor
       * Array() instead. */
     Array(Index rows, Index cols);
     /** constructs an initialized 2D vector with given coefficients
       * \sa Array(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args) */
     Array(const Scalar& val0, const Scalar& val1);
-    #endif  // end EIGEN_PARSED_BY_DOXYGEN 
+    #endif  // end EIGEN_PARSED_BY_DOXYGEN
 
     /** constructs an initialized 3D vector with given coefficients
       * \sa Array(const Scalar& a0, const Scalar& a1, const Scalar& a2, const Scalar& a3, const ArgTypes&... args)
       */
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE Array(const Scalar& val0, const Scalar& val1, const Scalar& val2)
     {
@@ -284,16 +284,18 @@
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE Array(const EigenBase<OtherDerived> &other,
                               typename internal::enable_if<internal::is_convertible<typename OtherDerived::Scalar,Scalar>::value,
                                                            PrivateType>::type = PrivateType())
       : Base(other.derived())
     { }
 
-    EIGEN_DEVICE_FUNC inline Index innerStride() const { return 1; }
-    EIGEN_DEVICE_FUNC inline Index outerStride() const { return this->innerSize(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT{ return 1; }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return this->innerSize(); }
 
     #ifdef EIGEN_ARRAY_PLUGIN
     #include EIGEN_ARRAY_PLUGIN
     #endif
 
   private:
 
@@ -318,15 +320,15 @@
   * a fixed-size 1D array of 4 complex floats.
   *
   * With \cpp11, template alias are also defined for common sizes.
   * They follow the same pattern as above except that the scalar type suffix is replaced by a
   * template parameter, i.e.:
   *   - `ArrayRowsCols<Type>` where `Rows` and `Cols` can be \c 2,\c 3,\c 4, or \c X for fixed or dynamic size.
   *   - `ArraySize<Type>` where `Size` can be \c 2,\c 3,\c 4 or \c X for fixed or dynamic size 1D arrays.
-  * 
+  *
   * \sa class Array
   */
 
 #define EIGEN_MAKE_ARRAY_TYPEDEFS(Type, TypeSuffix, Size, SizeSuffix)   \
 /** \ingroup arraytypedefs */                                    \
 typedef Array<Type, Size, Size> Array##SizeSuffix##SizeSuffix##TypeSuffix;  \
 /** \ingroup arraytypedefs */                                    \
@@ -363,15 +365,15 @@
 /** \ingroup arraytypedefs */                                     \
 /** \brief \cpp11 */                                              \
 template <typename Type>                                          \
 using Array##SizeSuffix##SizeSuffix = Array<Type, Size, Size>;    \
 /** \ingroup arraytypedefs */                                     \
 /** \brief \cpp11 */                                              \
 template <typename Type>                                          \
-using Array##SizeSuffix = Array<Type, Size, 1>; 
+using Array##SizeSuffix = Array<Type, Size, 1>;
 
 #define EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(Size)                     \
 /** \ingroup arraytypedefs */                                     \
 /** \brief \cpp11 */                                              \
 template <typename Type>                                          \
 using Array##Size##X = Array<Type, Size, Dynamic>;                \
 /** \ingroup arraytypedefs */                                     \
@@ -387,15 +389,15 @@
 EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(3)
 EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS(4)
 
 #undef EIGEN_MAKE_ARRAY_TYPEDEFS
 #undef EIGEN_MAKE_ARRAY_FIXED_TYPEDEFS
 
 #endif // EIGEN_HAS_CXX11
-  
+
 #define EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE_AND_SIZE(TypeSuffix, SizeSuffix) \
 using Eigen::Matrix##SizeSuffix##TypeSuffix; \
 using Eigen::Vector##SizeSuffix##TypeSuffix; \
 using Eigen::RowVector##SizeSuffix##TypeSuffix;
 
 #define EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE(TypeSuffix) \
 EIGEN_USING_ARRAY_TYPEDEFS_FOR_TYPE_AND_SIZE(TypeSuffix, 2) \
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ArrayBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ArrayBase.h`

 * *Files 1% similar despite different names*

```diff
@@ -149,16 +149,16 @@
     EIGEN_DEVICE_FUNC
     const MatrixWrapper<const Derived> matrix() const { return MatrixWrapper<const Derived>(derived()); }
 
 //     template<typename Dest>
 //     inline void evalTo(Dest& dst) const { dst = matrix(); }
 
   protected:
-    EIGEN_DEVICE_FUNC
-    ArrayBase() : Base() {}
+    EIGEN_DEFAULT_COPY_CONSTRUCTOR(ArrayBase)
+    EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(ArrayBase)
 
   private:
     explicit ArrayBase(Index);
     ArrayBase(Index,Index);
     template<typename OtherDerived> explicit ArrayBase(const ArrayBase<OtherDerived>&);
   protected:
     // mixing arrays and matrices is not legal
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ArrayWrapper.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ArrayWrapper.h`

 * *Files 20% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_ARRAYWRAPPER_H
 #define EIGEN_ARRAYWRAPPER_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \class ArrayWrapper
   * \ingroup Core_Module
   *
   * \brief Expression of a mathematical vector or matrix as an array object
   *
   * This class is the return type of MatrixBase::array(), and most of the time
@@ -56,22 +56,22 @@
     typedef typename internal::ref_selector<ExpressionType>::non_const_type NestedExpressionType;
 
     using Base::coeffRef;
 
     EIGEN_DEVICE_FUNC
     explicit EIGEN_STRONG_INLINE ArrayWrapper(ExpressionType& matrix) : m_expression(matrix) {}
 
-    EIGEN_DEVICE_FUNC
-    inline Index rows() const { return m_expression.rows(); }
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return m_expression.cols(); }
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const { return m_expression.outerStride(); }
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const { return m_expression.innerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_expression.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_expression.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return m_expression.outerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return m_expression.innerStride(); }
 
     EIGEN_DEVICE_FUNC
     inline ScalarWithConstIfNotLvalue* data() { return m_expression.data(); }
     EIGEN_DEVICE_FUNC
     inline const Scalar* data() const { return m_expression.data(); }
 
     EIGEN_DEVICE_FUNC
@@ -87,16 +87,16 @@
     }
 
     template<typename Dest>
     EIGEN_DEVICE_FUNC
     inline void evalTo(Dest& dst) const { dst = m_expression; }
 
     EIGEN_DEVICE_FUNC
-    const typename internal::remove_all<NestedExpressionType>::type& 
-    nestedExpression() const 
+    const typename internal::remove_all<NestedExpressionType>::type&
+    nestedExpression() const
     {
       return m_expression;
     }
 
     /** Forwards the resizing request to the nested expression
       * \sa DenseBase::resize(Index)  */
     EIGEN_DEVICE_FUNC
@@ -154,22 +154,22 @@
     typedef typename internal::ref_selector<ExpressionType>::non_const_type NestedExpressionType;
 
     using Base::coeffRef;
 
     EIGEN_DEVICE_FUNC
     explicit inline MatrixWrapper(ExpressionType& matrix) : m_expression(matrix) {}
 
-    EIGEN_DEVICE_FUNC
-    inline Index rows() const { return m_expression.rows(); }
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return m_expression.cols(); }
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const { return m_expression.outerStride(); }
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const { return m_expression.innerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_expression.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_expression.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return m_expression.outerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return m_expression.innerStride(); }
 
     EIGEN_DEVICE_FUNC
     inline ScalarWithConstIfNotLvalue* data() { return m_expression.data(); }
     EIGEN_DEVICE_FUNC
     inline const Scalar* data() const { return m_expression.data(); }
 
     EIGEN_DEVICE_FUNC
@@ -181,16 +181,16 @@
     EIGEN_DEVICE_FUNC
     inline const Scalar& coeffRef(Index index) const
     {
       return m_expression.coeffRef(index);
     }
 
     EIGEN_DEVICE_FUNC
-    const typename internal::remove_all<NestedExpressionType>::type& 
-    nestedExpression() const 
+    const typename internal::remove_all<NestedExpressionType>::type&
+    nestedExpression() const
     {
       return m_expression;
     }
 
     /** Forwards the resizing request to the nested expression
       * \sa DenseBase::resize(Index)  */
     EIGEN_DEVICE_FUNC
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Assign.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Assign.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/AssignEvaluator.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/AssignEvaluator.h`

 * *Files 4% similar despite different names*

```diff
@@ -13,32 +13,32 @@
 #define EIGEN_ASSIGN_EVALUATOR_H
 
 namespace Eigen {
 
 // This implementation is based on Assign.h
 
 namespace internal {
-  
+
 /***************************************************************************
 * Part 1 : the logic deciding a strategy for traversal and unrolling       *
 ***************************************************************************/
 
 // copy_using_evaluator_traits is based on assign_traits
 
 template <typename DstEvaluator, typename SrcEvaluator, typename AssignFunc, int MaxPacketSize = -1>
 struct copy_using_evaluator_traits
 {
   typedef typename DstEvaluator::XprType Dst;
   typedef typename Dst::Scalar DstScalar;
-  
+
   enum {
     DstFlags = DstEvaluator::Flags,
     SrcFlags = SrcEvaluator::Flags
   };
-  
+
 public:
   enum {
     DstAlignment = DstEvaluator::Alignment,
     SrcAlignment = SrcEvaluator::Alignment,
     DstHasDirectAccess = (DstFlags & DirectAccessBit) == DirectAccessBit,
     JointAlignment = EIGEN_PLAIN_ENUM_MIN(DstAlignment,SrcAlignment)
   };
@@ -95,15 +95,16 @@
          indicated by InnerMaxSize rather than InnerSize, think of the case of a dynamic block
          in a fixed-size matrix
          However, with EIGEN_UNALIGNED_VECTORIZE and unrolling, slice vectorization is still worth it */
   };
 
 public:
   enum {
-    Traversal = (int(MayLinearVectorize) && (LinearPacketSize>InnerPacketSize)) ? int(LinearVectorizedTraversal)
+    Traversal =  int(Dst::SizeAtCompileTime) == 0 ? int(AllAtOnceTraversal) // If compile-size is zero, traversing will fail at compile-time.
+              : (int(MayLinearVectorize) && (LinearPacketSize>InnerPacketSize)) ? int(LinearVectorizedTraversal)
               : int(MayInnerVectorize)   ? int(InnerVectorizedTraversal)
               : int(MayLinearVectorize)  ? int(LinearVectorizedTraversal)
               : int(MaySliceVectorize)   ? int(SliceVectorizedTraversal)
               : int(MayLinearize)        ? int(LinearTraversal)
                                          : int(DefaultTraversal),
     Vectorized = int(Traversal) == InnerVectorizedTraversal
               || int(Traversal) == LinearVectorizedTraversal
@@ -133,15 +134,15 @@
                                              : int(NoUnrolling)
                   )
               : int(Traversal) == int(LinearVectorizedTraversal)
                 ? ( bool(MayUnrollCompletely) && ( EIGEN_UNALIGNED_VECTORIZE || (int(DstAlignment)>=int(LinearRequiredAlignment)))
                           ? int(CompleteUnrolling)
                           : int(NoUnrolling) )
               : int(Traversal) == int(LinearTraversal)
-                ? ( bool(MayUnrollCompletely) ? int(CompleteUnrolling) 
+                ? ( bool(MayUnrollCompletely) ? int(CompleteUnrolling)
                                               : int(NoUnrolling) )
 #if EIGEN_UNALIGNED_VECTORIZE
               : int(Traversal) == int(SliceVectorizedTraversal)
                 ? ( bool(MayUnrollInner) ? int(InnerUnrolling)
                                          : int(NoUnrolling) )
 #endif
               : int(NoUnrolling)
@@ -195,15 +196,15 @@
 
 template<typename Kernel, int Index, int Stop>
 struct copy_using_evaluator_DefaultTraversal_CompleteUnrolling
 {
   // FIXME: this is not very clean, perhaps this information should be provided by the kernel?
   typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
   typedef typename DstEvaluatorType::XprType DstXprType;
-  
+
   enum {
     outer = Index / DstXprType::InnerSizeAtCompileTime,
     inner = Index % DstXprType::InnerSizeAtCompileTime
   };
 
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
   {
@@ -261,15 +262,15 @@
 template<typename Kernel, int Index, int Stop>
 struct copy_using_evaluator_innervec_CompleteUnrolling
 {
   // FIXME: this is not very clean, perhaps this information should be provided by the kernel?
   typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
   typedef typename DstEvaluatorType::XprType DstXprType;
   typedef typename Kernel::PacketType PacketType;
-  
+
   enum {
     outer = Index / DstXprType::InnerSizeAtCompileTime,
     inner = Index % DstXprType::InnerSizeAtCompileTime,
     SrcAlignment = Kernel::AssignmentTraits::SrcAlignment,
     DstAlignment = Kernel::AssignmentTraits::DstAlignment
   };
 
@@ -313,14 +314,30 @@
 
 template<typename Kernel,
          int Traversal = Kernel::AssignmentTraits::Traversal,
          int Unrolling = Kernel::AssignmentTraits::Unrolling>
 struct dense_assignment_loop;
 
 /************************
+***** Special Cases *****
+************************/
+
+// Zero-sized assignment is a no-op.
+template<typename Kernel, int Unrolling>
+struct dense_assignment_loop<Kernel, AllAtOnceTraversal, Unrolling>
+{
+  EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel& /*kernel*/)
+  {
+    typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
+    EIGEN_STATIC_ASSERT(int(DstXprType::SizeAtCompileTime) == 0,
+      EIGEN_INTERNAL_ERROR_PLEASE_FILE_A_BUG_REPORT)
+  }
+};
+
+/************************
 *** Default traversal ***
 ************************/
 
 template<typename Kernel>
 struct dense_assignment_loop<Kernel, DefaultTraversal, NoUnrolling>
 {
   EIGEN_DEVICE_FUNC static void EIGEN_STRONG_INLINE run(Kernel &kernel)
@@ -426,18 +443,18 @@
 template<typename Kernel>
 struct dense_assignment_loop<Kernel, LinearVectorizedTraversal, CompleteUnrolling>
 {
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
   {
     typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
     typedef typename Kernel::PacketType PacketType;
-    
+
     enum { size = DstXprType::SizeAtCompileTime,
            packetSize =unpacket_traits<PacketType>::size,
-           alignedSize = (size/packetSize)*packetSize };
+           alignedSize = (int(size)/packetSize)*packetSize };
 
     copy_using_evaluator_innervec_CompleteUnrolling<Kernel, 0, alignedSize>::run(kernel);
     copy_using_evaluator_DefaultTraversal_CompleteUnrolling<Kernel, alignedSize, size>::run(kernel);
   }
 };
 
 /**************************
@@ -568,22 +585,23 @@
 struct dense_assignment_loop<Kernel, SliceVectorizedTraversal, InnerUnrolling>
 {
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void run(Kernel &kernel)
   {
     typedef typename Kernel::DstEvaluatorType::XprType DstXprType;
     typedef typename Kernel::PacketType PacketType;
 
-    enum { size = DstXprType::InnerSizeAtCompileTime,
+    enum { innerSize = DstXprType::InnerSizeAtCompileTime,
            packetSize =unpacket_traits<PacketType>::size,
-           vectorizableSize = (size/packetSize)*packetSize };
+           vectorizableSize = (int(innerSize) / int(packetSize)) * int(packetSize),
+           size = DstXprType::SizeAtCompileTime };
 
     for(Index outer = 0; outer < kernel.outerSize(); ++outer)
     {
       copy_using_evaluator_innervec_InnerUnrolling<Kernel, 0, vectorizableSize, 0, 0>::run(kernel, outer);
-      copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, vectorizableSize, size>::run(kernel, outer);
+      copy_using_evaluator_DefaultTraversal_InnerUnrolling<Kernel, vectorizableSize, innerSize>::run(kernel, outer);
     }
   }
 };
 #endif
 
 
 /***************************************************************************
@@ -599,82 +617,82 @@
 template<typename DstEvaluatorTypeT, typename SrcEvaluatorTypeT, typename Functor, int Version = Specialized>
 class generic_dense_assignment_kernel
 {
 protected:
   typedef typename DstEvaluatorTypeT::XprType DstXprType;
   typedef typename SrcEvaluatorTypeT::XprType SrcXprType;
 public:
-  
+
   typedef DstEvaluatorTypeT DstEvaluatorType;
   typedef SrcEvaluatorTypeT SrcEvaluatorType;
   typedef typename DstEvaluatorType::Scalar Scalar;
   typedef copy_using_evaluator_traits<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor> AssignmentTraits;
   typedef typename AssignmentTraits::PacketType PacketType;
-  
-  
+
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   generic_dense_assignment_kernel(DstEvaluatorType &dst, const SrcEvaluatorType &src, const Functor &func, DstXprType& dstExpr)
     : m_dst(dst), m_src(src), m_functor(func), m_dstExpr(dstExpr)
   {
     #ifdef EIGEN_DEBUG_ASSIGN
     AssignmentTraits::debug();
     #endif
   }
-  
-  EIGEN_DEVICE_FUNC Index size() const        { return m_dstExpr.size(); }
-  EIGEN_DEVICE_FUNC Index innerSize() const   { return m_dstExpr.innerSize(); }
-  EIGEN_DEVICE_FUNC Index outerSize() const   { return m_dstExpr.outerSize(); }
-  EIGEN_DEVICE_FUNC Index rows() const        { return m_dstExpr.rows(); }
-  EIGEN_DEVICE_FUNC Index cols() const        { return m_dstExpr.cols(); }
-  EIGEN_DEVICE_FUNC Index outerStride() const { return m_dstExpr.outerStride(); }
-  
-  EIGEN_DEVICE_FUNC DstEvaluatorType& dstEvaluator() { return m_dst; }
-  EIGEN_DEVICE_FUNC const SrcEvaluatorType& srcEvaluator() const { return m_src; }
-  
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index size() const EIGEN_NOEXCEPT { return m_dstExpr.size(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index innerSize() const EIGEN_NOEXCEPT { return m_dstExpr.innerSize(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index outerSize() const EIGEN_NOEXCEPT { return m_dstExpr.outerSize(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_dstExpr.rows(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_dstExpr.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index outerStride() const EIGEN_NOEXCEPT { return m_dstExpr.outerStride(); }
+
+  EIGEN_DEVICE_FUNC DstEvaluatorType& dstEvaluator() EIGEN_NOEXCEPT { return m_dst; }
+  EIGEN_DEVICE_FUNC const SrcEvaluatorType& srcEvaluator() const EIGEN_NOEXCEPT { return m_src; }
+
   /// Assign src(row,col) to dst(row,col) through the assignment functor.
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(Index row, Index col)
   {
     m_functor.assignCoeff(m_dst.coeffRef(row,col), m_src.coeff(row,col));
   }
-  
+
   /// \sa assignCoeff(Index,Index)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeff(Index index)
   {
     m_functor.assignCoeff(m_dst.coeffRef(index), m_src.coeff(index));
   }
-  
+
   /// \sa assignCoeff(Index,Index)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignCoeffByOuterInner(Index outer, Index inner)
   {
-    Index row = rowIndexByOuterInner(outer, inner); 
-    Index col = colIndexByOuterInner(outer, inner); 
+    Index row = rowIndexByOuterInner(outer, inner);
+    Index col = colIndexByOuterInner(outer, inner);
     assignCoeff(row, col);
   }
-  
-  
+
+
   template<int StoreMode, int LoadMode, typename PacketType>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignPacket(Index row, Index col)
   {
     m_functor.template assignPacket<StoreMode>(&m_dst.coeffRef(row,col), m_src.template packet<LoadMode,PacketType>(row,col));
   }
-  
+
   template<int StoreMode, int LoadMode, typename PacketType>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignPacket(Index index)
   {
     m_functor.template assignPacket<StoreMode>(&m_dst.coeffRef(index), m_src.template packet<LoadMode,PacketType>(index));
   }
-  
+
   template<int StoreMode, int LoadMode, typename PacketType>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void assignPacketByOuterInner(Index outer, Index inner)
   {
-    Index row = rowIndexByOuterInner(outer, inner); 
+    Index row = rowIndexByOuterInner(outer, inner);
     Index col = colIndexByOuterInner(outer, inner);
     assignPacket<StoreMode,LoadMode,PacketType>(row, col);
   }
-  
+
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE Index rowIndexByOuterInner(Index outer, Index inner)
   {
     typedef typename DstEvaluatorType::ExpressionTraits Traits;
     return int(Traits::RowsAtCompileTime) == 1 ? 0
       : int(Traits::ColsAtCompileTime) == 1 ? inner
       : int(DstEvaluatorType::Flags)&RowMajorBit ? outer
       : inner;
@@ -689,15 +707,15 @@
       : outer;
   }
 
   EIGEN_DEVICE_FUNC const Scalar* dstDataPtr() const
   {
     return m_dstExpr.data();
   }
-  
+
 protected:
   DstEvaluatorType& m_dst;
   const SrcEvaluatorType& m_src;
   const Functor &m_functor;
   // TODO find a way to avoid the needs of the original expression
   DstXprType& m_dstExpr;
 };
@@ -712,21 +730,21 @@
 protected:
   typedef generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, BuiltIn> Base;
  public:
     typedef typename Base::Scalar Scalar;
     typedef typename Base::DstXprType DstXprType;
     typedef copy_using_evaluator_traits<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, 4> AssignmentTraits;
     typedef typename AssignmentTraits::PacketType PacketType;
-    
+
     EIGEN_DEVICE_FUNC restricted_packet_dense_assignment_kernel(DstEvaluatorTypeT &dst, const SrcEvaluatorTypeT &src, const Functor &func, DstXprType& dstExpr)
     : Base(dst, src, func, dstExpr)
   {
   }
  };
- 
+
 /***************************************************************************
 * Part 5 : Entry point for dense rectangular assignment
 ***************************************************************************/
 
 template<typename DstXprType,typename SrcXprType, typename Functor>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 void resize_if_allowed(DstXprType &dst, const SrcXprType& src, const Functor &/*func*/)
@@ -756,21 +774,31 @@
   SrcEvaluatorType srcEvaluator(src);
 
   // NOTE To properly handle A = (A*A.transpose())/s with A rectangular,
   // we need to resize the destination after the source evaluator has been created.
   resize_if_allowed(dst, src, func);
 
   DstEvaluatorType dstEvaluator(dst);
-    
+
   typedef generic_dense_assignment_kernel<DstEvaluatorType,SrcEvaluatorType,Functor> Kernel;
   Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
 
   dense_assignment_loop<Kernel>::run(kernel);
 }
 
+// Specialization for filling the destination with a constant value.
+#ifndef EIGEN_GPU_COMPILE_PHASE
+template<typename DstXprType>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_dense_assignment_loop(DstXprType& dst, const Eigen::CwiseNullaryOp<Eigen::internal::scalar_constant_op<typename DstXprType::Scalar>, DstXprType>& src, const internal::assign_op<typename DstXprType::Scalar,typename DstXprType::Scalar>& func)
+{
+  resize_if_allowed(dst, src, func);
+  std::fill_n(dst.data(), dst.size(), src.functor()());
+}
+#endif
+
 template<typename DstXprType, typename SrcXprType>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void call_dense_assignment_loop(DstXprType& dst, const SrcXprType& src)
 {
   call_dense_assignment_loop(dst, src, internal::assign_op<typename DstXprType::Scalar,typename SrcXprType::Scalar>());
 }
 
 /***************************************************************************
@@ -784,15 +812,15 @@
 
 // Assignment kind defined in this file:
 struct Dense2Dense {};
 struct EigenBase2EigenBase {};
 
 template<typename,typename> struct AssignmentKind { typedef EigenBase2EigenBase Kind; };
 template<> struct AssignmentKind<DenseShape,DenseShape> { typedef Dense2Dense Kind; };
-    
+
 // This is the main assignment class
 template< typename DstXprType, typename SrcXprType, typename Functor,
           typename Kind = typename AssignmentKind< typename evaluator_traits<DstXprType>::Shape , typename evaluator_traits<SrcXprType>::Shape >::Kind,
           typename EnableIf = void>
 struct Assignment;
 
 
@@ -809,15 +837,15 @@
 }
 template<typename Dst, typename Src>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 void call_assignment(const Dst& dst, const Src& src)
 {
   call_assignment(dst, src, internal::assign_op<typename Dst::Scalar,typename Src::Scalar>());
 }
-                     
+
 // Deal with "assume-aliasing"
 template<typename Dst, typename Src, typename Func>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 void call_assignment(Dst& dst, const Src& src, const Func& func, typename enable_if< evaluator_assume_aliasing<Src>::value, void*>::type = 0)
 {
   typename plain_matrix_type<Src>::type tmp(src);
   call_assignment_no_alias(dst, tmp, func);
@@ -849,20 +877,20 @@
                         || (int(Dst::ColsAtCompileTime) == 1 && int(Src::RowsAtCompileTime) == 1)
                       ) && int(Dst::SizeAtCompileTime) != 1
   };
 
   typedef typename internal::conditional<NeedToTranspose, Transpose<Dst>, Dst>::type ActualDstTypeCleaned;
   typedef typename internal::conditional<NeedToTranspose, Transpose<Dst>, Dst&>::type ActualDstType;
   ActualDstType actualDst(dst);
-  
+
   // TODO check whether this is the right place to perform these checks:
   EIGEN_STATIC_ASSERT_LVALUE(Dst)
   EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(ActualDstTypeCleaned,Src)
   EIGEN_CHECK_BINARY_COMPATIBILIY(Func,typename ActualDstTypeCleaned::Scalar,typename Src::Scalar);
-  
+
   Assignment<ActualDstTypeCleaned,Src,Func>::run(actualDst, src, func);
 }
 
 template<typename Dst, typename Src, typename Func>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 void call_restricted_packet_assignment_no_alias(Dst& dst, const Src& src, const Func& func)
 {
@@ -871,15 +899,15 @@
     typedef restricted_packet_dense_assignment_kernel<DstEvaluatorType,SrcEvaluatorType,Func> Kernel;
 
     EIGEN_STATIC_ASSERT_LVALUE(Dst)
     EIGEN_CHECK_BINARY_COMPATIBILIY(Func,typename Dst::Scalar,typename Src::Scalar);
 
     SrcEvaluatorType srcEvaluator(src);
     resize_if_allowed(dst, src, func);
-    
+
     DstEvaluatorType dstEvaluator(dst);
     Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
 
     dense_assignment_loop<Kernel>::run(kernel);
 }
 
 template<typename Dst, typename Src>
@@ -918,15 +946,15 @@
 {
   EIGEN_DEVICE_FUNC
   static EIGEN_STRONG_INLINE void run(DstXprType &dst, const SrcXprType &src, const Functor &func)
   {
 #ifndef EIGEN_NO_DEBUG
     internal::check_for_aliasing(dst, src);
 #endif
-    
+
     call_dense_assignment_loop(dst, src, func);
   }
 };
 
 // Generic assignment through evalTo.
 // TODO: not sure we have to keep that one, but it helps porting current code to new evaluator mechanism.
 // Note that the last template argument "Weak" is needed to make it possible to perform
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Assign_MKL.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Assign_MKL.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/BandMatrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/BandMatrix.h`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_BANDMATRIX_H
 #define EIGEN_BANDMATRIX_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename Derived>
 class BandMatrixBase : public EigenBase<Derived>
 {
   public:
@@ -41,37 +41,37 @@
       DataRowsAtCompileTime = ((Supers!=Dynamic) && (Subs!=Dynamic))
                             ? 1 + Supers + Subs
                             : Dynamic,
       SizeAtCompileTime = EIGEN_SIZE_MIN_PREFER_DYNAMIC(RowsAtCompileTime,ColsAtCompileTime)
     };
 
   public:
-    
+
     using Base::derived;
     using Base::rows;
     using Base::cols;
 
     /** \returns the number of super diagonals */
     inline Index supers() const { return derived().supers(); }
 
     /** \returns the number of sub diagonals */
     inline Index subs() const { return derived().subs(); }
-    
+
     /** \returns an expression of the underlying coefficient matrix */
     inline const CoefficientsType& coeffs() const { return derived().coeffs(); }
-    
+
     /** \returns an expression of the underlying coefficient matrix */
     inline CoefficientsType& coeffs() { return derived().coeffs(); }
 
     /** \returns a vector expression of the \a i -th column,
       * only the meaningful part is returned.
       * \warning the internal storage must be column major. */
     inline Block<CoefficientsType,Dynamic,1> col(Index i)
     {
-      EIGEN_STATIC_ASSERT((Options&RowMajor)==0,THIS_METHOD_IS_ONLY_FOR_COLUMN_MAJOR_MATRICES);
+      EIGEN_STATIC_ASSERT((int(Options) & int(RowMajor)) == 0, THIS_METHOD_IS_ONLY_FOR_COLUMN_MAJOR_MATRICES);
       Index start = 0;
       Index len = coeffs().rows();
       if (i<=supers())
       {
         start = supers()-i;
         len = (std::min)(rows(),std::max<Index>(0,coeffs().rows() - (supers()-i)));
       }
@@ -86,15 +86,15 @@
 
     /** \returns a vector expression of the main diagonal (const version) */
     inline const Block<const CoefficientsType,1,SizeAtCompileTime> diagonal() const
     { return Block<const CoefficientsType,1,SizeAtCompileTime>(coeffs(),supers(),0,1,(std::min)(rows(),cols())); }
 
     template<int Index> struct DiagonalIntReturnType {
       enum {
-        ReturnOpposite = (Options&SelfAdjoint) && (((Index)>0 && Supers==0) || ((Index)<0 && Subs==0)),
+        ReturnOpposite = (int(Options) & int(SelfAdjoint)) && (((Index) > 0 && Supers == 0) || ((Index) < 0 && Subs == 0)),
         Conjugate = ReturnOpposite && NumTraits<Scalar>::IsComplex,
         ActualIndex = ReturnOpposite ? -Index : Index,
         DiagonalSize = (RowsAtCompileTime==Dynamic || ColsAtCompileTime==Dynamic)
                      ? Dynamic
                      : (ActualIndex<0
                      ? EIGEN_SIZE_MIN_PREFER_DYNAMIC(ColsAtCompileTime, RowsAtCompileTime + ActualIndex)
                      : EIGEN_SIZE_MIN_PREFER_DYNAMIC(RowsAtCompileTime, ColsAtCompileTime - ActualIndex))
@@ -126,15 +126,15 @@
 
     /** \returns a vector expression of the \a i -th sub or super diagonal */
     inline const Block<const CoefficientsType,1,Dynamic> diagonal(Index i) const
     {
       eigen_assert((i<0 && -i<=subs()) || (i>=0 && i<=supers()));
       return Block<const CoefficientsType,1,Dynamic>(coeffs(), supers()-i, std::max<Index>(0,i), 1, diagonalLength(i));
     }
-    
+
     template<typename Dest> inline void evalTo(Dest& dst) const
     {
       dst.resize(rows(),cols());
       dst.setZero();
       dst.diagonal() = diagonal();
       for (Index i=1; i<=supers();++i)
         dst.diagonal(i) = diagonal(i);
@@ -188,15 +188,15 @@
     MaxColsAtCompileTime = _Cols,
     Flags = LvalueBit,
     Supers = _Supers,
     Subs = _Subs,
     Options = _Options,
     DataRowsAtCompileTime = ((Supers!=Dynamic) && (Subs!=Dynamic)) ? 1 + Supers + Subs : Dynamic
   };
-  typedef Matrix<Scalar,DataRowsAtCompileTime,ColsAtCompileTime,Options&RowMajor?RowMajor:ColMajor> CoefficientsType;
+  typedef Matrix<Scalar, DataRowsAtCompileTime, ColsAtCompileTime, int(Options) & int(RowMajor) ? RowMajor : ColMajor> CoefficientsType;
 };
 
 template<typename _Scalar, int Rows, int Cols, int Supers, int Subs, int Options>
 class BandMatrix : public BandMatrixBase<BandMatrix<_Scalar,Rows,Cols,Supers,Subs,Options> >
 {
   public:
 
@@ -207,24 +207,24 @@
     explicit inline BandMatrix(Index rows=Rows, Index cols=Cols, Index supers=Supers, Index subs=Subs)
       : m_coeffs(1+supers+subs,cols),
         m_rows(rows), m_supers(supers), m_subs(subs)
     {
     }
 
     /** \returns the number of columns */
-    inline Index rows() const { return m_rows.value(); }
+    inline EIGEN_CONSTEXPR Index rows() const { return m_rows.value(); }
 
     /** \returns the number of rows */
-    inline Index cols() const { return m_coeffs.cols(); }
+    inline EIGEN_CONSTEXPR Index cols() const { return m_coeffs.cols(); }
 
     /** \returns the number of super diagonals */
-    inline Index supers() const { return m_supers.value(); }
+    inline EIGEN_CONSTEXPR Index supers() const { return m_supers.value(); }
 
     /** \returns the number of sub diagonals */
-    inline Index subs() const { return m_subs.value(); }
+    inline EIGEN_CONSTEXPR Index subs() const { return m_subs.value(); }
 
     inline const CoefficientsType& coeffs() const { return m_coeffs; }
     inline CoefficientsType& coeffs() { return m_coeffs; }
 
   protected:
 
     CoefficientsType m_coeffs;
@@ -271,24 +271,24 @@
         m_rows(rows), m_supers(supers), m_subs(subs)
     {
       EIGEN_UNUSED_VARIABLE(cols);
       //internal::assert(coeffs.cols()==cols() && (supers()+subs()+1)==coeffs.rows());
     }
 
     /** \returns the number of columns */
-    inline Index rows() const { return m_rows.value(); }
+    inline EIGEN_CONSTEXPR Index rows() const { return m_rows.value(); }
 
     /** \returns the number of rows */
-    inline Index cols() const { return m_coeffs.cols(); }
+    inline EIGEN_CONSTEXPR Index cols() const { return m_coeffs.cols(); }
 
     /** \returns the number of super diagonals */
-    inline Index supers() const { return m_supers.value(); }
+    inline EIGEN_CONSTEXPR Index supers() const { return m_supers.value(); }
 
     /** \returns the number of sub diagonals */
-    inline Index subs() const { return m_subs.value(); }
+    inline EIGEN_CONSTEXPR Index subs() const { return m_subs.value(); }
 
     inline const CoefficientsType& coeffs() const { return m_coeffs; }
 
   protected:
 
     const CoefficientsType& m_coeffs;
     internal::variable_if_dynamic<Index, _Rows>   m_rows;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Block.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Block.h`

 * *Files 3% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_BLOCK_H
 #define EIGEN_BLOCK_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 template<typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
 struct traits<Block<XprType, BlockRows, BlockCols, InnerPanel> > : traits<XprType>
 {
   typedef typename traits<XprType>::Scalar Scalar;
   typedef typename traits<XprType>::StorageKind StorageKind;
@@ -48,24 +48,24 @@
                              : int(inner_stride_at_compile_time<XprType>::ret),
 
     // FIXME, this traits is rather specialized for dense object and it needs to be cleaned further
     FlagsLvalueBit = is_lvalue<XprType>::value ? LvalueBit : 0,
     FlagsRowMajorBit = IsRowMajor ? RowMajorBit : 0,
     Flags = (traits<XprType>::Flags & (DirectAccessBit | (InnerPanel?CompressedAccessBit:0))) | FlagsLvalueBit | FlagsRowMajorBit,
     // FIXME DirectAccessBit should not be handled by expressions
-    // 
+    //
     // Alignment is needed by MapBase's assertions
     // We can sefely set it to false here. Internal alignment errors will be detected by an eigen_internal_assert in the respective evaluator
     Alignment = 0
   };
 };
 
 template<typename XprType, int BlockRows=Dynamic, int BlockCols=Dynamic, bool InnerPanel = false,
          bool HasDirectAccess = internal::has_direct_access<XprType>::ret> class BlockImpl_dense;
-         
+
 } // end namespace internal
 
 template<typename XprType, int BlockRows, int BlockCols, bool InnerPanel, typename StorageKind> class BlockImpl;
 
 /** \class Block
   * \ingroup Core_Module
   *
@@ -105,17 +105,17 @@
 {
     typedef BlockImpl<XprType, BlockRows, BlockCols, InnerPanel, typename internal::traits<XprType>::StorageKind> Impl;
   public:
     //typedef typename Impl::Base Base;
     typedef Impl Base;
     EIGEN_GENERIC_PUBLIC_INTERFACE(Block)
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Block)
-    
+
     typedef typename internal::remove_all<XprType>::type NestedExpression;
-  
+
     /** Column or Row constructor
       */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     Block(XprType& xpr, Index i) : Impl(xpr,i)
     {
       eigen_assert( (i>=0) && (
           ((BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) && i<xpr.rows())
@@ -143,15 +143,15 @@
     {
       eigen_assert((RowsAtCompileTime==Dynamic || RowsAtCompileTime==blockRows)
           && (ColsAtCompileTime==Dynamic || ColsAtCompileTime==blockCols));
       eigen_assert(startRow >= 0 && blockRows >= 0 && startRow  <= xpr.rows() - blockRows
           && startCol >= 0 && blockCols >= 0 && startCol <= xpr.cols() - blockCols);
     }
 };
-         
+
 // The generic default implementation for dense block simplu forward to the internal::BlockImpl_dense
 // that must be specialized for direct and non-direct access...
 template<typename XprType, int BlockRows, int BlockCols, bool InnerPanel>
 class BlockImpl<XprType, BlockRows, BlockCols, InnerPanel, Dense>
   : public internal::BlockImpl_dense<XprType, BlockRows, BlockCols, InnerPanel>
 {
     typedef internal::BlockImpl_dense<XprType, BlockRows, BlockCols, InnerPanel> Impl;
@@ -256,35 +256,35 @@
     inline const CoeffReturnType coeff(Index index) const
     {
       return m_xpr.coeff(m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
                          m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0));
     }
 
     template<int LoadMode>
-    inline PacketScalar packet(Index rowId, Index colId) const
+    EIGEN_DEVICE_FUNC inline PacketScalar packet(Index rowId, Index colId) const
     {
       return m_xpr.template packet<Unaligned>(rowId + m_startRow.value(), colId + m_startCol.value());
     }
 
     template<int LoadMode>
-    inline void writePacket(Index rowId, Index colId, const PacketScalar& val)
+    EIGEN_DEVICE_FUNC inline void writePacket(Index rowId, Index colId, const PacketScalar& val)
     {
       m_xpr.template writePacket<Unaligned>(rowId + m_startRow.value(), colId + m_startCol.value(), val);
     }
 
     template<int LoadMode>
-    inline PacketScalar packet(Index index) const
+    EIGEN_DEVICE_FUNC inline PacketScalar packet(Index index) const
     {
       return m_xpr.template packet<Unaligned>
               (m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
                m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0));
     }
 
     template<int LoadMode>
-    inline void writePacket(Index index, const PacketScalar& val)
+    EIGEN_DEVICE_FUNC inline void writePacket(Index index, const PacketScalar& val)
     {
       m_xpr.template writePacket<Unaligned>
          (m_startRow.value() + (RowsAtCompileTime == 1 ? 0 : index),
           m_startCol.value() + (RowsAtCompileTime == 1 ? index : 0), val);
     }
 
     #ifdef EIGEN_PARSED_BY_DOXYGEN
@@ -292,31 +292,31 @@
     EIGEN_DEVICE_FUNC inline const Scalar* data() const;
     EIGEN_DEVICE_FUNC inline Index innerStride() const;
     EIGEN_DEVICE_FUNC inline Index outerStride() const;
     #endif
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const typename internal::remove_all<XprTypeNested>::type& nestedExpression() const
-    { 
-      return m_xpr; 
+    {
+      return m_xpr;
     }
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     XprType& nestedExpression() { return m_xpr; }
-      
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    StorageIndex startRow() const
-    { 
-      return m_startRow.value(); 
+
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    StorageIndex startRow() const EIGEN_NOEXCEPT
+    {
+      return m_startRow.value();
     }
-      
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    StorageIndex startCol() const
-    { 
-      return m_startCol.value(); 
+
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    StorageIndex startCol() const EIGEN_NOEXCEPT
+    {
+      return m_startCol.value();
     }
 
   protected:
 
     XprTypeNested m_xpr;
     const internal::variable_if_dynamic<StorageIndex, (XprType::RowsAtCompileTime == 1 && BlockRows==1) ? 0 : Dynamic> m_startRow;
     const internal::variable_if_dynamic<StorageIndex, (XprType::ColsAtCompileTime == 1 && BlockCols==1) ? 0 : Dynamic> m_startCol;
@@ -340,15 +340,15 @@
     EIGEN_DENSE_PUBLIC_INTERFACE(BlockType)
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(BlockImpl_dense)
 
     /** Column or Row constructor
       */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     BlockImpl_dense(XprType& xpr, Index i)
-      : Base(xpr.data() + i * (    ((BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) && (!XprTypeIsRowMajor)) 
+      : Base(xpr.data() + i * (    ((BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) && (!XprTypeIsRowMajor))
                                 || ((BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) && ( XprTypeIsRowMajor)) ? xpr.innerStride() : xpr.outerStride()),
              BlockRows==1 ? 1 : xpr.rows(),
              BlockCols==1 ? 1 : xpr.cols()),
         m_xpr(xpr),
         m_startRow( (BlockRows==1) && (BlockCols==XprType::ColsAtCompileTime) ? i : 0),
         m_startCol( (BlockRows==XprType::RowsAtCompileTime) && (BlockCols==1) ? i : 0)
     {
@@ -374,49 +374,45 @@
       : Base(xpr.data()+xpr.innerStride()*(XprTypeIsRowMajor?startCol:startRow) + xpr.outerStride()*(XprTypeIsRowMajor?startRow:startCol), blockRows, blockCols),
         m_xpr(xpr), m_startRow(startRow), m_startCol(startCol)
     {
       init();
     }
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    const typename internal::remove_all<XprTypeNested>::type& nestedExpression() const
-    { 
-      return m_xpr; 
+    const typename internal::remove_all<XprTypeNested>::type& nestedExpression() const EIGEN_NOEXCEPT
+    {
+      return m_xpr;
     }
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     XprType& nestedExpression() { return m_xpr; }
-      
+
     /** \sa MapBase::innerStride() */
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index innerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index innerStride() const EIGEN_NOEXCEPT
     {
       return internal::traits<BlockType>::HasSameStorageOrderAsXprType
              ? m_xpr.innerStride()
              : m_xpr.outerStride();
     }
 
     /** \sa MapBase::outerStride() */
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index outerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index outerStride() const EIGEN_NOEXCEPT
     {
-      return m_outerStride;
+      return internal::traits<BlockType>::HasSameStorageOrderAsXprType
+                    ? m_xpr.outerStride()
+                    : m_xpr.innerStride();
     }
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    StorageIndex startRow() const
-    {
-      return m_startRow.value();
-    }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    StorageIndex startRow() const EIGEN_NOEXCEPT { return m_startRow.value(); }
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    StorageIndex startCol() const
-    {
-      return m_startCol.value();
-    }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    StorageIndex startCol() const EIGEN_NOEXCEPT { return m_startCol.value(); }
 
   #ifndef __SUNPRO_CC
   // FIXME sunstudio is not friendly with the above friend...
   // META-FIXME there is no 'friend' keyword around here. Is this obsolete?
   protected:
   #endif
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/BooleanRedux.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/BooleanRedux.h`

 * *Files 16% similar despite different names*

```diff
@@ -18,56 +18,56 @@
 struct all_unroller
 {
   enum {
     col = (UnrollCount-1) / Rows,
     row = (UnrollCount-1) % Rows
   };
 
-  static inline bool run(const Derived &mat)
+  EIGEN_DEVICE_FUNC static inline bool run(const Derived &mat)
   {
     return all_unroller<Derived, UnrollCount-1, Rows>::run(mat) && mat.coeff(row, col);
   }
 };
 
 template<typename Derived, int Rows>
 struct all_unroller<Derived, 0, Rows>
 {
-  static inline bool run(const Derived &/*mat*/) { return true; }
+  EIGEN_DEVICE_FUNC static inline bool run(const Derived &/*mat*/) { return true; }
 };
 
 template<typename Derived, int Rows>
 struct all_unroller<Derived, Dynamic, Rows>
 {
-  static inline bool run(const Derived &) { return false; }
+  EIGEN_DEVICE_FUNC static inline bool run(const Derived &) { return false; }
 };
 
 template<typename Derived, int UnrollCount, int Rows>
 struct any_unroller
 {
   enum {
     col = (UnrollCount-1) / Rows,
     row = (UnrollCount-1) % Rows
   };
   
-  static inline bool run(const Derived &mat)
+  EIGEN_DEVICE_FUNC static inline bool run(const Derived &mat)
   {
     return any_unroller<Derived, UnrollCount-1, Rows>::run(mat) || mat.coeff(row, col);
   }
 };
 
 template<typename Derived, int Rows>
 struct any_unroller<Derived, 0, Rows>
 {
-  static inline bool run(const Derived & /*mat*/) { return false; }
+  EIGEN_DEVICE_FUNC static inline bool run(const Derived & /*mat*/) { return false; }
 };
 
 template<typename Derived, int Rows>
 struct any_unroller<Derived, Dynamic, Rows>
 {
-  static inline bool run(const Derived &) { return false; }
+  EIGEN_DEVICE_FUNC static inline bool run(const Derived &) { return false; }
 };
 
 } // end namespace internal
 
 /** \returns true if all coefficients are true
   *
   * Example: \include MatrixBase_all.cpp
@@ -77,15 +77,15 @@
   */
 template<typename Derived>
 EIGEN_DEVICE_FUNC inline bool DenseBase<Derived>::all() const
 {
   typedef internal::evaluator<Derived> Evaluator;
   enum {
     unroll = SizeAtCompileTime != Dynamic
-          && SizeAtCompileTime * (Evaluator::CoeffReadCost + NumTraits<Scalar>::AddCost) <= EIGEN_UNROLLING_LIMIT
+          && SizeAtCompileTime * (int(Evaluator::CoeffReadCost) + int(NumTraits<Scalar>::AddCost)) <= EIGEN_UNROLLING_LIMIT
   };
   Evaluator evaluator(derived());
   if(unroll)
     return internal::all_unroller<Evaluator, unroll ? int(SizeAtCompileTime) : Dynamic, internal::traits<Derived>::RowsAtCompileTime>::run(evaluator);
   else
   {
     for(Index j = 0; j < cols(); ++j)
@@ -101,15 +101,15 @@
   */
 template<typename Derived>
 EIGEN_DEVICE_FUNC inline bool DenseBase<Derived>::any() const
 {
   typedef internal::evaluator<Derived> Evaluator;
   enum {
     unroll = SizeAtCompileTime != Dynamic
-          && SizeAtCompileTime * (Evaluator::CoeffReadCost + NumTraits<Scalar>::AddCost) <= EIGEN_UNROLLING_LIMIT
+          && SizeAtCompileTime * (int(Evaluator::CoeffReadCost) + int(NumTraits<Scalar>::AddCost)) <= EIGEN_UNROLLING_LIMIT
   };
   Evaluator evaluator(derived());
   if(unroll)
     return internal::any_unroller<Evaluator, unroll ? int(SizeAtCompileTime) : Dynamic, internal::traits<Derived>::RowsAtCompileTime>::run(evaluator);
   else
   {
     for(Index j = 0; j < cols(); ++j)
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CommaInitializer.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CommaInitializer.h`

 * *Files 5% similar despite different names*

```diff
@@ -29,22 +29,26 @@
 {
   typedef typename XprType::Scalar Scalar;
 
   EIGEN_DEVICE_FUNC
   inline CommaInitializer(XprType& xpr, const Scalar& s)
     : m_xpr(xpr), m_row(0), m_col(1), m_currentBlockRows(1)
   {
+    eigen_assert(m_xpr.rows() > 0 && m_xpr.cols() > 0
+      && "Cannot comma-initialize a 0x0 matrix (operator<<)");
     m_xpr.coeffRef(0,0) = s;
   }
 
   template<typename OtherDerived>
   EIGEN_DEVICE_FUNC
   inline CommaInitializer(XprType& xpr, const DenseBase<OtherDerived>& other)
     : m_xpr(xpr), m_row(0), m_col(other.cols()), m_currentBlockRows(other.rows())
   {
+    eigen_assert(m_xpr.rows() >= other.rows() && m_xpr.cols() >= other.cols()
+      && "Cannot comma-initialize a 0x0 matrix (operator<<)");
     m_xpr.block(0, 0, other.rows(), other.cols()) = other;
   }
 
   /* Copy/Move constructor which transfers ownership. This is crucial in 
    * absence of return value optimization to avoid assertions during destruction. */
   // FIXME in C++11 mode this could be replaced by a proper RValue constructor
   EIGEN_DEVICE_FUNC
@@ -99,15 +103,15 @@
 
   EIGEN_DEVICE_FUNC
   inline ~CommaInitializer()
 #if defined VERIFY_RAISES_ASSERT && (!defined EIGEN_NO_ASSERTION_CHECKING) && defined EIGEN_EXCEPTIONS
   EIGEN_EXCEPTION_SPEC(Eigen::eigen_assert_exception)
 #endif
   {
-      finished();
+    finished();
   }
 
   /** \returns the built matrix once all its coefficients have been set.
     * Calling finished is 100% optional. Its purpose is to write expressions
     * like this:
     * \code
     * quaternion.fromRotationMatrix((Matrix3f() << axis0, axis1, axis2).finished());
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ConditionEstimator.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ConditionEstimator.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CoreEvaluators.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CoreEvaluators.h`

 * *Files 2% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 
 #ifndef EIGEN_COREEVALUATORS_H
 #define EIGEN_COREEVALUATORS_H
 
 namespace Eigen {
-  
+
 namespace internal {
 
 // This class returns the evaluator kind from the expression storage kind.
 // Default assumes index based accessors
 template<typename StorageKind>
 struct storage_kind_to_evaluator_kind {
   typedef IndexBased Kind;
@@ -59,16 +59,16 @@
           typename RhsKind   = typename evaluator_traits<typename T::Rhs>::Kind,
           typename LhsScalar = typename traits<typename T::Lhs>::Scalar,
           typename RhsScalar = typename traits<typename T::Rhs>::Scalar> struct binary_evaluator;
 
 template< typename T,
           typename Kind   = typename evaluator_traits<typename T::NestedExpression>::Kind,
           typename Scalar = typename T::Scalar> struct unary_evaluator;
-          
-// evaluator_traits<T> contains traits for evaluator<T> 
+
+// evaluator_traits<T> contains traits for evaluator<T>
 
 template<typename T>
 struct evaluator_traits_base
 {
   // by default, get evaluator kind and shape from storage
   typedef typename storage_kind_to_evaluator_kind<typename traits<T>::StorageKind>::Kind Kind;
   typedef typename storage_kind_to_shape<typename traits<T>::StorageKind>::Shape Shape;
@@ -107,15 +107,15 @@
 // ---------- base class for all evaluators ----------
 
 template<typename ExpressionType>
 struct evaluator_base
 {
   // TODO that's not very nice to have to propagate all these traits. They are currently only needed to handle outer,inner indices.
   typedef traits<ExpressionType> ExpressionTraits;
-  
+
   enum {
     Alignment = 0
   };
   // noncopyable:
   // Don't make this class inherit noncopyable as this kills EBO (Empty Base Optimization)
   // and make complex evaluator much larger than then should do.
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE evaluator_base() {}
@@ -139,16 +139,16 @@
   plainobjectbase_evaluator_data(const Scalar* ptr, Index outerStride) : data(ptr)
   {
 #ifndef EIGEN_INTERNAL_DEBUGGING
     EIGEN_UNUSED_VARIABLE(outerStride);
 #endif
     eigen_internal_assert(outerStride==OuterStride);
   }
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-  Index outerStride() const { return OuterStride; }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+  Index outerStride() const EIGEN_NOEXCEPT { return OuterStride; }
   const Scalar *data;
 };
 
 template<typename Scalar> class plainobjectbase_evaluator_data<Scalar,Dynamic> {
 public:
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   plainobjectbase_evaluator_data(const Scalar* ptr, Index outerStride) : data(ptr), m_outerStride(outerStride) {}
@@ -168,15 +168,15 @@
   typedef typename PlainObjectType::CoeffReturnType CoeffReturnType;
 
   enum {
     IsRowMajor = PlainObjectType::IsRowMajor,
     IsVectorAtCompileTime = PlainObjectType::IsVectorAtCompileTime,
     RowsAtCompileTime = PlainObjectType::RowsAtCompileTime,
     ColsAtCompileTime = PlainObjectType::ColsAtCompileTime,
-    
+
     CoeffReadCost = NumTraits<Scalar>::ReadCost,
     Flags = traits<Derived>::EvaluatorFlags,
     Alignment = traits<Derived>::Alignment
   };
   enum {
     // We do not need to know the outer stride for vectors
     OuterStrideAtCompileTime = IsVectorAtCompileTime  ? 0
@@ -270,49 +270,49 @@
 };
 
 template<typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
 struct evaluator<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols> >
   : evaluator<PlainObjectBase<Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols> > >
 {
   typedef Matrix<Scalar, Rows, Cols, Options, MaxRows, MaxCols> XprType;
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   evaluator() {}
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& m)
-    : evaluator<PlainObjectBase<XprType> >(m) 
+    : evaluator<PlainObjectBase<XprType> >(m)
   { }
 };
 
 template<typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
 struct evaluator<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> >
   : evaluator<PlainObjectBase<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> > >
 {
   typedef Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> XprType;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   evaluator() {}
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& m)
-    : evaluator<PlainObjectBase<XprType> >(m) 
+    : evaluator<PlainObjectBase<XprType> >(m)
   { }
 };
 
 // -------------------- Transpose --------------------
 
 template<typename ArgType>
 struct unary_evaluator<Transpose<ArgType>, IndexBased>
   : evaluator_base<Transpose<ArgType> >
 {
   typedef Transpose<ArgType> XprType;
-  
+
   enum {
-    CoeffReadCost = evaluator<ArgType>::CoeffReadCost,    
+    CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
     Flags = evaluator<ArgType>::Flags ^ RowMajorBit,
     Alignment = evaluator<ArgType>::Alignment
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit unary_evaluator(const XprType& t) : m_argImpl(t.nestedExpression()) {}
 
@@ -495,18 +495,18 @@
 
 template<typename NullaryOp, typename PlainObjectType>
 struct evaluator<CwiseNullaryOp<NullaryOp,PlainObjectType> >
   : evaluator_base<CwiseNullaryOp<NullaryOp,PlainObjectType> >
 {
   typedef CwiseNullaryOp<NullaryOp,PlainObjectType> XprType;
   typedef typename internal::remove_all<PlainObjectType>::type PlainObjectTypeCleaned;
-  
+
   enum {
     CoeffReadCost = internal::functor_traits<NullaryOp>::Cost,
-    
+
     Flags = (evaluator<PlainObjectTypeCleaned>::Flags
           &  (  HereditaryBits
               | (functor_has_linear_access<NullaryOp>::ret  ? LinearAccessBit : 0)
               | (functor_traits<NullaryOp>::PacketAccess    ? PacketAccessBit : 0)))
           | (functor_traits<NullaryOp>::IsRepeatable ? 0 : EvalBeforeNestingBit),
     Alignment = AlignedMax
   };
@@ -555,18 +555,18 @@
 // -------------------- CwiseUnaryOp --------------------
 
 template<typename UnaryOp, typename ArgType>
 struct unary_evaluator<CwiseUnaryOp<UnaryOp, ArgType>, IndexBased >
   : evaluator_base<CwiseUnaryOp<UnaryOp, ArgType> >
 {
   typedef CwiseUnaryOp<UnaryOp, ArgType> XprType;
-  
+
   enum {
-    CoeffReadCost = evaluator<ArgType>::CoeffReadCost + functor_traits<UnaryOp>::Cost,
-    
+    CoeffReadCost = int(evaluator<ArgType>::CoeffReadCost) + int(functor_traits<UnaryOp>::Cost),
+
     Flags = evaluator<ArgType>::Flags
           & (HereditaryBits | LinearAccessBit | (functor_traits<UnaryOp>::PacketAccess ? PacketAccessBit : 0)),
     Alignment = evaluator<ArgType>::Alignment
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit unary_evaluator(const XprType& op) : m_d(op)
@@ -602,21 +602,21 @@
   {
     return m_d.func().packetOp(m_d.argImpl.template packet<LoadMode, PacketType>(index));
   }
 
 protected:
 
   // this helper permits to completely eliminate the functor if it is empty
-  class Data : private UnaryOp
+  struct Data
   {
-  public:
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Data(const XprType& xpr) : UnaryOp(xpr.functor()), argImpl(xpr.nestedExpression()) {}
+    Data(const XprType& xpr) : op(xpr.functor()), argImpl(xpr.nestedExpression()) {}
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    const UnaryOp& func() const { return static_cast<const UnaryOp&>(*this); }
+    const UnaryOp& func() const { return op; }
+    UnaryOp op;
     evaluator<ArgType> argImpl;
   };
 
   Data m_d;
 };
 
 // -------------------- CwiseTernaryOp --------------------
@@ -624,27 +624,27 @@
 // this is a ternary expression
 template<typename TernaryOp, typename Arg1, typename Arg2, typename Arg3>
 struct evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> >
   : public ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> >
 {
   typedef CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> XprType;
   typedef ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> > Base;
-  
+
   EIGEN_DEVICE_FUNC explicit evaluator(const XprType& xpr) : Base(xpr) {}
 };
 
 template<typename TernaryOp, typename Arg1, typename Arg2, typename Arg3>
 struct ternary_evaluator<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3>, IndexBased, IndexBased>
   : evaluator_base<CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> >
 {
   typedef CwiseTernaryOp<TernaryOp, Arg1, Arg2, Arg3> XprType;
-  
+
   enum {
-    CoeffReadCost = evaluator<Arg1>::CoeffReadCost + evaluator<Arg2>::CoeffReadCost + evaluator<Arg3>::CoeffReadCost + functor_traits<TernaryOp>::Cost,
-    
+    CoeffReadCost = int(evaluator<Arg1>::CoeffReadCost) + int(evaluator<Arg2>::CoeffReadCost) + int(evaluator<Arg3>::CoeffReadCost) + int(functor_traits<TernaryOp>::Cost),
+
     Arg1Flags = evaluator<Arg1>::Flags,
     Arg2Flags = evaluator<Arg2>::Flags,
     Arg3Flags = evaluator<Arg3>::Flags,
     SameType = is_same<typename Arg1::Scalar,typename Arg2::Scalar>::value && is_same<typename Arg1::Scalar,typename Arg3::Scalar>::value,
     StorageOrdersAgree = (int(Arg1Flags)&RowMajorBit)==(int(Arg2Flags)&RowMajorBit) && (int(Arg1Flags)&RowMajorBit)==(int(Arg3Flags)&RowMajorBit),
     Flags0 = (int(Arg1Flags) | int(Arg2Flags) | int(Arg3Flags)) & (
         HereditaryBits
@@ -696,20 +696,21 @@
     return m_d.func().packetOp(m_d.arg1Impl.template packet<LoadMode,PacketType>(index),
                                m_d.arg2Impl.template packet<LoadMode,PacketType>(index),
                                m_d.arg3Impl.template packet<LoadMode,PacketType>(index));
   }
 
 protected:
   // this helper permits to completely eliminate the functor if it is empty
-  struct Data : private TernaryOp
+  struct Data
   {
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Data(const XprType& xpr) : TernaryOp(xpr.functor()), arg1Impl(xpr.arg1()), arg2Impl(xpr.arg2()), arg3Impl(xpr.arg3()) {}
+    Data(const XprType& xpr) : op(xpr.functor()), arg1Impl(xpr.arg1()), arg2Impl(xpr.arg2()), arg3Impl(xpr.arg3()) {}
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    const TernaryOp& func() const { return static_cast<const TernaryOp&>(*this); }
+    const TernaryOp& func() const { return op; }
+    TernaryOp op;
     evaluator<Arg1> arg1Impl;
     evaluator<Arg2> arg2Impl;
     evaluator<Arg3> arg3Impl;
   };
 
   Data m_d;
 };
@@ -719,28 +720,28 @@
 // this is a binary expression
 template<typename BinaryOp, typename Lhs, typename Rhs>
 struct evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs> >
   : public binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs> >
 {
   typedef CwiseBinaryOp<BinaryOp, Lhs, Rhs> XprType;
   typedef binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs> > Base;
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& xpr) : Base(xpr) {}
 };
 
 template<typename BinaryOp, typename Lhs, typename Rhs>
 struct binary_evaluator<CwiseBinaryOp<BinaryOp, Lhs, Rhs>, IndexBased, IndexBased>
   : evaluator_base<CwiseBinaryOp<BinaryOp, Lhs, Rhs> >
 {
   typedef CwiseBinaryOp<BinaryOp, Lhs, Rhs> XprType;
-  
+
   enum {
-    CoeffReadCost = evaluator<Lhs>::CoeffReadCost + evaluator<Rhs>::CoeffReadCost + functor_traits<BinaryOp>::Cost,
-    
+    CoeffReadCost = int(evaluator<Lhs>::CoeffReadCost) + int(evaluator<Rhs>::CoeffReadCost) + int(functor_traits<BinaryOp>::Cost),
+
     LhsFlags = evaluator<Lhs>::Flags,
     RhsFlags = evaluator<Rhs>::Flags,
     SameType = is_same<typename Lhs::Scalar,typename Rhs::Scalar>::value,
     StorageOrdersAgree = (int(LhsFlags)&RowMajorBit)==(int(RhsFlags)&RowMajorBit),
     Flags0 = (int(LhsFlags) | int(RhsFlags)) & (
         HereditaryBits
       | (int(LhsFlags) & int(RhsFlags) &
@@ -789,40 +790,41 @@
     return m_d.func().packetOp(m_d.lhsImpl.template packet<LoadMode,PacketType>(index),
                                m_d.rhsImpl.template packet<LoadMode,PacketType>(index));
   }
 
 protected:
 
   // this helper permits to completely eliminate the functor if it is empty
-  struct Data : private BinaryOp
+  struct Data
   {
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Data(const XprType& xpr) : BinaryOp(xpr.functor()), lhsImpl(xpr.lhs()), rhsImpl(xpr.rhs()) {}
+    Data(const XprType& xpr) : op(xpr.functor()), lhsImpl(xpr.lhs()), rhsImpl(xpr.rhs()) {}
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    const BinaryOp& func() const { return static_cast<const BinaryOp&>(*this); }
+    const BinaryOp& func() const { return op; }
+    BinaryOp op;
     evaluator<Lhs> lhsImpl;
     evaluator<Rhs> rhsImpl;
   };
 
   Data m_d;
 };
 
 // -------------------- CwiseUnaryView --------------------
 
 template<typename UnaryOp, typename ArgType>
 struct unary_evaluator<CwiseUnaryView<UnaryOp, ArgType>, IndexBased>
   : evaluator_base<CwiseUnaryView<UnaryOp, ArgType> >
 {
   typedef CwiseUnaryView<UnaryOp, ArgType> XprType;
-  
+
   enum {
-    CoeffReadCost = evaluator<ArgType>::CoeffReadCost + functor_traits<UnaryOp>::Cost,
-    
+    CoeffReadCost = int(evaluator<ArgType>::CoeffReadCost) + int(functor_traits<UnaryOp>::Cost),
+
     Flags = (evaluator<ArgType>::Flags & (HereditaryBits | LinearAccessBit | DirectAccessBit)),
-    
+
     Alignment = 0 // FIXME it is not very clear why alignment is necessarily lost...
   };
 
   EIGEN_DEVICE_FUNC explicit unary_evaluator(const XprType& op) : m_d(op)
   {
     EIGEN_INTERNAL_CHECK_COST_VALUE(functor_traits<UnaryOp>::Cost);
     EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
@@ -854,20 +856,21 @@
   {
     return m_d.func()(m_d.argImpl.coeffRef(index));
   }
 
 protected:
 
   // this helper permits to completely eliminate the functor if it is empty
-  struct Data : private UnaryOp
+  struct Data
   {
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Data(const XprType& xpr) : UnaryOp(xpr.functor()), argImpl(xpr.nestedExpression()) {}
+    Data(const XprType& xpr) : op(xpr.functor()), argImpl(xpr.nestedExpression()) {}
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    const UnaryOp& func() const { return static_cast<const UnaryOp&>(*this); }
+    const UnaryOp& func() const { return op; }
+    UnaryOp op;
     evaluator<ArgType> argImpl;
   };
 
   Data m_d;
 };
 
 // -------------------- Map --------------------
@@ -880,15 +883,15 @@
 template<typename Derived, typename PlainObjectType>
 struct mapbase_evaluator : evaluator_base<Derived>
 {
   typedef Derived  XprType;
   typedef typename XprType::PointerType PointerType;
   typedef typename XprType::Scalar Scalar;
   typedef typename XprType::CoeffReturnType CoeffReturnType;
-  
+
   enum {
     IsRowMajor = XprType::RowsAtCompileTime,
     ColsAtCompileTime = XprType::ColsAtCompileTime,
     CoeffReadCost = NumTraits<Scalar>::ReadCost
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
@@ -952,119 +955,123 @@
   template<int StoreMode, typename PacketType>
   EIGEN_STRONG_INLINE
   void writePacket(Index index, const PacketType& x)
   {
     internal::pstoret<Scalar, PacketType, StoreMode>(m_data + index * m_innerStride.value(), x);
   }
 protected:
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-  Index rowStride() const { return XprType::IsRowMajor ? m_outerStride.value() : m_innerStride.value(); }
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-  Index colStride() const { return XprType::IsRowMajor ? m_innerStride.value() : m_outerStride.value(); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+  Index rowStride() const EIGEN_NOEXCEPT {
+    return XprType::IsRowMajor ? m_outerStride.value() : m_innerStride.value();
+  }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+  Index colStride() const EIGEN_NOEXCEPT {
+     return XprType::IsRowMajor ? m_innerStride.value() : m_outerStride.value();
+  }
 
   PointerType m_data;
   const internal::variable_if_dynamic<Index, XprType::InnerStrideAtCompileTime> m_innerStride;
   const internal::variable_if_dynamic<Index, XprType::OuterStrideAtCompileTime> m_outerStride;
 };
 
-template<typename PlainObjectType, int MapOptions, typename StrideType> 
+template<typename PlainObjectType, int MapOptions, typename StrideType>
 struct evaluator<Map<PlainObjectType, MapOptions, StrideType> >
   : public mapbase_evaluator<Map<PlainObjectType, MapOptions, StrideType>, PlainObjectType>
 {
   typedef Map<PlainObjectType, MapOptions, StrideType> XprType;
   typedef typename XprType::Scalar Scalar;
   // TODO: should check for smaller packet types once we can handle multi-sized packet types
   typedef typename packet_traits<Scalar>::type PacketScalar;
-  
+
   enum {
     InnerStrideAtCompileTime = StrideType::InnerStrideAtCompileTime == 0
                              ? int(PlainObjectType::InnerStrideAtCompileTime)
                              : int(StrideType::InnerStrideAtCompileTime),
     OuterStrideAtCompileTime = StrideType::OuterStrideAtCompileTime == 0
                              ? int(PlainObjectType::OuterStrideAtCompileTime)
                              : int(StrideType::OuterStrideAtCompileTime),
     HasNoInnerStride = InnerStrideAtCompileTime == 1,
     HasNoOuterStride = StrideType::OuterStrideAtCompileTime == 0,
     HasNoStride = HasNoInnerStride && HasNoOuterStride,
     IsDynamicSize = PlainObjectType::SizeAtCompileTime==Dynamic,
-    
+
     PacketAccessMask = bool(HasNoInnerStride) ? ~int(0) : ~int(PacketAccessBit),
     LinearAccessMask = bool(HasNoStride) || bool(PlainObjectType::IsVectorAtCompileTime) ? ~int(0) : ~int(LinearAccessBit),
     Flags = int( evaluator<PlainObjectType>::Flags) & (LinearAccessMask&PacketAccessMask),
-    
+
     Alignment = int(MapOptions)&int(AlignedMask)
   };
 
   EIGEN_DEVICE_FUNC explicit evaluator(const XprType& map)
-    : mapbase_evaluator<XprType, PlainObjectType>(map) 
+    : mapbase_evaluator<XprType, PlainObjectType>(map)
   { }
 };
 
 // -------------------- Ref --------------------
 
-template<typename PlainObjectType, int RefOptions, typename StrideType> 
+template<typename PlainObjectType, int RefOptions, typename StrideType>
 struct evaluator<Ref<PlainObjectType, RefOptions, StrideType> >
   : public mapbase_evaluator<Ref<PlainObjectType, RefOptions, StrideType>, PlainObjectType>
 {
   typedef Ref<PlainObjectType, RefOptions, StrideType> XprType;
-  
+
   enum {
     Flags = evaluator<Map<PlainObjectType, RefOptions, StrideType> >::Flags,
     Alignment = evaluator<Map<PlainObjectType, RefOptions, StrideType> >::Alignment
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& ref)
-    : mapbase_evaluator<XprType, PlainObjectType>(ref) 
+    : mapbase_evaluator<XprType, PlainObjectType>(ref)
   { }
 };
 
 // -------------------- Block --------------------
 
 template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel,
          bool HasDirectAccess = internal::has_direct_access<ArgType>::ret> struct block_evaluator;
-         
-template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel> 
+
+template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 struct evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel> >
   : block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel>
 {
   typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
   typedef typename XprType::Scalar Scalar;
   // TODO: should check for smaller packet types once we can handle multi-sized packet types
   typedef typename packet_traits<Scalar>::type PacketScalar;
-  
+
   enum {
     CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
-    
+
     RowsAtCompileTime = traits<XprType>::RowsAtCompileTime,
     ColsAtCompileTime = traits<XprType>::ColsAtCompileTime,
     MaxRowsAtCompileTime = traits<XprType>::MaxRowsAtCompileTime,
     MaxColsAtCompileTime = traits<XprType>::MaxColsAtCompileTime,
-    
+
     ArgTypeIsRowMajor = (int(evaluator<ArgType>::Flags)&RowMajorBit) != 0,
     IsRowMajor = (MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1) ? 1
                : (MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1) ? 0
                : ArgTypeIsRowMajor,
     HasSameStorageOrderAsArgType = (IsRowMajor == ArgTypeIsRowMajor),
     InnerSize = IsRowMajor ? int(ColsAtCompileTime) : int(RowsAtCompileTime),
     InnerStrideAtCompileTime = HasSameStorageOrderAsArgType
                              ? int(inner_stride_at_compile_time<ArgType>::ret)
                              : int(outer_stride_at_compile_time<ArgType>::ret),
     OuterStrideAtCompileTime = HasSameStorageOrderAsArgType
                              ? int(outer_stride_at_compile_time<ArgType>::ret)
                              : int(inner_stride_at_compile_time<ArgType>::ret),
     MaskPacketAccessBit = (InnerStrideAtCompileTime == 1 || HasSameStorageOrderAsArgType) ? PacketAccessBit : 0,
-    
-    FlagsLinearAccessBit = (RowsAtCompileTime == 1 || ColsAtCompileTime == 1 || (InnerPanel && (evaluator<ArgType>::Flags&LinearAccessBit))) ? LinearAccessBit : 0,    
+
+    FlagsLinearAccessBit = (RowsAtCompileTime == 1 || ColsAtCompileTime == 1 || (InnerPanel && (evaluator<ArgType>::Flags&LinearAccessBit))) ? LinearAccessBit : 0,
     FlagsRowMajorBit = XprType::Flags&RowMajorBit,
     Flags0 = evaluator<ArgType>::Flags & ( (HereditaryBits & ~RowMajorBit) |
                                            DirectAccessBit |
                                            MaskPacketAccessBit),
     Flags = Flags0 | FlagsLinearAccessBit | FlagsRowMajorBit,
-    
+
     PacketAlignment = unpacket_traits<PacketScalar>::alignment,
     Alignment0 = (InnerPanel && (OuterStrideAtCompileTime!=Dynamic)
                              && (OuterStrideAtCompileTime!=0)
                              && (((OuterStrideAtCompileTime * int(sizeof(Scalar))) % int(PacketAlignment)) == 0)) ? int(PacketAlignment) : 0,
     Alignment = EIGEN_PLAIN_ENUM_MIN(evaluator<ArgType>::Alignment, Alignment0)
   };
   typedef block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel> block_evaluator_type;
@@ -1080,128 +1087,144 @@
 struct block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel, /*HasDirectAccess*/ false>
   : unary_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel> >
 {
   typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit block_evaluator(const XprType& block)
-    : unary_evaluator<XprType>(block) 
+    : unary_evaluator<XprType>(block)
   {}
 };
 
 template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 struct unary_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>, IndexBased>
   : evaluator_base<Block<ArgType, BlockRows, BlockCols, InnerPanel> >
 {
   typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit unary_evaluator(const XprType& block)
-    : m_argImpl(block.nestedExpression()), 
-      m_startRow(block.startRow()), 
+    : m_argImpl(block.nestedExpression()),
+      m_startRow(block.startRow()),
       m_startCol(block.startCol()),
       m_linear_offset(ForwardLinearAccess?(ArgType::IsRowMajor ? block.startRow()*block.nestedExpression().cols() + block.startCol() : block.startCol()*block.nestedExpression().rows() + block.startRow()):0)
   { }
- 
+
   typedef typename XprType::Scalar Scalar;
   typedef typename XprType::CoeffReturnType CoeffReturnType;
 
   enum {
     RowsAtCompileTime = XprType::RowsAtCompileTime,
     ForwardLinearAccess = (InnerPanel || int(XprType::IsRowMajor)==int(ArgType::IsRowMajor)) && bool(evaluator<ArgType>::Flags&LinearAccessBit)
   };
- 
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index row, Index col) const
-  { 
-    return m_argImpl.coeff(m_startRow.value() + row, m_startCol.value() + col); 
+  {
+    return m_argImpl.coeff(m_startRow.value() + row, m_startCol.value() + col);
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index index) const
-  { 
-    if (ForwardLinearAccess)
-      return m_argImpl.coeff(m_linear_offset.value() + index); 
-    else
-      return coeff(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
+  {
+    return linear_coeff_impl(index, bool_constant<ForwardLinearAccess>());
   }
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   Scalar& coeffRef(Index row, Index col)
-  { 
-    return m_argImpl.coeffRef(m_startRow.value() + row, m_startCol.value() + col); 
+  {
+    return m_argImpl.coeffRef(m_startRow.value() + row, m_startCol.value() + col);
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   Scalar& coeffRef(Index index)
-  { 
-    if (ForwardLinearAccess)
-      return m_argImpl.coeffRef(m_linear_offset.value() + index); 
-    else
-      return coeffRef(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
+  {
+    return linear_coeffRef_impl(index, bool_constant<ForwardLinearAccess>());
   }
- 
+
   template<int LoadMode, typename PacketType>
   EIGEN_STRONG_INLINE
-  PacketType packet(Index row, Index col) const 
-  { 
-    return m_argImpl.template packet<LoadMode,PacketType>(m_startRow.value() + row, m_startCol.value() + col); 
+  PacketType packet(Index row, Index col) const
+  {
+    return m_argImpl.template packet<LoadMode,PacketType>(m_startRow.value() + row, m_startCol.value() + col);
   }
 
   template<int LoadMode, typename PacketType>
   EIGEN_STRONG_INLINE
-  PacketType packet(Index index) const 
-  { 
+  PacketType packet(Index index) const
+  {
     if (ForwardLinearAccess)
       return m_argImpl.template packet<LoadMode,PacketType>(m_linear_offset.value() + index);
     else
       return packet<LoadMode,PacketType>(RowsAtCompileTime == 1 ? 0 : index,
                                          RowsAtCompileTime == 1 ? index : 0);
   }
-  
+
   template<int StoreMode, typename PacketType>
   EIGEN_STRONG_INLINE
-  void writePacket(Index row, Index col, const PacketType& x) 
+  void writePacket(Index row, Index col, const PacketType& x)
   {
-    return m_argImpl.template writePacket<StoreMode,PacketType>(m_startRow.value() + row, m_startCol.value() + col, x); 
+    return m_argImpl.template writePacket<StoreMode,PacketType>(m_startRow.value() + row, m_startCol.value() + col, x);
   }
-  
+
   template<int StoreMode, typename PacketType>
   EIGEN_STRONG_INLINE
-  void writePacket(Index index, const PacketType& x) 
+  void writePacket(Index index, const PacketType& x)
   {
     if (ForwardLinearAccess)
       return m_argImpl.template writePacket<StoreMode,PacketType>(m_linear_offset.value() + index, x);
     else
       return writePacket<StoreMode,PacketType>(RowsAtCompileTime == 1 ? 0 : index,
                                               RowsAtCompileTime == 1 ? index : 0,
                                               x);
   }
- 
+
 protected:
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+  CoeffReturnType linear_coeff_impl(Index index, internal::true_type /* ForwardLinearAccess */) const
+  {
+    return m_argImpl.coeff(m_linear_offset.value() + index);
+  }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+  CoeffReturnType linear_coeff_impl(Index index, internal::false_type /* not ForwardLinearAccess */) const
+  {
+    return coeff(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
+  }
+
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+  Scalar& linear_coeffRef_impl(Index index, internal::true_type /* ForwardLinearAccess */)
+  {
+    return m_argImpl.coeffRef(m_linear_offset.value() + index);
+  }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+  Scalar& linear_coeffRef_impl(Index index, internal::false_type /* not ForwardLinearAccess */)
+  {
+    return coeffRef(RowsAtCompileTime == 1 ? 0 : index, RowsAtCompileTime == 1 ? index : 0);
+  }
+
   evaluator<ArgType> m_argImpl;
   const variable_if_dynamic<Index, (ArgType::RowsAtCompileTime == 1 && BlockRows==1) ? 0 : Dynamic> m_startRow;
   const variable_if_dynamic<Index, (ArgType::ColsAtCompileTime == 1 && BlockCols==1) ? 0 : Dynamic> m_startCol;
   const variable_if_dynamic<Index, ForwardLinearAccess ? Dynamic : 0> m_linear_offset;
 };
 
-// TODO: This evaluator does not actually use the child evaluator; 
+// TODO: This evaluator does not actually use the child evaluator;
 // all action is via the data() as returned by the Block expression.
 
-template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel> 
+template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 struct block_evaluator<ArgType, BlockRows, BlockCols, InnerPanel, /* HasDirectAccess */ true>
   : mapbase_evaluator<Block<ArgType, BlockRows, BlockCols, InnerPanel>,
                       typename Block<ArgType, BlockRows, BlockCols, InnerPanel>::PlainObject>
 {
   typedef Block<ArgType, BlockRows, BlockCols, InnerPanel> XprType;
   typedef typename XprType::Scalar Scalar;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit block_evaluator(const XprType& block)
-    : mapbase_evaluator<XprType, typename XprType::PlainObject>(block) 
+    : mapbase_evaluator<XprType, typename XprType::PlainObject>(block)
   {
     // TODO: for the 3.3 release, this should be turned to an internal assertion, but let's keep it as is for the beta lifetime
     eigen_assert(((internal::UIntPtr(block.data()) % EIGEN_PLAIN_ENUM_MAX(1,evaluator<XprType>::Alignment)) == 0) && "data is not aligned");
   }
 };
 
 
@@ -1216,27 +1239,27 @@
   typedef Select<ConditionMatrixType, ThenMatrixType, ElseMatrixType> XprType;
   enum {
     CoeffReadCost = evaluator<ConditionMatrixType>::CoeffReadCost
                   + EIGEN_PLAIN_ENUM_MAX(evaluator<ThenMatrixType>::CoeffReadCost,
                                          evaluator<ElseMatrixType>::CoeffReadCost),
 
     Flags = (unsigned int)evaluator<ThenMatrixType>::Flags & evaluator<ElseMatrixType>::Flags & HereditaryBits,
-    
+
     Alignment = EIGEN_PLAIN_ENUM_MIN(evaluator<ThenMatrixType>::Alignment, evaluator<ElseMatrixType>::Alignment)
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& select)
     : m_conditionImpl(select.conditionMatrix()),
       m_thenImpl(select.thenMatrix()),
       m_elseImpl(select.elseMatrix())
   {
     EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
   }
- 
+
   typedef typename XprType::CoeffReturnType CoeffReturnType;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index row, Index col) const
   {
     if (m_conditionImpl.coeff(row, col))
       return m_thenImpl.coeff(row, col);
@@ -1248,74 +1271,74 @@
   CoeffReturnType coeff(Index index) const
   {
     if (m_conditionImpl.coeff(index))
       return m_thenImpl.coeff(index);
     else
       return m_elseImpl.coeff(index);
   }
- 
+
 protected:
   evaluator<ConditionMatrixType> m_conditionImpl;
   evaluator<ThenMatrixType> m_thenImpl;
   evaluator<ElseMatrixType> m_elseImpl;
 };
 
 
 // -------------------- Replicate --------------------
 
-template<typename ArgType, int RowFactor, int ColFactor> 
+template<typename ArgType, int RowFactor, int ColFactor>
 struct unary_evaluator<Replicate<ArgType, RowFactor, ColFactor> >
   : evaluator_base<Replicate<ArgType, RowFactor, ColFactor> >
 {
   typedef Replicate<ArgType, RowFactor, ColFactor> XprType;
   typedef typename XprType::CoeffReturnType CoeffReturnType;
   enum {
     Factor = (RowFactor==Dynamic || ColFactor==Dynamic) ? Dynamic : RowFactor*ColFactor
   };
   typedef typename internal::nested_eval<ArgType,Factor>::type ArgTypeNested;
   typedef typename internal::remove_all<ArgTypeNested>::type ArgTypeNestedCleaned;
-  
+
   enum {
     CoeffReadCost = evaluator<ArgTypeNestedCleaned>::CoeffReadCost,
     LinearAccessMask = XprType::IsVectorAtCompileTime ? LinearAccessBit : 0,
     Flags = (evaluator<ArgTypeNestedCleaned>::Flags & (HereditaryBits|LinearAccessMask) & ~RowMajorBit) | (traits<XprType>::Flags & RowMajorBit),
-    
+
     Alignment = evaluator<ArgTypeNestedCleaned>::Alignment
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit unary_evaluator(const XprType& replicate)
     : m_arg(replicate.nestedExpression()),
       m_argImpl(m_arg),
       m_rows(replicate.nestedExpression().rows()),
       m_cols(replicate.nestedExpression().cols())
   {}
- 
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index row, Index col) const
   {
     // try to avoid using modulo; this is a pure optimization strategy
     const Index actual_row = internal::traits<XprType>::RowsAtCompileTime==1 ? 0
                            : RowFactor==1 ? row
                            : row % m_rows.value();
     const Index actual_col = internal::traits<XprType>::ColsAtCompileTime==1 ? 0
                            : ColFactor==1 ? col
                            : col % m_cols.value();
-    
+
     return m_argImpl.coeff(actual_row, actual_col);
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index index) const
   {
     // try to avoid using modulo; this is a pure optimization strategy
     const Index actual_index = internal::traits<XprType>::RowsAtCompileTime==1
                                   ? (ColFactor==1 ?  index : index%m_cols.value())
                                   : (RowFactor==1 ?  index : index%m_rows.value());
-    
+
     return m_argImpl.coeff(actual_index);
   }
 
   template<int LoadMode, typename PacketType>
   EIGEN_STRONG_INLINE
   PacketType packet(Index row, Index col) const
   {
@@ -1324,26 +1347,26 @@
                            : row % m_rows.value();
     const Index actual_col = internal::traits<XprType>::ColsAtCompileTime==1 ? 0
                            : ColFactor==1 ? col
                            : col % m_cols.value();
 
     return m_argImpl.template packet<LoadMode,PacketType>(actual_row, actual_col);
   }
-  
+
   template<int LoadMode, typename PacketType>
   EIGEN_STRONG_INLINE
   PacketType packet(Index index) const
   {
     const Index actual_index = internal::traits<XprType>::RowsAtCompileTime==1
                                   ? (ColFactor==1 ?  index : index%m_cols.value())
                                   : (RowFactor==1 ?  index : index%m_rows.value());
 
     return m_argImpl.template packet<LoadMode,PacketType>(actual_index);
   }
- 
+
 protected:
   const ArgTypeNested m_arg;
   evaluator<ArgTypeNestedCleaned> m_argImpl;
   const variable_if_dynamic<Index, ArgType::RowsAtCompileTime> m_rows;
   const variable_if_dynamic<Index, ArgType::ColsAtCompileTime> m_cols;
 };
 
@@ -1467,36 +1490,36 @@
     IsRowMajor = XprType::IsRowMajor,
     IsColMajor = !IsRowMajor,
     ReverseRow = (Direction == Vertical)   || (Direction == BothDirections),
     ReverseCol = (Direction == Horizontal) || (Direction == BothDirections),
     ReversePacket = (Direction == BothDirections)
                     || ((Direction == Vertical)   && IsColMajor)
                     || ((Direction == Horizontal) && IsRowMajor),
-                    
+
     CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
-    
+
     // let's enable LinearAccess only with vectorization because of the product overhead
     // FIXME enable DirectAccess with negative strides?
     Flags0 = evaluator<ArgType>::Flags,
     LinearAccess = ( (Direction==BothDirections) && (int(Flags0)&PacketAccessBit) )
                   || ((ReverseRow && XprType::ColsAtCompileTime==1) || (ReverseCol && XprType::RowsAtCompileTime==1))
                  ? LinearAccessBit : 0,
 
     Flags = int(Flags0) & (HereditaryBits | PacketAccessBit | LinearAccess),
-    
+
     Alignment = 0 // FIXME in some rare cases, Alignment could be preserved, like a Vector4f.
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit unary_evaluator(const XprType& reverse)
     : m_argImpl(reverse.nestedExpression()),
       m_rows(ReverseRow ? reverse.nestedExpression().rows() : 1),
       m_cols(ReverseCol ? reverse.nestedExpression().cols() : 1)
   { }
- 
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index row, Index col) const
   {
     return m_argImpl.coeff(ReverseRow ? m_rows.value() - row - 1 : row,
                            ReverseCol ? m_cols.value() - col - 1 : col);
   }
 
@@ -1563,15 +1586,15 @@
   EIGEN_STRONG_INLINE
   void writePacket(Index index, const PacketType& x)
   {
     enum { PacketSize = unpacket_traits<PacketType>::size };
     m_argImpl.template writePacket<LoadMode>
       (m_rows.value() * m_cols.value() - index - PacketSize, preverse(x));
   }
- 
+
 protected:
   evaluator<ArgType> m_argImpl;
 
   // If we do not reverse rows, then we do not need to know the number of rows; same for columns
   // Nonetheless, in this case it is important to set to 1 such that the coeff(index) method works fine for vectors.
   const variable_if_dynamic<Index, ReverseRow ? ArgType::RowsAtCompileTime : 1> m_rows;
   const variable_if_dynamic<Index, ReverseCol ? ArgType::ColsAtCompileTime : 1> m_cols;
@@ -1581,29 +1604,29 @@
 // -------------------- Diagonal --------------------
 
 template<typename ArgType, int DiagIndex>
 struct evaluator<Diagonal<ArgType, DiagIndex> >
   : evaluator_base<Diagonal<ArgType, DiagIndex> >
 {
   typedef Diagonal<ArgType, DiagIndex> XprType;
-  
+
   enum {
     CoeffReadCost = evaluator<ArgType>::CoeffReadCost,
-    
+
     Flags = (unsigned int)(evaluator<ArgType>::Flags & (HereditaryBits | DirectAccessBit) & ~RowMajorBit) | LinearAccessBit,
-    
+
     Alignment = 0
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit evaluator(const XprType& diagonal)
     : m_argImpl(diagonal.nestedExpression()),
       m_index(diagonal.index())
   { }
- 
+
   typedef typename XprType::Scalar Scalar;
   typedef typename XprType::CoeffReturnType CoeffReturnType;
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   CoeffReturnType coeff(Index row, Index) const
   {
     return m_argImpl.coeff(row + rowOffset(), row + colOffset());
@@ -1628,16 +1651,18 @@
   }
 
 protected:
   evaluator<ArgType> m_argImpl;
   const internal::variable_if_dynamicindex<Index, XprType::DiagIndex> m_index;
 
 private:
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index rowOffset() const { return m_index.value() > 0 ? 0 : -m_index.value(); }
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Index colOffset() const { return m_index.value() > 0 ? m_index.value() : 0; }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+  Index rowOffset() const { return m_index.value() > 0 ? 0 : -m_index.value(); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+  Index colOffset() const { return m_index.value() > 0 ? m_index.value() : 0; }
 };
 
 
 //----------------------------------------------------------------------
 // deprecated code
 //----------------------------------------------------------------------
 
@@ -1653,49 +1678,49 @@
 { };
 
 template<typename ArgType>
 class EvalToTemp
   : public dense_xpr_base<EvalToTemp<ArgType> >::type
 {
  public:
- 
+
   typedef typename dense_xpr_base<EvalToTemp>::type Base;
   EIGEN_GENERIC_PUBLIC_INTERFACE(EvalToTemp)
- 
+
   explicit EvalToTemp(const ArgType& arg)
     : m_arg(arg)
   { }
- 
+
   const ArgType& arg() const
   {
     return m_arg;
   }
 
-  Index rows() const 
+  EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT
   {
     return m_arg.rows();
   }
 
-  Index cols() const 
+  EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT
   {
     return m_arg.cols();
   }
 
  private:
   const ArgType& m_arg;
 };
- 
+
 template<typename ArgType>
 struct evaluator<EvalToTemp<ArgType> >
   : public evaluator<typename ArgType::PlainObject>
 {
   typedef EvalToTemp<ArgType>                   XprType;
   typedef typename ArgType::PlainObject         PlainObject;
   typedef evaluator<PlainObject> Base;
-  
+
   EIGEN_DEVICE_FUNC explicit evaluator(const XprType& xpr)
     : m_result(xpr.arg())
   {
     ::new (static_cast<Base*>(this)) Base(m_result);
   }
 
   // This constructor is used when nesting an EvalTo evaluator in another evaluator
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CoreIterators.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CoreIterators.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CwiseBinaryOp.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CwiseBinaryOp.h`

 * *Files 6% similar despite different names*

```diff
@@ -70,24 +70,24 @@
   *
   * Most of the time, this is the only way that it is used, so you typically don't have to name
   * CwiseBinaryOp types explicitly.
   *
   * \sa MatrixBase::binaryExpr(const MatrixBase<OtherDerived> &,const CustomBinaryOp &) const, class CwiseUnaryOp, class CwiseNullaryOp
   */
 template<typename BinaryOp, typename LhsType, typename RhsType>
-class CwiseBinaryOp : 
+class CwiseBinaryOp :
   public CwiseBinaryOpImpl<
           BinaryOp, LhsType, RhsType,
           typename internal::cwise_promote_storage_type<typename internal::traits<LhsType>::StorageKind,
                                                         typename internal::traits<RhsType>::StorageKind,
                                                         BinaryOp>::ret>,
   internal::no_assignment_operator
 {
   public:
-    
+
     typedef typename internal::remove_all<BinaryOp>::type Functor;
     typedef typename internal::remove_all<LhsType>::type Lhs;
     typedef typename internal::remove_all<RhsType>::type Rhs;
 
     typedef typename CwiseBinaryOpImpl<
         BinaryOp, LhsType, RhsType,
         typename internal::cwise_promote_storage_type<typename internal::traits<LhsType>::StorageKind,
@@ -98,43 +98,37 @@
     typedef typename internal::ref_selector<LhsType>::type LhsNested;
     typedef typename internal::ref_selector<RhsType>::type RhsNested;
     typedef typename internal::remove_reference<LhsNested>::type _LhsNested;
     typedef typename internal::remove_reference<RhsNested>::type _RhsNested;
 
 #if EIGEN_COMP_MSVC && EIGEN_HAS_CXX11
     //Required for Visual Studio or the Copy constructor will probably not get inlined!
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+    EIGEN_STRONG_INLINE
     CwiseBinaryOp(const CwiseBinaryOp<BinaryOp,LhsType,RhsType>&) = default;
 #endif
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     CwiseBinaryOp(const Lhs& aLhs, const Rhs& aRhs, const BinaryOp& func = BinaryOp())
       : m_lhs(aLhs), m_rhs(aRhs), m_functor(func)
     {
       EIGEN_CHECK_BINARY_COMPATIBILIY(BinaryOp,typename Lhs::Scalar,typename Rhs::Scalar);
       // require the sizes to match
       EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(Lhs, Rhs)
       eigen_assert(aLhs.rows() == aRhs.rows() && aLhs.cols() == aRhs.cols());
     }
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index rows() const {
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT {
       // return the fixed size type if available to enable compile time optimizations
-      if (internal::traits<typename internal::remove_all<LhsNested>::type>::RowsAtCompileTime==Dynamic)
-        return m_rhs.rows();
-      else
-        return m_lhs.rows();
+      return internal::traits<typename internal::remove_all<LhsNested>::type>::RowsAtCompileTime==Dynamic ? m_rhs.rows() : m_lhs.rows();
     }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index cols() const {
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT {
       // return the fixed size type if available to enable compile time optimizations
-      if (internal::traits<typename internal::remove_all<LhsNested>::type>::ColsAtCompileTime==Dynamic)
-        return m_rhs.cols();
-      else
-        return m_lhs.cols();
+      return internal::traits<typename internal::remove_all<LhsNested>::type>::ColsAtCompileTime==Dynamic ? m_rhs.cols() : m_lhs.cols();
     }
 
     /** \returns the left hand side nested expression */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const _LhsNested& lhs() const { return m_lhs; }
     /** \returns the right hand side nested expression */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CwiseNullaryOp.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CwiseNullaryOp.h`

 * *Files 8% similar despite different names*

```diff
@@ -70,18 +70,18 @@
     {
       eigen_assert(rows >= 0
             && (RowsAtCompileTime == Dynamic || RowsAtCompileTime == rows)
             &&  cols >= 0
             && (ColsAtCompileTime == Dynamic || ColsAtCompileTime == cols));
     }
 
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index rows() const { return m_rows.value(); }
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index cols() const { return m_cols.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const { return m_rows.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const { return m_cols.value(); }
 
     /** \returns the functor representing the nullary operation */
     EIGEN_DEVICE_FUNC
     const NullaryOp& functor() const { return m_functor; }
 
   protected:
     const internal::variable_if_dynamic<Index, RowsAtCompileTime> m_rows;
@@ -127,15 +127,15 @@
   * it is redundant to pass \a size as argument, so Zero() should be used
   * instead.
   *
   * The template parameter \a CustomNullaryOp is the type of the functor.
   *
   * Here is an example with C++11 random generators: \include random_cpp11.cpp
   * Output: \verbinclude random_cpp11.out
-  * 
+  *
   * \sa class CwiseNullaryOp
   */
 template<typename Derived>
 template<typename CustomNullaryOp>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 #ifndef EIGEN_PARSED_BY_DOXYGEN
 const CwiseNullaryOp<CustomNullaryOp, typename DenseBase<Derived>::PlainObject>
@@ -379,14 +379,41 @@
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
 PlainObjectBase<Derived>::setConstant(Index rows, Index cols, const Scalar& val)
 {
   resize(rows, cols);
   return setConstant(val);
 }
 
+/** Resizes to the given size, changing only the number of columns, and sets all
+  * coefficients in this expression to the given value \a val. For the parameter
+  * of type NoChange_t, just pass the special value \c NoChange.
+  *
+  * \sa MatrixBase::setConstant(const Scalar&), setConstant(Index,const Scalar&), class CwiseNullaryOp, MatrixBase::Constant(const Scalar&)
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setConstant(NoChange_t, Index cols, const Scalar& val)
+{
+  return setConstant(rows(), cols, val);
+}
+
+/** Resizes to the given size, changing only the number of rows, and sets all
+  * coefficients in this expression to the given value \a val. For the parameter
+  * of type NoChange_t, just pass the special value \c NoChange.
+  *
+  * \sa MatrixBase::setConstant(const Scalar&), setConstant(Index,const Scalar&), class CwiseNullaryOp, MatrixBase::Constant(const Scalar&)
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setConstant(Index rows, NoChange_t, const Scalar& val)
+{
+  return setConstant(rows, cols(), val);
+}
+
+
 /**
   * \brief Sets a linearly spaced vector.
   *
   * The function generates 'size' equally spaced values in the closed interval [low,high].
   * When size is set to 1, a vector of length 1 containing 'high' is returned.
   *
   * \only_for_vectors
@@ -552,14 +579,40 @@
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
 PlainObjectBase<Derived>::setZero(Index rows, Index cols)
 {
   resize(rows, cols);
   return setConstant(Scalar(0));
 }
 
+/** Resizes to the given size, changing only the number of columns, and sets all
+  * coefficients in this expression to zero. For the parameter of type NoChange_t,
+  * just pass the special value \c NoChange.
+  *
+  * \sa DenseBase::setZero(), setZero(Index), setZero(Index, Index), setZero(Index, NoChange_t), class CwiseNullaryOp, DenseBase::Zero()
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setZero(NoChange_t, Index cols)
+{
+  return setZero(rows(), cols);
+}
+
+/** Resizes to the given size, changing only the number of rows, and sets all
+  * coefficients in this expression to zero. For the parameter of type NoChange_t,
+  * just pass the special value \c NoChange.
+  *
+  * \sa DenseBase::setZero(), setZero(Index), setZero(Index, Index), setZero(NoChange_t, Index), class CwiseNullaryOp, DenseBase::Zero()
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setZero(Index rows, NoChange_t)
+{
+  return setZero(rows, cols());
+}
+
 // ones:
 
 /** \returns an expression of a matrix where all coefficients equal one.
   *
   * The parameters \a rows and \a cols are the number of rows and of columns of
   * the returned matrix. Must be compatible with this MatrixBase type.
   *
@@ -678,14 +731,40 @@
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
 PlainObjectBase<Derived>::setOnes(Index rows, Index cols)
 {
   resize(rows, cols);
   return setConstant(Scalar(1));
 }
 
+/** Resizes to the given size, changing only the number of rows, and sets all
+  * coefficients in this expression to one. For the parameter of type NoChange_t,
+  * just pass the special value \c NoChange.
+  *
+ * \sa MatrixBase::setOnes(), setOnes(Index), setOnes(Index, Index), setOnes(NoChange_t, Index), class CwiseNullaryOp, MatrixBase::Ones()
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setOnes(Index rows, NoChange_t)
+{
+  return setOnes(rows, cols());
+}
+
+/** Resizes to the given size, changing only the number of columns, and sets all
+  * coefficients in this expression to one. For the parameter of type NoChange_t,
+  * just pass the special value \c NoChange.
+  *
+ * \sa MatrixBase::setOnes(), setOnes(Index), setOnes(Index, Index), setOnes(Index, NoChange_t) class CwiseNullaryOp, MatrixBase::Ones()
+  */
+template<typename Derived>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setOnes(NoChange_t, Index cols)
+{
+  return setOnes(rows(), cols);
+}
+
 // Identity:
 
 /** \returns an expression of the identity matrix (not necessarily square).
   *
   * The parameters \a rows and \a cols are the number of rows and of columns of
   * the returned matrix. Must be compatible with this MatrixBase type.
   *
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CwiseTernaryOp.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CwiseTernaryOp.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CwiseUnaryOp.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CwiseUnaryOp.h`

 * *Files 7% similar despite different names*

```diff
@@ -7,28 +7,28 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_CWISE_UNARY_OP_H
 #define EIGEN_CWISE_UNARY_OP_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 template<typename UnaryOp, typename XprType>
 struct traits<CwiseUnaryOp<UnaryOp, XprType> >
  : traits<XprType>
 {
   typedef typename result_of<
                      UnaryOp(const typename XprType::Scalar&)
                    >::type Scalar;
   typedef typename XprType::Nested XprTypeNested;
   typedef typename remove_reference<XprTypeNested>::type _XprTypeNested;
   enum {
-    Flags = _XprTypeNested::Flags & RowMajorBit 
+    Flags = _XprTypeNested::Flags & RowMajorBit
   };
 };
 }
 
 template<typename UnaryOp, typename XprType, typename StorageKind>
 class CwiseUnaryOpImpl;
 
@@ -61,18 +61,18 @@
     typedef typename internal::ref_selector<XprType>::type XprTypeNested;
     typedef typename internal::remove_all<XprType>::type NestedExpression;
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     explicit CwiseUnaryOp(const XprType& xpr, const UnaryOp& func = UnaryOp())
       : m_xpr(xpr), m_functor(func) {}
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index rows() const { return m_xpr.rows(); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index cols() const { return m_xpr.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_xpr.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_xpr.cols(); }
 
     /** \returns the functor representing the unary operation */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const UnaryOp& functor() const { return m_functor; }
 
     /** \returns the nested expression */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/CwiseUnaryView.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/CwiseUnaryView.h`

 * *Files 8% similar despite different names*

```diff
@@ -60,31 +60,33 @@
   public:
 
     typedef typename CwiseUnaryViewImpl<ViewOp, MatrixType,typename internal::traits<MatrixType>::StorageKind>::Base Base;
     EIGEN_GENERIC_PUBLIC_INTERFACE(CwiseUnaryView)
     typedef typename internal::ref_selector<MatrixType>::non_const_type MatrixTypeNested;
     typedef typename internal::remove_all<MatrixType>::type NestedExpression;
 
-    explicit inline CwiseUnaryView(MatrixType& mat, const ViewOp& func = ViewOp())
+    explicit EIGEN_DEVICE_FUNC inline CwiseUnaryView(MatrixType& mat, const ViewOp& func = ViewOp())
       : m_matrix(mat), m_functor(func) {}
 
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(CwiseUnaryView)
 
-    EIGEN_STRONG_INLINE Index rows() const { return m_matrix.rows(); }
-    EIGEN_STRONG_INLINE Index cols() const { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
     /** \returns the functor representing unary operation */
-    const ViewOp& functor() const { return m_functor; }
+    EIGEN_DEVICE_FUNC const ViewOp& functor() const { return m_functor; }
 
     /** \returns the nested expression */
-    const typename internal::remove_all<MatrixTypeNested>::type&
+    EIGEN_DEVICE_FUNC const typename internal::remove_all<MatrixTypeNested>::type&
     nestedExpression() const { return m_matrix; }
 
     /** \returns the nested expression */
-    typename internal::remove_reference<MatrixTypeNested>::type&
+    EIGEN_DEVICE_FUNC typename internal::remove_reference<MatrixTypeNested>::type&
     nestedExpression() { return m_matrix; }
 
   protected:
     MatrixTypeNested m_matrix;
     ViewOp m_functor;
 };
 
@@ -104,25 +106,27 @@
   public:
 
     typedef CwiseUnaryView<ViewOp, MatrixType> Derived;
     typedef typename internal::dense_xpr_base< CwiseUnaryView<ViewOp, MatrixType> >::type Base;
 
     EIGEN_DENSE_PUBLIC_INTERFACE(Derived)
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(CwiseUnaryViewImpl)
-    
+
     EIGEN_DEVICE_FUNC inline Scalar* data() { return &(this->coeffRef(0)); }
     EIGEN_DEVICE_FUNC inline const Scalar* data() const { return &(this->coeff(0)); }
 
-    EIGEN_DEVICE_FUNC inline Index innerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const
     {
       return derived().nestedExpression().innerStride() * sizeof(typename internal::traits<MatrixType>::Scalar) / sizeof(Scalar);
     }
 
-    EIGEN_DEVICE_FUNC inline Index outerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const
     {
       return derived().nestedExpression().outerStride() * sizeof(typename internal::traits<MatrixType>::Scalar) / sizeof(Scalar);
     }
+  protected:
+    EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(CwiseUnaryViewImpl)
 };
 
 } // end namespace Eigen
 
 #endif // EIGEN_CWISE_UNARY_VIEW_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/DenseBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/DenseBase.h`

 * *Files 2% similar despite different names*

```diff
@@ -10,23 +10,23 @@
 
 #ifndef EIGEN_DENSEBASE_H
 #define EIGEN_DENSEBASE_H
 
 namespace Eigen {
 
 namespace internal {
-  
+
 // The index type defined by EIGEN_DEFAULT_DENSE_INDEX_TYPE must be a signed type.
 // This dummy function simply aims at checking that at compile time.
 static inline void check_DenseIndex_is_signed() {
-  EIGEN_STATIC_ASSERT(NumTraits<DenseIndex>::IsSigned,THE_INDEX_TYPE_MUST_BE_A_SIGNED_TYPE); 
+  EIGEN_STATIC_ASSERT(NumTraits<DenseIndex>::IsSigned,THE_INDEX_TYPE_MUST_BE_A_SIGNED_TYPE)
 }
 
 } // end namespace internal
-  
+
 /** \class DenseBase
   * \ingroup Core_Module
   *
   * \brief Base class for all dense matrices, vectors, and arrays
   *
   * This class is the base that is inherited by all dense objects (matrix, vector, arrays,
   * and related expression types). The common Eigen API for dense objects is contained in this class.
@@ -60,20 +60,20 @@
       *          PermutationMatrix or Transpositions, otherwise it defaults to Eigen::Index
       * \sa \blank \ref TopicPreprocessorDirectives, Eigen::Index, SparseMatrixBase.
      */
     typedef typename internal::traits<Derived>::StorageIndex StorageIndex;
 
     /** The numeric type of the expression' coefficients, e.g. float, double, int or std::complex<float>, etc. */
     typedef typename internal::traits<Derived>::Scalar Scalar;
-    
+
     /** The numeric type of the expression' coefficients, e.g. float, double, int or std::complex<float>, etc.
       *
       * It is an alias for the Scalar type */
     typedef Scalar value_type;
-    
+
     typedef typename NumTraits<Scalar>::Real RealScalar;
     typedef DenseCoeffsBase<Derived, internal::accessors_level<Derived>::value> Base;
 
     using Base::derived;
     using Base::const_cast_derived;
     using Base::rows;
     using Base::cols;
@@ -154,15 +154,15 @@
                            || internal::traits<Derived>::ColsAtCompileTime == 1,
         /**< This is set to true if either the number of rows or the number of
           * columns is known at compile-time to be equal to 1. Indeed, in that case,
           * we are dealing with a column-vector (if there is only one column) or with
           * a row-vector (if there is only one row). */
 
       NumDimensions = int(MaxSizeAtCompileTime) == 1 ? 0 : bool(IsVectorAtCompileTime) ? 1 : 2,
-        /**< This value is equal to Tensor::NumDimensions, i.e. 0 for scalars, 1 for vectors, 
+        /**< This value is equal to Tensor::NumDimensions, i.e. 0 for scalars, 1 for vectors,
          * and 2 for matrices.
          */
 
       Flags = internal::traits<Derived>::Flags,
         /**< This stores expression \ref flags flags which may or may not be inherited by new expressions
           * constructed from this one. See the \ref flags "list of flags".
           */
@@ -171,29 +171,29 @@
 
       InnerSizeAtCompileTime = int(IsVectorAtCompileTime) ? int(SizeAtCompileTime)
                              : int(IsRowMajor) ? int(ColsAtCompileTime) : int(RowsAtCompileTime),
 
       InnerStrideAtCompileTime = internal::inner_stride_at_compile_time<Derived>::ret,
       OuterStrideAtCompileTime = internal::outer_stride_at_compile_time<Derived>::ret
     };
-    
+
     typedef typename internal::find_best_packet<Scalar,SizeAtCompileTime>::type PacketScalar;
 
     enum { IsPlainObjectBase = 0 };
-    
+
     /** The plain matrix type corresponding to this expression.
       * \sa PlainObject */
     typedef Matrix<typename internal::traits<Derived>::Scalar,
                 internal::traits<Derived>::RowsAtCompileTime,
                 internal::traits<Derived>::ColsAtCompileTime,
                 AutoAlign | (internal::traits<Derived>::Flags&RowMajorBit ? RowMajor : ColMajor),
                 internal::traits<Derived>::MaxRowsAtCompileTime,
                 internal::traits<Derived>::MaxColsAtCompileTime
           > PlainMatrix;
-    
+
     /** The plain array type corresponding to this expression.
       * \sa PlainObject */
     typedef Array<typename internal::traits<Derived>::Scalar,
                 internal::traits<Derived>::RowsAtCompileTime,
                 internal::traits<Derived>::ColsAtCompileTime,
                 AutoAlign | (internal::traits<Derived>::Flags&RowMajorBit ? RowMajor : ColMajor),
                 internal::traits<Derived>::MaxRowsAtCompileTime,
@@ -207,35 +207,35 @@
       * that the return type of eval() is either PlainObject or const PlainObject&.
       */
     typedef typename internal::conditional<internal::is_same<typename internal::traits<Derived>::XprKind,MatrixXpr >::value,
                                  PlainMatrix, PlainArray>::type PlainObject;
 
     /** \returns the number of nonzero coefficients which is in practice the number
       * of stored coefficients. */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index nonZeros() const { return size(); }
 
     /** \returns the outer size.
       *
       * \note For a vector, this returns just 1. For a matrix (non-vector), this is the major dimension
       * with respect to the \ref TopicStorageOrders "storage order", i.e., the number of columns for a
       * column-major matrix, and the number of rows for a row-major matrix. */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     Index outerSize() const
     {
       return IsVectorAtCompileTime ? 1
            : int(IsRowMajor) ? this->rows() : this->cols();
     }
 
     /** \returns the inner size.
       *
       * \note For a vector, this is just the size. For a matrix (non-vector), this is the minor dimension
-      * with respect to the \ref TopicStorageOrders "storage order", i.e., the number of rows for a 
+      * with respect to the \ref TopicStorageOrders "storage order", i.e., the number of rows for a
       * column-major matrix, and the number of columns for a row-major matrix. */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     Index innerSize() const
     {
       return IsVectorAtCompileTime ? this->size()
            : int(IsRowMajor) ? this->cols() : this->rows();
     }
 
     /** Only plain matrices/arrays, not expressions, may be resized; therefore the only useful resize methods are
@@ -407,15 +407,15 @@
     EIGEN_STRONG_INLINE EvalReturnType eval() const
     {
       // Even though MSVC does not honor strong inlining when the return type
       // is a dynamic matrix, we desperately need strong inlining for fixed
       // size types on MSVC.
       return typename internal::eval<Derived>::type(derived());
     }
-    
+
     /** swaps *this with the expression \a other.
       *
       */
     template<typename OtherDerived>
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     void swap(const DenseBase<OtherDerived>& other)
     {
@@ -445,26 +445,66 @@
 
     EIGEN_DEVICE_FUNC Scalar sum() const;
     EIGEN_DEVICE_FUNC Scalar mean() const;
     EIGEN_DEVICE_FUNC Scalar trace() const;
 
     EIGEN_DEVICE_FUNC Scalar prod() const;
 
+    template<int NaNPropagation>
     EIGEN_DEVICE_FUNC typename internal::traits<Derived>::Scalar minCoeff() const;
+    template<int NaNPropagation>
     EIGEN_DEVICE_FUNC typename internal::traits<Derived>::Scalar maxCoeff() const;
 
-    template<typename IndexType> EIGEN_DEVICE_FUNC
+
+    // By default, the fastest version with undefined NaN propagation semantics is
+    // used.
+    // TODO(rmlarsen): Replace with default template argument when we move to
+    // c++11 or beyond.
+    EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar minCoeff() const {
+      return minCoeff<PropagateFast>();
+    }
+    EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar maxCoeff() const {
+      return maxCoeff<PropagateFast>();
+    }
+
+    template<int NaNPropagation, typename IndexType>
+    EIGEN_DEVICE_FUNC
     typename internal::traits<Derived>::Scalar minCoeff(IndexType* row, IndexType* col) const;
-    template<typename IndexType> EIGEN_DEVICE_FUNC
+    template<int NaNPropagation, typename IndexType>
+    EIGEN_DEVICE_FUNC
     typename internal::traits<Derived>::Scalar maxCoeff(IndexType* row, IndexType* col) const;
-    template<typename IndexType> EIGEN_DEVICE_FUNC
+    template<int NaNPropagation, typename IndexType>
+    EIGEN_DEVICE_FUNC
     typename internal::traits<Derived>::Scalar minCoeff(IndexType* index) const;
-    template<typename IndexType> EIGEN_DEVICE_FUNC
+    template<int NaNPropagation, typename IndexType>
+    EIGEN_DEVICE_FUNC
     typename internal::traits<Derived>::Scalar maxCoeff(IndexType* index) const;
 
+    // TODO(rmlarsen): Replace these methods with a default template argument.
+    template<typename IndexType>
+    EIGEN_DEVICE_FUNC inline
+    typename internal::traits<Derived>::Scalar minCoeff(IndexType* row, IndexType* col) const {
+      return minCoeff<PropagateFast>(row, col);
+    }
+    template<typename IndexType>
+    EIGEN_DEVICE_FUNC inline
+    typename internal::traits<Derived>::Scalar maxCoeff(IndexType* row, IndexType* col) const {
+      return maxCoeff<PropagateFast>(row, col);
+    }
+    template<typename IndexType>
+     EIGEN_DEVICE_FUNC inline
+    typename internal::traits<Derived>::Scalar minCoeff(IndexType* index) const {
+      return minCoeff<PropagateFast>(index);
+    }
+    template<typename IndexType>
+    EIGEN_DEVICE_FUNC inline
+    typename internal::traits<Derived>::Scalar maxCoeff(IndexType* index) const {
+      return maxCoeff<PropagateFast>(index);
+    }
+  
     template<typename BinaryOp>
     EIGEN_DEVICE_FUNC
     Scalar redux(const BinaryOp& func) const;
 
     template<typename Visitor>
     EIGEN_DEVICE_FUNC
     void visit(Visitor& func) const;
@@ -526,24 +566,24 @@
 
     typedef CwiseNullaryOp<internal::scalar_random_op<Scalar>,PlainObject> RandomReturnType;
     static const RandomReturnType Random(Index rows, Index cols);
     static const RandomReturnType Random(Index size);
     static const RandomReturnType Random();
 
     template<typename ThenDerived,typename ElseDerived>
-    const Select<Derived,ThenDerived,ElseDerived>
+    inline EIGEN_DEVICE_FUNC const Select<Derived,ThenDerived,ElseDerived>
     select(const DenseBase<ThenDerived>& thenMatrix,
            const DenseBase<ElseDerived>& elseMatrix) const;
 
     template<typename ThenDerived>
-    inline const Select<Derived,ThenDerived, typename ThenDerived::ConstantReturnType>
+    inline EIGEN_DEVICE_FUNC const Select<Derived,ThenDerived, typename ThenDerived::ConstantReturnType>
     select(const DenseBase<ThenDerived>& thenMatrix, const typename ThenDerived::Scalar& elseScalar) const;
 
     template<typename ElseDerived>
-    inline const Select<Derived, typename ElseDerived::ConstantReturnType, ElseDerived >
+    inline EIGEN_DEVICE_FUNC const Select<Derived, typename ElseDerived::ConstantReturnType, ElseDerived >
     select(const typename ElseDerived::Scalar& thenScalar, const DenseBase<ElseDerived>& elseMatrix) const;
 
     template<int p> RealScalar lpNorm() const;
 
     template<int RowFactor, int ColFactor>
     EIGEN_DEVICE_FUNC
     const Replicate<Derived,RowFactor,ColFactor> replicate() const;
@@ -632,19 +672,20 @@
     EIGEN_DEVICE_FUNC
     inline void evalTo(Dest& ) const
     {
       EIGEN_STATIC_ASSERT((internal::is_same<Dest,void>::value),THE_EVAL_EVALTO_FUNCTION_SHOULD_NEVER_BE_CALLED_FOR_DENSE_OBJECTS);
     }
 
   protected:
+    EIGEN_DEFAULT_COPY_CONSTRUCTOR(DenseBase)
     /** Default constructor. Do nothing. */
     EIGEN_DEVICE_FUNC DenseBase()
     {
       /* Just checks for self-consistency of the flags.
-       * Only do it when debugging Eigen, as this borders on paranoiac and could slow compilation down
+       * Only do it when debugging Eigen, as this borders on paranoia and could slow compilation down
        */
 #ifdef EIGEN_INTERNAL_DEBUGGING
       EIGEN_STATIC_ASSERT((EIGEN_IMPLIES(MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1, int(IsRowMajor))
                         && EIGEN_IMPLIES(MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1, int(!IsRowMajor))),
                           INVALID_STORAGE_ORDER_FOR_THIS_VECTOR_EXPRESSION)
 #endif
     }
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/DenseCoeffsBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/DenseCoeffsBase.h`

 * *Files 4% similar despite different names*

```diff
@@ -23,15 +23,15 @@
   * \ingroup Core_Module
   * \tparam Derived Type of the derived class
   *
   * \note #ReadOnlyAccessors Constant indicating read-only access
   *
   * This class defines the \c operator() \c const function and friends, which can be used to read specific
   * entries of a matrix or array.
-  * 
+  *
   * \sa DenseCoeffsBase<Derived, WriteAccessors>, DenseCoeffsBase<Derived, DirectAccessors>,
   *     \ref TopicClassHierarchy
   */
 template<typename Derived>
 class DenseCoeffsBase<Derived,ReadOnlyAccessors> : public EigenBase<Derived>
 {
   public:
@@ -291,15 +291,15 @@
   * \tparam Derived Type of the derived class
   *
   * \note #WriteAccessors Constant indicating read/write access
   *
   * This class defines the non-const \c operator() function and friends, which can be used to write specific
   * entries of a matrix or array. This class inherits DenseCoeffsBase<Derived, ReadOnlyAccessors> which
   * defines the const variant for reading specific entries.
-  * 
+  *
   * \sa DenseCoeffsBase<Derived, DirectAccessors>, \ref TopicClassHierarchy
   */
 template<typename Derived>
 class DenseCoeffsBase<Derived, WriteAccessors> : public DenseCoeffsBase<Derived, ReadOnlyAccessors>
 {
   public:
 
@@ -491,52 +491,52 @@
     using Base::size;
     using Base::derived;
 
     /** \returns the pointer increment between two consecutive elements within a slice in the inner direction.
       *
       * \sa outerStride(), rowStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index innerStride() const
     {
       return derived().innerStride();
     }
 
     /** \returns the pointer increment between two consecutive inner slices (for example, between two consecutive columns
       *          in a column-major matrix).
       *
       * \sa innerStride(), rowStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index outerStride() const
     {
       return derived().outerStride();
     }
 
     // FIXME shall we remove it ?
-    inline Index stride() const
+    EIGEN_CONSTEXPR inline Index stride() const
     {
       return Derived::IsVectorAtCompileTime ? innerStride() : outerStride();
     }
 
     /** \returns the pointer increment between two consecutive rows.
       *
       * \sa innerStride(), outerStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index rowStride() const
     {
       return Derived::IsRowMajor ? outerStride() : innerStride();
     }
 
     /** \returns the pointer increment between two consecutive columns.
       *
       * \sa innerStride(), outerStride(), rowStride()
       */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index colStride() const
     {
       return Derived::IsRowMajor ? innerStride() : outerStride();
     }
 };
 
 /** \brief Base class providing direct read/write coefficient access to matrices and arrays.
@@ -566,64 +566,64 @@
     using Base::size;
     using Base::derived;
 
     /** \returns the pointer increment between two consecutive elements within a slice in the inner direction.
       *
       * \sa outerStride(), rowStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT
     {
       return derived().innerStride();
     }
 
     /** \returns the pointer increment between two consecutive inner slices (for example, between two consecutive columns
       *          in a column-major matrix).
       *
       * \sa innerStride(), rowStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT
     {
       return derived().outerStride();
     }
 
     // FIXME shall we remove it ?
-    inline Index stride() const
+    EIGEN_CONSTEXPR inline Index stride() const EIGEN_NOEXCEPT
     {
       return Derived::IsVectorAtCompileTime ? innerStride() : outerStride();
     }
 
     /** \returns the pointer increment between two consecutive rows.
       *
       * \sa innerStride(), outerStride(), colStride()
       */
-    EIGEN_DEVICE_FUNC
-    inline Index rowStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rowStride() const EIGEN_NOEXCEPT
     {
       return Derived::IsRowMajor ? outerStride() : innerStride();
     }
 
     /** \returns the pointer increment between two consecutive columns.
       *
       * \sa innerStride(), outerStride(), rowStride()
       */
-    EIGEN_DEVICE_FUNC
-    inline Index colStride() const
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index colStride() const EIGEN_NOEXCEPT
     {
       return Derived::IsRowMajor ? innerStride() : outerStride();
     }
 };
 
 namespace internal {
 
 template<int Alignment, typename Derived, bool JustReturnZero>
 struct first_aligned_impl
 {
-  static inline Index run(const Derived&)
+  static EIGEN_CONSTEXPR inline Index run(const Derived&) EIGEN_NOEXCEPT
   { return 0; }
 };
 
 template<int Alignment, typename Derived>
 struct first_aligned_impl<Alignment, Derived, false>
 {
   static inline Index run(const Derived& m)
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/DenseStorage.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/DenseStorage.h`

 * *Files 7% similar despite different names*

```diff
@@ -43,28 +43,28 @@
                         : compute_default_alignment<T,Size>::value >
 struct plain_array
 {
   T array[Size];
 
   EIGEN_DEVICE_FUNC
   plain_array()
-  { 
+  {
     check_static_allocation_size<T,Size>();
   }
 
   EIGEN_DEVICE_FUNC
   plain_array(constructor_without_unaligned_array_assert)
-  { 
+  {
     check_static_allocation_size<T,Size>();
   }
 };
 
 #if defined(EIGEN_DISABLE_UNALIGNED_ARRAY_ASSERT)
   #define EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(sizemask)
-#elif EIGEN_GNUC_AT_LEAST(4,7) 
+#elif EIGEN_GNUC_AT_LEAST(4,7)
   // GCC 4.7 is too aggressive in its optimizations and remove the alignment test based on the fact the array is declared to be aligned.
   // See this bug report: http://gcc.gnu.org/bugzilla/show_bug.cgi?id=53900
   // Hiding the origin of the array pointer behind a function argument seems to do the trick even if the function is inlined:
   template<typename PtrType>
   EIGEN_ALWAYS_INLINE PtrType eigen_unaligned_array_assert_workaround_gcc47(PtrType array) { return array; }
   #define EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(sizemask) \
     eigen_assert((internal::UIntPtr(eigen_unaligned_array_assert_workaround_gcc47(array)) & (sizemask)) == 0 \
@@ -81,92 +81,116 @@
 
 template <typename T, int Size, int MatrixOrArrayOptions>
 struct plain_array<T, Size, MatrixOrArrayOptions, 8>
 {
   EIGEN_ALIGN_TO_BOUNDARY(8) T array[Size];
 
   EIGEN_DEVICE_FUNC
-  plain_array() 
+  plain_array()
   {
     EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(7);
     check_static_allocation_size<T,Size>();
   }
 
   EIGEN_DEVICE_FUNC
-  plain_array(constructor_without_unaligned_array_assert) 
-  { 
+  plain_array(constructor_without_unaligned_array_assert)
+  {
     check_static_allocation_size<T,Size>();
   }
 };
 
 template <typename T, int Size, int MatrixOrArrayOptions>
 struct plain_array<T, Size, MatrixOrArrayOptions, 16>
 {
   EIGEN_ALIGN_TO_BOUNDARY(16) T array[Size];
 
   EIGEN_DEVICE_FUNC
-  plain_array() 
-  { 
+  plain_array()
+  {
     EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(15);
     check_static_allocation_size<T,Size>();
   }
 
   EIGEN_DEVICE_FUNC
-  plain_array(constructor_without_unaligned_array_assert) 
-  { 
+  plain_array(constructor_without_unaligned_array_assert)
+  {
     check_static_allocation_size<T,Size>();
   }
 };
 
 template <typename T, int Size, int MatrixOrArrayOptions>
 struct plain_array<T, Size, MatrixOrArrayOptions, 32>
 {
   EIGEN_ALIGN_TO_BOUNDARY(32) T array[Size];
 
   EIGEN_DEVICE_FUNC
-  plain_array() 
+  plain_array()
   {
     EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(31);
     check_static_allocation_size<T,Size>();
   }
 
   EIGEN_DEVICE_FUNC
-  plain_array(constructor_without_unaligned_array_assert) 
-  { 
+  plain_array(constructor_without_unaligned_array_assert)
+  {
     check_static_allocation_size<T,Size>();
   }
 };
 
 template <typename T, int Size, int MatrixOrArrayOptions>
 struct plain_array<T, Size, MatrixOrArrayOptions, 64>
 {
   EIGEN_ALIGN_TO_BOUNDARY(64) T array[Size];
 
   EIGEN_DEVICE_FUNC
-  plain_array() 
-  { 
+  plain_array()
+  {
     EIGEN_MAKE_UNALIGNED_ARRAY_ASSERT(63);
     check_static_allocation_size<T,Size>();
   }
 
   EIGEN_DEVICE_FUNC
-  plain_array(constructor_without_unaligned_array_assert) 
-  { 
+  plain_array(constructor_without_unaligned_array_assert)
+  {
     check_static_allocation_size<T,Size>();
   }
 };
 
 template <typename T, int MatrixOrArrayOptions, int Alignment>
 struct plain_array<T, 0, MatrixOrArrayOptions, Alignment>
 {
   T array[1];
   EIGEN_DEVICE_FUNC plain_array() {}
   EIGEN_DEVICE_FUNC plain_array(constructor_without_unaligned_array_assert) {}
 };
 
+struct plain_array_helper {
+  template<typename T, int Size, int MatrixOrArrayOptions, int Alignment>
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+  static void copy(const plain_array<T, Size, MatrixOrArrayOptions, Alignment>& src, const Eigen::Index size,
+                         plain_array<T, Size, MatrixOrArrayOptions, Alignment>& dst) {
+    smart_copy(src.array, src.array + size, dst.array);
+  }
+  
+  template<typename T, int Size, int MatrixOrArrayOptions, int Alignment>
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+  static void swap(plain_array<T, Size, MatrixOrArrayOptions, Alignment>& a, const Eigen::Index a_size,
+                   plain_array<T, Size, MatrixOrArrayOptions, Alignment>& b, const Eigen::Index b_size) {
+    if (a_size < b_size) {
+      std::swap_ranges(b.array, b.array + a_size, a.array);
+      smart_move(b.array + a_size, b.array + b_size, a.array + a_size);
+    } else if (a_size > b_size) {
+      std::swap_ranges(a.array, a.array + b_size, b.array);
+      smart_move(a.array + b_size, a.array + a_size, b.array + b_size);
+    } else {
+      std::swap_ranges(a.array, a.array + a_size, b.array);
+    }
+  }
+};
+
 } // end namespace internal
 
 /** \internal
   *
   * \class DenseStorage
   * \ingroup Core_Module
   *
@@ -186,36 +210,61 @@
   public:
     EIGEN_DEVICE_FUNC DenseStorage() {
       EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = Size)
     }
     EIGEN_DEVICE_FUNC
     explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
       : m_data(internal::constructor_without_unaligned_array_assert()) {}
-    EIGEN_DEVICE_FUNC 
+#if !EIGEN_HAS_CXX11 || defined(EIGEN_DENSE_STORAGE_CTOR_PLUGIN)
+    EIGEN_DEVICE_FUNC
     DenseStorage(const DenseStorage& other) : m_data(other.m_data) {
       EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN(Index size = Size)
     }
-    EIGEN_DEVICE_FUNC 
+#else
+    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage&) = default;
+#endif
+#if !EIGEN_HAS_CXX11
+    EIGEN_DEVICE_FUNC
     DenseStorage& operator=(const DenseStorage& other)
-    { 
+    {
       if (this != &other) m_data = other.m_data;
-      return *this; 
+      return *this;
+    }
+#else
+    EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage&) = default;
+#endif
+#if EIGEN_HAS_RVALUE_REFERENCES
+#if !EIGEN_HAS_CXX11
+    EIGEN_DEVICE_FUNC DenseStorage(DenseStorage&& other) EIGEN_NOEXCEPT
+      : m_data(std::move(other.m_data))
+    {
+    }
+    EIGEN_DEVICE_FUNC DenseStorage& operator=(DenseStorage&& other) EIGEN_NOEXCEPT
+    {
+      if (this != &other)
+        m_data = std::move(other.m_data);
+      return *this;
     }
+#else
+    EIGEN_DEVICE_FUNC DenseStorage(DenseStorage&&) = default;
+    EIGEN_DEVICE_FUNC DenseStorage& operator=(DenseStorage&&) = default;
+#endif
+#endif
     EIGEN_DEVICE_FUNC DenseStorage(Index size, Index rows, Index cols) {
       EIGEN_INTERNAL_DENSE_STORAGE_CTOR_PLUGIN({})
       eigen_internal_assert(size==rows*cols && rows==_Rows && cols==_Cols);
       EIGEN_UNUSED_VARIABLE(size);
       EIGEN_UNUSED_VARIABLE(rows);
       EIGEN_UNUSED_VARIABLE(cols);
     }
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other) {
       numext::swap(m_data, other.m_data);
     }
-    EIGEN_DEVICE_FUNC static Index rows(void) {return _Rows;}
-    EIGEN_DEVICE_FUNC static Index cols(void) {return _Cols;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index rows(void) EIGEN_NOEXCEPT {return _Rows;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index cols(void) EIGEN_NOEXCEPT {return _Cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index,Index,Index) {}
     EIGEN_DEVICE_FUNC void resize(Index,Index,Index) {}
     EIGEN_DEVICE_FUNC const T *data() const { return m_data.array; }
     EIGEN_DEVICE_FUNC T *data() { return m_data.array; }
 };
 
 // null matrix
@@ -224,16 +273,16 @@
   public:
     EIGEN_DEVICE_FUNC DenseStorage() {}
     EIGEN_DEVICE_FUNC explicit DenseStorage(internal::constructor_without_unaligned_array_assert) {}
     EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage&) {}
     EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage&) { return *this; }
     EIGEN_DEVICE_FUNC DenseStorage(Index,Index,Index) {}
     EIGEN_DEVICE_FUNC void swap(DenseStorage& ) {}
-    EIGEN_DEVICE_FUNC static Index rows(void) {return _Rows;}
-    EIGEN_DEVICE_FUNC static Index cols(void) {return _Cols;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index rows(void) EIGEN_NOEXCEPT {return _Rows;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index cols(void) EIGEN_NOEXCEPT {return _Cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index,Index,Index) {}
     EIGEN_DEVICE_FUNC void resize(Index,Index,Index) {}
     EIGEN_DEVICE_FUNC const T *data() const { return 0; }
     EIGEN_DEVICE_FUNC T *data() { return 0; }
 };
 
 // more specializations for null matrices; these are necessary to resolve ambiguities
@@ -252,29 +301,33 @@
     internal::plain_array<T,Size,_Options> m_data;
     Index m_rows;
     Index m_cols;
   public:
     EIGEN_DEVICE_FUNC DenseStorage() : m_rows(0), m_cols(0) {}
     EIGEN_DEVICE_FUNC explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
       : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(0), m_cols(0) {}
-    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other) : m_data(other.m_data), m_rows(other.m_rows), m_cols(other.m_cols) {}
-    EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage& other) 
-    { 
+    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other)
+      : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(other.m_rows), m_cols(other.m_cols)
+    {
+      internal::plain_array_helper::copy(other.m_data, m_rows * m_cols, m_data);
+    }
+    EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage& other)
+    {
       if (this != &other)
       {
-        m_data = other.m_data;
         m_rows = other.m_rows;
         m_cols = other.m_cols;
+        internal::plain_array_helper::copy(other.m_data, m_rows * m_cols, m_data);
       }
-      return *this; 
+      return *this;
     }
     EIGEN_DEVICE_FUNC DenseStorage(Index, Index rows, Index cols) : m_rows(rows), m_cols(cols) {}
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other)
     {
-      numext::swap(m_data,other.m_data);
+      internal::plain_array_helper::swap(m_data, m_rows * m_cols, other.m_data, other.m_rows * other.m_cols);
       numext::swap(m_rows,other.m_rows);
       numext::swap(m_cols,other.m_cols);
     }
     EIGEN_DEVICE_FUNC Index rows() const {return m_rows;}
     EIGEN_DEVICE_FUNC Index cols() const {return m_cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index, Index rows, Index cols) { m_rows = rows; m_cols = cols; }
     EIGEN_DEVICE_FUNC void resize(Index, Index rows, Index cols) { m_rows = rows; m_cols = cols; }
@@ -287,32 +340,37 @@
 {
     internal::plain_array<T,Size,_Options> m_data;
     Index m_rows;
   public:
     EIGEN_DEVICE_FUNC DenseStorage() : m_rows(0) {}
     EIGEN_DEVICE_FUNC explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
       : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(0) {}
-    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other) : m_data(other.m_data), m_rows(other.m_rows) {}
-    EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage& other) 
+    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other)
+      : m_data(internal::constructor_without_unaligned_array_assert()), m_rows(other.m_rows)
+    {
+      internal::plain_array_helper::copy(other.m_data, m_rows * _Cols, m_data);
+    }
+    
+    EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage& other)
     {
       if (this != &other)
       {
-        m_data = other.m_data;
         m_rows = other.m_rows;
+        internal::plain_array_helper::copy(other.m_data, m_rows * _Cols, m_data);
       }
-      return *this; 
+      return *this;
     }
     EIGEN_DEVICE_FUNC DenseStorage(Index, Index rows, Index) : m_rows(rows) {}
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other)
-    {
-      numext::swap(m_data,other.m_data);
-      numext::swap(m_rows,other.m_rows);
+    { 
+      internal::plain_array_helper::swap(m_data, m_rows * _Cols, other.m_data, other.m_rows * _Cols);
+      numext::swap(m_rows, other.m_rows);
     }
-    EIGEN_DEVICE_FUNC Index rows(void) const {return m_rows;}
-    EIGEN_DEVICE_FUNC Index cols(void) const {return _Cols;}
+    EIGEN_DEVICE_FUNC Index rows(void) const EIGEN_NOEXCEPT {return m_rows;}
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols(void) const EIGEN_NOEXCEPT {return _Cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index, Index rows, Index) { m_rows = rows; }
     EIGEN_DEVICE_FUNC void resize(Index, Index rows, Index) { m_rows = rows; }
     EIGEN_DEVICE_FUNC const T *data() const { return m_data.array; }
     EIGEN_DEVICE_FUNC T *data() { return m_data.array; }
 };
 
 // dynamic-size matrix with fixed-size storage and fixed height
@@ -320,31 +378,35 @@
 {
     internal::plain_array<T,Size,_Options> m_data;
     Index m_cols;
   public:
     EIGEN_DEVICE_FUNC DenseStorage() : m_cols(0) {}
     EIGEN_DEVICE_FUNC explicit DenseStorage(internal::constructor_without_unaligned_array_assert)
       : m_data(internal::constructor_without_unaligned_array_assert()), m_cols(0) {}
-    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other) : m_data(other.m_data), m_cols(other.m_cols) {}
+    EIGEN_DEVICE_FUNC DenseStorage(const DenseStorage& other) 
+      : m_data(internal::constructor_without_unaligned_array_assert()), m_cols(other.m_cols)
+    {
+      internal::plain_array_helper::copy(other.m_data, _Rows * m_cols, m_data);
+    }
     EIGEN_DEVICE_FUNC DenseStorage& operator=(const DenseStorage& other)
     {
       if (this != &other)
       {
-        m_data = other.m_data;
         m_cols = other.m_cols;
+        internal::plain_array_helper::copy(other.m_data, _Rows * m_cols, m_data);
       }
       return *this;
     }
     EIGEN_DEVICE_FUNC DenseStorage(Index, Index, Index cols) : m_cols(cols) {}
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other) {
-      numext::swap(m_data,other.m_data);
-      numext::swap(m_cols,other.m_cols);
+      internal::plain_array_helper::swap(m_data, _Rows * m_cols, other.m_data, _Rows * other.m_cols);
+      numext::swap(m_cols, other.m_cols);
     }
-    EIGEN_DEVICE_FUNC Index rows(void) const {return _Rows;}
-    EIGEN_DEVICE_FUNC Index cols(void) const {return m_cols;}
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows(void) const EIGEN_NOEXCEPT {return _Rows;}
+    EIGEN_DEVICE_FUNC Index cols(void) const EIGEN_NOEXCEPT {return m_cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index, Index, Index cols) { m_cols = cols; }
     EIGEN_DEVICE_FUNC void resize(Index, Index, Index cols) { m_cols = cols; }
     EIGEN_DEVICE_FUNC const T *data() const { return m_data.array; }
     EIGEN_DEVICE_FUNC T *data() { return m_data.array; }
 };
 
 // purely dynamic matrix.
@@ -403,16 +465,16 @@
     EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, m_rows*m_cols); }
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other)
     {
       numext::swap(m_data,other.m_data);
       numext::swap(m_rows,other.m_rows);
       numext::swap(m_cols,other.m_cols);
     }
-    EIGEN_DEVICE_FUNC Index rows(void) const {return m_rows;}
-    EIGEN_DEVICE_FUNC Index cols(void) const {return m_cols;}
+    EIGEN_DEVICE_FUNC Index rows(void) const EIGEN_NOEXCEPT {return m_rows;}
+    EIGEN_DEVICE_FUNC Index cols(void) const EIGEN_NOEXCEPT {return m_cols;}
     void conservativeResize(Index size, Index rows, Index cols)
     {
       m_data = internal::conditional_aligned_realloc_new_auto<T,(_Options&DontAlign)==0>(m_data, size, m_rows*m_cols);
       m_rows = rows;
       m_cols = cols;
     }
     EIGEN_DEVICE_FUNC void resize(Index size, Index rows, Index cols)
@@ -458,15 +520,15 @@
     {
       if (this != &other)
       {
         DenseStorage tmp(other);
         this->swap(tmp);
       }
       return *this;
-    }    
+    }
 #if EIGEN_HAS_RVALUE_REFERENCES
     EIGEN_DEVICE_FUNC
     DenseStorage(DenseStorage&& other) EIGEN_NOEXCEPT
       : m_data(std::move(other.m_data))
       , m_cols(std::move(other.m_cols))
     {
       other.m_data = nullptr;
@@ -481,16 +543,16 @@
     }
 #endif
     EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, _Rows*m_cols); }
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other) {
       numext::swap(m_data,other.m_data);
       numext::swap(m_cols,other.m_cols);
     }
-    EIGEN_DEVICE_FUNC static Index rows(void) {return _Rows;}
-    EIGEN_DEVICE_FUNC Index cols(void) const {return m_cols;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index rows(void) EIGEN_NOEXCEPT {return _Rows;}
+    EIGEN_DEVICE_FUNC Index cols(void) const EIGEN_NOEXCEPT {return m_cols;}
     EIGEN_DEVICE_FUNC void conservativeResize(Index size, Index, Index cols)
     {
       m_data = internal::conditional_aligned_realloc_new_auto<T,(_Options&DontAlign)==0>(m_data, size, _Rows*m_cols);
       m_cols = cols;
     }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize(Index size, Index, Index cols)
     {
@@ -534,15 +596,15 @@
     {
       if (this != &other)
       {
         DenseStorage tmp(other);
         this->swap(tmp);
       }
       return *this;
-    }    
+    }
 #if EIGEN_HAS_RVALUE_REFERENCES
     EIGEN_DEVICE_FUNC
     DenseStorage(DenseStorage&& other) EIGEN_NOEXCEPT
       : m_data(std::move(other.m_data))
       , m_rows(std::move(other.m_rows))
     {
       other.m_data = nullptr;
@@ -557,16 +619,16 @@
     }
 #endif
     EIGEN_DEVICE_FUNC ~DenseStorage() { internal::conditional_aligned_delete_auto<T,(_Options&DontAlign)==0>(m_data, _Cols*m_rows); }
     EIGEN_DEVICE_FUNC void swap(DenseStorage& other) {
       numext::swap(m_data,other.m_data);
       numext::swap(m_rows,other.m_rows);
     }
-    EIGEN_DEVICE_FUNC Index rows(void) const {return m_rows;}
-    EIGEN_DEVICE_FUNC static Index cols(void) {return _Cols;}
+    EIGEN_DEVICE_FUNC Index rows(void) const EIGEN_NOEXCEPT {return m_rows;}
+    EIGEN_DEVICE_FUNC static EIGEN_CONSTEXPR Index cols(void) {return _Cols;}
     void conservativeResize(Index size, Index rows, Index)
     {
       m_data = internal::conditional_aligned_realloc_new_auto<T,(_Options&DontAlign)==0>(m_data, size, m_rows*_Cols);
       m_rows = rows;
     }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void resize(Index size, Index rows, Index)
     {
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Diagonal.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Diagonal.h`

 * *Files 8% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_DIAGONAL_H
 #define EIGEN_DIAGONAL_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \class Diagonal
   * \ingroup Core_Module
   *
   * \brief Expression of a diagonal/subdiagonal/superdiagonal in a matrix
   *
   * \param MatrixType the type of the object in which we are taking a sub/main/super diagonal
@@ -80,28 +80,24 @@
     EIGEN_DEVICE_FUNC
     inline Index rows() const
     {
       return m_index.value()<0 ? numext::mini<Index>(m_matrix.cols(),m_matrix.rows()+m_index.value())
                                : numext::mini<Index>(m_matrix.rows(),m_matrix.cols()-m_index.value());
     }
 
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return 1; }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return 1; }
 
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const
-    {
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT {
       return m_matrix.outerStride() + 1;
     }
 
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const
-    {
-      return 0;
-    }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return 0; }
 
     typedef typename internal::conditional<
                        internal::is_lvalue<MatrixType>::value,
                        Scalar,
                        const Scalar
                      >::type ScalarWithConstIfNotLvalue;
 
@@ -145,16 +141,16 @@
     EIGEN_DEVICE_FUNC
     inline CoeffReturnType coeff(Index idx) const
     {
       return m_matrix.coeff(idx+rowOffset(), idx+colOffset());
     }
 
     EIGEN_DEVICE_FUNC
-    inline const typename internal::remove_all<typename MatrixType::Nested>::type& 
-    nestedExpression() const 
+    inline const typename internal::remove_all<typename MatrixType::Nested>::type&
+    nestedExpression() const
     {
       return m_matrix;
     }
 
     EIGEN_DEVICE_FUNC
     inline Index index() const
     {
@@ -163,20 +159,20 @@
 
   protected:
     typename internal::ref_selector<MatrixType>::non_const_type m_matrix;
     const internal::variable_if_dynamicindex<Index, DiagIndex> m_index;
 
   private:
     // some compilers may fail to optimize std::max etc in case of compile-time constants...
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index absDiagIndex() const { return m_index.value()>0 ? m_index.value() : -m_index.value(); }
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index rowOffset() const { return m_index.value()>0 ? 0 : -m_index.value(); }
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index colOffset() const { return m_index.value()>0 ? m_index.value() : 0; }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index absDiagIndex() const EIGEN_NOEXCEPT { return m_index.value()>0 ? m_index.value() : -m_index.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rowOffset() const EIGEN_NOEXCEPT { return m_index.value()>0 ? 0 : -m_index.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index colOffset() const EIGEN_NOEXCEPT { return m_index.value()>0 ? m_index.value() : 0; }
     // trigger a compile-time error if someone try to call packet
     template<int LoadMode> typename MatrixType::PacketReturnType packet(Index) const;
     template<int LoadMode> typename MatrixType::PacketReturnType packet(Index,Index) const;
 };
 
 /** \returns an expression of the main diagonal of the matrix \c *this
   *
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/DiagonalMatrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/DiagonalMatrix.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/DiagonalProduct.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/DiagonalProduct.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Dot.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Dot.h`

 * *Files 0% similar despite different names*

```diff
@@ -82,15 +82,15 @@
   eigen_assert(size() == other.size());
 
   return internal::dot_nocheck<Derived,OtherDerived>::run(*this, other);
 }
 
 //---------- implementation of L2 norm and related functions ----------
 
-/** \returns, for vectors, the squared \em l2 norm of \c *this, and for matrices the Frobenius norm.
+/** \returns, for vectors, the squared \em l2 norm of \c *this, and for matrices the squared Frobenius norm.
   * In both cases, it consists in the sum of the square of all the matrix entries.
   * For vectors, this is also equals to the dot product of \c *this with itself.
   *
   * \sa dot(), norm(), lpNorm()
   */
 template<typename Derived>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename NumTraits<typename internal::traits<Derived>::Scalar>::Real MatrixBase<Derived>::squaredNorm() const
@@ -203,15 +203,15 @@
 template<typename Derived, int p>
 struct lpNorm_selector
 {
   typedef typename NumTraits<typename traits<Derived>::Scalar>::Real RealScalar;
   EIGEN_DEVICE_FUNC
   static inline RealScalar run(const MatrixBase<Derived>& m)
   {
-    EIGEN_USING_STD_MATH(pow)
+    EIGEN_USING_STD(pow)
     return pow(m.cwiseAbs().array().pow(p).sum(), RealScalar(1)/p);
   }
 };
 
 template<typename Derived>
 struct lpNorm_selector<Derived, 1>
 {
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/EigenBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/EigenBase.h`

 * *Files 2% similar despite different names*

```diff
@@ -11,29 +11,29 @@
 #ifndef EIGEN_EIGENBASE_H
 #define EIGEN_EIGENBASE_H
 
 namespace Eigen {
 
 /** \class EigenBase
   * \ingroup Core_Module
-  * 
+  *
   * Common base class for all classes T such that MatrixBase has an operator=(T) and a constructor MatrixBase(T).
   *
   * In other words, an EigenBase object is an object that can be copied into a MatrixBase.
   *
   * Besides MatrixBase-derived classes, this also includes special matrix classes such as diagonal matrices, etc.
   *
   * Notice that this class is trivial, it is only used to disambiguate overloaded functions.
   *
   * \sa \blank \ref TopicClassHierarchy
   */
 template<typename Derived> struct EigenBase
 {
 //   typedef typename internal::plain_matrix_type<Derived>::type PlainObject;
-  
+
   /** \brief The interface type of indices
     * \details To change this, \c \#define the preprocessor symbol \c EIGEN_DEFAULT_DENSE_INDEX_TYPE.
     * \sa StorageIndex, \ref TopicPreprocessorDirectives.
     * DEPRECATED: Since Eigen 3.3, its usage is deprecated. Use Eigen::Index instead.
     * Deprecation is not marked with a doxygen comment because there are too many existing usages to add the deprecation attribute.
     */
   typedef Eigen::Index Index;
@@ -52,23 +52,23 @@
   inline Derived& const_cast_derived() const
   { return *static_cast<Derived*>(const_cast<EigenBase*>(this)); }
   EIGEN_DEVICE_FUNC
   inline const Derived& const_derived() const
   { return *static_cast<const Derived*>(this); }
 
   /** \returns the number of rows. \sa cols(), RowsAtCompileTime */
-  EIGEN_DEVICE_FUNC
-  inline Index rows() const { return derived().rows(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  inline Index rows() const EIGEN_NOEXCEPT { return derived().rows(); }
   /** \returns the number of columns. \sa rows(), ColsAtCompileTime*/
-  EIGEN_DEVICE_FUNC
-  inline Index cols() const { return derived().cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  inline Index cols() const EIGEN_NOEXCEPT { return derived().cols(); }
   /** \returns the number of coefficients, which is rows()*cols().
     * \sa rows(), cols(), SizeAtCompileTime. */
-  EIGEN_DEVICE_FUNC
-  inline Index size() const { return rows() * cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  inline Index size() const EIGEN_NOEXCEPT { return rows() * cols(); }
 
   /** \internal Don't use it, but do the equivalent: \code dst = *this; \endcode */
   template<typename Dest>
   EIGEN_DEVICE_FUNC
   inline void evalTo(Dest& dst) const
   { derived().evalTo(dst); }
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ForceAlignedAccess.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ForceAlignedAccess.h`

 * *Files 7% similar despite different names*

```diff
@@ -37,18 +37,22 @@
   public:
 
     typedef typename internal::dense_xpr_base<ForceAlignedAccess>::type Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(ForceAlignedAccess)
 
     EIGEN_DEVICE_FUNC explicit inline ForceAlignedAccess(const ExpressionType& matrix) : m_expression(matrix) {}
 
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_expression.rows(); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_expression.cols(); }
-    EIGEN_DEVICE_FUNC inline Index outerStride() const { return m_expression.outerStride(); }
-    EIGEN_DEVICE_FUNC inline Index innerStride() const { return m_expression.innerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_expression.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_expression.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return m_expression.outerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return m_expression.innerStride(); }
 
     EIGEN_DEVICE_FUNC inline const CoeffReturnType coeff(Index row, Index col) const
     {
       return m_expression.coeff(row, col);
     }
 
     EIGEN_DEVICE_FUNC inline Scalar& coeffRef(Index row, Index col)
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Fuzzy.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Fuzzy.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/GeneralProduct.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/GeneralProduct.h`

 * *Files 2% similar despite different names*

```diff
@@ -224,16 +224,15 @@
     typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
   
     typedef Map<Matrix<ResScalar,Dynamic,1>, EIGEN_PLAIN_ENUM_MIN(AlignedMax,internal::packet_traits<ResScalar>::size)> MappedDest;
 
     ActualLhsType actualLhs = LhsBlasTraits::extract(lhs);
     ActualRhsType actualRhs = RhsBlasTraits::extract(rhs);
 
-    ResScalar actualAlpha = alpha * LhsBlasTraits::extractScalarFactor(lhs)
-                                  * RhsBlasTraits::extractScalarFactor(rhs);
+    ResScalar actualAlpha = combine_scalar_factors(alpha, lhs, rhs);
 
     // make sure Dest is a compile-time vector type (bug 1166)
     typedef typename conditional<Dest::IsVectorAtCompileTime, Dest, typename Dest::ColXpr>::type ActualDest;
 
     enum {
       // FIXME find a way to allow an inner stride on the result if packet_traits<Scalar>::size==1
       // on, the other hand it is good for the cache to pack the vector anyways...
@@ -316,16 +315,15 @@
     typedef internal::blas_traits<Rhs> RhsBlasTraits;
     typedef typename RhsBlasTraits::DirectLinearAccessType ActualRhsType;
     typedef typename internal::remove_all<ActualRhsType>::type ActualRhsTypeCleaned;
 
     typename add_const<ActualLhsType>::type actualLhs = LhsBlasTraits::extract(lhs);
     typename add_const<ActualRhsType>::type actualRhs = RhsBlasTraits::extract(rhs);
 
-    ResScalar actualAlpha = alpha * LhsBlasTraits::extractScalarFactor(lhs)
-                                  * RhsBlasTraits::extractScalarFactor(rhs);
+    ResScalar actualAlpha = combine_scalar_factors(alpha, lhs, rhs);
 
     enum {
       // FIXME find a way to allow an inner stride on the result if packet_traits<Scalar>::size==1
       // on, the other hand it is good for the cache to pack the vector anyways...
       DirectlyUseRhs = ActualRhsTypeCleaned::InnerStrideAtCompileTime==1 || ActualRhsTypeCleaned::MaxSizeAtCompileTime==0
     };
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/GenericPacketMath.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/GenericPacketMath.h`

 * *Files 24% similar despite different names*

```diff
@@ -40,27 +40,31 @@
 #endif
 
 struct default_packet_traits
 {
   enum {
     HasHalfPacket = 0,
 
-    HasAdd    = 1,
-    HasSub    = 1,
-    HasMul    = 1,
-    HasNegate = 1,
-    HasAbs    = 1,
-    HasArg    = 0,
-    HasAbs2   = 1,
-    HasMin    = 1,
-    HasMax    = 1,
-    HasConj   = 1,
+    HasAdd       = 1,
+    HasSub       = 1,
+    HasShift     = 1,
+    HasMul       = 1,
+    HasNegate    = 1,
+    HasAbs       = 1,
+    HasArg       = 0,
+    HasAbs2      = 1,
+    HasAbsDiff   = 0,
+    HasMin       = 1,
+    HasMax       = 1,
+    HasConj      = 1,
     HasSetLinear = 1,
-    HasBlend  = 0,
-    HasReduxp = 1,
+    HasBlend     = 0,
+    // This flag is used to indicate whether packet comparison is supported.
+    // pcmp_eq, pcmp_lt and pcmp_le should be defined for it to be true.
+    HasCmp       = 0,
 
     HasDiv    = 0,
     HasSqrt   = 0,
     HasRsqrt  = 0,
     HasExp    = 0,
     HasExpm1  = 0,
     HasLog    = 0,
@@ -79,26 +83,26 @@
     HasTanh   = 0,
     HasLGamma = 0,
     HasDiGamma = 0,
     HasZeta = 0,
     HasPolygamma = 0,
     HasErf = 0,
     HasErfc = 0,
-    HasI0e = 0,
-    HasI1e = 0,
+    HasNdtri = 0,
+    HasBessel = 0,
     HasIGamma = 0,
     HasIGammaDerA = 0,
     HasGammaSampleDerAlpha = 0,
     HasIGammac = 0,
     HasBetaInc = 0,
 
     HasRound  = 0,
+    HasRint   = 0,
     HasFloor  = 0,
     HasCeil   = 0,
-
     HasSign   = 0
   };
 };
 
 template<typename T> struct packet_traits : default_packet_traits
 {
   typedef T type;
@@ -121,167 +125,478 @@
     HasConj   = 0,
     HasSetLinear = 0
   };
 };
 
 template<typename T> struct packet_traits<const T> : packet_traits<T> { };
 
+template<typename T> struct unpacket_traits
+{
+  typedef T type;
+  typedef T half;
+  enum
+  {
+    size = 1,
+    alignment = 1,
+    vectorizable = false,
+    masked_load_available=false,
+    masked_store_available=false
+  };
+};
+
+template<typename T> struct unpacket_traits<const T> : unpacket_traits<T> { };
+
 template <typename Src, typename Tgt> struct type_casting_traits {
   enum {
     VectorizedCast = 0,
     SrcCoeffRatio = 1,
     TgtCoeffRatio = 1
   };
 };
 
+/** \internal Wrapper to ensure that multiple packet types can map to the same
+    same underlying vector type. */
+template<typename T, int unique_id = 0>
+struct eigen_packet_wrapper
+{
+  EIGEN_ALWAYS_INLINE operator T&() { return m_val; }
+  EIGEN_ALWAYS_INLINE operator const T&() const { return m_val; }
+  EIGEN_ALWAYS_INLINE eigen_packet_wrapper() {}
+  EIGEN_ALWAYS_INLINE eigen_packet_wrapper(const T &v) : m_val(v) {}
+  EIGEN_ALWAYS_INLINE eigen_packet_wrapper& operator=(const T &v) {
+    m_val = v;
+    return *this;
+  }
+
+  T m_val;
+};
+
+
+/** \internal A convenience utility for determining if the type is a scalar.
+ * This is used to enable some generic packet implementations.
+ */
+template<typename Packet>
+struct is_scalar {
+  typedef typename unpacket_traits<Packet>::type Scalar;
+  enum {
+    value = internal::is_same<Packet, Scalar>::value
+  };
+};
 
 /** \internal \returns static_cast<TgtType>(a) (coeff-wise) */
 template <typename SrcPacket, typename TgtPacket>
 EIGEN_DEVICE_FUNC inline TgtPacket
 pcast(const SrcPacket& a) {
   return static_cast<TgtPacket>(a);
 }
 template <typename SrcPacket, typename TgtPacket>
 EIGEN_DEVICE_FUNC inline TgtPacket
 pcast(const SrcPacket& a, const SrcPacket& /*b*/) {
   return static_cast<TgtPacket>(a);
 }
-
 template <typename SrcPacket, typename TgtPacket>
 EIGEN_DEVICE_FUNC inline TgtPacket
 pcast(const SrcPacket& a, const SrcPacket& /*b*/, const SrcPacket& /*c*/, const SrcPacket& /*d*/) {
   return static_cast<TgtPacket>(a);
 }
+template <typename SrcPacket, typename TgtPacket>
+EIGEN_DEVICE_FUNC inline TgtPacket
+pcast(const SrcPacket& a, const SrcPacket& /*b*/, const SrcPacket& /*c*/, const SrcPacket& /*d*/,
+      const SrcPacket& /*e*/, const SrcPacket& /*f*/, const SrcPacket& /*g*/, const SrcPacket& /*h*/) {
+  return static_cast<TgtPacket>(a);
+}
 
 /** \internal \returns reinterpret_cast<Target>(a) */
 template <typename Target, typename Packet>
 EIGEN_DEVICE_FUNC inline Target
 preinterpret(const Packet& a); /* { return reinterpret_cast<const Target&>(a); } */
 
 /** \internal \returns a + b (coeff-wise) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 padd(const Packet& a, const Packet& b) { return a+b; }
+// Avoid compiler warning for boolean algebra.
+template<> EIGEN_DEVICE_FUNC inline bool
+padd(const bool& a, const bool& b) { return a || b; }
 
 /** \internal \returns a - b (coeff-wise) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 psub(const Packet& a, const Packet& b) { return a-b; }
 
 /** \internal \returns -a (coeff-wise) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 pnegate(const Packet& a) { return -a; }
 
-/** \internal \returns conj(a) (coeff-wise) */
+template<> EIGEN_DEVICE_FUNC inline bool
+pnegate(const bool& a) { return !a; }
 
+/** \internal \returns conj(a) (coeff-wise) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 pconj(const Packet& a) { return numext::conj(a); }
 
 /** \internal \returns a * b (coeff-wise) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 pmul(const Packet& a, const Packet& b) { return a*b; }
+// Avoid compiler warning for boolean algebra.
+template<> EIGEN_DEVICE_FUNC inline bool
+pmul(const bool& a, const bool& b) { return a && b; }
 
 /** \internal \returns a / b (coeff-wise) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 pdiv(const Packet& a, const Packet& b) { return a/b; }
 
-/** \internal \returns the min of \a a and \a b  (coeff-wise) */
+// In the generic case, memset to all one bits.
+template<typename Packet, typename EnableIf = void>
+struct ptrue_impl {
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& /*a*/){
+    Packet b;
+    memset(static_cast<void*>(&b), 0xff, sizeof(Packet));
+    return b;
+  }
+};
+
+// For non-trivial scalars, set to Scalar(1) (i.e. a non-zero value).
+// Although this is technically not a valid bitmask, the scalar path for pselect
+// uses a comparison to zero, so this should still work in most cases. We don't
+// have another option, since the scalar type requires initialization.
+template<typename T>
+struct ptrue_impl<T, 
+    typename internal::enable_if<is_scalar<T>::value && NumTraits<T>::RequireInitialization>::type > {
+  static EIGEN_DEVICE_FUNC inline T run(const T& /*a*/){
+    return T(1);
+  }
+};
+
+/** \internal \returns one bits. */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pmin(const Packet& a, const Packet& b) { return numext::mini(a, b); }
+ptrue(const Packet& a) {
+  return ptrue_impl<Packet>::run(a);
+}
 
-/** \internal \returns the max of \a a and \a b  (coeff-wise) */
+// In the general case, memset to zero.
+template<typename Packet, typename EnableIf = void>
+struct pzero_impl {
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& /*a*/) {
+    Packet b;
+    memset(static_cast<void*>(&b), 0x00, sizeof(Packet));
+    return b;
+  }
+};
+
+// For scalars, explicitly set to Scalar(0), since the underlying representation
+// for zero may not consist of all-zero bits.
+template<typename T>
+struct pzero_impl<T,
+    typename internal::enable_if<is_scalar<T>::value>::type> {
+  static EIGEN_DEVICE_FUNC inline T run(const T& /*a*/) {
+    return T(0);
+  }
+};
+
+/** \internal \returns packet of zeros */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pmax(const Packet& a, const Packet& b) { return numext::maxi(a, b); }
+pzero(const Packet& a) {
+  return pzero_impl<Packet>::run(a);
+}
 
-/** \internal \returns the absolute value of \a a */
+/** \internal \returns a <= b as a bit mask */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pcmp_le(const Packet& a, const Packet& b)  { return a<=b ? ptrue(a) : pzero(a); }
+
+/** \internal \returns a < b as a bit mask */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pabs(const Packet& a) { using std::abs; return abs(a); }
+pcmp_lt(const Packet& a, const Packet& b)  { return a<b ? ptrue(a) : pzero(a); }
 
-/** \internal \returns the phase angle of \a a */
+/** \internal \returns a == b as a bit mask */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-parg(const Packet& a) { using numext::arg; return arg(a); }
+pcmp_eq(const Packet& a, const Packet& b) { return a==b ? ptrue(a) : pzero(a); }
+
+/** \internal \returns a < b or a==NaN or b==NaN as a bit mask */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pcmp_lt_or_nan(const Packet& a, const Packet& b) { return a>=b ? pzero(a) : ptrue(a); }
+
+template<typename T>
+struct bit_and {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a, const T& b) const {
+    return a & b;
+  }
+};
+
+template<typename T>
+struct bit_or {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a, const T& b) const {
+    return a | b;
+  }
+};
+
+template<typename T>
+struct bit_xor {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a, const T& b) const {
+    return a ^ b;
+  }
+};
+
+template<typename T>
+struct bit_not {
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR EIGEN_ALWAYS_INLINE T operator()(const T& a) const {
+    return ~a;
+  }
+};
+
+// Use operators &, |, ^, ~.
+template<typename T>
+struct operator_bitwise_helper {
+  EIGEN_DEVICE_FUNC static inline T bitwise_and(const T& a, const T& b) { return bit_and<T>()(a, b); }
+  EIGEN_DEVICE_FUNC static inline T bitwise_or(const T& a, const T& b) { return bit_or<T>()(a, b); }
+  EIGEN_DEVICE_FUNC static inline T bitwise_xor(const T& a, const T& b) { return bit_xor<T>()(a, b); }
+  EIGEN_DEVICE_FUNC static inline T bitwise_not(const T& a) { return bit_not<T>()(a); }
+};
+
+// Apply binary operations byte-by-byte
+template<typename T>
+struct bytewise_bitwise_helper {
+  EIGEN_DEVICE_FUNC static inline T bitwise_and(const T& a, const T& b) {
+    return binary(a, b, bit_and<unsigned char>());
+  }
+  EIGEN_DEVICE_FUNC static inline T bitwise_or(const T& a, const T& b) { 
+    return binary(a, b, bit_or<unsigned char>());
+   }
+  EIGEN_DEVICE_FUNC static inline T bitwise_xor(const T& a, const T& b) {
+    return binary(a, b, bit_xor<unsigned char>());
+  }
+  EIGEN_DEVICE_FUNC static inline T bitwise_not(const T& a) { 
+    return unary(a,bit_not<unsigned char>());
+   }
+  
+ private:
+  template<typename Op>
+  EIGEN_DEVICE_FUNC static inline T unary(const T& a, Op op) {
+    const unsigned char* a_ptr = reinterpret_cast<const unsigned char*>(&a);
+    T c;
+    unsigned char* c_ptr = reinterpret_cast<unsigned char*>(&c);
+    for (size_t i = 0; i < sizeof(T); ++i) {
+      *c_ptr++ = op(*a_ptr++);
+    }
+    return c;
+  }
+
+  template<typename Op>
+  EIGEN_DEVICE_FUNC static inline T binary(const T& a, const T& b, Op op) {
+    const unsigned char* a_ptr = reinterpret_cast<const unsigned char*>(&a);
+    const unsigned char* b_ptr = reinterpret_cast<const unsigned char*>(&b);
+    T c;
+    unsigned char* c_ptr = reinterpret_cast<unsigned char*>(&c);
+    for (size_t i = 0; i < sizeof(T); ++i) {
+      *c_ptr++ = op(*a_ptr++, *b_ptr++);
+    }
+    return c;
+  }
+};
+
+// In the general case, use byte-by-byte manipulation.
+template<typename T, typename EnableIf = void>
+struct bitwise_helper : public bytewise_bitwise_helper<T> {};
+
+// For integers or non-trivial scalars, use binary operators.
+template<typename T>
+struct bitwise_helper<T,
+  typename internal::enable_if<
+    is_scalar<T>::value && (NumTraits<T>::IsInteger || NumTraits<T>::RequireInitialization)>::type
+  > : public operator_bitwise_helper<T> {};
 
 /** \internal \returns the bitwise and of \a a and \a b */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pand(const Packet& a, const Packet& b) { return a & b; }
+pand(const Packet& a, const Packet& b) {
+  return bitwise_helper<Packet>::bitwise_and(a, b);
+}
 
 /** \internal \returns the bitwise or of \a a and \a b */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-por(const Packet& a, const Packet& b) { return a | b; }
+por(const Packet& a, const Packet& b) {
+  return bitwise_helper<Packet>::bitwise_or(a, b);
+}
 
 /** \internal \returns the bitwise xor of \a a and \a b */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pxor(const Packet& a, const Packet& b) { return a ^ b; }
+pxor(const Packet& a, const Packet& b) {
+  return bitwise_helper<Packet>::bitwise_xor(a, b);
+}
 
-/** \internal \returns the bitwise andnot of \a a and \a b */
+/** \internal \returns the bitwise not of \a a */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pandnot(const Packet& a, const Packet& b) { return a & (~b); }
+pnot(const Packet& a) {
+  return bitwise_helper<Packet>::bitwise_not(a);
+}
 
-/** \internal \returns ones */
+/** \internal \returns the bitwise and of \a a and not \a b */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-ptrue(const Packet& /*a*/) { Packet b; memset((void*)&b, 0xff, sizeof(b)); return b;}
+pandnot(const Packet& a, const Packet& b) { return pand(a, pnot(b)); }
+
+// In the general case, use bitwise select.
+template<typename Packet, typename EnableIf = void>
+struct pselect_impl {
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& mask, const Packet& a, const Packet& b) {
+    return por(pand(a,mask),pandnot(b,mask));
+  }
+};
 
-template <typename RealScalar>
-EIGEN_DEVICE_FUNC inline std::complex<RealScalar> ptrue(const std::complex<RealScalar>& /*a*/) {
-  RealScalar b;
-  b = ptrue(b);
-  return std::complex<RealScalar>(b, b);
+// For scalars, use ternary select.
+template<typename Packet>
+struct pselect_impl<Packet, 
+    typename internal::enable_if<is_scalar<Packet>::value>::type > {
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& mask, const Packet& a, const Packet& b) {
+    return numext::equal_strict(mask, Packet(0)) ? b : a;
+  }
+};
+
+/** \internal \returns \a or \b for each field in packet according to \mask */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pselect(const Packet& mask, const Packet& a, const Packet& b) {
+  return pselect_impl<Packet>::run(mask, a, b);
 }
 
-/** \internal \returns the bitwise not of \a a */
-template <typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pnot(const Packet& a) { return pxor(ptrue(a), a);}
+template<> EIGEN_DEVICE_FUNC inline bool pselect<bool>(
+    const bool& cond, const bool& a, const bool& b) {
+  return cond ? a : b;
+}
+
+/** \internal \returns the min or of \a a and \a b (coeff-wise)
+    If either \a a or \a b are NaN, the result is implementation defined. */
+template<int NaNPropagation>
+struct pminmax_impl {
+  template <typename Packet, typename Op>
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a, const Packet& b, Op op) {
+    return op(a,b);
+  }
+};
+
+/** \internal \returns the min or max of \a a and \a b (coeff-wise)
+    If either \a a or \a b are NaN, NaN is returned. */
+template<>
+struct pminmax_impl<PropagateNaN> {
+  template <typename Packet, typename Op>
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a, const Packet& b, Op op) {
+  Packet not_nan_mask_a = pcmp_eq(a, a);
+  Packet not_nan_mask_b = pcmp_eq(b, b);
+  return pselect(not_nan_mask_a,
+                 pselect(not_nan_mask_b, op(a, b), b),
+                 a);
+  }
+};
+
+/** \internal \returns the min or max of \a a and \a b (coeff-wise)
+    If both \a a and \a b are NaN, NaN is returned.
+    Equivalent to std::fmin(a, b).  */
+template<>
+struct pminmax_impl<PropagateNumbers> {
+  template <typename Packet, typename Op>
+  static EIGEN_DEVICE_FUNC inline Packet run(const Packet& a, const Packet& b, Op op) {
+  Packet not_nan_mask_a = pcmp_eq(a, a);
+  Packet not_nan_mask_b = pcmp_eq(b, b);
+  return pselect(not_nan_mask_a,
+                 pselect(not_nan_mask_b, op(a, b), a),
+                 b);
+  }
+};
+
+
+#ifndef SYCL_DEVICE_ONLY
+#define EIGEN_BINARY_OP_NAN_PROPAGATION(Type, Func) Func
+#else
+#define EIGEN_BINARY_OP_NAN_PROPAGATION(Type, Func) \
+[](const Type& a, const Type& b) { \
+        return Func(a, b);}
+#endif
+
+/** \internal \returns the min of \a a and \a b  (coeff-wise).
+    If \a a or \b b is NaN, the return value is implementation defined. */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pmin(const Packet& a, const Packet& b) { return numext::mini(a,b); }
+
+/** \internal \returns the min of \a a and \a b  (coeff-wise).
+    NaNPropagation determines the NaN propagation semantics. */
+template <int NaNPropagation, typename Packet>
+EIGEN_DEVICE_FUNC inline Packet pmin(const Packet& a, const Packet& b) {
+  return pminmax_impl<NaNPropagation>::run(a, b, EIGEN_BINARY_OP_NAN_PROPAGATION(Packet, (pmin<Packet>)));
+}
+
+/** \internal \returns the max of \a a and \a b  (coeff-wise)
+    If \a a or \b b is NaN, the return value is implementation defined. */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pmax(const Packet& a, const Packet& b) { return numext::maxi(a, b); }
+
+/** \internal \returns the max of \a a and \a b  (coeff-wise).
+    NaNPropagation determines the NaN propagation semantics. */
+template <int NaNPropagation, typename Packet>
+EIGEN_DEVICE_FUNC inline Packet pmax(const Packet& a, const Packet& b) {
+  return pminmax_impl<NaNPropagation>::run(a, b, EIGEN_BINARY_OP_NAN_PROPAGATION(Packet,(pmax<Packet>)));
+}
+
+/** \internal \returns the absolute value of \a a */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+pabs(const Packet& a) { return numext::abs(a); }
+template<> EIGEN_DEVICE_FUNC inline unsigned int
+pabs(const unsigned int& a) { return a; }
+template<> EIGEN_DEVICE_FUNC inline unsigned long
+pabs(const unsigned long& a) { return a; }
+template<> EIGEN_DEVICE_FUNC inline unsigned long long
+pabs(const unsigned long long& a) { return a; }
+
+/** \internal \returns the addsub value of \a a,b */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+paddsub(const Packet& a, const Packet& b) {
+  return pselect(peven_mask(a), padd(a, b), psub(a, b));
+ }
+
+/** \internal \returns the phase angle of \a a */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+parg(const Packet& a) { using numext::arg; return arg(a); }
 
-/** \internal \returns \a a shifted by N bits to the right */
+
+/** \internal \returns \a a logically shifted by N bits to the right */
+template<int N> EIGEN_DEVICE_FUNC inline int
+parithmetic_shift_right(const int& a) { return a >> N; }
+template<int N> EIGEN_DEVICE_FUNC inline long int
+parithmetic_shift_right(const long int& a) { return a >> N; }
+
+/** \internal \returns \a a arithmetically shifted by N bits to the right */
 template<int N> EIGEN_DEVICE_FUNC inline int
-pshiftright(const int& a) { return a >> N; }
+plogical_shift_right(const int& a) { return static_cast<int>(static_cast<unsigned int>(a) >> N); }
 template<int N> EIGEN_DEVICE_FUNC inline long int
-pshiftright(const long int& a) { return a >> N; }
+plogical_shift_right(const long int& a) { return static_cast<long>(static_cast<unsigned long>(a) >> N); }
 
 /** \internal \returns \a a shifted by N bits to the left */
 template<int N> EIGEN_DEVICE_FUNC inline int
-pshiftleft(const int& a) { return a << N; }
+plogical_shift_left(const int& a) { return a << N; }
 template<int N> EIGEN_DEVICE_FUNC inline long int
-pshiftleft(const long int& a) { return a << N; }
+plogical_shift_left(const long int& a) { return a << N; }
 
 /** \internal \returns the significant and exponent of the underlying floating point numbers
   * See https://en.cppreference.com/w/cpp/numeric/math/frexp
   */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pfrexp(const Packet &a, Packet &exponent) { return std::frexp(a,&exponent); }
+template <typename Packet>
+EIGEN_DEVICE_FUNC inline Packet pfrexp(const Packet& a, Packet& exponent) {
+  int exp;
+  EIGEN_USING_STD(frexp);
+  Packet result = static_cast<Packet>(frexp(a, &exp));
+  exponent = static_cast<Packet>(exp);
+  return result;
+}
 
-/** \internal \returns a * 2^exponent
+/** \internal \returns a * 2^((int)exponent)
   * See https://en.cppreference.com/w/cpp/numeric/math/ldexp
   */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pldexp(const Packet &a, const Packet &exponent) { return std::ldexp(a,exponent); }
-
-/** \internal \returns zeros */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pzero(const Packet& a) { return pxor(a,a); }
-
-/** \internal \returns bits of \a or \b according to the input bit mask \a mask */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pselect(const Packet& mask, const Packet& a, const Packet& b) {
-  return por(pand(a,mask),pandnot(b,mask));
+pldexp(const Packet &a, const Packet &exponent) {
+  EIGEN_USING_STD(ldexp)
+  return static_cast<Packet>(ldexp(a, static_cast<int>(exponent)));
 }
 
-/** \internal \returns a <= b as a bit mask */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pcmp_le(const Packet& a, const Packet& b)  { return a<=b ? ptrue(a) : pzero(a); }
-
-/** \internal \returns a < b as a bit mask */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pcmp_lt(const Packet& a, const Packet& b)  { return a<b ? ptrue(a) : pzero(a); }
-
-/** \internal \returns a == b as a bit mask */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pcmp_eq(const Packet& a, const Packet& b) { return a==b ? ptrue(a) : pzero(a); }
-
-/** \internal \returns a < b or a==NaN or b==NaN as a bit mask */
+/** \internal \returns the min of \a a and \a b  (coeff-wise) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pcmp_lt_or_nan(const Packet& a, const Packet& b) { return pnot(pcmp_le(b,a)); } 
+pabsdiff(const Packet& a, const Packet& b) { return pselect(pcmp_lt(a, b), psub(b, a), psub(a, b)); }
 
 /** \internal \returns a packet version of \a *from, from must be 16 bytes aligned */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 pload(const typename unpacket_traits<Packet>::type* from) { return *from; }
 
 /** \internal \returns a packet version of \a *from, (un-aligned load) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
@@ -315,15 +630,15 @@
 template<typename Packet> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet
 ploaddup(const typename unpacket_traits<Packet>::type* from) { return *from; }
 
 /** \internal \returns a packet with elements of \a *from quadrupled.
   * For instance, for a packet of 8 elements, 2 scalars will be read from \a *from and
   * replicated to form: {from[0],from[0],from[0],from[0],from[1],from[1],from[1],from[1]}
   * Currently, this function is only used in matrix products.
-  * For packet-size smaller or equal to 4, this function is equivalent to pload1 
+  * For packet-size smaller or equal to 4, this function is equivalent to pload1
   */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 ploadquad(const typename unpacket_traits<Packet>::type* from)
 { return pload1<Packet>(from); }
 
 /** \internal equivalent to
   * \code
@@ -359,14 +674,28 @@
   a1 = pload1<Packet>(a+1);
 }
 
 /** \internal \brief Returns a packet with coefficients (a,a+1,...,a+packet_size-1). */
 template<typename Packet> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet
 plset(const typename unpacket_traits<Packet>::type& a) { return a; }
 
+/** \internal \returns a packet with constant coefficients \a a, e.g.: (x, 0, x, 0),
+     where x is the value of all 1-bits. */
+template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
+peven_mask(const Packet& /*a*/) {
+  typedef typename unpacket_traits<Packet>::type Scalar;
+  const size_t n = unpacket_traits<Packet>::size;
+  EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) Scalar elements[n];
+  for(size_t i = 0; i < n; ++i) {
+    memset(elements+i, ((i & 1) == 0 ? 0xff : 0), sizeof(Scalar));
+  }
+  return ploadu<Packet>(elements);
+}
+
+
 /** \internal copy the packet \a from to \a *to, \a to must be 16 bytes aligned */
 template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstore(Scalar* to, const Packet& from)
 { (*to) = from; }
 
 /** \internal copy the packet \a from to \a *to, (un-aligned store) */
 template<typename Scalar, typename Packet> EIGEN_DEVICE_FUNC inline void pstoreu(Scalar* to, const Packet& from)
 {  (*to) = from; }
@@ -388,175 +717,232 @@
 
 /** \internal tries to do cache prefetching of \a addr */
 template<typename Scalar> EIGEN_DEVICE_FUNC inline void prefetch(const Scalar* addr)
 {
 #if defined(EIGEN_HIP_DEVICE_COMPILE)
   // do nothing
 #elif defined(EIGEN_CUDA_ARCH)
-#if defined(__LP64__)
+#if defined(__LP64__) || EIGEN_OS_WIN64
   // 64-bit pointer operand constraint for inlined asm
   asm(" prefetch.L1 [ %1 ];" : "=l"(addr) : "l"(addr));
 #else
   // 32-bit pointer operand constraint for inlined asm
   asm(" prefetch.L1 [ %1 ];" : "=r"(addr) : "r"(addr));
 #endif
 #elif (!EIGEN_COMP_MSVC) && (EIGEN_COMP_GNUC || EIGEN_COMP_CLANG || EIGEN_COMP_ICC)
   __builtin_prefetch(addr);
 #endif
 }
 
-/** \internal \returns the first element of a packet */
-template<typename Packet> EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type pfirst(const Packet& a)
-{ return a; }
-
-/** \internal \returns a packet where the element i contains the sum of the packet of \a vec[i] */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-preduxp(const Packet* vecs) { return vecs[0]; }
-
-/** \internal \returns the sum of the elements of \a a*/
-template<typename Packet> EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux(const Packet& a)
-{ return a; }
-
-/** \internal \returns the sum of the elements of upper and lower half of \a a if \a a is larger than 4.
-  * For a packet {a0, a1, a2, a3, a4, a5, a6, a7}, it returns a half packet {a0+a4, a1+a5, a2+a6, a3+a7}
-  * For packet-size smaller or equal to 4, this boils down to a noop.
-  */
-template<typename Packet> EIGEN_DEVICE_FUNC inline
-typename conditional<(unpacket_traits<Packet>::size%8)==0,typename unpacket_traits<Packet>::half,Packet>::type
-predux_half_dowto4(const Packet& a)
-{ return a; }
-
-/** \internal \returns the product of the elements of \a a */
-template<typename Packet> EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_mul(const Packet& a)
-{ return a; }
-
-/** \internal \returns the min of the elements of \a a */
-template<typename Packet> EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_min(const Packet& a)
-{ return a; }
-
-/** \internal \returns the max of the elements of \a a */
-template<typename Packet> EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_max(const Packet& a)
-{ return a; }
-
-/** \internal \returns true if all coeffs of \a a means "true"
-  * It is supposed to be called on values returned by pcmp_*.
-  */
-// not needed yet
-// template<typename Packet> EIGEN_DEVICE_FUNC inline bool predux_all(const Packet& a)
-// { return bool(a); }
-
-/** \internal \returns true if any coeffs of \a a means "true"
-  * It is supposed to be called on values returned by pcmp_*.
-  */
-template<typename Packet> EIGEN_DEVICE_FUNC inline bool predux_any(const Packet& a)
-{
-  // Dirty but generic implementation where "true" is assumed to be non 0 and all the sames.
-  // It is expected that "true" is either:
-  //  - Scalar(1)
-  //  - bits full of ones (NaN for floats),
-  //  - or first bit equals to 1 (1 for ints, smallest denormal for floats).
-  // For all these cases, taking the sum is just fine, and this boils down to a no-op for scalars.
-  return bool(predux(a));
-}
-
 /** \internal \returns the reversed elements of \a a*/
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet preverse(const Packet& a)
 { return a; }
 
 /** \internal \returns \a a with real and imaginary part flipped (for complex type only) */
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet pcplxflip(const Packet& a)
 {
-  // FIXME: uncomment the following in case we drop the internal imag and real functions.
-//   using std::imag;
-//   using std::real;
-  return Packet(imag(a),real(a));
+  return Packet(numext::imag(a),numext::real(a));
 }
 
 /**************************
 * Special math functions
 ***************************/
 
 /** \internal \returns the sine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet psin(const Packet& a) { using std::sin; return sin(a); }
+Packet psin(const Packet& a) { EIGEN_USING_STD(sin); return sin(a); }
 
 /** \internal \returns the cosine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet pcos(const Packet& a) { using std::cos; return cos(a); }
+Packet pcos(const Packet& a) { EIGEN_USING_STD(cos); return cos(a); }
 
 /** \internal \returns the tan of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet ptan(const Packet& a) { using std::tan; return tan(a); }
+Packet ptan(const Packet& a) { EIGEN_USING_STD(tan); return tan(a); }
 
 /** \internal \returns the arc sine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet pasin(const Packet& a) { using std::asin; return asin(a); }
+Packet pasin(const Packet& a) { EIGEN_USING_STD(asin); return asin(a); }
 
 /** \internal \returns the arc cosine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet pacos(const Packet& a) { using std::acos; return acos(a); }
+Packet pacos(const Packet& a) { EIGEN_USING_STD(acos); return acos(a); }
 
 /** \internal \returns the arc tangent of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet patan(const Packet& a) { using std::atan; return atan(a); }
+Packet patan(const Packet& a) { EIGEN_USING_STD(atan); return atan(a); }
 
 /** \internal \returns the hyperbolic sine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet psinh(const Packet& a) { using std::sinh; return sinh(a); }
+Packet psinh(const Packet& a) { EIGEN_USING_STD(sinh); return sinh(a); }
 
 /** \internal \returns the hyperbolic cosine of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet pcosh(const Packet& a) { using std::cosh; return cosh(a); }
+Packet pcosh(const Packet& a) { EIGEN_USING_STD(cosh); return cosh(a); }
 
 /** \internal \returns the hyperbolic tan of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet ptanh(const Packet& a) { using std::tanh; return tanh(a); }
+Packet ptanh(const Packet& a) { EIGEN_USING_STD(tanh); return tanh(a); }
 
 /** \internal \returns the exp of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet pexp(const Packet& a) { using std::exp; return exp(a); }
+Packet pexp(const Packet& a) { EIGEN_USING_STD(exp); return exp(a); }
 
 /** \internal \returns the expm1 of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet pexpm1(const Packet& a) { return numext::expm1(a); }
 
 /** \internal \returns the log of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet plog(const Packet& a) { using std::log; return log(a); }
+Packet plog(const Packet& a) { EIGEN_USING_STD(log); return log(a); }
 
 /** \internal \returns the log1p of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet plog1p(const Packet& a) { return numext::log1p(a); }
 
 /** \internal \returns the log10 of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet plog10(const Packet& a) { using std::log10; return log10(a); }
+Packet plog10(const Packet& a) { EIGEN_USING_STD(log10); return log10(a); }
+
+/** \internal \returns the log10 of \a a (coeff-wise) */
+template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
+Packet plog2(const Packet& a) {
+  typedef typename internal::unpacket_traits<Packet>::type Scalar;
+  return pmul(pset1<Packet>(Scalar(EIGEN_LOG2E)), plog(a)); 
+}
 
 /** \internal \returns the square-root of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
-Packet psqrt(const Packet& a) { using std::sqrt; return sqrt(a); }
+Packet psqrt(const Packet& a) { return numext::sqrt(a); }
 
 /** \internal \returns the reciprocal square-root of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet prsqrt(const Packet& a) {
-  return pdiv(pset1<Packet>(1), psqrt(a));
+  typedef typename internal::unpacket_traits<Packet>::type Scalar;
+  return pdiv(pset1<Packet>(Scalar(1)), psqrt(a));
 }
 
 /** \internal \returns the rounded value of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet pround(const Packet& a) { using numext::round; return round(a); }
 
 /** \internal \returns the floor of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet pfloor(const Packet& a) { using numext::floor; return floor(a); }
 
+/** \internal \returns the rounded value of \a a (coeff-wise) with current
+ * rounding mode */
+template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
+Packet print(const Packet& a) { using numext::rint; return rint(a); }
+
 /** \internal \returns the ceil of \a a (coeff-wise) */
 template<typename Packet> EIGEN_DECLARE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS
 Packet pceil(const Packet& a) { using numext::ceil; return ceil(a); }
 
+/** \internal \returns the first element of a packet */
+template<typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type
+pfirst(const Packet& a)
+{ return a; }
+
+/** \internal \returns the sum of the elements of upper and lower half of \a a if \a a is larger than 4.
+  * For a packet {a0, a1, a2, a3, a4, a5, a6, a7}, it returns a half packet {a0+a4, a1+a5, a2+a6, a3+a7}
+  * For packet-size smaller or equal to 4, this boils down to a noop.
+  */
+template<typename Packet>
+EIGEN_DEVICE_FUNC inline typename conditional<(unpacket_traits<Packet>::size%8)==0,typename unpacket_traits<Packet>::half,Packet>::type
+predux_half_dowto4(const Packet& a)
+{ return a; }
+
+// Slow generic implementation of Packet reduction.
+template <typename Packet, typename Op>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type
+predux_helper(const Packet& a, Op op) {
+  typedef typename unpacket_traits<Packet>::type Scalar;
+  const size_t n = unpacket_traits<Packet>::size;
+  EIGEN_ALIGN_TO_BOUNDARY(sizeof(Packet)) Scalar elements[n];
+  pstoreu<Scalar>(elements, a);
+  for(size_t k = n / 2; k > 0; k /= 2)  {
+    for(size_t i = 0; i < k; ++i) {
+      elements[i] = op(elements[i], elements[i + k]);
+    }
+  }
+  return elements[0];
+}
+
+/** \internal \returns the sum of the elements of \a a*/
+template<typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type
+predux(const Packet& a)
+{
+  return a;
+}
+
+/** \internal \returns the product of the elements of \a a */
+template <typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_mul(
+    const Packet& a) {
+  typedef typename unpacket_traits<Packet>::type Scalar; 
+  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmul<Scalar>)));
+}
+
+/** \internal \returns the min of the elements of \a a */
+template <typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_min(
+    const Packet &a) {
+  typedef typename unpacket_traits<Packet>::type Scalar; 
+  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmin<PropagateFast, Scalar>)));
+}
+
+template <int NaNPropagation, typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_min(
+    const Packet& a) {
+  typedef typename unpacket_traits<Packet>::type Scalar; 
+  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmin<NaNPropagation, Scalar>)));
+}
+
+/** \internal \returns the min of the elements of \a a */
+template <typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_max(
+    const Packet &a) {
+  typedef typename unpacket_traits<Packet>::type Scalar; 
+  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmax<PropagateFast, Scalar>)));
+}
+
+template <int NaNPropagation, typename Packet>
+EIGEN_DEVICE_FUNC inline typename unpacket_traits<Packet>::type predux_max(
+    const Packet& a) {
+  typedef typename unpacket_traits<Packet>::type Scalar; 
+  return predux_helper(a, EIGEN_BINARY_OP_NAN_PROPAGATION(Scalar, (pmax<NaNPropagation, Scalar>)));
+}
+
+#undef EIGEN_BINARY_OP_NAN_PROPAGATION
+
+/** \internal \returns true if all coeffs of \a a means "true"
+  * It is supposed to be called on values returned by pcmp_*.
+  */
+// not needed yet
+// template<typename Packet> EIGEN_DEVICE_FUNC inline bool predux_all(const Packet& a)
+// { return bool(a); }
+
+/** \internal \returns true if any coeffs of \a a means "true"
+  * It is supposed to be called on values returned by pcmp_*.
+  */
+template<typename Packet> EIGEN_DEVICE_FUNC inline bool predux_any(const Packet& a)
+{
+  // Dirty but generic implementation where "true" is assumed to be non 0 and all the sames.
+  // It is expected that "true" is either:
+  //  - Scalar(1)
+  //  - bits full of ones (NaN for floats),
+  //  - or first bit equals to 1 (1 for ints, smallest denormal for floats).
+  // For all these cases, taking the sum is just fine, and this boils down to a no-op for scalars.
+  typedef typename unpacket_traits<Packet>::type Scalar;
+  return numext::not_equal_strict(predux(a), Scalar(0));
+}
+
 /***************************************************************************
 * The following functions might not have to be overwritten for vectorized types
 ***************************************************************************/
 
 /** \internal copy a packet with constant coefficient \a a (e.g., [a,a,a,a]) to \a *to. \a to must be 16 bytes aligned */
 // NOTE: this function must really be templated on the packet type (think about different packet types for the same scalar type)
 template<typename Packet>
@@ -601,55 +987,26 @@
   */
 template<typename Packet, int LoadMode>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet ploadt_ro(const typename unpacket_traits<Packet>::type* from)
 {
   return ploadt<Packet, LoadMode>(from);
 }
 
-/** \internal default implementation of palign() allowing partial specialization */
-template<int Offset,typename PacketType>
-struct palign_impl
-{
-  // by default data are aligned, so there is nothing to be done :)
-  static inline void run(PacketType&, const PacketType&) {}
-};
-
-/** \internal update \a first using the concatenation of the packet_size minus \a Offset last elements
-  * of \a first and \a Offset first elements of \a second.
-  * 
-  * This function is currently only used to optimize matrix-vector products on unligned matrices.
-  * It takes 2 packets that represent a contiguous memory array, and returns a packet starting
-  * at the position \a Offset. For instance, for packets of 4 elements, we have:
-  *  Input:
-  *  - first = {f0,f1,f2,f3}
-  *  - second = {s0,s1,s2,s3}
-  * Output: 
-  *   - if Offset==0 then {f0,f1,f2,f3}
-  *   - if Offset==1 then {f1,f2,f3,s0}
-  *   - if Offset==2 then {f2,f3,s0,s1}
-  *   - if Offset==3 then {f3,s0,s1,s3}
-  */
-template<int Offset,typename PacketType>
-inline void palign(PacketType& first, const PacketType& second)
-{
-  palign_impl<Offset,PacketType>::run(first,second);
-}
-
 /***************************************************************************
 * Fast complex products (GCC generates a function call which is very slow)
 ***************************************************************************/
 
 // Eigen+CUDA does not support complexes.
 #if !defined(EIGEN_GPUCC)
 
 template<> inline std::complex<float> pmul(const std::complex<float>& a, const std::complex<float>& b)
-{ return std::complex<float>(real(a)*real(b) - imag(a)*imag(b), imag(a)*real(b) + real(a)*imag(b)); }
+{ return std::complex<float>(a.real()*b.real() - a.imag()*b.imag(), a.imag()*b.real() + a.real()*b.imag()); }
 
 template<> inline std::complex<double> pmul(const std::complex<double>& a, const std::complex<double>& b)
-{ return std::complex<double>(real(a)*real(b) - imag(a)*imag(b), imag(a)*real(b) + real(a)*imag(b)); }
+{ return std::complex<double>(a.real()*b.real() - a.imag()*b.imag(), a.imag()*b.real() + a.real()*b.imag()); }
 
 #endif
 
 
 /***************************************************************************
  * PacketBlock, that is a collection of N packets where the number of words
  * in the packet is a multiple of N.
@@ -672,56 +1029,12 @@
 };
 
 template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
 pblend(const Selector<unpacket_traits<Packet>::size>& ifPacket, const Packet& thenPacket, const Packet& elsePacket) {
   return ifPacket.select[0] ? thenPacket : elsePacket;
 }
 
-/** \internal \returns \a a with the first coefficient replaced by the scalar b */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pinsertfirst(const Packet& a, typename unpacket_traits<Packet>::type b)
-{
-  // Default implementation based on pblend.
-  // It must be specialized for higher performance.
-  Selector<unpacket_traits<Packet>::size> mask;
-  mask.select[0] = true;
-  // This for loop should be optimized away by the compiler.
-  for(Index i=1; i<unpacket_traits<Packet>::size; ++i)
-    mask.select[i] = false;
-  return pblend(mask, pset1<Packet>(b), a);
-}
-
-/** \internal \returns \a a with the last coefficient replaced by the scalar b */
-template<typename Packet> EIGEN_DEVICE_FUNC inline Packet
-pinsertlast(const Packet& a, typename unpacket_traits<Packet>::type b)
-{
-  // Default implementation based on pblend.
-  // It must be specialized for higher performance.
-  Selector<unpacket_traits<Packet>::size> mask;
-  // This for loop should be optimized away by the compiler.
-  for(Index i=0; i<unpacket_traits<Packet>::size-1; ++i)
-    mask.select[i] = false;
-  mask.select[unpacket_traits<Packet>::size-1] = true;
-  return pblend(mask, pset1<Packet>(b), a);
-}
-
-/***************************************************************************
- * Some generic implementations to be used by implementors
-***************************************************************************/
-
-/** Default implementation of pfrexp for float.
-  * It is expected to be called by implementers of template<> pfrexp.
-  */
-template<typename Packet> EIGEN_STRONG_INLINE Packet
-pfrexp_float(const Packet& a, Packet& exponent);
-
-/** Default implementation of pldexp for float.
-  * It is expected to be called by implementers of template<> pldexp.
-  */
-template<typename Packet> EIGEN_STRONG_INLINE Packet
-pldexp_float(Packet a, Packet exponent);
-
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_GENERIC_PACKET_MATH_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/GlobalFunctions.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/GlobalFunctions.h`

 * *Files 1% similar despite different names*

```diff
@@ -72,26 +72,29 @@
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(atanh,scalar_atanh_op,inverse hyperbolic tangent,\sa ArrayBase::atanh)
 #endif
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(logistic,scalar_logistic_op,logistic function,\sa ArrayBase::logistic)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(lgamma,scalar_lgamma_op,natural logarithm of the gamma function,\sa ArrayBase::lgamma)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(digamma,scalar_digamma_op,derivative of lgamma,\sa ArrayBase::digamma)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(erf,scalar_erf_op,error function,\sa ArrayBase::erf)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(erfc,scalar_erfc_op,complement error function,\sa ArrayBase::erfc)
+  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(ndtri,scalar_ndtri_op,inverse normal distribution function,\sa ArrayBase::ndtri)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(exp,scalar_exp_op,exponential,\sa ArrayBase::exp)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(expm1,scalar_expm1_op,exponential of a value minus 1,\sa ArrayBase::expm1)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(log,scalar_log_op,natural logarithm,\sa Eigen::log10 DOXCOMMA ArrayBase::log)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(log1p,scalar_log1p_op,natural logarithm of 1 plus the value,\sa ArrayBase::log1p)
-  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(log10,scalar_log10_op,base 10 logarithm,\sa Eigen::log DOXCOMMA ArrayBase::log)
+  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(log10,scalar_log10_op,base 10 logarithm,\sa Eigen::log DOXCOMMA ArrayBase::log10)
+  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(log2,scalar_log2_op,base 2 logarithm,\sa Eigen::log DOXCOMMA ArrayBase::log2)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(abs,scalar_abs_op,absolute value,\sa ArrayBase::abs DOXCOMMA MatrixBase::cwiseAbs)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(abs2,scalar_abs2_op,squared absolute value,\sa ArrayBase::abs2 DOXCOMMA MatrixBase::cwiseAbs2)
-  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(arg,scalar_arg_op,complex argument,\sa ArrayBase::arg)
+  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(arg,scalar_arg_op,complex argument,\sa ArrayBase::arg DOXCOMMA MatrixBase::cwiseArg)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(sqrt,scalar_sqrt_op,square root,\sa ArrayBase::sqrt DOXCOMMA MatrixBase::cwiseSqrt)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(rsqrt,scalar_rsqrt_op,reciprocal square root,\sa ArrayBase::rsqrt)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(square,scalar_square_op,square (power 2),\sa Eigen::abs2 DOXCOMMA Eigen::pow DOXCOMMA ArrayBase::square)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(cube,scalar_cube_op,cube (power 3),\sa Eigen::pow DOXCOMMA ArrayBase::cube)
+  EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(rint,scalar_rint_op,nearest integer,\sa Eigen::floor DOXCOMMA Eigen::ceil DOXCOMMA ArrayBase::round)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(round,scalar_round_op,nearest integer,\sa Eigen::floor DOXCOMMA Eigen::ceil DOXCOMMA ArrayBase::round)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(floor,scalar_floor_op,nearest integer not greater than the giben value,\sa Eigen::ceil DOXCOMMA ArrayBase::floor)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(ceil,scalar_ceil_op,nearest integer not less than the giben value,\sa Eigen::floor DOXCOMMA ArrayBase::ceil)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(isnan,scalar_isnan_op,not-a-number test,\sa Eigen::isinf DOXCOMMA Eigen::isfinite DOXCOMMA ArrayBase::isnan)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(isinf,scalar_isinf_op,infinite value test,\sa Eigen::isnan DOXCOMMA Eigen::isfinite DOXCOMMA ArrayBase::isinf)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(isfinite,scalar_isfinite_op,finite value test,\sa Eigen::isinf DOXCOMMA Eigen::isnan DOXCOMMA ArrayBase::isfinite)
   EIGEN_ARRAY_DECLARE_GLOBAL_UNARY(sign,scalar_sign_op,sign (or 0),\sa ArrayBase::sign)
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/IO.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/IO.h`

 * *Files 11% similar despite different names*

```diff
@@ -126,22 +126,41 @@
 };
 
 /** \internal
   * print the matrix \a _m to the output stream \a s using the output format \a fmt */
 template<typename Derived>
 std::ostream & print_matrix(std::ostream & s, const Derived& _m, const IOFormat& fmt)
 {
+  using internal::is_same;
+  using internal::conditional;
+
   if(_m.size() == 0)
   {
     s << fmt.matPrefix << fmt.matSuffix;
     return s;
   }
   
   typename Derived::Nested m = _m;
   typedef typename Derived::Scalar Scalar;
+  typedef typename
+      conditional<
+          is_same<Scalar, char>::value ||
+            is_same<Scalar, unsigned char>::value ||
+            is_same<Scalar, numext::int8_t>::value ||
+            is_same<Scalar, numext::uint8_t>::value,
+          int,
+          typename conditional<
+              is_same<Scalar, std::complex<char> >::value ||
+                is_same<Scalar, std::complex<unsigned char> >::value ||
+                is_same<Scalar, std::complex<numext::int8_t> >::value ||
+                is_same<Scalar, std::complex<numext::uint8_t> >::value,
+              std::complex<int>,
+              const Scalar&
+            >::type
+        >::type PrintType;
 
   Index width = 0;
 
   std::streamsize explicit_precision;
   if(fmt.precision == StreamPrecision)
   {
     explicit_precision = 0;
@@ -170,15 +189,15 @@
   {
     // compute the largest width
     for(Index j = 0; j < m.cols(); ++j)
       for(Index i = 0; i < m.rows(); ++i)
       {
         std::stringstream sstr;
         sstr.copyfmt(s);
-        sstr << m.coeff(i,j);
+        sstr << static_cast<PrintType>(m.coeff(i,j));
         width = std::max<Index>(width, Index(sstr.str().length()));
       }
   }
   std::streamsize old_width = s.width();
   char old_fill_character = s.fill();
   s << fmt.matPrefix;
   for(Index i = 0; i < m.rows(); ++i)
@@ -186,23 +205,23 @@
     if (i)
       s << fmt.rowSpacer;
     s << fmt.rowPrefix;
     if(width) {
       s.fill(fmt.fill);
       s.width(width);
     }
-    s << m.coeff(i, 0);
+    s << static_cast<PrintType>(m.coeff(i, 0));
     for(Index j = 1; j < m.cols(); ++j)
     {
       s << fmt.coeffSeparator;
       if(width) {
         s.fill(fmt.fill);
         s.width(width);
       }
-      s << m.coeff(i, j);
+      s << static_cast<PrintType>(m.coeff(i, j));
     }
     s << fmt.rowSuffix;
     if( i < m.rows() - 1)
       s << fmt.rowSeparator;
   }
   s << fmt.matSuffix;
   if(explicit_precision) s.precision(old_precision);
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/IndexedView.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/IndexedView.h`

 * *Files 5% similar despite different names*

```diff
@@ -50,15 +50,16 @@
     ReturnAsIndexedView = (!ReturnAsScalar) && (!ReturnAsBlock),
 
     // FIXME we deal with compile-time strides if and only if we have DirectAccessBit flag,
     // but this is too strict regarding negative strides...
     DirectAccessMask = (int(InnerIncr)!=UndefinedIncr && int(OuterIncr)!=UndefinedIncr && InnerIncr>=0 && OuterIncr>=0) ? DirectAccessBit : 0,
     FlagsRowMajorBit = IsRowMajor ? RowMajorBit : 0,
     FlagsLvalueBit = is_lvalue<XprType>::value ? LvalueBit : 0,
-    Flags = (traits<XprType>::Flags & (HereditaryBits | DirectAccessMask)) | FlagsLvalueBit | FlagsRowMajorBit
+    FlagsLinearAccessBit = (RowsAtCompileTime == 1 || ColsAtCompileTime == 1) ? LinearAccessBit : 0,
+    Flags = (traits<XprType>::Flags & (HereditaryBits | DirectAccessMask )) | FlagsLvalueBit | FlagsRowMajorBit | FlagsLinearAccessBit
   };
 
   typedef Block<XprType,RowsAtCompileTime,ColsAtCompileTime,IsInnerPannel> BlockType;
 };
 
 }
 
@@ -164,15 +165,19 @@
   : evaluator_base<IndexedView<ArgType, RowIndices, ColIndices> >
 {
   typedef IndexedView<ArgType, RowIndices, ColIndices> XprType;
 
   enum {
     CoeffReadCost = evaluator<ArgType>::CoeffReadCost /* TODO + cost of row/col index */,
 
-    Flags = (evaluator<ArgType>::Flags & (HereditaryBits /*| LinearAccessBit | DirectAccessBit*/)),
+    FlagsLinearAccessBit = (traits<XprType>::RowsAtCompileTime == 1 || traits<XprType>::ColsAtCompileTime == 1) ? LinearAccessBit : 0,
+
+    FlagsRowMajorBit = traits<XprType>::FlagsRowMajorBit, 
+
+    Flags = (evaluator<ArgType>::Flags & (HereditaryBits & ~RowMajorBit /*| LinearAccessBit | DirectAccessBit*/)) | FlagsLinearAccessBit | FlagsRowMajorBit,
 
     Alignment = 0
   };
 
   EIGEN_DEVICE_FUNC explicit unary_evaluator(const XprType& xpr) : m_argImpl(xpr.nestedExpression()), m_xpr(xpr)
   {
     EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
@@ -189,14 +194,39 @@
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   Scalar& coeffRef(Index row, Index col)
   {
     return m_argImpl.coeffRef(m_xpr.rowIndices()[row], m_xpr.colIndices()[col]);
   }
 
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+  Scalar& coeffRef(Index index)
+  {
+    EIGEN_STATIC_ASSERT_LVALUE(XprType)
+    Index row = XprType::RowsAtCompileTime == 1 ? 0 : index;
+    Index col = XprType::RowsAtCompileTime == 1 ? index : 0;
+    return m_argImpl.coeffRef( m_xpr.rowIndices()[row], m_xpr.colIndices()[col]);
+  }
+
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+  const Scalar& coeffRef(Index index) const
+  {
+    Index row = XprType::RowsAtCompileTime == 1 ? 0 : index;
+    Index col = XprType::RowsAtCompileTime == 1 ? index : 0;
+    return m_argImpl.coeffRef( m_xpr.rowIndices()[row], m_xpr.colIndices()[col]);
+  }
+
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+  const CoeffReturnType coeff(Index index) const
+  {
+    Index row = XprType::RowsAtCompileTime == 1 ? 0 : index;
+    Index col = XprType::RowsAtCompileTime == 1 ? index : 0;
+    return m_argImpl.coeff( m_xpr.rowIndices()[row], m_xpr.colIndices()[col]);
+  }
+
 protected:
 
   evaluator<ArgType> m_argImpl;
   const XprType& m_xpr;
 
 };
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Inverse.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Inverse.h`

 * *Files 7% similar despite different names*

```diff
@@ -1,20 +1,20 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
-// Copyright (C) 2014 Gael Guennebaud <gael.guennebaud@inria.fr>
+// Copyright (C) 2014-2019 Gael Guennebaud <gael.guennebaud@inria.fr>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_INVERSE_H
 #define EIGEN_INVERSE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 template<typename XprType,typename StorageKind> class InverseImpl;
 
 namespace internal {
 
 template<typename XprType>
 struct traits<Inverse<XprType> >
@@ -40,27 +40,26 @@
   *
   */
 template<typename XprType>
 class Inverse : public InverseImpl<XprType,typename internal::traits<XprType>::StorageKind>
 {
 public:
   typedef typename XprType::StorageIndex StorageIndex;
-  typedef typename XprType::PlainObject                       PlainObject;
   typedef typename XprType::Scalar                            Scalar;
   typedef typename internal::ref_selector<XprType>::type      XprTypeNested;
   typedef typename internal::remove_all<XprTypeNested>::type  XprTypeNestedCleaned;
   typedef typename internal::ref_selector<Inverse>::type Nested;
   typedef typename internal::remove_all<XprType>::type NestedExpression;
-  
+
   explicit EIGEN_DEVICE_FUNC Inverse(const XprType &xpr)
     : m_xpr(xpr)
   {}
 
-  EIGEN_DEVICE_FUNC Index rows() const { return m_xpr.rows(); }
-  EIGEN_DEVICE_FUNC Index cols() const { return m_xpr.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR  Index rows() const EIGEN_NOEXCEPT { return m_xpr.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR  Index cols() const EIGEN_NOEXCEPT { return m_xpr.rows(); }
 
   EIGEN_DEVICE_FUNC const XprTypeNestedCleaned& nestedExpression() const { return m_xpr; }
 
 protected:
   XprTypeNested m_xpr;
 };
 
@@ -78,41 +77,41 @@
   Scalar coeff(Index i) const;
 };
 
 namespace internal {
 
 /** \internal
   * \brief Default evaluator for Inverse expression.
-  * 
+  *
   * This default evaluator for Inverse expression simply evaluate the inverse into a temporary
   * by a call to internal::call_assignment_no_alias.
   * Therefore, inverse implementers only have to specialize Assignment<Dst,Inverse<...>, ...> for
   * there own nested expression.
   *
   * \sa class Inverse
   */
 template<typename ArgType>
 struct unary_evaluator<Inverse<ArgType> >
   : public evaluator<typename Inverse<ArgType>::PlainObject>
 {
   typedef Inverse<ArgType> InverseType;
   typedef typename InverseType::PlainObject PlainObject;
   typedef evaluator<PlainObject> Base;
-  
+
   enum { Flags = Base::Flags | EvalBeforeNestingBit };
 
   unary_evaluator(const InverseType& inv_xpr)
     : m_result(inv_xpr.rows(), inv_xpr.cols())
   {
     ::new (static_cast<Base*>(this)) Base(m_result);
     internal::call_assignment_no_alias(m_result, inv_xpr);
   }
-  
+
 protected:
   PlainObject m_result;
 };
-  
+
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_INVERSE_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Map.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Map.h`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_MAP_H
 #define EIGEN_MAP_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 template<typename PlainObjectType, int MapOptions, typename StrideType>
 struct traits<Map<PlainObjectType, MapOptions, StrideType> >
   : public traits<PlainObjectType>
 {
   typedef traits<PlainObjectType> TraitsBase;
@@ -43,15 +43,15 @@
 
 /** \class Map
   * \ingroup Core_Module
   *
   * \brief A matrix or vector expression mapping an existing array of data.
   *
   * \tparam PlainObjectType the equivalent matrix type of the mapped data
-  * \tparam MapOptions specifies the pointer alignment in bytes. It can be: \c #Aligned128, , \c #Aligned64, \c #Aligned32, \c #Aligned16, \c #Aligned8 or \c #Unaligned.
+  * \tparam MapOptions specifies the pointer alignment in bytes. It can be: \c #Aligned128, \c #Aligned64, \c #Aligned32, \c #Aligned16, \c #Aligned8 or \c #Unaligned.
   *                The default is \c #Unaligned.
   * \tparam StrideType optionally specifies strides. By default, Map assumes the memory layout
   *                   of an ordinary, contiguous array. This can be overridden by specifying strides.
   *                   The type passed here must be a specialization of the Stride template, see examples below.
   *
   * This class represents a matrix or vector expression mapping an existing array of data.
   * It can be used to let Eigen interface without any overhead with non-Eigen data structures,
@@ -100,21 +100,21 @@
     EIGEN_DENSE_PUBLIC_INTERFACE(Map)
 
     typedef typename Base::PointerType PointerType;
     typedef PointerType PointerArgType;
     EIGEN_DEVICE_FUNC
     inline PointerType cast_to_pointer_type(PointerArgType ptr) { return ptr; }
 
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index innerStride() const
     {
       return StrideType::InnerStrideAtCompileTime != 0 ? m_stride.inner() : 1;
     }
 
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index outerStride() const
     {
       return StrideType::OuterStrideAtCompileTime != 0 ? m_stride.outer()
            : internal::traits<Map>::OuterStrideAtCompileTime != Dynamic ? Index(internal::traits<Map>::OuterStrideAtCompileTime)
            : IsVectorAtCompileTime ? (this->size() * innerStride())
            : int(Flags)&RowMajorBit ? (this->cols() * innerStride())
            : (this->rows() * innerStride());
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/MapBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/MapBase.h`

 * *Files 2% similar despite different names*

```diff
@@ -11,15 +11,15 @@
 #ifndef EIGEN_MAPBASE_H
 #define EIGEN_MAPBASE_H
 
 #define EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS(Derived) \
       EIGEN_STATIC_ASSERT((int(internal::evaluator<Derived>::Flags) & LinearAccessBit) || Derived::IsVectorAtCompileTime, \
                           YOU_ARE_TRYING_TO_USE_AN_INDEX_BASED_ACCESSOR_ON_AN_EXPRESSION_THAT_DOES_NOT_SUPPORT_THAT)
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \ingroup Core_Module
   *
   * \brief Base class for dense Map and Block expression with direct access
   *
   * This base class provides the const low-level accessors (e.g. coeff, coeffRef) of dense
   * Map and Block objects with direct access.
@@ -83,17 +83,19 @@
 
     // bug 217 - compile error on ICC 11.1
     using Base::operator=;
 
     typedef typename Base::CoeffReturnType CoeffReturnType;
 
     /** \copydoc DenseBase::rows() */
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_rows.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_rows.value(); }
     /** \copydoc DenseBase::cols() */
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_cols.value(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_cols.value(); }
 
     /** Returns a pointer to the first coefficient of the matrix or vector.
       *
       * \note When addressing this data, make sure to honor the strides returned by innerStride() and outerStride().
       *
       * \sa innerStride(), outerStride()
       */
@@ -178,14 +180,16 @@
     }
 
     #ifdef EIGEN_MAPBASE_PLUGIN
     #include EIGEN_MAPBASE_PLUGIN
     #endif
 
   protected:
+    EIGEN_DEFAULT_COPY_CONSTRUCTOR(MapBase)
+    EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(MapBase)
 
     template<typename T>
     EIGEN_DEVICE_FUNC
     void checkSanity(typename internal::enable_if<(internal::traits<T>::Alignment>0),void*>::type = 0) const
     {
 #if EIGEN_MAX_ALIGN_BYTES>0
       // innerStride() is not set yet when this function is called, so we optimistically assume the lowest plausible value:
@@ -290,14 +294,17 @@
       ReadOnlyMapBase::Base::operator=(other);
       return derived();
     }
 
     // In theory we could simply refer to Base:Base::operator=, but MSVC does not like Base::Base,
     // see bugs 821 and 920.
     using ReadOnlyMapBase::Base::operator=;
+  protected:
+    EIGEN_DEFAULT_COPY_CONSTRUCTOR(MapBase)
+    EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(MapBase)
 };
 
 #undef EIGEN_STATIC_ASSERT_INDEX_BASED_ACCESS
 
 } // end namespace Eigen
 
 #endif // EIGEN_MAPBASE_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/MathFunctions.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/MathFunctions.h`

 * *Files 8% similar despite different names*

```diff
@@ -1,22 +1,25 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
 // Copyright (C) 2006-2010 Benoit Jacob <jacob.benoit.1@gmail.com>
+// Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_MATHFUNCTIONS_H
 #define EIGEN_MATHFUNCTIONS_H
 
-// source: http://www.geom.uiuc.edu/~huberty/math5337/groupe/digits.html
 // TODO this should better be moved to NumTraits
-#define EIGEN_PI 3.141592653589793238462643383279502884197169399375105820974944592307816406L
+// Source: WolframAlpha
+#define EIGEN_PI    3.141592653589793238462643383279502884197169399375105820974944592307816406L
+#define EIGEN_LOG2E 1.442695040888963407359924681001892137426645954152985934135449406931109219L
+#define EIGEN_LN2   0.693147180559945309417232121458176568075500134360255254120680009493393621L
 
 namespace Eigen {
 
 // On WINCE, std::abs is defined for int only, so let's defined our own overloads:
 // This issue has been confirmed with MSVC 2008 only, but the issue might exist for more recent versions too.
 #if EIGEN_OS_WINCE && EIGEN_COMP_MSVC && EIGEN_COMP_MSVC<=1500
 long        abs(long        x) { return (labs(x));  }
@@ -208,20 +211,20 @@
     return reinterpret_cast<RealScalar*>(&x)[1];
   }
 };
 
 template<typename Scalar>
 struct imag_ref_default_impl<Scalar, false>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline Scalar run(Scalar&)
   {
     return Scalar(0);
   }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline const Scalar run(const Scalar&)
   {
     return Scalar(0);
   }
 };
 
 template<typename Scalar>
@@ -254,27 +257,16 @@
   static inline Scalar run(const Scalar& x)
   {
     using std::conj;
     return conj(x);
   }
 };
 
-template<typename Scalar> struct conj_impl : conj_default_impl<Scalar> {};
-
-#if defined(EIGEN_GPU_COMPILE_PHASE)
-template<typename T>
-struct conj_impl<std::complex<T> >
-{
-  EIGEN_DEVICE_FUNC
-  static inline std::complex<T> run(const std::complex<T>& x)
-  {
-    return std::complex<T>(x.real(), -x.imag());
-  }
-};
-#endif
+template<typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
+struct conj_impl : conj_default_impl<Scalar, IsComplex> {};
 
 template<typename Scalar>
 struct conj_retval
 {
   typedef Scalar type;
 };
 
@@ -296,15 +288,15 @@
 template<typename Scalar>
 struct abs2_impl_default<Scalar, true> // IsComplex
 {
   typedef typename NumTraits<Scalar>::Real RealScalar;
   EIGEN_DEVICE_FUNC
   static inline RealScalar run(const Scalar& x)
   {
-    return real(x)*real(x) + imag(x)*imag(x);
+    return x.real()*x.real() + x.imag()*x.imag();
   }
 };
 
 template<typename Scalar>
 struct abs2_impl
 {
   typedef typename NumTraits<Scalar>::Real RealScalar;
@@ -318,36 +310,98 @@
 template<typename Scalar>
 struct abs2_retval
 {
   typedef typename NumTraits<Scalar>::Real type;
 };
 
 /****************************************************************************
+* Implementation of sqrt/rsqrt                                             *
+****************************************************************************/
+
+template<typename Scalar>
+struct sqrt_impl
+{
+  EIGEN_DEVICE_FUNC
+  static EIGEN_ALWAYS_INLINE Scalar run(const Scalar& x)
+  {
+    EIGEN_USING_STD(sqrt);
+    return sqrt(x);
+  }
+};
+
+// Complex sqrt defined in MathFunctionsImpl.h.
+template<typename T> EIGEN_DEVICE_FUNC std::complex<T> complex_sqrt(const std::complex<T>& a_x);
+
+// Custom implementation is faster than `std::sqrt`, works on
+// GPU, and correctly handles special cases (unlike MSVC).
+template<typename T>
+struct sqrt_impl<std::complex<T> >
+{
+  EIGEN_DEVICE_FUNC
+  static EIGEN_ALWAYS_INLINE std::complex<T> run(const std::complex<T>& x)
+  {
+    return complex_sqrt<T>(x);
+  }
+};
+
+template<typename Scalar>
+struct sqrt_retval
+{
+  typedef Scalar type;
+};
+
+// Default implementation relies on numext::sqrt, at bottom of file.
+template<typename T>
+struct rsqrt_impl;
+
+// Complex rsqrt defined in MathFunctionsImpl.h.
+template<typename T> EIGEN_DEVICE_FUNC std::complex<T> complex_rsqrt(const std::complex<T>& a_x);
+
+template<typename T>
+struct rsqrt_impl<std::complex<T> >
+{
+  EIGEN_DEVICE_FUNC
+  static EIGEN_ALWAYS_INLINE std::complex<T> run(const std::complex<T>& x)
+  {
+    return complex_rsqrt<T>(x);
+  }
+};
+
+template<typename Scalar>
+struct rsqrt_retval
+{
+  typedef Scalar type;
+};
+
+/****************************************************************************
 * Implementation of norm1                                                *
 ****************************************************************************/
 
 template<typename Scalar, bool IsComplex>
-struct norm1_default_impl
+struct norm1_default_impl;
+
+template<typename Scalar>
+struct norm1_default_impl<Scalar,true>
 {
   typedef typename NumTraits<Scalar>::Real RealScalar;
   EIGEN_DEVICE_FUNC
   static inline RealScalar run(const Scalar& x)
   {
-    EIGEN_USING_STD_MATH(abs);
-    return abs(real(x)) + abs(imag(x));
+    EIGEN_USING_STD(abs);
+    return abs(x.real()) + abs(x.imag());
   }
 };
 
 template<typename Scalar>
 struct norm1_default_impl<Scalar, false>
 {
   EIGEN_DEVICE_FUNC
   static inline Scalar run(const Scalar& x)
   {
-    EIGEN_USING_STD_MATH(abs);
+    EIGEN_USING_STD(abs);
     return abs(x);
   }
 };
 
 template<typename Scalar>
 struct norm1_impl : norm1_default_impl<Scalar, NumTraits<Scalar>::IsComplex> {};
 
@@ -369,110 +423,220 @@
   typedef typename NumTraits<Scalar>::Real type;
 };
 
 /****************************************************************************
 * Implementation of cast                                                 *
 ****************************************************************************/
 
-template<typename OldType, typename NewType>
+template<typename OldType, typename NewType, typename EnableIf = void>
 struct cast_impl
 {
   EIGEN_DEVICE_FUNC
   static inline NewType run(const OldType& x)
   {
     return static_cast<NewType>(x);
   }
 };
 
+// Casting from S -> Complex<T> leads to an implicit conversion from S to T,
+// generating warnings on clang.  Here we explicitly cast the real component.
+template<typename OldType, typename NewType>
+struct cast_impl<OldType, NewType,
+  typename internal::enable_if<
+    !NumTraits<OldType>::IsComplex && NumTraits<NewType>::IsComplex
+  >::type>
+{
+  EIGEN_DEVICE_FUNC
+  static inline NewType run(const OldType& x)
+  {
+    typedef typename NumTraits<NewType>::Real NewReal;
+    return static_cast<NewType>(static_cast<NewReal>(x));
+  }
+};
+
 // here, for once, we're plainly returning NewType: we don't want cast to do weird things.
 
 template<typename OldType, typename NewType>
 EIGEN_DEVICE_FUNC
 inline NewType cast(const OldType& x)
 {
   return cast_impl<OldType, NewType>::run(x);
 }
 
 /****************************************************************************
 * Implementation of round                                                   *
 ****************************************************************************/
 
+template<typename Scalar>
+struct round_impl
+{
+  EIGEN_DEVICE_FUNC
+  static inline Scalar run(const Scalar& x)
+  {
+    EIGEN_STATIC_ASSERT((!NumTraits<Scalar>::IsComplex), NUMERIC_TYPE_MUST_BE_REAL)
 #if EIGEN_HAS_CXX11_MATH
-  template<typename Scalar>
-  struct round_impl {
-    static inline Scalar run(const Scalar& x)
-    {
-      EIGEN_STATIC_ASSERT((!NumTraits<Scalar>::IsComplex), NUMERIC_TYPE_MUST_BE_REAL)
-      EIGEN_USING_STD_MATH(round);
-      return round(x);
-    }
-  };
+    EIGEN_USING_STD(round);
+#endif
+    return Scalar(round(x));
+  }
+};
+
+#if !EIGEN_HAS_CXX11_MATH
+#if EIGEN_HAS_C99_MATH
+// Use ::roundf for float.
+template<>
+struct round_impl<float> {
+  EIGEN_DEVICE_FUNC
+  static inline float run(const float& x)
+  {
+    return ::roundf(x);
+  }
+};
 #else
-  template<typename Scalar>
-  struct round_impl
+template<typename Scalar>
+struct round_using_floor_ceil_impl
+{
+  EIGEN_DEVICE_FUNC
+  static inline Scalar run(const Scalar& x)
   {
-    static inline Scalar run(const Scalar& x)
-    {
-      EIGEN_STATIC_ASSERT((!NumTraits<Scalar>::IsComplex), NUMERIC_TYPE_MUST_BE_REAL)
-      EIGEN_USING_STD_MATH(floor);
-      EIGEN_USING_STD_MATH(ceil);
-      return (x > Scalar(0)) ? floor(x + Scalar(0.5)) : ceil(x - Scalar(0.5));
+    EIGEN_STATIC_ASSERT((!NumTraits<Scalar>::IsComplex), NUMERIC_TYPE_MUST_BE_REAL)
+    // Without C99 round/roundf, resort to floor/ceil.
+    EIGEN_USING_STD(floor);
+    EIGEN_USING_STD(ceil);
+    // If not enough precision to resolve a decimal at all, return the input.
+    // Otherwise, adding 0.5 can trigger an increment by 1.
+    const Scalar limit = Scalar(1ull << (NumTraits<Scalar>::digits() - 1));
+    if (x >= limit || x <= -limit) {
+      return x;
     }
-  };
-#endif
+    return (x > Scalar(0)) ? Scalar(floor(x + Scalar(0.5))) : Scalar(ceil(x - Scalar(0.5)));
+  }
+};
+
+template<>
+struct round_impl<float> : round_using_floor_ceil_impl<float> {};
+
+template<>
+struct round_impl<double> : round_using_floor_ceil_impl<double> {};
+#endif // EIGEN_HAS_C99_MATH
+#endif // !EIGEN_HAS_CXX11_MATH
 
 template<typename Scalar>
 struct round_retval
 {
   typedef Scalar type;
 };
 
 /****************************************************************************
-* Implementation of arg                                                     *
+* Implementation of rint                                                    *
 ****************************************************************************/
 
+template<typename Scalar>
+struct rint_impl {
+  EIGEN_DEVICE_FUNC
+  static inline Scalar run(const Scalar& x)
+  {
+    EIGEN_STATIC_ASSERT((!NumTraits<Scalar>::IsComplex), NUMERIC_TYPE_MUST_BE_REAL)
 #if EIGEN_HAS_CXX11_MATH
-  template<typename Scalar>
-  struct arg_impl {
-    static inline Scalar run(const Scalar& x)
-    {
-      #if defined(EIGEN_HIP_DEVICE_COMPILE)
-      // HIP does not seem to have a native device side implementation for the math routine "arg"
-      using std::arg;
-      #else 		  
-      EIGEN_USING_STD_MATH(arg);
-      #endif
-      return arg(x);
-    }
-  };
-#else
-  template<typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
-  struct arg_default_impl
+      EIGEN_USING_STD(rint);
+#endif
+    return rint(x);
+  }
+};
+
+#if !EIGEN_HAS_CXX11_MATH
+template<>
+struct rint_impl<double> {
+  EIGEN_DEVICE_FUNC
+  static inline double run(const double& x)
   {
-    typedef typename NumTraits<Scalar>::Real RealScalar;
-    EIGEN_DEVICE_FUNC
-    static inline RealScalar run(const Scalar& x)
-    {
-      return (x < Scalar(0)) ? Scalar(EIGEN_PI) : Scalar(0); }
-  };
+    return ::rint(x);
+  }
+};
+template<>
+struct rint_impl<float> {
+  EIGEN_DEVICE_FUNC
+  static inline float run(const float& x)
+  {
+    return ::rintf(x);
+  }
+};
+#endif
 
-  template<typename Scalar>
-  struct arg_default_impl<Scalar,true>
+template<typename Scalar>
+struct rint_retval
+{
+  typedef Scalar type;
+};
+
+/****************************************************************************
+* Implementation of arg                                                     *
+****************************************************************************/
+
+// Visual Studio 2017 has a bug where arg(float) returns 0 for negative inputs.
+// This seems to be fixed in VS 2019.
+#if EIGEN_HAS_CXX11_MATH && (!EIGEN_COMP_MSVC || EIGEN_COMP_MSVC >= 1920)
+// std::arg is only defined for types of std::complex, or integer types or float/double/long double
+template<typename Scalar,
+          bool HasStdImpl = NumTraits<Scalar>::IsComplex || is_integral<Scalar>::value
+                            || is_same<Scalar, float>::value || is_same<Scalar, double>::value
+                            || is_same<Scalar, long double>::value >
+struct arg_default_impl;
+
+template<typename Scalar>
+struct arg_default_impl<Scalar, true> {
+  typedef typename NumTraits<Scalar>::Real RealScalar;
+  EIGEN_DEVICE_FUNC
+  static inline RealScalar run(const Scalar& x)
   {
-    typedef typename NumTraits<Scalar>::Real RealScalar;
-    EIGEN_DEVICE_FUNC
-    static inline RealScalar run(const Scalar& x)
-    {
-      EIGEN_USING_STD_MATH(arg);
-      return arg(x);
-    }
-  };
+    #if defined(EIGEN_HIP_DEVICE_COMPILE)
+    // HIP does not seem to have a native device side implementation for the math routine "arg"
+    using std::arg;
+    #else
+    EIGEN_USING_STD(arg);
+    #endif
+    return static_cast<RealScalar>(arg(x));
+  }
+};
 
-  template<typename Scalar> struct arg_impl : arg_default_impl<Scalar> {};
+// Must be non-complex floating-point type (e.g. half/bfloat16).
+template<typename Scalar>
+struct arg_default_impl<Scalar, false> {
+  typedef typename NumTraits<Scalar>::Real RealScalar;
+  EIGEN_DEVICE_FUNC
+  static inline RealScalar run(const Scalar& x)
+  {
+    return (x < Scalar(0)) ? RealScalar(EIGEN_PI) : RealScalar(0);
+  }
+};
+#else
+template<typename Scalar, bool IsComplex = NumTraits<Scalar>::IsComplex>
+struct arg_default_impl
+{
+  typedef typename NumTraits<Scalar>::Real RealScalar;
+  EIGEN_DEVICE_FUNC
+  static inline RealScalar run(const Scalar& x)
+  {
+    return (x < RealScalar(0)) ? RealScalar(EIGEN_PI) : RealScalar(0);
+  }
+};
+
+template<typename Scalar>
+struct arg_default_impl<Scalar,true>
+{
+  typedef typename NumTraits<Scalar>::Real RealScalar;
+  EIGEN_DEVICE_FUNC
+  static inline RealScalar run(const Scalar& x)
+  {
+    EIGEN_USING_STD(arg);
+    return arg(x);
+  }
+};
 #endif
+template<typename Scalar> struct arg_impl : arg_default_impl<Scalar> {};
 
 template<typename Scalar>
 struct arg_retval
 {
   typedef typename NumTraits<Scalar>::Real type;
 };
 
@@ -486,79 +650,117 @@
   // or that there is no suitable std::expm1 function available. Implementation
   // attributed to Kahan. See: http://www.plunk.org/~hatch/rightway.php.
   template<typename Scalar>
   EIGEN_DEVICE_FUNC inline Scalar expm1(const Scalar& x) {
     EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar)
     typedef typename NumTraits<Scalar>::Real RealScalar;
 
-    EIGEN_USING_STD_MATH(exp);
+    EIGEN_USING_STD(exp);
     Scalar u = exp(x);
     if (numext::equal_strict(u, Scalar(1))) {
       return x;
     }
     Scalar um1 = u - RealScalar(1);
     if (numext::equal_strict(um1, Scalar(-1))) {
       return RealScalar(-1);
     }
 
-    EIGEN_USING_STD_MATH(log);
-    return (u - RealScalar(1)) * x / log(u);
+    EIGEN_USING_STD(log);
+    Scalar logu = log(u);
+    return numext::equal_strict(u, logu) ? u : (u - RealScalar(1)) * x / logu;
   }
 }
 
 template<typename Scalar>
 struct expm1_impl {
   EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& x)
   {
     EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar)
     #if EIGEN_HAS_CXX11_MATH
     using std::expm1;
-    #endif
+    #else
     using std_fallback::expm1;
+    #endif
     return expm1(x);
   }
 };
 
-
 template<typename Scalar>
 struct expm1_retval
 {
   typedef Scalar type;
 };
 
 /****************************************************************************
+* Implementation of log                                                     *
+****************************************************************************/
+
+// Complex log defined in MathFunctionsImpl.h.
+template<typename T> EIGEN_DEVICE_FUNC std::complex<T> complex_log(const std::complex<T>& z);
+
+template<typename Scalar>
+struct log_impl {
+  EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& x)
+  {
+    EIGEN_USING_STD(log);
+    return static_cast<Scalar>(log(x));
+  }
+};
+
+template<typename Scalar>
+struct log_impl<std::complex<Scalar> > {
+  EIGEN_DEVICE_FUNC static inline std::complex<Scalar> run(const std::complex<Scalar>& z)
+  {
+    return complex_log(z);
+  }
+};
+
+/****************************************************************************
 * Implementation of log1p                                                   *
 ****************************************************************************/
 
 namespace std_fallback {
   // fallback log1p implementation in case there is no log1p(Scalar) function in namespace of Scalar,
   // or that there is no suitable std::log1p function available
   template<typename Scalar>
   EIGEN_DEVICE_FUNC inline Scalar log1p(const Scalar& x) {
     EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar)
     typedef typename NumTraits<Scalar>::Real RealScalar;
-    EIGEN_USING_STD_MATH(log);
+    EIGEN_USING_STD(log);
     Scalar x1p = RealScalar(1) + x;
-    return numext::equal_strict(x1p, Scalar(1)) ? x : x * ( log(x1p) / (x1p - RealScalar(1)) );
+    Scalar log_1p = log_impl<Scalar>::run(x1p);
+    const bool is_small = numext::equal_strict(x1p, Scalar(1));
+    const bool is_inf = numext::equal_strict(x1p, log_1p);
+    return (is_small || is_inf) ? x : x * (log_1p / (x1p - RealScalar(1)));
   }
 }
 
 template<typename Scalar>
 struct log1p_impl {
   EIGEN_DEVICE_FUNC static inline Scalar run(const Scalar& x)
   {
     EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar)
     #if EIGEN_HAS_CXX11_MATH
     using std::log1p;
-    #endif
+    #else
     using std_fallback::log1p;
+    #endif
     return log1p(x);
   }
 };
 
+// Specialization for complex types that are not supported by std::log1p.
+template <typename RealScalar>
+struct log1p_impl<std::complex<RealScalar> > {
+  EIGEN_DEVICE_FUNC static inline std::complex<RealScalar> run(
+      const std::complex<RealScalar>& x) {
+    EIGEN_STATIC_ASSERT_NON_INTEGER(RealScalar)
+    return std_fallback::log1p(x);
+  }
+};
 
 template<typename Scalar>
 struct log1p_retval
 {
   typedef Scalar type;
 };
 
@@ -569,15 +771,15 @@
 template<typename ScalarX,typename ScalarY, bool IsInteger = NumTraits<ScalarX>::IsInteger&&NumTraits<ScalarY>::IsInteger>
 struct pow_impl
 {
   //typedef Scalar retval;
   typedef typename ScalarBinaryOpTraits<ScalarX,ScalarY,internal::scalar_pow_op<ScalarX,ScalarY> >::ReturnType result_type;
   static EIGEN_DEVICE_FUNC inline result_type run(const ScalarX& x, const ScalarY& y)
   {
-    EIGEN_USING_STD_MATH(pow);
+    EIGEN_USING_STD(pow);
     return pow(x, y);
   }
 };
 
 template<typename ScalarX,typename ScalarY>
 struct pow_impl<ScalarX,ScalarY, true>
 {
@@ -725,16 +927,16 @@
 };
 
 template<typename Scalar>
 struct random_default_impl<Scalar, true, false>
 {
   static inline Scalar run(const Scalar& x, const Scalar& y)
   {
-    return Scalar(random(real(x), real(y)),
-                  random(imag(x), imag(y)));
+    return Scalar(random(x.real(), y.real()),
+                  random(x.imag(), y.imag()));
   }
   static inline Scalar run()
   {
     typedef typename NumTraits<Scalar>::Real RealScalar;
     return Scalar(random<RealScalar>(), random<RealScalar>());
   }
 };
@@ -863,37 +1065,36 @@
 
 // The following overload are defined at the end of this file
 template<typename T> EIGEN_DEVICE_FUNC bool isfinite_impl(const std::complex<T>& x);
 template<typename T> EIGEN_DEVICE_FUNC bool isnan_impl(const std::complex<T>& x);
 template<typename T> EIGEN_DEVICE_FUNC bool isinf_impl(const std::complex<T>& x);
 
 template<typename T> T generic_fast_tanh_float(const T& a_x);
-
 } // end namespace internal
 
 /****************************************************************************
 * Generic math functions                                                    *
 ****************************************************************************/
 
 namespace numext {
 
-#if (!defined(EIGEN_GPUCC) || defined(EIGEN_CONSTEXPR_ARE_DEVICE_FUNC)) 
+#if (!defined(EIGEN_GPUCC) || defined(EIGEN_CONSTEXPR_ARE_DEVICE_FUNC))
 template<typename T>
 EIGEN_DEVICE_FUNC
 EIGEN_ALWAYS_INLINE T mini(const T& x, const T& y)
 {
-  EIGEN_USING_STD_MATH(min);
+  EIGEN_USING_STD(min)
   return min EIGEN_NOT_A_MACRO (x,y);
 }
 
 template<typename T>
 EIGEN_DEVICE_FUNC
 EIGEN_ALWAYS_INLINE T maxi(const T& x, const T& y)
 {
-  EIGEN_USING_STD_MATH(max);
+  EIGEN_USING_STD(max)
   return max EIGEN_NOT_A_MACRO (x,y);
 }
 #else
 template<typename T>
 EIGEN_DEVICE_FUNC
 EIGEN_ALWAYS_INLINE T mini(const T& x, const T& y)
 {
@@ -1086,14 +1287,42 @@
 {
   return EIGEN_MATHFUNC_IMPL(abs2, Scalar)::run(x);
 }
 
 EIGEN_DEVICE_FUNC
 inline bool abs2(bool x) { return x; }
 
+template<typename T>
+EIGEN_DEVICE_FUNC
+EIGEN_ALWAYS_INLINE T absdiff(const T& x, const T& y)
+{
+  return x > y ? x - y : y - x;
+}
+template<>
+EIGEN_DEVICE_FUNC
+EIGEN_ALWAYS_INLINE float absdiff(const float& x, const float& y)
+{
+  return fabsf(x - y);
+}
+template<>
+EIGEN_DEVICE_FUNC
+EIGEN_ALWAYS_INLINE double absdiff(const double& x, const double& y)
+{
+  return fabs(x - y);
+}
+
+#if !defined(EIGEN_GPUCC)
+// HIP and CUDA do not support long double.
+template<>
+EIGEN_DEVICE_FUNC
+EIGEN_ALWAYS_INLINE long double absdiff(const long double& x, const long double& y) {
+  return fabsl(x - y);
+}
+#endif
+
 template<typename Scalar>
 EIGEN_DEVICE_FUNC
 inline EIGEN_MATHFUNC_RETVAL(norm1, Scalar) norm1(const Scalar& x)
 {
   return EIGEN_MATHFUNC_IMPL(norm1, Scalar)::run(x);
 }
 
@@ -1146,28 +1375,35 @@
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY_FUNC_RET_TYPE(isnan, isnan, bool)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY_FUNC_RET_TYPE(isinf, isinf, bool)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY_FUNC_RET_TYPE(isfinite, isfinite, bool)
 #endif
 
 template<typename Scalar>
 EIGEN_DEVICE_FUNC
+inline EIGEN_MATHFUNC_RETVAL(rint, Scalar) rint(const Scalar& x)
+{
+  return EIGEN_MATHFUNC_IMPL(rint, Scalar)::run(x);
+}
+
+template<typename Scalar>
+EIGEN_DEVICE_FUNC
 inline EIGEN_MATHFUNC_RETVAL(round, Scalar) round(const Scalar& x)
 {
   return EIGEN_MATHFUNC_IMPL(round, Scalar)::run(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(round, round)
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC
 T (floor)(const T& x)
 {
-  EIGEN_USING_STD_MATH(floor);
+  EIGEN_USING_STD(floor)
   return floor(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(floor, floor)
 #endif
 
@@ -1179,15 +1415,15 @@
 double floor(const double &x) { return ::floor(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC
 T (ceil)(const T& x)
 {
-  EIGEN_USING_STD_MATH(ceil);
+  EIGEN_USING_STD(ceil);
   return ceil(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(ceil, ceil)
 #endif
 
@@ -1220,31 +1456,42 @@
   * It is essentially equivalent to
   * \code using std::sqrt; return sqrt(x); \endcode
   * but slightly faster for float/double and some compilers (e.g., gcc), thanks to
   * specializations when SSE is enabled.
   *
   * It's usage is justified in performance critical functions, like norm/normalize.
   */
-template<typename T>
-EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
-T sqrt(const T &x)
+template<typename Scalar>
+EIGEN_DEVICE_FUNC
+EIGEN_ALWAYS_INLINE EIGEN_MATHFUNC_RETVAL(sqrt, Scalar) sqrt(const Scalar& x)
 {
-  EIGEN_USING_STD_MATH(sqrt);
-  return sqrt(x);
+  return EIGEN_MATHFUNC_IMPL(sqrt, Scalar)::run(x);
 }
 
+// Boolean specialization, avoids implicit float to bool conversion (-Wimplicit-conversion-floating-point-to-bool).
+template<>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_DEVICE_FUNC
+bool sqrt<bool>(const bool &x) { return x; }
+
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(sqrt, sqrt)
 #endif
 
+/** \returns the reciprocal square root of \a x. **/
+template<typename T>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
+T rsqrt(const T& x)
+{
+  return internal::rsqrt_impl<T>::run(x);
+}
+
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T log(const T &x) {
-  EIGEN_USING_STD_MATH(log);
-  return log(x);
+  return internal::log_impl<T>::run(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(log, log)
 #endif
 
 
@@ -1256,15 +1503,15 @@
 double log(const double &x) { return ::log(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 typename internal::enable_if<NumTraits<T>::IsSigned || NumTraits<T>::IsComplex,typename NumTraits<T>::Real>::type
 abs(const T &x) {
-  EIGEN_USING_STD_MATH(abs);
+  EIGEN_USING_STD(abs);
   return abs(x);
 }
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 typename internal::enable_if<!(NumTraits<T>::IsSigned || NumTraits<T>::IsComplex),typename NumTraits<T>::Real>::type
 abs(const T &x) {
@@ -1293,15 +1540,15 @@
   return ::hypot(x.real(), x.imag());
 }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T exp(const T &x) {
-  EIGEN_USING_STD_MATH(exp);
+  EIGEN_USING_STD(exp);
   return exp(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(exp, exp)
 #endif
 
@@ -1347,15 +1594,15 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double expm1(const double &x) { return ::expm1(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T cos(const T &x) {
-  EIGEN_USING_STD_MATH(cos);
+  EIGEN_USING_STD(cos);
   return cos(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(cos,cos)
 #endif
 
@@ -1366,15 +1613,15 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double cos(const double &x) { return ::cos(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T sin(const T &x) {
-  EIGEN_USING_STD_MATH(sin);
+  EIGEN_USING_STD(sin);
   return sin(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(sin, sin)
 #endif
 
@@ -1385,15 +1632,15 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double sin(const double &x) { return ::sin(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T tan(const T &x) {
-  EIGEN_USING_STD_MATH(tan);
+  EIGEN_USING_STD(tan);
   return tan(x);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(tan, tan)
 #endif
 
@@ -1404,24 +1651,24 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double tan(const double &x) { return ::tan(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T acos(const T &x) {
-  EIGEN_USING_STD_MATH(acos);
+  EIGEN_USING_STD(acos);
   return acos(x);
 }
 
 #if EIGEN_HAS_CXX11_MATH
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T acosh(const T &x) {
-  EIGEN_USING_STD_MATH(acosh);
-  return acosh(x);
+  EIGEN_USING_STD(acosh);
+  return static_cast<T>(acosh(x));
 }
 #endif
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(acos, acos)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(acosh, acosh)
 #endif
@@ -1433,24 +1680,24 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double acos(const double &x) { return ::acos(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T asin(const T &x) {
-  EIGEN_USING_STD_MATH(asin);
+  EIGEN_USING_STD(asin);
   return asin(x);
 }
 
 #if EIGEN_HAS_CXX11_MATH
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T asinh(const T &x) {
-  EIGEN_USING_STD_MATH(asinh);
-  return asinh(x);
+  EIGEN_USING_STD(asinh);
+  return static_cast<T>(asinh(x));
 }
 #endif
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(asin, asin)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(asinh, asinh)
 #endif
@@ -1462,24 +1709,24 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double asin(const double &x) { return ::asin(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T atan(const T &x) {
-  EIGEN_USING_STD_MATH(atan);
-  return atan(x);
+  EIGEN_USING_STD(atan);
+  return static_cast<T>(atan(x));
 }
 
 #if EIGEN_HAS_CXX11_MATH
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T atanh(const T &x) {
-  EIGEN_USING_STD_MATH(atanh);
-  return atanh(x);
+  EIGEN_USING_STD(atanh);
+  return static_cast<T>(atanh(x));
 }
 #endif
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(atan, atan)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(atanh, atanh)
 #endif
@@ -1492,16 +1739,16 @@
 double atan(const double &x) { return ::atan(x); }
 #endif
 
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T cosh(const T &x) {
-  EIGEN_USING_STD_MATH(cosh);
-  return cosh(x);
+  EIGEN_USING_STD(cosh);
+  return static_cast<T>(cosh(x));
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(cosh, cosh)
 #endif
 
 #if defined(EIGEN_GPUCC)
@@ -1511,16 +1758,16 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double cosh(const double &x) { return ::cosh(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T sinh(const T &x) {
-  EIGEN_USING_STD_MATH(sinh);
-  return sinh(x);
+  EIGEN_USING_STD(sinh);
+  return static_cast<T>(sinh(x));
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_UNARY(sinh, sinh)
 #endif
 
 #if defined(EIGEN_GPUCC)
@@ -1530,15 +1777,15 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double sinh(const double &x) { return ::sinh(x); }
 #endif
 
 template<typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T tanh(const T &x) {
-  EIGEN_USING_STD_MATH(tanh);
+  EIGEN_USING_STD(tanh);
   return tanh(x);
 }
 
 #if (!defined(EIGEN_GPUCC)) && EIGEN_FAST_MATH && !defined(SYCL_DEVICE_ONLY)
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 float tanh(float x) { return internal::generic_fast_tanh_float(x); }
 #endif
@@ -1554,15 +1801,15 @@
 template<> EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 double tanh(const double &x) { return ::tanh(x); }
 #endif
 
 template <typename T>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
 T fmod(const T& a, const T& b) {
-  EIGEN_USING_STD_MATH(fmod);
+  EIGEN_USING_STD(fmod);
   return fmod(a, b);
 }
 
 #if defined(SYCL_DEVICE_ONLY)
 SYCL_SPECIALIZE_FLOATING_TYPES_BINARY(fmod, fmod)
 #endif
 
@@ -1716,14 +1963,19 @@
 
 template<> struct random_impl<bool>
 {
   static inline bool run()
   {
     return random<int>(0,1)==0 ? false : true;
   }
+
+  static inline bool run(const bool& a, const bool& b)
+  {
+    return random<int>(a, b)==0 ? false : true;
+  }
 };
 
 template<> struct scalar_fuzzy_impl<bool>
 {
   typedef bool RealScalar;
 
   template<typename OtherScalar> EIGEN_DEVICE_FUNC
@@ -1742,13 +1994,64 @@
   static inline bool isApproxOrLessThan(const bool& x, const bool& y, const bool&)
   {
     return (!x) || y;
   }
 
 };
 
+} // end namespace internal
+
+// Default implementations that rely on other numext implementations
+namespace internal {
+
+// Specialization for complex types that are not supported by std::expm1.
+template <typename RealScalar>
+struct expm1_impl<std::complex<RealScalar> > {
+  EIGEN_DEVICE_FUNC static inline std::complex<RealScalar> run(
+      const std::complex<RealScalar>& x) {
+    EIGEN_STATIC_ASSERT_NON_INTEGER(RealScalar)
+    RealScalar xr = x.real();
+    RealScalar xi = x.imag();
+    // expm1(z) = exp(z) - 1
+    //          = exp(x +  i * y) - 1
+    //          = exp(x) * (cos(y) + i * sin(y)) - 1
+    //          = exp(x) * cos(y) - 1 + i * exp(x) * sin(y)
+    // Imag(expm1(z)) = exp(x) * sin(y)
+    // Real(expm1(z)) = exp(x) * cos(y) - 1
+    //          = exp(x) * cos(y) - 1.
+    //          = expm1(x) + exp(x) * (cos(y) - 1)
+    //          = expm1(x) + exp(x) * (2 * sin(y / 2) ** 2)
+    RealScalar erm1 = numext::expm1<RealScalar>(xr);
+    RealScalar er = erm1 + RealScalar(1.);
+    RealScalar sin2 = numext::sin(xi / RealScalar(2.));
+    sin2 = sin2 * sin2;
+    RealScalar s = numext::sin(xi);
+    RealScalar real_part = erm1 - RealScalar(2.) * er * sin2;
+    return std::complex<RealScalar>(real_part, er * s);
+  }
+};
+
+template<typename T>
+struct rsqrt_impl {
+  EIGEN_DEVICE_FUNC
+  static EIGEN_ALWAYS_INLINE T run(const T& x) {
+    return T(1)/numext::sqrt(x);
+  }
+};
+
+#if defined(EIGEN_GPU_COMPILE_PHASE)
+template<typename T>
+struct conj_impl<std::complex<T>, true>
+{
+  EIGEN_DEVICE_FUNC
+  static inline std::complex<T> run(const std::complex<T>& x)
+  {
+    return std::complex<T>(numext::real(x), -numext::imag(x));
+  }
+};
+#endif
 
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_MATHFUNCTIONS_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Matrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Matrix.h`

 * *Files 2% similar despite different names*

```diff
@@ -25,30 +25,30 @@
       is_dynamic_size_storage = _MaxRows==Dynamic || _MaxCols==Dynamic,
       max_size = is_dynamic_size_storage ? Dynamic : _MaxRows*_MaxCols,
       default_alignment = compute_default_alignment<_Scalar,max_size>::value,
       actual_alignment = ((_Options&DontAlign)==0) ? default_alignment : 0,
       required_alignment = unpacket_traits<PacketScalar>::alignment,
       packet_access_bit = (packet_traits<_Scalar>::Vectorizable && (EIGEN_UNALIGNED_VECTORIZE || (actual_alignment>=required_alignment))) ? PacketAccessBit : 0
     };
-    
+
 public:
   typedef _Scalar Scalar;
   typedef Dense StorageKind;
   typedef Eigen::Index StorageIndex;
   typedef MatrixXpr XprKind;
   enum {
     RowsAtCompileTime = _Rows,
     ColsAtCompileTime = _Cols,
     MaxRowsAtCompileTime = _MaxRows,
     MaxColsAtCompileTime = _MaxCols,
     Flags = compute_matrix_flags<_Scalar, _Rows, _Cols, _Options, _MaxRows, _MaxCols>::ret,
     Options = _Options,
     InnerStrideAtCompileTime = 1,
     OuterStrideAtCompileTime = (Options&RowMajor) ? ColsAtCompileTime : RowsAtCompileTime,
-    
+
     // FIXME, the following flag in only used to define NeedsToAlign in PlainObjectBase
     EvaluatorFlags = LinearAccessBit | DirectAccessBit | packet_access_bit | row_major_bit,
     Alignment = actual_alignment
   };
 };
 }
 
@@ -274,15 +274,15 @@
       : Base(std::move(other))
     {
       Base::_check_template_params();
     }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     Matrix& operator=(Matrix&& other) EIGEN_NOEXCEPT_IF(std::is_nothrow_move_assignable<Scalar>::value)
     {
-      other.swap(*this);
+      Base::operator=(std::move(other));
       return *this;
     }
 #endif
 
 #if EIGEN_HAS_CXX11
     /** \copydoc PlainObjectBase(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&... args)
      *
@@ -293,33 +293,33 @@
      */
     template <typename... ArgTypes>
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     Matrix(const Scalar& a0, const Scalar& a1, const Scalar& a2,  const Scalar& a3, const ArgTypes&... args)
       : Base(a0, a1, a2, a3, args...) {}
 
     /** \brief Constructs a Matrix and initializes it from the coefficients given as initializer-lists grouped by row. \cpp11
-      * 
+      *
       * In the general case, the constructor takes a list of rows, each row being represented as a list of coefficients:
-      * 
+      *
       * Example: \include Matrix_initializer_list_23_cxx11.cpp
       * Output: \verbinclude Matrix_initializer_list_23_cxx11.out
-      * 
+      *
       * Each of the inner initializer lists must contain the exact same number of elements, otherwise an assertion is triggered.
-      * 
+      *
       * In the case of a compile-time column vector, implicit transposition from a single row is allowed.
       * Therefore <code>VectorXd{{1,2,3,4,5}}</code> is legal and the more verbose syntax
       * <code>RowVectorXd{{1},{2},{3},{4},{5}}</code> can be avoided:
-      * 
+      *
       * Example: \include Matrix_initializer_list_vector_cxx11.cpp
       * Output: \verbinclude Matrix_initializer_list_vector_cxx11.out
-      * 
+      *
       * In the case of fixed-sized matrices, the initializer list sizes must exactly match the matrix sizes,
       * and implicit transposition is allowed for compile-time vectors only.
-      * 
-      * \sa {@ref Matrix(const Scalar& a0, const Scalar& a1, const Scalar& a2,  const Scalar& a3, const ArgTypes&... args)}
+      *
+      * \sa Matrix(const Scalar& a0, const Scalar& a1, const Scalar& a2,  const Scalar& a3, const ArgTypes&... args)
       */
     EIGEN_DEVICE_FUNC
     explicit EIGEN_STRONG_INLINE Matrix(const std::initializer_list<std::initializer_list<Scalar>>& list) : Base(list) {}
 #endif // end EIGEN_HAS_CXX11
 
 #ifndef EIGEN_PARSED_BY_DOXYGEN
 
@@ -347,15 +347,15 @@
     explicit Matrix(const Scalar *data);
 
     /** \brief Constructs a vector or row-vector with given dimension. \only_for_vectors
       *
       * This is useful for dynamic-size vectors. For fixed-size vectors,
       * it is redundant to pass these parameters, so one should use the default constructor
       * Matrix() instead.
-      * 
+      *
       * \warning This constructor is disabled for fixed-size \c 1x1 matrices. For instance,
       * calling Matrix<double,1,1>(1) will call the initialization constructor: Matrix(const Scalar&).
       * For fixed-size \c 1x1 matrices it is therefore recommended to use the default
       * constructor Matrix() instead, especially when using one of the non standard
       * \c EIGEN_INITIALIZE_MATRICES_BY_{ZERO,\c NAN} macros (see \ref TopicPreprocessorDirectives).
       */
     EIGEN_STRONG_INLINE explicit Matrix(Index dim);
@@ -363,24 +363,24 @@
       * \sa Matrix(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&...) */
     Matrix(const Scalar& x);
     /** \brief Constructs an uninitialized matrix with \a rows rows and \a cols columns.
       *
       * This is useful for dynamic-size matrices. For fixed-size matrices,
       * it is redundant to pass these parameters, so one should use the default constructor
       * Matrix() instead.
-      * 
+      *
       * \warning This constructor is disabled for fixed-size \c 1x2 and \c 2x1 vectors. For instance,
       * calling Matrix2f(2,1) will call the initialization constructor: Matrix(const Scalar& x, const Scalar& y).
       * For fixed-size \c 1x2 or \c 2x1 vectors it is therefore recommended to use the default
       * constructor Matrix() instead, especially when using one of the non standard
       * \c EIGEN_INITIALIZE_MATRICES_BY_{ZERO,\c NAN} macros (see \ref TopicPreprocessorDirectives).
       */
     EIGEN_DEVICE_FUNC
     Matrix(Index rows, Index cols);
-    
+
     /** \brief Constructs an initialized 2D vector with given coefficients
       * \sa Matrix(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&...) */
     Matrix(const Scalar& x, const Scalar& y);
     #endif  // end EIGEN_PARSED_BY_DOXYGEN
 
     /** \brief Constructs an initialized 3D vector with given coefficients
       * \sa Matrix(const Scalar&, const Scalar&, const Scalar&,  const Scalar&, const ArgTypes&...)
@@ -419,16 +419,18 @@
       */
     template<typename OtherDerived>
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE Matrix(const EigenBase<OtherDerived> &other)
       : Base(other.derived())
     { }
 
-    EIGEN_DEVICE_FUNC inline Index innerStride() const { return 1; }
-    EIGEN_DEVICE_FUNC inline Index outerStride() const { return this->innerSize(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return 1; }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return this->innerSize(); }
 
     /////////// Geometry module ///////////
 
     template<typename OtherDerived>
     EIGEN_DEVICE_FUNC
     explicit Matrix(const RotationBase<OtherDerived,ColsAtCompileTime>& r);
     template<typename OtherDerived>
@@ -459,22 +461,22 @@
   * and where \c Type can be \c i for integer, \c f for float, \c d for double, \c cf for complex float, \c cd
   * for complex double.
   *
   * For example, \c Matrix3d is a fixed-size 3x3 matrix type of doubles, and \c MatrixXf is a dynamic-size matrix of floats.
   *
   * There are also \c VectorSizeType and \c RowVectorSizeType which are self-explanatory. For example, \c Vector4cf is
   * a fixed-size vector of 4 complex floats.
-  * 
+  *
   * With \cpp11, template alias are also defined for common sizes.
   * They follow the same pattern as above except that the scalar type suffix is replaced by a
   * template parameter, i.e.:
   *   - `MatrixSize<Type>` where `Size` can be \c 2,\c 3,\c 4 for fixed size square matrices or \c X for dynamic size.
   *   - `MatrixXSize<Type>` and `MatrixSizeX<Type>` where `Size` can be \c 2,\c 3,\c 4 for hybrid dynamic/fixed matrices.
   *   - `VectorSize<Type>` and `RowVectorSize<Type>` for column and row vectors.
-  * 
+  *
   * With \cpp11, you can also use fully generic column and row vector types: `Vector<Type,Size>` and `RowVector<Type,Size>`.
   *
   * \sa class Matrix
   */
 
 #define EIGEN_MAKE_TYPEDEFS(Type, TypeSuffix, Size, SizeSuffix)   \
 /** \ingroup matrixtypedefs */                                    \
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/MatrixBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/MatrixBase.h`

 * *Files 2% similar despite different names*

```diff
@@ -477,15 +477,16 @@
     EIGEN_MATRIX_FUNCTION(MatrixFunctionReturnValue, sin, sine)
     EIGEN_MATRIX_FUNCTION(MatrixSquareRootReturnValue, sqrt, square root)
     EIGEN_MATRIX_FUNCTION(MatrixLogarithmReturnValue, log, logarithm)
     EIGEN_MATRIX_FUNCTION_1(MatrixPowerReturnValue,        pow, power to \c p, const RealScalar& p)
     EIGEN_MATRIX_FUNCTION_1(MatrixComplexPowerReturnValue, pow, power to \c p, const std::complex<RealScalar>& p)
 
   protected:
-    EIGEN_DEVICE_FUNC MatrixBase() : Base() {}
+    EIGEN_DEFAULT_COPY_CONSTRUCTOR(MatrixBase)
+    EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(MatrixBase)
 
   private:
     EIGEN_DEVICE_FUNC explicit MatrixBase(int);
     EIGEN_DEVICE_FUNC MatrixBase(int,int);
     template<typename OtherDerived> EIGEN_DEVICE_FUNC explicit MatrixBase(const MatrixBase<OtherDerived>&);
   protected:
     // mixing arrays and matrices is not legal
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/NestByValue.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/NestByValue.h`

 * *Files 5% similar despite different names*

```diff
@@ -41,16 +41,16 @@
   public:
 
     typedef typename internal::dense_xpr_base<NestByValue>::type Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(NestByValue)
 
     EIGEN_DEVICE_FUNC explicit inline NestByValue(const ExpressionType& matrix) : m_expression(matrix) {}
 
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_expression.rows(); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_expression.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return m_expression.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return m_expression.cols(); }
 
     EIGEN_DEVICE_FUNC operator const ExpressionType&() const { return m_expression; }
 
     EIGEN_DEVICE_FUNC const ExpressionType& nestedExpression() const { return m_expression; }
 
   protected:
     const ExpressionType m_expression;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/NoAlias.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/NoAlias.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/NumTraits.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/NumTraits.h`

 * *Files 16% similar despite different names*

```diff
@@ -17,70 +17,91 @@
 // default implementation of digits10(), based on numeric_limits if specialized,
 // 0 for integer types, and log10(epsilon()) otherwise.
 template< typename T,
           bool use_numeric_limits = std::numeric_limits<T>::is_specialized,
           bool is_integer = NumTraits<T>::IsInteger>
 struct default_digits10_impl
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() { return std::numeric_limits<T>::digits10; }
 };
 
 template<typename T>
 struct default_digits10_impl<T,false,false> // Floating point
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() {
     using std::log10;
     using std::ceil;
     typedef typename NumTraits<T>::Real Real;
     return int(ceil(-log10(NumTraits<Real>::epsilon())));
   }
 };
 
 template<typename T>
 struct default_digits10_impl<T,false,true> // Integer
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() { return 0; }
 };
 
 
 // default implementation of digits(), based on numeric_limits if specialized,
 // 0 for integer types, and log2(epsilon()) otherwise.
 template< typename T,
           bool use_numeric_limits = std::numeric_limits<T>::is_specialized,
           bool is_integer = NumTraits<T>::IsInteger>
 struct default_digits_impl
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() { return std::numeric_limits<T>::digits; }
 };
 
 template<typename T>
 struct default_digits_impl<T,false,false> // Floating point
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() {
     using std::log;
     using std::ceil;
     typedef typename NumTraits<T>::Real Real;
     return int(ceil(-log(NumTraits<Real>::epsilon())/log(static_cast<Real>(2))));
   }
 };
 
 template<typename T>
 struct default_digits_impl<T,false,true> // Integer
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int run() { return 0; }
 };
 
 } // end namespace internal
 
+namespace numext {
+/** \internal bit-wise cast without changing the underlying bit representation. */
+
+// TODO: Replace by std::bit_cast (available in C++20)
+template <typename Tgt, typename Src>
+EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC Tgt bit_cast(const Src& src) {
+#if EIGEN_HAS_TYPE_TRAITS
+  // The behaviour of memcpy is not specified for non-trivially copyable types
+  EIGEN_STATIC_ASSERT(std::is_trivially_copyable<Src>::value, THIS_TYPE_IS_NOT_SUPPORTED);
+  EIGEN_STATIC_ASSERT(std::is_trivially_copyable<Tgt>::value && std::is_default_constructible<Tgt>::value,
+                      THIS_TYPE_IS_NOT_SUPPORTED);
+#endif
+
+  EIGEN_STATIC_ASSERT(sizeof(Src) == sizeof(Tgt), THIS_TYPE_IS_NOT_SUPPORTED);
+  Tgt tgt;
+  EIGEN_USING_STD(memcpy)
+  memcpy(&tgt, &src, sizeof(Tgt));
+  return tgt;
+}
+}  // namespace numext
+
 /** \class NumTraits
   * \ingroup Core_Module
   *
   * \brief Holds information about the various numeric (i.e. scalar) types allowed by Eigen.
   *
   * \tparam T the numeric type at hand
   *
@@ -110,17 +131,26 @@
   * \li An enum value \a RequireInitialization. It is equal to \c 1 if the constructor of the numeric type \a T must
   *     be called, and to 0 if it is safe not to call it. Default is 0 if \a T is an arithmetic type, and 1 otherwise.
   * \li An epsilon() function which, unlike <a href="http://en.cppreference.com/w/cpp/types/numeric_limits/epsilon">std::numeric_limits::epsilon()</a>,
   *     it returns a \a Real instead of a \a T.
   * \li A dummy_precision() function returning a weak epsilon value. It is mainly used as a default
   *     value by the fuzzy comparison operators.
   * \li highest() and lowest() functions returning the highest and lowest possible values respectively.
+  * \li digits() function returning the number of radix digits (non-sign digits for integers, mantissa for floating-point). This is
+  *     the analogue of <a href="http://en.cppreference.com/w/cpp/types/numeric_limits/digits">std::numeric_limits<T>::digits</a>
+  *     which is used as the default implementation if specialized.
   * \li digits10() function returning the number of decimal digits that can be represented without change. This is
   *     the analogue of <a href="http://en.cppreference.com/w/cpp/types/numeric_limits/digits10">std::numeric_limits<T>::digits10</a>
   *     which is used as the default implementation if specialized.
+  * \li min_exponent() and max_exponent() functions returning the highest and lowest possible values, respectively,
+  *     such that the radix raised to the power exponent-1 is a normalized floating-point number.  These are equivalent to
+  *     <a href="http://en.cppreference.com/w/cpp/types/numeric_limits/min_exponent">std::numeric_limits<T>::min_exponent</a>/
+  *     <a href="http://en.cppreference.com/w/cpp/types/numeric_limits/max_exponent">std::numeric_limits<T>::max_exponent</a>.
+  * \li infinity() function returning a representation of positive infinity, if available.
+  * \li quiet_NaN function returning a non-signaling "not-a-number", if available.
   */
 
 template<typename T> struct GenericNumTraits
 {
   enum {
     IsInteger = std::numeric_limits<T>::is_integer,
     IsSigned = std::numeric_limits<T>::is_signed,
@@ -136,81 +166,93 @@
                      IsInteger,
                      typename internal::conditional<sizeof(T)<=2, float, double>::type,
                      T
                    >::type NonInteger;
   typedef T Nested;
   typedef T Literal;
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline Real epsilon()
   {
     return numext::numeric_limits<T>::epsilon();
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline int digits10()
   {
     return internal::default_digits10_impl<T>::run();
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline int digits()
   {
     return internal::default_digits_impl<T>::run();
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  static inline int min_exponent()
+  {
+    return numext::numeric_limits<T>::min_exponent;
+  }
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  static inline int max_exponent()
+  {
+    return numext::numeric_limits<T>::max_exponent;
+  }
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline Real dummy_precision()
   {
     // make sure to override this for floating-point types
     return Real(0);
   }
 
-
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline T highest() {
     return (numext::numeric_limits<T>::max)();
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline T lowest()  {
     return IsInteger ? (numext::numeric_limits<T>::min)()
                      : static_cast<T>(-(numext::numeric_limits<T>::max)());
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline T infinity() {
     return numext::numeric_limits<T>::infinity();
   }
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline T quiet_NaN() {
     return numext::numeric_limits<T>::quiet_NaN();
   }
 };
 
 template<typename T> struct NumTraits : GenericNumTraits<T>
 {};
 
 template<> struct NumTraits<float>
   : GenericNumTraits<float>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline float dummy_precision() { return 1e-5f; }
 };
 
 template<> struct NumTraits<double> : GenericNumTraits<double>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline double dummy_precision() { return 1e-12; }
 };
 
 template<> struct NumTraits<long double>
   : GenericNumTraits<long double>
 {
+  EIGEN_CONSTEXPR
   static inline long double dummy_precision() { return 1e-15l; }
 };
 
 template<typename _Real> struct NumTraits<std::complex<_Real> >
   : GenericNumTraits<std::complex<_Real> >
 {
   typedef _Real Real;
@@ -219,19 +261,19 @@
     IsComplex = 1,
     RequireInitialization = NumTraits<_Real>::RequireInitialization,
     ReadCost = 2 * NumTraits<_Real>::ReadCost,
     AddCost = 2 * NumTraits<Real>::AddCost,
     MulCost = 4 * NumTraits<Real>::MulCost + 2 * NumTraits<Real>::AddCost
   };
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline Real epsilon() { return NumTraits<Real>::epsilon(); }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline Real dummy_precision() { return NumTraits<Real>::dummy_precision(); }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline int digits10() { return NumTraits<Real>::digits10(); }
 };
 
 template<typename Scalar, int Rows, int Cols, int Options, int MaxRows, int MaxCols>
 struct NumTraits<Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> >
 {
   typedef Array<Scalar, Rows, Cols, Options, MaxRows, MaxCols> ArrayType;
@@ -243,47 +285,51 @@
   typedef typename NumTraits<Scalar>::Literal Literal;
 
   enum {
     IsComplex = NumTraits<Scalar>::IsComplex,
     IsInteger = NumTraits<Scalar>::IsInteger,
     IsSigned  = NumTraits<Scalar>::IsSigned,
     RequireInitialization = 1,
-    ReadCost = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * NumTraits<Scalar>::ReadCost,
-    AddCost  = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * NumTraits<Scalar>::AddCost,
-    MulCost  = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * NumTraits<Scalar>::MulCost
+    ReadCost = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::ReadCost),
+    AddCost  = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::AddCost),
+    MulCost  = ArrayType::SizeAtCompileTime==Dynamic ? HugeCost : ArrayType::SizeAtCompileTime * int(NumTraits<Scalar>::MulCost)
   };
 
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline RealScalar epsilon() { return NumTraits<RealScalar>::epsilon(); }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static inline RealScalar dummy_precision() { return NumTraits<RealScalar>::dummy_precision(); }
 
+  EIGEN_CONSTEXPR
   static inline int digits10() { return NumTraits<Scalar>::digits10(); }
 };
 
 template<> struct NumTraits<std::string>
   : GenericNumTraits<std::string>
 {
   enum {
     RequireInitialization = 1,
     ReadCost = HugeCost,
     AddCost  = HugeCost,
     MulCost  = HugeCost
   };
 
+  EIGEN_CONSTEXPR
   static inline int digits10() { return 0; }
 
 private:
   static inline std::string epsilon();
   static inline std::string dummy_precision();
   static inline std::string lowest();
   static inline std::string highest();
   static inline std::string infinity();
   static inline std::string quiet_NaN();
 };
 
 // Empty specialization for void to allow template specialization based on NumTraits<T>::Real with T==void and SFINAE.
 template<> struct NumTraits<void> {};
 
+template<> struct NumTraits<bool> : GenericNumTraits<bool> {};
+
 } // end namespace Eigen
 
 #endif // EIGEN_NUMTRAITS_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/PartialReduxEvaluator.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/PartialReduxEvaluator.h`

 * *Files 2% similar despite different names*

```diff
@@ -50,20 +50,25 @@
   };
 
 };
 
 /* Value to be returned when size==0 , by default let's return 0 */
 template<typename PacketType,typename Func>
 EIGEN_DEVICE_FUNC
-PacketType packetwise_redux_empty_value(const Func& ) { return pset1<PacketType>(0); }
+PacketType packetwise_redux_empty_value(const Func& ) {
+  const typename unpacket_traits<PacketType>::type zero(0);
+  return pset1<PacketType>(zero);
+}
 
 /* For products the default is 1 */
 template<typename PacketType,typename Scalar>
 EIGEN_DEVICE_FUNC
-PacketType packetwise_redux_empty_value(const scalar_product_op<Scalar,Scalar>& ) { return pset1<PacketType>(1); }
+PacketType packetwise_redux_empty_value(const scalar_product_op<Scalar,Scalar>& ) {
+  return pset1<PacketType>(Scalar(1));
+}
 
 /* Perform the actual reduction */
 template<typename Func, typename Evaluator,
          int Unrolling = packetwise_redux_traits<Func, Evaluator>::Unrolling
 >
 struct packetwise_redux_impl;
 
@@ -141,15 +146,15 @@
   enum {
     TraversalSize = Direction==int(Vertical) ? int(ArgType::RowsAtCompileTime) :  int(ArgType::ColsAtCompileTime)
   };
   typedef typename MemberOp::template Cost<int(TraversalSize)> CostOpType;
   enum {
     CoeffReadCost = TraversalSize==Dynamic ? HugeCost
                   : TraversalSize==0 ? 1
-                  : TraversalSize * evaluator<ArgType>::CoeffReadCost + int(CostOpType::value),
+                  : int(TraversalSize) * int(evaluator<ArgType>::CoeffReadCost) + int(CostOpType::value),
     
     _ArgFlags = evaluator<ArgType>::Flags,
 
     _Vectorizable =  bool(int(_ArgFlags)&PacketAccessBit)
                   && bool(MemberOp::Vectorizable)
                   && (Direction==int(Vertical) ? bool(_ArgFlags&RowMajorBit) : (_ArgFlags&RowMajorBit)==0)
                   && (TraversalSize!=0),
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/PermutationMatrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/PermutationMatrix.h`

 * *Files 3% similar despite different names*

```diff
@@ -83,25 +83,14 @@
     {
       setIdentity(tr.size());
       for(Index k=size()-1; k>=0; --k)
         applyTranspositionOnTheRight(k,tr.coeff(k));
       return derived();
     }
 
-    #ifndef EIGEN_PARSED_BY_DOXYGEN
-    /** This is a special case of the templated operator=. Its purpose is to
-      * prevent a default operator= from hiding the templated operator=.
-      */
-    Derived& operator=(const PermutationBase& other)
-    {
-      indices() = other.indices();
-      return derived();
-    }
-    #endif
-
     /** \returns the number of rows */
     inline EIGEN_DEVICE_FUNC Index rows() const { return Index(indices().size()); }
 
     /** \returns the number of columns */
     inline EIGEN_DEVICE_FUNC Index cols() const { return Index(indices().size()); }
 
     /** \returns the size of a side of the respective square matrix, i.e., the number of indices */
@@ -329,20 +318,14 @@
     }
 
     /** Copy constructor. */
     template<typename OtherDerived>
     inline PermutationMatrix(const PermutationBase<OtherDerived>& other)
       : m_indices(other.indices()) {}
 
-    #ifndef EIGEN_PARSED_BY_DOXYGEN
-    /** Standard copy constructor. Defined only to prevent a default copy constructor
-      * from hiding the other templated constructor */
-    inline PermutationMatrix(const PermutationMatrix& other) : m_indices(other.indices()) {}
-    #endif
-
     /** Generic constructor from expression of the indices. The indices
       * array has the meaning that the permutations sends each integer i to indices[i].
       *
       * \warning It is your responsibility to check that the indices array that you passes actually
       * describes a permutation, i.e., each value between 0 and n-1 occurs exactly once, where n is the
       * array's size.
       */
@@ -369,25 +352,14 @@
     /** Assignment from the Transpositions \a tr */
     template<typename Other>
     PermutationMatrix& operator=(const TranspositionsBase<Other>& tr)
     {
       return Base::operator=(tr.derived());
     }
 
-    #ifndef EIGEN_PARSED_BY_DOXYGEN
-    /** This is a special case of the templated operator=. Its purpose is to
-      * prevent a default operator= from hiding the templated operator=.
-      */
-    PermutationMatrix& operator=(const PermutationMatrix& other)
-    {
-      m_indices = other.m_indices;
-      return *this;
-    }
-    #endif
-
     /** const version of indices(). */
     const IndicesType& indices() const { return m_indices; }
     /** \returns a reference to the stored array representing the permutation. */
     IndicesType& indices() { return m_indices; }
 
 
     /**** multiplication helpers to hopefully get RVO ****/
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/PlainObjectBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/PlainObjectBase.h`

 * *Files 2% similar despite different names*

```diff
@@ -9,18 +9,18 @@
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_DENSESTORAGEBASE_H
 #define EIGEN_DENSESTORAGEBASE_H
 
 #if defined(EIGEN_INITIALIZE_MATRICES_BY_ZERO)
 # define EIGEN_INITIALIZE_COEFFS
-# define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED for(int i=0;i<base().size();++i) coeffRef(i)=Scalar(0);
+# define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED for(Index i=0;i<base().size();++i) coeffRef(i)=Scalar(0);
 #elif defined(EIGEN_INITIALIZE_MATRICES_BY_NAN)
 # define EIGEN_INITIALIZE_COEFFS
-# define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED for(int i=0;i<base().size();++i) coeffRef(i)=std::numeric_limits<Scalar>::quiet_NaN();
+# define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED for(Index i=0;i<base().size();++i) coeffRef(i)=std::numeric_limits<Scalar>::quiet_NaN();
 #else
 # undef EIGEN_INITIALIZE_COEFFS
 # define EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
 #endif
 
 namespace Eigen {
 
@@ -114,24 +114,16 @@
     using Base::SizeAtCompileTime;
     using Base::MaxRowsAtCompileTime;
     using Base::MaxColsAtCompileTime;
     using Base::MaxSizeAtCompileTime;
     using Base::IsVectorAtCompileTime;
     using Base::Flags;
 
-    template<typename PlainObjectType, int MapOptions, typename StrideType> friend class Eigen::Map;
-    friend  class Eigen::Map<Derived, Unaligned>;
     typedef Eigen::Map<Derived, Unaligned>  MapType;
-    friend  class Eigen::Map<const Derived, Unaligned>;
     typedef const Eigen::Map<const Derived, Unaligned> ConstMapType;
-#if EIGEN_MAX_ALIGN_BYTES>0
-    // for EIGEN_MAX_ALIGN_BYTES==0, AlignedMax==Unaligned, and many compilers generate warnings for friend-ing a class twice.
-    friend  class Eigen::Map<Derived, AlignedMax>;
-    friend  class Eigen::Map<const Derived, AlignedMax>;
-#endif
     typedef Eigen::Map<Derived, AlignedMax> AlignedMapType;
     typedef const Eigen::Map<const Derived, AlignedMax> ConstAlignedMapType;
     template<typename StrideType> struct StridedMapType { typedef Eigen::Map<Derived, Unaligned, StrideType> type; };
     template<typename StrideType> struct StridedConstMapType { typedef Eigen::Map<const Derived, Unaligned, StrideType> type; };
     template<typename StrideType> struct StridedAlignedMapType { typedef Eigen::Map<Derived, AlignedMax, StrideType> type; };
     template<typename StrideType> struct StridedConstAlignedMapType { typedef Eigen::Map<const Derived, AlignedMax, StrideType> type; };
 
@@ -143,18 +135,18 @@
     EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)
 
     EIGEN_DEVICE_FUNC
     Base& base() { return *static_cast<Base*>(this); }
     EIGEN_DEVICE_FUNC
     const Base& base() const { return *static_cast<const Base*>(this); }
 
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index rows() const { return m_storage.rows(); }
-    EIGEN_DEVICE_FUNC
-    EIGEN_STRONG_INLINE Index cols() const { return m_storage.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_storage.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_storage.cols(); }
 
     /** This is an overloaded version of DenseCoeffsBase<Derived,ReadOnlyAccessors>::coeff(Index,Index) const
       * provided to by-pass the creation of an evaluator of the expression, thus saving compilation efforts.
       *
       * See DenseCoeffsBase<Derived,ReadOnlyAccessors>::coeff(Index) const for details. */
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE const Scalar& coeff(Index rowId, Index colId) const
@@ -504,16 +496,16 @@
       : m_storage( std::move(other.m_storage) )
     {
     }
 
     EIGEN_DEVICE_FUNC
     PlainObjectBase& operator=(PlainObjectBase&& other) EIGEN_NOEXCEPT
     {
-      using std::swap;
-      swap(m_storage, other.m_storage);
+      _check_template_params();
+      m_storage = std::move(other.m_storage);
       return *this;
     }
 #endif
 
     /** Copy constructor */
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE PlainObjectBase(const PlainObjectBase& other)
@@ -526,33 +518,33 @@
 //       EIGEN_INITIALIZE_COEFFS_IF_THAT_OPTION_IS_ENABLED
     }
 
     #if EIGEN_HAS_CXX11
     /** \brief Construct a row of column vector with fixed size from an arbitrary number of coefficients. \cpp11
       *
       * \only_for_vectors
-      * 
+      *
       * This constructor is for 1D array or vectors with more than 4 coefficients.
       * There exists C++98 analogue constructors for fixed-size array/vector having 1, 2, 3, or 4 coefficients.
-      * 
-      * \warning To construct a column (resp. row) vector of fixed length, the number of values passed to this 
+      *
+      * \warning To construct a column (resp. row) vector of fixed length, the number of values passed to this
       * constructor must match the the fixed number of rows (resp. columns) of \c *this.
       */
     template <typename... ArgTypes>
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     PlainObjectBase(const Scalar& a0, const Scalar& a1, const Scalar& a2,  const Scalar& a3, const ArgTypes&... args)
       : m_storage()
     {
       _check_template_params();
       EIGEN_STATIC_ASSERT_VECTOR_SPECIFIC_SIZE(PlainObjectBase, sizeof...(args) + 4);
       m_storage.data()[0] = a0;
       m_storage.data()[1] = a1;
       m_storage.data()[2] = a2;
       m_storage.data()[3] = a3;
-      int i = 4;
+      Index i = 4;
       auto x = {(m_storage.data()[i++] = args, 0)...};
       static_cast<void>(x);
     }
 
     /** \brief Constructs a Matrix or Array and initializes it by elements given by an initializer list of initializer
       * lists \cpp11
       */
@@ -572,15 +564,15 @@
         eigen_assert(list_size == static_cast<size_t>(RowsAtCompileTime) || RowsAtCompileTime == Dynamic);
         resize(list_size, ColsAtCompileTime);
         std::copy(list.begin()->begin(), list.begin()->end(), m_storage.data());
       } else {
         eigen_assert(list.size() == static_cast<size_t>(RowsAtCompileTime) || RowsAtCompileTime == Dynamic);
         eigen_assert(list_size == static_cast<size_t>(ColsAtCompileTime) || ColsAtCompileTime == Dynamic);
         resize(list.size(), list_size);
-       
+
         Index row_index = 0;
         for (const std::initializer_list<Scalar>& row : list) {
           eigen_assert(list_size == row.size());
           Index col_index = 0;
           for (const Scalar& e : row) {
             coeffRef(row_index, col_index) = e;
             ++col_index;
@@ -713,26 +705,34 @@
     static inline typename StridedAlignedMapType<Stride<Outer, Inner> >::type MapAligned(Scalar* data, Index rows, Index cols, const Stride<Outer, Inner>& stride)
     { return typename StridedAlignedMapType<Stride<Outer, Inner> >::type(data, rows, cols, stride); }
     //@}
 
     using Base::setConstant;
     EIGEN_DEVICE_FUNC Derived& setConstant(Index size, const Scalar& val);
     EIGEN_DEVICE_FUNC Derived& setConstant(Index rows, Index cols, const Scalar& val);
+    EIGEN_DEVICE_FUNC Derived& setConstant(NoChange_t, Index cols, const Scalar& val);
+    EIGEN_DEVICE_FUNC Derived& setConstant(Index rows, NoChange_t, const Scalar& val);
 
     using Base::setZero;
     EIGEN_DEVICE_FUNC Derived& setZero(Index size);
     EIGEN_DEVICE_FUNC Derived& setZero(Index rows, Index cols);
+    EIGEN_DEVICE_FUNC Derived& setZero(NoChange_t, Index cols);
+    EIGEN_DEVICE_FUNC Derived& setZero(Index rows, NoChange_t);
 
     using Base::setOnes;
     EIGEN_DEVICE_FUNC Derived& setOnes(Index size);
     EIGEN_DEVICE_FUNC Derived& setOnes(Index rows, Index cols);
+    EIGEN_DEVICE_FUNC Derived& setOnes(NoChange_t, Index cols);
+    EIGEN_DEVICE_FUNC Derived& setOnes(Index rows, NoChange_t);
 
     using Base::setRandom;
     Derived& setRandom(Index size);
     Derived& setRandom(Index rows, Index cols);
+    Derived& setRandom(NoChange_t, Index cols);
+    Derived& setRandom(Index rows, NoChange_t);
 
     #ifdef EIGEN_PLAINOBJECTBASE_PLUGIN
     #include EIGEN_PLAINOBJECTBASE_PLUGIN
     #endif
 
   protected:
     /** \internal Resizes *this in preparation for assigning \a other to it.
@@ -963,28 +963,39 @@
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     void swap(DenseBase<OtherDerived> const & other)
     { Base::swap(other.derived()); }
 
     EIGEN_DEVICE_FUNC
     static EIGEN_STRONG_INLINE void _check_template_params()
     {
-      EIGEN_STATIC_ASSERT((EIGEN_IMPLIES(MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1, (Options&RowMajor)==RowMajor)
-                        && EIGEN_IMPLIES(MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1, (Options&RowMajor)==0)
+      EIGEN_STATIC_ASSERT((EIGEN_IMPLIES(MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1, (int(Options)&RowMajor)==RowMajor)
+                        && EIGEN_IMPLIES(MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1, (int(Options)&RowMajor)==0)
                         && ((RowsAtCompileTime == Dynamic) || (RowsAtCompileTime >= 0))
                         && ((ColsAtCompileTime == Dynamic) || (ColsAtCompileTime >= 0))
                         && ((MaxRowsAtCompileTime == Dynamic) || (MaxRowsAtCompileTime >= 0))
                         && ((MaxColsAtCompileTime == Dynamic) || (MaxColsAtCompileTime >= 0))
                         && (MaxRowsAtCompileTime == RowsAtCompileTime || RowsAtCompileTime==Dynamic)
                         && (MaxColsAtCompileTime == ColsAtCompileTime || ColsAtCompileTime==Dynamic)
                         && (Options & (DontAlign|RowMajor)) == Options),
         INVALID_MATRIX_TEMPLATE_PARAMETERS)
     }
 
     enum { IsPlainObjectBase = 1 };
 #endif
+  public:
+    // These apparently need to be down here for nvcc+icc to prevent duplicate
+    // Map symbol.
+    template<typename PlainObjectType, int MapOptions, typename StrideType> friend class Eigen::Map;
+    friend class Eigen::Map<Derived, Unaligned>;
+    friend class Eigen::Map<const Derived, Unaligned>;
+#if EIGEN_MAX_ALIGN_BYTES>0
+    // for EIGEN_MAX_ALIGN_BYTES==0, AlignedMax==Unaligned, and many compilers generate warnings for friend-ing a class twice.
+    friend class Eigen::Map<Derived, AlignedMax>;
+    friend class Eigen::Map<const Derived, AlignedMax>;
+#endif
 };
 
 namespace internal {
 
 template <typename Derived, typename OtherDerived, bool IsVector>
 struct conservative_resize_like_impl
 {
@@ -1004,15 +1015,15 @@
     {
       internal::check_rows_cols_for_overflow<Derived::MaxSizeAtCompileTime>::run(rows, cols);
       _this.derived().m_storage.conservativeResize(rows*cols,rows,cols);
     }
     else
     {
       // The storage order does not allow us to use reallocation.
-      typename Derived::PlainObject tmp(rows,cols);
+      Derived tmp(rows,cols);
       const Index common_rows = numext::mini(rows, _this.rows());
       const Index common_cols = numext::mini(cols, _this.cols());
       tmp.block(0,0,common_rows,common_cols) = _this.block(0,0,common_rows,common_cols);
       _this.derived().swap(tmp);
     }
   }
 
@@ -1039,15 +1050,15 @@
         _this.bottomRightCorner(new_rows, other.cols()) = other.bottomRows(new_rows);
       else if (new_cols>0)
         _this.bottomRightCorner(other.rows(), new_cols) = other.rightCols(new_cols);
     }
     else
     {
       // The storage order does not allow us to use reallocation.
-      typename Derived::PlainObject tmp(other);
+      Derived tmp(other);
       const Index common_rows = numext::mini(tmp.rows(), _this.rows());
       const Index common_cols = numext::mini(tmp.cols(), _this.cols());
       tmp.block(0,0,common_rows,common_cols) = _this.block(0,0,common_rows,common_cols);
       _this.derived().swap(tmp);
     }
   }
 };
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Product.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Product.h`

 * *Files 6% similar despite different names*

```diff
@@ -19,33 +19,33 @@
 template<typename Lhs, typename Rhs, int Option>
 struct traits<Product<Lhs, Rhs, Option> >
 {
   typedef typename remove_all<Lhs>::type LhsCleaned;
   typedef typename remove_all<Rhs>::type RhsCleaned;
   typedef traits<LhsCleaned> LhsTraits;
   typedef traits<RhsCleaned> RhsTraits;
-  
+
   typedef MatrixXpr XprKind;
-  
+
   typedef typename ScalarBinaryOpTraits<typename traits<LhsCleaned>::Scalar, typename traits<RhsCleaned>::Scalar>::ReturnType Scalar;
   typedef typename product_promote_storage_type<typename LhsTraits::StorageKind,
                                                 typename RhsTraits::StorageKind,
                                                 internal::product_type<Lhs,Rhs>::ret>::ret StorageKind;
   typedef typename promote_index_type<typename LhsTraits::StorageIndex,
                                       typename RhsTraits::StorageIndex>::type StorageIndex;
-  
+
   enum {
     RowsAtCompileTime    = LhsTraits::RowsAtCompileTime,
     ColsAtCompileTime    = RhsTraits::ColsAtCompileTime,
     MaxRowsAtCompileTime = LhsTraits::MaxRowsAtCompileTime,
     MaxColsAtCompileTime = RhsTraits::MaxColsAtCompileTime,
-    
+
     // FIXME: only needed by GeneralMatrixMatrixTriangular
     InnerSize = EIGEN_SIZE_MIN_PREFER_FIXED(LhsTraits::ColsAtCompileTime, RhsTraits::RowsAtCompileTime),
-    
+
     // The storage order is somewhat arbitrary here. The correct one will be determined through the evaluator.
     Flags = (MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1) ? RowMajorBit
           : (MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1) ? 0
           : (   ((LhsTraits::Flags&NoPreferredStorageOrderBit) && (RhsTraits::Flags&RowMajorBit))
              || ((RhsTraits::Flags&NoPreferredStorageOrderBit) && (LhsTraits::Flags&RowMajorBit)) ) ? RowMajorBit
           : NoPreferredStorageOrderBit
   };
@@ -70,18 +70,18 @@
 template<typename _Lhs, typename _Rhs, int Option>
 class Product : public ProductImpl<_Lhs,_Rhs,Option,
                                    typename internal::product_promote_storage_type<typename internal::traits<_Lhs>::StorageKind,
                                                                                    typename internal::traits<_Rhs>::StorageKind,
                                                                                    internal::product_type<_Lhs,_Rhs>::ret>::ret>
 {
   public:
-    
+
     typedef _Lhs Lhs;
     typedef _Rhs Rhs;
-    
+
     typedef typename ProductImpl<
         Lhs, Rhs, Option,
         typename internal::product_promote_storage_type<typename internal::traits<Lhs>::StorageKind,
                                                         typename internal::traits<Rhs>::StorageKind,
                                                         internal::product_type<Lhs,Rhs>::ret>::ret>::Base Base;
     EIGEN_GENERIC_PUBLIC_INTERFACE(Product)
 
@@ -94,32 +94,32 @@
     Product(const Lhs& lhs, const Rhs& rhs) : m_lhs(lhs), m_rhs(rhs)
     {
       eigen_assert(lhs.cols() == rhs.rows()
         && "invalid matrix product"
         && "if you wanted a coeff-wise or a dot product use the respective explicit functions");
     }
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index rows() const { return m_lhs.rows(); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index cols() const { return m_rhs.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_lhs.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const LhsNestedCleaned& lhs() const { return m_lhs; }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const RhsNestedCleaned& rhs() const { return m_rhs; }
 
   protected:
 
     LhsNested m_lhs;
     RhsNested m_rhs;
 };
 
 namespace internal {
-  
+
 template<typename Lhs, typename Rhs, int Option, int ProductTag = internal::product_type<Lhs,Rhs>::ret>
 class dense_product_base
  : public internal::dense_xpr_base<Product<Lhs,Rhs,Option> >::type
 {};
 
 /** Conversion to scalar for inner-products */
 template<typename Lhs, typename Rhs, int Option>
@@ -127,15 +127,15 @@
  : public internal::dense_xpr_base<Product<Lhs,Rhs,Option> >::type
 {
   typedef Product<Lhs,Rhs,Option> ProductXpr;
   typedef typename internal::dense_xpr_base<ProductXpr>::type Base;
 public:
   using Base::derived;
   typedef typename Base::Scalar Scalar;
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE operator const Scalar() const
   {
     return internal::evaluator<ProductXpr>(derived()).coeff(0,0);
   }
 };
 
 } // namespace internal
@@ -149,43 +149,43 @@
 };
 
 template<typename Lhs, typename Rhs, int Option>
 class ProductImpl<Lhs,Rhs,Option,Dense>
   : public internal::dense_product_base<Lhs,Rhs,Option>
 {
     typedef Product<Lhs, Rhs, Option> Derived;
-    
+
   public:
-    
+
     typedef typename internal::dense_product_base<Lhs, Rhs, Option> Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(Derived)
   protected:
     enum {
-      IsOneByOne = (RowsAtCompileTime == 1 || RowsAtCompileTime == Dynamic) && 
+      IsOneByOne = (RowsAtCompileTime == 1 || RowsAtCompileTime == Dynamic) &&
                    (ColsAtCompileTime == 1 || ColsAtCompileTime == Dynamic),
       EnableCoeff = IsOneByOne || Option==LazyProduct
     };
-    
+
   public:
-  
+
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(Index row, Index col) const
     {
       EIGEN_STATIC_ASSERT(EnableCoeff, THIS_METHOD_IS_ONLY_FOR_INNER_OR_LAZY_PRODUCTS);
       eigen_assert( (Option==LazyProduct) || (this->rows() == 1 && this->cols() == 1) );
-      
+
       return internal::evaluator<Derived>(derived()).coeff(row,col);
     }
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar coeff(Index i) const
     {
       EIGEN_STATIC_ASSERT(EnableCoeff, THIS_METHOD_IS_ONLY_FOR_INNER_OR_LAZY_PRODUCTS);
       eigen_assert( (Option==LazyProduct) || (this->rows() == 1 && this->cols() == 1) );
-      
+
       return internal::evaluator<Derived>(derived()).coeff(i);
     }
-    
-  
+
+
 };
 
 } // end namespace Eigen
 
 #endif // EIGEN_PRODUCT_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ProductEvaluators.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ProductEvaluators.h`

 * *Files 2% similar despite different names*

```diff
@@ -10,35 +10,35 @@
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 
 #ifndef EIGEN_PRODUCTEVALUATORS_H
 #define EIGEN_PRODUCTEVALUATORS_H
 
 namespace Eigen {
-  
+
 namespace internal {
 
 /** \internal
   * Evaluator of a product expression.
   * Since products require special treatments to handle all possible cases,
   * we simply defer the evaluation logic to a product_evaluator class
   * which offers more partial specialization possibilities.
-  * 
+  *
   * \sa class product_evaluator
   */
 template<typename Lhs, typename Rhs, int Options>
-struct evaluator<Product<Lhs, Rhs, Options> > 
+struct evaluator<Product<Lhs, Rhs, Options> >
  : public product_evaluator<Product<Lhs, Rhs, Options> >
 {
   typedef Product<Lhs, Rhs, Options> XprType;
   typedef product_evaluator<XprType> Base;
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& xpr) : Base(xpr) {}
 };
- 
+
 // Catch "scalar * ( A * B )" and transform it to "(A*scalar) * B"
 // TODO we should apply that rule only if that's really helpful
 template<typename Lhs, typename Rhs, typename Scalar1, typename Scalar2, typename Plain1>
 struct evaluator_assume_aliasing<CwiseBinaryOp<internal::scalar_product_op<Scalar1,Scalar2>,
                                                const CwiseNullaryOp<internal::scalar_constant_op<Scalar1>, Plain1>,
                                                const Product<Lhs, Rhs, DefaultProduct> > >
 {
@@ -58,20 +58,20 @@
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& xpr)
     : Base(xpr.lhs().functor().m_other * xpr.rhs().lhs() * xpr.rhs().rhs())
   {}
 };
 
 
 template<typename Lhs, typename Rhs, int DiagIndex>
-struct evaluator<Diagonal<const Product<Lhs, Rhs, DefaultProduct>, DiagIndex> > 
+struct evaluator<Diagonal<const Product<Lhs, Rhs, DefaultProduct>, DiagIndex> >
  : public evaluator<Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex> >
 {
   typedef Diagonal<const Product<Lhs, Rhs, DefaultProduct>, DiagIndex> XprType;
   typedef evaluator<Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex> > Base;
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit evaluator(const XprType& xpr)
     : Base(Diagonal<const Product<Lhs, Rhs, LazyProduct>, DiagIndex>(
         Product<Lhs, Rhs, LazyProduct>(xpr.nestedExpression().lhs(), xpr.nestedExpression().rhs()),
         xpr.index() ))
   {}
 };
 
@@ -104,31 +104,31 @@
   };
 
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   explicit product_evaluator(const XprType& xpr)
     : m_result(xpr.rows(), xpr.cols())
   {
     ::new (static_cast<Base*>(this)) Base(m_result);
-    
+
 // FIXME shall we handle nested_eval here?,
 // if so, then we must take care at removing the call to nested_eval in the specializations (e.g., in permutation_matrix_product, transposition_matrix_product, etc.)
 //     typedef typename internal::nested_eval<Lhs,Rhs::ColsAtCompileTime>::type LhsNested;
 //     typedef typename internal::nested_eval<Rhs,Lhs::RowsAtCompileTime>::type RhsNested;
 //     typedef typename internal::remove_all<LhsNested>::type LhsNestedCleaned;
 //     typedef typename internal::remove_all<RhsNested>::type RhsNestedCleaned;
-//     
+//
 //     const LhsNested lhs(xpr.lhs());
 //     const RhsNested rhs(xpr.rhs());
-//   
+//
 //     generic_product_impl<LhsNestedCleaned, RhsNestedCleaned>::evalTo(m_result, lhs, rhs);
 
     generic_product_impl<Lhs, Rhs, LhsShape, RhsShape, ProductTag>::evalTo(m_result, xpr.lhs(), xpr.rhs());
   }
-  
-protected:  
+
+protected:
   PlainObject m_result;
 };
 
 // The following three shortcuts are enabled only if the scalar types match exactly.
 // TODO: we could enable them for different scalar types when the product is not vectorized.
 
 // Dense = Product
@@ -246,21 +246,21 @@
 struct generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,InnerProduct>
 {
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     dst.coeffRef(0,0) = (lhs.transpose().cwiseProduct(rhs)).sum();
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     dst.coeffRef(0,0) += (lhs.transpose().cwiseProduct(rhs)).sum();
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   { dst.coeffRef(0,0) -= (lhs.transpose().cwiseProduct(rhs)).sum(); }
 };
 
 
 /***********************************************************************
@@ -294,72 +294,72 @@
 }
 
 template<typename Lhs, typename Rhs>
 struct generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,OuterProduct>
 {
   template<typename T> struct is_row_major : internal::conditional<(int(T::Flags)&RowMajorBit), internal::true_type, internal::false_type>::type {};
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   // TODO it would be nice to be able to exploit our *_assign_op functors for that purpose
   struct set  { template<typename Dst, typename Src> EIGEN_DEVICE_FUNC void operator()(const Dst& dst, const Src& src) const { dst.const_cast_derived()  = src; } };
   struct add  { template<typename Dst, typename Src> EIGEN_DEVICE_FUNC void operator()(const Dst& dst, const Src& src) const { dst.const_cast_derived() += src; } };
   struct sub  { template<typename Dst, typename Src> EIGEN_DEVICE_FUNC void operator()(const Dst& dst, const Src& src) const { dst.const_cast_derived() -= src; } };
   struct adds {
     Scalar m_scale;
     explicit adds(const Scalar& s) : m_scale(s) {}
     template<typename Dst, typename Src> void EIGEN_DEVICE_FUNC operator()(const Dst& dst, const Src& src) const {
       dst.const_cast_derived() += m_scale * src;
     }
   };
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     internal::outer_product_selector_run(dst, lhs, rhs, set(), is_row_major<Dst>());
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     internal::outer_product_selector_run(dst, lhs, rhs, add(), is_row_major<Dst>());
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     internal::outer_product_selector_run(dst, lhs, rhs, sub(), is_row_major<Dst>());
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void scaleAndAddTo(Dst& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
     internal::outer_product_selector_run(dst, lhs, rhs, adds(alpha), is_row_major<Dst>());
   }
-  
+
 };
 
 
 // This base class provides default implementations for evalTo, addTo, subTo, in terms of scaleAndAddTo
 template<typename Lhs, typename Rhs, typename Derived>
 struct generic_product_impl_base
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   { dst.setZero(); scaleAndAddTo(dst, lhs, rhs, Scalar(1)); }
 
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   { scaleAndAddTo(dst,lhs, rhs, Scalar(1)); }
 
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   { scaleAndAddTo(dst, lhs, rhs, Scalar(-1)); }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void scaleAndAddTo(Dst& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   { Derived::scaleAndAddTo(dst,lhs,rhs,alpha); }
 
 };
 
 template<typename Lhs, typename Rhs>
@@ -371,43 +371,48 @@
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
   enum { Side = Lhs::IsVectorAtCompileTime ? OnTheLeft : OnTheRight };
   typedef typename internal::remove_all<typename internal::conditional<int(Side)==OnTheRight,LhsNested,RhsNested>::type>::type MatrixType;
 
   template<typename Dest>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
+    // Fallback to inner product if both the lhs and rhs is a runtime vector.
+    if (lhs.rows() == 1 && rhs.cols() == 1) {
+      dst.coeffRef(0,0) += alpha * lhs.row(0).conjugate().dot(rhs.col(0));
+      return;
+    }
     LhsNested actual_lhs(lhs);
     RhsNested actual_rhs(rhs);
     internal::gemv_dense_selector<Side,
                             (int(MatrixType::Flags)&RowMajorBit) ? RowMajor : ColMajor,
                             bool(internal::blas_traits<MatrixType>::HasUsableDirectAccess)
                            >::run(actual_lhs, actual_rhs, dst, alpha);
   }
 };
 
 template<typename Lhs, typename Rhs>
-struct generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,CoeffBasedProductMode> 
+struct generic_product_impl<Lhs,Rhs,DenseShape,DenseShape,CoeffBasedProductMode>
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     // Same as: dst.noalias() = lhs.lazyProduct(rhs);
     // but easier on the compiler side
     call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::assign_op<typename Dst::Scalar,Scalar>());
   }
 
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void addTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     // dst.noalias() += lhs.lazyProduct(rhs);
     call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::add_assign_op<typename Dst::Scalar,Scalar>());
   }
-  
+
   template<typename Dst>
   static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void subTo(Dst& dst, const Lhs& lhs, const Rhs& rhs)
   {
     // dst.noalias() -= lhs.lazyProduct(rhs);
     call_assignment_no_alias(dst, lhs.lazyProduct(rhs), internal::sub_assign_op<typename Dst::Scalar,Scalar>());
   }
 
@@ -432,16 +437,16 @@
     enum {
       HasScalarFactor = blas_traits<Lhs>::HasScalarFactor || blas_traits<Rhs>::HasScalarFactor,
       ConjLhs = blas_traits<Lhs>::NeedToConjugate,
       ConjRhs = blas_traits<Rhs>::NeedToConjugate
     };
     // FIXME: in c++11 this should be auto, and extractScalarFactor should also return auto
     //        this is important for real*complex_mat
-    Scalar actualAlpha =    blas_traits<Lhs>::extractScalarFactor(lhs)
-                          * blas_traits<Rhs>::extractScalarFactor(rhs);
+    Scalar actualAlpha = combine_scalar_factors<Scalar>(lhs, rhs);
+
     eval_dynamic_impl(dst,
                       blas_traits<Lhs>::extract(lhs).template conjugateIf<ConjLhs>(),
                       blas_traits<Rhs>::extract(rhs).template conjugateIf<ConjRhs>(),
                       func,
                       actualAlpha,
                       typename conditional<HasScalarFactor,true_type,false_type>::type());
   }
@@ -516,15 +521,15 @@
 #endif
   }
 
   // Everything below here is taken from CoeffBasedProduct.h
 
   typedef typename internal::nested_eval<Lhs,Rhs::ColsAtCompileTime>::type LhsNested;
   typedef typename internal::nested_eval<Rhs,Lhs::RowsAtCompileTime>::type RhsNested;
-  
+
   typedef typename internal::remove_all<LhsNested>::type LhsNestedCleaned;
   typedef typename internal::remove_all<RhsNested>::type RhsNestedCleaned;
 
   typedef evaluator<LhsNestedCleaned> LhsEtorType;
   typedef evaluator<RhsNestedCleaned> RhsEtorType;
 
   enum {
@@ -535,52 +540,52 @@
     MaxColsAtCompileTime = RhsNestedCleaned::MaxColsAtCompileTime
   };
 
   typedef typename find_best_packet<Scalar,RowsAtCompileTime>::type LhsVecPacketType;
   typedef typename find_best_packet<Scalar,ColsAtCompileTime>::type RhsVecPacketType;
 
   enum {
-      
+
     LhsCoeffReadCost = LhsEtorType::CoeffReadCost,
     RhsCoeffReadCost = RhsEtorType::CoeffReadCost,
     CoeffReadCost = InnerSize==0 ? NumTraits<Scalar>::ReadCost
                   : InnerSize == Dynamic ? HugeCost
-                  : InnerSize * (NumTraits<Scalar>::MulCost + LhsCoeffReadCost + RhsCoeffReadCost)
+                    : InnerSize * (NumTraits<Scalar>::MulCost + int(LhsCoeffReadCost) + int(RhsCoeffReadCost))
                     + (InnerSize - 1) * NumTraits<Scalar>::AddCost,
 
     Unroll = CoeffReadCost <= EIGEN_UNROLLING_LIMIT,
-    
+
     LhsFlags = LhsEtorType::Flags,
     RhsFlags = RhsEtorType::Flags,
-    
+
     LhsRowMajor = LhsFlags & RowMajorBit,
     RhsRowMajor = RhsFlags & RowMajorBit,
 
     LhsVecPacketSize = unpacket_traits<LhsVecPacketType>::size,
     RhsVecPacketSize = unpacket_traits<RhsVecPacketType>::size,
 
     // Here, we don't care about alignment larger than the usable packet size.
     LhsAlignment = EIGEN_PLAIN_ENUM_MIN(LhsEtorType::Alignment,LhsVecPacketSize*int(sizeof(typename LhsNestedCleaned::Scalar))),
     RhsAlignment = EIGEN_PLAIN_ENUM_MIN(RhsEtorType::Alignment,RhsVecPacketSize*int(sizeof(typename RhsNestedCleaned::Scalar))),
-      
+
     SameType = is_same<typename LhsNestedCleaned::Scalar,typename RhsNestedCleaned::Scalar>::value,
 
     CanVectorizeRhs = bool(RhsRowMajor) && (RhsFlags & PacketAccessBit) && (ColsAtCompileTime!=1),
     CanVectorizeLhs = (!LhsRowMajor) && (LhsFlags & PacketAccessBit) && (RowsAtCompileTime!=1),
 
     EvalToRowMajor = (MaxRowsAtCompileTime==1&&MaxColsAtCompileTime!=1) ? 1
                     : (MaxColsAtCompileTime==1&&MaxRowsAtCompileTime!=1) ? 0
                     : (bool(RhsRowMajor) && !CanVectorizeLhs),
 
-    Flags = ((unsigned int)(LhsFlags | RhsFlags) & HereditaryBits & ~RowMajorBit)
+    Flags = ((int(LhsFlags) | int(RhsFlags)) & HereditaryBits & ~RowMajorBit)
           | (EvalToRowMajor ? RowMajorBit : 0)
           // TODO enable vectorization for mixed types
           | (SameType && (CanVectorizeLhs || CanVectorizeRhs) ? PacketAccessBit : 0)
           | (XprType::IsVectorAtCompileTime ? LinearAccessBit : 0),
-          
+
     LhsOuterStrideBytes = int(LhsNestedCleaned::OuterStrideAtCompileTime) * int(sizeof(typename LhsNestedCleaned::Scalar)),
     RhsOuterStrideBytes = int(RhsNestedCleaned::OuterStrideAtCompileTime) * int(sizeof(typename RhsNestedCleaned::Scalar)),
 
     Alignment = bool(CanVectorizeLhs) ? (LhsOuterStrideBytes<=0 || (int(LhsOuterStrideBytes) % EIGEN_PLAIN_ENUM_MAX(1,LhsAlignment))!=0 ? 0 : LhsAlignment)
               : bool(CanVectorizeRhs) ? (RhsOuterStrideBytes<=0 || (int(RhsOuterStrideBytes) % EIGEN_PLAIN_ENUM_MAX(1,RhsAlignment))!=0 ? 0 : RhsAlignment)
               : 0,
 
@@ -588,18 +593,18 @@
      * of Product. If the Product itself is not a packet-access expression, there is still a chance that the inner
      * loop of the product might be vectorized. This is the meaning of CanVectorizeInner. Since it doesn't affect
      * the Flags, it is safe to make this value depend on ActualPacketAccessBit, that doesn't affect the ABI.
      */
     CanVectorizeInner =    SameType
                         && LhsRowMajor
                         && (!RhsRowMajor)
-                        && (LhsFlags & RhsFlags & ActualPacketAccessBit)
-                        && (InnerSize % packet_traits<Scalar>::size == 0)
+                        && (int(LhsFlags) & int(RhsFlags) & ActualPacketAccessBit)
+                        && (int(InnerSize) % packet_traits<Scalar>::size == 0)
   };
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CoeffReturnType coeff(Index row, Index col) const
   {
     return (m_lhs.row(row).transpose().cwiseProduct( m_rhs.col(col) )).sum();
   }
 
   /* Allow index-based non-packet access. It is impossible though to allow index-based packed access,
    * which is why we don't set the LinearAccessBit.
@@ -633,15 +638,15 @@
     const Index col = (RowsAtCompileTime == 1 || MaxRowsAtCompileTime==1) ? index : 0;
     return packet<LoadMode,PacketType>(row,col);
   }
 
 protected:
   typename internal::add_const_on_value_type<LhsNested>::type m_lhs;
   typename internal::add_const_on_value_type<RhsNested>::type m_rhs;
-  
+
   LhsEtorType m_lhsImpl;
   RhsEtorType m_rhsImpl;
 
   // TODO: Get rid of m_innerDim if known at compile time
   Index m_innerDim;
 };
 
@@ -664,82 +669,82 @@
 /****************************************
 *** Coeff based product, Packet path  ***
 ****************************************/
 
 template<int UnrollingIndex, typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<RowMajor, UnrollingIndex, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet &res)
   {
     etor_product_packet_impl<RowMajor, UnrollingIndex-1, Lhs, Rhs, Packet, LoadMode>::run(row, col, lhs, rhs, innerDim, res);
     res =  pmadd(pset1<Packet>(lhs.coeff(row, Index(UnrollingIndex-1))), rhs.template packet<LoadMode,Packet>(Index(UnrollingIndex-1), col), res);
   }
 };
 
 template<int UnrollingIndex, typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<ColMajor, UnrollingIndex, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet &res)
   {
     etor_product_packet_impl<ColMajor, UnrollingIndex-1, Lhs, Rhs, Packet, LoadMode>::run(row, col, lhs, rhs, innerDim, res);
     res =  pmadd(lhs.template packet<LoadMode,Packet>(row, Index(UnrollingIndex-1)), pset1<Packet>(rhs.coeff(Index(UnrollingIndex-1), col)), res);
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<RowMajor, 1, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index /*innerDim*/, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index /*innerDim*/, Packet &res)
   {
     res = pmul(pset1<Packet>(lhs.coeff(row, Index(0))),rhs.template packet<LoadMode,Packet>(Index(0), col));
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<ColMajor, 1, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index /*innerDim*/, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index /*innerDim*/, Packet &res)
   {
     res = pmul(lhs.template packet<LoadMode,Packet>(row, Index(0)), pset1<Packet>(rhs.coeff(Index(0), col)));
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<RowMajor, 0, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index /*row*/, Index /*col*/, const Lhs& /*lhs*/, const Rhs& /*rhs*/, Index /*innerDim*/, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index /*row*/, Index /*col*/, const Lhs& /*lhs*/, const Rhs& /*rhs*/, Index /*innerDim*/, Packet &res)
   {
     res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<ColMajor, 0, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index /*row*/, Index /*col*/, const Lhs& /*lhs*/, const Rhs& /*rhs*/, Index /*innerDim*/, Packet &res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index /*row*/, Index /*col*/, const Lhs& /*lhs*/, const Rhs& /*rhs*/, Index /*innerDim*/, Packet &res)
   {
     res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<RowMajor, Dynamic, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res)
   {
     res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
     for(Index i = 0; i < innerDim; ++i)
       res =  pmadd(pset1<Packet>(lhs.coeff(row, i)), rhs.template packet<LoadMode,Packet>(i, col), res);
   }
 };
 
 template<typename Lhs, typename Rhs, typename Packet, int LoadMode>
 struct etor_product_packet_impl<ColMajor, Dynamic, Lhs, Rhs, Packet, LoadMode>
 {
-  static EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Index row, Index col, const Lhs& lhs, const Rhs& rhs, Index innerDim, Packet& res)
   {
     res = pset1<Packet>(typename unpacket_traits<Packet>::type(0));
     for(Index i = 0; i < innerDim; ++i)
       res =  pmadd(lhs.template packet<LoadMode,Packet>(row, i), pset1<Packet>(rhs.coeff(i, col)), res);
   }
 };
 
@@ -753,29 +758,29 @@
 struct triangular_product_impl;
 
 template<typename Lhs, typename Rhs, int ProductTag>
 struct generic_product_impl<Lhs,Rhs,TriangularShape,DenseShape,ProductTag>
   : generic_product_impl_base<Lhs,Rhs,generic_product_impl<Lhs,Rhs,TriangularShape,DenseShape,ProductTag> >
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dest>
   static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
     triangular_product_impl<Lhs::Mode,true,typename Lhs::MatrixType,false,Rhs, Rhs::ColsAtCompileTime==1>
         ::run(dst, lhs.nestedExpression(), rhs, alpha);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag>
 struct generic_product_impl<Lhs,Rhs,DenseShape,TriangularShape,ProductTag>
 : generic_product_impl_base<Lhs,Rhs,generic_product_impl<Lhs,Rhs,DenseShape,TriangularShape,ProductTag> >
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dest>
   static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
     triangular_product_impl<Rhs::Mode,false,Lhs,Lhs::RowsAtCompileTime==1, typename Rhs::MatrixType, false>::run(dst, lhs, rhs.nestedExpression(), alpha);
   }
 };
 
@@ -788,53 +793,53 @@
 struct selfadjoint_product_impl;
 
 template<typename Lhs, typename Rhs, int ProductTag>
 struct generic_product_impl<Lhs,Rhs,SelfAdjointShape,DenseShape,ProductTag>
   : generic_product_impl_base<Lhs,Rhs,generic_product_impl<Lhs,Rhs,SelfAdjointShape,DenseShape,ProductTag> >
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dest>
   static EIGEN_DEVICE_FUNC
   void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
     selfadjoint_product_impl<typename Lhs::MatrixType,Lhs::Mode,false,Rhs,0,Rhs::IsVectorAtCompileTime>::run(dst, lhs.nestedExpression(), rhs, alpha);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag>
 struct generic_product_impl<Lhs,Rhs,DenseShape,SelfAdjointShape,ProductTag>
 : generic_product_impl_base<Lhs,Rhs,generic_product_impl<Lhs,Rhs,DenseShape,SelfAdjointShape,ProductTag> >
 {
   typedef typename Product<Lhs,Rhs>::Scalar Scalar;
-  
+
   template<typename Dest>
   static void scaleAndAddTo(Dest& dst, const Lhs& lhs, const Rhs& rhs, const Scalar& alpha)
   {
     selfadjoint_product_impl<Lhs,0,Lhs::IsVectorAtCompileTime,typename Rhs::MatrixType,Rhs::Mode,false>::run(dst, lhs, rhs.nestedExpression(), alpha);
   }
 };
 
 
 /***************************************************************************
 * Diagonal products
 ***************************************************************************/
-  
+
 template<typename MatrixType, typename DiagonalType, typename Derived, int ProductOrder>
 struct diagonal_product_evaluator_base
   : evaluator_base<Derived>
 {
    typedef typename ScalarBinaryOpTraits<typename MatrixType::Scalar, typename DiagonalType::Scalar>::ReturnType Scalar;
 public:
   enum {
-    CoeffReadCost = NumTraits<Scalar>::MulCost + evaluator<MatrixType>::CoeffReadCost + evaluator<DiagonalType>::CoeffReadCost,
-    
+    CoeffReadCost = int(NumTraits<Scalar>::MulCost) + int(evaluator<MatrixType>::CoeffReadCost) + int(evaluator<DiagonalType>::CoeffReadCost),
+
     MatrixFlags = evaluator<MatrixType>::Flags,
     DiagFlags = evaluator<DiagonalType>::Flags,
-    
+
     _StorageOrder = (Derived::MaxRowsAtCompileTime==1 && Derived::MaxColsAtCompileTime!=1) ? RowMajor
                   : (Derived::MaxColsAtCompileTime==1 && Derived::MaxRowsAtCompileTime!=1) ? ColMajor
                   : MatrixFlags & RowMajorBit ? RowMajor : ColMajor,
     _SameStorageOrder = _StorageOrder == (MatrixFlags & RowMajorBit ? RowMajor : ColMajor),
 
     _ScalarAccessOnDiag =  !((int(_StorageOrder) == ColMajor && int(ProductOrder) == OnTheLeft)
                            ||(int(_StorageOrder) == RowMajor && int(ProductOrder) == OnTheRight)),
@@ -849,91 +854,91 @@
     Flags = ((HereditaryBits|_LinearAccessMask) & (unsigned int)(MatrixFlags)) | (_Vectorizable ? PacketAccessBit : 0),
     Alignment = evaluator<MatrixType>::Alignment,
 
     AsScalarProduct =     (DiagonalType::SizeAtCompileTime==1)
                       ||  (DiagonalType::SizeAtCompileTime==Dynamic && MatrixType::RowsAtCompileTime==1 && ProductOrder==OnTheLeft)
                       ||  (DiagonalType::SizeAtCompileTime==Dynamic && MatrixType::ColsAtCompileTime==1 && ProductOrder==OnTheRight)
   };
-  
-  diagonal_product_evaluator_base(const MatrixType &mat, const DiagonalType &diag)
+
+  EIGEN_DEVICE_FUNC diagonal_product_evaluator_base(const MatrixType &mat, const DiagonalType &diag)
     : m_diagImpl(diag), m_matImpl(mat)
   {
     EIGEN_INTERNAL_CHECK_COST_VALUE(NumTraits<Scalar>::MulCost);
     EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar coeff(Index idx) const
   {
     if(AsScalarProduct)
       return m_diagImpl.coeff(0) * m_matImpl.coeff(idx);
     else
       return m_diagImpl.coeff(idx) * m_matImpl.coeff(idx);
   }
-  
+
 protected:
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet_impl(Index row, Index col, Index id, internal::true_type) const
   {
     return internal::pmul(m_matImpl.template packet<LoadMode,PacketType>(row, col),
                           internal::pset1<PacketType>(m_diagImpl.coeff(id)));
   }
-  
+
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet_impl(Index row, Index col, Index id, internal::false_type) const
   {
     enum {
       InnerSize = (MatrixType::Flags & RowMajorBit) ? MatrixType::ColsAtCompileTime : MatrixType::RowsAtCompileTime,
       DiagonalPacketLoadMode = EIGEN_PLAIN_ENUM_MIN(LoadMode,((InnerSize%16) == 0) ? int(Aligned16) : int(evaluator<DiagonalType>::Alignment)) // FIXME hardcoded 16!!
     };
     return internal::pmul(m_matImpl.template packet<LoadMode,PacketType>(row, col),
                           m_diagImpl.template packet<DiagonalPacketLoadMode,PacketType>(id));
   }
-  
+
   evaluator<DiagonalType> m_diagImpl;
   evaluator<MatrixType>   m_matImpl;
 };
 
 // diagonal * dense
 template<typename Lhs, typename Rhs, int ProductKind, int ProductTag>
 struct product_evaluator<Product<Lhs, Rhs, ProductKind>, ProductTag, DiagonalShape, DenseShape>
   : diagonal_product_evaluator_base<Rhs, typename Lhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>, OnTheLeft>
 {
   typedef diagonal_product_evaluator_base<Rhs, typename Lhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>, OnTheLeft> Base;
   using Base::m_diagImpl;
   using Base::m_matImpl;
   using Base::coeff;
   typedef typename Base::Scalar Scalar;
-  
+
   typedef Product<Lhs, Rhs, ProductKind> XprType;
   typedef typename XprType::PlainObject PlainObject;
   typedef typename Lhs::DiagonalVectorType DiagonalType;
 
-  
+
   enum { StorageOrder = Base::_StorageOrder };
 
   EIGEN_DEVICE_FUNC explicit product_evaluator(const XprType& xpr)
     : Base(xpr.rhs(), xpr.lhs().diagonal())
   {
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar coeff(Index row, Index col) const
   {
     return m_diagImpl.coeff(row) * m_matImpl.coeff(row, col);
   }
-  
+
 #ifndef EIGEN_GPUCC
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const
   {
     // FIXME: NVCC used to complain about the template keyword, but we have to check whether this is still the case.
     // See also similar calls below.
     return this->template packet_impl<LoadMode,PacketType>(row,col, row,
                                  typename internal::conditional<int(StorageOrder)==RowMajor, internal::true_type, internal::false_type>::type());
   }
-  
+
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet(Index idx) const
   {
     return packet<LoadMode,PacketType>(int(StorageOrder)==ColMajor?idx:0,int(StorageOrder)==ColMajor?0:idx);
   }
 #endif
 };
@@ -944,38 +949,38 @@
   : diagonal_product_evaluator_base<Lhs, typename Rhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>, OnTheRight>
 {
   typedef diagonal_product_evaluator_base<Lhs, typename Rhs::DiagonalVectorType, Product<Lhs, Rhs, LazyProduct>, OnTheRight> Base;
   using Base::m_diagImpl;
   using Base::m_matImpl;
   using Base::coeff;
   typedef typename Base::Scalar Scalar;
-  
+
   typedef Product<Lhs, Rhs, ProductKind> XprType;
   typedef typename XprType::PlainObject PlainObject;
-  
+
   enum { StorageOrder = Base::_StorageOrder };
 
   EIGEN_DEVICE_FUNC explicit product_evaluator(const XprType& xpr)
     : Base(xpr.lhs(), xpr.rhs().diagonal())
   {
   }
-  
+
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar coeff(Index row, Index col) const
   {
     return m_matImpl.coeff(row, col) * m_diagImpl.coeff(col);
   }
-  
+
 #ifndef EIGEN_GPUCC
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet(Index row, Index col) const
   {
     return this->template packet_impl<LoadMode,PacketType>(row,col, col,
                                  typename internal::conditional<int(StorageOrder)==ColMajor, internal::true_type, internal::false_type>::type());
   }
-  
+
   template<int LoadMode,typename PacketType>
   EIGEN_STRONG_INLINE PacketType packet(Index idx) const
   {
     return packet<LoadMode,PacketType>(int(StorageOrder)==ColMajor?idx:0,int(StorageOrder)==ColMajor?0:idx);
   }
 #endif
 };
@@ -995,15 +1000,15 @@
 template<typename ExpressionType, int Side, bool Transposed>
 struct permutation_matrix_product<ExpressionType, Side, Transposed, DenseShape>
 {
     typedef typename nested_eval<ExpressionType, 1>::type MatrixType;
     typedef typename remove_all<MatrixType>::type MatrixTypeCleaned;
 
     template<typename Dest, typename PermutationType>
-    static inline void run(Dest& dst, const PermutationType& perm, const ExpressionType& xpr)
+    static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Dest& dst, const PermutationType& perm, const ExpressionType& xpr)
     {
       MatrixType mat(xpr);
       const Index n = Side==OnTheLeft ? mat.rows() : mat.cols();
       // FIXME we need an is_same for expression that is not sensitive to constness. For instance
       // is_same_xpr<Block<const Matrix>, Block<Matrix> >::value should be true.
       //if(is_same<MatrixTypeCleaned,Dest>::value && extract_data(dst) == extract_data(mat))
       if(is_same_dense(dst, mat))
@@ -1049,45 +1054,45 @@
     }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Rhs, PermutationShape, MatrixShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
   {
     permutation_matrix_product<Rhs, OnTheLeft, false, MatrixShape>::run(dst, lhs, rhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Rhs, MatrixShape, PermutationShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
   {
     permutation_matrix_product<Lhs, OnTheRight, false, MatrixShape>::run(dst, rhs, lhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Inverse<Lhs>, Rhs, PermutationShape, MatrixShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Inverse<Lhs>& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Inverse<Lhs>& lhs, const Rhs& rhs)
   {
     permutation_matrix_product<Rhs, OnTheLeft, true, MatrixShape>::run(dst, lhs.nestedExpression(), rhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Inverse<Rhs>, MatrixShape, PermutationShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Inverse<Rhs>& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Inverse<Rhs>& rhs)
   {
     permutation_matrix_product<Lhs, OnTheRight, true, MatrixShape>::run(dst, rhs.nestedExpression(), lhs);
   }
 };
 
 
 /***************************************************************************
@@ -1101,17 +1106,17 @@
   * Internal helper class implementing the product between a permutation matrix and a matrix.
   */
 template<typename ExpressionType, int Side, bool Transposed, typename ExpressionShape>
 struct transposition_matrix_product
 {
   typedef typename nested_eval<ExpressionType, 1>::type MatrixType;
   typedef typename remove_all<MatrixType>::type MatrixTypeCleaned;
-  
+
   template<typename Dest, typename TranspositionType>
-  static inline void run(Dest& dst, const TranspositionType& tr, const ExpressionType& xpr)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void run(Dest& dst, const TranspositionType& tr, const ExpressionType& xpr)
   {
     MatrixType mat(xpr);
     typedef typename TranspositionType::StorageIndex StorageIndex;
     const Index size = tr.size();
     StorageIndex j = 0;
 
     if(!is_same_dense(dst,mat))
@@ -1126,46 +1131,46 @@
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Rhs, TranspositionsShape, MatrixShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
   {
     transposition_matrix_product<Rhs, OnTheLeft, false, MatrixShape>::run(dst, lhs, rhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Rhs, MatrixShape, TranspositionsShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Rhs& rhs)
   {
     transposition_matrix_product<Lhs, OnTheRight, false, MatrixShape>::run(dst, rhs, lhs);
   }
 };
 
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Transpose<Lhs>, Rhs, TranspositionsShape, MatrixShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Transpose<Lhs>& lhs, const Rhs& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Transpose<Lhs>& lhs, const Rhs& rhs)
   {
     transposition_matrix_product<Rhs, OnTheLeft, true, MatrixShape>::run(dst, lhs.nestedExpression(), rhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int ProductTag, typename MatrixShape>
 struct generic_product_impl<Lhs, Transpose<Rhs>, MatrixShape, TranspositionsShape, ProductTag>
 {
   template<typename Dest>
-  static void evalTo(Dest& dst, const Lhs& lhs, const Transpose<Rhs>& rhs)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void evalTo(Dest& dst, const Lhs& lhs, const Transpose<Rhs>& rhs)
   {
     transposition_matrix_product<Lhs, OnTheRight, true, MatrixShape>::run(dst, rhs.nestedExpression(), lhs);
   }
 };
 
 } // end namespace internal
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Random.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Random.h`

 * *Files 13% similar despite different names*

```diff
@@ -173,10 +173,46 @@
 EIGEN_STRONG_INLINE Derived&
 PlainObjectBase<Derived>::setRandom(Index rows, Index cols)
 {
   resize(rows, cols);
   return setRandom();
 }
 
+/** Resizes to the given size, changing only the number of columns, and sets all
+  * coefficients in this expression to random values. For the parameter of type
+  * NoChange_t, just pass the special value \c NoChange.
+  *
+  * Numbers are uniformly spread through their whole definition range for integer types,
+  * and in the [-1:1] range for floating point scalar types.
+  *
+  * \not_reentrant
+  *
+  * \sa DenseBase::setRandom(), setRandom(Index), setRandom(Index, NoChange_t), class CwiseNullaryOp, DenseBase::Random()
+  */
+template<typename Derived>
+EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setRandom(NoChange_t, Index cols)
+{
+  return setRandom(rows(), cols);
+}
+
+/** Resizes to the given size, changing only the number of rows, and sets all
+  * coefficients in this expression to random values. For the parameter of type
+  * NoChange_t, just pass the special value \c NoChange.
+  *
+  * Numbers are uniformly spread through their whole definition range for integer types,
+  * and in the [-1:1] range for floating point scalar types.
+  *
+  * \not_reentrant
+  *
+  * \sa DenseBase::setRandom(), setRandom(Index), setRandom(NoChange_t, Index), class CwiseNullaryOp, DenseBase::Random()
+  */
+template<typename Derived>
+EIGEN_STRONG_INLINE Derived&
+PlainObjectBase<Derived>::setRandom(Index rows, NoChange_t)
+{
+  return setRandom(rows, cols());
+}
+
 } // end namespace Eigen
 
 #endif // EIGEN_RANDOM_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Redux.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Redux.h`

 * *Files 3% similar despite different names*

```diff
@@ -54,15 +54,15 @@
               : int(MaySliceVectorize)  ? int(SliceVectorizedTraversal)
                                         : int(DefaultTraversal)
   };
 
 public:
   enum {
     Cost = Evaluator::SizeAtCompileTime == Dynamic ? HugeCost
-         : Evaluator::SizeAtCompileTime * Evaluator::CoeffReadCost + (Evaluator::SizeAtCompileTime-1) * functor_traits<Func>::Cost,
+         : int(Evaluator::SizeAtCompileTime) * int(Evaluator::CoeffReadCost) + (Evaluator::SizeAtCompileTime-1) * functor_traits<Func>::Cost,
     UnrollingLimit = EIGEN_UNROLLING_LIMIT * (int(Traversal) == int(DefaultTraversal) ? 1 : int(PacketSize))
   };
 
 public:
   enum {
     Unrolling = Cost <= UnrollingLimit ? CompleteUnrolling : NoUnrolling
   };
@@ -327,15 +327,15 @@
 {
   typedef typename Evaluator::Scalar Scalar;
 
   typedef typename redux_traits<Func, Evaluator>::PacketType PacketType;
   enum {
     PacketSize = redux_traits<Func, Evaluator>::PacketSize,
     Size = Evaluator::SizeAtCompileTime,
-    VectorizedSize = (Size / PacketSize) * PacketSize
+    VectorizedSize = (int(Size) / int(PacketSize)) * int(PacketSize)
   };
 
   template<typename XprType>
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE
   Scalar run(const Evaluator &eval, const Func& func, const XprType &xpr)
   {
     EIGEN_ONLY_USED_FOR_DEBUG(xpr)
@@ -415,33 +415,41 @@
 
   // The initial expression is passed to the reducer as an additional argument instead of
   // passing it as a member of redux_evaluator to help  
   return internal::redux_impl<Func, ThisEvaluator>::run(thisEval, func, derived());
 }
 
 /** \returns the minimum of all coefficients of \c *this.
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is minimum of elements that are not NaN
   * \warning the matrix must be not empty, otherwise an assertion is triggered.
-  * \warning the result is undefined if \c *this contains NaN.
   */
 template<typename Derived>
+template<int NaNPropagation>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::minCoeff() const
 {
-  return derived().redux(Eigen::internal::scalar_min_op<Scalar,Scalar>());
+  return derived().redux(Eigen::internal::scalar_min_op<Scalar,Scalar, NaNPropagation>());
 }
 
-/** \returns the maximum of all coefficients of \c *this.
+/** \returns the maximum of all coefficients of \c *this. 
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is maximum of elements that are not NaN
   * \warning the matrix must be not empty, otherwise an assertion is triggered.
-  * \warning the result is undefined if \c *this contains NaN.
   */
 template<typename Derived>
+template<int NaNPropagation>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::maxCoeff() const
 {
-  return derived().redux(Eigen::internal::scalar_max_op<Scalar,Scalar>());
+  return derived().redux(Eigen::internal::scalar_max_op<Scalar,Scalar, NaNPropagation>());
 }
 
 /** \returns the sum of all coefficients of \c *this
   *
   * If \c *this is empty, then the value 0 is returned.
   *
   * \sa trace(), prod(), mean()
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Ref.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Ref.h`

 * *Files 21% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_REF_H
 #define EIGEN_REF_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename _PlainObjectType, int _Options, typename _StrideType>
 struct traits<Ref<_PlainObjectType, _Options, _StrideType> >
   : public traits<Map<_PlainObjectType, _Options, _StrideType> >
 {
@@ -44,15 +44,15 @@
       DerivedAlignment = int(evaluator<Derived>::Alignment),
       AlignmentMatch = (int(traits<PlainObjectType>::Alignment)==int(Unaligned)) || (DerivedAlignment >= int(Alignment)), // FIXME the first condition is not very clear, it should be replaced by the required alignment
       ScalarTypeMatch = internal::is_same<typename PlainObjectType::Scalar, typename Derived::Scalar>::value,
       MatchAtCompileTime = HasDirectAccess && StorageOrderMatch && InnerStrideMatch && OuterStrideMatch && AlignmentMatch && ScalarTypeMatch
     };
     typedef typename internal::conditional<MatchAtCompileTime,internal::true_type,internal::false_type>::type type;
   };
-  
+
 };
 
 template<typename Derived>
 struct traits<RefBase<Derived> > : public traits<Derived> {};
 
 }
 
@@ -63,63 +63,149 @@
   typedef typename internal::traits<Derived>::StrideType StrideType;
 
 public:
 
   typedef MapBase<Derived> Base;
   EIGEN_DENSE_PUBLIC_INTERFACE(RefBase)
 
-  EIGEN_DEVICE_FUNC inline Index innerStride() const
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index innerStride() const
   {
     return StrideType::InnerStrideAtCompileTime != 0 ? m_stride.inner() : 1;
   }
 
-  EIGEN_DEVICE_FUNC inline Index outerStride() const
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index outerStride() const
   {
     return StrideType::OuterStrideAtCompileTime != 0 ? m_stride.outer()
          : IsVectorAtCompileTime ? this->size()
          : int(Flags)&RowMajorBit ? this->cols()
          : this->rows();
   }
 
   EIGEN_DEVICE_FUNC RefBase()
     : Base(0,RowsAtCompileTime==Dynamic?0:RowsAtCompileTime,ColsAtCompileTime==Dynamic?0:ColsAtCompileTime),
       // Stride<> does not allow default ctor for Dynamic strides, so let' initialize it with dummy values:
       m_stride(StrideType::OuterStrideAtCompileTime==Dynamic?0:StrideType::OuterStrideAtCompileTime,
                StrideType::InnerStrideAtCompileTime==Dynamic?0:StrideType::InnerStrideAtCompileTime)
   {}
-  
+
   EIGEN_INHERIT_ASSIGNMENT_OPERATORS(RefBase)
 
 protected:
 
   typedef Stride<StrideType::OuterStrideAtCompileTime,StrideType::InnerStrideAtCompileTime> StrideBase;
 
+  // Resolves inner stride if default 0.
+  static EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index resolveInnerStride(Index inner) {
+    return inner == 0 ? 1 : inner;
+  }
+
+  // Resolves outer stride if default 0.
+  static EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index resolveOuterStride(Index inner, Index outer, Index rows, Index cols, bool isVectorAtCompileTime, bool isRowMajor) {
+    return outer == 0 ? isVectorAtCompileTime ? inner * rows * cols : isRowMajor ? inner * cols : inner * rows : outer;
+  }
+
+  // Returns true if construction is valid, false if there is a stride mismatch,
+  // and fails if there is a size mismatch.
   template<typename Expression>
-  EIGEN_DEVICE_FUNC void construct(Expression& expr)
+  EIGEN_DEVICE_FUNC bool construct(Expression& expr)
   {
-    EIGEN_STATIC_ASSERT_SAME_MATRIX_SIZE(PlainObjectType,Expression);
-
+    // Check matrix sizes.  If this is a compile-time vector, we do allow
+    // implicitly transposing.
+    EIGEN_STATIC_ASSERT(
+      EIGEN_PREDICATE_SAME_MATRIX_SIZE(PlainObjectType, Expression)
+      // If it is a vector, the transpose sizes might match.
+      || ( PlainObjectType::IsVectorAtCompileTime
+            && ((int(PlainObjectType::RowsAtCompileTime)==Eigen::Dynamic
+              || int(Expression::ColsAtCompileTime)==Eigen::Dynamic
+              || int(PlainObjectType::RowsAtCompileTime)==int(Expression::ColsAtCompileTime))
+            &&  (int(PlainObjectType::ColsAtCompileTime)==Eigen::Dynamic
+              || int(Expression::RowsAtCompileTime)==Eigen::Dynamic
+              || int(PlainObjectType::ColsAtCompileTime)==int(Expression::RowsAtCompileTime)))),
+      YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES
+    )
+
+    // Determine runtime rows and columns.
+    Index rows = expr.rows();
+    Index cols = expr.cols();
     if(PlainObjectType::RowsAtCompileTime==1)
     {
       eigen_assert(expr.rows()==1 || expr.cols()==1);
-      ::new (static_cast<Base*>(this)) Base(expr.data(), 1, expr.size());
+      rows = 1;
+      cols = expr.size();
     }
     else if(PlainObjectType::ColsAtCompileTime==1)
     {
       eigen_assert(expr.rows()==1 || expr.cols()==1);
-      ::new (static_cast<Base*>(this)) Base(expr.data(), expr.size(), 1);
+      rows = expr.size();
+      cols = 1;
+    }
+    // Verify that the sizes are valid.
+    eigen_assert(
+      (PlainObjectType::RowsAtCompileTime == Dynamic) || (PlainObjectType::RowsAtCompileTime == rows));
+    eigen_assert(
+      (PlainObjectType::ColsAtCompileTime == Dynamic) || (PlainObjectType::ColsAtCompileTime == cols));
+
+
+    // If this is a vector, we might be transposing, which means that stride should swap.
+    const bool transpose = PlainObjectType::IsVectorAtCompileTime && (rows != expr.rows());
+    // If the storage format differs, we also need to swap the stride.
+    const bool row_major = ((PlainObjectType::Flags)&RowMajorBit) != 0;
+    const bool expr_row_major = (Expression::Flags&RowMajorBit) != 0;
+    const bool storage_differs =  (row_major != expr_row_major);
+
+    const bool swap_stride = (transpose != storage_differs);
+
+    // Determine expr's actual strides, resolving any defaults if zero.
+    const Index expr_inner_actual = resolveInnerStride(expr.innerStride());
+    const Index expr_outer_actual = resolveOuterStride(expr_inner_actual,
+                                                       expr.outerStride(),
+                                                       expr.rows(),
+                                                       expr.cols(),
+                                                       Expression::IsVectorAtCompileTime != 0,
+                                                       expr_row_major);
+
+    // If this is a column-major row vector or row-major column vector, the inner-stride
+    // is arbitrary, so set it to either the compile-time inner stride or 1.
+    const bool row_vector = (rows == 1);
+    const bool col_vector = (cols == 1);
+    const Index inner_stride =
+        ( (!row_major && row_vector) || (row_major && col_vector) ) ?
+            ( StrideType::InnerStrideAtCompileTime > 0 ? Index(StrideType::InnerStrideAtCompileTime) : 1)
+            : swap_stride ? expr_outer_actual : expr_inner_actual;
+
+    // If this is a column-major column vector or row-major row vector, the outer-stride
+    // is arbitrary, so set it to either the compile-time outer stride or vector size.
+    const Index outer_stride =
+      ( (!row_major && col_vector) || (row_major && row_vector) ) ?
+          ( StrideType::OuterStrideAtCompileTime > 0 ? Index(StrideType::OuterStrideAtCompileTime) : rows * cols * inner_stride)
+          : swap_stride ? expr_inner_actual : expr_outer_actual;
+
+    // Check if given inner/outer strides are compatible with compile-time strides.
+    const bool inner_valid = (StrideType::InnerStrideAtCompileTime == Dynamic)
+        || (resolveInnerStride(Index(StrideType::InnerStrideAtCompileTime)) == inner_stride);
+    if (!inner_valid) {
+      return false;
     }
-    else
-      ::new (static_cast<Base*>(this)) Base(expr.data(), expr.rows(), expr.cols());
-    
-    if(Expression::IsVectorAtCompileTime && (!PlainObjectType::IsVectorAtCompileTime) && ((Expression::Flags&RowMajorBit)!=(PlainObjectType::Flags&RowMajorBit)))
-      ::new (&m_stride) StrideBase(expr.innerStride(), StrideType::InnerStrideAtCompileTime==0?0:1);
-    else
-      ::new (&m_stride) StrideBase(StrideType::OuterStrideAtCompileTime==0?0:expr.outerStride(),
-                                   StrideType::InnerStrideAtCompileTime==0?0:expr.innerStride());    
+
+    const bool outer_valid = (StrideType::OuterStrideAtCompileTime == Dynamic)
+        || (resolveOuterStride(
+              inner_stride,
+              Index(StrideType::OuterStrideAtCompileTime),
+              rows, cols, PlainObjectType::IsVectorAtCompileTime != 0,
+              row_major)
+            == outer_stride);
+    if (!outer_valid) {
+      return false;
+    }
+
+    ::new (static_cast<Base*>(this)) Base(expr.data(), rows, cols);
+    ::new (&m_stride) StrideBase(
+      (StrideType::OuterStrideAtCompileTime == 0) ? 0 : outer_stride,
+      (StrideType::InnerStrideAtCompileTime == 0) ? 0 : inner_stride );
+    return true;
   }
 
   StrideBase m_stride;
 };
 
 /** \class Ref
   * \ingroup Core_Module
@@ -208,29 +294,35 @@
 
     #ifndef EIGEN_PARSED_BY_DOXYGEN
     template<typename Derived>
     EIGEN_DEVICE_FUNC inline Ref(PlainObjectBase<Derived>& expr,
                                  typename internal::enable_if<bool(Traits::template match<Derived>::MatchAtCompileTime),Derived>::type* = 0)
     {
       EIGEN_STATIC_ASSERT(bool(Traits::template match<Derived>::MatchAtCompileTime), STORAGE_LAYOUT_DOES_NOT_MATCH);
-      Base::construct(expr.derived());
+      // Construction must pass since we will not create temprary storage in the non-const case.
+      const bool success = Base::construct(expr.derived());
+      EIGEN_UNUSED_VARIABLE(success)
+      eigen_assert(success);
     }
     template<typename Derived>
     EIGEN_DEVICE_FUNC inline Ref(const DenseBase<Derived>& expr,
                                  typename internal::enable_if<bool(Traits::template match<Derived>::MatchAtCompileTime),Derived>::type* = 0)
     #else
     /** Implicit constructor from any dense expression */
     template<typename Derived>
     inline Ref(DenseBase<Derived>& expr)
     #endif
     {
       EIGEN_STATIC_ASSERT(bool(internal::is_lvalue<Derived>::value), THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY);
       EIGEN_STATIC_ASSERT(bool(Traits::template match<Derived>::MatchAtCompileTime), STORAGE_LAYOUT_DOES_NOT_MATCH);
       EIGEN_STATIC_ASSERT(!Derived::IsPlainObjectBase,THIS_EXPRESSION_IS_NOT_A_LVALUE__IT_IS_READ_ONLY);
-      Base::construct(expr.const_cast_derived());
+      // Construction must pass since we will not create temporary storage in the non-const case.
+      const bool success = Base::construct(expr.const_cast_derived());
+      EIGEN_UNUSED_VARIABLE(success)
+      eigen_assert(success);
     }
 
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Ref)
 
 };
 
 // this is the const ref version
@@ -263,15 +355,18 @@
     }
 
   protected:
 
     template<typename Expression>
     EIGEN_DEVICE_FUNC void construct(const Expression& expr,internal::true_type)
     {
-      Base::construct(expr);
+      // Check if we can use the underlying expr's storage directly, otherwise call the copy version.
+      if (!Base::construct(expr)) {
+        construct(expr, internal::false_type());
+      }
     }
 
     template<typename Expression>
     EIGEN_DEVICE_FUNC void construct(const Expression& expr, internal::false_type)
     {
       internal::call_assignment_no_alias(m_object,expr,internal::assign_op<Scalar,Scalar>());
       Base::construct(m_object);
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Replicate.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Replicate.h`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_REPLICATE_H
 #define EIGEN_REPLICATE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 template<typename MatrixType,int RowFactor,int ColFactor>
 struct traits<Replicate<MatrixType,RowFactor,ColFactor> >
  : traits<MatrixType>
 {
   typedef typename MatrixType::Scalar Scalar;
@@ -31,15 +31,15 @@
                       : ColFactor * MatrixType::ColsAtCompileTime,
    //FIXME we don't propagate the max sizes !!!
     MaxRowsAtCompileTime = RowsAtCompileTime,
     MaxColsAtCompileTime = ColsAtCompileTime,
     IsRowMajor = MaxRowsAtCompileTime==1 && MaxColsAtCompileTime!=1 ? 1
                : MaxColsAtCompileTime==1 && MaxRowsAtCompileTime!=1 ? 0
                : (MatrixType::Flags & RowMajorBit) ? 1 : 0,
-    
+
     // FIXME enable DirectAccess with negative strides?
     Flags = IsRowMajor ? RowMajorBit : 0
   };
 };
 }
 
 /**
@@ -84,23 +84,23 @@
     inline Replicate(const OriginalMatrixType& matrix, Index rowFactor, Index colFactor)
       : m_matrix(matrix), m_rowFactor(rowFactor), m_colFactor(colFactor)
     {
       EIGEN_STATIC_ASSERT((internal::is_same<typename internal::remove_const<MatrixType>::type,OriginalMatrixType>::value),
                           THE_MATRIX_OR_EXPRESSION_THAT_YOU_PASSED_DOES_NOT_HAVE_THE_EXPECTED_TYPE)
     }
 
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index rows() const { return m_matrix.rows() * m_rowFactor.value(); }
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index cols() const { return m_matrix.cols() * m_colFactor.value(); }
 
     EIGEN_DEVICE_FUNC
     const _MatrixTypeNested& nestedExpression() const
-    { 
-      return m_matrix; 
+    {
+      return m_matrix;
     }
 
   protected:
     MatrixTypeNested m_matrix;
     const internal::variable_if_dynamic<Index, RowFactor> m_rowFactor;
     const internal::variable_if_dynamic<Index, ColFactor> m_colFactor;
 };
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Reshaped.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Reshaped.h`

 * *Files 1% similar despite different names*

```diff
@@ -8,15 +8,14 @@
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_RESHAPED_H
 #define EIGEN_RESHAPED_H
 
 namespace Eigen {
-namespace internal {
 
 /** \class Reshaped
   * \ingroup Core_Module
   *
   * \brief Expression of a fixed-size or dynamic-size reshape
   *
   * \tparam XprType the type of the expression in which we are taking a reshape
@@ -40,14 +39,16 @@
   * Here is an example illustrating the fixed-size case:
   * \include class_FixedReshaped.cpp
   * Output: \verbinclude class_FixedReshaped.out
   *
   * \sa DenseBase::reshaped(NRowsType,NColsType)
   */
 
+namespace internal {
+
 template<typename XprType, int Rows, int Cols, int Order>
 struct traits<Reshaped<XprType, Rows, Cols, Order> > : traits<XprType>
 {
   typedef typename traits<XprType>::Scalar Scalar;
   typedef typename traits<XprType>::StorageKind StorageKind;
   typedef typename traits<XprType>::XprKind XprKind;
   enum{
@@ -235,22 +236,22 @@
       return m_xpr;
     }
 
     EIGEN_DEVICE_FUNC
     XprType& nestedExpression() { return m_xpr; }
 
     /** \sa MapBase::innerStride() */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index innerStride() const
     {
       return m_xpr.innerStride();
     }
 
     /** \sa MapBase::outerStride() */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index outerStride() const
     {
       return ((Flags&RowMajorBit)==RowMajorBit) ? this->cols() : this->rows();
     }
 
   protected:
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/ReturnByValue.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/ReturnByValue.h`

 * *Files 2% similar despite different names*

```diff
@@ -56,16 +56,18 @@
     typedef typename internal::dense_xpr_base<ReturnByValue>::type Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(ReturnByValue)
 
     template<typename Dest>
     EIGEN_DEVICE_FUNC
     inline void evalTo(Dest& dst) const
     { static_cast<const Derived*>(this)->evalTo(dst); }
-    EIGEN_DEVICE_FUNC inline Index rows() const { return static_cast<const Derived*>(this)->rows(); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return static_cast<const Derived*>(this)->cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return static_cast<const Derived*>(this)->rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return static_cast<const Derived*>(this)->cols(); }
 
 #ifndef EIGEN_PARSED_BY_DOXYGEN
 #define Unusable YOU_ARE_TRYING_TO_ACCESS_A_SINGLE_COEFFICIENT_IN_A_SPECIAL_EXPRESSION_WHERE_THAT_IS_NOT_ALLOWED_BECAUSE_THAT_WOULD_BE_INEFFICIENT
     class Unusable{
       Unusable(const Unusable&) {}
       Unusable& operator=(const Unusable&) {return *this;}
     };
@@ -86,23 +88,23 @@
 }
 
 namespace internal {
 
 // Expression is evaluated in a temporary; default implementation of Assignment is bypassed so that
 // when a ReturnByValue expression is assigned, the evaluator is not constructed.
 // TODO: Finalize port to new regime; ReturnByValue should not exist in the expression world
-  
+
 template<typename Derived>
 struct evaluator<ReturnByValue<Derived> >
   : public evaluator<typename internal::traits<Derived>::ReturnType>
 {
   typedef ReturnByValue<Derived> XprType;
   typedef typename internal::traits<Derived>::ReturnType PlainObject;
   typedef evaluator<PlainObject> Base;
-  
+
   EIGEN_DEVICE_FUNC explicit evaluator(const XprType& xpr)
     : m_result(xpr.rows(), xpr.cols())
   {
     ::new (static_cast<Base*>(this)) Base(m_result);
     xpr.evalTo(m_result);
   }
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Reverse.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Reverse.h`

 * *Files 4% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_REVERSE_H
 #define EIGEN_REVERSE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename MatrixType, int Direction>
 struct traits<Reverse<MatrixType, Direction> >
  : traits<MatrixType>
 {
@@ -40,15 +40,15 @@
 };
 
 template<typename PacketType> struct reverse_packet_cond<PacketType,false>
 {
   static inline PacketType run(const PacketType& x) { return x; }
 };
 
-} // end namespace internal 
+} // end namespace internal
 
 /** \class Reverse
   * \ingroup Core_Module
   *
   * \brief Expression of the reverse of a vector or matrix
   *
   * \tparam MatrixType the type of the object of which we are taking the reverse
@@ -85,24 +85,26 @@
     typedef internal::reverse_packet_cond<PacketScalar,ReversePacket> reverse_packet;
   public:
 
     EIGEN_DEVICE_FUNC explicit inline Reverse(const MatrixType& matrix) : m_matrix(matrix) { }
 
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Reverse)
 
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_matrix.rows(); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
     EIGEN_DEVICE_FUNC inline Index innerStride() const
     {
       return -m_matrix.innerStride();
     }
 
     EIGEN_DEVICE_FUNC const typename internal::remove_all<typename MatrixType::Nested>::type&
-    nestedExpression() const 
+    nestedExpression() const
     {
       return m_matrix;
     }
 
   protected:
     typename MatrixType::Nested m_matrix;
 };
@@ -157,15 +159,15 @@
       Index half2 = cols()/2;
       row(half).head(half2).swap(row(half).tail(half2).reverse());
     }
   }
 }
 
 namespace internal {
-  
+
 template<int Direction>
 struct vectorwise_reverse_inplace_impl;
 
 template<>
 struct vectorwise_reverse_inplace_impl<Vertical>
 {
   template<typename ExpressionType>
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Select.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Select.h`

 * *Files 9% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_SELECT_H
 #define EIGEN_SELECT_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \class Select
   * \ingroup Core_Module
   *
   * \brief Expression of a coefficient wise version of the C++ ternary operator ?:
   *
   * \param ConditionMatrixType the type of the \em condition expression which must be a boolean matrix
@@ -63,16 +63,18 @@
            const ElseMatrixType& a_elseMatrix)
       : m_condition(a_conditionMatrix), m_then(a_thenMatrix), m_else(a_elseMatrix)
     {
       eigen_assert(m_condition.rows() == m_then.rows() && m_condition.rows() == m_else.rows());
       eigen_assert(m_condition.cols() == m_then.cols() && m_condition.cols() == m_else.cols());
     }
 
-    inline EIGEN_DEVICE_FUNC Index rows() const { return m_condition.rows(); }
-    inline EIGEN_DEVICE_FUNC Index cols() const { return m_condition.cols(); }
+    inline EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_condition.rows(); }
+    inline EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_condition.cols(); }
 
     inline EIGEN_DEVICE_FUNC
     const Scalar coeff(Index i, Index j) const
     {
       if (m_condition.coeff(i,j))
         return m_then.coeff(i,j);
       else
@@ -116,44 +118,44 @@
   * Example: \include MatrixBase_select.cpp
   * Output: \verbinclude MatrixBase_select.out
   *
   * \sa class Select
   */
 template<typename Derived>
 template<typename ThenDerived,typename ElseDerived>
-inline const Select<Derived,ThenDerived,ElseDerived>
+inline EIGEN_DEVICE_FUNC const Select<Derived,ThenDerived,ElseDerived>
 DenseBase<Derived>::select(const DenseBase<ThenDerived>& thenMatrix,
                             const DenseBase<ElseDerived>& elseMatrix) const
 {
   return Select<Derived,ThenDerived,ElseDerived>(derived(), thenMatrix.derived(), elseMatrix.derived());
 }
 
 /** Version of DenseBase::select(const DenseBase&, const DenseBase&) with
   * the \em else expression being a scalar value.
   *
   * \sa DenseBase::select(const DenseBase<ThenDerived>&, const DenseBase<ElseDerived>&) const, class Select
   */
 template<typename Derived>
 template<typename ThenDerived>
-inline const Select<Derived,ThenDerived, typename ThenDerived::ConstantReturnType>
+inline EIGEN_DEVICE_FUNC const Select<Derived,ThenDerived, typename ThenDerived::ConstantReturnType>
 DenseBase<Derived>::select(const DenseBase<ThenDerived>& thenMatrix,
                            const typename ThenDerived::Scalar& elseScalar) const
 {
   return Select<Derived,ThenDerived,typename ThenDerived::ConstantReturnType>(
     derived(), thenMatrix.derived(), ThenDerived::Constant(rows(),cols(),elseScalar));
 }
 
 /** Version of DenseBase::select(const DenseBase&, const DenseBase&) with
   * the \em then expression being a scalar value.
   *
   * \sa DenseBase::select(const DenseBase<ThenDerived>&, const DenseBase<ElseDerived>&) const, class Select
   */
 template<typename Derived>
 template<typename ElseDerived>
-inline const Select<Derived, typename ElseDerived::ConstantReturnType, ElseDerived >
+inline EIGEN_DEVICE_FUNC const Select<Derived, typename ElseDerived::ConstantReturnType, ElseDerived >
 DenseBase<Derived>::select(const typename ElseDerived::Scalar& thenScalar,
                            const DenseBase<ElseDerived>& elseMatrix) const
 {
   return Select<Derived,typename ElseDerived::ConstantReturnType,ElseDerived>(
     derived(), ElseDerived::Constant(rows(),cols(),thenScalar), elseMatrix.derived());
 }
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/SelfAdjointView.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/SelfAdjointView.h`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_SELFADJOINTMATRIX_H
 #define EIGEN_SELFADJOINTMATRIX_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \class SelfAdjointView
   * \ingroup Core_Module
   *
   *
   * \brief Expression of a selfadjoint matrix from a triangular part of a dense matrix
   *
@@ -54,40 +54,40 @@
     typedef _MatrixType MatrixType;
     typedef TriangularBase<SelfAdjointView> Base;
     typedef typename internal::traits<SelfAdjointView>::MatrixTypeNested MatrixTypeNested;
     typedef typename internal::traits<SelfAdjointView>::MatrixTypeNestedCleaned MatrixTypeNestedCleaned;
     typedef MatrixTypeNestedCleaned NestedExpression;
 
     /** \brief The type of coefficients in this matrix */
-    typedef typename internal::traits<SelfAdjointView>::Scalar Scalar; 
+    typedef typename internal::traits<SelfAdjointView>::Scalar Scalar;
     typedef typename MatrixType::StorageIndex StorageIndex;
     typedef typename internal::remove_all<typename MatrixType::ConjugateReturnType>::type MatrixConjugateReturnType;
     typedef SelfAdjointView<typename internal::add_const<MatrixType>::type, UpLo> ConstSelfAdjointView;
 
     enum {
       Mode = internal::traits<SelfAdjointView>::Mode,
       Flags = internal::traits<SelfAdjointView>::Flags,
-      TransposeMode = ((Mode & Upper) ? Lower : 0) | ((Mode & Lower) ? Upper : 0)
+      TransposeMode = ((int(Mode) & int(Upper)) ? Lower : 0) | ((int(Mode) & int(Lower)) ? Upper : 0)
     };
     typedef typename MatrixType::PlainObject PlainObject;
 
     EIGEN_DEVICE_FUNC
     explicit inline SelfAdjointView(MatrixType& matrix) : m_matrix(matrix)
     {
       EIGEN_STATIC_ASSERT(UpLo==Lower || UpLo==Upper,SELFADJOINTVIEW_ACCEPTS_UPPER_AND_LOWER_MODE_ONLY);
     }
 
-    EIGEN_DEVICE_FUNC
-    inline Index rows() const { return m_matrix.rows(); }
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return m_matrix.cols(); }
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const { return m_matrix.outerStride(); }
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const { return m_matrix.innerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return m_matrix.outerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return m_matrix.innerStride(); }
 
     /** \sa MatrixBase::coeff()
       * \warning the coordinates must fit into the referenced triangular part
       */
     EIGEN_DEVICE_FUNC
     inline Scalar coeff(Index row, Index col) const
     {
@@ -128,15 +128,15 @@
     template<typename OtherDerived> friend
     EIGEN_DEVICE_FUNC
     const Product<OtherDerived,SelfAdjointView>
     operator*(const MatrixBase<OtherDerived>& lhs, const SelfAdjointView& rhs)
     {
       return Product<OtherDerived,SelfAdjointView>(lhs.derived(),rhs);
     }
-    
+
     friend EIGEN_DEVICE_FUNC
     const SelfAdjointView<const EIGEN_SCALAR_BINARYOP_EXPR_RETURN_TYPE(Scalar,MatrixType,product),UpLo>
     operator*(const Scalar& s, const SelfAdjointView& mat)
     {
       return (s*mat.nestedExpression()).template selfadjointView<UpLo>();
     }
 
@@ -296,38 +296,38 @@
   typedef generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version> Base;
   typedef typename Base::DstXprType DstXprType;
   typedef typename Base::SrcXprType SrcXprType;
   using Base::m_dst;
   using Base::m_src;
   using Base::m_functor;
 public:
-  
+
   typedef typename Base::DstEvaluatorType DstEvaluatorType;
   typedef typename Base::SrcEvaluatorType SrcEvaluatorType;
   typedef typename Base::Scalar Scalar;
   typedef typename Base::AssignmentTraits AssignmentTraits;
-  
-  
+
+
   EIGEN_DEVICE_FUNC triangular_dense_assignment_kernel(DstEvaluatorType &dst, const SrcEvaluatorType &src, const Functor &func, DstXprType& dstExpr)
     : Base(dst, src, func, dstExpr)
   {}
-  
+
   EIGEN_DEVICE_FUNC void assignCoeff(Index row, Index col)
   {
     eigen_internal_assert(row!=col);
     Scalar tmp = m_src.coeff(row,col);
     m_functor.assignCoeff(m_dst.coeffRef(row,col), tmp);
     m_functor.assignCoeff(m_dst.coeffRef(col,row), numext::conj(tmp));
   }
-  
+
   EIGEN_DEVICE_FUNC void assignDiagonalCoeff(Index id)
   {
     Base::assignCoeff(id,id);
   }
-  
+
   EIGEN_DEVICE_FUNC void assignOppositeCoeff(Index, Index)
   { eigen_internal_assert(false && "should never be called"); }
 };
 
 } // end namespace internal
 
 /***************************************************************************
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/SelfCwiseBinaryOp.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/SelfCwiseBinaryOp.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Solve.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Solve.h`

 * *Files 2% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 
 #ifndef EIGEN_SOLVE_H
 #define EIGEN_SOLVE_H
 
 namespace Eigen {
 
 template<typename Decomposition, typename RhsType, typename StorageKind> class SolveImpl;
-  
+
 /** \class Solve
   * \ingroup Core_Module
   *
   * \brief Pseudo expression representing a solving operation
   *
   * \tparam Decomposition the type of the matrix or decomposition object
   * \tparam Rhstype the type of the right-hand side
@@ -60,21 +60,21 @@
 
 template<typename Decomposition, typename RhsType>
 class Solve : public SolveImpl<Decomposition,RhsType,typename internal::traits<RhsType>::StorageKind>
 {
 public:
   typedef typename internal::traits<Solve>::PlainObject PlainObject;
   typedef typename internal::traits<Solve>::StorageIndex StorageIndex;
-  
+
   Solve(const Decomposition &dec, const RhsType &rhs)
     : m_dec(dec), m_rhs(rhs)
   {}
-  
-  EIGEN_DEVICE_FUNC Index rows() const { return m_dec.cols(); }
-  EIGEN_DEVICE_FUNC Index cols() const { return m_rhs.cols(); }
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_dec.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
 
   EIGEN_DEVICE_FUNC const Decomposition& dec() const { return m_dec; }
   EIGEN_DEVICE_FUNC const RhsType&       rhs() const { return m_rhs; }
 
 protected:
   const Decomposition &m_dec;
   const RhsType       &m_rhs;
@@ -83,22 +83,22 @@
 
 // Specialization of the Solve expression for dense results
 template<typename Decomposition, typename RhsType>
 class SolveImpl<Decomposition,RhsType,Dense>
   : public MatrixBase<Solve<Decomposition,RhsType> >
 {
   typedef Solve<Decomposition,RhsType> Derived;
-  
+
 public:
-  
+
   typedef MatrixBase<Solve<Decomposition,RhsType> > Base;
   EIGEN_DENSE_PUBLIC_INTERFACE(Derived)
 
 private:
-  
+
   Scalar coeff(Index row, Index col) const;
   Scalar coeff(Index i) const;
 };
 
 // Generic API dispatcher
 template<typename Decomposition, typename RhsType, typename StorageKind>
 class SolveImpl : public internal::generic_xpr_base<Solve<Decomposition,RhsType>, MatrixXpr, StorageKind>::type
@@ -115,23 +115,23 @@
   : public evaluator<typename Solve<Decomposition,RhsType>::PlainObject>
 {
   typedef Solve<Decomposition,RhsType> SolveType;
   typedef typename SolveType::PlainObject PlainObject;
   typedef evaluator<PlainObject> Base;
 
   enum { Flags = Base::Flags | EvalBeforeNestingBit };
-  
+
   EIGEN_DEVICE_FUNC explicit evaluator(const SolveType& solve)
     : m_result(solve.rows(), solve.cols())
   {
     ::new (static_cast<Base*>(this)) Base(m_result);
     solve.dec()._solve_impl(solve.rhs(), m_result);
   }
-  
-protected:  
+
+protected:
   PlainObject m_result;
 };
 
 // Specialization for "dst = dec.solve(rhs)"
 // NOTE we need to specialize it for Dense2Dense to avoid ambiguous specialization error and a Sparse2Sparse specialization must exist somewhere
 template<typename DstXprType, typename DecType, typename RhsType, typename Scalar>
 struct Assignment<DstXprType, Solve<DecType,RhsType>, internal::assign_op<Scalar,Scalar>, Dense2Dense>
@@ -172,15 +172,15 @@
   typedef Solve<CwiseUnaryOp<internal::scalar_conjugate_op<typename DecType::Scalar>, const Transpose<const DecType> >,RhsType> SrcXprType;
   static void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,Scalar> &)
   {
     Index dstRows = src.rows();
     Index dstCols = src.cols();
     if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
       dst.resize(dstRows, dstCols);
-    
+
     src.dec().nestedExpression().nestedExpression().template _solve_impl_transposed<true>(src.rhs(), dst);
   }
 };
 
 } // end namespace internal
 
 } // end namespace Eigen
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/SolveTriangular.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/SolveTriangular.h`

 * *Files 6% similar despite different names*

```diff
@@ -6,24 +6,24 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_SOLVETRIANGULAR_H
 #define EIGEN_SOLVETRIANGULAR_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 // Forward declarations:
 // The following two routines are implemented in the products/TriangularSolver*.h files
 template<typename LhsScalar, typename RhsScalar, typename Index, int Side, int Mode, bool Conjugate, int StorageOrder>
 struct triangular_solve_vector;
 
-template <typename Scalar, typename Index, int Side, int Mode, bool Conjugate, int TriStorageOrder, int OtherStorageOrder>
+template <typename Scalar, typename Index, int Side, int Mode, bool Conjugate, int TriStorageOrder, int OtherStorageOrder, int OtherInnerStride>
 struct triangular_solve_matrix;
 
 // small helper struct extracting some traits on the underlying solver operation
 template<typename Lhs, typename Rhs, int Side>
 class trsolve_traits
 {
   private:
@@ -50,25 +50,25 @@
 struct triangular_solver_selector<Lhs,Rhs,Side,Mode,NoUnrolling,1>
 {
   typedef typename Lhs::Scalar LhsScalar;
   typedef typename Rhs::Scalar RhsScalar;
   typedef blas_traits<Lhs> LhsProductTraits;
   typedef typename LhsProductTraits::ExtractType ActualLhsType;
   typedef Map<Matrix<RhsScalar,Dynamic,1>, Aligned> MappedRhs;
-  static void run(const Lhs& lhs, Rhs& rhs)
+  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, Rhs& rhs)
   {
     ActualLhsType actualLhs = LhsProductTraits::extract(lhs);
 
     // FIXME find a way to allow an inner stride if packet_traits<Scalar>::size==1
 
     bool useRhsDirectly = Rhs::InnerStrideAtCompileTime==1 || rhs.innerStride()==1;
 
     ei_declare_aligned_stack_constructed_variable(RhsScalar,actualRhs,rhs.size(),
                                                   (useRhsDirectly ? rhs.data() : 0));
-                                                  
+
     if(!useRhsDirectly)
       MappedRhs(actualRhs,rhs.size()) = rhs;
 
     triangular_solve_vector<LhsScalar, RhsScalar, Index, Side, Mode, LhsProductTraits::NeedToConjugate,
                             (int(Lhs::Flags) & RowMajorBit) ? RowMajor : ColMajor>
       ::run(actualLhs.cols(), actualLhs.data(), actualLhs.outerStride(), actualRhs);
 
@@ -81,29 +81,29 @@
 template<typename Lhs, typename Rhs, int Side, int Mode>
 struct triangular_solver_selector<Lhs,Rhs,Side,Mode,NoUnrolling,Dynamic>
 {
   typedef typename Rhs::Scalar Scalar;
   typedef blas_traits<Lhs> LhsProductTraits;
   typedef typename LhsProductTraits::DirectLinearAccessType ActualLhsType;
 
-  static void run(const Lhs& lhs, Rhs& rhs)
+  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, Rhs& rhs)
   {
     typename internal::add_const_on_value_type<ActualLhsType>::type actualLhs = LhsProductTraits::extract(lhs);
 
     const Index size = lhs.rows();
     const Index othersize = Side==OnTheLeft? rhs.cols() : rhs.rows();
 
     typedef internal::gemm_blocking_space<(Rhs::Flags&RowMajorBit) ? RowMajor : ColMajor,Scalar,Scalar,
               Rhs::MaxRowsAtCompileTime, Rhs::MaxColsAtCompileTime, Lhs::MaxRowsAtCompileTime,4> BlockingType;
 
     BlockingType blocking(rhs.rows(), rhs.cols(), size, 1, false);
 
     triangular_solve_matrix<Scalar,Index,Side,Mode,LhsProductTraits::NeedToConjugate,(int(Lhs::Flags) & RowMajorBit) ? RowMajor : ColMajor,
-                               (Rhs::Flags&RowMajorBit) ? RowMajor : ColMajor>
-      ::run(size, othersize, &actualLhs.coeffRef(0,0), actualLhs.outerStride(), &rhs.coeffRef(0,0), rhs.outerStride(), blocking);
+                               (Rhs::Flags&RowMajorBit) ? RowMajor : ColMajor, Rhs::InnerStrideAtCompileTime>
+      ::run(size, othersize, &actualLhs.coeffRef(0,0), actualLhs.outerStride(), &rhs.coeffRef(0,0), rhs.innerStride(), rhs.outerStride(), blocking);
   }
 };
 
 /***************************************************************************
 * meta-unrolling implementation
 ***************************************************************************/
 
@@ -114,45 +114,45 @@
 template<typename Lhs, typename Rhs, int Mode, int LoopIndex, int Size>
 struct triangular_solver_unroller<Lhs,Rhs,Mode,LoopIndex,Size,false> {
   enum {
     IsLower = ((Mode&Lower)==Lower),
     DiagIndex  = IsLower ? LoopIndex : Size - LoopIndex - 1,
     StartIndex = IsLower ? 0         : DiagIndex+1
   };
-  static void run(const Lhs& lhs, Rhs& rhs)
+  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, Rhs& rhs)
   {
     if (LoopIndex>0)
       rhs.coeffRef(DiagIndex) -= lhs.row(DiagIndex).template segment<LoopIndex>(StartIndex).transpose()
                                 .cwiseProduct(rhs.template segment<LoopIndex>(StartIndex)).sum();
 
     if(!(Mode & UnitDiag))
       rhs.coeffRef(DiagIndex) /= lhs.coeff(DiagIndex,DiagIndex);
 
     triangular_solver_unroller<Lhs,Rhs,Mode,LoopIndex+1,Size>::run(lhs,rhs);
   }
 };
 
 template<typename Lhs, typename Rhs, int Mode, int LoopIndex, int Size>
 struct triangular_solver_unroller<Lhs,Rhs,Mode,LoopIndex,Size,true> {
-  static void run(const Lhs&, Rhs&) {}
+  static EIGEN_DEVICE_FUNC void run(const Lhs&, Rhs&) {}
 };
 
 template<typename Lhs, typename Rhs, int Mode>
 struct triangular_solver_selector<Lhs,Rhs,OnTheLeft,Mode,CompleteUnrolling,1> {
-  static void run(const Lhs& lhs, Rhs& rhs)
+  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, Rhs& rhs)
   { triangular_solver_unroller<Lhs,Rhs,Mode,0,Rhs::SizeAtCompileTime>::run(lhs,rhs); }
 };
 
 template<typename Lhs, typename Rhs, int Mode>
 struct triangular_solver_selector<Lhs,Rhs,OnTheRight,Mode,CompleteUnrolling,1> {
-  static void run(const Lhs& lhs, Rhs& rhs)
+  static EIGEN_DEVICE_FUNC void run(const Lhs& lhs, Rhs& rhs)
   {
     Transpose<const Lhs> trLhs(lhs);
     Transpose<Rhs> trRhs(rhs);
-    
+
     triangular_solver_unroller<Transpose<const Lhs>,Transpose<Rhs>,
                               ((Mode&Upper)==Upper ? Lower : Upper) | (Mode&UnitDiag),
                               0,Rhs::SizeAtCompileTime>::run(trLhs,trRhs);
   }
 };
 
 } // end namespace internal
@@ -164,15 +164,15 @@
 #ifndef EIGEN_PARSED_BY_DOXYGEN
 template<typename MatrixType, unsigned int Mode>
 template<int Side, typename OtherDerived>
 EIGEN_DEVICE_FUNC void TriangularViewImpl<MatrixType,Mode,Dense>::solveInPlace(const MatrixBase<OtherDerived>& _other) const
 {
   OtherDerived& other = _other.const_cast_derived();
   eigen_assert( derived().cols() == derived().rows() && ((Side==OnTheLeft && derived().cols() == other.rows()) || (Side==OnTheRight && derived().cols() == other.cols())) );
-  eigen_assert((!(Mode & ZeroDiag)) && bool(Mode & (Upper|Lower)));
+  eigen_assert((!(int(Mode) & int(ZeroDiag))) && bool(int(Mode) & (int(Upper) | int(Lower))));
   // If solving for a 0x0 matrix, nothing to do, simply return.
   if (derived().cols() == 0)
     return;
 
   enum { copy = (internal::traits<OtherDerived>::Flags & RowMajorBit)  && OtherDerived::IsVectorAtCompileTime && OtherDerived::SizeAtCompileTime!=1};
   typedef typename internal::conditional<copy,
     typename internal::plain_matrix_type_column_major<OtherDerived>::type, OtherDerived&>::type OtherCopy;
@@ -209,16 +209,16 @@
   typedef typename remove_all<typename Rhs::Nested>::type RhsNestedCleaned;
   typedef ReturnByValue<triangular_solve_retval> Base;
 
   triangular_solve_retval(const TriangularType& tri, const Rhs& rhs)
     : m_triangularMatrix(tri), m_rhs(rhs)
   {}
 
-  inline Index rows() const { return m_rhs.rows(); }
-  inline Index cols() const { return m_rhs.cols(); }
+  inline EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_rhs.rows(); }
+  inline EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
 
   template<typename Dest> inline void evalTo(Dest& dst) const
   {
     if(!is_same_dense(dst,m_rhs))
       dst = m_rhs;
     m_triangularMatrix.template solveInPlace<Side>(dst);
   }
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/SolverBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/SolverBase.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/StableNorm.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/StableNorm.h`

 * *Files 10% similar despite different names*

```diff
@@ -119,60 +119,47 @@
 inline typename NumTraits<typename traits<Derived>::Scalar>::Real
 blueNorm_impl(const EigenBase<Derived>& _vec)
 {
   typedef typename Derived::RealScalar RealScalar;  
   using std::pow;
   using std::sqrt;
   using std::abs;
-  const Derived& vec(_vec.derived());
-  static bool initialized = false;
-  static RealScalar b1, b2, s1m, s2m, rbig, relerr;
-  if(!initialized)
-  {
-    int ibeta, it, iemin, iemax, iexp;
-    RealScalar eps;
-    // This program calculates the machine-dependent constants
-    // bl, b2, slm, s2m, relerr overfl
-    // from the "basic" machine-dependent numbers
-    // nbig, ibeta, it, iemin, iemax, rbig.
-    // The following define the basic machine-dependent constants.
-    // For portability, the PORT subprograms "ilmaeh" and "rlmach"
-    // are used. For any specific computer, each of the assignment
-    // statements can be replaced
-    ibeta = std::numeric_limits<RealScalar>::radix;                 // base for floating-point numbers
-    it    = NumTraits<RealScalar>::digits();                        // number of base-beta digits in mantissa
-    iemin = std::numeric_limits<RealScalar>::min_exponent;          // minimum exponent
-    iemax = std::numeric_limits<RealScalar>::max_exponent;          // maximum exponent
-    rbig  = (std::numeric_limits<RealScalar>::max)();               // largest floating-point number
-
-    iexp  = -((1-iemin)/2);
-    b1    = RealScalar(pow(RealScalar(ibeta),RealScalar(iexp)));    // lower boundary of midrange
-    iexp  = (iemax + 1 - it)/2;
-    b2    = RealScalar(pow(RealScalar(ibeta),RealScalar(iexp)));    // upper boundary of midrange
 
-    iexp  = (2-iemin)/2;
-    s1m   = RealScalar(pow(RealScalar(ibeta),RealScalar(iexp)));    // scaling factor for lower range
-    iexp  = - ((iemax+it)/2);
-    s2m   = RealScalar(pow(RealScalar(ibeta),RealScalar(iexp)));    // scaling factor for upper range
+  // This program calculates the machine-dependent constants
+  // bl, b2, slm, s2m, relerr overfl
+  // from the "basic" machine-dependent numbers
+  // nbig, ibeta, it, iemin, iemax, rbig.
+  // The following define the basic machine-dependent constants.
+  // For portability, the PORT subprograms "ilmaeh" and "rlmach"
+  // are used. For any specific computer, each of the assignment
+  // statements can be replaced
+  static const int ibeta = std::numeric_limits<RealScalar>::radix;  // base for floating-point numbers
+  static const int it    = NumTraits<RealScalar>::digits();  // number of base-beta digits in mantissa
+  static const int iemin = NumTraits<RealScalar>::min_exponent();  // minimum exponent
+  static const int iemax = NumTraits<RealScalar>::max_exponent();  // maximum exponent
+  static const RealScalar rbig   = NumTraits<RealScalar>::highest();  // largest floating-point number
+  static const RealScalar b1     = RealScalar(pow(RealScalar(ibeta),RealScalar(-((1-iemin)/2))));  // lower boundary of midrange
+  static const RealScalar b2     = RealScalar(pow(RealScalar(ibeta),RealScalar((iemax + 1 - it)/2)));  // upper boundary of midrange
+  static const RealScalar s1m    = RealScalar(pow(RealScalar(ibeta),RealScalar((2-iemin)/2)));  // scaling factor for lower range
+  static const RealScalar s2m    = RealScalar(pow(RealScalar(ibeta),RealScalar(- ((iemax+it)/2))));  // scaling factor for upper range
+  static const RealScalar eps    = RealScalar(pow(double(ibeta), 1-it));
+  static const RealScalar relerr = sqrt(eps);  // tolerance for neglecting asml
 
-    eps     = RealScalar(pow(double(ibeta), 1-it));
-    relerr  = sqrt(eps);                                            // tolerance for neglecting asml
-    initialized = true;
-  }
+  const Derived& vec(_vec.derived());
   Index n = vec.size();
   RealScalar ab2 = b2 / RealScalar(n);
   RealScalar asml = RealScalar(0);
   RealScalar amed = RealScalar(0);
   RealScalar abig = RealScalar(0);
 
   for(Index j=0; j<vec.outerSize(); ++j)
   {
-    for(typename Derived::InnerIterator it(vec, j); it; ++it)
+    for(typename Derived::InnerIterator iter(vec, j); iter; ++iter)
     {
-      RealScalar ax = abs(it.value());
+      RealScalar ax = abs(iter.value());
       if(ax > ab2)     abig += numext::abs2(ax*s2m);
       else if(ax < b1) asml += numext::abs2(ax*s1m);
       else             amed += numext::abs2(ax);
     }
   }
   if(amed!=amed)
     return amed;  // we got a NaN
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/StlIterators.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/StlIterators.h`

 * *Files 26% similar despite different names*

```diff
@@ -3,14 +3,17 @@
 //
 // Copyright (C) 2018 Gael Guennebaud <gael.guennebaud@inria.fr>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
+#ifndef EIGEN_STLITERATORS_H
+#define EIGEN_STLITERATORS_H
+
 namespace Eigen {
 
 namespace internal {
 
 template<typename IteratorType>
 struct indexed_based_stl_iterator_traits;
 
@@ -26,18 +29,18 @@
   // NOTE: in C++03 we cannot declare friend classes through typedefs because we need to write friend class:
   friend class indexed_based_stl_iterator_base<typename traits::const_iterator>;
   friend class indexed_based_stl_iterator_base<typename traits::non_const_iterator>;
 public:
   typedef Index difference_type;
   typedef std::random_access_iterator_tag iterator_category;
 
-  indexed_based_stl_iterator_base() : mp_xpr(0), m_index(0) {}
-  indexed_based_stl_iterator_base(XprType& xpr, Index index) : mp_xpr(&xpr), m_index(index) {}
+  indexed_based_stl_iterator_base() EIGEN_NO_THROW : mp_xpr(0), m_index(0) {}
+  indexed_based_stl_iterator_base(XprType& xpr, Index index) EIGEN_NO_THROW : mp_xpr(&xpr), m_index(index) {}
 
-  indexed_based_stl_iterator_base(const non_const_iterator& other)
+  indexed_based_stl_iterator_base(const non_const_iterator& other) EIGEN_NO_THROW
     : mp_xpr(other.mp_xpr), m_index(other.m_index)
   {}
 
   indexed_based_stl_iterator_base& operator=(const non_const_iterator& other)
   {
     mp_xpr = other.mp_xpr;
     m_index = other.m_index;
@@ -89,14 +92,93 @@
   Derived& derived() { return static_cast<Derived&>(*this); }
   const Derived& derived() const { return static_cast<const Derived&>(*this); }
 
   XprType *mp_xpr;
   Index m_index;
 };
 
+template<typename  Derived>
+class indexed_based_stl_reverse_iterator_base
+{
+protected:
+  typedef indexed_based_stl_iterator_traits<Derived> traits;
+  typedef typename traits::XprType XprType;
+  typedef indexed_based_stl_reverse_iterator_base<typename traits::non_const_iterator> non_const_iterator;
+  typedef indexed_based_stl_reverse_iterator_base<typename traits::const_iterator> const_iterator;
+  typedef typename internal::conditional<internal::is_const<XprType>::value,non_const_iterator,const_iterator>::type other_iterator;
+  // NOTE: in C++03 we cannot declare friend classes through typedefs because we need to write friend class:
+  friend class indexed_based_stl_reverse_iterator_base<typename traits::const_iterator>;
+  friend class indexed_based_stl_reverse_iterator_base<typename traits::non_const_iterator>;
+public:
+  typedef Index difference_type;
+  typedef std::random_access_iterator_tag iterator_category;
+
+  indexed_based_stl_reverse_iterator_base() : mp_xpr(0), m_index(0) {}
+  indexed_based_stl_reverse_iterator_base(XprType& xpr, Index index) : mp_xpr(&xpr), m_index(index) {}
+
+  indexed_based_stl_reverse_iterator_base(const non_const_iterator& other)
+    : mp_xpr(other.mp_xpr), m_index(other.m_index)
+  {}
+
+  indexed_based_stl_reverse_iterator_base& operator=(const non_const_iterator& other)
+  {
+    mp_xpr = other.mp_xpr;
+    m_index = other.m_index;
+    return *this;
+  }
+
+  Derived& operator++() { --m_index; return derived(); }
+  Derived& operator--() { ++m_index; return derived(); }
+
+  Derived operator++(int) { Derived prev(derived()); operator++(); return prev;}
+  Derived operator--(int) { Derived prev(derived()); operator--(); return prev;}
+
+  friend Derived operator+(const indexed_based_stl_reverse_iterator_base& a, Index b) { Derived ret(a.derived()); ret += b; return ret; }
+  friend Derived operator-(const indexed_based_stl_reverse_iterator_base& a, Index b) { Derived ret(a.derived()); ret -= b; return ret; }
+  friend Derived operator+(Index a, const indexed_based_stl_reverse_iterator_base& b) { Derived ret(b.derived()); ret += a; return ret; }
+  friend Derived operator-(Index a, const indexed_based_stl_reverse_iterator_base& b) { Derived ret(b.derived()); ret -= a; return ret; }
+  
+  Derived& operator+=(Index b) { m_index -= b; return derived(); }
+  Derived& operator-=(Index b) { m_index += b; return derived(); }
+
+  difference_type operator-(const indexed_based_stl_reverse_iterator_base& other) const
+  {
+    eigen_assert(mp_xpr == other.mp_xpr);
+    return other.m_index - m_index;
+  }
+
+  difference_type operator-(const other_iterator& other) const
+  {
+    eigen_assert(mp_xpr == other.mp_xpr);
+    return other.m_index - m_index;
+  }
+
+  bool operator==(const indexed_based_stl_reverse_iterator_base& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index == other.m_index; }
+  bool operator!=(const indexed_based_stl_reverse_iterator_base& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index != other.m_index; }
+  bool operator< (const indexed_based_stl_reverse_iterator_base& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index >  other.m_index; }
+  bool operator<=(const indexed_based_stl_reverse_iterator_base& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index >= other.m_index; }
+  bool operator> (const indexed_based_stl_reverse_iterator_base& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index <  other.m_index; }
+  bool operator>=(const indexed_based_stl_reverse_iterator_base& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index <= other.m_index; }
+
+  bool operator==(const other_iterator& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index == other.m_index; }
+  bool operator!=(const other_iterator& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index != other.m_index; }
+  bool operator< (const other_iterator& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index >  other.m_index; }
+  bool operator<=(const other_iterator& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index >= other.m_index; }
+  bool operator> (const other_iterator& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index <  other.m_index; }
+  bool operator>=(const other_iterator& other) const { eigen_assert(mp_xpr == other.mp_xpr); return m_index <= other.m_index; }
+
+protected:
+
+  Derived& derived() { return static_cast<Derived&>(*this); }
+  const Derived& derived() const { return static_cast<const Derived&>(*this); }
+
+  XprType *mp_xpr;
+  Index m_index;
+};
+
 template<typename XprType>
 class pointer_based_stl_iterator
 {
   enum { is_lvalue  = internal::is_lvalue<XprType>::value };
   typedef pointer_based_stl_iterator<typename internal::remove_const<XprType>::type> non_const_iterator;
   typedef pointer_based_stl_iterator<typename internal::add_const<XprType>::type> const_iterator;
   typedef typename internal::conditional<internal::is_const<XprType>::value,non_const_iterator,const_iterator>::type other_iterator;
@@ -107,25 +189,25 @@
   typedef Index difference_type;
   typedef typename XprType::Scalar value_type;
   typedef std::random_access_iterator_tag iterator_category;
   typedef typename internal::conditional<bool(is_lvalue), value_type*, const value_type*>::type pointer;
   typedef typename internal::conditional<bool(is_lvalue), value_type&, const value_type&>::type reference;
 
 
-  pointer_based_stl_iterator() : m_ptr(0) {}
-  pointer_based_stl_iterator(XprType& xpr, Index index) : m_incr(xpr.innerStride())
+  pointer_based_stl_iterator() EIGEN_NO_THROW : m_ptr(0) {}
+  pointer_based_stl_iterator(XprType& xpr, Index index) EIGEN_NO_THROW : m_incr(xpr.innerStride())
   {
     m_ptr = xpr.data() + index * m_incr.value();
   }
 
-  pointer_based_stl_iterator(const non_const_iterator& other)
+  pointer_based_stl_iterator(const non_const_iterator& other) EIGEN_NO_THROW
     : m_ptr(other.m_ptr), m_incr(other.m_incr)
   {}
 
-  pointer_based_stl_iterator& operator=(const non_const_iterator& other)
+  pointer_based_stl_iterator& operator=(const non_const_iterator& other) EIGEN_NO_THROW
   {
     m_ptr = other.m_ptr;
     m_incr.setValue(other.m_incr);
     return *this;
   }
 
   reference operator*()         const { return *m_ptr;   }
@@ -237,25 +319,86 @@
   typedef indexed_based_stl_iterator_base<subvector_stl_iterator> Base;
   using Base::m_index;
   using Base::mp_xpr;
 
   typedef typename internal::conditional<Direction==Vertical,typename XprType::ColXpr,typename XprType::RowXpr>::type SubVectorType;
   typedef typename internal::conditional<Direction==Vertical,typename XprType::ConstColXpr,typename XprType::ConstRowXpr>::type ConstSubVectorType;
 
+
 public:
-  typedef typename internal::conditional<bool(is_lvalue), SubVectorType, ConstSubVectorType>::type value_type;
-  typedef value_type* pointer;
-  typedef value_type  reference;
+  typedef typename internal::conditional<bool(is_lvalue), SubVectorType, ConstSubVectorType>::type reference;
+  typedef typename reference::PlainObject value_type;
+
+private:
+  class subvector_stl_iterator_ptr
+  {
+  public:
+      subvector_stl_iterator_ptr(const reference &subvector) : m_subvector(subvector) {}
+      reference* operator->() { return &m_subvector; }
+  private:
+      reference m_subvector;
+  };
+public:
+
+  typedef subvector_stl_iterator_ptr pointer;
   
   subvector_stl_iterator() : Base() {}
   subvector_stl_iterator(XprType& xpr, Index index) : Base(xpr,index) {}
 
-  reference operator*()         const { return   (*mp_xpr).template subVector<Direction>(m_index);   }
-  reference operator[](Index i) const { return   (*mp_xpr).template subVector<Direction>(m_index+i); }
-  pointer   operator->()        const { return &((*mp_xpr).template subVector<Direction>(m_index)); }
+  reference operator*()         const { return (*mp_xpr).template subVector<Direction>(m_index); }
+  reference operator[](Index i) const { return (*mp_xpr).template subVector<Direction>(m_index+i); }
+  pointer   operator->()        const { return (*mp_xpr).template subVector<Direction>(m_index); }
+};
+
+template<typename _XprType, DirectionType Direction>
+struct indexed_based_stl_iterator_traits<subvector_stl_reverse_iterator<_XprType,Direction> >
+{
+  typedef _XprType XprType;
+  typedef subvector_stl_reverse_iterator<typename internal::remove_const<XprType>::type, Direction> non_const_iterator;
+  typedef subvector_stl_reverse_iterator<typename internal::add_const<XprType>::type, Direction> const_iterator;
+};
+
+template<typename XprType, DirectionType Direction>
+class subvector_stl_reverse_iterator : public indexed_based_stl_reverse_iterator_base<subvector_stl_reverse_iterator<XprType,Direction> >
+{
+protected:
+
+  enum { is_lvalue  = internal::is_lvalue<XprType>::value };
+
+  typedef indexed_based_stl_reverse_iterator_base<subvector_stl_reverse_iterator> Base;
+  using Base::m_index;
+  using Base::mp_xpr;
+
+  typedef typename internal::conditional<Direction==Vertical,typename XprType::ColXpr,typename XprType::RowXpr>::type SubVectorType;
+  typedef typename internal::conditional<Direction==Vertical,typename XprType::ConstColXpr,typename XprType::ConstRowXpr>::type ConstSubVectorType;
+
+
+public:
+  typedef typename internal::conditional<bool(is_lvalue), SubVectorType, ConstSubVectorType>::type reference;
+  typedef typename reference::PlainObject value_type;
+
+private:
+  class subvector_stl_reverse_iterator_ptr
+  {
+  public:
+      subvector_stl_reverse_iterator_ptr(const reference &subvector) : m_subvector(subvector) {}
+      reference* operator->() { return &m_subvector; }
+  private:
+      reference m_subvector;
+  };
+public:
+
+  typedef subvector_stl_reverse_iterator_ptr pointer;
+  
+  subvector_stl_reverse_iterator() : Base() {}
+  subvector_stl_reverse_iterator(XprType& xpr, Index index) : Base(xpr,index) {}
+
+  reference operator*()         const { return (*mp_xpr).template subVector<Direction>(m_index); }
+  reference operator[](Index i) const { return (*mp_xpr).template subVector<Direction>(m_index+i); }
+  pointer   operator->()        const { return (*mp_xpr).template subVector<Direction>(m_index); }
 };
 
 } // namespace internal
 
 
 /** returns an iterator to the first element of the 1D vector or array
   * \only_for_vectors
@@ -312,7 +455,9 @@
 inline typename DenseBase<Derived>::const_iterator DenseBase<Derived>::cend() const
 {
   EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived);
   return const_iterator(derived(), size());
 }
 
 } // namespace Eigen
+
+#endif // EIGEN_STLITERATORS_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Stride.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Stride.h`

 * *Files 10% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_STRIDE_H
 #define EIGEN_STRIDE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \class Stride
   * \ingroup Core_Module
   *
   * \brief Holds strides information for Map
   *
   * This class holds the strides information for mapping arrays with strides with class Map.
@@ -34,14 +34,22 @@
   *  \tparam _OuterStrideAtCompileTime the outer stride, or Dynamic if you want to specify it at runtime.
   *  \tparam _InnerStrideAtCompileTime the inner stride, or Dynamic if you want to specify it at runtime.
   *
   * Here is an example:
   * \include Map_general_stride.cpp
   * Output: \verbinclude Map_general_stride.out
   *
+  * Both strides can be negative. However, a negative stride of -1 cannot be specified at compile time
+  * because of the ambiguity with Dynamic which is defined to -1 (historically, negative strides were
+  * not allowed).
+  *
+  * Note that for compile-time vectors (ColsAtCompileTime==1 or RowsAtCompile==1),
+  * the inner stride is the pointer increment between two consecutive elements,
+  * regardless of storage layout.
+  *
   * \sa class InnerStride, class OuterStride, \ref TopicStorageOrders
   */
 template<int _OuterStrideAtCompileTime, int _InnerStrideAtCompileTime>
 class Stride
 {
   public:
     typedef Eigen::Index Index; ///< \deprecated since Eigen 3.3
@@ -51,36 +59,37 @@
     };
 
     /** Default constructor, for use when strides are fixed at compile time */
     EIGEN_DEVICE_FUNC
     Stride()
       : m_outer(OuterStrideAtCompileTime), m_inner(InnerStrideAtCompileTime)
     {
+      // FIXME: for Eigen 4 we should use DynamicIndex instead of Dynamic.
+      // FIXME: for Eigen 4 we should also unify this API with fix<>
       eigen_assert(InnerStrideAtCompileTime != Dynamic && OuterStrideAtCompileTime != Dynamic);
     }
 
     /** Constructor allowing to pass the strides at runtime */
     EIGEN_DEVICE_FUNC
     Stride(Index outerStride, Index innerStride)
       : m_outer(outerStride), m_inner(innerStride)
     {
-      eigen_assert(innerStride>=0 && outerStride>=0);
     }
 
     /** Copy constructor */
     EIGEN_DEVICE_FUNC
     Stride(const Stride& other)
       : m_outer(other.outer()), m_inner(other.inner())
     {}
 
     /** \returns the outer stride */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index outer() const { return m_outer.value(); }
     /** \returns the inner stride */
-    EIGEN_DEVICE_FUNC
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
     inline Index inner() const { return m_inner.value(); }
 
   protected:
     internal::variable_if_dynamic<Index, OuterStrideAtCompileTime> m_outer;
     internal::variable_if_dynamic<Index, InnerStrideAtCompileTime> m_inner;
 };
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Swap.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Swap.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Transpose.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Transpose.h`

 * *Files 12% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_TRANSPOSE_H
 #define EIGEN_TRANSPOSE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 template<typename MatrixType>
 struct traits<Transpose<MatrixType> > : public traits<MatrixType>
 {
   typedef typename ref_selector<MatrixType>::type MatrixTypeNested;
   typedef typename remove_reference<MatrixTypeNested>::type MatrixTypeNestedPlain;
@@ -61,18 +61,18 @@
     typedef typename internal::remove_all<MatrixType>::type NestedExpression;
 
     EIGEN_DEVICE_FUNC
     explicit EIGEN_STRONG_INLINE Transpose(MatrixType& matrix) : m_matrix(matrix) {}
 
     EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Transpose)
 
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index rows() const { return m_matrix.cols(); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-    Index cols() const { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
 
     /** \returns the nested expression */
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const typename internal::remove_all<MatrixTypeNested>::type&
     nestedExpression() const { return m_matrix; }
 
     /** \returns the nested expression */
@@ -149,14 +149,16 @@
     }
 
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
     const Scalar& coeffRef(Index index) const
     {
       return derived().nestedExpression().coeffRef(index);
     }
+  protected:
+    EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(TransposeImpl)
 };
 
 /** \returns an expression of the transpose of *this.
   *
   * Example: \include MatrixBase_transpose.cpp
   * Output: \verbinclude MatrixBase_transpose.out
   *
@@ -237,15 +239,14 @@
 template<typename MatrixType>
 struct inplace_transpose_selector<MatrixType,true,false> { // square matrix
   static void run(MatrixType& m) {
     m.matrix().template triangularView<StrictlyUpper>().swap(m.matrix().transpose().template triangularView<StrictlyUpper>());
   }
 };
 
-// TODO: vectorized path is currently limited to LargestPacketSize x LargestPacketSize cases only.
 template<typename MatrixType>
 struct inplace_transpose_selector<MatrixType,true,true> { // PacketSize x PacketSize
   static void run(MatrixType& m) {
     typedef typename MatrixType::Scalar Scalar;
     typedef typename internal::packet_traits<typename MatrixType::Scalar>::type Packet;
     const Index PacketSize = internal::packet_traits<Scalar>::size;
     const Index Alignment = internal::evaluator<MatrixType>::Alignment;
@@ -254,24 +255,74 @@
       A.packet[i] = m.template packetByOuterInner<Alignment>(i,0);
     internal::ptranspose(A);
     for (Index i=0; i<PacketSize; ++i)
       m.template writePacket<Alignment>(m.rowIndexByOuterInner(i,0), m.colIndexByOuterInner(i,0), A.packet[i]);
   }
 };
 
+
+template <typename MatrixType, Index Alignment>
+void BlockedInPlaceTranspose(MatrixType& m) {
+  typedef typename MatrixType::Scalar Scalar;
+  typedef typename internal::packet_traits<typename MatrixType::Scalar>::type Packet;
+  const Index PacketSize = internal::packet_traits<Scalar>::size;
+  eigen_assert(m.rows() == m.cols());
+  int row_start = 0;
+  for (; row_start + PacketSize <= m.rows(); row_start += PacketSize) {
+    for (int col_start = row_start; col_start + PacketSize <= m.cols(); col_start += PacketSize) {
+      PacketBlock<Packet> A;
+      if (row_start == col_start) {
+        for (Index i=0; i<PacketSize; ++i)
+          A.packet[i] = m.template packetByOuterInner<Alignment>(row_start + i,col_start);
+        internal::ptranspose(A);
+        for (Index i=0; i<PacketSize; ++i)
+          m.template writePacket<Alignment>(m.rowIndexByOuterInner(row_start + i, col_start), m.colIndexByOuterInner(row_start + i,col_start), A.packet[i]);
+      } else {
+        PacketBlock<Packet> B;
+        for (Index i=0; i<PacketSize; ++i) {
+          A.packet[i] = m.template packetByOuterInner<Alignment>(row_start + i,col_start);
+          B.packet[i] = m.template packetByOuterInner<Alignment>(col_start + i, row_start);
+        }
+        internal::ptranspose(A);
+        internal::ptranspose(B);
+        for (Index i=0; i<PacketSize; ++i) {
+          m.template writePacket<Alignment>(m.rowIndexByOuterInner(row_start + i, col_start), m.colIndexByOuterInner(row_start + i,col_start), B.packet[i]);
+          m.template writePacket<Alignment>(m.rowIndexByOuterInner(col_start + i, row_start), m.colIndexByOuterInner(col_start + i,row_start), A.packet[i]);
+        }
+      }
+    }
+  }
+  for (Index row = row_start; row < m.rows(); ++row) {
+    m.matrix().row(row).head(row).swap(
+        m.matrix().col(row).head(row).transpose());
+  }
+}
+
 template<typename MatrixType,bool MatchPacketSize>
-struct inplace_transpose_selector<MatrixType,false,MatchPacketSize> { // non square matrix
+struct inplace_transpose_selector<MatrixType,false,MatchPacketSize> { // non square or dynamic matrix
   static void run(MatrixType& m) {
-    if (m.rows()==m.cols())
-      m.matrix().template triangularView<StrictlyUpper>().swap(m.matrix().transpose().template triangularView<StrictlyUpper>());
-    else
+    typedef typename MatrixType::Scalar Scalar;
+    if (m.rows() == m.cols()) {
+      const Index PacketSize = internal::packet_traits<Scalar>::size;
+      if (!NumTraits<Scalar>::IsComplex && m.rows() >= PacketSize) {
+        if ((m.rows() % PacketSize) == 0)
+          BlockedInPlaceTranspose<MatrixType,internal::evaluator<MatrixType>::Alignment>(m);
+        else
+          BlockedInPlaceTranspose<MatrixType,Unaligned>(m);
+      }
+      else {
+        m.matrix().template triangularView<StrictlyUpper>().swap(m.matrix().transpose().template triangularView<StrictlyUpper>());
+      }
+    } else {
       m = m.transpose().eval();
+    }
   }
 };
 
+
 } // end namespace internal
 
 /** This is the "in place" version of transpose(): it replaces \c *this by its own transpose.
   * Thus, doing
   * \code
   * m.transposeInPlace();
   * \endcode
@@ -281,15 +332,15 @@
   * \endcode
   * and is faster and also safer because in the latter line of code, forgetting the eval() results
   * in a bug caused by \ref TopicAliasing "aliasing".
   *
   * Notice however that this method is only useful if you want to replace a matrix by its own transpose.
   * If you just need the transpose of a matrix, use transpose().
   *
-  * \note if the matrix is not square, then \c *this must be a resizable matrix. 
+  * \note if the matrix is not square, then \c *this must be a resizable matrix.
   * This excludes (non-square) fixed-size matrices, block-expressions and maps.
   *
   * \sa transpose(), adjoint(), adjointInPlace() */
 template<typename Derived>
 EIGEN_DEVICE_FUNC inline void DenseBase<Derived>::transposeInPlace()
 {
   eigen_assert((rows() == cols() || (RowsAtCompileTime == Dynamic && ColsAtCompileTime == Dynamic))
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Transpositions.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Transpositions.h`

 * *Files 9% similar despite different names*

```diff
@@ -6,72 +6,69 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_TRANSPOSITIONS_H
 #define EIGEN_TRANSPOSITIONS_H
 
-namespace Eigen { 
+namespace Eigen {
 
 template<typename Derived>
 class TranspositionsBase
 {
     typedef internal::traits<Derived> Traits;
-    
+
   public:
 
     typedef typename Traits::IndicesType IndicesType;
     typedef typename IndicesType::Scalar StorageIndex;
     typedef Eigen::Index Index; ///< \deprecated since Eigen 3.3
 
+    EIGEN_DEVICE_FUNC
     Derived& derived() { return *static_cast<Derived*>(this); }
+    EIGEN_DEVICE_FUNC
     const Derived& derived() const { return *static_cast<const Derived*>(this); }
 
     /** Copies the \a other transpositions into \c *this */
     template<typename OtherDerived>
     Derived& operator=(const TranspositionsBase<OtherDerived>& other)
     {
       indices() = other.indices();
       return derived();
     }
-    
-    #ifndef EIGEN_PARSED_BY_DOXYGEN
-    /** This is a special case of the templated operator=. Its purpose is to
-      * prevent a default operator= from hiding the templated operator=.
-      */
-    Derived& operator=(const TranspositionsBase& other)
-    {
-      indices() = other.indices();
-      return derived();
-    }
-    #endif
 
     /** \returns the number of transpositions */
+    EIGEN_DEVICE_FUNC
     Index size() const { return indices().size(); }
     /** \returns the number of rows of the equivalent permutation matrix */
+    EIGEN_DEVICE_FUNC
     Index rows() const { return indices().size(); }
     /** \returns the number of columns of the equivalent permutation matrix */
+    EIGEN_DEVICE_FUNC
     Index cols() const { return indices().size(); }
 
     /** Direct access to the underlying index vector */
+    EIGEN_DEVICE_FUNC
     inline const StorageIndex& coeff(Index i) const { return indices().coeff(i); }
     /** Direct access to the underlying index vector */
     inline StorageIndex& coeffRef(Index i) { return indices().coeffRef(i); }
     /** Direct access to the underlying index vector */
     inline const StorageIndex& operator()(Index i) const { return indices()(i); }
     /** Direct access to the underlying index vector */
     inline StorageIndex& operator()(Index i) { return indices()(i); }
     /** Direct access to the underlying index vector */
     inline const StorageIndex& operator[](Index i) const { return indices()(i); }
     /** Direct access to the underlying index vector */
     inline StorageIndex& operator[](Index i) { return indices()(i); }
 
     /** const version of indices(). */
+    EIGEN_DEVICE_FUNC
     const IndicesType& indices() const { return derived().indices(); }
     /** \returns a reference to the stored array representing the transpositions. */
+    EIGEN_DEVICE_FUNC
     IndicesType& indices() { return derived().indices(); }
 
     /** Resizes to given size. */
     inline void resize(Index newSize)
     {
       indices().resize(newSize);
     }
@@ -167,51 +164,36 @@
     inline Transpositions() {}
 
     /** Copy constructor. */
     template<typename OtherDerived>
     inline Transpositions(const TranspositionsBase<OtherDerived>& other)
       : m_indices(other.indices()) {}
 
-    #ifndef EIGEN_PARSED_BY_DOXYGEN
-    /** Standard copy constructor. Defined only to prevent a default copy constructor
-      * from hiding the other templated constructor */
-    inline Transpositions(const Transpositions& other) : m_indices(other.indices()) {}
-    #endif
-
     /** Generic constructor from expression of the transposition indices. */
     template<typename Other>
     explicit inline Transpositions(const MatrixBase<Other>& indices) : m_indices(indices)
     {}
 
     /** Copies the \a other transpositions into \c *this */
     template<typename OtherDerived>
     Transpositions& operator=(const TranspositionsBase<OtherDerived>& other)
     {
       return Base::operator=(other);
     }
 
-    #ifndef EIGEN_PARSED_BY_DOXYGEN
-    /** This is a special case of the templated operator=. Its purpose is to
-      * prevent a default operator= from hiding the templated operator=.
-      */
-    Transpositions& operator=(const Transpositions& other)
-    {
-      m_indices = other.m_indices;
-      return *this;
-    }
-    #endif
-
     /** Constructs an uninitialized permutation matrix of given size.
       */
     inline Transpositions(Index size) : m_indices(size)
     {}
 
     /** const version of indices(). */
+    EIGEN_DEVICE_FUNC
     const IndicesType& indices() const { return m_indices; }
     /** \returns a reference to the stored array representing the transpositions. */
+    EIGEN_DEVICE_FUNC
     IndicesType& indices() { return m_indices; }
 
   protected:
 
     IndicesType m_indices;
 };
 
@@ -261,17 +243,19 @@
     {
       m_indices = other.m_indices;
       return *this;
     }
     #endif
 
     /** const version of indices(). */
+    EIGEN_DEVICE_FUNC
     const IndicesType& indices() const { return m_indices; }
-    
+
     /** \returns a reference to the stored array representing the transpositions. */
+    EIGEN_DEVICE_FUNC
     IndicesType& indices() { return m_indices; }
 
   protected:
 
     IndicesType m_indices;
 };
 
@@ -302,29 +286,20 @@
     /** Copies the \a other transpositions into \c *this */
     template<typename OtherDerived>
     TranspositionsWrapper& operator=(const TranspositionsBase<OtherDerived>& other)
     {
       return Base::operator=(other);
     }
 
-    #ifndef EIGEN_PARSED_BY_DOXYGEN
-    /** This is a special case of the templated operator=. Its purpose is to
-      * prevent a default operator= from hiding the templated operator=.
-      */
-    TranspositionsWrapper& operator=(const TranspositionsWrapper& other)
-    {
-      m_indices = other.m_indices;
-      return *this;
-    }
-    #endif
-
     /** const version of indices(). */
+    EIGEN_DEVICE_FUNC
     const IndicesType& indices() const { return m_indices; }
 
     /** \returns a reference to the stored array representing the transpositions. */
+    EIGEN_DEVICE_FUNC
     IndicesType& indices() { return m_indices; }
 
   protected:
 
     typename IndicesType::Nested m_indices;
 };
 
@@ -370,17 +345,20 @@
 {
     typedef TranspositionsDerived TranspositionType;
     typedef typename TranspositionType::IndicesType IndicesType;
   public:
 
     explicit Transpose(const TranspositionType& t) : m_transpositions(t) {}
 
-    Index size() const { return m_transpositions.size(); }
-    Index rows() const { return m_transpositions.size(); }
-    Index cols() const { return m_transpositions.size(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index size() const EIGEN_NOEXCEPT { return m_transpositions.size(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return m_transpositions.size(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return m_transpositions.size(); }
 
     /** \returns the \a matrix with the inverse transpositions applied to the columns.
       */
     template<typename OtherDerived> friend
     const Product<OtherDerived, Transpose, AliasFreeProduct>
     operator*(const MatrixBase<OtherDerived>& matrix, const Transpose& trt)
     {
@@ -391,15 +369,16 @@
       */
     template<typename OtherDerived>
     const Product<Transpose, OtherDerived, AliasFreeProduct>
     operator*(const MatrixBase<OtherDerived>& matrix) const
     {
       return Product<Transpose, OtherDerived, AliasFreeProduct>(*this, matrix.derived());
     }
-    
+
+    EIGEN_DEVICE_FUNC
     const TranspositionType& nestedExpression() const { return m_transpositions; }
 
   protected:
     const TranspositionType& m_transpositions;
 };
 
 } // end namespace Eigen
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/TriangularMatrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/TriangularMatrix.h`

 * *Files 5% similar despite different names*

```diff
@@ -7,20 +7,20 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_TRIANGULARMATRIX_H
 #define EIGEN_TRIANGULARMATRIX_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
-  
+
 template<int Side, typename TriangularType, typename Rhs> struct triangular_solve_retval;
-  
+
 }
 
 /** \class TriangularBase
   * \ingroup Core_Module
   *
   * \brief Base class for triangular part in a matrix
   */
@@ -30,44 +30,44 @@
 
     enum {
       Mode = internal::traits<Derived>::Mode,
       RowsAtCompileTime = internal::traits<Derived>::RowsAtCompileTime,
       ColsAtCompileTime = internal::traits<Derived>::ColsAtCompileTime,
       MaxRowsAtCompileTime = internal::traits<Derived>::MaxRowsAtCompileTime,
       MaxColsAtCompileTime = internal::traits<Derived>::MaxColsAtCompileTime,
-      
+
       SizeAtCompileTime = (internal::size_at_compile_time<internal::traits<Derived>::RowsAtCompileTime,
                                                    internal::traits<Derived>::ColsAtCompileTime>::ret),
       /**< This is equal to the number of coefficients, i.e. the number of
           * rows times the number of columns, or to \a Dynamic if this is not
           * known at compile-time. \sa RowsAtCompileTime, ColsAtCompileTime */
-      
+
       MaxSizeAtCompileTime = (internal::size_at_compile_time<internal::traits<Derived>::MaxRowsAtCompileTime,
                                                    internal::traits<Derived>::MaxColsAtCompileTime>::ret)
-        
+
     };
     typedef typename internal::traits<Derived>::Scalar Scalar;
     typedef typename internal::traits<Derived>::StorageKind StorageKind;
     typedef typename internal::traits<Derived>::StorageIndex StorageIndex;
     typedef typename internal::traits<Derived>::FullMatrixType DenseMatrixType;
     typedef DenseMatrixType DenseType;
     typedef Derived const& Nested;
 
     EIGEN_DEVICE_FUNC
-    inline TriangularBase() { eigen_assert(!((Mode&UnitDiag) && (Mode&ZeroDiag))); }
+    inline TriangularBase() { eigen_assert(!((int(Mode) & int(UnitDiag)) && (int(Mode) & int(ZeroDiag)))); }
+
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return derived().rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return derived().cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index outerStride() const EIGEN_NOEXCEPT { return derived().outerStride(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index innerStride() const EIGEN_NOEXCEPT { return derived().innerStride(); }
 
-    EIGEN_DEVICE_FUNC
-    inline Index rows() const { return derived().rows(); }
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return derived().cols(); }
-    EIGEN_DEVICE_FUNC
-    inline Index outerStride() const { return derived().outerStride(); }
-    EIGEN_DEVICE_FUNC
-    inline Index innerStride() const { return derived().innerStride(); }
-    
     // dummy resize function
     EIGEN_DEVICE_FUNC
     void resize(Index rows, Index cols)
     {
       EIGEN_UNUSED_VARIABLE(rows);
       EIGEN_UNUSED_VARIABLE(cols);
       eigen_assert(rows==this->rows() && cols==this->cols());
@@ -152,15 +152,15 @@
   * \ingroup Core_Module
   *
   * \brief Expression of a triangular part in a matrix
   *
   * \param MatrixType the type of the object in which we are taking the triangular part
   * \param Mode the kind of triangular matrix expression to construct. Can be #Upper,
   *             #Lower, #UnitUpper, #UnitLower, #StrictlyUpper, or #StrictlyLower.
-  *             This is in fact a bit field; it must have either #Upper or #Lower, 
+  *             This is in fact a bit field; it must have either #Upper or #Lower,
   *             and additionally it may have #UnitDiag or #ZeroDiag or neither.
   *
   * This class represents a triangular part of a matrix, not necessarily square. Strictly speaking, for rectangular
   * matrices one should speak of "trapezoid" parts. This class is the return type
   * of MatrixBase::triangularView() and SparseMatrixBase::triangularView(), and most of the time this is the only way it is used.
   *
   * \sa MatrixBase::triangularView()
@@ -195,15 +195,15 @@
 
   protected:
     typedef typename internal::traits<TriangularView>::MatrixTypeNested MatrixTypeNested;
     typedef typename internal::traits<TriangularView>::MatrixTypeNestedNonRef MatrixTypeNestedNonRef;
 
     typedef typename internal::remove_all<typename MatrixType::ConjugateReturnType>::type MatrixConjugateReturnType;
     typedef TriangularView<typename internal::add_const<MatrixType>::type, _Mode> ConstTriangularView;
-    
+
   public:
 
     typedef typename internal::traits<TriangularView>::StorageKind StorageKind;
     typedef typename internal::traits<TriangularView>::MatrixTypeNestedCleaned NestedExpression;
 
     enum {
       Mode = _Mode,
@@ -214,34 +214,32 @@
                     | (Mode & (ZeroDiag)),
       IsVectorAtCompileTime = false
     };
 
     EIGEN_DEVICE_FUNC
     explicit inline TriangularView(MatrixType& matrix) : m_matrix(matrix)
     {}
-    
-    using Base::operator=;
-    TriangularView& operator=(const TriangularView &other)
-    { return Base::operator=(other); }
+
+    EIGEN_INHERIT_ASSIGNMENT_OPERATORS(TriangularView)
 
     /** \copydoc EigenBase::rows() */
-    EIGEN_DEVICE_FUNC
-    inline Index rows() const { return m_matrix.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
     /** \copydoc EigenBase::cols() */
-    EIGEN_DEVICE_FUNC
-    inline Index cols() const { return m_matrix.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
     /** \returns a const reference to the nested expression */
     EIGEN_DEVICE_FUNC
     const NestedExpression& nestedExpression() const { return m_matrix; }
 
     /** \returns a reference to the nested expression */
     EIGEN_DEVICE_FUNC
     NestedExpression& nestedExpression() { return m_matrix; }
-    
+
     typedef TriangularView<const MatrixConjugateReturnType,Mode> ConjugateReturnType;
     /** \sa MatrixBase::conjugate() const */
     EIGEN_DEVICE_FUNC
     inline const ConjugateReturnType conjugate() const
     { return ConjugateReturnType(m_matrix.conjugate()); }
 
     /** \returns an expression of the complex conjugate of \c *this if Cond==true,
@@ -267,29 +265,29 @@
     EIGEN_DEVICE_FUNC
     inline TransposeReturnType transpose()
     {
       EIGEN_STATIC_ASSERT_LVALUE(MatrixType)
       typename MatrixType::TransposeReturnType tmp(m_matrix);
       return TransposeReturnType(tmp);
     }
-    
+
     typedef TriangularView<const typename MatrixType::ConstTransposeReturnType,TransposeMode> ConstTransposeReturnType;
     /** \sa MatrixBase::transpose() const */
     EIGEN_DEVICE_FUNC
     inline const ConstTransposeReturnType transpose() const
     {
       return ConstTransposeReturnType(m_matrix.transpose());
     }
 
     template<typename Other>
     EIGEN_DEVICE_FUNC
-    inline const Solve<TriangularView, Other> 
+    inline const Solve<TriangularView, Other>
     solve(const MatrixBase<Other>& other) const
     { return Solve<TriangularView, Other>(*this, other.derived()); }
-    
+
   // workaround MSVC ICE
   #if EIGEN_COMP_MSVC
     template<int Side, typename Other>
     EIGEN_DEVICE_FUNC
     inline const internal::triangular_solve_retval<Side,TriangularView, Other>
     solve(const MatrixBase<Other>& other) const
     { return Base::template solve<Side>(other); }
@@ -325,15 +323,15 @@
       if (Mode & UnitDiag)
         return 1;
       else if (Mode & ZeroDiag)
         return 0;
       else
         return m_matrix.diagonal().prod();
     }
-      
+
   protected:
 
     MatrixTypeNested m_matrix;
 };
 
 /** \ingroup Core_Module
   *
@@ -387,15 +385,15 @@
     /** \sa MatrixBase::operator-=() */
     template<typename Other>
     EIGEN_DEVICE_FUNC
     TriangularViewType&  operator-=(const DenseBase<Other>& other) {
       internal::call_assignment_no_alias(derived(), other.derived(), internal::sub_assign_op<Scalar,typename Other::Scalar>());
       return derived();
     }
-    
+
     /** \sa MatrixBase::operator*=() */
     EIGEN_DEVICE_FUNC
     TriangularViewType&  operator*=(const typename internal::traits<MatrixType>::Scalar& other) { return *this = derived().nestedExpression() * other; }
     /** \sa DenseBase::operator/=() */
     EIGEN_DEVICE_FUNC
     TriangularViewType&  operator/=(const typename internal::traits<MatrixType>::Scalar& other) { return *this = derived().nestedExpression() / other; }
 
@@ -553,14 +551,18 @@
         dst = rhs;
       this->solveInPlace(dst);
     }
 
     template<typename ProductType>
     EIGEN_DEVICE_FUNC
     EIGEN_STRONG_INLINE TriangularViewType& _assignProduct(const ProductType& prod, const Scalar& alpha, bool beta);
+  protected:
+    EIGEN_DEFAULT_COPY_CONSTRUCTOR(TriangularViewImpl)
+    EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(TriangularViewImpl)
+
 };
 
 /***************************************************************************
 * Implementation of triangular evaluation/assignment
 ***************************************************************************/
 
 #ifndef EIGEN_PARSED_BY_DOXYGEN
@@ -709,15 +711,15 @@
 ****************************************************************************
 * Evaluators and Assignment of triangular expressions
 ***************************************************************************
 ***************************************************************************/
 
 namespace internal {
 
-  
+
 // TODO currently a triangular expression has the form TriangularView<.,.>
 //      in the future triangular-ness should be defined by the expression traits
 //      such that Transpose<TriangularView<.,.> > is valid. (currently TriangularBase::transpose() is overloaded to make it work)
 template<typename MatrixType, unsigned int Mode>
 struct evaluator_traits<TriangularView<MatrixType,Mode> >
 {
   typedef typename storage_kind_to_evaluator_kind<typename MatrixType::StorageKind>::Kind Kind;
@@ -738,15 +740,15 @@
 struct Triangular2Triangular    {};
 struct Triangular2Dense         {};
 struct Dense2Triangular         {};
 
 
 template<typename Kernel, unsigned int Mode, int UnrollCount, bool ClearOpposite> struct triangular_assignment_loop;
 
- 
+
 /** \internal Specialization of the dense assignment kernel for triangular matrices.
   * The main difference is that the triangular, diagonal, and opposite parts are processed through three different functions.
   * \tparam UpLo must be either Lower or Upper
   * \tparam Mode must be either 0, UnitDiag, ZeroDiag, or SelfAdjoint
   */
 template<int UpLo, int Mode, int SetOpposite, typename DstEvaluatorTypeT, typename SrcEvaluatorTypeT, typename Functor, int Version = Specialized>
 class triangular_dense_assignment_kernel : public generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version>
@@ -755,44 +757,44 @@
   typedef generic_dense_assignment_kernel<DstEvaluatorTypeT, SrcEvaluatorTypeT, Functor, Version> Base;
   typedef typename Base::DstXprType DstXprType;
   typedef typename Base::SrcXprType SrcXprType;
   using Base::m_dst;
   using Base::m_src;
   using Base::m_functor;
 public:
-  
+
   typedef typename Base::DstEvaluatorType DstEvaluatorType;
   typedef typename Base::SrcEvaluatorType SrcEvaluatorType;
   typedef typename Base::Scalar Scalar;
   typedef typename Base::AssignmentTraits AssignmentTraits;
-  
-  
+
+
   EIGEN_DEVICE_FUNC triangular_dense_assignment_kernel(DstEvaluatorType &dst, const SrcEvaluatorType &src, const Functor &func, DstXprType& dstExpr)
     : Base(dst, src, func, dstExpr)
   {}
-  
+
 #ifdef EIGEN_INTERNAL_DEBUGGING
   EIGEN_DEVICE_FUNC void assignCoeff(Index row, Index col)
   {
     eigen_internal_assert(row!=col);
     Base::assignCoeff(row,col);
   }
 #else
   using Base::assignCoeff;
 #endif
-  
+
   EIGEN_DEVICE_FUNC void assignDiagonalCoeff(Index id)
   {
          if(Mode==UnitDiag && SetOpposite) m_functor.assignCoeff(m_dst.coeffRef(id,id), Scalar(1));
     else if(Mode==ZeroDiag && SetOpposite) m_functor.assignCoeff(m_dst.coeffRef(id,id), Scalar(0));
     else if(Mode==0)                       Base::assignCoeff(id,id);
   }
-  
+
   EIGEN_DEVICE_FUNC void assignOppositeCoeff(Index row, Index col)
-  { 
+  {
     eigen_internal_assert(row!=col);
     if(SetOpposite)
       m_functor.assignCoeff(m_dst.coeffRef(row,col), Scalar(0));
   }
 };
 
 template<int Mode, bool SetOpposite, typename DstXprType, typename SrcXprType, typename Functor>
@@ -805,25 +807,25 @@
   SrcEvaluatorType srcEvaluator(src);
 
   Index dstRows = src.rows();
   Index dstCols = src.cols();
   if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
     dst.resize(dstRows, dstCols);
   DstEvaluatorType dstEvaluator(dst);
-    
+
   typedef triangular_dense_assignment_kernel< Mode&(Lower|Upper),Mode&(UnitDiag|ZeroDiag|SelfAdjoint),SetOpposite,
                                               DstEvaluatorType,SrcEvaluatorType,Functor> Kernel;
   Kernel kernel(dstEvaluator, srcEvaluator, func, dst.const_cast_derived());
-  
+
   enum {
       unroll = DstXprType::SizeAtCompileTime != Dynamic
             && SrcEvaluatorType::CoeffReadCost < HugeCost
-            && DstXprType::SizeAtCompileTime * (DstEvaluatorType::CoeffReadCost+SrcEvaluatorType::CoeffReadCost) / 2 <= EIGEN_UNROLLING_LIMIT
+            && DstXprType::SizeAtCompileTime * (int(DstEvaluatorType::CoeffReadCost) + int(SrcEvaluatorType::CoeffReadCost)) / 2 <= EIGEN_UNROLLING_LIMIT
     };
-  
+
   triangular_assignment_loop<Kernel, Mode, unroll ? int(DstXprType::SizeAtCompileTime) : Dynamic, SetOpposite>::run(kernel);
 }
 
 template<int Mode, bool SetOpposite, typename DstXprType, typename SrcXprType>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
 void call_triangular_assignment_loop(DstXprType& dst, const SrcXprType& src)
 {
@@ -837,57 +839,57 @@
 
 template< typename DstXprType, typename SrcXprType, typename Functor>
 struct Assignment<DstXprType, SrcXprType, Functor, Triangular2Triangular>
 {
   EIGEN_DEVICE_FUNC static void run(DstXprType &dst, const SrcXprType &src, const Functor &func)
   {
     eigen_assert(int(DstXprType::Mode) == int(SrcXprType::Mode));
-    
-    call_triangular_assignment_loop<DstXprType::Mode, false>(dst, src, func);  
+
+    call_triangular_assignment_loop<DstXprType::Mode, false>(dst, src, func);
   }
 };
 
 template< typename DstXprType, typename SrcXprType, typename Functor>
 struct Assignment<DstXprType, SrcXprType, Functor, Triangular2Dense>
 {
   EIGEN_DEVICE_FUNC static void run(DstXprType &dst, const SrcXprType &src, const Functor &func)
   {
-    call_triangular_assignment_loop<SrcXprType::Mode, (SrcXprType::Mode&SelfAdjoint)==0>(dst, src, func);  
+    call_triangular_assignment_loop<SrcXprType::Mode, (int(SrcXprType::Mode) & int(SelfAdjoint)) == 0>(dst, src, func);
   }
 };
 
 template< typename DstXprType, typename SrcXprType, typename Functor>
 struct Assignment<DstXprType, SrcXprType, Functor, Dense2Triangular>
 {
   EIGEN_DEVICE_FUNC static void run(DstXprType &dst, const SrcXprType &src, const Functor &func)
   {
-    call_triangular_assignment_loop<DstXprType::Mode, false>(dst, src, func);  
+    call_triangular_assignment_loop<DstXprType::Mode, false>(dst, src, func);
   }
 };
 
 
 template<typename Kernel, unsigned int Mode, int UnrollCount, bool SetOpposite>
 struct triangular_assignment_loop
 {
   // FIXME: this is not very clean, perhaps this information should be provided by the kernel?
   typedef typename Kernel::DstEvaluatorType DstEvaluatorType;
   typedef typename DstEvaluatorType::XprType DstXprType;
-  
+
   enum {
     col = (UnrollCount-1) / DstXprType::RowsAtCompileTime,
     row = (UnrollCount-1) % DstXprType::RowsAtCompileTime
   };
-  
+
   typedef typename Kernel::Scalar Scalar;
 
   EIGEN_DEVICE_FUNC
   static inline void run(Kernel &kernel)
   {
     triangular_assignment_loop<Kernel, Mode, UnrollCount-1, SetOpposite>::run(kernel);
-    
+
     if(row==col)
       kernel.assignDiagonalCoeff(row);
     else if( ((Mode&Lower) && row>col) || ((Mode&Upper) && row<col) )
       kernel.assignCoeff(row,col);
     else if(SetOpposite)
       kernel.assignOppositeCoeff(row,col);
   }
@@ -922,18 +924,18 @@
       {
         for(; i < maxi; ++i)
           if(Mode&Upper) kernel.assignCoeff(i, j);
           else           kernel.assignOppositeCoeff(i, j);
       }
       else
         i = maxi;
-      
+
       if(i<kernel.rows()) // then i==j
         kernel.assignDiagonalCoeff(i++);
-      
+
       if (((Mode&Upper) && SetOpposite) || (Mode&Lower))
       {
         for(; i < kernel.rows(); ++i)
           if(Mode&Lower) kernel.assignCoeff(i, j);
           else           kernel.assignOppositeCoeff(i, j);
       }
     }
@@ -945,54 +947,54 @@
 /** Assigns a triangular or selfadjoint matrix to a dense matrix.
   * If the matrix is triangular, the opposite part is set to zero. */
 template<typename Derived>
 template<typename DenseDerived>
 EIGEN_DEVICE_FUNC void TriangularBase<Derived>::evalToLazy(MatrixBase<DenseDerived> &other) const
 {
   other.derived().resize(this->rows(), this->cols());
-  internal::call_triangular_assignment_loop<Derived::Mode,(Derived::Mode&SelfAdjoint)==0 /* SetOpposite */>(other.derived(), derived().nestedExpression());
+  internal::call_triangular_assignment_loop<Derived::Mode, (int(Derived::Mode) & int(SelfAdjoint)) == 0 /* SetOpposite */>(other.derived(), derived().nestedExpression());
 }
 
 namespace internal {
-  
+
 // Triangular = Product
 template< typename DstXprType, typename Lhs, typename Rhs, typename Scalar>
 struct Assignment<DstXprType, Product<Lhs,Rhs,DefaultProduct>, internal::assign_op<Scalar,typename Product<Lhs,Rhs,DefaultProduct>::Scalar>, Dense2Triangular>
 {
   typedef Product<Lhs,Rhs,DefaultProduct> SrcXprType;
   static void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<Scalar,typename SrcXprType::Scalar> &)
   {
     Index dstRows = src.rows();
     Index dstCols = src.cols();
     if((dst.rows()!=dstRows) || (dst.cols()!=dstCols))
       dst.resize(dstRows, dstCols);
 
-    dst._assignProduct(src, 1, 0);
+    dst._assignProduct(src, Scalar(1), false);
   }
 };
 
 // Triangular += Product
 template< typename DstXprType, typename Lhs, typename Rhs, typename Scalar>
 struct Assignment<DstXprType, Product<Lhs,Rhs,DefaultProduct>, internal::add_assign_op<Scalar,typename Product<Lhs,Rhs,DefaultProduct>::Scalar>, Dense2Triangular>
 {
   typedef Product<Lhs,Rhs,DefaultProduct> SrcXprType;
   static void run(DstXprType &dst, const SrcXprType &src, const internal::add_assign_op<Scalar,typename SrcXprType::Scalar> &)
   {
-    dst._assignProduct(src, 1, 1);
+    dst._assignProduct(src, Scalar(1), true);
   }
 };
 
 // Triangular -= Product
 template< typename DstXprType, typename Lhs, typename Rhs, typename Scalar>
 struct Assignment<DstXprType, Product<Lhs,Rhs,DefaultProduct>, internal::sub_assign_op<Scalar,typename Product<Lhs,Rhs,DefaultProduct>::Scalar>, Dense2Triangular>
 {
   typedef Product<Lhs,Rhs,DefaultProduct> SrcXprType;
   static void run(DstXprType &dst, const SrcXprType &src, const internal::sub_assign_op<Scalar,typename SrcXprType::Scalar> &)
   {
-    dst._assignProduct(src, -1, 1);
+    dst._assignProduct(src, Scalar(-1), true);
   }
 };
 
 } // end namespace internal
 
 } // end namespace Eigen
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/VectorBlock.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/VectorBlock.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/VectorwiseOp.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/VectorwiseOp.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,11 +1,11 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
-// Copyright (C) 2008-2010 Gael Guennebaud <gael.guennebaud@inria.fr>
+// Copyright (C) 2008-2019 Gael Guennebaud <gael.guennebaud@inria.fr>
 // Copyright (C) 2006-2008 Benoit Jacob <jacob.benoit.1@gmail.com>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_PARTIAL_REDUX_H
@@ -61,18 +61,18 @@
     typedef typename internal::dense_xpr_base<PartialReduxExpr>::type Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(PartialReduxExpr)
 
     EIGEN_DEVICE_FUNC
     explicit PartialReduxExpr(const MatrixType& mat, const MemberOp& func = MemberOp())
       : m_matrix(mat), m_functor(func) {}
 
-    EIGEN_DEVICE_FUNC
-    Index rows() const { return (Direction==Vertical   ? 1 : m_matrix.rows()); }
-    EIGEN_DEVICE_FUNC
-    Index cols() const { return (Direction==Horizontal ? 1 : m_matrix.cols()); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return (Direction==Vertical   ? 1 : m_matrix.rows()); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return (Direction==Horizontal ? 1 : m_matrix.cols()); }
 
     EIGEN_DEVICE_FUNC
     typename MatrixType::Nested nestedExpression() const { return m_matrix; }
 
     EIGEN_DEVICE_FUNC
     const MemberOp& functor() const { return m_functor; }
 
@@ -130,15 +130,15 @@
 
 template <typename BinaryOpT, typename Scalar>
 struct member_redux {
   typedef BinaryOpT BinaryOp;
   typedef typename result_of<
                      BinaryOp(const Scalar&,const Scalar&)
                    >::type  result_type;
-  
+
   enum { Vectorizable = functor_traits<BinaryOp>::PacketAccess };
   template<int Size> struct Cost { enum { value = (Size-1) * functor_traits<BinaryOp>::Cost }; };
   EIGEN_DEVICE_FUNC explicit member_redux(const BinaryOp func) : m_functor(func) {}
   template<typename Derived>
   EIGEN_DEVICE_FUNC inline result_type operator()(const DenseBase<Derived>& mat) const
   { return mat.redux(m_functor); }
   const BinaryOp& binaryFunc() const { return m_functor; }
@@ -158,33 +158,33 @@
   * It is the return type of DenseBase::colwise() and DenseBase::rowwise()
   * and most of the time this is the only way it is explicitly used.
   *
   * To understand the logic of rowwise/colwise expression, let's consider a generic case `A.colwise().foo()`
   * where `foo` is any method of `VectorwiseOp`. This expression is equivalent to applying `foo()` to each
   * column of `A` and then re-assemble the outputs in a matrix expression:
   * \code [A.col(0).foo(), A.col(1).foo(), ..., A.col(A.cols()-1).foo()] \endcode
-  * 
+  *
   * Example: \include MatrixBase_colwise.cpp
   * Output: \verbinclude MatrixBase_colwise.out
   *
   * The begin() and end() methods are obviously exceptions to the previous rule as they
   * return STL-compatible begin/end iterators to the rows or columns of the nested expression.
   * Typical use cases include for-range-loop and calls to STL algorithms:
-  * 
+  *
   * Example: \include MatrixBase_colwise_iterator_cxx11.cpp
   * Output: \verbinclude MatrixBase_colwise_iterator_cxx11.out
-  * 
+  *
   * For a partial reduction on an empty input, some rules apply.
   * For the sake of clarity, let's consider a vertical reduction:
   *   - If the number of columns is zero, then a 1x0 row-major vector expression is returned.
   *   - Otherwise, if the number of rows is zero, then
   *       - a row vector of zeros is returned for sum-like reductions (sum, squaredNorm, norm, etc.)
   *       - a row vector of ones is returned for a product reduction (e.g., <code>MatrixXd(n,0).colwise().prod()</code>)
   *       - an assert is triggered for all other reductions (minCoeff,maxCoeff,redux(bin_op))
-  * 
+  *
   * \sa DenseBase::colwise(), DenseBase::rowwise(), class PartialReduxExpr
   */
 template<typename ExpressionType, int Direction> class VectorwiseOp
 {
   public:
 
     typedef typename ExpressionType::Scalar Scalar;
@@ -212,15 +212,15 @@
 
     enum {
       isVertical   = (Direction==Vertical) ? 1 : 0,
       isHorizontal = (Direction==Horizontal) ? 1 : 0
     };
 
   protected:
-  
+
     template<typename OtherDerived> struct ExtendedType {
       typedef Replicate<OtherDerived,
                         isVertical   ? 1 : ExpressionType::RowsAtCompileTime,
                         isHorizontal ? 1 : ExpressionType::ColsAtCompileTime> Type;
     };
 
     /** \internal
@@ -275,40 +275,64 @@
     /** STL-like <a href="https://en.cppreference.com/w/cpp/named_req/RandomAccessIterator">RandomAccessIterator</a>
       * iterator type over the columns or rows as returned by the begin() and end() methods.
       */
     random_access_iterator_type iterator;
     /** This is the const version of iterator (aka read-only) */
     random_access_iterator_type const_iterator;
     #else
-    typedef internal::subvector_stl_iterator<ExpressionType,       DirectionType(Direction)> iterator;
-    typedef internal::subvector_stl_iterator<const ExpressionType, DirectionType(Direction)> const_iterator;
+    typedef internal::subvector_stl_iterator<ExpressionType,               DirectionType(Direction)> iterator;
+    typedef internal::subvector_stl_iterator<const ExpressionType,         DirectionType(Direction)> const_iterator;
+    typedef internal::subvector_stl_reverse_iterator<ExpressionType,       DirectionType(Direction)> reverse_iterator;
+    typedef internal::subvector_stl_reverse_iterator<const ExpressionType, DirectionType(Direction)> const_reverse_iterator;
     #endif
 
     /** returns an iterator to the first row (rowwise) or column (colwise) of the nested expression.
       * \sa end(), cbegin()
       */
-    iterator        begin() const { return iterator      (m_matrix, 0); }
+    iterator                 begin()       { return iterator      (m_matrix, 0); }
     /** const version of begin() */
-    const_iterator cbegin() const { return const_iterator(m_matrix, 0); }
+    const_iterator           begin() const { return const_iterator(m_matrix, 0); }
+    /** const version of begin() */
+    const_iterator          cbegin() const { return const_iterator(m_matrix, 0); }
+
+    /** returns a reverse iterator to the last row (rowwise) or column (colwise) of the nested expression.
+      * \sa rend(), crbegin()
+      */
+    reverse_iterator        rbegin()       { return reverse_iterator       (m_matrix, m_matrix.template subVectors<DirectionType(Direction)>()-1); }
+	/** const version of rbegin() */
+    const_reverse_iterator  rbegin() const { return const_reverse_iterator (m_matrix, m_matrix.template subVectors<DirectionType(Direction)>()-1); }
+	/** const version of rbegin() */
+	const_reverse_iterator crbegin() const { return const_reverse_iterator (m_matrix, m_matrix.template subVectors<DirectionType(Direction)>()-1); }
 
     /** returns an iterator to the row (resp. column) following the last row (resp. column) of the nested expression
       * \sa begin(), cend()
       */
-    iterator        end()   const { return iterator      (m_matrix, m_matrix.template subVectors<DirectionType(Direction)>()); }
+    iterator                 end()         { return iterator      (m_matrix, m_matrix.template subVectors<DirectionType(Direction)>()); }
+    /** const version of end() */
+    const_iterator           end()  const  { return const_iterator(m_matrix, m_matrix.template subVectors<DirectionType(Direction)>()); }
     /** const version of end() */
-    const_iterator cend()   const { return const_iterator(m_matrix, m_matrix.template subVectors<DirectionType(Direction)>()); }
+    const_iterator          cend()  const  { return const_iterator(m_matrix, m_matrix.template subVectors<DirectionType(Direction)>()); }
+
+    /** returns a reverse iterator to the row (resp. column) before the first row (resp. column) of the nested expression
+      * \sa begin(), cend()
+      */
+    reverse_iterator        rend()         { return reverse_iterator       (m_matrix, -1); }
+    /** const version of rend() */
+    const_reverse_iterator  rend()  const  { return const_reverse_iterator (m_matrix, -1); }
+    /** const version of rend() */
+    const_reverse_iterator crend()  const  { return const_reverse_iterator (m_matrix, -1); }
 
     /** \returns a row or column vector expression of \c *this reduxed by \a func
       *
       * The template parameter \a BinaryOp is the type of the functor
       * of the custom redux operator. Note that func must be an associative operator.
       *
       * \warning the size along the reduction direction must be strictly positive,
       *          otherwise an assertion is triggered.
-      * 
+      *
       * \sa class VectorwiseOp, DenseBase::colwise(), DenseBase::rowwise()
       */
     template<typename BinaryOp>
     EIGEN_DEVICE_FUNC
     const typename ReduxReturnType<BinaryOp>::Type
     redux(const BinaryOp& func = BinaryOp()) const
     {
@@ -337,15 +361,15 @@
     };
 
     /** \returns a row (or column) vector expression of the smallest coefficient
       * of each column (or row) of the referenced expression.
       *
       * \warning the size along the reduction direction must be strictly positive,
       *          otherwise an assertion is triggered.
-      * 
+      *
       * \warning the result is undefined if \c *this contains NaN.
       *
       * Example: \include PartialRedux_minCoeff.cpp
       * Output: \verbinclude PartialRedux_minCoeff.out
       *
       * \sa DenseBase::minCoeff() */
     EIGEN_DEVICE_FUNC
@@ -356,15 +380,15 @@
     }
 
     /** \returns a row (or column) vector expression of the largest coefficient
       * of each column (or row) of the referenced expression.
       *
       * \warning the size along the reduction direction must be strictly positive,
       *          otherwise an assertion is triggered.
-      * 
+      *
       * \warning the result is undefined if \c *this contains NaN.
       *
       * Example: \include PartialRedux_maxCoeff.cpp
       * Output: \verbinclude PartialRedux_maxCoeff.out
       *
       * \sa DenseBase::maxCoeff() */
     EIGEN_DEVICE_FUNC
@@ -711,14 +735,18 @@
                   Direction==Vertical   ? HNormalized_SizeMinusOne : 1,
                   Direction==Horizontal ? HNormalized_SizeMinusOne : 1> >
             HNormalizedReturnType;
 
     EIGEN_DEVICE_FUNC
     const HNormalizedReturnType hnormalized() const;
 
+#   ifdef EIGEN_VECTORWISEOP_PLUGIN
+#     include EIGEN_VECTORWISEOP_PLUGIN
+#   endif
+
   protected:
     Index redux_length() const
     {
       return Direction==Vertical ? m_matrix.rows() : m_matrix.cols();
     }
     ExpressionTypeNested m_matrix;
 };
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/Visitor.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/Visitor.h`

 * *Files 19% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_VISITOR_H
 #define EIGEN_VISITOR_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename Visitor, typename Derived, int UnrollCount>
 struct visitor_impl
 {
   enum {
@@ -66,30 +66,30 @@
 // evaluator adaptor
 template<typename XprType>
 class visitor_evaluator
 {
 public:
   EIGEN_DEVICE_FUNC
   explicit visitor_evaluator(const XprType &xpr) : m_evaluator(xpr), m_xpr(xpr) {}
-  
+
   typedef typename XprType::Scalar Scalar;
   typedef typename XprType::CoeffReturnType CoeffReturnType;
-  
+
   enum {
     RowsAtCompileTime = XprType::RowsAtCompileTime,
     CoeffReadCost = internal::evaluator<XprType>::CoeffReadCost
   };
-  
-  EIGEN_DEVICE_FUNC Index rows() const { return m_xpr.rows(); }
-  EIGEN_DEVICE_FUNC Index cols() const { return m_xpr.cols(); }
-  EIGEN_DEVICE_FUNC Index size() const { return m_xpr.size(); }
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_xpr.rows(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_xpr.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index size() const EIGEN_NOEXCEPT { return m_xpr.size(); }
 
   EIGEN_DEVICE_FUNC CoeffReturnType coeff(Index row, Index col) const
   { return m_evaluator.coeff(row, col); }
-  
+
 protected:
   internal::evaluator<XprType> m_evaluator;
   const XprType &m_xpr;
 };
 } // end namespace internal
 
 /** Applies the visitor \a visitor to the whole coefficients of the matrix or vector.
@@ -102,33 +102,33 @@
   *   // called for all other coefficients
   *   void operator() (const Scalar& value, Index i, Index j);
   * };
   * \endcode
   *
   * \note compared to one or two \em for \em loops, visitors offer automatic
   * unrolling for small fixed size matrix.
-  * 
+  *
   * \note if the matrix is empty, then the visitor is left unchanged.
   *
   * \sa minCoeff(Index*,Index*), maxCoeff(Index*,Index*), DenseBase::redux()
   */
 template<typename Derived>
 template<typename Visitor>
 EIGEN_DEVICE_FUNC
 void DenseBase<Derived>::visit(Visitor& visitor) const
 {
   if(size()==0)
     return;
-  
+
   typedef typename internal::visitor_evaluator<Derived> ThisEvaluator;
   ThisEvaluator thisEval(derived());
-  
+
   enum {
     unroll =  SizeAtCompileTime != Dynamic
-           && SizeAtCompileTime * ThisEvaluator::CoeffReadCost + (SizeAtCompileTime-1) * internal::functor_traits<Visitor>::Cost <= EIGEN_UNROLLING_LIMIT
+           && SizeAtCompileTime * int(ThisEvaluator::CoeffReadCost) + (SizeAtCompileTime-1) * int(internal::functor_traits<Visitor>::Cost) <= EIGEN_UNROLLING_LIMIT
   };
   return internal::visitor_impl<Visitor, ThisEvaluator, unroll ? int(SizeAtCompileTime) : Dynamic>::run(thisEval, visitor);
 }
 
 namespace internal {
 
 /** \internal
@@ -153,15 +153,15 @@
 };
 
 /** \internal
   * \brief Visitor computing the min coefficient with its value and coordinates
   *
   * \sa DenseBase::minCoeff(Index*, Index*)
   */
-template <typename Derived>
+template <typename Derived, int NaNPropagation>
 struct min_coeff_visitor : coeff_visitor<Derived>
 {
   typedef typename Derived::Scalar Scalar;
   EIGEN_DEVICE_FUNC
   void operator() (const Scalar& value, Index i, Index j)
   {
     if(value < this->res)
@@ -169,140 +169,212 @@
       this->res = value;
       this->row = i;
       this->col = j;
     }
   }
 };
 
-template<typename Scalar>
-struct functor_traits<min_coeff_visitor<Scalar> > {
+template <typename Derived>
+struct min_coeff_visitor<Derived, PropagateNumbers> : coeff_visitor<Derived>
+{
+  typedef typename Derived::Scalar Scalar;
+  EIGEN_DEVICE_FUNC
+  void operator() (const Scalar& value, Index i, Index j)
+  {
+    if((numext::isnan)(this->res) || (!(numext::isnan)(value) && value < this->res))
+    {
+      this->res = value;
+      this->row = i;
+      this->col = j;
+    }
+  }
+};
+
+template <typename Derived>
+struct min_coeff_visitor<Derived, PropagateNaN> : coeff_visitor<Derived>
+{
+  typedef typename Derived::Scalar Scalar;
+  EIGEN_DEVICE_FUNC
+  void operator() (const Scalar& value, Index i, Index j)
+  {
+    if((numext::isnan)(value) || value < this->res)
+    {
+      this->res = value;
+      this->row = i;
+      this->col = j;
+    }
+  }
+};
+
+template<typename Scalar, int NaNPropagation>
+    struct functor_traits<min_coeff_visitor<Scalar, NaNPropagation> > {
   enum {
     Cost = NumTraits<Scalar>::AddCost
   };
 };
 
 /** \internal
   * \brief Visitor computing the max coefficient with its value and coordinates
   *
   * \sa DenseBase::maxCoeff(Index*, Index*)
   */
-template <typename Derived>
+template <typename Derived, int NaNPropagation>
 struct max_coeff_visitor : coeff_visitor<Derived>
 {
-  typedef typename Derived::Scalar Scalar; 
+  typedef typename Derived::Scalar Scalar;
   EIGEN_DEVICE_FUNC
   void operator() (const Scalar& value, Index i, Index j)
   {
     if(value > this->res)
     {
       this->res = value;
       this->row = i;
       this->col = j;
     }
   }
 };
 
-template<typename Scalar>
-struct functor_traits<max_coeff_visitor<Scalar> > {
+template <typename Derived>
+struct max_coeff_visitor<Derived, PropagateNumbers> : coeff_visitor<Derived>
+{
+  typedef typename Derived::Scalar Scalar;
+  EIGEN_DEVICE_FUNC
+  void operator() (const Scalar& value, Index i, Index j)
+  {
+    if((numext::isnan)(this->res) || (!(numext::isnan)(value) && value > this->res))
+    {
+      this->res = value;
+      this->row = i;
+      this->col = j;
+    }
+  }
+};
+
+template <typename Derived>
+struct max_coeff_visitor<Derived, PropagateNaN> : coeff_visitor<Derived>
+{
+  typedef typename Derived::Scalar Scalar;
+  EIGEN_DEVICE_FUNC
+  void operator() (const Scalar& value, Index i, Index j)
+  {
+    if((numext::isnan)(value) || value > this->res)
+    {
+      this->res = value;
+      this->row = i;
+      this->col = j;
+    }
+  }
+};
+
+template<typename Scalar, int NaNPropagation>
+struct functor_traits<max_coeff_visitor<Scalar, NaNPropagation> > {
   enum {
     Cost = NumTraits<Scalar>::AddCost
   };
 };
 
 } // end namespace internal
 
 /** \fn DenseBase<Derived>::minCoeff(IndexType* rowId, IndexType* colId) const
   * \returns the minimum of all coefficients of *this and puts in *row and *col its location.
-  * 
+  *
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is maximum of elements that are not NaN
   * \warning the matrix must be not empty, otherwise an assertion is triggered.
-  * 
-  * \warning the result is undefined if \c *this contains NaN.
   *
   * \sa DenseBase::minCoeff(Index*), DenseBase::maxCoeff(Index*,Index*), DenseBase::visit(), DenseBase::minCoeff()
   */
 template<typename Derived>
-template<typename IndexType>
+template<int NaNPropagation, typename IndexType>
 EIGEN_DEVICE_FUNC
 typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::minCoeff(IndexType* rowId, IndexType* colId) const
 {
   eigen_assert(this->rows()>0 && this->cols()>0 && "you are using an empty matrix");
 
-  internal::min_coeff_visitor<Derived> minVisitor;
+  internal::min_coeff_visitor<Derived, NaNPropagation> minVisitor;
   this->visit(minVisitor);
   *rowId = minVisitor.row;
   if (colId) *colId = minVisitor.col;
   return minVisitor.res;
 }
 
 /** \returns the minimum of all coefficients of *this and puts in *index its location.
-  * 
+  *
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is maximum of elements that are not NaN
   * \warning the matrix must be not empty, otherwise an assertion is triggered.
-  * 
-  * \warning the result is undefined if \c *this contains NaN. 
   *
   * \sa DenseBase::minCoeff(IndexType*,IndexType*), DenseBase::maxCoeff(IndexType*,IndexType*), DenseBase::visit(), DenseBase::minCoeff()
   */
 template<typename Derived>
-template<typename IndexType>
+template<int NaNPropagation, typename IndexType>
 EIGEN_DEVICE_FUNC
 typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::minCoeff(IndexType* index) const
 {
   eigen_assert(this->rows()>0 && this->cols()>0 && "you are using an empty matrix");
 
   EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
-  internal::min_coeff_visitor<Derived> minVisitor;
+      internal::min_coeff_visitor<Derived, NaNPropagation> minVisitor;
   this->visit(minVisitor);
   *index = IndexType((RowsAtCompileTime==1) ? minVisitor.col : minVisitor.row);
   return minVisitor.res;
 }
 
 /** \fn DenseBase<Derived>::maxCoeff(IndexType* rowId, IndexType* colId) const
   * \returns the maximum of all coefficients of *this and puts in *row and *col its location.
-  * 
+  *
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is maximum of elements that are not NaN
   * \warning the matrix must be not empty, otherwise an assertion is triggered.
-  * 
-  * \warning the result is undefined if \c *this contains NaN. 
   *
   * \sa DenseBase::minCoeff(IndexType*,IndexType*), DenseBase::visit(), DenseBase::maxCoeff()
   */
 template<typename Derived>
-template<typename IndexType>
+template<int NaNPropagation, typename IndexType>
 EIGEN_DEVICE_FUNC
 typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::maxCoeff(IndexType* rowPtr, IndexType* colPtr) const
 {
   eigen_assert(this->rows()>0 && this->cols()>0 && "you are using an empty matrix");
 
-  internal::max_coeff_visitor<Derived> maxVisitor;
+  internal::max_coeff_visitor<Derived, NaNPropagation> maxVisitor;
   this->visit(maxVisitor);
   *rowPtr = maxVisitor.row;
   if (colPtr) *colPtr = maxVisitor.col;
   return maxVisitor.res;
 }
 
 /** \returns the maximum of all coefficients of *this and puts in *index its location.
-  * 
-  * \warning the matrix must be not empty, otherwise an assertion is triggered.
   *
-  * \warning the result is undefined if \c *this contains NaN.
+  * In case \c *this contains NaN, NaNPropagation determines the behavior:
+  *   NaNPropagation == PropagateFast : undefined
+  *   NaNPropagation == PropagateNaN : result is NaN
+  *   NaNPropagation == PropagateNumbers : result is maximum of elements that are not NaN
+  * \warning the matrix must be not empty, otherwise an assertion is triggered.
   *
   * \sa DenseBase::maxCoeff(IndexType*,IndexType*), DenseBase::minCoeff(IndexType*,IndexType*), DenseBase::visitor(), DenseBase::maxCoeff()
   */
 template<typename Derived>
-template<typename IndexType>
+template<int NaNPropagation, typename IndexType>
 EIGEN_DEVICE_FUNC
 typename internal::traits<Derived>::Scalar
 DenseBase<Derived>::maxCoeff(IndexType* index) const
 {
   eigen_assert(this->rows()>0 && this->cols()>0 && "you are using an empty matrix");
 
   EIGEN_STATIC_ASSERT_VECTOR_ONLY(Derived)
-  internal::max_coeff_visitor<Derived> maxVisitor;
+      internal::max_coeff_visitor<Derived, NaNPropagation> maxVisitor;
   this->visit(maxVisitor);
   *index = (RowsAtCompileTime==1) ? maxVisitor.col : maxVisitor.row;
   return maxVisitor.res;
 }
 
 } // end namespace Eigen
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX/Complex.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AltiVec/Complex.h`

 * *Files 15% similar despite different names*

```diff
@@ -1,471 +1,417 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
-// Copyright (C) 2014 Benoit Steiner (benoit.steiner.goog@gmail.com)
+// Copyright (C) 2010 Gael Guennebaud <gael.guennebaud@inria.fr>
+// Copyright (C) 2010-2016 Konstantinos Margaritis <markos@freevec.org>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
-#ifndef EIGEN_COMPLEX_AVX_H
-#define EIGEN_COMPLEX_AVX_H
+#ifndef EIGEN_COMPLEX32_ALTIVEC_H
+#define EIGEN_COMPLEX32_ALTIVEC_H
 
 namespace Eigen {
 
 namespace internal {
 
+static Packet4ui  p4ui_CONJ_XOR = vec_mergeh((Packet4ui)p4i_ZERO, (Packet4ui)p4f_MZERO);//{ 0x00000000, 0x80000000, 0x00000000, 0x80000000 };
+#ifdef __VSX__
+#if defined(_BIG_ENDIAN)
+static Packet2ul  p2ul_CONJ_XOR1 = (Packet2ul) vec_sld((Packet4ui) p2d_MZERO, (Packet4ui) p2l_ZERO, 8);//{ 0x8000000000000000, 0x0000000000000000 };
+static Packet2ul  p2ul_CONJ_XOR2 = (Packet2ul) vec_sld((Packet4ui) p2l_ZERO,  (Packet4ui) p2d_MZERO, 8);//{ 0x8000000000000000, 0x0000000000000000 };
+#else
+static Packet2ul  p2ul_CONJ_XOR1 = (Packet2ul) vec_sld((Packet4ui) p2l_ZERO,  (Packet4ui) p2d_MZERO, 8);//{ 0x8000000000000000, 0x0000000000000000 };
+static Packet2ul  p2ul_CONJ_XOR2 = (Packet2ul) vec_sld((Packet4ui) p2d_MZERO, (Packet4ui) p2l_ZERO, 8);//{ 0x8000000000000000, 0x0000000000000000 };
+#endif
+#endif
+
 //---------- float ----------
-struct Packet4cf
+struct Packet2cf
 {
-  EIGEN_STRONG_INLINE Packet4cf() {}
-  EIGEN_STRONG_INLINE explicit Packet4cf(const __m256& a) : v(a) {}
-  __m256  v;
+  EIGEN_STRONG_INLINE explicit Packet2cf() {}
+  EIGEN_STRONG_INLINE explicit Packet2cf(const Packet4f& a) : v(a) {}
+
+  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b)
+  {
+    Packet4f v1, v2;
+
+    // Permute and multiply the real parts of a and b
+    v1 = vec_perm(a.v, a.v, p16uc_PSET32_WODD);
+    // Get the imaginary parts of a
+    v2 = vec_perm(a.v, a.v, p16uc_PSET32_WEVEN);
+    // multiply a_re * b
+    v1 = vec_madd(v1, b.v, p4f_ZERO);
+    // multiply a_im * b and get the conjugate result
+    v2 = vec_madd(v2, b.v, p4f_ZERO);
+    v2 = reinterpret_cast<Packet4f>(pxor(v2, reinterpret_cast<Packet4f>(p4ui_CONJ_XOR)));
+    // permute back to a proper order
+    v2 = vec_perm(v2, v2, p16uc_COMPLEX32_REV);
+
+    return Packet2cf(padd<Packet4f>(v1, v2));
+  }
+
+  EIGEN_STRONG_INLINE Packet2cf& operator*=(const Packet2cf& b) {
+    v = pmul(Packet2cf(*this), b).v;
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet2cf operator*(const Packet2cf& b) const {
+    return Packet2cf(*this) *= b;
+  }
+
+  EIGEN_STRONG_INLINE Packet2cf& operator+=(const Packet2cf& b) {
+    v = padd(v, b.v);
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet2cf operator+(const Packet2cf& b) const {
+    return Packet2cf(*this) += b;
+  }
+  EIGEN_STRONG_INLINE Packet2cf& operator-=(const Packet2cf& b) {
+    v = psub(v, b.v);
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet2cf operator-(const Packet2cf& b) const {
+    return Packet2cf(*this) -= b;
+  }
+  EIGEN_STRONG_INLINE Packet2cf operator-(void) const {
+    return Packet2cf(-v);
+  }
+
+  Packet4f  v;
 };
 
-#ifndef EIGEN_VECTORIZE_AVX512
 template<> struct packet_traits<std::complex<float> >  : default_packet_traits
 {
-  typedef Packet4cf type;
+  typedef Packet2cf type;
   typedef Packet2cf half;
+  typedef Packet4f as_real;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
-    size = 4,
-    HasHalfPacket = 1,
+    size = 2,
+    HasHalfPacket = 0,
 
     HasAdd    = 1,
     HasSub    = 1,
     HasMul    = 1,
     HasDiv    = 1,
     HasNegate = 1,
     HasAbs    = 0,
     HasAbs2   = 0,
     HasMin    = 0,
     HasMax    = 0,
+#ifdef __VSX__
+    HasBlend  = 1,
+#endif
     HasSetLinear = 0
   };
 };
-#endif
 
-template<> struct unpacket_traits<Packet4cf> { typedef std::complex<float> type; enum {size=4, alignment=Aligned32, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet2cf half; };
+template<> struct unpacket_traits<Packet2cf> { typedef std::complex<float> type; enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet2cf half; typedef Packet4f as_real; };
 
-template<> EIGEN_STRONG_INLINE Packet4cf padd<Packet4cf>(const Packet4cf& a, const Packet4cf& b) { return Packet4cf(_mm256_add_ps(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet4cf psub<Packet4cf>(const Packet4cf& a, const Packet4cf& b) { return Packet4cf(_mm256_sub_ps(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet4cf pnegate(const Packet4cf& a)
-{
-  return Packet4cf(pnegate(a.v));
-}
-template<> EIGEN_STRONG_INLINE Packet4cf pconj(const Packet4cf& a)
+template<> EIGEN_STRONG_INLINE Packet2cf pset1<Packet2cf>(const std::complex<float>&  from)
 {
-  const __m256 mask = _mm256_castsi256_ps(_mm256_setr_epi32(0x00000000,0x80000000,0x00000000,0x80000000,0x00000000,0x80000000,0x00000000,0x80000000));
-  return Packet4cf(_mm256_xor_ps(a.v,mask));
+  Packet2cf res;
+  if((std::ptrdiff_t(&from) % 16) == 0)
+    res.v = pload<Packet4f>((const float *)&from);
+  else
+    res.v = ploadu<Packet4f>((const float *)&from);
+  res.v = vec_perm(res.v, res.v, p16uc_PSET64_HI);
+  return res;
+}
+
+template<> EIGEN_STRONG_INLINE Packet2cf pload<Packet2cf>(const std::complex<float>*        from) { return Packet2cf(pload<Packet4f>((const float *) from)); }
+template<> EIGEN_STRONG_INLINE Packet2cf ploadu<Packet2cf>(const std::complex<float>*       from) { return Packet2cf(ploadu<Packet4f>((const float*) from)); }
+template<> EIGEN_STRONG_INLINE Packet2cf ploaddup<Packet2cf>(const std::complex<float>*     from) { return pset1<Packet2cf>(*from); }
+
+template<> EIGEN_STRONG_INLINE void pstore <std::complex<float> >(std::complex<float> *   to, const Packet2cf& from) { pstore((float*)to, from.v); }
+template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<float> >(std::complex<float> *   to, const Packet2cf& from) { pstoreu((float*)to, from.v); }
+
+EIGEN_STRONG_INLINE Packet2cf pload2(const std::complex<float>& from0, const std::complex<float>& from1)
+{
+  Packet4f res0, res1;
+#ifdef __VSX__
+  __asm__ ("lxsdx %x0,%y1" : "=wa" (res0) : "Z" (from0));
+  __asm__ ("lxsdx %x0,%y1" : "=wa" (res1) : "Z" (from1));
+#ifdef _BIG_ENDIAN
+  __asm__ ("xxpermdi %x0, %x1, %x2, 0" : "=wa" (res0) : "wa" (res0), "wa" (res1));
+#else
+  __asm__ ("xxpermdi %x0, %x2, %x1, 0" : "=wa" (res0) : "wa" (res0), "wa" (res1));
+#endif
+#else
+  *reinterpret_cast<std::complex<float> *>(&res0) = from0;
+  *reinterpret_cast<std::complex<float> *>(&res1) = from1;
+  res0 = vec_perm(res0, res1, p16uc_TRANSPOSE64_HI);
+#endif
+  return Packet2cf(res0);
 }
 
-template<> EIGEN_STRONG_INLINE Packet4cf pmul<Packet4cf>(const Packet4cf& a, const Packet4cf& b)
+template<> EIGEN_DEVICE_FUNC inline Packet2cf pgather<std::complex<float>, Packet2cf>(const std::complex<float>* from, Index stride)
 {
-  __m256 tmp1 = _mm256_mul_ps(_mm256_moveldup_ps(a.v), b.v);
-  __m256 tmp2 = _mm256_mul_ps(_mm256_movehdup_ps(a.v), _mm256_permute_ps(b.v, _MM_SHUFFLE(2,3,0,1)));
-  __m256 result = _mm256_addsub_ps(tmp1, tmp2);
-  return Packet4cf(result);
+  EIGEN_ALIGN16 std::complex<float> af[2];
+  af[0] = from[0*stride];
+  af[1] = from[1*stride];
+  return pload<Packet2cf>(af);
 }
-
-template <>
-EIGEN_STRONG_INLINE Packet4cf pcmp_eq(const Packet4cf& a, const Packet4cf& b) {
-  __m256 eq = _mm256_cmp_ps(a.v, b.v, _CMP_EQ_OQ);
-  return Packet4cf(_mm256_and_ps(eq, _mm256_permute_ps(eq, 0xb1)));
+template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<float>, Packet2cf>(std::complex<float>* to, const Packet2cf& from, Index stride)
+{
+  EIGEN_ALIGN16 std::complex<float> af[2];
+  pstore<std::complex<float> >((std::complex<float> *) af, from);
+  to[0*stride] = af[0];
+  to[1*stride] = af[1];
 }
 
-template<> EIGEN_STRONG_INLINE Packet4cf ptrue<Packet4cf>(const Packet4cf& a) { return Packet4cf(ptrue(Packet8f(a.v))); }
-template<> EIGEN_STRONG_INLINE Packet4cf pnot<Packet4cf>(const Packet4cf& a) { return Packet4cf(pnot(Packet8f(a.v))); }
-template<> EIGEN_STRONG_INLINE Packet4cf pand   <Packet4cf>(const Packet4cf& a, const Packet4cf& b) { return Packet4cf(_mm256_and_ps(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet4cf por    <Packet4cf>(const Packet4cf& a, const Packet4cf& b) { return Packet4cf(_mm256_or_ps(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet4cf pxor   <Packet4cf>(const Packet4cf& a, const Packet4cf& b) { return Packet4cf(_mm256_xor_ps(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet4cf pandnot<Packet4cf>(const Packet4cf& a, const Packet4cf& b) { return Packet4cf(_mm256_andnot_ps(b.v,a.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf padd<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(a.v + b.v); }
+template<> EIGEN_STRONG_INLINE Packet2cf psub<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(a.v - b.v); }
+template<> EIGEN_STRONG_INLINE Packet2cf pnegate(const Packet2cf& a) { return Packet2cf(pnegate(a.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf pconj(const Packet2cf& a) { return Packet2cf(pxor<Packet4f>(a.v, reinterpret_cast<Packet4f>(p4ui_CONJ_XOR))); }
 
-template<> EIGEN_STRONG_INLINE Packet4cf pload <Packet4cf>(const std::complex<float>* from) { EIGEN_DEBUG_ALIGNED_LOAD return Packet4cf(pload<Packet8f>(&numext::real_ref(*from))); }
-template<> EIGEN_STRONG_INLINE Packet4cf ploadu<Packet4cf>(const std::complex<float>* from) { EIGEN_DEBUG_UNALIGNED_LOAD return Packet4cf(ploadu<Packet8f>(&numext::real_ref(*from))); }
+template<> EIGEN_STRONG_INLINE Packet2cf pand   <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pand<Packet4f>(a.v, b.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf por    <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(por<Packet4f>(a.v, b.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf pxor   <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pxor<Packet4f>(a.v, b.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf pandnot<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pandnot<Packet4f>(a.v, b.v)); }
 
+template<> EIGEN_STRONG_INLINE void prefetch<std::complex<float> >(const std::complex<float> * addr)    { EIGEN_PPC_PREFETCH(addr); }
 
-template<> EIGEN_STRONG_INLINE Packet4cf pset1<Packet4cf>(const std::complex<float>& from)
+template<> EIGEN_STRONG_INLINE std::complex<float>  pfirst<Packet2cf>(const Packet2cf& a)
 {
-  return Packet4cf(_mm256_castpd_ps(_mm256_broadcast_sd((const double*)(const void*)&from)));
+  EIGEN_ALIGN16 std::complex<float> res[2];
+  pstore((float *)&res, a.v);
+
+  return res[0];
 }
 
-template<> EIGEN_STRONG_INLINE Packet4cf ploaddup<Packet4cf>(const std::complex<float>* from)
+template<> EIGEN_STRONG_INLINE Packet2cf preverse(const Packet2cf& a)
 {
-  // FIXME The following might be optimized using _mm256_movedup_pd
-  Packet2cf a = ploaddup<Packet2cf>(from);
-  Packet2cf b = ploaddup<Packet2cf>(from+1);
-  return  Packet4cf(_mm256_insertf128_ps(_mm256_castps128_ps256(a.v), b.v, 1));
+  Packet4f rev_a;
+  rev_a = vec_perm(a.v, a.v, p16uc_COMPLEX32_REV2);
+  return Packet2cf(rev_a);
 }
 
-template<> EIGEN_STRONG_INLINE void pstore <std::complex<float> >(std::complex<float>* to, const Packet4cf& from) { EIGEN_DEBUG_ALIGNED_STORE pstore(&numext::real_ref(*to), from.v); }
-template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<float> >(std::complex<float>* to, const Packet4cf& from) { EIGEN_DEBUG_UNALIGNED_STORE pstoreu(&numext::real_ref(*to), from.v); }
-
-template<> EIGEN_DEVICE_FUNC inline Packet4cf pgather<std::complex<float>, Packet4cf>(const std::complex<float>* from, Index stride)
+template<> EIGEN_STRONG_INLINE std::complex<float> predux<Packet2cf>(const Packet2cf& a)
 {
-  return Packet4cf(_mm256_set_ps(std::imag(from[3*stride]), std::real(from[3*stride]),
-                                 std::imag(from[2*stride]), std::real(from[2*stride]),
-                                 std::imag(from[1*stride]), std::real(from[1*stride]),
-                                 std::imag(from[0*stride]), std::real(from[0*stride])));
+  Packet4f b;
+  b = vec_sld(a.v, a.v, 8);
+  b = padd<Packet4f>(a.v, b);
+  return pfirst<Packet2cf>(Packet2cf(b));
 }
 
-template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<float>, Packet4cf>(std::complex<float>* to, const Packet4cf& from, Index stride)
+template<> EIGEN_STRONG_INLINE std::complex<float> predux_mul<Packet2cf>(const Packet2cf& a)
 {
-  __m128 low = _mm256_extractf128_ps(from.v, 0);
-  to[stride*0] = std::complex<float>(_mm_cvtss_f32(_mm_shuffle_ps(low, low, 0)),
-                                     _mm_cvtss_f32(_mm_shuffle_ps(low, low, 1)));
-  to[stride*1] = std::complex<float>(_mm_cvtss_f32(_mm_shuffle_ps(low, low, 2)),
-                                     _mm_cvtss_f32(_mm_shuffle_ps(low, low, 3)));
-
-  __m128 high = _mm256_extractf128_ps(from.v, 1);
-  to[stride*2] = std::complex<float>(_mm_cvtss_f32(_mm_shuffle_ps(high, high, 0)),
-                                     _mm_cvtss_f32(_mm_shuffle_ps(high, high, 1)));
-  to[stride*3] = std::complex<float>(_mm_cvtss_f32(_mm_shuffle_ps(high, high, 2)),
-                                     _mm_cvtss_f32(_mm_shuffle_ps(high, high, 3)));
+  Packet4f b;
+  Packet2cf prod;
+  b = vec_sld(a.v, a.v, 8);
+  prod = pmul<Packet2cf>(a, Packet2cf(b));
 
+  return pfirst<Packet2cf>(prod);
 }
 
-template<> EIGEN_STRONG_INLINE std::complex<float>  pfirst<Packet4cf>(const Packet4cf& a)
-{
-  return pfirst(Packet2cf(_mm256_castps256_ps128(a.v)));
-}
+EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf,Packet4f)
 
-template<> EIGEN_STRONG_INLINE Packet4cf preverse(const Packet4cf& a) {
-  __m128 low  = _mm256_extractf128_ps(a.v, 0);
-  __m128 high = _mm256_extractf128_ps(a.v, 1);
-  __m128d lowd  = _mm_castps_pd(low);
-  __m128d highd = _mm_castps_pd(high);
-  low  = _mm_castpd_ps(_mm_shuffle_pd(lowd,lowd,0x1));
-  high = _mm_castpd_ps(_mm_shuffle_pd(highd,highd,0x1));
-  __m256 result = _mm256_setzero_ps();
-  result = _mm256_insertf128_ps(result, low, 1);
-  result = _mm256_insertf128_ps(result, high, 0);
-  return Packet4cf(result);
+template<> EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
+{
+  // TODO optimize it for AltiVec
+  Packet2cf res = pmul(a, pconj(b));
+  Packet4f s = pmul<Packet4f>(b.v, b.v);
+  return Packet2cf(pdiv(res.v, padd<Packet4f>(s, vec_perm(s, s, p16uc_COMPLEX32_REV))));
 }
 
-template<> EIGEN_STRONG_INLINE std::complex<float> predux<Packet4cf>(const Packet4cf& a)
+template<> EIGEN_STRONG_INLINE Packet2cf pcplxflip<Packet2cf>(const Packet2cf& x)
 {
-  return predux(padd(Packet2cf(_mm256_extractf128_ps(a.v,0)),
-                     Packet2cf(_mm256_extractf128_ps(a.v,1))));
+  return Packet2cf(vec_perm(x.v, x.v, p16uc_COMPLEX32_REV));
 }
 
-template<> EIGEN_STRONG_INLINE Packet4cf preduxp<Packet4cf>(const Packet4cf* vecs)
+EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet2cf,2>& kernel)
 {
-  Packet8f t0 = _mm256_shuffle_ps(vecs[0].v, vecs[0].v, _MM_SHUFFLE(3, 1, 2 ,0));
-  Packet8f t1 = _mm256_shuffle_ps(vecs[1].v, vecs[1].v, _MM_SHUFFLE(3, 1, 2 ,0));
-  t0 = _mm256_hadd_ps(t0,t1);
-  Packet8f t2 = _mm256_shuffle_ps(vecs[2].v, vecs[2].v, _MM_SHUFFLE(3, 1, 2 ,0));
-  Packet8f t3 = _mm256_shuffle_ps(vecs[3].v, vecs[3].v, _MM_SHUFFLE(3, 1, 2 ,0));
-  t2 = _mm256_hadd_ps(t2,t3);
-  
-  t1 = _mm256_permute2f128_ps(t0,t2, 0 + (2<<4));
-  t3 = _mm256_permute2f128_ps(t0,t2, 1 + (3<<4));
+  Packet4f tmp = vec_perm(kernel.packet[0].v, kernel.packet[1].v, p16uc_TRANSPOSE64_HI);
+  kernel.packet[1].v = vec_perm(kernel.packet[0].v, kernel.packet[1].v, p16uc_TRANSPOSE64_LO);
+  kernel.packet[0].v = tmp;
+}
 
-  return Packet4cf(_mm256_add_ps(t1,t3));
+template<> EIGEN_STRONG_INLINE Packet2cf pcmp_eq(const Packet2cf& a, const Packet2cf& b) {
+  Packet4f eq = reinterpret_cast<Packet4f>(vec_cmpeq(a.v,b.v));
+  return Packet2cf(vec_and(eq, vec_perm(eq, eq, p16uc_COMPLEX32_REV)));
 }
 
-template<> EIGEN_STRONG_INLINE std::complex<float> predux_mul<Packet4cf>(const Packet4cf& a)
-{
-  return predux_mul(pmul(Packet2cf(_mm256_extractf128_ps(a.v, 0)),
-                         Packet2cf(_mm256_extractf128_ps(a.v, 1))));
+#ifdef __VSX__
+template<> EIGEN_STRONG_INLINE Packet2cf pblend(const Selector<2>& ifPacket, const Packet2cf& thenPacket, const Packet2cf& elsePacket) {
+  Packet2cf result;
+  result.v = reinterpret_cast<Packet4f>(pblend<Packet2d>(ifPacket, reinterpret_cast<Packet2d>(thenPacket.v), reinterpret_cast<Packet2d>(elsePacket.v)));
+  return result;
 }
+#endif
 
-template<int Offset>
-struct palign_impl<Offset,Packet4cf>
+template<> EIGEN_STRONG_INLINE Packet2cf psqrt<Packet2cf>(const Packet2cf& a)
 {
-  static EIGEN_STRONG_INLINE void run(Packet4cf& first, const Packet4cf& second)
-  {
-    if (Offset==0) return;
-    palign_impl<Offset*2,Packet8f>::run(first.v, second.v);
-  }
-};
+  return psqrt_complex<Packet2cf>(a);
+}
 
-template<> struct conj_helper<Packet4cf, Packet4cf, false,true>
+//---------- double ----------
+#ifdef __VSX__
+struct Packet1cd
 {
-  EIGEN_STRONG_INLINE Packet4cf pmadd(const Packet4cf& x, const Packet4cf& y, const Packet4cf& c) const
-  { return padd(pmul(x,y),c); }
+  EIGEN_STRONG_INLINE Packet1cd() {}
+  EIGEN_STRONG_INLINE explicit Packet1cd(const Packet2d& a) : v(a) {}
 
-  EIGEN_STRONG_INLINE Packet4cf pmul(const Packet4cf& a, const Packet4cf& b) const
+  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b)
   {
-    return internal::pmul(a, pconj(b));
-  }
-};
+    Packet2d a_re, a_im, v1, v2;
 
-template<> struct conj_helper<Packet4cf, Packet4cf, true,false>
-{
-  EIGEN_STRONG_INLINE Packet4cf pmadd(const Packet4cf& x, const Packet4cf& y, const Packet4cf& c) const
-  { return padd(pmul(x,y),c); }
+    // Permute and multiply the real parts of a and b
+    a_re = vec_perm(a.v, a.v, p16uc_PSET64_HI);
+    // Get the imaginary parts of a
+    a_im = vec_perm(a.v, a.v, p16uc_PSET64_LO);
+    // multiply a_re * b
+    v1 = vec_madd(a_re, b.v, p2d_ZERO);
+    // multiply a_im * b and get the conjugate result
+    v2 = vec_madd(a_im, b.v, p2d_ZERO);
+    v2 = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4ui>(v2), reinterpret_cast<Packet4ui>(v2), 8));
+    v2 = pxor(v2, reinterpret_cast<Packet2d>(p2ul_CONJ_XOR1));
 
-  EIGEN_STRONG_INLINE Packet4cf pmul(const Packet4cf& a, const Packet4cf& b) const
-  {
-    return internal::pmul(pconj(a), b);
+    return Packet1cd(padd<Packet2d>(v1, v2));
   }
-};
-
-template<> struct conj_helper<Packet4cf, Packet4cf, true,true>
-{
-  EIGEN_STRONG_INLINE Packet4cf pmadd(const Packet4cf& x, const Packet4cf& y, const Packet4cf& c) const
-  { return padd(pmul(x,y),c); }
 
-  EIGEN_STRONG_INLINE Packet4cf pmul(const Packet4cf& a, const Packet4cf& b) const
-  {
-    return pconj(internal::pmul(a, b));
+  EIGEN_STRONG_INLINE Packet1cd& operator*=(const Packet1cd& b) {
+    v = pmul(Packet1cd(*this), b).v;
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet1cd operator*(const Packet1cd& b) const {
+    return Packet1cd(*this) *= b;
   }
-};
-
-EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet4cf,Packet8f)
-
-template<> EIGEN_STRONG_INLINE Packet4cf pdiv<Packet4cf>(const Packet4cf& a, const Packet4cf& b)
-{
-  Packet4cf num = pmul(a, pconj(b));
-  __m256 tmp = _mm256_mul_ps(b.v, b.v);
-  __m256 tmp2    = _mm256_shuffle_ps(tmp,tmp,0xB1);
-  __m256 denom = _mm256_add_ps(tmp, tmp2);
-  return Packet4cf(_mm256_div_ps(num.v, denom));
-}
 
-template<> EIGEN_STRONG_INLINE Packet4cf pcplxflip<Packet4cf>(const Packet4cf& x)
-{
-  return Packet4cf(_mm256_shuffle_ps(x.v, x.v, _MM_SHUFFLE(2, 3, 0 ,1)));
-}
+  EIGEN_STRONG_INLINE Packet1cd& operator+=(const Packet1cd& b) {
+    v = padd(v, b.v);
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet1cd operator+(const Packet1cd& b) const {
+    return Packet1cd(*this) += b;
+  }
+  EIGEN_STRONG_INLINE Packet1cd& operator-=(const Packet1cd& b) {
+    v = psub(v, b.v);
+    return *this;
+  }
+  EIGEN_STRONG_INLINE Packet1cd operator-(const Packet1cd& b) const {
+    return Packet1cd(*this) -= b;
+  }
+  EIGEN_STRONG_INLINE Packet1cd operator-(void) const {
+    return Packet1cd(-v);
+  }
 
-//---------- double ----------
-struct Packet2cd
-{
-  EIGEN_STRONG_INLINE Packet2cd() {}
-  EIGEN_STRONG_INLINE explicit Packet2cd(const __m256d& a) : v(a) {}
-  __m256d  v;
+  Packet2d v;
 };
 
-#ifndef EIGEN_VECTORIZE_AVX512
 template<> struct packet_traits<std::complex<double> >  : default_packet_traits
 {
-  typedef Packet2cd type;
+  typedef Packet1cd type;
   typedef Packet1cd half;
+  typedef Packet2d as_real;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 0,
-    size = 2,
-    HasHalfPacket = 1,
+    size = 1,
+    HasHalfPacket = 0,
 
     HasAdd    = 1,
     HasSub    = 1,
     HasMul    = 1,
     HasDiv    = 1,
     HasNegate = 1,
     HasAbs    = 0,
     HasAbs2   = 0,
     HasMin    = 0,
     HasMax    = 0,
     HasSetLinear = 0
   };
 };
-#endif
-
-template<> struct unpacket_traits<Packet2cd> { typedef std::complex<double> type; enum {size=2, alignment=Aligned32, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet1cd half; };
 
-template<> EIGEN_STRONG_INLINE Packet2cd padd<Packet2cd>(const Packet2cd& a, const Packet2cd& b) { return Packet2cd(_mm256_add_pd(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet2cd psub<Packet2cd>(const Packet2cd& a, const Packet2cd& b) { return Packet2cd(_mm256_sub_pd(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet2cd pnegate(const Packet2cd& a) { return Packet2cd(pnegate(a.v)); }
-template<> EIGEN_STRONG_INLINE Packet2cd pconj(const Packet2cd& a)
-{
-  const __m256d mask = _mm256_castsi256_pd(_mm256_set_epi32(0x80000000,0x0,0x0,0x0,0x80000000,0x0,0x0,0x0));
-  return Packet2cd(_mm256_xor_pd(a.v,mask));
-}
-
-template<> EIGEN_STRONG_INLINE Packet2cd pmul<Packet2cd>(const Packet2cd& a, const Packet2cd& b)
-{
-  __m256d tmp1 = _mm256_shuffle_pd(a.v,a.v,0x0);
-  __m256d even = _mm256_mul_pd(tmp1, b.v);
-  __m256d tmp2 = _mm256_shuffle_pd(a.v,a.v,0xF);
-  __m256d tmp3 = _mm256_shuffle_pd(b.v,b.v,0x5);
-  __m256d odd  = _mm256_mul_pd(tmp2, tmp3);
-  return Packet2cd(_mm256_addsub_pd(even, odd));
-}
-
-template <>
-EIGEN_STRONG_INLINE Packet2cd pcmp_eq(const Packet2cd& a, const Packet2cd& b) {
-  __m256d eq = _mm256_cmp_pd(a.v, b.v, _CMP_EQ_OQ);
-  return Packet2cd(pand(eq, _mm256_permute_pd(eq, 0x5)));
-}
+template<> struct unpacket_traits<Packet1cd> { typedef std::complex<double> type; enum {size=1, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet1cd half; typedef Packet2d as_real; };
 
-template<> EIGEN_STRONG_INLINE Packet2cd ptrue<Packet2cd>(const Packet2cd& a) { return Packet2cd(ptrue(Packet4d(a.v))); }
-template<> EIGEN_STRONG_INLINE Packet2cd pnot<Packet2cd>(const Packet2cd& a) { return Packet2cd(pnot(Packet4d(a.v))); }
-template<> EIGEN_STRONG_INLINE Packet2cd pand   <Packet2cd>(const Packet2cd& a, const Packet2cd& b) { return Packet2cd(_mm256_and_pd(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet2cd por    <Packet2cd>(const Packet2cd& a, const Packet2cd& b) { return Packet2cd(_mm256_or_pd(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet2cd pxor   <Packet2cd>(const Packet2cd& a, const Packet2cd& b) { return Packet2cd(_mm256_xor_pd(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet2cd pandnot<Packet2cd>(const Packet2cd& a, const Packet2cd& b) { return Packet2cd(_mm256_andnot_pd(b.v,a.v)); }
+template<> EIGEN_STRONG_INLINE Packet1cd pload <Packet1cd>(const std::complex<double>* from) { return Packet1cd(pload<Packet2d>((const double*)from)); }
+template<> EIGEN_STRONG_INLINE Packet1cd ploadu<Packet1cd>(const std::complex<double>* from) { return Packet1cd(ploadu<Packet2d>((const double*)from)); }
+template<> EIGEN_STRONG_INLINE void pstore <std::complex<double> >(std::complex<double> *   to, const Packet1cd& from) { pstore((double*)to, from.v); }
+template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<double> >(std::complex<double> *   to, const Packet1cd& from) { pstoreu((double*)to, from.v); }
 
-template<> EIGEN_STRONG_INLINE Packet2cd pload <Packet2cd>(const std::complex<double>* from)
-{ EIGEN_DEBUG_ALIGNED_LOAD return Packet2cd(pload<Packet4d>((const double*)from)); }
-template<> EIGEN_STRONG_INLINE Packet2cd ploadu<Packet2cd>(const std::complex<double>* from)
-{ EIGEN_DEBUG_UNALIGNED_LOAD return Packet2cd(ploadu<Packet4d>((const double*)from)); }
+template<> EIGEN_STRONG_INLINE Packet1cd pset1<Packet1cd>(const std::complex<double>&  from)
+{ /* here we really have to use unaligned loads :( */ return ploadu<Packet1cd>(&from); }
 
-template<> EIGEN_STRONG_INLINE Packet2cd pset1<Packet2cd>(const std::complex<double>& from)
+template<> EIGEN_DEVICE_FUNC inline Packet1cd pgather<std::complex<double>, Packet1cd>(const std::complex<double>* from, Index)
 {
-  // in case casting to a __m128d* is really not safe, then we can still fallback to this version: (much slower though)
-//   return Packet2cd(_mm256_loadu2_m128d((const double*)&from,(const double*)&from));
-    return Packet2cd(_mm256_broadcast_pd((const __m128d*)(const void*)&from));
+  return pload<Packet1cd>(from);
 }
-
-template<> EIGEN_STRONG_INLINE Packet2cd ploaddup<Packet2cd>(const std::complex<double>* from) { return pset1<Packet2cd>(*from); }
-
-template<> EIGEN_STRONG_INLINE void pstore <std::complex<double> >(std::complex<double> *   to, const Packet2cd& from) { EIGEN_DEBUG_ALIGNED_STORE pstore((double*)to, from.v); }
-template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<double> >(std::complex<double> *   to, const Packet2cd& from) { EIGEN_DEBUG_UNALIGNED_STORE pstoreu((double*)to, from.v); }
-
-template<> EIGEN_DEVICE_FUNC inline Packet2cd pgather<std::complex<double>, Packet2cd>(const std::complex<double>* from, Index stride)
+template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<double>, Packet1cd>(std::complex<double>* to, const Packet1cd& from, Index)
 {
-  return Packet2cd(_mm256_set_pd(std::imag(from[1*stride]), std::real(from[1*stride]),
-				 std::imag(from[0*stride]), std::real(from[0*stride])));
+  pstore<std::complex<double> >(to, from);
 }
 
-template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<double>, Packet2cd>(std::complex<double>* to, const Packet2cd& from, Index stride)
-{
-  __m128d low = _mm256_extractf128_pd(from.v, 0);
-  to[stride*0] = std::complex<double>(_mm_cvtsd_f64(low), _mm_cvtsd_f64(_mm_shuffle_pd(low, low, 1)));
-  __m128d high = _mm256_extractf128_pd(from.v, 1);
-  to[stride*1] = std::complex<double>(_mm_cvtsd_f64(high), _mm_cvtsd_f64(_mm_shuffle_pd(high, high, 1)));
-}
+template<> EIGEN_STRONG_INLINE Packet1cd padd<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(a.v + b.v); }
+template<> EIGEN_STRONG_INLINE Packet1cd psub<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(a.v - b.v); }
+template<> EIGEN_STRONG_INLINE Packet1cd pnegate(const Packet1cd& a) { return Packet1cd(pnegate(Packet2d(a.v))); }
+template<> EIGEN_STRONG_INLINE Packet1cd pconj(const Packet1cd& a) { return Packet1cd(pxor(a.v, reinterpret_cast<Packet2d>(p2ul_CONJ_XOR2))); }
 
-template<> EIGEN_STRONG_INLINE std::complex<double> pfirst<Packet2cd>(const Packet2cd& a)
-{
-  __m128d low = _mm256_extractf128_pd(a.v, 0);
-  EIGEN_ALIGN16 double res[2];
-  _mm_store_pd(res, low);
-  return std::complex<double>(res[0],res[1]);
-}
+template<> EIGEN_STRONG_INLINE Packet1cd pand   <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(pand(a.v,b.v)); }
+template<> EIGEN_STRONG_INLINE Packet1cd por    <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(por(a.v,b.v)); }
+template<> EIGEN_STRONG_INLINE Packet1cd pxor   <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(pxor(a.v,b.v)); }
+template<> EIGEN_STRONG_INLINE Packet1cd pandnot<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(pandnot(a.v, b.v)); }
 
-template<> EIGEN_STRONG_INLINE Packet2cd preverse(const Packet2cd& a) {
-  __m256d result = _mm256_permute2f128_pd(a.v, a.v, 1);
-  return Packet2cd(result);
-}
+template<> EIGEN_STRONG_INLINE Packet1cd ploaddup<Packet1cd>(const std::complex<double>*     from)  { return pset1<Packet1cd>(*from); }
 
-template<> EIGEN_STRONG_INLINE std::complex<double> predux<Packet2cd>(const Packet2cd& a)
-{
-  return predux(padd(Packet1cd(_mm256_extractf128_pd(a.v,0)),
-                     Packet1cd(_mm256_extractf128_pd(a.v,1))));
-}
+template<> EIGEN_STRONG_INLINE void prefetch<std::complex<double> >(const std::complex<double> * addr)    { EIGEN_PPC_PREFETCH(addr); }
 
-template<> EIGEN_STRONG_INLINE Packet2cd preduxp<Packet2cd>(const Packet2cd* vecs)
+template<> EIGEN_STRONG_INLINE std::complex<double>  pfirst<Packet1cd>(const Packet1cd& a)
 {
-  Packet4d t0 = _mm256_permute2f128_pd(vecs[0].v,vecs[1].v, 0 + (2<<4));
-  Packet4d t1 = _mm256_permute2f128_pd(vecs[0].v,vecs[1].v, 1 + (3<<4));
+  EIGEN_ALIGN16 std::complex<double> res[2];
+  pstore<std::complex<double> >(res, a);
 
-  return Packet2cd(_mm256_add_pd(t0,t1));
+  return res[0];
 }
 
-template<> EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet2cd>(const Packet2cd& a)
-{
-  return predux(pmul(Packet1cd(_mm256_extractf128_pd(a.v,0)),
-                     Packet1cd(_mm256_extractf128_pd(a.v,1))));
-}
-
-template<int Offset>
-struct palign_impl<Offset,Packet2cd>
-{
-  static EIGEN_STRONG_INLINE void run(Packet2cd& first, const Packet2cd& second)
-  {
-    if (Offset==0) return;
-    palign_impl<Offset*2,Packet4d>::run(first.v, second.v);
-  }
-};
-
-template<> struct conj_helper<Packet2cd, Packet2cd, false,true>
-{
-  EIGEN_STRONG_INLINE Packet2cd pmadd(const Packet2cd& x, const Packet2cd& y, const Packet2cd& c) const
-  { return padd(pmul(x,y),c); }
+template<> EIGEN_STRONG_INLINE Packet1cd preverse(const Packet1cd& a) { return a; }
 
-  EIGEN_STRONG_INLINE Packet2cd pmul(const Packet2cd& a, const Packet2cd& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
+template<> EIGEN_STRONG_INLINE std::complex<double> predux<Packet1cd>(const Packet1cd& a) { return pfirst(a); }
 
-template<> struct conj_helper<Packet2cd, Packet2cd, true,false>
-{
-  EIGEN_STRONG_INLINE Packet2cd pmadd(const Packet2cd& x, const Packet2cd& y, const Packet2cd& c) const
-  { return padd(pmul(x,y),c); }
+template<> EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet1cd>(const Packet1cd& a) { return pfirst(a); }
 
-  EIGEN_STRONG_INLINE Packet2cd pmul(const Packet2cd& a, const Packet2cd& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
+EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cd,Packet2d)
 
-template<> struct conj_helper<Packet2cd, Packet2cd, true,true>
+template<> EIGEN_STRONG_INLINE Packet1cd pdiv<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
 {
-  EIGEN_STRONG_INLINE Packet2cd pmadd(const Packet2cd& x, const Packet2cd& y, const Packet2cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cd pmul(const Packet2cd& a, const Packet2cd& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
-EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cd,Packet4d)
-
-template<> EIGEN_STRONG_INLINE Packet2cd pdiv<Packet2cd>(const Packet2cd& a, const Packet2cd& b)
-{
-  Packet2cd num = pmul(a, pconj(b));
-  __m256d tmp = _mm256_mul_pd(b.v, b.v);
-  __m256d denom = _mm256_hadd_pd(tmp, tmp);
-  return Packet2cd(_mm256_div_pd(num.v, denom));
-}
-
-template<> EIGEN_STRONG_INLINE Packet2cd pcplxflip<Packet2cd>(const Packet2cd& x)
-{
-  return Packet2cd(_mm256_shuffle_pd(x.v, x.v, 0x5));
+  // TODO optimize it for AltiVec
+  Packet1cd res = pmul(a,pconj(b));
+  Packet2d s = pmul<Packet2d>(b.v, b.v);
+  return Packet1cd(pdiv(res.v, padd<Packet2d>(s, vec_perm(s, s, p16uc_REVERSE64))));
 }
 
-EIGEN_DEVICE_FUNC inline void
-ptranspose(PacketBlock<Packet4cf,4>& kernel) {
-  __m256d P0 = _mm256_castps_pd(kernel.packet[0].v);
-  __m256d P1 = _mm256_castps_pd(kernel.packet[1].v);
-  __m256d P2 = _mm256_castps_pd(kernel.packet[2].v);
-  __m256d P3 = _mm256_castps_pd(kernel.packet[3].v);
-
-  __m256d T0 = _mm256_shuffle_pd(P0, P1, 15);
-  __m256d T1 = _mm256_shuffle_pd(P0, P1, 0);
-  __m256d T2 = _mm256_shuffle_pd(P2, P3, 15);
-  __m256d T3 = _mm256_shuffle_pd(P2, P3, 0);
-
-  kernel.packet[1].v = _mm256_castpd_ps(_mm256_permute2f128_pd(T0, T2, 32));
-  kernel.packet[3].v = _mm256_castpd_ps(_mm256_permute2f128_pd(T0, T2, 49));
-  kernel.packet[0].v = _mm256_castpd_ps(_mm256_permute2f128_pd(T1, T3, 32));
-  kernel.packet[2].v = _mm256_castpd_ps(_mm256_permute2f128_pd(T1, T3, 49));
-}
-
-EIGEN_DEVICE_FUNC inline void
-ptranspose(PacketBlock<Packet2cd,2>& kernel) {
-  __m256d tmp = _mm256_permute2f128_pd(kernel.packet[0].v, kernel.packet[1].v, 0+(2<<4));
-  kernel.packet[1].v = _mm256_permute2f128_pd(kernel.packet[0].v, kernel.packet[1].v, 1+(3<<4));
- kernel.packet[0].v = tmp;
-}
-
-template<> EIGEN_STRONG_INLINE Packet4cf pinsertfirst(const Packet4cf& a, std::complex<float> b)
+EIGEN_STRONG_INLINE Packet1cd pcplxflip/*<Packet1cd>*/(const Packet1cd& x)
 {
-  return Packet4cf(_mm256_blend_ps(a.v,pset1<Packet4cf>(b).v,1|2));
+  return Packet1cd(preverse(Packet2d(x.v)));
 }
 
-template<> EIGEN_STRONG_INLINE Packet2cd pinsertfirst(const Packet2cd& a, std::complex<double> b)
+EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet1cd,2>& kernel)
 {
-  return Packet2cd(_mm256_blend_pd(a.v,pset1<Packet2cd>(b).v,1|2));
+  Packet2d tmp = vec_perm(kernel.packet[0].v, kernel.packet[1].v, p16uc_TRANSPOSE64_HI);
+  kernel.packet[1].v = vec_perm(kernel.packet[0].v, kernel.packet[1].v, p16uc_TRANSPOSE64_LO);
+  kernel.packet[0].v = tmp;
 }
 
-template<> EIGEN_STRONG_INLINE Packet4cf pinsertlast(const Packet4cf& a, std::complex<float> b)
-{
-  return Packet4cf(_mm256_blend_ps(a.v,pset1<Packet4cf>(b).v,(1<<7)|(1<<6)));
+template<> EIGEN_STRONG_INLINE Packet1cd pcmp_eq(const Packet1cd& a, const Packet1cd& b) {
+  // Compare real and imaginary parts of a and b to get the mask vector:
+  // [re(a)==re(b), im(a)==im(b)]
+  Packet2d eq = reinterpret_cast<Packet2d>(vec_cmpeq(a.v,b.v));
+  // Swap real/imag elements in the mask in to get:
+  // [im(a)==im(b), re(a)==re(b)]
+  Packet2d eq_swapped = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4ui>(eq), reinterpret_cast<Packet4ui>(eq), 8));
+  // Return re(a)==re(b) & im(a)==im(b) by computing bitwise AND of eq and eq_swapped
+  return Packet1cd(vec_and(eq, eq_swapped));
 }
 
-template<> EIGEN_STRONG_INLINE Packet2cd pinsertlast(const Packet2cd& a, std::complex<double> b)
+template<> EIGEN_STRONG_INLINE Packet1cd psqrt<Packet1cd>(const Packet1cd& a)
 {
-  return Packet2cd(_mm256_blend_pd(a.v,pset1<Packet2cd>(b).v,(1<<3)|(1<<2)));
+  return psqrt_complex<Packet1cd>(a);
 }
 
+#endif // __VSX__
 } // end namespace internal
 
 } // end namespace Eigen
 
-#endif // EIGEN_COMPLEX_AVX_H
+#endif // EIGEN_COMPLEX32_ALTIVEC_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX/MathFunctions.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SSE/MathFunctions.h`

 * *Files 27% similar despite different names*

```diff
@@ -1,145 +1,199 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
-// Copyright (C) 2014 Pedro Gonnet (pedro.gonnet@gmail.com)
+// Copyright (C) 2007 Julien Pommier
+// Copyright (C) 2009 Gael Guennebaud <gael.guennebaud@inria.fr>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
-#ifndef EIGEN_MATH_FUNCTIONS_AVX_H
-#define EIGEN_MATH_FUNCTIONS_AVX_H
-
-/* The sin and cos functions of this file are loosely derived from
+/* The sin and cos and functions of this file come from
  * Julien Pommier's sse math library: http://gruntthepeon.free.fr/ssemath/
  */
 
+#ifndef EIGEN_MATH_FUNCTIONS_SSE_H
+#define EIGEN_MATH_FUNCTIONS_SSE_H
+
 namespace Eigen {
 
 namespace internal {
 
-template <>
-EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8f
-psin<Packet8f>(const Packet8f& _x) {
-  return psin_float(_x);
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f plog<Packet4f>(const Packet4f& _x) {
+  return plog_float(_x);
 }
 
-template <>
-EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8f
-pcos<Packet8f>(const Packet8f& _x) {
-  return pcos_float(_x);
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet2d plog<Packet2d>(const Packet2d& _x) {
+  return plog_double(_x);
 }
 
-template <>
-EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8f
-plog<Packet8f>(const Packet8f& _x) {
-  return plog_float(_x);
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f plog2<Packet4f>(const Packet4f& _x) {
+  return plog2_float(_x);
 }
 
-// Exponential function. Works by writing "x = m*log(2) + r" where
-// "m = floor(x/log(2)+1/2)" and "r" is the remainder. The result is then
-// "exp(x) = 2^m*exp(r)" where exp(r) is in the range [-1,1).
-template <>
-EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8f
-pexp<Packet8f>(const Packet8f& _x) {
-  return pexp_float(_x);
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet2d plog2<Packet2d>(const Packet2d& _x) {
+  return plog2_double(_x);
 }
 
-// Hyperbolic Tangent function.
-template <>
-EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8f
-ptanh<Packet8f>(const Packet8f& x) {
-  return internal::generic_fast_tanh_float(x);
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f plog1p<Packet4f>(const Packet4f& _x) {
+  return generic_plog1p(_x);
 }
 
-template <>
-EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet4d
-pexp<Packet4d>(const Packet4d& x) {
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f pexpm1<Packet4f>(const Packet4f& _x) {
+  return generic_expm1(_x);
+}
+
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f pexp<Packet4f>(const Packet4f& _x)
+{
+  return pexp_float(_x);
+}
+
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet2d pexp<Packet2d>(const Packet2d& x)
+{
   return pexp_double(x);
 }
 
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f psin<Packet4f>(const Packet4f& _x)
+{
+  return psin_float(_x);
+}
+
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f pcos<Packet4f>(const Packet4f& _x)
+{
+  return pcos_float(_x);
+}
+
+#if EIGEN_FAST_MATH
+
 // Functions for sqrt.
 // The EIGEN_FAST_MATH version uses the _mm_rsqrt_ps approximation and one step
 // of Newton's method, at a cost of 1-2 bits of precision as opposed to the
 // exact solution. It does not handle +inf, or denormalized numbers correctly.
 // The main advantage of this approach is not just speed, but also the fact that
 // it can be inlined and pipelined with other computations, further reducing its
 // effective latency. This is similar to Quake3's fast inverse square root.
 // For detail see here: http://www.beyond3d.com/content/articles/8/
-#if EIGEN_FAST_MATH
-template <>
-EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8f
-psqrt<Packet8f>(const Packet8f& _x) {
-  Packet8f half = pmul(_x, pset1<Packet8f>(.5f));
-  Packet8f denormal_mask = _mm256_and_ps(
-      _mm256_cmp_ps(_x, pset1<Packet8f>((std::numeric_limits<float>::min)()),
-                    _CMP_LT_OQ),
-      _mm256_cmp_ps(_x, _mm256_setzero_ps(), _CMP_GE_OQ));
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f psqrt<Packet4f>(const Packet4f& _x)
+{
+  Packet4f minus_half_x = pmul(_x, pset1<Packet4f>(-0.5f));
+  Packet4f denormal_mask = pandnot(
+      pcmp_lt(_x, pset1<Packet4f>((std::numeric_limits<float>::min)())),
+      pcmp_lt(_x, pzero(_x)));
 
   // Compute approximate reciprocal sqrt.
-  Packet8f x = _mm256_rsqrt_ps(_x);
+  Packet4f x = _mm_rsqrt_ps(_x);
   // Do a single step of Newton's iteration.
-  x = pmul(x, psub(pset1<Packet8f>(1.5f), pmul(half, pmul(x,x))));
+  x = pmul(x, pmadd(minus_half_x, pmul(x,x), pset1<Packet4f>(1.5f)));
   // Flush results for denormals to zero.
-  return _mm256_andnot_ps(denormal_mask, pmul(_x,x));
+  return pandnot(pmul(_x,x), denormal_mask);
 }
+
 #else
-template <> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
-Packet8f psqrt<Packet8f>(const Packet8f& x) {
-  return _mm256_sqrt_ps(x);
-}
+
+template<>EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f psqrt<Packet4f>(const Packet4f& x) { return _mm_sqrt_ps(x); }
+
 #endif
-template <> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
-Packet4d psqrt<Packet4d>(const Packet4d& x) {
-  return _mm256_sqrt_pd(x);
-}
-#if EIGEN_FAST_MATH
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
-Packet8f prsqrt<Packet8f>(const Packet8f& _x) {
-  _EIGEN_DECLARE_CONST_Packet8f_FROM_INT(inf, 0x7f800000);
-  _EIGEN_DECLARE_CONST_Packet8f_FROM_INT(nan, 0x7fc00000);
-  _EIGEN_DECLARE_CONST_Packet8f(one_point_five, 1.5f);
-  _EIGEN_DECLARE_CONST_Packet8f(minus_half, -0.5f);
-  _EIGEN_DECLARE_CONST_Packet8f_FROM_INT(flt_min, 0x00800000);
-
-  Packet8f neg_half = pmul(_x, p8f_minus_half);
-
-  // select only the inverse sqrt of positive normal inputs (denormals are
-  // flushed to zero and cause infs as well).
-  Packet8f le_zero_mask = _mm256_cmp_ps(_x, p8f_flt_min, _CMP_LT_OQ);
-  Packet8f x = _mm256_andnot_ps(le_zero_mask, _mm256_rsqrt_ps(_x));
-
-  // Fill in NaNs and Infs for the negative/zero entries.
-  Packet8f neg_mask = _mm256_cmp_ps(_x, _mm256_setzero_ps(), _CMP_LT_OQ);
-  Packet8f zero_mask = _mm256_andnot_ps(neg_mask, le_zero_mask);
-  Packet8f infs_and_nans = _mm256_or_ps(_mm256_and_ps(neg_mask, p8f_nan),
-                                        _mm256_and_ps(zero_mask, p8f_inf));
+Packet2d psqrt<Packet2d>(const Packet2d& x) { return _mm_sqrt_pd(x); }
 
-  // Do a single step of Newton's iteration.
-  x = pmul(x, pmadd(neg_half, pmul(x, x), p8f_one_point_five));
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet16b psqrt<Packet16b>(const Packet16b& x) { return x; }
 
-  // Insert NaNs and Infs in all the right places.
-  return _mm256_or_ps(x, infs_and_nans);
+#if EIGEN_FAST_MATH
+
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f prsqrt<Packet4f>(const Packet4f& _x) {
+  _EIGEN_DECLARE_CONST_Packet4f(one_point_five, 1.5f);
+  _EIGEN_DECLARE_CONST_Packet4f(minus_half, -0.5f);
+  _EIGEN_DECLARE_CONST_Packet4f_FROM_INT(inf, 0x7f800000u);
+  _EIGEN_DECLARE_CONST_Packet4f_FROM_INT(flt_min, 0x00800000u);
+
+  Packet4f neg_half = pmul(_x, p4f_minus_half);
+
+  // Identity infinite, zero, negative and denormal arguments.
+  Packet4f lt_min_mask = _mm_cmplt_ps(_x, p4f_flt_min);
+  Packet4f inf_mask = _mm_cmpeq_ps(_x, p4f_inf);
+  Packet4f not_normal_finite_mask = _mm_or_ps(lt_min_mask, inf_mask);
+
+  // Compute an approximate result using the rsqrt intrinsic.
+  Packet4f y_approx = _mm_rsqrt_ps(_x);
+
+  // Do a single step of Newton-Raphson iteration to improve the approximation.
+  // This uses the formula y_{n+1} = y_n * (1.5 - y_n * (0.5 * x) * y_n).
+  // It is essential to evaluate the inner term like this because forming
+  // y_n^2 may over- or underflow.
+  Packet4f y_newton = pmul(
+      y_approx, pmadd(y_approx, pmul(neg_half, y_approx), p4f_one_point_five));
+
+  // Select the result of the Newton-Raphson step for positive normal arguments.
+  // For other arguments, choose the output of the intrinsic. This will
+  // return rsqrt(+inf) = 0, rsqrt(x) = NaN if x < 0, and rsqrt(x) = +inf if
+  // x is zero or a positive denormalized float (equivalent to flushing positive
+  // denormalized inputs to zero).
+  return pselect<Packet4f>(not_normal_finite_mask, y_approx, y_newton);
 }
 
 #else
-template <> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
-Packet8f prsqrt<Packet8f>(const Packet8f& x) {
-  _EIGEN_DECLARE_CONST_Packet8f(one, 1.0f);
-  return _mm256_div_ps(p8f_one, _mm256_sqrt_ps(x));
+
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet4f prsqrt<Packet4f>(const Packet4f& x) {
+  // Unfortunately we can't use the much faster mm_rsqrt_ps since it only provides an approximation.
+  return _mm_div_ps(pset1<Packet4f>(1.0f), _mm_sqrt_ps(x));
 }
+
 #endif
 
-template <> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
-Packet4d prsqrt<Packet4d>(const Packet4d& x) {
-  _EIGEN_DECLARE_CONST_Packet4d(one, 1.0);
-  return _mm256_div_pd(p4d_one, _mm256_sqrt_pd(x));
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet2d prsqrt<Packet2d>(const Packet2d& x) {
+  return _mm_div_pd(pset1<Packet2d>(1.0), _mm_sqrt_pd(x));
+}
+
+// Hyperbolic Tangent function.
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet4f
+ptanh<Packet4f>(const Packet4f& x) {
+  return internal::generic_fast_tanh_float(x);
 }
 
+} // end namespace internal
+
+namespace numext {
+
+template<>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
+float sqrt(const float &x)
+{
+  return internal::pfirst(internal::Packet4f(_mm_sqrt_ss(_mm_set_ss(x))));
+}
+
+template<>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE
+double sqrt(const double &x)
+{
+#if EIGEN_COMP_GNUC_STRICT
+  // This works around a GCC bug generating poor code for _mm_sqrt_pd
+  // See https://gitlab.com/libeigen/eigen/commit/8dca9f97e38970
+  return internal::pfirst(internal::Packet2d(__builtin_ia32_sqrtsd(_mm_set_sd(x))));
+#else
+  return internal::pfirst(internal::Packet2d(_mm_sqrt_pd(_mm_set_sd(x))));
+#endif
+}
 
-}  // end namespace internal
+} // end namespace numex
 
-}  // end namespace Eigen
+} // end namespace Eigen
 
-#endif  // EIGEN_MATH_FUNCTIONS_AVX_H
+#endif // EIGEN_MATH_FUNCTIONS_SSE_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX/PacketMath.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/ZVector/PacketMath.h`

 * *Files 23% similar despite different names*

```diff
@@ -1,852 +1,1060 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
-// Copyright (C) 2014 Benoit Steiner (benoit.steiner.goog@gmail.com)
+// Copyright (C) 2016 Konstantinos Margaritis <markos@freevec.org>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
-#ifndef EIGEN_PACKET_MATH_AVX_H
-#define EIGEN_PACKET_MATH_AVX_H
+#ifndef EIGEN_PACKET_MATH_ZVECTOR_H
+#define EIGEN_PACKET_MATH_ZVECTOR_H
 
 namespace Eigen {
 
 namespace internal {
 
 #ifndef EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD
-#define EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD 8
+#define EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD 16
 #endif
 
-#if !defined(EIGEN_VECTORIZE_AVX512) && !defined(EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS)
-#define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS 16
-#endif
-
-#ifdef EIGEN_VECTORIZE_FMA
 #ifndef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #define EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #endif
+
+#ifndef EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS
+#define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS  32
+#endif
+
+typedef __vector int                 Packet4i;
+typedef __vector unsigned int        Packet4ui;
+typedef __vector __bool int          Packet4bi;
+typedef __vector short int           Packet8i;
+typedef __vector unsigned char       Packet16uc;
+typedef __vector double              Packet2d;
+typedef __vector unsigned long long  Packet2ul;
+typedef __vector long long           Packet2l;
+
+// Z14 has builtin support for float vectors
+#if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ >= 12)
+typedef __vector float               Packet4f;
+#else
+typedef struct {
+	Packet2d  v4f[2];
+} Packet4f;
+#endif
+
+typedef union {
+  numext::int32_t   i[4];
+  numext::uint32_t ui[4];
+  numext::int64_t   l[2];
+  numext::uint64_t ul[2];
+  double    d[2];
+  float     f[4];
+  Packet4i  v4i;
+  Packet4ui v4ui;
+  Packet2l  v2l;
+  Packet2ul v2ul;
+  Packet2d  v2d;
+#if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ >= 12)
+  Packet4f  v4f;
+#endif
+} Packet;
+
+// We don't want to write the same code all the time, but we need to reuse the constants
+// and it doesn't really work to declare them global, so we define macros instead
+
+#define _EIGEN_DECLARE_CONST_FAST_Packet4i(NAME,X) \
+  Packet4i p4i_##NAME = reinterpret_cast<Packet4i>(vec_splat_s32(X))
+
+#define _EIGEN_DECLARE_CONST_FAST_Packet2d(NAME,X) \
+  Packet2d p2d_##NAME = reinterpret_cast<Packet2d>(vec_splat_s64(X))
+
+#define _EIGEN_DECLARE_CONST_FAST_Packet2l(NAME,X) \
+  Packet2l p2l_##NAME = reinterpret_cast<Packet2l>(vec_splat_s64(X))
+
+#define _EIGEN_DECLARE_CONST_Packet4i(NAME,X) \
+  Packet4i p4i_##NAME = pset1<Packet4i>(X)
+
+#define _EIGEN_DECLARE_CONST_Packet2d(NAME,X) \
+  Packet2d p2d_##NAME = pset1<Packet2d>(X)
+
+#define _EIGEN_DECLARE_CONST_Packet2l(NAME,X) \
+  Packet2l p2l_##NAME = pset1<Packet2l>(X)
+
+// These constants are endian-agnostic
+static _EIGEN_DECLARE_CONST_FAST_Packet4i(ZERO, 0); //{ 0, 0, 0, 0,}
+static _EIGEN_DECLARE_CONST_FAST_Packet4i(ONE, 1); //{ 1, 1, 1, 1}
+
+static _EIGEN_DECLARE_CONST_FAST_Packet2d(ZERO, 0);
+static _EIGEN_DECLARE_CONST_FAST_Packet2l(ZERO, 0);
+static _EIGEN_DECLARE_CONST_FAST_Packet2l(ONE, 1);
+
+static Packet2d p2d_ONE = { 1.0, 1.0 };
+static Packet2d p2d_ZERO_ = { numext::bit_cast<double>(0x8000000000000000ull),
+                              numext::bit_cast<double>(0x8000000000000000ull) };
+
+#if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ >= 12)
+#define _EIGEN_DECLARE_CONST_FAST_Packet4f(NAME,X) \
+  Packet4f p4f_##NAME = reinterpret_cast<Packet4f>(vec_splat_s32(X))
+
+#define _EIGEN_DECLARE_CONST_Packet4f(NAME,X) \
+  Packet4f p4f_##NAME = pset1<Packet4f>(X)
+
+#define _EIGEN_DECLARE_CONST_Packet4f_FROM_INT(NAME,X) \
+  const Packet4f p4f_##NAME = reinterpret_cast<Packet4f>(pset1<Packet4i>(X))
+
+static _EIGEN_DECLARE_CONST_FAST_Packet4f(ZERO, 0); //{ 0.0, 0.0, 0.0, 0.0}
+static _EIGEN_DECLARE_CONST_FAST_Packet4i(MINUS1,-1); //{ -1, -1, -1, -1}
+static Packet4f p4f_MZERO = { 0x80000000, 0x80000000, 0x80000000, 0x80000000};
 #endif
 
-typedef __m256  Packet8f;
-typedef __m256i Packet8i;
-typedef __m256d Packet4d;
+static Packet4i p4i_COUNTDOWN = { 0, 1, 2, 3 };
+static Packet4f p4f_COUNTDOWN = { 0.0, 1.0, 2.0, 3.0 };
+static Packet2d p2d_COUNTDOWN = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet16uc>(p2d_ZERO), reinterpret_cast<Packet16uc>(p2d_ONE), 8));
 
-template<> struct is_arithmetic<__m256>  { enum { value = true }; };
-template<> struct is_arithmetic<__m256i> { enum { value = true }; };
-template<> struct is_arithmetic<__m256d> { enum { value = true }; };
+static Packet16uc p16uc_PSET64_HI = { 0,1,2,3, 4,5,6,7, 0,1,2,3, 4,5,6,7 };
+static Packet16uc p16uc_DUPLICATE32_HI = { 0,1,2,3, 0,1,2,3, 4,5,6,7, 4,5,6,7 };
 
-#define _EIGEN_DECLARE_CONST_Packet8f(NAME,X) \
-  const Packet8f p8f_##NAME = pset1<Packet8f>(X)
+// Mask alignment
+#define _EIGEN_MASK_ALIGNMENT	0xfffffffffffffff0
 
-#define _EIGEN_DECLARE_CONST_Packet4d(NAME,X) \
-  const Packet4d p4d_##NAME = pset1<Packet4d>(X)
+#define _EIGEN_ALIGNED_PTR(x)	((std::ptrdiff_t)(x) & _EIGEN_MASK_ALIGNMENT)
 
-#define _EIGEN_DECLARE_CONST_Packet8f_FROM_INT(NAME,X) \
-  const Packet8f p8f_##NAME = _mm256_castsi256_ps(pset1<Packet8i>(X))
+// Handle endianness properly while loading constants
+// Define global static constants:
 
-#define _EIGEN_DECLARE_CONST_Packet8i(NAME,X) \
-  const Packet8i p8i_##NAME = pset1<Packet8i>(X)
+static Packet16uc p16uc_FORWARD =   { 0,1,2,3, 4,5,6,7, 8,9,10,11, 12,13,14,15 };
+static Packet16uc p16uc_REVERSE32 = { 12,13,14,15, 8,9,10,11, 4,5,6,7, 0,1,2,3 };
+static Packet16uc p16uc_REVERSE64 = { 8,9,10,11, 12,13,14,15, 0,1,2,3, 4,5,6,7 };
+
+static Packet16uc p16uc_PSET32_WODD   = vec_sld((Packet16uc) vec_splat((Packet4ui)p16uc_FORWARD, 0), (Packet16uc) vec_splat((Packet4ui)p16uc_FORWARD, 2), 8);//{ 0,1,2,3, 0,1,2,3, 8,9,10,11, 8,9,10,11 };
+static Packet16uc p16uc_PSET32_WEVEN  = vec_sld(p16uc_DUPLICATE32_HI, (Packet16uc) vec_splat((Packet4ui)p16uc_FORWARD, 3), 8);//{ 4,5,6,7, 4,5,6,7, 12,13,14,15, 12,13,14,15 };
+/*static Packet16uc p16uc_HALF64_0_16 = vec_sld((Packet16uc)p4i_ZERO, vec_splat((Packet16uc) vec_abs(p4i_MINUS16), 3), 8);      //{ 0,0,0,0, 0,0,0,0, 16,16,16,16, 16,16,16,16};
+
+static Packet16uc p16uc_PSET64_HI = (Packet16uc) vec_mergeh((Packet4ui)p16uc_PSET32_WODD, (Packet4ui)p16uc_PSET32_WEVEN);     //{ 0,1,2,3, 4,5,6,7, 0,1,2,3, 4,5,6,7 };*/
+static Packet16uc p16uc_PSET64_LO = (Packet16uc) vec_mergel((Packet4ui)p16uc_PSET32_WODD, (Packet4ui)p16uc_PSET32_WEVEN);     //{ 8,9,10,11, 12,13,14,15, 8,9,10,11, 12,13,14,15 };
+/*static Packet16uc p16uc_TRANSPOSE64_HI = vec_add(p16uc_PSET64_HI, p16uc_HALF64_0_16);                                         //{ 0,1,2,3, 4,5,6,7, 16,17,18,19, 20,21,22,23};
+static Packet16uc p16uc_TRANSPOSE64_LO = vec_add(p16uc_PSET64_LO, p16uc_HALF64_0_16);                                         //{ 8,9,10,11, 12,13,14,15, 24,25,26,27, 28,29,30,31};*/
+static Packet16uc p16uc_TRANSPOSE64_HI = { 0,1,2,3, 4,5,6,7, 16,17,18,19, 20,21,22,23};
+static Packet16uc p16uc_TRANSPOSE64_LO = { 8,9,10,11, 12,13,14,15, 24,25,26,27, 28,29,30,31};
+
+static Packet16uc p16uc_COMPLEX32_REV = vec_sld(p16uc_REVERSE32, p16uc_REVERSE32, 8);                                         //{ 4,5,6,7, 0,1,2,3, 12,13,14,15, 8,9,10,11 };
+
+static Packet16uc p16uc_COMPLEX32_REV2 = vec_sld(p16uc_FORWARD, p16uc_FORWARD, 8);                                            //{ 8,9,10,11, 12,13,14,15, 0,1,2,3, 4,5,6,7 };
+
+
+#if EIGEN_HAS_BUILTIN(__builtin_prefetch) || EIGEN_COMP_GNUC
+  #define EIGEN_ZVECTOR_PREFETCH(ADDR) __builtin_prefetch(ADDR);
+#else
+  #define EIGEN_ZVECTOR_PREFETCH(ADDR) asm( "   pfd [%[addr]]\n" :: [addr] "r" (ADDR) : "cc" );
+#endif
 
-// Use the packet_traits defined in AVX512/PacketMath.h instead if we're going
-// to leverage AVX512 instructions.
-#ifndef EIGEN_VECTORIZE_AVX512
-template<> struct packet_traits<float>  : default_packet_traits
+template<> struct packet_traits<int>    : default_packet_traits
 {
-  typedef Packet8f type;
-  typedef Packet4f half;
+  typedef Packet4i type;
+  typedef Packet4i half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
-    size=8,
-    HasHalfPacket = 1,
+    size = 4,
+    HasHalfPacket = 0,
 
+    HasAdd  = 1,
+    HasSub  = 1,
+    HasMul  = 1,
     HasDiv  = 1,
-    HasSin  = EIGEN_FAST_MATH,
-    HasCos  = EIGEN_FAST_MATH,
-    HasLog  = 1,
-    HasExp  = 1,
+    HasBlend = 1
+  };
+};
+
+template <>
+struct packet_traits<float> : default_packet_traits {
+  typedef Packet4f type;
+  typedef Packet4f half;
+  enum {
+    Vectorizable = 1,
+    AlignedOnScalar = 1,
+    size = 4,
+    HasHalfPacket = 0,
+
+    HasAdd = 1,
+    HasSub = 1,
+    HasMul = 1,
+    HasDiv = 1,
+    HasMin = 1,
+    HasMax = 1,
+    HasAbs = 1,
+    HasSin = 0,
+    HasCos = 0,
+    HasLog = 0,
+    HasExp = 1,
     HasSqrt = 1,
     HasRsqrt = 1,
-    HasTanh  = EIGEN_FAST_MATH,
-    HasBlend = 1,
+    HasTanh = 1,
+    HasErf = 1,
     HasRound = 1,
     HasFloor = 1,
-    HasCeil = 1
+    HasCeil = 1,
+    HasNegate = 1,
+    HasBlend = 1
   };
 };
+
 template<> struct packet_traits<double> : default_packet_traits
 {
-  typedef Packet4d type;
+  typedef Packet2d type;
   typedef Packet2d half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
-    size=4,
+    size=2,
     HasHalfPacket = 1,
 
+    HasAdd  = 1,
+    HasSub  = 1,
+    HasMul  = 1,
     HasDiv  = 1,
+    HasMin  = 1,
+    HasMax  = 1,
+    HasAbs  = 1,
+    HasSin  = 0,
+    HasCos  = 0,
+    HasLog  = 0,
     HasExp  = 1,
     HasSqrt = 1,
     HasRsqrt = 1,
-    HasBlend = 1,
     HasRound = 1,
     HasFloor = 1,
-    HasCeil = 1
+    HasCeil = 1,
+    HasNegate = 1,
+    HasBlend = 1
   };
 };
-#endif
 
-template<> struct scalar_div_cost<float,true> { enum { value = 14 }; };
-template<> struct scalar_div_cost<double,true> { enum { value = 16 }; };
+template<> struct unpacket_traits<Packet4i> { typedef int    type; enum {size=4, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet4i half; };
+template<> struct unpacket_traits<Packet4f> { typedef float  type; enum {size=4, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet4f half; };
+template<> struct unpacket_traits<Packet2d> { typedef double type; enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet2d half; };
 
-/* Proper support for integers is only provided by AVX2. In the meantime, we'll
-   use SSE instructions and packets to deal with integers.
-template<> struct packet_traits<int>    : default_packet_traits
+/* Forward declaration */
+EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet4f,4>& kernel);
+ 
+inline std::ostream & operator <<(std::ostream & s, const Packet4i & v)
 {
-  typedef Packet8i type;
-  enum {
-    Vectorizable = 1,
-    AlignedOnScalar = 1,
-    size=8
-  };
-};
-*/
-
-template<> struct unpacket_traits<Packet8f> {
-  typedef float     type;
-  typedef Packet4f  half;
-  typedef Packet8i  integer_packet;
-  typedef uint8_t   mask_t;
-  enum {size=8, alignment=Aligned32, vectorizable=true, masked_load_available=true, masked_store_available=true};
-};
-template<> struct unpacket_traits<Packet4d> {
-  typedef double type;
-  typedef Packet2d half;
-  enum {size=4, alignment=Aligned32, vectorizable=true, masked_load_available=false, masked_store_available=false};
-};
-template<> struct unpacket_traits<Packet8i> { typedef int    type; typedef Packet4i half; enum {size=8, alignment=Aligned32, vectorizable=false, masked_load_available=false, masked_store_available=false}; };
-
-template<> EIGEN_STRONG_INLINE Packet8f pset1<Packet8f>(const float&  from) { return _mm256_set1_ps(from); }
-template<> EIGEN_STRONG_INLINE Packet4d pset1<Packet4d>(const double& from) { return _mm256_set1_pd(from); }
-template<> EIGEN_STRONG_INLINE Packet8i pset1<Packet8i>(const int&    from) { return _mm256_set1_epi32(from); }
-
-template<> EIGEN_STRONG_INLINE Packet8f pset1frombits<Packet8f>(unsigned int from) { return _mm256_castsi256_ps(pset1<Packet8i>(from)); }
-
-template<> EIGEN_STRONG_INLINE Packet8f pzero(const Packet8f& /*a*/) { return _mm256_setzero_ps(); }
-template<> EIGEN_STRONG_INLINE Packet4d pzero(const Packet4d& /*a*/) { return _mm256_setzero_pd(); }
-template<> EIGEN_STRONG_INLINE Packet8i pzero(const Packet8i& /*a*/) { return _mm256_setzero_si256(); }
-
-template<> EIGEN_STRONG_INLINE Packet8f pload1<Packet8f>(const float*  from) { return _mm256_broadcast_ss(from); }
-template<> EIGEN_STRONG_INLINE Packet4d pload1<Packet4d>(const double* from) { return _mm256_broadcast_sd(from); }
+  Packet vt;
+  vt.v4i = v;
+  s << vt.i[0] << ", " << vt.i[1] << ", " << vt.i[2] << ", " << vt.i[3];
+  return s;
+}
 
-template<> EIGEN_STRONG_INLINE Packet8f plset<Packet8f>(const float& a) { return _mm256_add_ps(_mm256_set1_ps(a), _mm256_set_ps(7.0,6.0,5.0,4.0,3.0,2.0,1.0,0.0)); }
-template<> EIGEN_STRONG_INLINE Packet4d plset<Packet4d>(const double& a) { return _mm256_add_pd(_mm256_set1_pd(a), _mm256_set_pd(3.0,2.0,1.0,0.0)); }
+inline std::ostream & operator <<(std::ostream & s, const Packet4ui & v)
+{
+  Packet vt;
+  vt.v4ui = v;
+  s << vt.ui[0] << ", " << vt.ui[1] << ", " << vt.ui[2] << ", " << vt.ui[3];
+  return s;
+}
 
-template<> EIGEN_STRONG_INLINE Packet8f padd<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_add_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4d padd<Packet4d>(const Packet4d& a, const Packet4d& b) { return _mm256_add_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet8i padd<Packet8i>(const Packet8i& a, const Packet8i& b) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  return _mm256_add_epi32(a,b);
-#else
-  __m128i lo = _mm_add_epi32(_mm256_extractf128_si256(a, 0), _mm256_extractf128_si256(b, 0));
-  __m128i hi = _mm_add_epi32(_mm256_extractf128_si256(a, 1), _mm256_extractf128_si256(b, 1));
-  return _mm256_insertf128_si256(_mm256_castsi128_si256(lo), (hi), 1);
-#endif
+inline std::ostream & operator <<(std::ostream & s, const Packet2l & v)
+{
+  Packet vt;
+  vt.v2l = v;
+  s << vt.l[0] << ", " << vt.l[1];
+  return s;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8f psub<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_sub_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4d psub<Packet4d>(const Packet4d& a, const Packet4d& b) { return _mm256_sub_pd(a,b); }
+inline std::ostream & operator <<(std::ostream & s, const Packet2ul & v)
+{
+  Packet vt;
+  vt.v2ul = v;
+  s << vt.ul[0] << ", " << vt.ul[1] ;
+  return s;
+}
 
-template<> EIGEN_STRONG_INLINE Packet8f pnegate(const Packet8f& a)
+inline std::ostream & operator <<(std::ostream & s, const Packet2d & v)
 {
-  return _mm256_sub_ps(_mm256_set1_ps(0.0),a);
+  Packet vt;
+  vt.v2d = v;
+  s << vt.d[0] << ", " << vt.d[1];
+  return s;
 }
-template<> EIGEN_STRONG_INLINE Packet4d pnegate(const Packet4d& a)
+
+#if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ >= 12)
+inline std::ostream & operator <<(std::ostream & s, const Packet4f & v)
 {
-  return _mm256_sub_pd(_mm256_set1_pd(0.0),a);
+  Packet vt;
+  vt.v4f = v;
+  s << vt.f[0] << ", " << vt.f[1] << ", " << vt.f[2] << ", " << vt.f[3];
+  return s;
 }
+#endif
 
-template<> EIGEN_STRONG_INLINE Packet8f pconj(const Packet8f& a) { return a; }
-template<> EIGEN_STRONG_INLINE Packet4d pconj(const Packet4d& a) { return a; }
-template<> EIGEN_STRONG_INLINE Packet8i pconj(const Packet8i& a) { return a; }
+template<> EIGEN_STRONG_INLINE Packet4i pload<Packet4i>(const int*     from)
+{
+  // FIXME: No intrinsic yet
+  EIGEN_DEBUG_ALIGNED_LOAD
+  Packet *vfrom;
+  vfrom = (Packet *) from;
+  return vfrom->v4i;
+}
 
-template<> EIGEN_STRONG_INLINE Packet8f pmul<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_mul_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4d pmul<Packet4d>(const Packet4d& a, const Packet4d& b) { return _mm256_mul_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d pload<Packet2d>(const double* from)
+{
+  // FIXME: No intrinsic yet
+  EIGEN_DEBUG_ALIGNED_LOAD
+  Packet *vfrom;
+  vfrom = (Packet *) from;
+  return vfrom->v2d;
+}
 
+template<> EIGEN_STRONG_INLINE void pstore<int>(int*       to, const Packet4i& from)
+{
+  // FIXME: No intrinsic yet
+  EIGEN_DEBUG_ALIGNED_STORE
+  Packet *vto;
+  vto = (Packet *) to;
+  vto->v4i = from;
+}
 
-template<> EIGEN_STRONG_INLINE Packet8f pdiv<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_div_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4d pdiv<Packet4d>(const Packet4d& a, const Packet4d& b) { return _mm256_div_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet8i pdiv<Packet8i>(const Packet8i& /*a*/, const Packet8i& /*b*/)
-{ eigen_assert(false && "packet integer division are not supported by AVX");
-  return pset1<Packet8i>(0);
+template<> EIGEN_STRONG_INLINE void pstore<double>(double*   to, const Packet2d& from)
+{
+  // FIXME: No intrinsic yet
+  EIGEN_DEBUG_ALIGNED_STORE
+  Packet *vto;
+  vto = (Packet *) to;
+  vto->v2d = from;
 }
 
-#ifdef EIGEN_VECTORIZE_FMA
-template<> EIGEN_STRONG_INLINE Packet8f pmadd(const Packet8f& a, const Packet8f& b, const Packet8f& c) {
-#if ( (EIGEN_COMP_GNUC_STRICT && EIGEN_COMP_GNUC<80) || (EIGEN_COMP_CLANG) )
-  // Clang stupidly generates a vfmadd213ps instruction plus some vmovaps on registers,
-  //  and even register spilling with clang>=6.0 (bug 1637).
-  // Gcc stupidly generates a vfmadd132ps instruction.
-  // So let's enforce it to generate a vfmadd231ps instruction since the most common use
-  //  case is to accumulate the result of the product.
-  Packet8f res = c;
-  __asm__("vfmadd231ps %[a], %[b], %[c]" : [c] "+x" (res) : [a] "x" (a), [b] "x" (b));
-  return res;
-#else
-  return _mm256_fmadd_ps(a,b,c);
-#endif
+template<> EIGEN_STRONG_INLINE Packet4i pset1<Packet4i>(const int&    from)
+{
+  return vec_splats(from);
 }
-template<> EIGEN_STRONG_INLINE Packet4d pmadd(const Packet4d& a, const Packet4d& b, const Packet4d& c) {
-#if ( (EIGEN_COMP_GNUC_STRICT && EIGEN_COMP_GNUC<80) || (EIGEN_COMP_CLANG) )
-  // see above
-  Packet4d res = c;
-  __asm__("vfmadd231pd %[a], %[b], %[c]" : [c] "+x" (res) : [a] "x" (a), [b] "x" (b));
-  return res;
-#else
-  return _mm256_fmadd_pd(a,b,c);
-#endif
+template<> EIGEN_STRONG_INLINE Packet2d pset1<Packet2d>(const double& from) {
+  return vec_splats(from);
 }
-#endif
 
-template<> EIGEN_STRONG_INLINE Packet8f pmin<Packet8f>(const Packet8f& a, const Packet8f& b) {
-#if EIGEN_COMP_GNUC && EIGEN_COMP_GNUC < 63
-  // There appears to be a bug in GCC, by which the optimizer may flip
-  // the argument order in calls to _mm_min_ps/_mm_max_ps, so we have to
-  // resort to inline ASM here. This is supposed to be fixed in gcc6.3,
-  // see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867
-  Packet8f res;
-  asm("vminps %[a], %[b], %[res]" : [res] "=x" (res) : [a] "x" (a), [b] "x" (b));
-  return res;
-#else
-  // Arguments are swapped to match NaN propagation behavior of std::min.
-  return _mm256_min_ps(b,a);
-#endif
+template<> EIGEN_STRONG_INLINE void
+pbroadcast4<Packet4i>(const int *a,
+                      Packet4i& a0, Packet4i& a1, Packet4i& a2, Packet4i& a3)
+{
+  a3 = pload<Packet4i>(a);
+  a0 = vec_splat(a3, 0);
+  a1 = vec_splat(a3, 1);
+  a2 = vec_splat(a3, 2);
+  a3 = vec_splat(a3, 3);
 }
-template<> EIGEN_STRONG_INLINE Packet4d pmin<Packet4d>(const Packet4d& a, const Packet4d& b) {
-#if EIGEN_COMP_GNUC && EIGEN_COMP_GNUC < 63
-  // See pmin above
-  Packet4d res;
-  asm("vminpd %[a], %[b], %[res]" : [res] "=x" (res) : [a] "x" (a), [b] "x" (b));
-  return res;
-#else
-  // Arguments are swapped to match NaN propagation behavior of std::min.
-  return _mm256_min_pd(b,a);
-#endif
+
+template<> EIGEN_STRONG_INLINE void
+pbroadcast4<Packet2d>(const double *a,
+                      Packet2d& a0, Packet2d& a1, Packet2d& a2, Packet2d& a3)
+{
+  a1 = pload<Packet2d>(a);
+  a0 = vec_splat(a1, 0);
+  a1 = vec_splat(a1, 1);
+  a3 = pload<Packet2d>(a+2);
+  a2 = vec_splat(a3, 0);
+  a3 = vec_splat(a3, 1);
 }
-template<> EIGEN_STRONG_INLINE Packet8f pmax<Packet8f>(const Packet8f& a, const Packet8f& b) {
-#if EIGEN_COMP_GNUC && EIGEN_COMP_GNUC < 63
-  // See pmin above
-  Packet8f res;
-  asm("vmaxps %[a], %[b], %[res]" : [res] "=x" (res) : [a] "x" (a), [b] "x" (b));
-  return res;
-#else
-  // Arguments are swapped to match NaN propagation behavior of std::max.
-  return _mm256_max_ps(b,a);
-#endif
+
+template<> EIGEN_DEVICE_FUNC inline Packet4i pgather<int, Packet4i>(const int* from, Index stride)
+{
+  EIGEN_ALIGN16 int ai[4];
+  ai[0] = from[0*stride];
+  ai[1] = from[1*stride];
+  ai[2] = from[2*stride];
+  ai[3] = from[3*stride];
+ return pload<Packet4i>(ai);
 }
-template<> EIGEN_STRONG_INLINE Packet4d pmax<Packet4d>(const Packet4d& a, const Packet4d& b) {
-#if EIGEN_COMP_GNUC && EIGEN_COMP_GNUC < 63
-  // See pmin above
-  Packet4d res;
-  asm("vmaxpd %[a], %[b], %[res]" : [res] "=x" (res) : [a] "x" (a), [b] "x" (b));
-  return res;
-#else
-  // Arguments are swapped to match NaN propagation behavior of std::max.
-  return _mm256_max_pd(b,a);
-#endif
+
+template<> EIGEN_DEVICE_FUNC inline Packet2d pgather<double, Packet2d>(const double* from, Index stride)
+{
+  EIGEN_ALIGN16 double af[2];
+  af[0] = from[0*stride];
+  af[1] = from[1*stride];
+ return pload<Packet2d>(af);
 }
 
-template<> EIGEN_STRONG_INLINE Packet8f pcmp_le(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a,b,_CMP_LE_OQ); }
-template<> EIGEN_STRONG_INLINE Packet8f pcmp_lt(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a,b,_CMP_LT_OQ); }
-template<> EIGEN_STRONG_INLINE Packet8f pcmp_eq(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a,b,_CMP_EQ_OQ); }
-template<> EIGEN_STRONG_INLINE Packet4d pcmp_eq(const Packet4d& a, const Packet4d& b) { return _mm256_cmp_pd(a,b,_CMP_EQ_OQ); }
-template<> EIGEN_STRONG_INLINE Packet8f pcmp_lt_or_nan(const Packet8f& a, const Packet8f& b) { return _mm256_cmp_ps(a, b, _CMP_NGE_UQ); }
-
-template<> EIGEN_STRONG_INLINE Packet8i pcmp_eq(const Packet8i& a, const Packet8i& b) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  return _mm256_cmpeq_epi32(a,b);
-#else
-  __m128i lo = _mm_cmpeq_epi32(_mm256_extractf128_si256(a, 0), _mm256_extractf128_si256(b, 0));
-  __m128i hi = _mm_cmpeq_epi32(_mm256_extractf128_si256(a, 1), _mm256_extractf128_si256(b, 1));
-  return _mm256_insertf128_si256(_mm256_castsi128_si256(lo), (hi), 1);
-#endif
+template<> EIGEN_DEVICE_FUNC inline void pscatter<int, Packet4i>(int* to, const Packet4i& from, Index stride)
+{
+  EIGEN_ALIGN16 int ai[4];
+  pstore<int>((int *)ai, from);
+  to[0*stride] = ai[0];
+  to[1*stride] = ai[1];
+  to[2*stride] = ai[2];
+  to[3*stride] = ai[3];
 }
 
-template<> EIGEN_STRONG_INLINE Packet8f pround<Packet8f>(const Packet8f& a) { return _mm256_round_ps(a, _MM_FROUND_CUR_DIRECTION); }
-template<> EIGEN_STRONG_INLINE Packet4d pround<Packet4d>(const Packet4d& a) { return _mm256_round_pd(a, _MM_FROUND_CUR_DIRECTION); }
+template<> EIGEN_DEVICE_FUNC inline void pscatter<double, Packet2d>(double* to, const Packet2d& from, Index stride)
+{
+  EIGEN_ALIGN16 double af[2];
+  pstore<double>(af, from);
+  to[0*stride] = af[0];
+  to[1*stride] = af[1];
+}
 
-template<> EIGEN_STRONG_INLINE Packet8f pceil<Packet8f>(const Packet8f& a) { return _mm256_ceil_ps(a); }
-template<> EIGEN_STRONG_INLINE Packet4d pceil<Packet4d>(const Packet4d& a) { return _mm256_ceil_pd(a); }
+template<> EIGEN_STRONG_INLINE Packet4i padd<Packet4i>(const Packet4i& a, const Packet4i& b) { return (a + b); }
+template<> EIGEN_STRONG_INLINE Packet2d padd<Packet2d>(const Packet2d& a, const Packet2d& b) { return (a + b); }
 
-template<> EIGEN_STRONG_INLINE Packet8f pfloor<Packet8f>(const Packet8f& a) { return _mm256_floor_ps(a); }
-template<> EIGEN_STRONG_INLINE Packet4d pfloor<Packet4d>(const Packet4d& a) { return _mm256_floor_pd(a); }
+template<> EIGEN_STRONG_INLINE Packet4i psub<Packet4i>(const Packet4i& a, const Packet4i& b) { return (a - b); }
+template<> EIGEN_STRONG_INLINE Packet2d psub<Packet2d>(const Packet2d& a, const Packet2d& b) { return (a - b); }
 
+template<> EIGEN_STRONG_INLINE Packet4i pmul<Packet4i>(const Packet4i& a, const Packet4i& b) { return (a * b); }
+template<> EIGEN_STRONG_INLINE Packet2d pmul<Packet2d>(const Packet2d& a, const Packet2d& b) { return (a * b); }
 
-template<> EIGEN_STRONG_INLINE Packet8i ptrue<Packet8i>(const Packet8i& a) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  // vpcmpeqd has lower latency than the more general vcmpps
-  return _mm256_cmpeq_epi32(a,a);
-#else
-  const __m256 b = _mm256_castsi256_ps(a);
-  return _mm256_castps_si256(_mm256_cmp_ps(b,b,_CMP_TRUE_UQ));
-#endif
-}
+template<> EIGEN_STRONG_INLINE Packet4i pdiv<Packet4i>(const Packet4i& a, const Packet4i& b) { return (a / b); }
+template<> EIGEN_STRONG_INLINE Packet2d pdiv<Packet2d>(const Packet2d& a, const Packet2d& b) { return (a / b); }
 
-template<> EIGEN_STRONG_INLINE Packet8f ptrue<Packet8f>(const Packet8f& a) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  // vpcmpeqd has lower latency than the more general vcmpps
-  const __m256i b = _mm256_castps_si256(a);
-  return _mm256_castsi256_ps(_mm256_cmpeq_epi32(b,b));
-#else
-  return _mm256_cmp_ps(a,a,_CMP_TRUE_UQ);
-#endif
-}
+template<> EIGEN_STRONG_INLINE Packet4i pnegate(const Packet4i& a) { return (-a); }
+template<> EIGEN_STRONG_INLINE Packet2d pnegate(const Packet2d& a) { return (-a); }
 
-template<> EIGEN_STRONG_INLINE Packet4d ptrue<Packet4d>(const Packet4d& a) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  // vpcmpeqq has lower latency than the more general vcmppd
-  const __m256i b = _mm256_castpd_si256(a);
-  return _mm256_castsi256_pd(_mm256_cmpeq_epi64(b,b));
-#else
-  return _mm256_cmp_pd(a,a,_CMP_TRUE_UQ);
-#endif
-}
+template<> EIGEN_STRONG_INLINE Packet4i pconj(const Packet4i& a) { return a; }
+template<> EIGEN_STRONG_INLINE Packet2d pconj(const Packet2d& a) { return a; }
 
-template<> EIGEN_STRONG_INLINE Packet8f pand<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_and_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4d pand<Packet4d>(const Packet4d& a, const Packet4d& b) { return _mm256_and_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet8i pand<Packet8i>(const Packet8i& a, const Packet8i& b) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  return _mm256_and_si256(a,b);
-#else
-  return _mm256_castps_si256(_mm256_and_ps(_mm256_castsi256_ps(a),_mm256_castsi256_ps(b)));
-#endif
-}
+template<> EIGEN_STRONG_INLINE Packet4i pmadd(const Packet4i& a, const Packet4i& b, const Packet4i& c) { return padd<Packet4i>(pmul<Packet4i>(a, b), c); }
+template<> EIGEN_STRONG_INLINE Packet2d pmadd(const Packet2d& a, const Packet2d& b, const Packet2d& c) { return vec_madd(a, b, c); }
 
-template<> EIGEN_STRONG_INLINE Packet8f por<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_or_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4d por<Packet4d>(const Packet4d& a, const Packet4d& b) { return _mm256_or_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet8i por<Packet8i>(const Packet8i& a, const Packet8i& b) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  return _mm256_or_si256(a,b);
-#else
-  return _mm256_castps_si256(_mm256_or_ps(_mm256_castsi256_ps(a),_mm256_castsi256_ps(b)));
-#endif
-}
+template<> EIGEN_STRONG_INLINE Packet4i plset<Packet4i>(const int& a)    { return padd<Packet4i>(pset1<Packet4i>(a), p4i_COUNTDOWN); }
+template<> EIGEN_STRONG_INLINE Packet2d plset<Packet2d>(const double& a) { return padd<Packet2d>(pset1<Packet2d>(a), p2d_COUNTDOWN); }
 
-template<> EIGEN_STRONG_INLINE Packet8f pxor<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_xor_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4d pxor<Packet4d>(const Packet4d& a, const Packet4d& b) { return _mm256_xor_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet8i pxor<Packet8i>(const Packet8i& a, const Packet8i& b) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  return _mm256_xor_si256(a,b);
-#else
-  return _mm256_castps_si256(_mm256_xor_ps(_mm256_castsi256_ps(a),_mm256_castsi256_ps(b)));
-#endif
-}
+template<> EIGEN_STRONG_INLINE Packet4i pmin<Packet4i>(const Packet4i& a, const Packet4i& b) { return vec_min(a, b); }
+template<> EIGEN_STRONG_INLINE Packet2d pmin<Packet2d>(const Packet2d& a, const Packet2d& b) { return vec_min(a, b); }
 
-template<> EIGEN_STRONG_INLINE Packet8f pandnot<Packet8f>(const Packet8f& a, const Packet8f& b) { return _mm256_andnot_ps(b,a); }
-template<> EIGEN_STRONG_INLINE Packet4d pandnot<Packet4d>(const Packet4d& a, const Packet4d& b) { return _mm256_andnot_pd(b,a); }
-template<> EIGEN_STRONG_INLINE Packet8i pandnot<Packet8i>(const Packet8i& a, const Packet8i& b) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  return _mm256_andnot_si256(b,a);
-#else
-  return _mm256_castps_si256(_mm256_andnot_ps(_mm256_castsi256_ps(b),_mm256_castsi256_ps(a)));
-#endif
-}
+template<> EIGEN_STRONG_INLINE Packet4i pmax<Packet4i>(const Packet4i& a, const Packet4i& b) { return vec_max(a, b); }
+template<> EIGEN_STRONG_INLINE Packet2d pmax<Packet2d>(const Packet2d& a, const Packet2d& b) { return vec_max(a, b); }
 
-template<> EIGEN_STRONG_INLINE Packet8f pselect<Packet8f>(const Packet8f& mask, const Packet8f& a, const Packet8f& b)
-{ return _mm256_blendv_ps(b,a,mask); }
-template<> EIGEN_STRONG_INLINE Packet4d pselect<Packet4d>(const Packet4d& mask, const Packet4d& a, const Packet4d& b)
-{ return _mm256_blendv_pd(b,a,mask); }
-
-template<int N> EIGEN_STRONG_INLINE Packet8i pshiftright(Packet8i a) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  return _mm256_srli_epi32(a, N);
-#else
-  __m128i lo = _mm_srli_epi32(_mm256_extractf128_si256(a, 0), N);
-  __m128i hi = _mm_srli_epi32(_mm256_extractf128_si256(a, 1), N);
-  return _mm256_insertf128_si256(_mm256_castsi128_si256(lo), (hi), 1);
-#endif
-}
+template<> EIGEN_STRONG_INLINE Packet4i pand<Packet4i>(const Packet4i& a, const Packet4i& b) { return vec_and(a, b); }
+template<> EIGEN_STRONG_INLINE Packet2d pand<Packet2d>(const Packet2d& a, const Packet2d& b) { return vec_and(a, b); }
 
-template<int N> EIGEN_STRONG_INLINE Packet8i pshiftleft(Packet8i a) {
-#ifdef EIGEN_VECTORIZE_AVX2
-  return _mm256_slli_epi32(a, N);
-#else
-  __m128i lo = _mm_slli_epi32(_mm256_extractf128_si256(a, 0), N);
-  __m128i hi = _mm_slli_epi32(_mm256_extractf128_si256(a, 1), N);
-  return _mm256_insertf128_si256(_mm256_castsi128_si256(lo), (hi), 1);
-#endif
-}
+template<> EIGEN_STRONG_INLINE Packet4i por<Packet4i>(const Packet4i& a, const Packet4i& b) { return vec_or(a, b); }
+template<> EIGEN_STRONG_INLINE Packet2d por<Packet2d>(const Packet2d& a, const Packet2d& b) { return vec_or(a, b); }
 
-template<> EIGEN_STRONG_INLINE Packet8f pload<Packet8f>(const float*   from) { EIGEN_DEBUG_ALIGNED_LOAD return _mm256_load_ps(from); }
-template<> EIGEN_STRONG_INLINE Packet4d pload<Packet4d>(const double*  from) { EIGEN_DEBUG_ALIGNED_LOAD return _mm256_load_pd(from); }
-template<> EIGEN_STRONG_INLINE Packet8i pload<Packet8i>(const int*     from) { EIGEN_DEBUG_ALIGNED_LOAD return _mm256_load_si256(reinterpret_cast<const __m256i*>(from)); }
+template<> EIGEN_STRONG_INLINE Packet4i pxor<Packet4i>(const Packet4i& a, const Packet4i& b) { return vec_xor(a, b); }
+template<> EIGEN_STRONG_INLINE Packet2d pxor<Packet2d>(const Packet2d& a, const Packet2d& b) { return vec_xor(a, b); }
 
-template<> EIGEN_STRONG_INLINE Packet8f ploadu<Packet8f>(const float* from) { EIGEN_DEBUG_UNALIGNED_LOAD return _mm256_loadu_ps(from); }
-template<> EIGEN_STRONG_INLINE Packet4d ploadu<Packet4d>(const double* from) { EIGEN_DEBUG_UNALIGNED_LOAD return _mm256_loadu_pd(from); }
-template<> EIGEN_STRONG_INLINE Packet8i ploadu<Packet8i>(const int* from) { EIGEN_DEBUG_UNALIGNED_LOAD return _mm256_loadu_si256(reinterpret_cast<const __m256i*>(from)); }
+template<> EIGEN_STRONG_INLINE Packet4i pandnot<Packet4i>(const Packet4i& a, const Packet4i& b) { return pand<Packet4i>(a, vec_nor(b, b)); }
+template<> EIGEN_STRONG_INLINE Packet2d pandnot<Packet2d>(const Packet2d& a, const Packet2d& b) { return vec_and(a, vec_nor(b, b)); }
 
-template<> EIGEN_STRONG_INLINE Packet8f ploadu<Packet8f>(const float* from, uint8_t umask) {
-  Packet8i mask = _mm256_set1_epi8(static_cast<char>(umask));
-  const Packet8i bit_mask = _mm256_set_epi32(0xffffff7f, 0xffffffbf, 0xffffffdf, 0xffffffef, 0xfffffff7, 0xfffffffb, 0xfffffffd, 0xfffffffe);
-  mask = por<Packet8i>(mask, bit_mask);
-  mask = pcmp_eq<Packet8i>(mask, _mm256_set1_epi32(0xffffffff));
-  EIGEN_DEBUG_UNALIGNED_LOAD return _mm256_maskload_ps(from, mask);
-}
+template<> EIGEN_STRONG_INLINE Packet2d pround<Packet2d>(const Packet2d& a) { return vec_round(a); }
+template<> EIGEN_STRONG_INLINE Packet2d pceil<Packet2d>(const  Packet2d& a) { return vec_ceil(a); }
+template<> EIGEN_STRONG_INLINE Packet2d pfloor<Packet2d>(const Packet2d& a) { return vec_floor(a); }
 
-// Loads 4 floats from memory a returns the packet {a0, a0  a1, a1, a2, a2, a3, a3}
-template<> EIGEN_STRONG_INLINE Packet8f ploaddup<Packet8f>(const float* from)
-{
-  // TODO try to find a way to avoid the need of a temporary register
-//   Packet8f tmp  = _mm256_castps128_ps256(_mm_loadu_ps(from));
-//   tmp = _mm256_insertf128_ps(tmp, _mm_movehl_ps(_mm256_castps256_ps128(tmp),_mm256_castps256_ps128(tmp)), 1);
-//   return _mm256_unpacklo_ps(tmp,tmp);
+template<> EIGEN_STRONG_INLINE Packet4i ploadu<Packet4i>(const int*       from) { return pload<Packet4i>(from); }
+template<> EIGEN_STRONG_INLINE Packet2d ploadu<Packet2d>(const double*    from) { return pload<Packet2d>(from); }
 
-  // _mm256_insertf128_ps is very slow on Haswell, thus:
-  Packet8f tmp = _mm256_broadcast_ps((const __m128*)(const void*)from);
-  // mimic an "inplace" permutation of the lower 128bits using a blend
-  tmp = _mm256_blend_ps(tmp,_mm256_castps128_ps256(_mm_permute_ps( _mm256_castps256_ps128(tmp), _MM_SHUFFLE(1,0,1,0))), 15);
-  // then we can perform a consistent permutation on the global register to get everything in shape:
-  return  _mm256_permute_ps(tmp, _MM_SHUFFLE(3,3,2,2));
-}
-// Loads 2 doubles from memory a returns the packet {a0, a0  a1, a1}
-template<> EIGEN_STRONG_INLINE Packet4d ploaddup<Packet4d>(const double* from)
+
+template<> EIGEN_STRONG_INLINE Packet4i ploaddup<Packet4i>(const int*     from)
 {
-  Packet4d tmp = _mm256_broadcast_pd((const __m128d*)(const void*)from);
-  return  _mm256_permute_pd(tmp, 3<<2);
+  Packet4i p = pload<Packet4i>(from);
+  return vec_perm(p, p, p16uc_DUPLICATE32_HI);
 }
 
-// Loads 2 floats from memory a returns the packet {a0, a0  a0, a0, a1, a1, a1, a1}
-template<> EIGEN_STRONG_INLINE Packet8f ploadquad<Packet8f>(const float* from)
+template<> EIGEN_STRONG_INLINE Packet2d ploaddup<Packet2d>(const double*   from)
 {
-  Packet8f tmp = _mm256_castps128_ps256(_mm_broadcast_ss(from));
-  return _mm256_insertf128_ps(tmp, _mm_broadcast_ss(from+1), 1);
+  Packet2d p = pload<Packet2d>(from);
+  return vec_perm(p, p, p16uc_PSET64_HI);
 }
 
-template<> EIGEN_STRONG_INLINE void pstore<float>(float*   to, const Packet8f& from) { EIGEN_DEBUG_ALIGNED_STORE _mm256_store_ps(to, from); }
-template<> EIGEN_STRONG_INLINE void pstore<double>(double* to, const Packet4d& from) { EIGEN_DEBUG_ALIGNED_STORE _mm256_store_pd(to, from); }
-template<> EIGEN_STRONG_INLINE void pstore<int>(int*       to, const Packet8i& from) { EIGEN_DEBUG_ALIGNED_STORE _mm256_storeu_si256(reinterpret_cast<__m256i*>(to), from); }
+template<> EIGEN_STRONG_INLINE void pstoreu<int>(int*        to, const Packet4i& from) { pstore<int>(to, from); }
+template<> EIGEN_STRONG_INLINE void pstoreu<double>(double*  to, const Packet2d& from) { pstore<double>(to, from); }
+
+template<> EIGEN_STRONG_INLINE void prefetch<int>(const int*       addr) { EIGEN_ZVECTOR_PREFETCH(addr); }
+template<> EIGEN_STRONG_INLINE void prefetch<double>(const double* addr) { EIGEN_ZVECTOR_PREFETCH(addr); }
 
-template<> EIGEN_STRONG_INLINE void pstoreu<float>(float*   to, const Packet8f& from) { EIGEN_DEBUG_UNALIGNED_STORE _mm256_storeu_ps(to, from); }
-template<> EIGEN_STRONG_INLINE void pstoreu<double>(double* to, const Packet4d& from) { EIGEN_DEBUG_UNALIGNED_STORE _mm256_storeu_pd(to, from); }
-template<> EIGEN_STRONG_INLINE void pstoreu<int>(int*       to, const Packet8i& from) { EIGEN_DEBUG_UNALIGNED_STORE _mm256_storeu_si256(reinterpret_cast<__m256i*>(to), from); }
+template<> EIGEN_STRONG_INLINE int    pfirst<Packet4i>(const Packet4i& a) { EIGEN_ALIGN16 int    x[4]; pstore(x, a); return x[0]; }
+template<> EIGEN_STRONG_INLINE double pfirst<Packet2d>(const Packet2d& a) { EIGEN_ALIGN16 double x[2]; pstore(x, a); return x[0]; }
 
-template<> EIGEN_STRONG_INLINE void pstoreu<float>(float*   to, const Packet8f& from, uint8_t umask) {
-  Packet8i mask = _mm256_set1_epi8(static_cast<char>(umask));
-  const Packet8i bit_mask = _mm256_set_epi32(0xffffff7f, 0xffffffbf, 0xffffffdf, 0xffffffef, 0xfffffff7, 0xfffffffb, 0xfffffffd, 0xfffffffe);
-  mask = por<Packet8i>(mask, bit_mask);
-  mask = pcmp_eq<Packet8i>(mask, _mm256_set1_epi32(0xffffffff));
-  EIGEN_DEBUG_UNALIGNED_STORE return _mm256_maskstore_ps(to, mask, from);
+template<> EIGEN_STRONG_INLINE Packet4i preverse(const Packet4i& a)
+{
+  return reinterpret_cast<Packet4i>(vec_perm(reinterpret_cast<Packet16uc>(a), reinterpret_cast<Packet16uc>(a), p16uc_REVERSE32));
 }
 
-// NOTE: leverage _mm256_i32gather_ps and _mm256_i32gather_pd if AVX2 instructions are available
-// NOTE: for the record the following seems to be slower: return _mm256_i32gather_ps(from, _mm256_set1_epi32(stride), 4);
-template<> EIGEN_DEVICE_FUNC inline Packet8f pgather<float, Packet8f>(const float* from, Index stride)
+template<> EIGEN_STRONG_INLINE Packet2d preverse(const Packet2d& a)
 {
-  return _mm256_set_ps(from[7*stride], from[6*stride], from[5*stride], from[4*stride],
-                       from[3*stride], from[2*stride], from[1*stride], from[0*stride]);
+  return reinterpret_cast<Packet2d>(vec_perm(reinterpret_cast<Packet16uc>(a), reinterpret_cast<Packet16uc>(a), p16uc_REVERSE64));
 }
-template<> EIGEN_DEVICE_FUNC inline Packet4d pgather<double, Packet4d>(const double* from, Index stride)
+
+template<> EIGEN_STRONG_INLINE Packet4i pabs<Packet4i>(const Packet4i& a) { return vec_abs(a); }
+template<> EIGEN_STRONG_INLINE Packet2d pabs<Packet2d>(const Packet2d& a) { return vec_abs(a); }
+
+template<> EIGEN_STRONG_INLINE int predux<Packet4i>(const Packet4i& a)
 {
-  return _mm256_set_pd(from[3*stride], from[2*stride], from[1*stride], from[0*stride]);
+  Packet4i b, sum;
+  b   = vec_sld(a, a, 8);
+  sum = padd<Packet4i>(a, b);
+  b   = vec_sld(sum, sum, 4);
+  sum = padd<Packet4i>(sum, b);
+  return pfirst(sum);
 }
 
-template<> EIGEN_DEVICE_FUNC inline void pscatter<float, Packet8f>(float* to, const Packet8f& from, Index stride)
+template<> EIGEN_STRONG_INLINE double predux<Packet2d>(const Packet2d& a)
 {
-  __m128 low = _mm256_extractf128_ps(from, 0);
-  to[stride*0] = _mm_cvtss_f32(low);
-  to[stride*1] = _mm_cvtss_f32(_mm_shuffle_ps(low, low, 1));
-  to[stride*2] = _mm_cvtss_f32(_mm_shuffle_ps(low, low, 2));
-  to[stride*3] = _mm_cvtss_f32(_mm_shuffle_ps(low, low, 3));
+  Packet2d b, sum;
+  b   = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4i>(a), reinterpret_cast<Packet4i>(a), 8));
+  sum = padd<Packet2d>(a, b);
+  return pfirst(sum);
+}
 
-  __m128 high = _mm256_extractf128_ps(from, 1);
-  to[stride*4] = _mm_cvtss_f32(high);
-  to[stride*5] = _mm_cvtss_f32(_mm_shuffle_ps(high, high, 1));
-  to[stride*6] = _mm_cvtss_f32(_mm_shuffle_ps(high, high, 2));
-  to[stride*7] = _mm_cvtss_f32(_mm_shuffle_ps(high, high, 3));
+// Other reduction functions:
+// mul
+template<> EIGEN_STRONG_INLINE int predux_mul<Packet4i>(const Packet4i& a)
+{
+  EIGEN_ALIGN16 int aux[4];
+  pstore(aux, a);
+  return aux[0] * aux[1] * aux[2] * aux[3];
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<double, Packet4d>(double* to, const Packet4d& from, Index stride)
+
+template<> EIGEN_STRONG_INLINE double predux_mul<Packet2d>(const Packet2d& a)
 {
-  __m128d low = _mm256_extractf128_pd(from, 0);
-  to[stride*0] = _mm_cvtsd_f64(low);
-  to[stride*1] = _mm_cvtsd_f64(_mm_shuffle_pd(low, low, 1));
-  __m128d high = _mm256_extractf128_pd(from, 1);
-  to[stride*2] = _mm_cvtsd_f64(high);
-  to[stride*3] = _mm_cvtsd_f64(_mm_shuffle_pd(high, high, 1));
+  return pfirst(pmul(a, reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4i>(a), reinterpret_cast<Packet4i>(a), 8))));
 }
 
-template<> EIGEN_STRONG_INLINE void pstore1<Packet8f>(float* to, const float& a)
+// min
+template<> EIGEN_STRONG_INLINE int predux_min<Packet4i>(const Packet4i& a)
 {
-  Packet8f pa = pset1<Packet8f>(a);
-  pstore(to, pa);
+  Packet4i b, res;
+  b   = pmin<Packet4i>(a, vec_sld(a, a, 8));
+  res = pmin<Packet4i>(b, vec_sld(b, b, 4));
+  return pfirst(res);
 }
-template<> EIGEN_STRONG_INLINE void pstore1<Packet4d>(double* to, const double& a)
+
+template<> EIGEN_STRONG_INLINE double predux_min<Packet2d>(const Packet2d& a)
 {
-  Packet4d pa = pset1<Packet4d>(a);
-  pstore(to, pa);
+  return pfirst(pmin<Packet2d>(a, reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4i>(a), reinterpret_cast<Packet4i>(a), 8))));
 }
-template<> EIGEN_STRONG_INLINE void pstore1<Packet8i>(int* to, const int& a)
+
+// max
+template<> EIGEN_STRONG_INLINE int predux_max<Packet4i>(const Packet4i& a)
 {
-  Packet8i pa = pset1<Packet8i>(a);
-  pstore(to, pa);
+  Packet4i b, res;
+  b = pmax<Packet4i>(a, vec_sld(a, a, 8));
+  res = pmax<Packet4i>(b, vec_sld(b, b, 4));
+  return pfirst(res);
 }
 
-#ifndef EIGEN_VECTORIZE_AVX512
-template<> EIGEN_STRONG_INLINE void prefetch<float>(const float*   addr) { _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0); }
-template<> EIGEN_STRONG_INLINE void prefetch<double>(const double* addr) { _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0); }
-template<> EIGEN_STRONG_INLINE void prefetch<int>(const int*       addr) { _mm_prefetch((SsePrefetchPtrType)(addr), _MM_HINT_T0); }
-#endif
+// max
+template<> EIGEN_STRONG_INLINE double predux_max<Packet2d>(const Packet2d& a)
+{
+  return pfirst(pmax<Packet2d>(a, reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4i>(a), reinterpret_cast<Packet4i>(a), 8))));
+}
+
+EIGEN_DEVICE_FUNC inline void
+ptranspose(PacketBlock<Packet4i,4>& kernel) {
+  Packet4i t0 = vec_mergeh(kernel.packet[0], kernel.packet[2]);
+  Packet4i t1 = vec_mergel(kernel.packet[0], kernel.packet[2]);
+  Packet4i t2 = vec_mergeh(kernel.packet[1], kernel.packet[3]);
+  Packet4i t3 = vec_mergel(kernel.packet[1], kernel.packet[3]);
+  kernel.packet[0] = vec_mergeh(t0, t2);
+  kernel.packet[1] = vec_mergel(t0, t2);
+  kernel.packet[2] = vec_mergeh(t1, t3);
+  kernel.packet[3] = vec_mergel(t1, t3);
+}
 
-template<> EIGEN_STRONG_INLINE float  pfirst<Packet8f>(const Packet8f& a) {
-  return _mm_cvtss_f32(_mm256_castps256_ps128(a));
+EIGEN_DEVICE_FUNC inline void
+ptranspose(PacketBlock<Packet2d,2>& kernel) {
+  Packet2d t0 = vec_perm(kernel.packet[0], kernel.packet[1], p16uc_TRANSPOSE64_HI);
+  Packet2d t1 = vec_perm(kernel.packet[0], kernel.packet[1], p16uc_TRANSPOSE64_LO);
+  kernel.packet[0] = t0;
+  kernel.packet[1] = t1;
 }
-template<> EIGEN_STRONG_INLINE double pfirst<Packet4d>(const Packet4d& a) {
-  return _mm_cvtsd_f64(_mm256_castpd256_pd128(a));
+
+template<> EIGEN_STRONG_INLINE Packet4i pblend(const Selector<4>& ifPacket, const Packet4i& thenPacket, const Packet4i& elsePacket) {
+  Packet4ui select = { ifPacket.select[0], ifPacket.select[1], ifPacket.select[2], ifPacket.select[3] };
+  Packet4ui mask = vec_cmpeq(select, reinterpret_cast<Packet4ui>(p4i_ONE));
+  return vec_sel(elsePacket, thenPacket, mask);
 }
-template<> EIGEN_STRONG_INLINE int    pfirst<Packet8i>(const Packet8i& a) {
-  return _mm_cvtsi128_si32(_mm256_castsi256_si128(a));
+
+
+template<> EIGEN_STRONG_INLINE Packet2d pblend(const Selector<2>& ifPacket, const Packet2d& thenPacket, const Packet2d& elsePacket) {
+  Packet2ul select = { ifPacket.select[0], ifPacket.select[1] };
+  Packet2ul mask = vec_cmpeq(select, reinterpret_cast<Packet2ul>(p2l_ONE));
+  return vec_sel(elsePacket, thenPacket, mask);
+}
+
+/* z13 has no vector float support so we emulate that with double
+   z14 has proper vector float support.
+*/
+#if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ < 12)
+/* Helper function to simulate a vec_splat_packet4f
+ */
+template<int element> EIGEN_STRONG_INLINE Packet4f vec_splat_packet4f(const Packet4f&   from)
+{
+  Packet4f splat;
+  switch (element) {
+  case 0:
+    splat.v4f[0] = vec_splat(from.v4f[0], 0);
+    splat.v4f[1] = splat.v4f[0];
+    break;
+  case 1:
+    splat.v4f[0] = vec_splat(from.v4f[0], 1);
+    splat.v4f[1] = splat.v4f[0];
+    break;
+  case 2:
+    splat.v4f[0] = vec_splat(from.v4f[1], 0);
+    splat.v4f[1] = splat.v4f[0];
+    break;
+  case 3:
+    splat.v4f[0] = vec_splat(from.v4f[1], 1);
+    splat.v4f[1] = splat.v4f[0];
+    break;
+  }
+  return splat;
+}
+
+template<> EIGEN_STRONG_INLINE Packet4f pload<Packet4f>(const float*   from)
+{
+  // FIXME: No intrinsic yet
+  EIGEN_DEBUG_ALIGNED_LOAD
+  Packet4f vfrom;
+  vfrom.v4f[0] = vec_ld2f(&from[0]);
+  vfrom.v4f[1] = vec_ld2f(&from[2]);
+  return vfrom;
 }
 
+template<> EIGEN_STRONG_INLINE void pstore<float>(float*   to, const Packet4f& from)
+{
+  // FIXME: No intrinsic yet
+  EIGEN_DEBUG_ALIGNED_STORE
+  vec_st2f(from.v4f[0], &to[0]);
+  vec_st2f(from.v4f[1], &to[2]);
+}
 
-template<> EIGEN_STRONG_INLINE Packet8f preverse(const Packet8f& a)
+template<> EIGEN_STRONG_INLINE Packet4f pset1<Packet4f>(const float&    from)
 {
-  __m256 tmp = _mm256_shuffle_ps(a,a,0x1b);
-  return _mm256_permute2f128_ps(tmp, tmp, 1);
+  Packet4f to;
+  to.v4f[0] = pset1<Packet2d>(static_cast<const double&>(from));
+  to.v4f[1] = to.v4f[0];
+  return to;
 }
-template<> EIGEN_STRONG_INLINE Packet4d preverse(const Packet4d& a)
+
+template<> EIGEN_STRONG_INLINE void
+pbroadcast4<Packet4f>(const float *a,
+                      Packet4f& a0, Packet4f& a1, Packet4f& a2, Packet4f& a3)
 {
-   __m256d tmp = _mm256_shuffle_pd(a,a,5);
-  return _mm256_permute2f128_pd(tmp, tmp, 1);
-  #if 0
-  // This version is unlikely to be faster as _mm256_shuffle_ps and _mm256_permute_pd
-  // exhibit the same latency/throughput, but it is here for future reference/benchmarking...
-  __m256d swap_halves = _mm256_permute2f128_pd(a,a,1);
-    return _mm256_permute_pd(swap_halves,5);
-  #endif
+  a3 = pload<Packet4f>(a);
+  a0 = vec_splat_packet4f<0>(a3);
+  a1 = vec_splat_packet4f<1>(a3);
+  a2 = vec_splat_packet4f<2>(a3);
+  a3 = vec_splat_packet4f<3>(a3);
 }
 
-// pabs should be ok
-template<> EIGEN_STRONG_INLINE Packet8f pabs(const Packet8f& a)
+template<> EIGEN_DEVICE_FUNC inline Packet4f pgather<float, Packet4f>(const float* from, Index stride)
 {
-  const Packet8f mask = _mm256_castsi256_ps(_mm256_setr_epi32(0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF));
-  return _mm256_and_ps(a,mask);
+  EIGEN_ALIGN16 float ai[4];
+  ai[0] = from[0*stride];
+  ai[1] = from[1*stride];
+  ai[2] = from[2*stride];
+  ai[3] = from[3*stride];
+ return pload<Packet4f>(ai);
 }
-template<> EIGEN_STRONG_INLINE Packet4d pabs(const Packet4d& a)
+
+template<> EIGEN_DEVICE_FUNC inline void pscatter<float, Packet4f>(float* to, const Packet4f& from, Index stride)
 {
-  const Packet4d mask = _mm256_castsi256_pd(_mm256_setr_epi32(0xFFFFFFFF,0x7FFFFFFF,0xFFFFFFFF,0x7FFFFFFF,0xFFFFFFFF,0x7FFFFFFF,0xFFFFFFFF,0x7FFFFFFF));
-  return _mm256_and_pd(a,mask);
+  EIGEN_ALIGN16 float ai[4];
+  pstore<float>((float *)ai, from);
+  to[0*stride] = ai[0];
+  to[1*stride] = ai[1];
+  to[2*stride] = ai[2];
+  to[3*stride] = ai[3];
 }
 
-template<> EIGEN_STRONG_INLINE Packet8f pfrexp<Packet8f>(const Packet8f& a, Packet8f& exponent) {
-  return pfrexp_float(a,exponent);
+template<> EIGEN_STRONG_INLINE Packet4f padd<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f c;
+  c.v4f[0] = a.v4f[0] + b.v4f[0];
+  c.v4f[1] = a.v4f[1] + b.v4f[1];
+  return c;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8f pldexp<Packet8f>(const Packet8f& a, const Packet8f& exponent) {
-  return pldexp_float(a,exponent);
+template<> EIGEN_STRONG_INLINE Packet4f psub<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f c;
+  c.v4f[0] = a.v4f[0] - b.v4f[0];
+  c.v4f[1] = a.v4f[1] - b.v4f[1];
+  return c;
 }
 
-template<> EIGEN_STRONG_INLINE Packet4d pldexp<Packet4d>(const Packet4d& a, const Packet4d& exponent) {
-  // Build e=2^n by constructing the exponents in a 128-bit vector and
-  // shifting them to where they belong in double-precision values.
-  Packet4i cst_1023 = pset1<Packet4i>(1023);
-  __m128i emm0 = _mm256_cvtpd_epi32(exponent);
-  emm0 = _mm_add_epi32(emm0, cst_1023);
-  emm0 = _mm_shuffle_epi32(emm0, _MM_SHUFFLE(3, 1, 2, 0));
-  __m128i lo = _mm_slli_epi64(emm0, 52);
-  __m128i hi = _mm_slli_epi64(_mm_srli_epi64(emm0, 32), 52);
-  __m256i e = _mm256_insertf128_si256(_mm256_setzero_si256(), lo, 0);
-  e = _mm256_insertf128_si256(e, hi, 1);
-  return pmul(a,_mm256_castsi256_pd(e));
+template<> EIGEN_STRONG_INLINE Packet4f pmul<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f c;
+  c.v4f[0] = a.v4f[0] * b.v4f[0];
+  c.v4f[1] = a.v4f[1] * b.v4f[1];
+  return c;
 }
 
-// preduxp should be ok
-// FIXME: why is this ok? why isn't the simply implementation working as expected?
-template<> EIGEN_STRONG_INLINE Packet8f preduxp<Packet8f>(const Packet8f* vecs)
+template<> EIGEN_STRONG_INLINE Packet4f pdiv<Packet4f>(const Packet4f& a, const Packet4f& b)
 {
-    __m256 hsum1 = _mm256_hadd_ps(vecs[0], vecs[1]);
-    __m256 hsum2 = _mm256_hadd_ps(vecs[2], vecs[3]);
-    __m256 hsum3 = _mm256_hadd_ps(vecs[4], vecs[5]);
-    __m256 hsum4 = _mm256_hadd_ps(vecs[6], vecs[7]);
+  Packet4f c;
+  c.v4f[0] = a.v4f[0] / b.v4f[0];
+  c.v4f[1] = a.v4f[1] / b.v4f[1];
+  return c;
+}
 
-    __m256 hsum5 = _mm256_hadd_ps(hsum1, hsum1);
-    __m256 hsum6 = _mm256_hadd_ps(hsum2, hsum2);
-    __m256 hsum7 = _mm256_hadd_ps(hsum3, hsum3);
-    __m256 hsum8 = _mm256_hadd_ps(hsum4, hsum4);
+template<> EIGEN_STRONG_INLINE Packet4f pnegate(const Packet4f& a)
+{
+  Packet4f c;
+  c.v4f[0] = -a.v4f[0];
+  c.v4f[1] = -a.v4f[1];
+  return c;
+}
 
-    __m256 perm1 =  _mm256_permute2f128_ps(hsum5, hsum5, 0x23);
-    __m256 perm2 =  _mm256_permute2f128_ps(hsum6, hsum6, 0x23);
-    __m256 perm3 =  _mm256_permute2f128_ps(hsum7, hsum7, 0x23);
-    __m256 perm4 =  _mm256_permute2f128_ps(hsum8, hsum8, 0x23);
+template<> EIGEN_STRONG_INLINE Packet4f pmadd(const Packet4f& a, const Packet4f& b, const Packet4f& c)
+{
+  Packet4f res;
+  res.v4f[0] = vec_madd(a.v4f[0], b.v4f[0], c.v4f[0]);
+  res.v4f[1] = vec_madd(a.v4f[1], b.v4f[1], c.v4f[1]);
+  return res;
+}
 
-    __m256 sum1 = _mm256_add_ps(perm1, hsum5);
-    __m256 sum2 = _mm256_add_ps(perm2, hsum6);
-    __m256 sum3 = _mm256_add_ps(perm3, hsum7);
-    __m256 sum4 = _mm256_add_ps(perm4, hsum8);
+template<> EIGEN_STRONG_INLINE Packet4f pmin<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f res;
+  res.v4f[0] = pmin(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pmin(a.v4f[1], b.v4f[1]);
+  return res;
+}
 
-    __m256 blend1 = _mm256_blend_ps(sum1, sum2, 0xcc);
-    __m256 blend2 = _mm256_blend_ps(sum3, sum4, 0xcc);
+template<> EIGEN_STRONG_INLINE Packet4f pmax<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f res;
+  res.v4f[0] = pmax(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pmax(a.v4f[1], b.v4f[1]);
+  return res;
+}
 
-    __m256 final = _mm256_blend_ps(blend1, blend2, 0xf0);
-    return final;
+template<> EIGEN_STRONG_INLINE Packet4f pand<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f res;
+  res.v4f[0] = pand(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pand(a.v4f[1], b.v4f[1]);
+  return res;
 }
-template<> EIGEN_STRONG_INLINE Packet4d preduxp<Packet4d>(const Packet4d* vecs)
+
+template<> EIGEN_STRONG_INLINE Packet4f por<Packet4f>(const Packet4f& a, const Packet4f& b)
 {
- Packet4d tmp0, tmp1;
+  Packet4f res;
+  res.v4f[0] = por(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = por(a.v4f[1], b.v4f[1]);
+  return res;
+}
 
-  tmp0 = _mm256_hadd_pd(vecs[0], vecs[1]);
-  tmp0 = _mm256_add_pd(tmp0, _mm256_permute2f128_pd(tmp0, tmp0, 1));
+template<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f res;
+  res.v4f[0] = pxor(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pxor(a.v4f[1], b.v4f[1]);
+  return res;
+}
 
-  tmp1 = _mm256_hadd_pd(vecs[2], vecs[3]);
-  tmp1 = _mm256_add_pd(tmp1, _mm256_permute2f128_pd(tmp1, tmp1, 1));
+template<> EIGEN_STRONG_INLINE Packet4f pandnot<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f res;
+  res.v4f[0] = pandnot(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pandnot(a.v4f[1], b.v4f[1]);
+  return res;
+}
 
-  return _mm256_blend_pd(tmp0, tmp1, 0xC);
+template<> EIGEN_STRONG_INLINE Packet4f pround<Packet4f>(const Packet4f& a)
+{
+  Packet4f res;
+  res.v4f[0] = vec_round(a.v4f[0]);
+  res.v4f[1] = vec_round(a.v4f[1]);
+  return res;
 }
 
-template<> EIGEN_STRONG_INLINE float predux<Packet8f>(const Packet8f& a)
+template<> EIGEN_STRONG_INLINE Packet4f pceil<Packet4f>(const  Packet4f& a)
 {
-  return predux(Packet4f(_mm_add_ps(_mm256_castps256_ps128(a),_mm256_extractf128_ps(a,1))));
+  Packet4f res;
+  res.v4f[0] = vec_ceil(a.v4f[0]);
+  res.v4f[1] = vec_ceil(a.v4f[1]);
+  return res;
 }
-template<> EIGEN_STRONG_INLINE double predux<Packet4d>(const Packet4d& a)
+
+template<> EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f>(const Packet4f& a)
 {
-  return predux(Packet2d(_mm_add_pd(_mm256_castpd256_pd128(a),_mm256_extractf128_pd(a,1))));
+  Packet4f res;
+  res.v4f[0] = vec_floor(a.v4f[0]);
+  res.v4f[1] = vec_floor(a.v4f[1]);
+  return res;
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f predux_half_dowto4<Packet8f>(const Packet8f& a)
+template<> EIGEN_STRONG_INLINE Packet4f ploaddup<Packet4f>(const float*    from)
 {
-  return _mm_add_ps(_mm256_castps256_ps128(a),_mm256_extractf128_ps(a,1));
+  Packet4f p = pload<Packet4f>(from);
+  p.v4f[1] = vec_splat(p.v4f[0], 1);
+  p.v4f[0] = vec_splat(p.v4f[0], 0);
+  return p;
 }
 
-template<> EIGEN_STRONG_INLINE float predux_mul<Packet8f>(const Packet8f& a)
+template<> EIGEN_STRONG_INLINE float  pfirst<Packet4f>(const Packet4f& a) { EIGEN_ALIGN16 float x[2]; vec_st2f(a.v4f[0], &x[0]); return x[0]; }
+
+template<> EIGEN_STRONG_INLINE Packet4f preverse(const Packet4f& a)
 {
-  Packet8f tmp;
-  tmp = _mm256_mul_ps(a, _mm256_permute2f128_ps(a,a,1));
-  tmp = _mm256_mul_ps(tmp, _mm256_shuffle_ps(tmp,tmp,_MM_SHUFFLE(1,0,3,2)));
-  return pfirst(_mm256_mul_ps(tmp, _mm256_shuffle_ps(tmp,tmp,1)));
+  Packet4f rev;
+  rev.v4f[0] = preverse<Packet2d>(a.v4f[1]);
+  rev.v4f[1] = preverse<Packet2d>(a.v4f[0]);
+  return rev;
 }
-template<> EIGEN_STRONG_INLINE double predux_mul<Packet4d>(const Packet4d& a)
+
+template<> EIGEN_STRONG_INLINE Packet4f pabs<Packet4f>(const Packet4f& a)
 {
-  Packet4d tmp;
-  tmp = _mm256_mul_pd(a, _mm256_permute2f128_pd(a,a,1));
-  return pfirst(_mm256_mul_pd(tmp, _mm256_shuffle_pd(tmp,tmp,1)));
+  Packet4f res;
+  res.v4f[0] = pabs(a.v4f[0]);
+  res.v4f[1] = pabs(a.v4f[1]);
+  return res;
 }
 
-template<> EIGEN_STRONG_INLINE float predux_min<Packet8f>(const Packet8f& a)
+template<> EIGEN_STRONG_INLINE float predux<Packet4f>(const Packet4f& a)
 {
-  Packet8f tmp = _mm256_min_ps(a, _mm256_permute2f128_ps(a,a,1));
-  tmp = _mm256_min_ps(tmp, _mm256_shuffle_ps(tmp,tmp,_MM_SHUFFLE(1,0,3,2)));
-  return pfirst(_mm256_min_ps(tmp, _mm256_shuffle_ps(tmp,tmp,1)));
+  Packet2d sum;
+  sum = padd<Packet2d>(a.v4f[0], a.v4f[1]);
+  double first = predux<Packet2d>(sum);
+  return static_cast<float>(first);
 }
-template<> EIGEN_STRONG_INLINE double predux_min<Packet4d>(const Packet4d& a)
+
+template<> EIGEN_STRONG_INLINE float predux_mul<Packet4f>(const Packet4f& a)
 {
-  Packet4d tmp = _mm256_min_pd(a, _mm256_permute2f128_pd(a,a,1));
-  return pfirst(_mm256_min_pd(tmp, _mm256_shuffle_pd(tmp, tmp, 1)));
+  // Return predux_mul<Packet2d> of the subvectors product
+  return static_cast<float>(pfirst(predux_mul(pmul(a.v4f[0], a.v4f[1]))));
 }
 
-template<> EIGEN_STRONG_INLINE float predux_max<Packet8f>(const Packet8f& a)
+template<> EIGEN_STRONG_INLINE float predux_min<Packet4f>(const Packet4f& a)
 {
-  Packet8f tmp = _mm256_max_ps(a, _mm256_permute2f128_ps(a,a,1));
-  tmp = _mm256_max_ps(tmp, _mm256_shuffle_ps(tmp,tmp,_MM_SHUFFLE(1,0,3,2)));
-  return pfirst(_mm256_max_ps(tmp, _mm256_shuffle_ps(tmp,tmp,1)));
+  Packet2d b, res;
+  b   = pmin<Packet2d>(a.v4f[0], a.v4f[1]);
+  res = pmin<Packet2d>(b, reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4i>(b), reinterpret_cast<Packet4i>(b), 8)));
+  return static_cast<float>(pfirst(res));
 }
 
-template<> EIGEN_STRONG_INLINE double predux_max<Packet4d>(const Packet4d& a)
+template<> EIGEN_STRONG_INLINE float predux_max<Packet4f>(const Packet4f& a)
 {
-  Packet4d tmp = _mm256_max_pd(a, _mm256_permute2f128_pd(a,a,1));
-  return pfirst(_mm256_max_pd(tmp, _mm256_shuffle_pd(tmp, tmp, 1)));
+  Packet2d b, res;
+  b   = pmax<Packet2d>(a.v4f[0], a.v4f[1]);
+  res = pmax<Packet2d>(b, reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4i>(b), reinterpret_cast<Packet4i>(b), 8)));
+  return static_cast<float>(pfirst(res));
 }
 
-// not needed yet
-// template<> EIGEN_STRONG_INLINE bool predux_all(const Packet8f& x)
-// {
-//   return _mm256_movemask_ps(x)==0xFF;
-// }
+/* Split the Packet4f PacketBlock into 4 Packet2d PacketBlocks and transpose each one
+ */
+EIGEN_DEVICE_FUNC inline void
+ptranspose(PacketBlock<Packet4f,4>& kernel) {
+  PacketBlock<Packet2d,2> t0,t1,t2,t3;
+  // copy top-left 2x2 Packet2d block
+  t0.packet[0] = kernel.packet[0].v4f[0];
+  t0.packet[1] = kernel.packet[1].v4f[0];
+
+  // copy top-right 2x2 Packet2d block
+  t1.packet[0] = kernel.packet[0].v4f[1];
+  t1.packet[1] = kernel.packet[1].v4f[1];
+
+  // copy bottom-left 2x2 Packet2d block
+  t2.packet[0] = kernel.packet[2].v4f[0];
+  t2.packet[1] = kernel.packet[3].v4f[0];
+
+  // copy bottom-right 2x2 Packet2d block
+  t3.packet[0] = kernel.packet[2].v4f[1];
+  t3.packet[1] = kernel.packet[3].v4f[1];
+
+  // Transpose all 2x2 blocks
+  ptranspose(t0);
+  ptranspose(t1);
+  ptranspose(t2);
+  ptranspose(t3);
+
+  // Copy back transposed blocks, but exchange t1 and t2 due to transposition
+  kernel.packet[0].v4f[0] = t0.packet[0];
+  kernel.packet[0].v4f[1] = t2.packet[0];
+  kernel.packet[1].v4f[0] = t0.packet[1];
+  kernel.packet[1].v4f[1] = t2.packet[1];
+  kernel.packet[2].v4f[0] = t1.packet[0];
+  kernel.packet[2].v4f[1] = t3.packet[0];
+  kernel.packet[3].v4f[0] = t1.packet[1];
+  kernel.packet[3].v4f[1] = t3.packet[1];
+}
+
+template<> EIGEN_STRONG_INLINE Packet4f pblend(const Selector<4>& ifPacket, const Packet4f& thenPacket, const Packet4f& elsePacket) {
+  Packet2ul select_hi = { ifPacket.select[0], ifPacket.select[1] };
+  Packet2ul select_lo = { ifPacket.select[2], ifPacket.select[3] };
+  Packet2ul mask_hi = vec_cmpeq(select_hi, reinterpret_cast<Packet2ul>(p2l_ONE));
+  Packet2ul mask_lo = vec_cmpeq(select_lo, reinterpret_cast<Packet2ul>(p2l_ONE));
+  Packet4f result;
+  result.v4f[0] = vec_sel(elsePacket.v4f[0], thenPacket.v4f[0], mask_hi);
+  result.v4f[1] = vec_sel(elsePacket.v4f[1], thenPacket.v4f[1], mask_lo);
+  return result;
+}
+
+template<> Packet4f EIGEN_STRONG_INLINE pcmp_le<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+  Packet4f res;
+  res.v4f[0] = pcmp_le(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pcmp_le(a.v4f[1], b.v4f[1]);
+  return res;
+}
 
-template<> EIGEN_STRONG_INLINE bool predux_any(const Packet8f& x)
+template<> Packet4f EIGEN_STRONG_INLINE pcmp_lt<Packet4f>(const Packet4f& a, const Packet4f& b)
 {
-  return _mm256_movemask_ps(x)!=0;
+  Packet4f res;
+  res.v4f[0] = pcmp_lt(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pcmp_lt(a.v4f[1], b.v4f[1]);
+  return res;
 }
 
-template<int Offset>
-struct palign_impl<Offset,Packet8f>
+template<> Packet4f EIGEN_STRONG_INLINE pcmp_eq<Packet4f>(const Packet4f& a, const Packet4f& b)
 {
-  static EIGEN_STRONG_INLINE void run(Packet8f& first, const Packet8f& second)
-  {
-    if (Offset==1)
-    {
-      first = _mm256_blend_ps(first, second, 1);
-      Packet8f tmp1 = _mm256_permute_ps (first, _MM_SHUFFLE(0,3,2,1));
-      Packet8f tmp2 = _mm256_permute2f128_ps (tmp1, tmp1, 1);
-      first = _mm256_blend_ps(tmp1, tmp2, 0x88);
-    }
-    else if (Offset==2)
-    {
-      first = _mm256_blend_ps(first, second, 3);
-      Packet8f tmp1 = _mm256_permute_ps (first, _MM_SHUFFLE(1,0,3,2));
-      Packet8f tmp2 = _mm256_permute2f128_ps (tmp1, tmp1, 1);
-      first = _mm256_blend_ps(tmp1, tmp2, 0xcc);
-    }
-    else if (Offset==3)
-    {
-      first = _mm256_blend_ps(first, second, 7);
-      Packet8f tmp1 = _mm256_permute_ps (first, _MM_SHUFFLE(2,1,0,3));
-      Packet8f tmp2 = _mm256_permute2f128_ps (tmp1, tmp1, 1);
-      first = _mm256_blend_ps(tmp1, tmp2, 0xee);
-    }
-    else if (Offset==4)
-    {
-      first = _mm256_blend_ps(first, second, 15);
-      Packet8f tmp1 = _mm256_permute_ps (first, _MM_SHUFFLE(3,2,1,0));
-      Packet8f tmp2 = _mm256_permute2f128_ps (tmp1, tmp1, 1);
-      first = _mm256_permute_ps(tmp2, _MM_SHUFFLE(3,2,1,0));
-    }
-    else if (Offset==5)
-    {
-      first = _mm256_blend_ps(first, second, 31);
-      first = _mm256_permute2f128_ps(first, first, 1);
-      Packet8f tmp = _mm256_permute_ps (first, _MM_SHUFFLE(0,3,2,1));
-      first = _mm256_permute2f128_ps(tmp, tmp, 1);
-      first = _mm256_blend_ps(tmp, first, 0x88);
-    }
-    else if (Offset==6)
-    {
-      first = _mm256_blend_ps(first, second, 63);
-      first = _mm256_permute2f128_ps(first, first, 1);
-      Packet8f tmp = _mm256_permute_ps (first, _MM_SHUFFLE(1,0,3,2));
-      first = _mm256_permute2f128_ps(tmp, tmp, 1);
-      first = _mm256_blend_ps(tmp, first, 0xcc);
-    }
-    else if (Offset==7)
-    {
-      first = _mm256_blend_ps(first, second, 127);
-      first = _mm256_permute2f128_ps(first, first, 1);
-      Packet8f tmp = _mm256_permute_ps (first, _MM_SHUFFLE(2,1,0,3));
-      first = _mm256_permute2f128_ps(tmp, tmp, 1);
-      first = _mm256_blend_ps(tmp, first, 0xee);
-    }
-  }
-};
+  Packet4f res;
+  res.v4f[0] = pcmp_eq(a.v4f[0], b.v4f[0]);
+  res.v4f[1] = pcmp_eq(a.v4f[1], b.v4f[1]);
+  return res;
+}
 
-template<int Offset>
-struct palign_impl<Offset,Packet4d>
+#else
+template<> EIGEN_STRONG_INLINE Packet4f pload<Packet4f>(const float* from)
 {
-  static EIGEN_STRONG_INLINE void run(Packet4d& first, const Packet4d& second)
-  {
-    if (Offset==1)
-    {
-      first = _mm256_blend_pd(first, second, 1);
-      __m256d tmp = _mm256_permute_pd(first, 5);
-      first = _mm256_permute2f128_pd(tmp, tmp, 1);
-      first = _mm256_blend_pd(tmp, first, 0xA);
-    }
-    else if (Offset==2)
-    {
-      first = _mm256_blend_pd(first, second, 3);
-      first = _mm256_permute2f128_pd(first, first, 1);
-    }
-    else if (Offset==3)
-    {
-      first = _mm256_blend_pd(first, second, 7);
-      __m256d tmp = _mm256_permute_pd(first, 5);
-      first = _mm256_permute2f128_pd(tmp, tmp, 1);
-      first = _mm256_blend_pd(tmp, first, 5);
-    }
-  }
-};
+  // FIXME: No intrinsic yet
+  EIGEN_DEBUG_ALIGNED_LOAD
+  Packet *vfrom;
+  vfrom = (Packet *) from;
+  return vfrom->v4f;
+}
 
-EIGEN_DEVICE_FUNC inline void
-ptranspose(PacketBlock<Packet8f,8>& kernel) {
-  __m256 T0 = _mm256_unpacklo_ps(kernel.packet[0], kernel.packet[1]);
-  __m256 T1 = _mm256_unpackhi_ps(kernel.packet[0], kernel.packet[1]);
-  __m256 T2 = _mm256_unpacklo_ps(kernel.packet[2], kernel.packet[3]);
-  __m256 T3 = _mm256_unpackhi_ps(kernel.packet[2], kernel.packet[3]);
-  __m256 T4 = _mm256_unpacklo_ps(kernel.packet[4], kernel.packet[5]);
-  __m256 T5 = _mm256_unpackhi_ps(kernel.packet[4], kernel.packet[5]);
-  __m256 T6 = _mm256_unpacklo_ps(kernel.packet[6], kernel.packet[7]);
-  __m256 T7 = _mm256_unpackhi_ps(kernel.packet[6], kernel.packet[7]);
-  __m256 S0 = _mm256_shuffle_ps(T0,T2,_MM_SHUFFLE(1,0,1,0));
-  __m256 S1 = _mm256_shuffle_ps(T0,T2,_MM_SHUFFLE(3,2,3,2));
-  __m256 S2 = _mm256_shuffle_ps(T1,T3,_MM_SHUFFLE(1,0,1,0));
-  __m256 S3 = _mm256_shuffle_ps(T1,T3,_MM_SHUFFLE(3,2,3,2));
-  __m256 S4 = _mm256_shuffle_ps(T4,T6,_MM_SHUFFLE(1,0,1,0));
-  __m256 S5 = _mm256_shuffle_ps(T4,T6,_MM_SHUFFLE(3,2,3,2));
-  __m256 S6 = _mm256_shuffle_ps(T5,T7,_MM_SHUFFLE(1,0,1,0));
-  __m256 S7 = _mm256_shuffle_ps(T5,T7,_MM_SHUFFLE(3,2,3,2));
-  kernel.packet[0] = _mm256_permute2f128_ps(S0, S4, 0x20);
-  kernel.packet[1] = _mm256_permute2f128_ps(S1, S5, 0x20);
-  kernel.packet[2] = _mm256_permute2f128_ps(S2, S6, 0x20);
-  kernel.packet[3] = _mm256_permute2f128_ps(S3, S7, 0x20);
-  kernel.packet[4] = _mm256_permute2f128_ps(S0, S4, 0x31);
-  kernel.packet[5] = _mm256_permute2f128_ps(S1, S5, 0x31);
-  kernel.packet[6] = _mm256_permute2f128_ps(S2, S6, 0x31);
-  kernel.packet[7] = _mm256_permute2f128_ps(S3, S7, 0x31);
+template<> EIGEN_STRONG_INLINE void pstore<float>(float* to, const Packet4f& from)
+{
+  // FIXME: No intrinsic yet
+  EIGEN_DEBUG_ALIGNED_STORE
+  Packet *vto;
+  vto = (Packet *) to;
+  vto->v4f = from;
 }
 
-EIGEN_DEVICE_FUNC inline void
-ptranspose(PacketBlock<Packet8f,4>& kernel) {
-  __m256 T0 = _mm256_unpacklo_ps(kernel.packet[0], kernel.packet[1]);
-  __m256 T1 = _mm256_unpackhi_ps(kernel.packet[0], kernel.packet[1]);
-  __m256 T2 = _mm256_unpacklo_ps(kernel.packet[2], kernel.packet[3]);
-  __m256 T3 = _mm256_unpackhi_ps(kernel.packet[2], kernel.packet[3]);
-
-  __m256 S0 = _mm256_shuffle_ps(T0,T2,_MM_SHUFFLE(1,0,1,0));
-  __m256 S1 = _mm256_shuffle_ps(T0,T2,_MM_SHUFFLE(3,2,3,2));
-  __m256 S2 = _mm256_shuffle_ps(T1,T3,_MM_SHUFFLE(1,0,1,0));
-  __m256 S3 = _mm256_shuffle_ps(T1,T3,_MM_SHUFFLE(3,2,3,2));
-
-  kernel.packet[0] = _mm256_permute2f128_ps(S0, S1, 0x20);
-  kernel.packet[1] = _mm256_permute2f128_ps(S2, S3, 0x20);
-  kernel.packet[2] = _mm256_permute2f128_ps(S0, S1, 0x31);
-  kernel.packet[3] = _mm256_permute2f128_ps(S2, S3, 0x31);
+template<> EIGEN_STRONG_INLINE Packet4f pset1<Packet4f>(const float& from)
+{
+  return vec_splats(from);
 }
 
-EIGEN_DEVICE_FUNC inline void
-ptranspose(PacketBlock<Packet4d,4>& kernel) {
-  __m256d T0 = _mm256_shuffle_pd(kernel.packet[0], kernel.packet[1], 15);
-  __m256d T1 = _mm256_shuffle_pd(kernel.packet[0], kernel.packet[1], 0);
-  __m256d T2 = _mm256_shuffle_pd(kernel.packet[2], kernel.packet[3], 15);
-  __m256d T3 = _mm256_shuffle_pd(kernel.packet[2], kernel.packet[3], 0);
+template<> EIGEN_STRONG_INLINE void
+pbroadcast4<Packet4f>(const float *a,
+                      Packet4f& a0, Packet4f& a1, Packet4f& a2, Packet4f& a3)
+{
+  a3 = pload<Packet4f>(a);
+  a0 = vec_splat(a3, 0);
+  a1 = vec_splat(a3, 1);
+  a2 = vec_splat(a3, 2);
+  a3 = vec_splat(a3, 3);
+}
+
+template<> EIGEN_DEVICE_FUNC inline Packet4f pgather<float, Packet4f>(const float* from, Index stride)
+{
+  EIGEN_ALIGN16 float af[4];
+  af[0] = from[0*stride];
+  af[1] = from[1*stride];
+  af[2] = from[2*stride];
+  af[3] = from[3*stride];
+ return pload<Packet4f>(af);
+}
 
-  kernel.packet[1] = _mm256_permute2f128_pd(T0, T2, 32);
-  kernel.packet[3] = _mm256_permute2f128_pd(T0, T2, 49);
-  kernel.packet[0] = _mm256_permute2f128_pd(T1, T3, 32);
-  kernel.packet[2] = _mm256_permute2f128_pd(T1, T3, 49);
+template<> EIGEN_DEVICE_FUNC inline void pscatter<float, Packet4f>(float* to, const Packet4f& from, Index stride)
+{
+  EIGEN_ALIGN16 float af[4];
+  pstore<float>((float*)af, from);
+  to[0*stride] = af[0];
+  to[1*stride] = af[1];
+  to[2*stride] = af[2];
+  to[3*stride] = af[3];
 }
 
-template<> EIGEN_STRONG_INLINE Packet8f pblend(const Selector<8>& ifPacket, const Packet8f& thenPacket, const Packet8f& elsePacket) {
-  const __m256 zero = _mm256_setzero_ps();
-  const __m256 select = _mm256_set_ps(ifPacket.select[7], ifPacket.select[6], ifPacket.select[5], ifPacket.select[4], ifPacket.select[3], ifPacket.select[2], ifPacket.select[1], ifPacket.select[0]);
-  __m256 false_mask = _mm256_cmp_ps(select, zero, _CMP_EQ_UQ);
-  return _mm256_blendv_ps(thenPacket, elsePacket, false_mask);
+template<> EIGEN_STRONG_INLINE Packet4f padd<Packet4f>(const Packet4f& a, const Packet4f& b) { return (a + b); }
+template<> EIGEN_STRONG_INLINE Packet4f psub<Packet4f>(const Packet4f& a, const Packet4f& b) { return (a - b); }
+template<> EIGEN_STRONG_INLINE Packet4f pmul<Packet4f>(const Packet4f& a, const Packet4f& b) { return (a * b); }
+template<> EIGEN_STRONG_INLINE Packet4f pdiv<Packet4f>(const Packet4f& a, const Packet4f& b) { return (a / b); }
+template<> EIGEN_STRONG_INLINE Packet4f pnegate<Packet4f>(const Packet4f& a) { return (-a); }
+template<> EIGEN_STRONG_INLINE Packet4f pconj<Packet4f>  (const Packet4f& a) { return a; }
+template<> EIGEN_STRONG_INLINE Packet4f pmadd<Packet4f>  (const Packet4f& a, const Packet4f& b, const Packet4f& c) { return vec_madd(a, b, c); }
+template<> EIGEN_STRONG_INLINE Packet4f pmin<Packet4f>   (const Packet4f& a, const Packet4f& b) { return vec_min(a, b); }
+template<> EIGEN_STRONG_INLINE Packet4f pmax<Packet4f>   (const Packet4f& a, const Packet4f& b) { return vec_max(a, b); }
+template<> EIGEN_STRONG_INLINE Packet4f pand<Packet4f>   (const Packet4f& a, const Packet4f& b) { return vec_and(a, b); }
+template<> EIGEN_STRONG_INLINE Packet4f por<Packet4f>    (const Packet4f& a, const Packet4f& b) { return vec_or(a, b); }
+template<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>   (const Packet4f& a, const Packet4f& b) { return vec_xor(a, b); }
+template<> EIGEN_STRONG_INLINE Packet4f pandnot<Packet4f>(const Packet4f& a, const Packet4f& b) { return vec_and(a, vec_nor(b, b)); }
+template<> EIGEN_STRONG_INLINE Packet4f pround<Packet4f> (const Packet4f& a) { return vec_round(a); }
+template<> EIGEN_STRONG_INLINE Packet4f pceil<Packet4f>  (const Packet4f& a) { return vec_ceil(a); }
+template<> EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f> (const Packet4f& a) { return vec_floor(a); }
+template<> EIGEN_STRONG_INLINE Packet4f pabs<Packet4f>   (const Packet4f& a) { return vec_abs(a); }
+template<> EIGEN_STRONG_INLINE float pfirst<Packet4f>(const Packet4f& a) { EIGEN_ALIGN16 float x[4]; pstore(x, a); return x[0]; }
+
+template<> EIGEN_STRONG_INLINE Packet4f ploaddup<Packet4f>(const float* from)
+{
+  Packet4f p = pload<Packet4f>(from);
+  return vec_perm(p, p, p16uc_DUPLICATE32_HI);
 }
-template<> EIGEN_STRONG_INLINE Packet4d pblend(const Selector<4>& ifPacket, const Packet4d& thenPacket, const Packet4d& elsePacket) {
-  const __m256d zero = _mm256_setzero_pd();
-  const __m256d select = _mm256_set_pd(ifPacket.select[3], ifPacket.select[2], ifPacket.select[1], ifPacket.select[0]);
-  __m256d false_mask = _mm256_cmp_pd(select, zero, _CMP_EQ_UQ);
-  return _mm256_blendv_pd(thenPacket, elsePacket, false_mask);
+
+template<> EIGEN_STRONG_INLINE Packet4f preverse(const Packet4f& a)
+{
+  return reinterpret_cast<Packet4f>(vec_perm(reinterpret_cast<Packet16uc>(a), reinterpret_cast<Packet16uc>(a), p16uc_REVERSE32));
 }
 
-template<> EIGEN_STRONG_INLINE Packet8f pinsertfirst(const Packet8f& a, float b)
+template<> EIGEN_STRONG_INLINE float predux<Packet4f>(const Packet4f& a)
 {
-  return _mm256_blend_ps(a,pset1<Packet8f>(b),1);
+  Packet4f b, sum;
+  b   = vec_sld(a, a, 8);
+  sum = padd<Packet4f>(a, b);
+  b   = vec_sld(sum, sum, 4);
+  sum = padd<Packet4f>(sum, b);
+  return pfirst(sum);
 }
 
-template<> EIGEN_STRONG_INLINE Packet4d pinsertfirst(const Packet4d& a, double b)
+// Other reduction functions:
+// mul
+template<> EIGEN_STRONG_INLINE float predux_mul<Packet4f>(const Packet4f& a)
 {
-  return _mm256_blend_pd(a,pset1<Packet4d>(b),1);
+  Packet4f prod;
+  prod = pmul(a, vec_sld(a, a, 8));
+  return pfirst(pmul(prod, vec_sld(prod, prod, 4)));
 }
 
-template<> EIGEN_STRONG_INLINE Packet8f pinsertlast(const Packet8f& a, float b)
+// min
+template<> EIGEN_STRONG_INLINE float predux_min<Packet4f>(const Packet4f& a)
 {
-  return _mm256_blend_ps(a,pset1<Packet8f>(b),(1<<7));
+  Packet4f b, res;
+  b   = pmin<Packet4f>(a, vec_sld(a, a, 8));
+  res = pmin<Packet4f>(b, vec_sld(b, b, 4));
+  return pfirst(res);
 }
 
-template<> EIGEN_STRONG_INLINE Packet4d pinsertlast(const Packet4d& a, double b)
+// max
+template<> EIGEN_STRONG_INLINE float predux_max<Packet4f>(const Packet4f& a)
 {
-  return _mm256_blend_pd(a,pset1<Packet4d>(b),(1<<3));
+  Packet4f b, res;
+  b = pmax<Packet4f>(a, vec_sld(a, a, 8));
+  res = pmax<Packet4f>(b, vec_sld(b, b, 4));
+  return pfirst(res);
 }
 
+EIGEN_DEVICE_FUNC inline void
+ptranspose(PacketBlock<Packet4f,4>& kernel) {
+  Packet4f t0 = vec_mergeh(kernel.packet[0], kernel.packet[2]);
+  Packet4f t1 = vec_mergel(kernel.packet[0], kernel.packet[2]);
+  Packet4f t2 = vec_mergeh(kernel.packet[1], kernel.packet[3]);
+  Packet4f t3 = vec_mergel(kernel.packet[1], kernel.packet[3]);
+  kernel.packet[0] = vec_mergeh(t0, t2);
+  kernel.packet[1] = vec_mergel(t0, t2);
+  kernel.packet[2] = vec_mergeh(t1, t3);
+  kernel.packet[3] = vec_mergel(t1, t3);
+}
+
+template<> EIGEN_STRONG_INLINE Packet4f pblend(const Selector<4>& ifPacket, const Packet4f& thenPacket, const Packet4f& elsePacket) {
+  Packet4ui select = { ifPacket.select[0], ifPacket.select[1], ifPacket.select[2], ifPacket.select[3] };
+  Packet4ui mask = vec_cmpeq(select, reinterpret_cast<Packet4ui>(p4i_ONE));
+  return vec_sel(elsePacket, thenPacket, mask);
+}
+
+#endif
+
+template<> EIGEN_STRONG_INLINE void prefetch<float>(const float*   addr) { EIGEN_ZVECTOR_PREFETCH(addr); }
+template<> EIGEN_STRONG_INLINE Packet4f ploadu<Packet4f> (const float* from) { return pload<Packet4f>(from); }
+template<> EIGEN_STRONG_INLINE void pstoreu<float>(float* to, const Packet4f& from) { pstore<float>(to, from); }
+template<> EIGEN_STRONG_INLINE Packet4f plset<Packet4f>  (const float& a)  { return padd<Packet4f>(pset1<Packet4f>(a), p4f_COUNTDOWN); }
+
 } // end namespace internal
 
 } // end namespace Eigen
 
-#endif // EIGEN_PACKET_MATH_AVX_H
+#endif // EIGEN_PACKET_MATH_ZVECTOR_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX/TypeCasting.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SVE/TypeCasting.h`

 * *Files 24% similar despite different names*

```diff
@@ -1,59 +1,49 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
-// Copyright (C) 2015 Benoit Steiner <benoit.steiner.goog@gmail.com>
+// Copyright (C) 2020, Arm Limited and Contributors
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
-#ifndef EIGEN_TYPE_CASTING_AVX_H
-#define EIGEN_TYPE_CASTING_AVX_H
+#ifndef EIGEN_TYPE_CASTING_SVE_H
+#define EIGEN_TYPE_CASTING_SVE_H
 
 namespace Eigen {
-
 namespace internal {
 
-// For now we use SSE to handle integers, so we can't use AVX instructions to cast
-// from int to float
 template <>
-struct type_casting_traits<float, int> {
-  enum {
-    VectorizedCast = 0,
-    SrcCoeffRatio = 1,
-    TgtCoeffRatio = 1
-  };
+struct type_casting_traits<float, numext::int32_t> {
+  enum { VectorizedCast = 1, SrcCoeffRatio = 1, TgtCoeffRatio = 1 };
 };
 
 template <>
-struct type_casting_traits<int, float> {
-  enum {
-    VectorizedCast = 0,
-    SrcCoeffRatio = 1,
-    TgtCoeffRatio = 1
-  };
+struct type_casting_traits<numext::int32_t, float> {
+  enum { VectorizedCast = 1, SrcCoeffRatio = 1, TgtCoeffRatio = 1 };
 };
 
-
-
-template<> EIGEN_STRONG_INLINE Packet8i pcast<Packet8f, Packet8i>(const Packet8f& a) {
-  return _mm256_cvttps_epi32(a);
+template <>
+EIGEN_STRONG_INLINE PacketXf pcast<PacketXi, PacketXf>(const PacketXi& a) {
+  return svcvt_f32_s32_z(svptrue_b32(), a);
 }
 
-template<> EIGEN_STRONG_INLINE Packet8f pcast<Packet8i, Packet8f>(const Packet8i& a) {
-  return _mm256_cvtepi32_ps(a);
+template <>
+EIGEN_STRONG_INLINE PacketXi pcast<PacketXf, PacketXi>(const PacketXf& a) {
+  return svcvt_s32_f32_z(svptrue_b32(), a);
 }
 
-template<> EIGEN_STRONG_INLINE Packet8i preinterpret<Packet8i,Packet8f>(const Packet8f& a) {
-  return _mm256_castps_si256(a);
+template <>
+EIGEN_STRONG_INLINE PacketXf preinterpret<PacketXf, PacketXi>(const PacketXi& a) {
+  return svreinterpret_f32_s32(a);
 }
 
-template<> EIGEN_STRONG_INLINE Packet8f preinterpret<Packet8f,Packet8i>(const Packet8i& a) {
-  return _mm256_castsi256_ps(a);
+template <>
+EIGEN_STRONG_INLINE PacketXi preinterpret<PacketXi, PacketXf>(const PacketXf& a) {
+  return svreinterpret_s32_f32(a);
 }
 
-} // end namespace internal
-
-} // end namespace Eigen
+}  // namespace internal
+}  // namespace Eigen
 
-#endif // EIGEN_TYPE_CASTING_AVX_H
+#endif // EIGEN_TYPE_CASTING_SVE_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX512/Complex.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX512/Complex.h`

 * *Files 9% similar despite different names*

```diff
@@ -33,37 +33,37 @@
     HasHalfPacket = 1,
 
     HasAdd    = 1,
     HasSub    = 1,
     HasMul    = 1,
     HasDiv    = 1,
     HasNegate = 1,
+    HasSqrt   = 1,
     HasAbs    = 0,
     HasAbs2   = 0,
     HasMin    = 0,
     HasMax    = 0,
-    HasSetLinear = 0,
-    HasReduxp = 0
+    HasSetLinear = 0
   };
 };
 
 template<> struct unpacket_traits<Packet8cf> {
   typedef std::complex<float> type;
+  typedef Packet4cf half;
+  typedef Packet16f as_real;
   enum {
     size = 8,
     alignment=unpacket_traits<Packet16f>::alignment,
     vectorizable=true,
     masked_load_available=false,
     masked_store_available=false
   };
-  typedef Packet4cf half;
 };
 
 template<> EIGEN_STRONG_INLINE Packet8cf ptrue<Packet8cf>(const Packet8cf& a) { return Packet8cf(ptrue(Packet16f(a.v))); }
-template<> EIGEN_STRONG_INLINE Packet8cf pnot<Packet8cf>(const Packet8cf& a) { return Packet8cf(pnot(Packet16f(a.v))); }
 template<> EIGEN_STRONG_INLINE Packet8cf padd<Packet8cf>(const Packet8cf& a, const Packet8cf& b) { return Packet8cf(_mm512_add_ps(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet8cf psub<Packet8cf>(const Packet8cf& a, const Packet8cf& b) { return Packet8cf(_mm512_sub_ps(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet8cf pnegate(const Packet8cf& a)
 {
   return Packet8cf(pnegate(a.v));
 }
 template<> EIGEN_STRONG_INLINE Packet8cf pconj(const Packet8cf& a)
@@ -93,15 +93,17 @@
 
 template<> EIGEN_STRONG_INLINE Packet8cf pload <Packet8cf>(const std::complex<float>* from) { EIGEN_DEBUG_ALIGNED_LOAD return Packet8cf(pload<Packet16f>(&numext::real_ref(*from))); }
 template<> EIGEN_STRONG_INLINE Packet8cf ploadu<Packet8cf>(const std::complex<float>* from) { EIGEN_DEBUG_UNALIGNED_LOAD return Packet8cf(ploadu<Packet16f>(&numext::real_ref(*from))); }
 
 
 template<> EIGEN_STRONG_INLINE Packet8cf pset1<Packet8cf>(const std::complex<float>& from)
 {
-  return Packet8cf(_mm512_castpd_ps(pload1<Packet8d>((const double*)(const void*)&from)));
+  const float re = std::real(from);
+  const float im = std::imag(from);
+  return Packet8cf(_mm512_set_ps(im, re, im, re, im, re, im, re, im, re, im, re, im, re, im, re));
 }
 
 template<> EIGEN_STRONG_INLINE Packet8cf ploaddup<Packet8cf>(const std::complex<float>* from)
 {
   return Packet8cf( _mm512_castpd_ps( ploaddup<Packet8d>((const double*)(const void*)from )) );
 }
 template<> EIGEN_STRONG_INLINE Packet8cf ploadquad<Packet8cf>(const std::complex<float>* from)
@@ -149,57 +151,14 @@
 EIGEN_STRONG_INLINE Packet4cf predux_half_dowto4<Packet8cf>(const Packet8cf& a) {
   __m256 lane0 = extract256<0>(a.v);
   __m256 lane1 = extract256<1>(a.v);
   __m256 res = _mm256_add_ps(lane0, lane1);
   return Packet4cf(res);
 }
 
-template<int Offset>
-struct palign_impl<Offset,Packet8cf>
-{
-  static EIGEN_STRONG_INLINE void run(Packet8cf& first, const Packet8cf& second)
-  {
-    if (Offset==0) return;
-    palign_impl<Offset*2,Packet16f>::run(first.v, second.v);
-  }
-};
-
-template<> struct conj_helper<Packet8cf, Packet8cf, false,true>
-{
-  EIGEN_STRONG_INLINE Packet8cf pmadd(const Packet8cf& x, const Packet8cf& y, const Packet8cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet8cf pmul(const Packet8cf& a, const Packet8cf& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet8cf, Packet8cf, true,false>
-{
-  EIGEN_STRONG_INLINE Packet8cf pmadd(const Packet8cf& x, const Packet8cf& y, const Packet8cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet8cf pmul(const Packet8cf& a, const Packet8cf& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template<> struct conj_helper<Packet8cf, Packet8cf, true,true>
-{
-  EIGEN_STRONG_INLINE Packet8cf pmadd(const Packet8cf& x, const Packet8cf& y, const Packet8cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet8cf pmul(const Packet8cf& a, const Packet8cf& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet8cf,Packet16f)
 
 template<> EIGEN_STRONG_INLINE Packet8cf pdiv<Packet8cf>(const Packet8cf& a, const Packet8cf& b)
 {
   Packet8cf num = pmul(a, pconj(b));
   __m512 tmp = _mm512_mul_ps(b.v, b.v);
   __m512 tmp2    = _mm512_shuffle_ps(tmp,tmp,0xB1);
@@ -231,33 +190,34 @@
     HasHalfPacket = 1,
 
     HasAdd    = 1,
     HasSub    = 1,
     HasMul    = 1,
     HasDiv    = 1,
     HasNegate = 1,
+    HasSqrt   = 1,
     HasAbs    = 0,
     HasAbs2   = 0,
     HasMin    = 0,
     HasMax    = 0,
-    HasSetLinear = 0,
-    HasReduxp = 0
+    HasSetLinear = 0
   };
 };
 
 template<> struct unpacket_traits<Packet4cd> {
   typedef std::complex<double> type;
+  typedef Packet2cd half;
+  typedef Packet8d as_real;
   enum {
     size = 4,
     alignment = unpacket_traits<Packet8d>::alignment,
     vectorizable=true,
     masked_load_available=false,
     masked_store_available=false
   };
-  typedef Packet2cd half;
 };
 
 template<> EIGEN_STRONG_INLINE Packet4cd padd<Packet4cd>(const Packet4cd& a, const Packet4cd& b) { return Packet4cd(_mm512_add_pd(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet4cd psub<Packet4cd>(const Packet4cd& a, const Packet4cd& b) { return Packet4cd(_mm512_sub_pd(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet4cd pnegate(const Packet4cd& a) { return Packet4cd(pnegate(a.v)); }
 template<> EIGEN_STRONG_INLINE Packet4cd pconj(const Packet4cd& a)
 {
@@ -273,15 +233,14 @@
   __m512d tmp2 = _mm512_shuffle_pd(a.v,a.v,0xFF);
   __m512d tmp3 = _mm512_shuffle_pd(b.v,b.v,0x55);
   __m512d odd  = _mm512_mul_pd(tmp2, tmp3);
   return Packet4cd(_mm512_fmaddsub_pd(tmp1, b.v, odd));
 }
 
 template<> EIGEN_STRONG_INLINE Packet4cd ptrue<Packet4cd>(const Packet4cd& a) { return Packet4cd(ptrue(Packet8d(a.v))); }
-template<> EIGEN_STRONG_INLINE Packet4cd pnot<Packet4cd>(const Packet4cd& a) { return Packet4cd(pnot(Packet8d(a.v))); }
 template<> EIGEN_STRONG_INLINE Packet4cd pand   <Packet4cd>(const Packet4cd& a, const Packet4cd& b) { return Packet4cd(pand(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet4cd por    <Packet4cd>(const Packet4cd& a, const Packet4cd& b) { return Packet4cd(por(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet4cd pxor   <Packet4cd>(const Packet4cd& a, const Packet4cd& b) { return Packet4cd(pxor(a.v,b.v)); }
 template<> EIGEN_STRONG_INLINE Packet4cd pandnot<Packet4cd>(const Packet4cd& a, const Packet4cd& b) { return Packet4cd(pandnot(a.v,b.v)); }
 
 template <>
 EIGEN_STRONG_INLINE Packet4cd pcmp_eq(const Packet4cd& a, const Packet4cd& b) {
@@ -333,39 +292,29 @@
   __m128d low = extract128<0>(a.v);
   EIGEN_ALIGN16 double res[2];
   _mm_store_pd(res, low);
   return std::complex<double>(res[0],res[1]);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4cd preverse(const Packet4cd& a) {
-  return Packet4cd(_mm512_shuffle_f64x2(a.v, a.v, EIGEN_SSE_SHUFFLE_MASK(3,2,1,0)));
+  return Packet4cd(_mm512_shuffle_f64x2(a.v, a.v, (shuffle_mask<3,2,1,0>::mask)));
 }
 
 template<> EIGEN_STRONG_INLINE std::complex<double> predux<Packet4cd>(const Packet4cd& a)
 {
   return predux(padd(Packet2cd(_mm512_extractf64x4_pd(a.v,0)),
                      Packet2cd(_mm512_extractf64x4_pd(a.v,1))));
 }
 
 template<> EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet4cd>(const Packet4cd& a)
 {
   return predux_mul(pmul(Packet2cd(_mm512_extractf64x4_pd(a.v,0)),
                          Packet2cd(_mm512_extractf64x4_pd(a.v,1))));
 }
 
-template<int Offset>
-struct palign_impl<Offset,Packet4cd>
-{
-  static EIGEN_STRONG_INLINE void run(Packet4cd& first, const Packet4cd& second)
-  {
-    if (Offset==0) return;
-    palign_impl<Offset*2,Packet8d>::run(first.v, second.v);
-  }
-};
-
 template<> struct conj_helper<Packet4cd, Packet4cd, false,true>
 {
   EIGEN_STRONG_INLINE Packet4cd pmadd(const Packet4cd& x, const Packet4cd& y, const Packet4cd& c) const
   { return padd(pmul(x,y),c); }
 
   EIGEN_STRONG_INLINE Packet4cd pmul(const Packet4cd& a, const Packet4cd& b) const
   {
@@ -446,47 +395,30 @@
   kernel.packet[5].v = _mm512_castpd_ps(pb.packet[5]);
   kernel.packet[6].v = _mm512_castpd_ps(pb.packet[6]);
   kernel.packet[7].v = _mm512_castpd_ps(pb.packet[7]);
 }
 
 EIGEN_DEVICE_FUNC inline void
 ptranspose(PacketBlock<Packet4cd,4>& kernel) {
-  __m512d T0 = _mm512_shuffle_f64x2(kernel.packet[0].v, kernel.packet[1].v, EIGEN_SSE_SHUFFLE_MASK(0,1,0,1)); // [a0 a1 b0 b1]
-  __m512d T1 = _mm512_shuffle_f64x2(kernel.packet[0].v, kernel.packet[1].v, EIGEN_SSE_SHUFFLE_MASK(2,3,2,3)); // [a2 a3 b2 b3]
-  __m512d T2 = _mm512_shuffle_f64x2(kernel.packet[2].v, kernel.packet[3].v, EIGEN_SSE_SHUFFLE_MASK(0,1,0,1)); // [c0 c1 d0 d1]
-  __m512d T3 = _mm512_shuffle_f64x2(kernel.packet[2].v, kernel.packet[3].v, EIGEN_SSE_SHUFFLE_MASK(2,3,2,3)); // [c2 c3 d2 d3]
+  __m512d T0 = _mm512_shuffle_f64x2(kernel.packet[0].v, kernel.packet[1].v, (shuffle_mask<0,1,0,1>::mask)); // [a0 a1 b0 b1]
+  __m512d T1 = _mm512_shuffle_f64x2(kernel.packet[0].v, kernel.packet[1].v, (shuffle_mask<2,3,2,3>::mask)); // [a2 a3 b2 b3]
+  __m512d T2 = _mm512_shuffle_f64x2(kernel.packet[2].v, kernel.packet[3].v, (shuffle_mask<0,1,0,1>::mask)); // [c0 c1 d0 d1]
+  __m512d T3 = _mm512_shuffle_f64x2(kernel.packet[2].v, kernel.packet[3].v, (shuffle_mask<2,3,2,3>::mask)); // [c2 c3 d2 d3]
 
-  kernel.packet[3] = Packet4cd(_mm512_shuffle_f64x2(T1, T3, EIGEN_SSE_SHUFFLE_MASK(1,3,1,3))); // [a3 b3 c3 d3]
-  kernel.packet[2] = Packet4cd(_mm512_shuffle_f64x2(T1, T3, EIGEN_SSE_SHUFFLE_MASK(0,2,0,2))); // [a2 b2 c2 d2]
-  kernel.packet[1] = Packet4cd(_mm512_shuffle_f64x2(T0, T2, EIGEN_SSE_SHUFFLE_MASK(1,3,1,3))); // [a1 b1 c1 d1]
-  kernel.packet[0] = Packet4cd(_mm512_shuffle_f64x2(T0, T2, EIGEN_SSE_SHUFFLE_MASK(0,2,0,2))); // [a0 b0 c0 d0]
+  kernel.packet[3] = Packet4cd(_mm512_shuffle_f64x2(T1, T3, (shuffle_mask<1,3,1,3>::mask))); // [a3 b3 c3 d3]
+  kernel.packet[2] = Packet4cd(_mm512_shuffle_f64x2(T1, T3, (shuffle_mask<0,2,0,2>::mask))); // [a2 b2 c2 d2]
+  kernel.packet[1] = Packet4cd(_mm512_shuffle_f64x2(T0, T2, (shuffle_mask<1,3,1,3>::mask))); // [a1 b1 c1 d1]
+  kernel.packet[0] = Packet4cd(_mm512_shuffle_f64x2(T0, T2, (shuffle_mask<0,2,0,2>::mask))); // [a0 b0 c0 d0]
 }
 
-template<> EIGEN_STRONG_INLINE Packet8cf pinsertfirst(const Packet8cf& a, std::complex<float> b)
-{
-  Packet2cf tmp = Packet2cf(_mm512_extractf32x4_ps(a.v,0));
-  tmp = pinsertfirst(tmp, b);
-  return Packet8cf( _mm512_insertf32x4(a.v, tmp.v, 0) );
+template<> EIGEN_STRONG_INLINE Packet4cd psqrt<Packet4cd>(const Packet4cd& a) {
+  return psqrt_complex<Packet4cd>(a);
 }
 
-template<> EIGEN_STRONG_INLINE Packet4cd pinsertfirst(const Packet4cd& a, std::complex<double> b)
-{
-  return Packet4cd(_mm512_castsi512_pd( _mm512_inserti32x4(_mm512_castpd_si512(a.v), _mm_castpd_si128(pset1<Packet1cd>(b).v), 0) ));
-}
-
-template<> EIGEN_STRONG_INLINE Packet8cf pinsertlast(const Packet8cf& a, std::complex<float> b)
-{
-  Packet2cf tmp = Packet2cf(_mm512_extractf32x4_ps(a.v,3) );
-  tmp = pinsertlast(tmp, b);
-  return Packet8cf( _mm512_insertf32x4(a.v, tmp.v, 3) );
-}
-
-template<> EIGEN_STRONG_INLINE Packet4cd pinsertlast(const Packet4cd& a, std::complex<double> b)
-{
-  return Packet4cd(_mm512_castsi512_pd( _mm512_inserti32x4(_mm512_castpd_si512(a.v), _mm_castpd_si128(pset1<Packet1cd>(b).v), 3) ));
+template<> EIGEN_STRONG_INLINE Packet8cf psqrt<Packet8cf>(const Packet8cf& a) {
+  return psqrt_complex<Packet8cf>(a);
 }
 
 } // end namespace internal
-
 } // end namespace Eigen
 
 #endif // EIGEN_COMPLEX_AVX512_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX512/MathFunctions.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX512/MathFunctions.h`

 * *Files 27% similar despite different names*

```diff
@@ -11,128 +11,63 @@
 #define THIRD_PARTY_EIGEN3_EIGEN_SRC_CORE_ARCH_AVX512_MATHFUNCTIONS_H_
 
 namespace Eigen {
 
 namespace internal {
 
 // Disable the code for older versions of gcc that don't support many of the required avx512 instrinsics.
-#if EIGEN_GNUC_AT_LEAST(5, 3) || EIGEN_COMP_CLANG
+#if EIGEN_GNUC_AT_LEAST(5, 3) || EIGEN_COMP_CLANG  || EIGEN_COMP_MSVC >= 1923
 
 #define _EIGEN_DECLARE_CONST_Packet16f(NAME, X) \
   const Packet16f p16f_##NAME = pset1<Packet16f>(X)
 
 #define _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(NAME, X) \
-  const Packet16f p16f_##NAME = (__m512)pset1<Packet16i>(X)
+  const Packet16f p16f_##NAME =  preinterpret<Packet16f,Packet16i>(pset1<Packet16i>(X))
 
 #define _EIGEN_DECLARE_CONST_Packet8d(NAME, X) \
   const Packet8d p8d_##NAME = pset1<Packet8d>(X)
 
 #define _EIGEN_DECLARE_CONST_Packet8d_FROM_INT64(NAME, X) \
   const Packet8d p8d_##NAME = _mm512_castsi512_pd(_mm512_set1_epi64(X))
 
-// Natural logarithm
-// Computes log(x) as log(2^e * m) = C*e + log(m), where the constant C =log(2)
-// and m is in the range [sqrt(1/2),sqrt(2)). In this range, the logarithm can
-// be easily approximated by a polynomial centered on m=1 for stability.
-#if defined(EIGEN_VECTORIZE_AVX512DQ)
+#define _EIGEN_DECLARE_CONST_Packet16bf(NAME, X) \
+  const Packet16bf p16bf_##NAME = pset1<Packet16bf>(X)
+
+#define _EIGEN_DECLARE_CONST_Packet16bf_FROM_INT(NAME, X) \
+  const Packet16bf p16bf_##NAME =  preinterpret<Packet16bf,Packet16i>(pset1<Packet16i>(X))
+
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
 plog<Packet16f>(const Packet16f& _x) {
-  Packet16f x = _x;
-  _EIGEN_DECLARE_CONST_Packet16f(1, 1.0f);
-  _EIGEN_DECLARE_CONST_Packet16f(half, 0.5f);
-  _EIGEN_DECLARE_CONST_Packet16f(126f, 126.0f);
+  return plog_float(_x);
+}
 
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(inv_mant_mask, ~0x7f800000);
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8d
+plog<Packet8d>(const Packet8d& _x) {
+  return plog_double(_x);
+}
 
-  // The smallest non denormalized float number.
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(min_norm_pos, 0x00800000);
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(minus_inf, 0xff800000);
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(pos_inf, 0x7f800000);
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(nan, 0x7fc00000);
-
-  // Polynomial coefficients.
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_SQRTHF, 0.707106781186547524f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p0, 7.0376836292E-2f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p1, -1.1514610310E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p2, 1.1676998740E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p3, -1.2420140846E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p4, +1.4249322787E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p5, -1.6668057665E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p6, +2.0000714765E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p7, -2.4999993993E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_p8, +3.3333331174E-1f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_q1, -2.12194440e-4f);
-  _EIGEN_DECLARE_CONST_Packet16f(cephes_log_q2, 0.693359375f);
-
-  // invalid_mask is set to true when x is NaN
-  __mmask16 invalid_mask =  _mm512_cmp_ps_mask(x, _mm512_setzero_ps(), _CMP_NGE_UQ);
-  __mmask16 iszero_mask  =  _mm512_cmp_ps_mask(x, _mm512_setzero_ps(), _CMP_EQ_OQ);
-      
-  // Truncate input values to the minimum positive normal.
-  x = pmax(x, p16f_min_norm_pos);
-
-  // Extract the shifted exponents.
-  Packet16f emm0 = _mm512_cvtepi32_ps(_mm512_srli_epi32((__m512i)x, 23));
-  Packet16f e = _mm512_sub_ps(emm0, p16f_126f);
-
-  // Set the exponents to -1, i.e. x are in the range [0.5,1).
-  x = _mm512_and_ps(x, p16f_inv_mant_mask);
-  x = _mm512_or_ps(x, p16f_half);
-
-  // part2: Shift the inputs from the range [0.5,1) to [sqrt(1/2),sqrt(2))
-  // and shift by -1. The values are then centered around 0, which improves
-  // the stability of the polynomial evaluation.
-  //   if( x < SQRTHF ) {
-  //     e -= 1;
-  //     x = x + x - 1.0;
-  //   } else { x = x - 1.0; }
-  __mmask16 mask = _mm512_cmp_ps_mask(x, p16f_cephes_SQRTHF, _CMP_LT_OQ);
-  Packet16f tmp = _mm512_mask_blend_ps(mask, _mm512_setzero_ps(), x);
-  x = psub(x, p16f_1);
-  e = psub(e, _mm512_mask_blend_ps(mask, _mm512_setzero_ps(), p16f_1));
-  x = padd(x, tmp);
+F16_PACKET_FUNCTION(Packet16f, Packet16h, plog)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, plog)
 
-  Packet16f x2 = pmul(x, x);
-  Packet16f x3 = pmul(x2, x);
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
+plog2<Packet16f>(const Packet16f& _x) {
+  return plog2_float(_x);
+}
 
-  // Evaluate the polynomial approximant of degree 8 in three parts, probably
-  // to improve instruction-level parallelism.
-  Packet16f y, y1, y2;
-  y = pmadd(p16f_cephes_log_p0, x, p16f_cephes_log_p1);
-  y1 = pmadd(p16f_cephes_log_p3, x, p16f_cephes_log_p4);
-  y2 = pmadd(p16f_cephes_log_p6, x, p16f_cephes_log_p7);
-  y = pmadd(y, x, p16f_cephes_log_p2);
-  y1 = pmadd(y1, x, p16f_cephes_log_p5);
-  y2 = pmadd(y2, x, p16f_cephes_log_p8);
-  y = pmadd(y, x3, y1);
-  y = pmadd(y, x3, y2);
-  y = pmul(y, x3);
-
-  // Add the logarithm of the exponent back to the result of the interpolation.
-  y1 = pmul(e, p16f_cephes_log_q1);
-  tmp = pmul(x2, p16f_half);
-  y = padd(y, y1);
-  x = psub(x, tmp);
-  y2 = pmul(e, p16f_cephes_log_q2);
-  x = padd(x, y);
-  x = padd(x, y2);
-
-  __mmask16 pos_inf_mask = _mm512_cmp_ps_mask(_x,p16f_pos_inf,_CMP_EQ_OQ);
-  // Filter out invalid inputs, i.e.:
-  //  - negative arg will be NAN,
-  //  - 0 will be -INF.
-  //  - +INF will be +INF
-  return _mm512_mask_blend_ps(iszero_mask,
-            _mm512_mask_blend_ps(invalid_mask,
-              _mm512_mask_blend_ps(pos_inf_mask,x,p16f_pos_inf),
-              p16f_nan),
-            p16f_minus_inf);
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8d
+plog2<Packet8d>(const Packet8d& _x) {
+  return plog2_double(_x);
 }
-#endif
+
+F16_PACKET_FUNCTION(Packet16f, Packet16h, plog2)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, plog2)
 
 // Exponential function. Works by writing "x = m*log(2) + r" where
 // "m = floor(x/log(2)+1/2)" and "r" is the remainder. The result is then
 // "exp(x) = 2^m*exp(r)" where exp(r) is in the range [-1,1).
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
 pexp<Packet16f>(const Packet16f& _x) {
@@ -160,102 +95,68 @@
   Packet16f m = _mm512_floor_ps(pmadd(x, p16f_cephes_LOG2EF, p16f_half));
 
   // Get r = x - m*ln(2). Note that we can do this without losing more than one
   // ulp precision due to the FMA instruction.
   _EIGEN_DECLARE_CONST_Packet16f(nln2, -0.6931471805599453f);
   Packet16f r = _mm512_fmadd_ps(m, p16f_nln2, x);
   Packet16f r2 = pmul(r, r);
+  Packet16f r3 = pmul(r2, r);
 
-  // TODO(gonnet): Split into odd/even polynomials and try to exploit
-  //               instruction-level parallelism.
-  Packet16f y = p16f_cephes_exp_p0;
-  y = pmadd(y, r, p16f_cephes_exp_p1);
-  y = pmadd(y, r, p16f_cephes_exp_p2);
-  y = pmadd(y, r, p16f_cephes_exp_p3);
-  y = pmadd(y, r, p16f_cephes_exp_p4);
-  y = pmadd(y, r, p16f_cephes_exp_p5);
-  y = pmadd(y, r2, r);
-  y = padd(y, p16f_1);
+  // Evaluate the polynomial approximant,improved by instruction-level parallelism.
+  Packet16f y, y1, y2;
+  y  = pmadd(p16f_cephes_exp_p0, r, p16f_cephes_exp_p1);
+  y1 = pmadd(p16f_cephes_exp_p3, r, p16f_cephes_exp_p4);
+  y2 = padd(r, p16f_1);
+  y  = pmadd(y, r, p16f_cephes_exp_p2);
+  y1 = pmadd(y1, r, p16f_cephes_exp_p5);
+  y  = pmadd(y, r3, y1);
+  y  = pmadd(y, r2, y2);
 
   // Build emm0 = 2^m.
   Packet16i emm0 = _mm512_cvttps_epi32(padd(m, p16f_127));
   emm0 = _mm512_slli_epi32(emm0, 23);
 
   // Return 2^m * exp(r).
   return pmax(pmul(y, _mm512_castsi512_ps(emm0)), _x);
 }
 
-/*template <>
+template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8d
 pexp<Packet8d>(const Packet8d& _x) {
-  Packet8d x = _x;
+  return pexp_double(_x);
+}
 
-  _EIGEN_DECLARE_CONST_Packet8d(1, 1.0);
-  _EIGEN_DECLARE_CONST_Packet8d(2, 2.0);
+F16_PACKET_FUNCTION(Packet16f, Packet16h, pexp)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, pexp)
 
-  _EIGEN_DECLARE_CONST_Packet8d(exp_hi, 709.437);
-  _EIGEN_DECLARE_CONST_Packet8d(exp_lo, -709.436139303);
+template <>
+EIGEN_STRONG_INLINE Packet16h pfrexp(const Packet16h& a, Packet16h& exponent) {
+  Packet16f fexponent;
+  const Packet16h out = float2half(pfrexp<Packet16f>(half2float(a), fexponent));
+  exponent = float2half(fexponent);
+  return out;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16h pldexp(const Packet16h& a, const Packet16h& exponent) {
+  return float2half(pldexp<Packet16f>(half2float(a), half2float(exponent)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pfrexp(const Packet16bf& a, Packet16bf& exponent) {
+  Packet16f fexponent;
+  const Packet16bf out = F32ToBf16(pfrexp<Packet16f>(Bf16ToF32(a), fexponent));
+  exponent = F32ToBf16(fexponent);
+  return out;
+}
 
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_LOG2EF, 1.4426950408889634073599);
-
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_p0, 1.26177193074810590878e-4);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_p1, 3.02994407707441961300e-2);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_p2, 9.99999999999999999910e-1);
-
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_q0, 3.00198505138664455042e-6);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_q1, 2.52448340349684104192e-3);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_q2, 2.27265548208155028766e-1);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_q3, 2.00000000000000000009e0);
-
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_C1, 0.693145751953125);
-  _EIGEN_DECLARE_CONST_Packet8d(cephes_exp_C2, 1.42860682030941723212e-6);
-
-  // clamp x
-  x = pmax(pmin(x, p8d_exp_hi), p8d_exp_lo);
-
-  // Express exp(x) as exp(g + n*log(2)).
-  const Packet8d n =
-      _mm512_mul_round_pd(p8d_cephes_LOG2EF, x, _MM_FROUND_TO_NEAREST_INT);
-
-  // Get the remainder modulo log(2), i.e. the "g" described above. Subtract
-  // n*log(2) out in two steps, i.e. n*C1 + n*C2, C1+C2=log2 to get the last
-  // digits right.
-  const Packet8d nC1 = pmul(n, p8d_cephes_exp_C1);
-  const Packet8d nC2 = pmul(n, p8d_cephes_exp_C2);
-  x = psub(x, nC1);
-  x = psub(x, nC2);
-
-  const Packet8d x2 = pmul(x, x);
-
-  // Evaluate the numerator polynomial of the rational interpolant.
-  Packet8d px = p8d_cephes_exp_p0;
-  px = pmadd(px, x2, p8d_cephes_exp_p1);
-  px = pmadd(px, x2, p8d_cephes_exp_p2);
-  px = pmul(px, x);
-
-  // Evaluate the denominator polynomial of the rational interpolant.
-  Packet8d qx = p8d_cephes_exp_q0;
-  qx = pmadd(qx, x2, p8d_cephes_exp_q1);
-  qx = pmadd(qx, x2, p8d_cephes_exp_q2);
-  qx = pmadd(qx, x2, p8d_cephes_exp_q3);
-
-  // I don't really get this bit, copied from the SSE2 routines, so...
-  // TODO(gonnet): Figure out what is going on here, perhaps find a better
-  // rational interpolant?
-  x = _mm512_div_pd(px, psub(qx, px));
-  x = pmadd(p8d_2, x, p8d_1);
-
-  // Build e=2^n.
-  const Packet8d e = _mm512_castsi512_pd(_mm512_slli_epi64(
-      _mm512_add_epi64(_mm512_cvtpd_epi64(n), _mm512_set1_epi64(1023)), 52));
-
-  // Construct the result 2^n * exp(g) = e * x. The max is used to catch
-  // non-finite values in the input.
-  return pmax(pmul(x, e), _x);
-  }*/
+template <>
+EIGEN_STRONG_INLINE Packet16bf pldexp(const Packet16bf& a, const Packet16bf& exponent) {
+  return F32ToBf16(pldexp<Packet16f>(Bf16ToF32(a), Bf16ToF32(exponent)));
+}
 
 // Functions for sqrt.
 // The EIGEN_FAST_MATH version uses the _mm_rsqrt_ps approximation and one step
 // of Newton's method, at a cost of 1-2 bits of precision as opposed to the
 // exact solution. The main advantage of this approach is not just speed, but
 // also the fact that it can be inlined and pipelined with other computations,
 // further reducing its effective latency.
@@ -298,90 +199,137 @@
   return _mm512_mask_blend_pd(denormal_mask, pmul(_x,x), _mm512_setzero_pd());
 }
 #else
 template <>
 EIGEN_STRONG_INLINE Packet16f psqrt<Packet16f>(const Packet16f& x) {
   return _mm512_sqrt_ps(x);
 }
+
 template <>
 EIGEN_STRONG_INLINE Packet8d psqrt<Packet8d>(const Packet8d& x) {
   return _mm512_sqrt_pd(x);
 }
 #endif
 
-// Functions for rsqrt.
-// Almost identical to the sqrt routine, just leave out the last multiplication
-// and fill in NaN/Inf where needed. Note that this function only exists as an
-// iterative version for doubles since there is no instruction for diretly
-// computing the reciprocal square root in AVX-512.
-#ifdef EIGEN_FAST_MATH
+F16_PACKET_FUNCTION(Packet16f, Packet16h, psqrt)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, psqrt)
+
+// prsqrt for float.
+#if defined(EIGEN_VECTORIZE_AVX512ER)
+
+template <>
+EIGEN_STRONG_INLINE Packet16f prsqrt<Packet16f>(const Packet16f& x) {
+  return _mm512_rsqrt28_ps(x);
+}
+#elif EIGEN_FAST_MATH
+
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
 prsqrt<Packet16f>(const Packet16f& _x) {
   _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(inf, 0x7f800000);
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(nan, 0x7fc00000);
   _EIGEN_DECLARE_CONST_Packet16f(one_point_five, 1.5f);
   _EIGEN_DECLARE_CONST_Packet16f(minus_half, -0.5f);
-  _EIGEN_DECLARE_CONST_Packet16f_FROM_INT(flt_min, 0x00800000);
 
   Packet16f neg_half = pmul(_x, p16f_minus_half);
 
-  // select only the inverse sqrt of positive normal inputs (denormals are
-  // flushed to zero and cause infs as well).
-  __mmask16 le_zero_mask = _mm512_cmp_ps_mask(_x, p16f_flt_min, _CMP_LT_OQ);
-  Packet16f x = _mm512_mask_blend_ps(le_zero_mask, _mm512_rsqrt14_ps(_x), _mm512_setzero_ps());
-
-  // Fill in NaNs and Infs for the negative/zero entries.
-  __mmask16 neg_mask = _mm512_cmp_ps_mask(_x, _mm512_setzero_ps(), _CMP_LT_OQ);
-  Packet16f infs_and_nans = _mm512_mask_blend_ps(
-      neg_mask, _mm512_mask_blend_ps(le_zero_mask, _mm512_setzero_ps(), p16f_inf), p16f_nan);
-
-  // Do a single step of Newton's iteration.
-  x = pmul(x, pmadd(neg_half, pmul(x, x), p16f_one_point_five));
+  // Identity infinite, negative and denormal arguments.
+  __mmask16 inf_mask = _mm512_cmp_ps_mask(_x, p16f_inf, _CMP_EQ_OQ);
+  __mmask16 not_pos_mask = _mm512_cmp_ps_mask(_x, _mm512_setzero_ps(), _CMP_LE_OQ);
+  __mmask16 not_finite_pos_mask = not_pos_mask | inf_mask;
+
+  // Compute an approximate result using the rsqrt intrinsic, forcing +inf
+  // for denormals for consistency with AVX and SSE implementations.
+  Packet16f y_approx = _mm512_rsqrt14_ps(_x);
+
+  // Do a single step of Newton-Raphson iteration to improve the approximation.
+  // This uses the formula y_{n+1} = y_n * (1.5 - y_n * (0.5 * x) * y_n).
+  // It is essential to evaluate the inner term like this because forming
+  // y_n^2 may over- or underflow.
+  Packet16f y_newton = pmul(y_approx, pmadd(y_approx, pmul(neg_half, y_approx), p16f_one_point_five));
+
+  // Select the result of the Newton-Raphson step for positive finite arguments.
+  // For other arguments, choose the output of the intrinsic. This will
+  // return rsqrt(+inf) = 0, rsqrt(x) = NaN if x < 0, and rsqrt(0) = +inf.
+  return _mm512_mask_blend_ps(not_finite_pos_mask, y_newton, y_approx);
+}
+#else
 
-  // Insert NaNs and Infs in all the right places.
-  return _mm512_mask_blend_ps(le_zero_mask, x, infs_and_nans);
+template <>
+EIGEN_STRONG_INLINE Packet16f prsqrt<Packet16f>(const Packet16f& x) {
+  _EIGEN_DECLARE_CONST_Packet16f(one, 1.0f);
+  return _mm512_div_ps(p16f_one, _mm512_sqrt_ps(x));
 }
+#endif
+
+F16_PACKET_FUNCTION(Packet16f, Packet16h, prsqrt)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, prsqrt)
 
+// prsqrt for double.
+#if EIGEN_FAST_MATH
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet8d
 prsqrt<Packet8d>(const Packet8d& _x) {
-  _EIGEN_DECLARE_CONST_Packet8d_FROM_INT64(inf, 0x7ff0000000000000LL);
-  _EIGEN_DECLARE_CONST_Packet8d_FROM_INT64(nan, 0x7ff1000000000000LL);
   _EIGEN_DECLARE_CONST_Packet8d(one_point_five, 1.5);
   _EIGEN_DECLARE_CONST_Packet8d(minus_half, -0.5);
-  _EIGEN_DECLARE_CONST_Packet8d_FROM_INT64(dbl_min, 0x0010000000000000LL);
+  _EIGEN_DECLARE_CONST_Packet8d_FROM_INT64(inf, 0x7ff0000000000000LL);
 
   Packet8d neg_half = pmul(_x, p8d_minus_half);
 
-  // select only the inverse sqrt of positive normal inputs (denormals are
-  // flushed to zero and cause infs as well).
-  __mmask8 le_zero_mask = _mm512_cmp_pd_mask(_x, p8d_dbl_min, _CMP_LT_OQ);
-  Packet8d x = _mm512_mask_blend_pd(le_zero_mask, _mm512_rsqrt14_pd(_x), _mm512_setzero_pd());
-
-  // Fill in NaNs and Infs for the negative/zero entries.
-  __mmask8 neg_mask = _mm512_cmp_pd_mask(_x, _mm512_setzero_pd(), _CMP_LT_OQ);
-  Packet8d infs_and_nans = _mm512_mask_blend_pd(
-      neg_mask, _mm512_mask_blend_pd(le_zero_mask, _mm512_setzero_pd(), p8d_inf), p8d_nan);
-
-  // Do a first step of Newton's iteration.
-  x = pmul(x, pmadd(neg_half, pmul(x, x), p8d_one_point_five));
-
-  // Do a second step of Newton's iteration.
-  x = pmul(x, pmadd(neg_half, pmul(x, x), p8d_one_point_five));
-
-  // Insert NaNs and Infs in all the right places.
-  return _mm512_mask_blend_pd(le_zero_mask, x, infs_and_nans);
+  // Identity infinite, negative and denormal arguments.
+  __mmask8 inf_mask = _mm512_cmp_pd_mask(_x, p8d_inf, _CMP_EQ_OQ);
+  __mmask8 not_pos_mask = _mm512_cmp_pd_mask(_x, _mm512_setzero_pd(), _CMP_LE_OQ);
+  __mmask8 not_finite_pos_mask = not_pos_mask | inf_mask;
+
+  // Compute an approximate result using the rsqrt intrinsic, forcing +inf
+  // for denormals for consistency with AVX and SSE implementations.
+#if defined(EIGEN_VECTORIZE_AVX512ER)
+  Packet8d y_approx = _mm512_rsqrt28_pd(_x);
+#else
+  Packet8d y_approx = _mm512_rsqrt14_pd(_x);
+#endif
+  // Do one or two steps of Newton-Raphson's to improve the approximation, depending on the
+  // starting accuracy (either 2^-14 or 2^-28, depending on whether AVX512ER is available).
+  // The Newton-Raphson algorithm has quadratic convergence and roughly doubles the number
+  // of correct digits for each step.
+  // This uses the formula y_{n+1} = y_n * (1.5 - y_n * (0.5 * x) * y_n).
+  // It is essential to evaluate the inner term like this because forming
+  // y_n^2 may over- or underflow.
+  Packet8d y_newton = pmul(y_approx, pmadd(neg_half, pmul(y_approx, y_approx), p8d_one_point_five));
+#if !defined(EIGEN_VECTORIZE_AVX512ER)
+  y_newton = pmul(y_newton, pmadd(y_newton, pmul(neg_half, y_newton), p8d_one_point_five));
+#endif
+  // Select the result of the Newton-Raphson step for positive finite arguments.
+  // For other arguments, choose the output of the intrinsic. This will
+  // return rsqrt(+inf) = 0, rsqrt(x) = NaN if x < 0, and rsqrt(0) = +inf.
+  return _mm512_mask_blend_pd(not_finite_pos_mask, y_newton, y_approx);
 }
-#elif defined(EIGEN_VECTORIZE_AVX512ER)
+#else
 template <>
-EIGEN_STRONG_INLINE Packet16f prsqrt<Packet16f>(const Packet16f& x) {
-  return _mm512_rsqrt28_ps(x);
+EIGEN_STRONG_INLINE Packet8d prsqrt<Packet8d>(const Packet8d& x) {
+  _EIGEN_DECLARE_CONST_Packet8d(one, 1.0f);
+  return _mm512_div_pd(p8d_one, _mm512_sqrt_pd(x));
 }
 #endif
+
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet16f plog1p<Packet16f>(const Packet16f& _x) {
+  return generic_plog1p(_x);
+}
+
+F16_PACKET_FUNCTION(Packet16f, Packet16h, plog1p)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, plog1p)
+
+template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
+Packet16f pexpm1<Packet16f>(const Packet16f& _x) {
+  return generic_expm1(_x);
+}
+
+F16_PACKET_FUNCTION(Packet16f, Packet16h, pexpm1)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, pexpm1)
+
 #endif
 
 
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
 psin<Packet16f>(const Packet16f& _x) {
   return psin_float(_x);
@@ -389,12 +337,26 @@
 
 template <>
 EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
 pcos<Packet16f>(const Packet16f& _x) {
   return pcos_float(_x);
 }
 
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet16f
+ptanh<Packet16f>(const Packet16f& _x) {
+  return internal::generic_fast_tanh_float(_x);
+}
+
+F16_PACKET_FUNCTION(Packet16f, Packet16h, psin)
+F16_PACKET_FUNCTION(Packet16f, Packet16h, pcos)
+F16_PACKET_FUNCTION(Packet16f, Packet16h, ptanh)
+
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, psin)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, pcos)
+BF16_PACKET_FUNCTION(Packet16f, Packet16bf, ptanh)
+
 }  // end namespace internal
 
 }  // end namespace Eigen
 
 #endif  // THIRD_PARTY_EIGEN3_EIGEN_SRC_CORE_ARCH_AVX512_MATHFUNCTIONS_H_
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AVX512/PacketMath.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX512/PacketMath.h`

 * *Files 27% similar despite different names*

```diff
@@ -27,65 +27,133 @@
 #define EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #endif
 #endif
 
 typedef __m512 Packet16f;
 typedef __m512i Packet16i;
 typedef __m512d Packet8d;
+typedef eigen_packet_wrapper<__m256i, 1> Packet16h;
+typedef eigen_packet_wrapper<__m256i, 2> Packet16bf;
 
 template <>
 struct is_arithmetic<__m512> {
   enum { value = true };
 };
 template <>
 struct is_arithmetic<__m512i> {
   enum { value = true };
 };
 template <>
 struct is_arithmetic<__m512d> {
   enum { value = true };
 };
 
+template<> struct is_arithmetic<Packet16h> { enum { value = true }; };
+
+template <>
+struct packet_traits<half> : default_packet_traits {
+  typedef Packet16h type;
+  // There is no half-size packet for Packet16h.
+  typedef Packet16h half;
+  enum {
+    Vectorizable = 1,
+    AlignedOnScalar = 1,
+    size = 16,
+    HasHalfPacket = 1,
+
+    HasCmp    = 1,
+    HasAdd    = 1,
+    HasSub    = 1,
+    HasMul    = 1,
+    HasDiv    = 1,
+    HasNegate = 1,
+    HasAbs    = 1,
+    HasAbs2   = 0,
+    HasMin    = 1,
+    HasMax    = 1,
+    HasConj   = 1,
+    HasSetLinear = 0,
+    HasLog    = 1,
+    HasLog1p  = 1,
+    HasExpm1  = 1,
+    HasExp    = 1,
+    HasSqrt   = 1,
+    HasRsqrt  = 1,
+    HasSin    = EIGEN_FAST_MATH,
+    HasCos    = EIGEN_FAST_MATH,
+    HasTanh   = EIGEN_FAST_MATH,
+    HasErf    = EIGEN_FAST_MATH,
+    HasBlend = 0,
+    HasRound  = 1,
+    HasFloor  = 1,
+    HasCeil   = 1,
+    HasRint   = 1,
+    HasBessel = 1,
+    HasNdtri  = 1
+  };
+};
+
 template<> struct packet_traits<float>  : default_packet_traits
 {
   typedef Packet16f type;
   typedef Packet8f half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 16,
     HasHalfPacket = 1,
+
+    HasAbs = 1,
+    HasMin    = 1,
+    HasMax    = 1,
+    HasConj   = 1,
     HasBlend = 0,
     HasSin = EIGEN_FAST_MATH,
     HasCos = EIGEN_FAST_MATH,
 #if EIGEN_GNUC_AT_LEAST(5, 3) || (!EIGEN_COMP_GNUC_STRICT)
-#ifdef EIGEN_VECTORIZE_AVX512DQ
     HasLog = 1,
-#endif
+    HasLog1p  = 1,
+    HasExpm1  = 1,
+    HasNdtri = 1,
+    HasBessel  = 1,
     HasExp = 1,
     HasSqrt = EIGEN_FAST_MATH,
     HasRsqrt = EIGEN_FAST_MATH,
+    HasTanh = EIGEN_FAST_MATH,
+    HasErf = EIGEN_FAST_MATH,
 #endif
-    HasDiv = 1
+    HasCmp  = 1,
+    HasDiv = 1,
+    HasRound = 1,
+    HasFloor = 1,
+    HasCeil = 1,
+    HasRint = 1
   };
  };
 template<> struct packet_traits<double> : default_packet_traits
 {
   typedef Packet8d type;
   typedef Packet4d half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 8,
     HasHalfPacket = 1,
 #if EIGEN_GNUC_AT_LEAST(5, 3) || (!EIGEN_COMP_GNUC_STRICT)
+    HasLog  = 1,
+    HasExp = 1,
     HasSqrt = EIGEN_FAST_MATH,
     HasRsqrt = EIGEN_FAST_MATH,
 #endif
-    HasDiv = 1
+    HasCmp  = 1,
+    HasDiv = 1,
+    HasRound = 1,
+    HasFloor = 1,
+    HasCeil = 1,
+    HasRint = 1
   };
 };
 
 /* TODO Implement AVX512 for integers
 template<> struct packet_traits<int>    : default_packet_traits
 {
   typedef Packet16i type;
@@ -114,14 +182,21 @@
 template <>
 struct unpacket_traits<Packet16i> {
   typedef int type;
   typedef Packet8i half;
   enum { size = 16, alignment=Aligned64, vectorizable=false, masked_load_available=false, masked_store_available=false };
 };
 
+template<>
+struct unpacket_traits<Packet16h> {
+  typedef Eigen::half type;
+  typedef Packet8h half;
+  enum {size=16, alignment=Aligned32, vectorizable=true, masked_load_available=false, masked_store_available=false};
+};
+
 template <>
 EIGEN_STRONG_INLINE Packet16f pset1<Packet16f>(const float& from) {
   return _mm512_set1_ps(from);
 }
 template <>
 EIGEN_STRONG_INLINE Packet8d pset1<Packet8d>(const double& from) {
   return _mm512_set1_pd(from);
@@ -133,14 +208,36 @@
 
 template <>
 EIGEN_STRONG_INLINE Packet16f pset1frombits<Packet16f>(unsigned int from) {
   return _mm512_castsi512_ps(_mm512_set1_epi32(from));
 }
 
 template <>
+EIGEN_STRONG_INLINE Packet8d pset1frombits<Packet8d>(const numext::uint64_t from) {
+  return _mm512_castsi512_pd(_mm512_set1_epi64(from));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16f pzero(const Packet16f& /*a*/) { return _mm512_setzero_ps(); }
+template<> EIGEN_STRONG_INLINE Packet8d pzero(const Packet8d& /*a*/) { return _mm512_setzero_pd(); }
+template<> EIGEN_STRONG_INLINE Packet16i pzero(const Packet16i& /*a*/) { return _mm512_setzero_si512(); }
+
+template<> EIGEN_STRONG_INLINE Packet16f peven_mask(const Packet16f& /*a*/) {
+  return _mm512_castsi512_ps(_mm512_set_epi32(0, -1, 0, -1, 0, -1, 0, -1,
+                                              0, -1, 0, -1, 0, -1, 0, -1));
+}
+template<> EIGEN_STRONG_INLINE Packet16i peven_mask(const Packet16i& /*a*/) {
+  return _mm512_set_epi32(0, -1, 0, -1, 0, -1, 0, -1,
+                          0, -1, 0, -1, 0, -1, 0, -1);
+}
+template<> EIGEN_STRONG_INLINE Packet8d peven_mask(const Packet8d& /*a*/) {
+  return _mm512_castsi512_pd(_mm512_set_epi32(0, 0, -1, -1, 0, 0, -1, -1,
+                                              0, 0, -1, -1, 0, 0, -1, -1));
+}
+
+template <>
 EIGEN_STRONG_INLINE Packet16f pload1<Packet16f>(const float* from) {
   return _mm512_broadcastss_ps(_mm_load_ps1(from));
 }
 template <>
 EIGEN_STRONG_INLINE Packet8d pload1<Packet8d>(const double* from) {
   return _mm512_set1_pd(*from);
 }
@@ -221,15 +318,15 @@
 EIGEN_STRONG_INLINE Packet8d pmul<Packet8d>(const Packet8d& a,
                                             const Packet8d& b) {
   return _mm512_mul_pd(a, b);
 }
 template <>
 EIGEN_STRONG_INLINE Packet16i pmul<Packet16i>(const Packet16i& a,
                                               const Packet16i& b) {
-  return _mm512_mul_epi32(a, b);
+  return _mm512_mullo_epi32(a, b);
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet16f pdiv<Packet16f>(const Packet16f& a,
                                               const Packet16f& b) {
   return _mm512_div_ps(a, b);
 }
@@ -292,14 +389,49 @@
 template <>
 EIGEN_STRONG_INLINE Packet8d pmax<Packet8d>(const Packet8d& a,
                                             const Packet8d& b) {
   // Arguments are reversed to match NaN propagation behavior of std::max.
   return _mm512_max_pd(b, a);
 }
 
+// Add specializations for min/max with prescribed NaN progation.
+template<>
+EIGEN_STRONG_INLINE Packet16f pmin<PropagateNumbers, Packet16f>(const Packet16f& a, const Packet16f& b) {
+  return pminmax_propagate_numbers(a, b, pmin<Packet16f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet8d pmin<PropagateNumbers, Packet8d>(const Packet8d& a, const Packet8d& b) {
+  return pminmax_propagate_numbers(a, b, pmin<Packet8d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet16f pmax<PropagateNumbers, Packet16f>(const Packet16f& a, const Packet16f& b) {
+  return pminmax_propagate_numbers(a, b, pmax<Packet16f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet8d pmax<PropagateNumbers, Packet8d>(const Packet8d& a, const Packet8d& b) {
+  return pminmax_propagate_numbers(a, b, pmax<Packet8d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet16f pmin<PropagateNaN, Packet16f>(const Packet16f& a, const Packet16f& b) {
+  return pminmax_propagate_nan(a, b, pmin<Packet16f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet8d pmin<PropagateNaN, Packet8d>(const Packet8d& a, const Packet8d& b) {
+  return pminmax_propagate_nan(a, b, pmin<Packet8d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet16f pmax<PropagateNaN, Packet16f>(const Packet16f& a, const Packet16f& b) {
+  return pminmax_propagate_nan(a, b, pmax<Packet16f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet8d pmax<PropagateNaN, Packet8d>(const Packet8d& a, const Packet8d& b) {
+  return pminmax_propagate_nan(a, b, pmax<Packet8d>);
+}
+
+
 #ifdef EIGEN_VECTORIZE_AVX512DQ
 template<int I_> EIGEN_STRONG_INLINE Packet8f extract256(Packet16f x) { return _mm512_extractf32x8_ps(x,I_); }
 template<int I_> EIGEN_STRONG_INLINE Packet2d extract128(Packet8d x) { return _mm512_extractf64x2_pd(x,I_); }
 EIGEN_STRONG_INLINE Packet16f cat256(Packet8f a, Packet8f b) { return _mm512_insertf32x8(_mm512_castps256_ps512(a),b,1); }
 #else
 // AVX512F does not define _mm512_extractf32x8_ps to extract _m256 from _m512
 template<int I_> EIGEN_STRONG_INLINE Packet8f extract256(Packet16f x) {
@@ -313,50 +445,96 @@
 
 EIGEN_STRONG_INLINE Packet16f cat256(Packet8f a, Packet8f b) {
   return _mm512_castsi512_ps(_mm512_inserti64x4(_mm512_castsi256_si512(_mm256_castps_si256(a)),
                                                 _mm256_castps_si256(b),1));
 }
 #endif
 
+// Helper function for bit packing snippet of low precision comparison.
+// It packs the flags from 32x16 to 16x16.
+EIGEN_STRONG_INLINE __m256i Pack32To16(Packet16f rf) {
+  // Split data into small pieces and handle with AVX instructions
+  // to guarantee internal order of vector.
+  // Operation:
+  //   dst[15:0]    := Saturate16(rf[31:0])
+  //   dst[31:16]   := Saturate16(rf[63:32])
+  //   ...
+  //   dst[255:240] := Saturate16(rf[255:224])
+  __m256i lo = _mm256_castps_si256(extract256<0>(rf));
+  __m256i hi = _mm256_castps_si256(extract256<1>(rf));
+  __m128i result_lo = _mm_packs_epi32(_mm256_extractf128_si256(lo, 0),
+                                      _mm256_extractf128_si256(lo, 1));
+  __m128i result_hi = _mm_packs_epi32(_mm256_extractf128_si256(hi, 0),
+                                      _mm256_extractf128_si256(hi, 1));
+  return _mm256_insertf128_si256(_mm256_castsi128_si256(result_lo), result_hi, 1);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16f pcmp_eq(const Packet16f& a, const Packet16f& b) {
+  __mmask16 mask = _mm512_cmp_ps_mask(a, b, _CMP_EQ_OQ);
+  return _mm512_castsi512_ps(
+      _mm512_mask_set1_epi32(_mm512_set1_epi32(0), mask, 0xffffffffu));
+}
 template<> EIGEN_STRONG_INLINE Packet16f pcmp_le(const Packet16f& a, const Packet16f& b) {
   __mmask16 mask = _mm512_cmp_ps_mask(a, b, _CMP_LE_OQ);
   return _mm512_castsi512_ps(
       _mm512_mask_set1_epi32(_mm512_set1_epi32(0), mask, 0xffffffffu));
 }
 
 template<> EIGEN_STRONG_INLINE Packet16f pcmp_lt(const Packet16f& a, const Packet16f& b) {
   __mmask16 mask = _mm512_cmp_ps_mask(a, b, _CMP_LT_OQ);
   return _mm512_castsi512_ps(
       _mm512_mask_set1_epi32(_mm512_set1_epi32(0), mask, 0xffffffffu));
 }
 
 template<> EIGEN_STRONG_INLINE Packet16f pcmp_lt_or_nan(const Packet16f& a, const Packet16f& b) {
-  __mmask16 mask = _mm512_cmp_ps_mask(a, b, _CMP_NGT_UQ);
+  __mmask16 mask = _mm512_cmp_ps_mask(a, b, _CMP_NGE_UQ);
   return _mm512_castsi512_ps(
       _mm512_mask_set1_epi32(_mm512_set1_epi32(0), mask, 0xffffffffu));
 }
 
 template<> EIGEN_STRONG_INLINE Packet16i pcmp_eq(const Packet16i& a, const Packet16i& b) {
   __mmask16 mask = _mm512_cmp_epi32_mask(a, b, _CMP_EQ_OQ);
   return _mm512_mask_set1_epi32(_mm512_set1_epi32(0), mask, 0xffffffffu);
 }
 
-template <>
-EIGEN_STRONG_INLINE Packet16f pcmp_eq(const Packet16f& a, const Packet16f& b) {
-  __mmask16 mask = _mm512_cmp_ps_mask(a, b, _CMP_EQ_OQ);
-  return _mm512_castsi512_ps(
-      _mm512_mask_set1_epi32(_mm512_set1_epi32(0), mask, 0xffffffffu));
-}
 
 template <>
 EIGEN_STRONG_INLINE Packet8d pcmp_eq(const Packet8d& a, const Packet8d& b) {
   __mmask8 mask = _mm512_cmp_pd_mask(a, b, _CMP_EQ_OQ);
   return _mm512_castsi512_pd(
       _mm512_mask_set1_epi64(_mm512_set1_epi64(0), mask, 0xffffffffffffffffu));
 }
+template <>
+EIGEN_STRONG_INLINE Packet8d pcmp_le(const Packet8d& a, const Packet8d& b) {
+  __mmask8 mask = _mm512_cmp_pd_mask(a, b, _CMP_LE_OQ);
+  return _mm512_castsi512_pd(
+      _mm512_mask_set1_epi64(_mm512_set1_epi64(0), mask, 0xffffffffffffffffu));
+}
+template <>
+EIGEN_STRONG_INLINE Packet8d pcmp_lt(const Packet8d& a, const Packet8d& b) {
+  __mmask8 mask = _mm512_cmp_pd_mask(a, b, _CMP_LT_OQ);
+  return _mm512_castsi512_pd(
+      _mm512_mask_set1_epi64(_mm512_set1_epi64(0), mask, 0xffffffffffffffffu));
+}
+template <>
+EIGEN_STRONG_INLINE Packet8d pcmp_lt_or_nan(const Packet8d& a, const Packet8d& b) {
+  __mmask8 mask = _mm512_cmp_pd_mask(a, b, _CMP_NGE_UQ);
+  return _mm512_castsi512_pd(
+      _mm512_mask_set1_epi64(_mm512_set1_epi64(0), mask, 0xffffffffffffffffu));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16f print<Packet16f>(const Packet16f& a) { return _mm512_roundscale_ps(a, _MM_FROUND_CUR_DIRECTION); }
+template<> EIGEN_STRONG_INLINE Packet8d print<Packet8d>(const Packet8d& a) { return _mm512_roundscale_pd(a, _MM_FROUND_CUR_DIRECTION); }
+
+template<> EIGEN_STRONG_INLINE Packet16f pceil<Packet16f>(const Packet16f& a) { return _mm512_roundscale_ps(a, _MM_FROUND_TO_POS_INF); }
+template<> EIGEN_STRONG_INLINE Packet8d pceil<Packet8d>(const Packet8d& a) { return _mm512_roundscale_pd(a, _MM_FROUND_TO_POS_INF); }
+
+template<> EIGEN_STRONG_INLINE Packet16f pfloor<Packet16f>(const Packet16f& a) { return _mm512_roundscale_ps(a, _MM_FROUND_TO_NEG_INF); }
+template<> EIGEN_STRONG_INLINE Packet8d pfloor<Packet8d>(const Packet8d& a) { return _mm512_roundscale_pd(a, _MM_FROUND_TO_NEG_INF); }
 
 template <>
 EIGEN_STRONG_INLINE Packet16i ptrue<Packet16i>(const Packet16i& /*a*/) {
   return _mm512_set1_epi32(0xffffffffu);
 }
 
 template <>
@@ -393,17 +571,15 @@
   Packet8d res = _mm512_undefined_pd();
   Packet4d lane0_a = _mm512_extractf64x4_pd(a, 0);
   Packet4d lane0_b = _mm512_extractf64x4_pd(b, 0);
   res = _mm512_insertf64x4(res, _mm256_and_pd(lane0_a, lane0_b), 0);
 
   Packet4d lane1_a = _mm512_extractf64x4_pd(a, 1);
   Packet4d lane1_b = _mm512_extractf64x4_pd(b, 1);
-  res = _mm512_insertf64x4(res, _mm256_and_pd(lane1_a, lane1_b), 1);
-
-  return res;
+  return _mm512_insertf64x4(res, _mm256_and_pd(lane1_a, lane1_b), 1);
 #endif
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet16i por<Packet16i>(const Packet16i& a, const Packet16i& b) {
   return _mm512_or_si512(a, b);
 }
@@ -468,15 +644,38 @@
 #ifdef EIGEN_VECTORIZE_AVX512DQ
   return _mm512_andnot_pd(b, a);
 #else
   return _mm512_castsi512_pd(pandnot(_mm512_castpd_si512(a),_mm512_castpd_si512(b)));
 #endif
 }
 
-template<int N> EIGEN_STRONG_INLINE Packet16i pshiftleft(Packet16i a) {
+template<> EIGEN_STRONG_INLINE Packet16f pround<Packet16f>(const Packet16f& a)
+{
+  // Work-around for default std::round rounding mode.
+  const Packet16f mask = pset1frombits<Packet16f>(static_cast<numext::uint32_t>(0x80000000u));
+  const Packet16f prev0dot5 = pset1frombits<Packet16f>(static_cast<numext::uint32_t>(0x3EFFFFFFu));
+  return _mm512_roundscale_ps(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);
+}
+template<> EIGEN_STRONG_INLINE Packet8d pround<Packet8d>(const Packet8d& a)
+{
+  // Work-around for default std::round rounding mode.
+  const Packet8d mask = pset1frombits<Packet8d>(static_cast<numext::uint64_t>(0x8000000000000000ull));
+  const Packet8d prev0dot5 = pset1frombits<Packet8d>(static_cast<numext::uint64_t>(0x3FDFFFFFFFFFFFFFull));
+  return _mm512_roundscale_pd(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);
+}
+
+template<int N> EIGEN_STRONG_INLINE Packet16i parithmetic_shift_right(Packet16i a) {
+  return _mm512_srai_epi32(a, N);
+}
+
+template<int N> EIGEN_STRONG_INLINE Packet16i plogical_shift_right(Packet16i a) {
+  return _mm512_srli_epi32(a, N);
+}
+
+template<int N> EIGEN_STRONG_INLINE Packet16i plogical_shift_left(Packet16i a) {
   return _mm512_slli_epi32(a, N);
 }
 
 template <>
 EIGEN_STRONG_INLINE Packet16f pload<Packet16f>(const float* from) {
   EIGEN_DEBUG_ALIGNED_LOAD return _mm512_load_ps(from);
 }
@@ -691,14 +890,67 @@
 template <>
 EIGEN_STRONG_INLINE Packet8d pabs(const Packet8d& a) {
   // _mm512_abs_ps intrinsic not found, so hack around it
   return _mm512_castsi512_pd(_mm512_and_si512(_mm512_castpd_si512(a),
                                    _mm512_set1_epi64(0x7fffffffffffffff)));
 }
 
+template<>
+EIGEN_STRONG_INLINE Packet16f pfrexp<Packet16f>(const Packet16f& a, Packet16f& exponent){
+  return pfrexp_generic(a, exponent);
+}
+
+// Extract exponent without existence of Packet8l.
+template<>
+EIGEN_STRONG_INLINE  
+Packet8d pfrexp_generic_get_biased_exponent(const Packet8d& a) {
+  const Packet8d cst_exp_mask  = pset1frombits<Packet8d>(static_cast<uint64_t>(0x7ff0000000000000ull));
+  #ifdef EIGEN_VECTORIZE_AVX512DQ
+  return _mm512_cvtepi64_pd(_mm512_srli_epi64(_mm512_castpd_si512(pand(a, cst_exp_mask)), 52));
+  #else
+  return _mm512_cvtepi32_pd(_mm512_cvtepi64_epi32(_mm512_srli_epi64(_mm512_castpd_si512(pand(a, cst_exp_mask)), 52)));
+  #endif
+}
+
+template<>
+EIGEN_STRONG_INLINE Packet8d pfrexp<Packet8d>(const Packet8d& a, Packet8d& exponent) {
+  return pfrexp_generic(a, exponent);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16f pldexp<Packet16f>(const Packet16f& a, const Packet16f& exponent) {
+  return pldexp_generic(a, exponent);
+}
+
+template<> EIGEN_STRONG_INLINE Packet8d pldexp<Packet8d>(const Packet8d& a, const Packet8d& exponent) {
+  // Clamp exponent to [-2099, 2099]
+  const Packet8d max_exponent = pset1<Packet8d>(2099.0);
+  const Packet8i e = _mm512_cvtpd_epi32(pmin(pmax(exponent, pnegate(max_exponent)), max_exponent));
+  
+  // Split 2^e into four factors and multiply.
+  const Packet8i bias = pset1<Packet8i>(1023);
+  Packet8i b = parithmetic_shift_right<2>(e);  // floor(e/4)
+  
+  // 2^b
+  const Packet8i permute_idx = _mm256_setr_epi32(0, 4, 1, 5, 2, 6, 3, 7);
+  Packet8i hi = _mm256_permutevar8x32_epi32(padd(b, bias), permute_idx);
+  Packet8i lo = _mm256_slli_epi64(hi, 52);
+  hi = _mm256_slli_epi64(_mm256_srli_epi64(hi, 32), 52);
+  Packet8d c = _mm512_castsi512_pd(_mm512_inserti64x4(_mm512_castsi256_si512(lo), hi, 1));
+  Packet8d out = pmul(pmul(pmul(a, c), c), c);  // a * 2^(3b)
+  
+  // 2^(e - 3b)
+  b = psub(psub(psub(e, b), b), b);  // e - 3b
+  hi = _mm256_permutevar8x32_epi32(padd(b, bias), permute_idx);
+  lo = _mm256_slli_epi64(hi, 52);
+  hi = _mm256_slli_epi64(_mm256_srli_epi64(hi, 32), 52);
+  c = _mm512_castsi512_pd(_mm512_inserti64x4(_mm512_castsi256_si512(lo), hi, 1));
+  out = pmul(out, c);  // a * 2^e
+  return out;
+}
+
 #ifdef EIGEN_VECTORIZE_AVX512DQ
 // AVX512F does not define _mm512_extractf32x8_ps to extract _m256 from _m512
 #define EIGEN_EXTRACT_8f_FROM_16f(INPUT, OUTPUT)                           \
   __m256 OUTPUT##_0 = _mm512_extractf32x8_ps(INPUT, 0);                    \
   __m256 OUTPUT##_1 = _mm512_extractf32x8_ps(INPUT, 1)
 #else
 #define EIGEN_EXTRACT_8f_FROM_16f(INPUT, OUTPUT)                \
@@ -717,204 +969,14 @@
 #define EIGEN_INSERT_8f_INTO_16f(OUTPUT, INPUTA, INPUTB)                    \
   OUTPUT = _mm512_undefined_ps();                                           \
   OUTPUT = _mm512_insertf32x4(OUTPUT, _mm256_extractf128_ps(INPUTA, 0), 0); \
   OUTPUT = _mm512_insertf32x4(OUTPUT, _mm256_extractf128_ps(INPUTA, 1), 1); \
   OUTPUT = _mm512_insertf32x4(OUTPUT, _mm256_extractf128_ps(INPUTB, 0), 2); \
   OUTPUT = _mm512_insertf32x4(OUTPUT, _mm256_extractf128_ps(INPUTB, 1), 3);
 #endif
-template<> EIGEN_STRONG_INLINE Packet16f preduxp<Packet16f>(const Packet16f*
-vecs)
-{
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[0], vecs0);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[1], vecs1);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[2], vecs2);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[3], vecs3);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[4], vecs4);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[5], vecs5);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[6], vecs6);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[7], vecs7);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[8], vecs8);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[9], vecs9);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[10], vecs10);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[11], vecs11);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[12], vecs12);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[13], vecs13);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[14], vecs14);
-  EIGEN_EXTRACT_8f_FROM_16f(vecs[15], vecs15);
-
-  __m256 hsum1 = _mm256_hadd_ps(vecs0_0, vecs1_0);
-  __m256 hsum2 = _mm256_hadd_ps(vecs2_0, vecs3_0);
-  __m256 hsum3 = _mm256_hadd_ps(vecs4_0, vecs5_0);
-  __m256 hsum4 = _mm256_hadd_ps(vecs6_0, vecs7_0);
-
-  __m256 hsum5 = _mm256_hadd_ps(hsum1, hsum1);
-  __m256 hsum6 = _mm256_hadd_ps(hsum2, hsum2);
-  __m256 hsum7 = _mm256_hadd_ps(hsum3, hsum3);
-  __m256 hsum8 = _mm256_hadd_ps(hsum4, hsum4);
-
-  __m256 perm1 = _mm256_permute2f128_ps(hsum5, hsum5, 0x23);
-  __m256 perm2 = _mm256_permute2f128_ps(hsum6, hsum6, 0x23);
-  __m256 perm3 = _mm256_permute2f128_ps(hsum7, hsum7, 0x23);
-  __m256 perm4 = _mm256_permute2f128_ps(hsum8, hsum8, 0x23);
-
-  __m256 sum1 = _mm256_add_ps(perm1, hsum5);
-  __m256 sum2 = _mm256_add_ps(perm2, hsum6);
-  __m256 sum3 = _mm256_add_ps(perm3, hsum7);
-  __m256 sum4 = _mm256_add_ps(perm4, hsum8);
-
-  __m256 blend1 = _mm256_blend_ps(sum1, sum2, 0xcc);
-  __m256 blend2 = _mm256_blend_ps(sum3, sum4, 0xcc);
-
-  __m256 final = _mm256_blend_ps(blend1, blend2, 0xf0);
-
-  hsum1 = _mm256_hadd_ps(vecs0_1, vecs1_1);
-  hsum2 = _mm256_hadd_ps(vecs2_1, vecs3_1);
-  hsum3 = _mm256_hadd_ps(vecs4_1, vecs5_1);
-  hsum4 = _mm256_hadd_ps(vecs6_1, vecs7_1);
-
-  hsum5 = _mm256_hadd_ps(hsum1, hsum1);
-  hsum6 = _mm256_hadd_ps(hsum2, hsum2);
-  hsum7 = _mm256_hadd_ps(hsum3, hsum3);
-  hsum8 = _mm256_hadd_ps(hsum4, hsum4);
-
-  perm1 = _mm256_permute2f128_ps(hsum5, hsum5, 0x23);
-  perm2 = _mm256_permute2f128_ps(hsum6, hsum6, 0x23);
-  perm3 = _mm256_permute2f128_ps(hsum7, hsum7, 0x23);
-  perm4 = _mm256_permute2f128_ps(hsum8, hsum8, 0x23);
-
-  sum1 = _mm256_add_ps(perm1, hsum5);
-  sum2 = _mm256_add_ps(perm2, hsum6);
-  sum3 = _mm256_add_ps(perm3, hsum7);
-  sum4 = _mm256_add_ps(perm4, hsum8);
-
-  blend1 = _mm256_blend_ps(sum1, sum2, 0xcc);
-  blend2 = _mm256_blend_ps(sum3, sum4, 0xcc);
-
-  final = _mm256_add_ps(final, _mm256_blend_ps(blend1, blend2, 0xf0));
-
-  hsum1 = _mm256_hadd_ps(vecs8_0, vecs9_0);
-  hsum2 = _mm256_hadd_ps(vecs10_0, vecs11_0);
-  hsum3 = _mm256_hadd_ps(vecs12_0, vecs13_0);
-  hsum4 = _mm256_hadd_ps(vecs14_0, vecs15_0);
-
-  hsum5 = _mm256_hadd_ps(hsum1, hsum1);
-  hsum6 = _mm256_hadd_ps(hsum2, hsum2);
-  hsum7 = _mm256_hadd_ps(hsum3, hsum3);
-  hsum8 = _mm256_hadd_ps(hsum4, hsum4);
-
-  perm1 = _mm256_permute2f128_ps(hsum5, hsum5, 0x23);
-  perm2 = _mm256_permute2f128_ps(hsum6, hsum6, 0x23);
-  perm3 = _mm256_permute2f128_ps(hsum7, hsum7, 0x23);
-  perm4 = _mm256_permute2f128_ps(hsum8, hsum8, 0x23);
-
-  sum1 = _mm256_add_ps(perm1, hsum5);
-  sum2 = _mm256_add_ps(perm2, hsum6);
-  sum3 = _mm256_add_ps(perm3, hsum7);
-  sum4 = _mm256_add_ps(perm4, hsum8);
-
-  blend1 = _mm256_blend_ps(sum1, sum2, 0xcc);
-  blend2 = _mm256_blend_ps(sum3, sum4, 0xcc);
-
-  __m256 final_1 = _mm256_blend_ps(blend1, blend2, 0xf0);
-
-  hsum1 = _mm256_hadd_ps(vecs8_1, vecs9_1);
-  hsum2 = _mm256_hadd_ps(vecs10_1, vecs11_1);
-  hsum3 = _mm256_hadd_ps(vecs12_1, vecs13_1);
-  hsum4 = _mm256_hadd_ps(vecs14_1, vecs15_1);
-
-  hsum5 = _mm256_hadd_ps(hsum1, hsum1);
-  hsum6 = _mm256_hadd_ps(hsum2, hsum2);
-  hsum7 = _mm256_hadd_ps(hsum3, hsum3);
-  hsum8 = _mm256_hadd_ps(hsum4, hsum4);
-
-  perm1 = _mm256_permute2f128_ps(hsum5, hsum5, 0x23);
-  perm2 = _mm256_permute2f128_ps(hsum6, hsum6, 0x23);
-  perm3 = _mm256_permute2f128_ps(hsum7, hsum7, 0x23);
-  perm4 = _mm256_permute2f128_ps(hsum8, hsum8, 0x23);
-
-  sum1 = _mm256_add_ps(perm1, hsum5);
-  sum2 = _mm256_add_ps(perm2, hsum6);
-  sum3 = _mm256_add_ps(perm3, hsum7);
-  sum4 = _mm256_add_ps(perm4, hsum8);
-
-  blend1 = _mm256_blend_ps(sum1, sum2, 0xcc);
-  blend2 = _mm256_blend_ps(sum3, sum4, 0xcc);
-
-  final_1 = _mm256_add_ps(final_1, _mm256_blend_ps(blend1, blend2, 0xf0));
-
-  __m512 final_output;
-
-  EIGEN_INSERT_8f_INTO_16f(final_output, final, final_1);
-  return final_output;
-}
-
-template<> EIGEN_STRONG_INLINE Packet8d preduxp<Packet8d>(const Packet8d* vecs)
-{
-  Packet4d vecs0_0 = _mm512_extractf64x4_pd(vecs[0], 0);
-  Packet4d vecs0_1 = _mm512_extractf64x4_pd(vecs[0], 1);
-
-  Packet4d vecs1_0 = _mm512_extractf64x4_pd(vecs[1], 0);
-  Packet4d vecs1_1 = _mm512_extractf64x4_pd(vecs[1], 1);
-
-  Packet4d vecs2_0 = _mm512_extractf64x4_pd(vecs[2], 0);
-  Packet4d vecs2_1 = _mm512_extractf64x4_pd(vecs[2], 1);
-
-  Packet4d vecs3_0 = _mm512_extractf64x4_pd(vecs[3], 0);
-  Packet4d vecs3_1 = _mm512_extractf64x4_pd(vecs[3], 1);
-
-  Packet4d vecs4_0 = _mm512_extractf64x4_pd(vecs[4], 0);
-  Packet4d vecs4_1 = _mm512_extractf64x4_pd(vecs[4], 1);
-
-  Packet4d vecs5_0 = _mm512_extractf64x4_pd(vecs[5], 0);
-  Packet4d vecs5_1 = _mm512_extractf64x4_pd(vecs[5], 1);
-
-  Packet4d vecs6_0 = _mm512_extractf64x4_pd(vecs[6], 0);
-  Packet4d vecs6_1 = _mm512_extractf64x4_pd(vecs[6], 1);
-
-  Packet4d vecs7_0 = _mm512_extractf64x4_pd(vecs[7], 0);
-  Packet4d vecs7_1 = _mm512_extractf64x4_pd(vecs[7], 1);
-
-  Packet4d tmp0, tmp1;
-
-  tmp0 = _mm256_hadd_pd(vecs0_0, vecs1_0);
-  tmp0 = _mm256_add_pd(tmp0, _mm256_permute2f128_pd(tmp0, tmp0, 1));
-
-  tmp1 = _mm256_hadd_pd(vecs2_0, vecs3_0);
-  tmp1 = _mm256_add_pd(tmp1, _mm256_permute2f128_pd(tmp1, tmp1, 1));
-
-  __m256d final_0 = _mm256_blend_pd(tmp0, tmp1, 0xC);
-
-  tmp0 = _mm256_hadd_pd(vecs0_1, vecs1_1);
-  tmp0 = _mm256_add_pd(tmp0, _mm256_permute2f128_pd(tmp0, tmp0, 1));
-
-  tmp1 = _mm256_hadd_pd(vecs2_1, vecs3_1);
-  tmp1 = _mm256_add_pd(tmp1, _mm256_permute2f128_pd(tmp1, tmp1, 1));
-
-  final_0 = _mm256_add_pd(final_0, _mm256_blend_pd(tmp0, tmp1, 0xC));
-
-  tmp0 = _mm256_hadd_pd(vecs4_0, vecs5_0);
-  tmp0 = _mm256_add_pd(tmp0, _mm256_permute2f128_pd(tmp0, tmp0, 1));
-
-  tmp1 = _mm256_hadd_pd(vecs6_0, vecs7_0);
-  tmp1 = _mm256_add_pd(tmp1, _mm256_permute2f128_pd(tmp1, tmp1, 1));
-
-  __m256d final_1 = _mm256_blend_pd(tmp0, tmp1, 0xC);
-
-  tmp0 = _mm256_hadd_pd(vecs4_1, vecs5_1);
-  tmp0 = _mm256_add_pd(tmp0, _mm256_permute2f128_pd(tmp0, tmp0, 1));
-
-  tmp1 = _mm256_hadd_pd(vecs6_1, vecs7_1);
-  tmp1 = _mm256_add_pd(tmp1, _mm256_permute2f128_pd(tmp1, tmp1, 1));
-
-  final_1 = _mm256_add_pd(final_1, _mm256_blend_pd(tmp0, tmp1, 0xC));
-
-  __m512d final_output = _mm512_castpd256_pd512(final_0);
-
-  return _mm512_insertf64x4(final_output, final_1, 1);
-}
 
 template <>
 EIGEN_STRONG_INLINE float predux<Packet16f>(const Packet16f& a) {
 #ifdef EIGEN_VECTORIZE_AVX512DQ
   __m256 lane0 = _mm512_extractf32x8_ps(a, 0);
   __m256 lane1 = _mm512_extractf32x8_ps(a, 1);
   Packet8f x = _mm256_add_ps(lane0, lane1);
@@ -955,16 +1017,15 @@
   return _mm256_insertf128_ps(_mm256_castps128_ps256(sum0), sum1, 1);
 #endif
 }
 template <>
 EIGEN_STRONG_INLINE Packet4d predux_half_dowto4<Packet8d>(const Packet8d& a) {
   __m256d lane0 = _mm512_extractf64x4_pd(a, 0);
   __m256d lane1 = _mm512_extractf64x4_pd(a, 1);
-  __m256d res = _mm256_add_pd(lane0, lane1);
-  return res;
+  return _mm256_add_pd(lane0, lane1);
 }
 
 template <>
 EIGEN_STRONG_INLINE float predux_mul<Packet16f>(const Packet16f& a) {
 //#ifdef EIGEN_VECTORIZE_AVX512DQ
 #if 0
   Packet8f lane0 = _mm512_extractf32x8_ps(a, 0);
@@ -1034,60 +1095,14 @@
 template<> EIGEN_STRONG_INLINE bool predux_any(const Packet16f& x)
 {
   Packet16i xi = _mm512_castps_si512(x);
   __mmask16 tmp = _mm512_test_epi32_mask(xi,xi);
   return !_mm512_kortestz(tmp,tmp);
 }
 
-template <int Offset>
-struct palign_impl<Offset, Packet16f> {
-  static EIGEN_STRONG_INLINE void run(Packet16f& first,
-                                      const Packet16f& second) {
-    if (Offset != 0) {
-      __m512i first_idx = _mm512_set_epi32(
-          Offset + 15, Offset + 14, Offset + 13, Offset + 12, Offset + 11,
-          Offset + 10, Offset + 9, Offset + 8, Offset + 7, Offset + 6,
-          Offset + 5, Offset + 4, Offset + 3, Offset + 2, Offset + 1, Offset);
-
-      __m512i second_idx =
-          _mm512_set_epi32(Offset - 1, Offset - 2, Offset - 3, Offset - 4,
-                           Offset - 5, Offset - 6, Offset - 7, Offset - 8,
-                           Offset - 9, Offset - 10, Offset - 11, Offset - 12,
-                           Offset - 13, Offset - 14, Offset - 15, Offset - 16);
-
-      unsigned short mask = 0xFFFF;
-      mask <<= (16 - Offset);
-
-      first = _mm512_permutexvar_ps(first_idx, first);
-      Packet16f tmp = _mm512_permutexvar_ps(second_idx, second);
-      first = _mm512_mask_blend_ps(mask, first, tmp);
-    }
-  }
-};
-template <int Offset>
-struct palign_impl<Offset, Packet8d> {
-  static EIGEN_STRONG_INLINE void run(Packet8d& first, const Packet8d& second) {
-    if (Offset != 0) {
-      __m512i first_idx = _mm512_set_epi32(
-          0, Offset + 7, 0, Offset + 6, 0, Offset + 5, 0, Offset + 4, 0,
-          Offset + 3, 0, Offset + 2, 0, Offset + 1, 0, Offset);
-
-      __m512i second_idx = _mm512_set_epi32(
-          0, Offset - 1, 0, Offset - 2, 0, Offset - 3, 0, Offset - 4, 0,
-          Offset - 5, 0, Offset - 6, 0, Offset - 7, 0, Offset - 8);
-
-      unsigned char mask = 0xFF;
-      mask <<= (8 - Offset);
-
-      first = _mm512_permutexvar_pd(first_idx, first);
-      Packet8d tmp = _mm512_permutexvar_pd(second_idx, second);
-      first = _mm512_mask_blend_pd(mask, first, tmp);
-    }
-  }
-};
 
 
 #define PACK_OUTPUT(OUTPUT, INPUT, INDEX, STRIDE) \
   EIGEN_INSERT_8f_INTO_16f(OUTPUT[INDEX], INPUT[INDEX], INPUT[INDEX + STRIDE]);
 
 EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet16f, 16>& kernel) {
   __m512 T0 = _mm512_unpacklo_ps(kernel.packet[0], kernel.packet[1]);
@@ -1355,48 +1370,934 @@
              | (ifPacket.select[4]<<4)
              | (ifPacket.select[5]<<5)
              | (ifPacket.select[6]<<6)
              | (ifPacket.select[7]<<7);
   return _mm512_mask_blend_pd(m, elsePacket, thenPacket);
 }
 
-template<> EIGEN_STRONG_INLINE Packet16f pinsertfirst(const Packet16f& a, float b)
+// Packet math for Eigen::half
+template<> EIGEN_STRONG_INLINE Packet16h pset1<Packet16h>(const Eigen::half& from) {
+  return _mm256_set1_epi16(from.x);
+}
+
+template<> EIGEN_STRONG_INLINE Eigen::half pfirst<Packet16h>(const Packet16h& from) {
+  return half_impl::raw_uint16_to_half(static_cast<unsigned short>(_mm256_extract_epi16(from, 0)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pload<Packet16h>(const Eigen::half* from) {
+  return _mm256_load_si256(reinterpret_cast<const __m256i*>(from));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h ploadu<Packet16h>(const Eigen::half* from) {
+  return _mm256_loadu_si256(reinterpret_cast<const __m256i*>(from));
+}
+
+template<> EIGEN_STRONG_INLINE void pstore<half>(Eigen::half* to, const Packet16h& from) {
+  // (void*) -> workaround clang warning:
+  // cast from 'Eigen::half *' to '__m256i *' increases required alignment from 2 to 32
+  _mm256_store_si256((__m256i*)(void*)to, from);
+}
+
+template<> EIGEN_STRONG_INLINE void pstoreu<half>(Eigen::half* to, const Packet16h& from) {
+  // (void*) -> workaround clang warning:
+  // cast from 'Eigen::half *' to '__m256i *' increases required alignment from 2 to 32
+  _mm256_storeu_si256((__m256i*)(void*)to, from);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h
+ploaddup<Packet16h>(const Eigen::half*  from) {
+  unsigned short a = from[0].x;
+  unsigned short b = from[1].x;
+  unsigned short c = from[2].x;
+  unsigned short d = from[3].x;
+  unsigned short e = from[4].x;
+  unsigned short f = from[5].x;
+  unsigned short g = from[6].x;
+  unsigned short h = from[7].x;
+  return _mm256_set_epi16(h, h, g, g, f, f, e, e, d, d, c, c, b, b, a, a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h
+ploadquad(const Eigen::half* from) {
+  unsigned short a = from[0].x;
+  unsigned short b = from[1].x;
+  unsigned short c = from[2].x;
+  unsigned short d = from[3].x;
+  return _mm256_set_epi16(d, d, d, d, c, c, c, c, b, b, b, b, a, a, a, a);
+}
+
+EIGEN_STRONG_INLINE Packet16f half2float(const Packet16h& a) {
+#ifdef EIGEN_HAS_FP16_C
+  return _mm512_cvtph_ps(a);
+#else
+  EIGEN_ALIGN64 half aux[16];
+  pstore(aux, a);
+  float f0(aux[0]);
+  float f1(aux[1]);
+  float f2(aux[2]);
+  float f3(aux[3]);
+  float f4(aux[4]);
+  float f5(aux[5]);
+  float f6(aux[6]);
+  float f7(aux[7]);
+  float f8(aux[8]);
+  float f9(aux[9]);
+  float fa(aux[10]);
+  float fb(aux[11]);
+  float fc(aux[12]);
+  float fd(aux[13]);
+  float fe(aux[14]);
+  float ff(aux[15]);
+
+  return _mm512_set_ps(
+      ff, fe, fd, fc, fb, fa, f9, f8, f7, f6, f5, f4, f3, f2, f1, f0);
+#endif
+}
+
+EIGEN_STRONG_INLINE Packet16h float2half(const Packet16f& a) {
+#ifdef EIGEN_HAS_FP16_C
+  return _mm512_cvtps_ph(a, _MM_FROUND_TO_NEAREST_INT|_MM_FROUND_NO_EXC);
+#else
+  EIGEN_ALIGN64 float aux[16];
+  pstore(aux, a);
+  half h0(aux[0]);
+  half h1(aux[1]);
+  half h2(aux[2]);
+  half h3(aux[3]);
+  half h4(aux[4]);
+  half h5(aux[5]);
+  half h6(aux[6]);
+  half h7(aux[7]);
+  half h8(aux[8]);
+  half h9(aux[9]);
+  half ha(aux[10]);
+  half hb(aux[11]);
+  half hc(aux[12]);
+  half hd(aux[13]);
+  half he(aux[14]);
+  half hf(aux[15]);
+
+  return _mm256_set_epi16(
+      hf.x, he.x, hd.x, hc.x, hb.x, ha.x, h9.x, h8.x,
+      h7.x, h6.x, h5.x, h4.x, h3.x, h2.x, h1.x, h0.x);
+#endif
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h ptrue(const Packet16h& a) {
+  return ptrue(Packet8i(a));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16h pabs(const Packet16h& a) {
+  const __m256i sign_mask = _mm256_set1_epi16(static_cast<numext::uint16_t>(0x8000));
+  return _mm256_andnot_si256(sign_mask, a);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16h pmin<Packet16h>(const Packet16h& a,
+                                              const Packet16h& b) {
+  return float2half(pmin<Packet16f>(half2float(a), half2float(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16h pmax<Packet16h>(const Packet16h& a,
+                                              const Packet16h& b) {
+  return float2half(pmax<Packet16f>(half2float(a), half2float(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16h plset<Packet16h>(const half& a) {
+  return float2half(plset<Packet16f>(static_cast<float>(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h por(const Packet16h& a,const Packet16h& b) {
+  // in some cases Packet8i is a wrapper around __m256i, so we need to
+  // cast to Packet8i to call the correct overload.
+  return por(Packet8i(a),Packet8i(b));
+}
+template<> EIGEN_STRONG_INLINE Packet16h pxor(const Packet16h& a,const Packet16h& b) {
+  return pxor(Packet8i(a),Packet8i(b));
+}
+template<> EIGEN_STRONG_INLINE Packet16h pand(const Packet16h& a,const Packet16h& b) {
+  return pand(Packet8i(a),Packet8i(b));
+}
+template<> EIGEN_STRONG_INLINE Packet16h pandnot(const Packet16h& a,const Packet16h& b) {
+  return pandnot(Packet8i(a),Packet8i(b));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pselect(const Packet16h& mask, const Packet16h& a, const Packet16h& b) {
+  return _mm256_blendv_epi8(b, a, mask);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pround<Packet16h>(const Packet16h& a) {
+  return float2half(pround<Packet16f>(half2float(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h print<Packet16h>(const Packet16h& a) {
+  return float2half(print<Packet16f>(half2float(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pceil<Packet16h>(const Packet16h& a) {
+  return float2half(pceil<Packet16f>(half2float(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pfloor<Packet16h>(const Packet16h& a) {
+  return float2half(pfloor<Packet16f>(half2float(a)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pcmp_eq(const Packet16h& a,const Packet16h& b) {
+  Packet16f af = half2float(a);
+  Packet16f bf = half2float(b);
+  return Pack32To16(pcmp_eq(af, bf));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pcmp_le(const Packet16h& a,const Packet16h& b) {
+  return Pack32To16(pcmp_le(half2float(a), half2float(b)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pcmp_lt(const Packet16h& a,const Packet16h& b) {
+  return Pack32To16(pcmp_lt(half2float(a), half2float(b)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pcmp_lt_or_nan(const Packet16h& a,const Packet16h& b) {
+  return Pack32To16(pcmp_lt_or_nan(half2float(a), half2float(b)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pconj(const Packet16h& a) { return a; }
+
+template<> EIGEN_STRONG_INLINE Packet16h pnegate(const Packet16h& a) {
+  Packet16h sign_mask = _mm256_set1_epi16(static_cast<unsigned short>(0x8000));
+  return _mm256_xor_si256(a, sign_mask);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h padd<Packet16h>(const Packet16h& a, const Packet16h& b) {
+  Packet16f af = half2float(a);
+  Packet16f bf = half2float(b);
+  Packet16f rf = padd(af, bf);
+  return float2half(rf);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h psub<Packet16h>(const Packet16h& a, const Packet16h& b) {
+  Packet16f af = half2float(a);
+  Packet16f bf = half2float(b);
+  Packet16f rf = psub(af, bf);
+  return float2half(rf);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pmul<Packet16h>(const Packet16h& a, const Packet16h& b) {
+  Packet16f af = half2float(a);
+  Packet16f bf = half2float(b);
+  Packet16f rf = pmul(af, bf);
+  return float2half(rf);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h pdiv<Packet16h>(const Packet16h& a, const Packet16h& b) {
+  Packet16f af = half2float(a);
+  Packet16f bf = half2float(b);
+  Packet16f rf = pdiv(af, bf);
+  return float2half(rf);
+}
+
+template<> EIGEN_STRONG_INLINE half predux<Packet16h>(const Packet16h& from) {
+  Packet16f from_float = half2float(from);
+  return half(predux(from_float));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8h predux_half_dowto4<Packet16h>(const Packet16h& a) {
+  Packet8h lane0 = _mm256_extractf128_si256(a, 0);
+  Packet8h lane1 = _mm256_extractf128_si256(a, 1);
+  return padd<Packet8h>(lane0, lane1);
+}
+
+template<> EIGEN_STRONG_INLINE Eigen::half predux_max<Packet16h>(const Packet16h& a) {
+  Packet16f af = half2float(a);
+  float reduced = predux_max<Packet16f>(af);
+  return Eigen::half(reduced);
+}
+
+template<> EIGEN_STRONG_INLINE Eigen::half predux_min<Packet16h>(const Packet16h& a) {
+  Packet16f af = half2float(a);
+  float reduced = predux_min<Packet16f>(af);
+  return Eigen::half(reduced);
+}
+
+template<> EIGEN_STRONG_INLINE half predux_mul<Packet16h>(const Packet16h& from) {
+  Packet16f from_float = half2float(from);
+  return half(predux_mul(from_float));
+}
+
+template<> EIGEN_STRONG_INLINE Packet16h preverse(const Packet16h& a)
 {
-  return _mm512_mask_broadcastss_ps(a, (1), _mm_load_ss(&b));
+  __m128i m = _mm_setr_epi8(14,15,12,13,10,11,8,9,6,7,4,5,2,3,0,1);
+  return _mm256_insertf128_si256(
+                    _mm256_castsi128_si256(_mm_shuffle_epi8(_mm256_extractf128_si256(a,1),m)),
+                                           _mm_shuffle_epi8(_mm256_extractf128_si256(a,0),m), 1);
 }
 
-template<> EIGEN_STRONG_INLINE Packet8d pinsertfirst(const Packet8d& a, double b)
+template<> EIGEN_STRONG_INLINE Packet16h pgather<Eigen::half, Packet16h>(const Eigen::half* from, Index stride)
 {
-  return _mm512_mask_broadcastsd_pd(a, (1), _mm_load_sd(&b));
+  return _mm256_set_epi16(
+      from[15*stride].x, from[14*stride].x, from[13*stride].x, from[12*stride].x,
+      from[11*stride].x, from[10*stride].x, from[9*stride].x, from[8*stride].x,
+      from[7*stride].x, from[6*stride].x, from[5*stride].x, from[4*stride].x,
+      from[3*stride].x, from[2*stride].x, from[1*stride].x, from[0*stride].x);
 }
 
-template<> EIGEN_STRONG_INLINE Packet16f pinsertlast(const Packet16f& a, float b)
+template<> EIGEN_STRONG_INLINE void pscatter<half, Packet16h>(half* to, const Packet16h& from, Index stride)
 {
-  return _mm512_mask_broadcastss_ps(a, (1<<15), _mm_load_ss(&b));
+  EIGEN_ALIGN64 half aux[16];
+  pstore(aux, from);
+  to[stride*0] = aux[0];
+  to[stride*1] = aux[1];
+  to[stride*2] = aux[2];
+  to[stride*3] = aux[3];
+  to[stride*4] = aux[4];
+  to[stride*5] = aux[5];
+  to[stride*6] = aux[6];
+  to[stride*7] = aux[7];
+  to[stride*8] = aux[8];
+  to[stride*9] = aux[9];
+  to[stride*10] = aux[10];
+  to[stride*11] = aux[11];
+  to[stride*12] = aux[12];
+  to[stride*13] = aux[13];
+  to[stride*14] = aux[14];
+  to[stride*15] = aux[15];
+}
+
+EIGEN_STRONG_INLINE void
+ptranspose(PacketBlock<Packet16h,16>& kernel) {
+  __m256i a = kernel.packet[0];
+  __m256i b = kernel.packet[1];
+  __m256i c = kernel.packet[2];
+  __m256i d = kernel.packet[3];
+  __m256i e = kernel.packet[4];
+  __m256i f = kernel.packet[5];
+  __m256i g = kernel.packet[6];
+  __m256i h = kernel.packet[7];
+  __m256i i = kernel.packet[8];
+  __m256i j = kernel.packet[9];
+  __m256i k = kernel.packet[10];
+  __m256i l = kernel.packet[11];
+  __m256i m = kernel.packet[12];
+  __m256i n = kernel.packet[13];
+  __m256i o = kernel.packet[14];
+  __m256i p = kernel.packet[15];
+
+  __m256i ab_07 = _mm256_unpacklo_epi16(a, b);
+  __m256i cd_07 = _mm256_unpacklo_epi16(c, d);
+  __m256i ef_07 = _mm256_unpacklo_epi16(e, f);
+  __m256i gh_07 = _mm256_unpacklo_epi16(g, h);
+  __m256i ij_07 = _mm256_unpacklo_epi16(i, j);
+  __m256i kl_07 = _mm256_unpacklo_epi16(k, l);
+  __m256i mn_07 = _mm256_unpacklo_epi16(m, n);
+  __m256i op_07 = _mm256_unpacklo_epi16(o, p);
+
+  __m256i ab_8f = _mm256_unpackhi_epi16(a, b);
+  __m256i cd_8f = _mm256_unpackhi_epi16(c, d);
+  __m256i ef_8f = _mm256_unpackhi_epi16(e, f);
+  __m256i gh_8f = _mm256_unpackhi_epi16(g, h);
+  __m256i ij_8f = _mm256_unpackhi_epi16(i, j);
+  __m256i kl_8f = _mm256_unpackhi_epi16(k, l);
+  __m256i mn_8f = _mm256_unpackhi_epi16(m, n);
+  __m256i op_8f = _mm256_unpackhi_epi16(o, p);
+
+  __m256i abcd_03 = _mm256_unpacklo_epi32(ab_07, cd_07);
+  __m256i abcd_47 = _mm256_unpackhi_epi32(ab_07, cd_07);
+  __m256i efgh_03 = _mm256_unpacklo_epi32(ef_07, gh_07);
+  __m256i efgh_47 = _mm256_unpackhi_epi32(ef_07, gh_07);
+  __m256i ijkl_03 = _mm256_unpacklo_epi32(ij_07, kl_07);
+  __m256i ijkl_47 = _mm256_unpackhi_epi32(ij_07, kl_07);
+  __m256i mnop_03 = _mm256_unpacklo_epi32(mn_07, op_07);
+  __m256i mnop_47 = _mm256_unpackhi_epi32(mn_07, op_07);
+
+  __m256i abcd_8b = _mm256_unpacklo_epi32(ab_8f, cd_8f);
+  __m256i abcd_cf = _mm256_unpackhi_epi32(ab_8f, cd_8f);
+  __m256i efgh_8b = _mm256_unpacklo_epi32(ef_8f, gh_8f);
+  __m256i efgh_cf = _mm256_unpackhi_epi32(ef_8f, gh_8f);
+  __m256i ijkl_8b = _mm256_unpacklo_epi32(ij_8f, kl_8f);
+  __m256i ijkl_cf = _mm256_unpackhi_epi32(ij_8f, kl_8f);
+  __m256i mnop_8b = _mm256_unpacklo_epi32(mn_8f, op_8f);
+  __m256i mnop_cf = _mm256_unpackhi_epi32(mn_8f, op_8f);
+
+  __m256i abcdefgh_01 = _mm256_unpacklo_epi64(abcd_03, efgh_03);
+  __m256i abcdefgh_23 = _mm256_unpackhi_epi64(abcd_03, efgh_03);
+  __m256i ijklmnop_01 = _mm256_unpacklo_epi64(ijkl_03, mnop_03);
+  __m256i ijklmnop_23 = _mm256_unpackhi_epi64(ijkl_03, mnop_03);
+  __m256i abcdefgh_45 = _mm256_unpacklo_epi64(abcd_47, efgh_47);
+  __m256i abcdefgh_67 = _mm256_unpackhi_epi64(abcd_47, efgh_47);
+  __m256i ijklmnop_45 = _mm256_unpacklo_epi64(ijkl_47, mnop_47);
+  __m256i ijklmnop_67 = _mm256_unpackhi_epi64(ijkl_47, mnop_47);
+  __m256i abcdefgh_89 = _mm256_unpacklo_epi64(abcd_8b, efgh_8b);
+  __m256i abcdefgh_ab = _mm256_unpackhi_epi64(abcd_8b, efgh_8b);
+  __m256i ijklmnop_89 = _mm256_unpacklo_epi64(ijkl_8b, mnop_8b);
+  __m256i ijklmnop_ab = _mm256_unpackhi_epi64(ijkl_8b, mnop_8b);
+  __m256i abcdefgh_cd = _mm256_unpacklo_epi64(abcd_cf, efgh_cf);
+  __m256i abcdefgh_ef = _mm256_unpackhi_epi64(abcd_cf, efgh_cf);
+  __m256i ijklmnop_cd = _mm256_unpacklo_epi64(ijkl_cf, mnop_cf);
+  __m256i ijklmnop_ef = _mm256_unpackhi_epi64(ijkl_cf, mnop_cf);
+
+  // NOTE: no unpacklo/hi instr in this case, so using permute instr.
+  __m256i a_p_0 = _mm256_permute2x128_si256(abcdefgh_01, ijklmnop_01, 0x20);
+  __m256i a_p_1 = _mm256_permute2x128_si256(abcdefgh_23, ijklmnop_23, 0x20);
+  __m256i a_p_2 = _mm256_permute2x128_si256(abcdefgh_45, ijklmnop_45, 0x20);
+  __m256i a_p_3 = _mm256_permute2x128_si256(abcdefgh_67, ijklmnop_67, 0x20);
+  __m256i a_p_4 = _mm256_permute2x128_si256(abcdefgh_89, ijklmnop_89, 0x20);
+  __m256i a_p_5 = _mm256_permute2x128_si256(abcdefgh_ab, ijklmnop_ab, 0x20);
+  __m256i a_p_6 = _mm256_permute2x128_si256(abcdefgh_cd, ijklmnop_cd, 0x20);
+  __m256i a_p_7 = _mm256_permute2x128_si256(abcdefgh_ef, ijklmnop_ef, 0x20);
+  __m256i a_p_8 = _mm256_permute2x128_si256(abcdefgh_01, ijklmnop_01, 0x31);
+  __m256i a_p_9 = _mm256_permute2x128_si256(abcdefgh_23, ijklmnop_23, 0x31);
+  __m256i a_p_a = _mm256_permute2x128_si256(abcdefgh_45, ijklmnop_45, 0x31);
+  __m256i a_p_b = _mm256_permute2x128_si256(abcdefgh_67, ijklmnop_67, 0x31);
+  __m256i a_p_c = _mm256_permute2x128_si256(abcdefgh_89, ijklmnop_89, 0x31);
+  __m256i a_p_d = _mm256_permute2x128_si256(abcdefgh_ab, ijklmnop_ab, 0x31);
+  __m256i a_p_e = _mm256_permute2x128_si256(abcdefgh_cd, ijklmnop_cd, 0x31);
+  __m256i a_p_f = _mm256_permute2x128_si256(abcdefgh_ef, ijklmnop_ef, 0x31);
+
+  kernel.packet[0] = a_p_0;
+  kernel.packet[1] = a_p_1;
+  kernel.packet[2] = a_p_2;
+  kernel.packet[3] = a_p_3;
+  kernel.packet[4] = a_p_4;
+  kernel.packet[5] = a_p_5;
+  kernel.packet[6] = a_p_6;
+  kernel.packet[7] = a_p_7;
+  kernel.packet[8] = a_p_8;
+  kernel.packet[9] = a_p_9;
+  kernel.packet[10] = a_p_a;
+  kernel.packet[11] = a_p_b;
+  kernel.packet[12] = a_p_c;
+  kernel.packet[13] = a_p_d;
+  kernel.packet[14] = a_p_e;
+  kernel.packet[15] = a_p_f;
+}
+
+EIGEN_STRONG_INLINE void
+ptranspose(PacketBlock<Packet16h,8>& kernel) {
+  EIGEN_ALIGN64 half in[8][16];
+  pstore<half>(in[0], kernel.packet[0]);
+  pstore<half>(in[1], kernel.packet[1]);
+  pstore<half>(in[2], kernel.packet[2]);
+  pstore<half>(in[3], kernel.packet[3]);
+  pstore<half>(in[4], kernel.packet[4]);
+  pstore<half>(in[5], kernel.packet[5]);
+  pstore<half>(in[6], kernel.packet[6]);
+  pstore<half>(in[7], kernel.packet[7]);
+
+  EIGEN_ALIGN64 half out[8][16];
+
+  for (int i = 0; i < 8; ++i) {
+    for (int j = 0; j < 8; ++j) {
+      out[i][j] = in[j][2*i];
+    }
+    for (int j = 0; j < 8; ++j) {
+      out[i][j+8] = in[j][2*i+1];
+    }
+  }
+
+  kernel.packet[0] = pload<Packet16h>(out[0]);
+  kernel.packet[1] = pload<Packet16h>(out[1]);
+  kernel.packet[2] = pload<Packet16h>(out[2]);
+  kernel.packet[3] = pload<Packet16h>(out[3]);
+  kernel.packet[4] = pload<Packet16h>(out[4]);
+  kernel.packet[5] = pload<Packet16h>(out[5]);
+  kernel.packet[6] = pload<Packet16h>(out[6]);
+  kernel.packet[7] = pload<Packet16h>(out[7]);
+}
+
+EIGEN_STRONG_INLINE void
+ptranspose(PacketBlock<Packet16h,4>& kernel) {
+  EIGEN_ALIGN64 half in[4][16];
+  pstore<half>(in[0], kernel.packet[0]);
+  pstore<half>(in[1], kernel.packet[1]);
+  pstore<half>(in[2], kernel.packet[2]);
+  pstore<half>(in[3], kernel.packet[3]);
+
+  EIGEN_ALIGN64 half out[4][16];
+
+  for (int i = 0; i < 4; ++i) {
+    for (int j = 0; j < 4; ++j) {
+      out[i][j] = in[j][4*i];
+    }
+    for (int j = 0; j < 4; ++j) {
+      out[i][j+4] = in[j][4*i+1];
+    }
+    for (int j = 0; j < 4; ++j) {
+      out[i][j+8] = in[j][4*i+2];
+    }
+    for (int j = 0; j < 4; ++j) {
+      out[i][j+12] = in[j][4*i+3];
+    }
+  }
+
+  kernel.packet[0] = pload<Packet16h>(out[0]);
+  kernel.packet[1] = pload<Packet16h>(out[1]);
+  kernel.packet[2] = pload<Packet16h>(out[2]);
+  kernel.packet[3] = pload<Packet16h>(out[3]);
+}
+
+template <> struct is_arithmetic<Packet16bf> { enum { value = true }; };
+
+template <>
+struct packet_traits<bfloat16> : default_packet_traits {
+  typedef Packet16bf type;
+  typedef Packet8bf half;
+  enum {
+    Vectorizable = 1,
+    AlignedOnScalar = 1,
+    size = 16,
+    HasHalfPacket = 1,
+    HasBlend = 0,
+    HasInsert = 1,
+    HasSin = EIGEN_FAST_MATH,
+    HasCos = EIGEN_FAST_MATH,
+#if EIGEN_GNUC_AT_LEAST(5, 3) || (!EIGEN_COMP_GNUC_STRICT)
+#ifdef EIGEN_VECTORIZE_AVX512DQ
+    HasLog = 1,  // Currently fails test with bad accuracy.
+    HasLog1p  = 1,
+    HasExpm1  = 1,
+    HasNdtri = 1,
+    HasBessel  = 1,
+#endif
+    HasExp = 1,
+    HasSqrt = EIGEN_FAST_MATH,
+    HasRsqrt = EIGEN_FAST_MATH,
+    HasTanh = EIGEN_FAST_MATH,
+    HasErf = EIGEN_FAST_MATH,
+#endif
+    HasCmp  = 1,
+    HasDiv = 1
+  };
+};
+
+template <>
+struct unpacket_traits<Packet16bf>
+{
+  typedef bfloat16 type;
+  enum {size=16, alignment=Aligned32, vectorizable=true, masked_load_available=false, masked_store_available=false};
+  typedef Packet8bf half;
+};
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pset1<Packet16bf>(const bfloat16& from) {
+  return _mm256_set1_epi16(from.value);
+}
+
+template <>
+EIGEN_STRONG_INLINE bfloat16 pfirst<Packet16bf>(const Packet16bf& from) {
+  bfloat16 t;
+  t.value = static_cast<unsigned short>(_mm256_extract_epi16(from, 0));
+  return t;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pload<Packet16bf>(const bfloat16* from) {
+  return _mm256_load_si256(reinterpret_cast<const __m256i*>(from));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf ploadu<Packet16bf>(const bfloat16* from) {
+  return _mm256_loadu_si256(reinterpret_cast<const __m256i*>(from));
+}
+
+template <>
+EIGEN_STRONG_INLINE void pstore<bfloat16>(bfloat16* to,
+                                          const Packet16bf& from) {
+  _mm256_store_si256(reinterpret_cast<__m256i*>(to), from);
+}
+
+template <>
+EIGEN_STRONG_INLINE void pstoreu<bfloat16>(bfloat16* to,
+                                           const Packet16bf& from) {
+  _mm256_storeu_si256(reinterpret_cast<__m256i*>(to), from);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16bf
+ploaddup<Packet16bf>(const bfloat16* from) {
+  Packet16bf r;
+  unsigned short a = from[0].value;
+  unsigned short b = from[1].value;
+  unsigned short c = from[2].value;
+  unsigned short d = from[3].value;
+  unsigned short e = from[4].value;
+  unsigned short f = from[5].value;
+  unsigned short g = from[6].value;
+  unsigned short h = from[7].value;
+  return _mm256_set_epi16(h, h, g, g, f, f, e, e, d, d, c, c, b, b, a, a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16bf
+ploadquad(const bfloat16* from) {
+  Packet16bf r;
+  unsigned short a = from[0].value;
+  unsigned short b = from[1].value;
+  unsigned short c = from[2].value;
+  unsigned short d = from[3].value;
+  return _mm256_set_epi16(d, d, d, d, c, c, c, c, b, b, b, b, a, a, a, a);
+}
+
+EIGEN_STRONG_INLINE Packet16f Bf16ToF32(const Packet16bf& a) {
+  return _mm512_castsi512_ps(_mm512_slli_epi32(_mm512_cvtepu16_epi32(a), 16));
+}
+
+// Convert float to bfloat16 according to round-to-nearest-even/denormals algorithm.
+EIGEN_STRONG_INLINE Packet16bf F32ToBf16(const Packet16f& a) {
+  Packet16bf r;
+
+#if defined(EIGEN_VECTORIZE_AVX512BF16) && EIGEN_GNUC_AT_LEAST(10, 1)
+  // Since GCC 10.1 supports avx512bf16 and C style explicit cast
+  // (C++ static_cast is not supported yet), do converion via intrinsic
+  // and register path for performance.
+  r = (__m256i)(_mm512_cvtneps_pbh(a));
+
+#else
+  __m512i t;
+  __m512i input = _mm512_castps_si512(a);
+  __m512i nan = _mm512_set1_epi32(0x7fc0);
+
+  // uint32_t lsb = (input >> 16) & 1;
+  t = _mm512_and_si512(_mm512_srli_epi32(input, 16), _mm512_set1_epi32(1));
+  // uint32_t rounding_bias = 0x7fff + lsb;
+  t = _mm512_add_epi32(t, _mm512_set1_epi32(0x7fff));
+  // input += rounding_bias;
+  t = _mm512_add_epi32(t, input);
+  // input = input >> 16;
+  t = _mm512_srli_epi32(t, 16);
+
+  // Check NaN before converting back to bf16
+  __mmask16 mask = _mm512_cmp_ps_mask(a, a, _CMP_ORD_Q);
+
+  t = _mm512_mask_blend_epi32(mask, nan, t);
+  // output.value = static_cast<uint16_t>(input);
+  r = _mm512_cvtepi32_epi16(t);
+#endif // EIGEN_VECTORIZE_AVX512BF16
+
+  return r;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf ptrue(const Packet16bf& a) {
+  return ptrue<Packet8i>(a);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf por(const Packet16bf& a, const Packet16bf& b) {
+  return por<Packet8i>(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pxor(const Packet16bf& a, const Packet16bf& b) {
+  return pxor<Packet8i>(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pand(const Packet16bf& a, const Packet16bf& b) {
+  return pand<Packet8i>(a, b);
 }
 
-template<> EIGEN_STRONG_INLINE Packet8d pinsertlast(const Packet8d& a, double b)
+template <>
+EIGEN_STRONG_INLINE Packet16bf pandnot(const Packet16bf& a,
+                                       const Packet16bf& b) {
+  return pandnot<Packet8i>(a, b);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pselect(const Packet16bf& mask,
+                                       const Packet16bf& a,
+                                       const Packet16bf& b) {
+  // Input mask is expected to be all 0/1, handle it with 8-bit
+  // intrinsic for performance.
+  return _mm256_blendv_epi8(b, a, mask);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16bf pround<Packet16bf>(const Packet16bf& a)
 {
-  return _mm512_mask_broadcastsd_pd(a, (1<<7), _mm_load_sd(&b));
+  return F32ToBf16(pround<Packet16f>(Bf16ToF32(a)));
 }
 
-template<> EIGEN_STRONG_INLINE Packet16i pcast<Packet16f, Packet16i>(const Packet16f& a) {
-  return _mm512_cvttps_epi32(a);
+template<> EIGEN_STRONG_INLINE Packet16bf print<Packet16bf>(const Packet16bf& a) {
+  return F32ToBf16(print<Packet16f>(Bf16ToF32(a)));
 }
 
-template<> EIGEN_STRONG_INLINE Packet16f pcast<Packet16i, Packet16f>(const Packet16i& a) {
-  return _mm512_cvtepi32_ps(a);
+template<> EIGEN_STRONG_INLINE Packet16bf pceil<Packet16bf>(const Packet16bf& a) {
+  return F32ToBf16(pceil<Packet16f>(Bf16ToF32(a)));
 }
 
-template<> EIGEN_STRONG_INLINE Packet16i preinterpret<Packet16i,Packet16f>(const Packet16f& a) {
-  return _mm512_castps_si512(a);
+template<> EIGEN_STRONG_INLINE Packet16bf pfloor<Packet16bf>(const Packet16bf& a) {
+  return F32ToBf16(pfloor<Packet16f>(Bf16ToF32(a)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pcmp_eq(const Packet16bf& a,
+                                       const Packet16bf& b) {
+  return Pack32To16(pcmp_eq(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pcmp_le(const Packet16bf& a,
+                                       const Packet16bf& b) {
+  return Pack32To16(pcmp_le(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pcmp_lt(const Packet16bf& a,
+                                       const Packet16bf& b) {
+  return Pack32To16(pcmp_lt(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pcmp_lt_or_nan(const Packet16bf& a,
+                                              const Packet16bf& b) {
+  return Pack32To16(pcmp_lt_or_nan(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pnegate(const Packet16bf& a) {
+  Packet16bf sign_mask = _mm256_set1_epi16(static_cast<unsigned short>(0x8000));
+  return _mm256_xor_si256(a, sign_mask);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pconj(const Packet16bf& a) {
+  return a;
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pabs(const Packet16bf& a) {
+  const __m256i sign_mask = _mm256_set1_epi16(static_cast<numext::uint16_t>(0x8000));
+  return _mm256_andnot_si256(sign_mask, a);
 }
 
-template<> EIGEN_STRONG_INLINE Packet16f preinterpret<Packet16f,Packet16i>(const Packet16i& a) {
-  return _mm512_castsi512_ps(a);
+template <>
+EIGEN_STRONG_INLINE Packet16bf padd<Packet16bf>(const Packet16bf& a,
+                                                const Packet16bf& b) {
+  return F32ToBf16(padd<Packet16f>(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf psub<Packet16bf>(const Packet16bf& a,
+                                                const Packet16bf& b) {
+  return F32ToBf16(psub<Packet16f>(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pmul<Packet16bf>(const Packet16bf& a,
+                                                const Packet16bf& b) {
+  return F32ToBf16(pmul<Packet16f>(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pdiv<Packet16bf>(const Packet16bf& a,
+                                                const Packet16bf& b) {
+  return F32ToBf16(pdiv<Packet16f>(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pmin<Packet16bf>(const Packet16bf& a,
+                                                const Packet16bf& b) {
+  return F32ToBf16(pmin<Packet16f>(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pmax<Packet16bf>(const Packet16bf& a,
+                                                const Packet16bf& b) {
+  return F32ToBf16(pmax<Packet16f>(Bf16ToF32(a), Bf16ToF32(b)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf plset<Packet16bf>(const bfloat16& a) {
+  return F32ToBf16(plset<Packet16f>(static_cast<float>(a)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet8bf predux_half_dowto4<Packet16bf>(const Packet16bf& a) {
+  Packet8bf lane0 = _mm256_extractf128_si256(a, 0);
+  Packet8bf lane1 = _mm256_extractf128_si256(a, 1);
+  return padd<Packet8bf>(lane0, lane1);
+}
+
+template <>
+EIGEN_STRONG_INLINE bfloat16 predux<Packet16bf>(const Packet16bf& p) {
+  return static_cast<bfloat16>(predux<Packet16f>(Bf16ToF32(p)));
+}
+
+template <>
+EIGEN_STRONG_INLINE bfloat16 predux_mul<Packet16bf>(const Packet16bf& from) {
+  return static_cast<bfloat16>(predux_mul<Packet16f>(Bf16ToF32(from)));
+}
+
+template <>
+EIGEN_STRONG_INLINE bfloat16 predux_min<Packet16bf>(const Packet16bf& from) {
+  return static_cast<bfloat16>(predux_min<Packet16f>(Bf16ToF32(from)));
+}
+
+template <>
+EIGEN_STRONG_INLINE bfloat16 predux_max<Packet16bf>(const Packet16bf& from) {
+  return static_cast<bfloat16>(predux_max<Packet16f>(Bf16ToF32(from)));
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf preverse(const Packet16bf& a) {
+  __m256i m = _mm256_setr_epi8(14,15,12,13,10,11,8,9,6,7,4,5,2,3,0,1,
+                               14,15,12,13,10,11,8,9,6,7,4,5,2,3,0,1);
+
+  Packet16bf res;
+  // Swap hi and lo first because shuffle is in 128-bit lanes.
+  res = _mm256_permute2x128_si256(a, a, 1);
+  // Shuffle 8-bit values in src within 2*128-bit lanes.
+  return _mm256_shuffle_epi8(res, m);
+}
+
+template <>
+EIGEN_STRONG_INLINE Packet16bf pgather<bfloat16, Packet16bf>(const bfloat16* from,
+                                                             Index stride) {
+  return _mm256_set_epi16(
+      from[15*stride].value, from[14*stride].value, from[13*stride].value, from[12*stride].value,
+      from[11*stride].value, from[10*stride].value, from[9*stride].value, from[8*stride].value,
+      from[7*stride].value, from[6*stride].value, from[5*stride].value, from[4*stride].value,
+      from[3*stride].value, from[2*stride].value, from[1*stride].value, from[0*stride].value);
+}
+
+template <>
+EIGEN_STRONG_INLINE void pscatter<bfloat16, Packet16bf>(bfloat16* to,
+                                                        const Packet16bf& from,
+                                                        Index stride) {
+  EIGEN_ALIGN64 bfloat16 aux[16];
+  pstore(aux, from);
+  to[stride*0] = aux[0];
+  to[stride*1] = aux[1];
+  to[stride*2] = aux[2];
+  to[stride*3] = aux[3];
+  to[stride*4] = aux[4];
+  to[stride*5] = aux[5];
+  to[stride*6] = aux[6];
+  to[stride*7] = aux[7];
+  to[stride*8] = aux[8];
+  to[stride*9] = aux[9];
+  to[stride*10] = aux[10];
+  to[stride*11] = aux[11];
+  to[stride*12] = aux[12];
+  to[stride*13] = aux[13];
+  to[stride*14] = aux[14];
+  to[stride*15] = aux[15];
+}
+
+EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet16bf,16>& kernel) {
+  __m256i a = kernel.packet[0];
+  __m256i b = kernel.packet[1];
+  __m256i c = kernel.packet[2];
+  __m256i d = kernel.packet[3];
+  __m256i e = kernel.packet[4];
+  __m256i f = kernel.packet[5];
+  __m256i g = kernel.packet[6];
+  __m256i h = kernel.packet[7];
+  __m256i i = kernel.packet[8];
+  __m256i j = kernel.packet[9];
+  __m256i k = kernel.packet[10];
+  __m256i l = kernel.packet[11];
+  __m256i m = kernel.packet[12];
+  __m256i n = kernel.packet[13];
+  __m256i o = kernel.packet[14];
+  __m256i p = kernel.packet[15];
+
+  __m256i ab_07 = _mm256_unpacklo_epi16(a, b);
+  __m256i cd_07 = _mm256_unpacklo_epi16(c, d);
+  __m256i ef_07 = _mm256_unpacklo_epi16(e, f);
+  __m256i gh_07 = _mm256_unpacklo_epi16(g, h);
+  __m256i ij_07 = _mm256_unpacklo_epi16(i, j);
+  __m256i kl_07 = _mm256_unpacklo_epi16(k, l);
+  __m256i mn_07 = _mm256_unpacklo_epi16(m, n);
+  __m256i op_07 = _mm256_unpacklo_epi16(o, p);
+
+  __m256i ab_8f = _mm256_unpackhi_epi16(a, b);
+  __m256i cd_8f = _mm256_unpackhi_epi16(c, d);
+  __m256i ef_8f = _mm256_unpackhi_epi16(e, f);
+  __m256i gh_8f = _mm256_unpackhi_epi16(g, h);
+  __m256i ij_8f = _mm256_unpackhi_epi16(i, j);
+  __m256i kl_8f = _mm256_unpackhi_epi16(k, l);
+  __m256i mn_8f = _mm256_unpackhi_epi16(m, n);
+  __m256i op_8f = _mm256_unpackhi_epi16(o, p);
+
+  __m256i abcd_03 = _mm256_unpacklo_epi32(ab_07, cd_07);
+  __m256i abcd_47 = _mm256_unpackhi_epi32(ab_07, cd_07);
+  __m256i efgh_03 = _mm256_unpacklo_epi32(ef_07, gh_07);
+  __m256i efgh_47 = _mm256_unpackhi_epi32(ef_07, gh_07);
+  __m256i ijkl_03 = _mm256_unpacklo_epi32(ij_07, kl_07);
+  __m256i ijkl_47 = _mm256_unpackhi_epi32(ij_07, kl_07);
+  __m256i mnop_03 = _mm256_unpacklo_epi32(mn_07, op_07);
+  __m256i mnop_47 = _mm256_unpackhi_epi32(mn_07, op_07);
+
+  __m256i abcd_8b = _mm256_unpacklo_epi32(ab_8f, cd_8f);
+  __m256i abcd_cf = _mm256_unpackhi_epi32(ab_8f, cd_8f);
+  __m256i efgh_8b = _mm256_unpacklo_epi32(ef_8f, gh_8f);
+  __m256i efgh_cf = _mm256_unpackhi_epi32(ef_8f, gh_8f);
+  __m256i ijkl_8b = _mm256_unpacklo_epi32(ij_8f, kl_8f);
+  __m256i ijkl_cf = _mm256_unpackhi_epi32(ij_8f, kl_8f);
+  __m256i mnop_8b = _mm256_unpacklo_epi32(mn_8f, op_8f);
+  __m256i mnop_cf = _mm256_unpackhi_epi32(mn_8f, op_8f);
+
+  __m256i abcdefgh_01 = _mm256_unpacklo_epi64(abcd_03, efgh_03);
+  __m256i abcdefgh_23 = _mm256_unpackhi_epi64(abcd_03, efgh_03);
+  __m256i ijklmnop_01 = _mm256_unpacklo_epi64(ijkl_03, mnop_03);
+  __m256i ijklmnop_23 = _mm256_unpackhi_epi64(ijkl_03, mnop_03);
+  __m256i abcdefgh_45 = _mm256_unpacklo_epi64(abcd_47, efgh_47);
+  __m256i abcdefgh_67 = _mm256_unpackhi_epi64(abcd_47, efgh_47);
+  __m256i ijklmnop_45 = _mm256_unpacklo_epi64(ijkl_47, mnop_47);
+  __m256i ijklmnop_67 = _mm256_unpackhi_epi64(ijkl_47, mnop_47);
+  __m256i abcdefgh_89 = _mm256_unpacklo_epi64(abcd_8b, efgh_8b);
+  __m256i abcdefgh_ab = _mm256_unpackhi_epi64(abcd_8b, efgh_8b);
+  __m256i ijklmnop_89 = _mm256_unpacklo_epi64(ijkl_8b, mnop_8b);
+  __m256i ijklmnop_ab = _mm256_unpackhi_epi64(ijkl_8b, mnop_8b);
+  __m256i abcdefgh_cd = _mm256_unpacklo_epi64(abcd_cf, efgh_cf);
+  __m256i abcdefgh_ef = _mm256_unpackhi_epi64(abcd_cf, efgh_cf);
+  __m256i ijklmnop_cd = _mm256_unpacklo_epi64(ijkl_cf, mnop_cf);
+  __m256i ijklmnop_ef = _mm256_unpackhi_epi64(ijkl_cf, mnop_cf);
+
+  // NOTE: no unpacklo/hi instr in this case, so using permute instr.
+  kernel.packet[0] = _mm256_permute2x128_si256(abcdefgh_01, ijklmnop_01, 0x20);
+  kernel.packet[1] = _mm256_permute2x128_si256(abcdefgh_23, ijklmnop_23, 0x20);
+  kernel.packet[2] = _mm256_permute2x128_si256(abcdefgh_45, ijklmnop_45, 0x20);
+  kernel.packet[3] = _mm256_permute2x128_si256(abcdefgh_67, ijklmnop_67, 0x20);
+  kernel.packet[4] = _mm256_permute2x128_si256(abcdefgh_89, ijklmnop_89, 0x20);
+  kernel.packet[5] = _mm256_permute2x128_si256(abcdefgh_ab, ijklmnop_ab, 0x20);
+  kernel.packet[6] = _mm256_permute2x128_si256(abcdefgh_cd, ijklmnop_cd, 0x20);
+  kernel.packet[7] = _mm256_permute2x128_si256(abcdefgh_ef, ijklmnop_ef, 0x20);
+  kernel.packet[8] = _mm256_permute2x128_si256(abcdefgh_01, ijklmnop_01, 0x31);
+  kernel.packet[9] = _mm256_permute2x128_si256(abcdefgh_23, ijklmnop_23, 0x31);
+  kernel.packet[10] = _mm256_permute2x128_si256(abcdefgh_45, ijklmnop_45, 0x31);
+  kernel.packet[11] = _mm256_permute2x128_si256(abcdefgh_67, ijklmnop_67, 0x31);
+  kernel.packet[12] = _mm256_permute2x128_si256(abcdefgh_89, ijklmnop_89, 0x31);
+  kernel.packet[13] = _mm256_permute2x128_si256(abcdefgh_ab, ijklmnop_ab, 0x31);
+  kernel.packet[14] = _mm256_permute2x128_si256(abcdefgh_cd, ijklmnop_cd, 0x31);
+  kernel.packet[15] = _mm256_permute2x128_si256(abcdefgh_ef, ijklmnop_ef, 0x31);
+}
+
+EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet16bf,4>& kernel) {
+  __m256i a = kernel.packet[0];
+  __m256i b = kernel.packet[1];
+  __m256i c = kernel.packet[2];
+  __m256i d = kernel.packet[3];
+
+  __m256i ab_07 = _mm256_unpacklo_epi16(a, b);
+  __m256i cd_07 = _mm256_unpacklo_epi16(c, d);
+  __m256i ab_8f = _mm256_unpackhi_epi16(a, b);
+  __m256i cd_8f = _mm256_unpackhi_epi16(c, d);
+
+  __m256i abcd_03 = _mm256_unpacklo_epi32(ab_07, cd_07);
+  __m256i abcd_47 = _mm256_unpackhi_epi32(ab_07, cd_07);
+  __m256i abcd_8b = _mm256_unpacklo_epi32(ab_8f, cd_8f);
+  __m256i abcd_cf = _mm256_unpackhi_epi32(ab_8f, cd_8f);
+
+  // NOTE: no unpacklo/hi instr in this case, so using permute instr.
+  kernel.packet[0] = _mm256_permute2x128_si256(abcd_03, abcd_47, 0x20);
+  kernel.packet[1] = _mm256_permute2x128_si256(abcd_8b, abcd_cf, 0x20);
+  kernel.packet[2] = _mm256_permute2x128_si256(abcd_03, abcd_47, 0x31);
+  kernel.packet[3] = _mm256_permute2x128_si256(abcd_8b, abcd_cf, 0x31);
 }
 
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_PACKET_MATH_AVX512_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AltiVec/Complex.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/ZVector/Complex.h`

 * *Files 8% similar despite different names*

```diff
@@ -1,41 +1,50 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
 // Copyright (C) 2010 Gael Guennebaud <gael.guennebaud@inria.fr>
-// Copyright (C) 2010-2016 Konstantinos Margaritis <markos@freevec.org>
+// Copyright (C) 2016 Konstantinos Margaritis <markos@freevec.org>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_COMPLEX32_ALTIVEC_H
 #define EIGEN_COMPLEX32_ALTIVEC_H
 
 namespace Eigen {
 
 namespace internal {
 
-static Packet4ui  p4ui_CONJ_XOR = vec_mergeh((Packet4ui)p4i_ZERO, (Packet4ui)p4f_MZERO);//{ 0x00000000, 0x80000000, 0x00000000, 0x80000000 };
-#ifdef __VSX__
-#if defined(_BIG_ENDIAN)
-static Packet2ul  p2ul_CONJ_XOR1 = (Packet2ul) vec_sld((Packet4ui) p2d_MZERO, (Packet4ui) p2l_ZERO, 8);//{ 0x8000000000000000, 0x0000000000000000 };
-static Packet2ul  p2ul_CONJ_XOR2 = (Packet2ul) vec_sld((Packet4ui) p2l_ZERO,  (Packet4ui) p2d_MZERO, 8);//{ 0x8000000000000000, 0x0000000000000000 };
-#else
-static Packet2ul  p2ul_CONJ_XOR1 = (Packet2ul) vec_sld((Packet4ui) p2l_ZERO,  (Packet4ui) p2d_MZERO, 8);//{ 0x8000000000000000, 0x0000000000000000 };
-static Packet2ul  p2ul_CONJ_XOR2 = (Packet2ul) vec_sld((Packet4ui) p2d_MZERO, (Packet4ui) p2l_ZERO, 8);//{ 0x8000000000000000, 0x0000000000000000 };
-#endif
+#if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ >= 12)
+static Packet4ui  p4ui_CONJ_XOR = { 0x00000000, 0x80000000, 0x00000000, 0x80000000 }; //vec_mergeh((Packet4ui)p4i_ZERO, (Packet4ui)p4f_MZERO);
 #endif
 
-//---------- float ----------
+static Packet2ul  p2ul_CONJ_XOR1 = (Packet2ul) vec_sld((Packet4ui) p2d_ZERO_, (Packet4ui) p2l_ZERO, 8);//{ 0x8000000000000000, 0x0000000000000000 };
+static Packet2ul  p2ul_CONJ_XOR2 = (Packet2ul) vec_sld((Packet4ui) p2l_ZERO,  (Packet4ui) p2d_ZERO_, 8);//{ 0x8000000000000000, 0x0000000000000000 };
+
+struct Packet1cd
+{
+  EIGEN_STRONG_INLINE Packet1cd() {}
+  EIGEN_STRONG_INLINE explicit Packet1cd(const Packet2d& a) : v(a) {}
+  Packet2d v;
+};
+
 struct Packet2cf
 {
-  EIGEN_STRONG_INLINE explicit Packet2cf() : v(p4f_ZERO) {}
+  EIGEN_STRONG_INLINE Packet2cf() {}
   EIGEN_STRONG_INLINE explicit Packet2cf(const Packet4f& a) : v(a) {}
-  Packet4f  v;
+#if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ < 12)
+  union {
+    Packet4f v;
+    Packet1cd cd[2];
+  };
+#else
+  Packet4f v;
+#endif
 };
 
 template<> struct packet_traits<std::complex<float> >  : default_packet_traits
 {
   typedef Packet2cf type;
   typedef Packet2cf half;
   enum {
@@ -49,399 +58,379 @@
     HasMul    = 1,
     HasDiv    = 1,
     HasNegate = 1,
     HasAbs    = 0,
     HasAbs2   = 0,
     HasMin    = 0,
     HasMax    = 0,
-#ifdef __VSX__
     HasBlend  = 1,
-#endif
     HasSetLinear = 0
   };
 };
 
-template<> struct unpacket_traits<Packet2cf> { typedef std::complex<float> type; enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet2cf half; };
 
-template<> EIGEN_STRONG_INLINE Packet2cf pset1<Packet2cf>(const std::complex<float>&  from)
+template<> struct packet_traits<std::complex<double> >  : default_packet_traits
 {
-  Packet2cf res;
-  if((std::ptrdiff_t(&from) % 16) == 0)
-    res.v = pload<Packet4f>((const float *)&from);
-  else
-    res.v = ploadu<Packet4f>((const float *)&from);
-  res.v = vec_perm(res.v, res.v, p16uc_PSET64_HI);
-  return res;
-}
+  typedef Packet1cd type;
+  typedef Packet1cd half;
+  enum {
+    Vectorizable = 1,
+    AlignedOnScalar = 1,
+    size = 1,
+    HasHalfPacket = 0,
+
+    HasAdd    = 1,
+    HasSub    = 1,
+    HasMul    = 1,
+    HasDiv    = 1,
+    HasNegate = 1,
+    HasAbs    = 0,
+    HasAbs2   = 0,
+    HasMin    = 0,
+    HasMax    = 0,
+    HasSetLinear = 0
+  };
+};
+
+template<> struct unpacket_traits<Packet2cf> {
+  typedef std::complex<float>  type;
+  enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false};
+  typedef Packet2cf half;
+  typedef Packet4f as_real;
+};
+template<> struct unpacket_traits<Packet1cd> {
+  typedef std::complex<double> type;
+  enum {size=1, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false};
+  typedef Packet1cd half;
+  typedef Packet2d as_real;
+};
 
-template<> EIGEN_STRONG_INLINE Packet2cf pload<Packet2cf>(const std::complex<float>*        from) { return Packet2cf(pload<Packet4f>((const float *) from)); }
-template<> EIGEN_STRONG_INLINE Packet2cf ploadu<Packet2cf>(const std::complex<float>*       from) { return Packet2cf(ploadu<Packet4f>((const float*) from)); }
-template<> EIGEN_STRONG_INLINE Packet2cf ploaddup<Packet2cf>(const std::complex<float>*     from) { return pset1<Packet2cf>(*from); }
+/* Forward declaration */
+EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet2cf,2>& kernel);
 
-template<> EIGEN_STRONG_INLINE void pstore <std::complex<float> >(std::complex<float> *   to, const Packet2cf& from) { pstore((float*)to, from.v); }
-template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<float> >(std::complex<float> *   to, const Packet2cf& from) { pstoreu((float*)to, from.v); }
+/* complex<double> first */
+template<> EIGEN_STRONG_INLINE Packet1cd pload <Packet1cd>(const std::complex<double>* from) { EIGEN_DEBUG_ALIGNED_LOAD return Packet1cd(pload<Packet2d>((const double*)from)); }
+template<> EIGEN_STRONG_INLINE Packet1cd ploadu<Packet1cd>(const std::complex<double>* from) { EIGEN_DEBUG_UNALIGNED_LOAD return Packet1cd(ploadu<Packet2d>((const double*)from)); }
+template<> EIGEN_STRONG_INLINE void pstore <std::complex<double> >(std::complex<double> *   to, const Packet1cd& from) { EIGEN_DEBUG_ALIGNED_STORE pstore((double*)to, from.v); }
+template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<double> >(std::complex<double> *   to, const Packet1cd& from) { EIGEN_DEBUG_UNALIGNED_STORE pstoreu((double*)to, from.v); }
 
-template<> EIGEN_DEVICE_FUNC inline Packet2cf pgather<std::complex<float>, Packet2cf>(const std::complex<float>* from, Index stride)
+template<> EIGEN_STRONG_INLINE Packet1cd pset1<Packet1cd>(const std::complex<double>&  from)
+{ /* here we really have to use unaligned loads :( */ return ploadu<Packet1cd>(&from); }
+
+template<> EIGEN_DEVICE_FUNC inline Packet1cd pgather<std::complex<double>, Packet1cd>(const std::complex<double>* from, Index stride EIGEN_UNUSED)
 {
-  EIGEN_ALIGN16 std::complex<float> af[2];
-  af[0] = from[0*stride];
-  af[1] = from[1*stride];
-  return pload<Packet2cf>(af);
+  return pload<Packet1cd>(from);
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<float>, Packet2cf>(std::complex<float>* to, const Packet2cf& from, Index stride)
+template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<double>, Packet1cd>(std::complex<double>* to, const Packet1cd& from, Index stride EIGEN_UNUSED)
 {
-  EIGEN_ALIGN16 std::complex<float> af[2];
-  pstore<std::complex<float> >((std::complex<float> *) af, from);
-  to[0*stride] = af[0];
-  to[1*stride] = af[1];
+  pstore<std::complex<double> >(to, from);
 }
-
-template<> EIGEN_STRONG_INLINE Packet2cf padd<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(a.v + b.v); }
-template<> EIGEN_STRONG_INLINE Packet2cf psub<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(a.v - b.v); }
-template<> EIGEN_STRONG_INLINE Packet2cf pnegate(const Packet2cf& a) { return Packet2cf(pnegate(a.v)); }
-template<> EIGEN_STRONG_INLINE Packet2cf pconj(const Packet2cf& a) { return Packet2cf(pxor<Packet4f>(a.v, reinterpret_cast<Packet4f>(p4ui_CONJ_XOR))); }
-
-template<> EIGEN_STRONG_INLINE Packet2cf pmul<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
+template<> EIGEN_STRONG_INLINE Packet1cd padd<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(a.v + b.v); }
+template<> EIGEN_STRONG_INLINE Packet1cd psub<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(a.v - b.v); }
+template<> EIGEN_STRONG_INLINE Packet1cd pnegate(const Packet1cd& a) { return Packet1cd(pnegate(Packet2d(a.v))); }
+template<> EIGEN_STRONG_INLINE Packet1cd pconj(const Packet1cd& a) { return Packet1cd((Packet2d)vec_xor((Packet2d)a.v, (Packet2d)p2ul_CONJ_XOR2)); }
+template<> EIGEN_STRONG_INLINE Packet1cd pmul<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
 {
-  Packet4f v1, v2;
+  Packet2d a_re, a_im, v1, v2;
 
   // Permute and multiply the real parts of a and b
-  v1 = vec_perm(a.v, a.v, p16uc_PSET32_WODD);
+  a_re = vec_perm(a.v, a.v, p16uc_PSET64_HI);
   // Get the imaginary parts of a
-  v2 = vec_perm(a.v, a.v, p16uc_PSET32_WEVEN);
-  // multiply a_re * b 
-  v1 = vec_madd(v1, b.v, p4f_ZERO);
+  a_im = vec_perm(a.v, a.v, p16uc_PSET64_LO);
+  // multiply a_re * b
+  v1 = vec_madd(a_re, b.v, p2d_ZERO);
   // multiply a_im * b and get the conjugate result
-  v2 = vec_madd(v2, b.v, p4f_ZERO);
-  v2 = reinterpret_cast<Packet4f>(pxor(v2, reinterpret_cast<Packet4f>(p4ui_CONJ_XOR)));
-  // permute back to a proper order
-  v2 = vec_perm(v2, v2, p16uc_COMPLEX32_REV);
-  
-  return Packet2cf(padd<Packet4f>(v1, v2));
-}
+  v2 = vec_madd(a_im, b.v, p2d_ZERO);
+  v2 = (Packet2d) vec_sld((Packet4ui)v2, (Packet4ui)v2, 8);
+  v2 = (Packet2d) vec_xor((Packet2d)v2, (Packet2d) p2ul_CONJ_XOR1);
 
-template<> EIGEN_STRONG_INLINE Packet2cf pand   <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pand<Packet4f>(a.v, b.v)); }
-template<> EIGEN_STRONG_INLINE Packet2cf por    <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(por<Packet4f>(a.v, b.v)); }
-template<> EIGEN_STRONG_INLINE Packet2cf pxor   <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pxor<Packet4f>(a.v, b.v)); }
-template<> EIGEN_STRONG_INLINE Packet2cf pandnot<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pandnot<Packet4f>(a.v, b.v)); }
+  return Packet1cd(v1 + v2);
+}
+template<> EIGEN_STRONG_INLINE Packet1cd pand    <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(vec_and(a.v,b.v)); }
+template<> EIGEN_STRONG_INLINE Packet1cd por     <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(vec_or(a.v,b.v)); }
+template<> EIGEN_STRONG_INLINE Packet1cd pxor    <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(vec_xor(a.v,b.v)); }
+template<> EIGEN_STRONG_INLINE Packet1cd pandnot <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(vec_and(a.v, vec_nor(b.v,b.v))); }
+template<> EIGEN_STRONG_INLINE Packet1cd ploaddup<Packet1cd>(const std::complex<double>*     from) {  return pset1<Packet1cd>(*from); }
+template<> EIGEN_STRONG_INLINE Packet1cd pcmp_eq(const Packet1cd& a, const Packet1cd& b) {
+  Packet2d eq = vec_cmpeq (a.v, b.v);
+  Packet2d tmp = { eq[1], eq[0] };
+  return (Packet1cd)pand<Packet2d>(eq, tmp);
+}
 
-template<> EIGEN_STRONG_INLINE void prefetch<std::complex<float> >(const std::complex<float> * addr)    { EIGEN_PPC_PREFETCH(addr); }
+template<> EIGEN_STRONG_INLINE void prefetch<std::complex<double> >(const std::complex<double> *   addr) { EIGEN_ZVECTOR_PREFETCH(addr); }
 
-template<> EIGEN_STRONG_INLINE std::complex<float>  pfirst<Packet2cf>(const Packet2cf& a)
+template<> EIGEN_STRONG_INLINE std::complex<double>  pfirst<Packet1cd>(const Packet1cd& a)
 {
-  EIGEN_ALIGN16 std::complex<float> res[2];
-  pstore((float *)&res, a.v);
+  EIGEN_ALIGN16 std::complex<double> res;
+  pstore<std::complex<double> >(&res, a);
 
-  return res[0];
+  return res;
 }
 
-template<> EIGEN_STRONG_INLINE Packet2cf preverse(const Packet2cf& a)
+template<> EIGEN_STRONG_INLINE Packet1cd preverse(const Packet1cd& a) { return a; }
+template<> EIGEN_STRONG_INLINE std::complex<double> predux<Packet1cd>(const Packet1cd& a)
 {
-  Packet4f rev_a;
-  rev_a = vec_perm(a.v, a.v, p16uc_COMPLEX32_REV2);
-  return Packet2cf(rev_a);
+  return pfirst(a);
 }
+template<> EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet1cd>(const Packet1cd& a)
+{
+  return pfirst(a);
+}
+EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cd,Packet2d)
 
-template<> EIGEN_STRONG_INLINE std::complex<float> predux<Packet2cf>(const Packet2cf& a)
+template<> EIGEN_STRONG_INLINE Packet1cd pdiv<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
 {
-  Packet4f b;
-  b = vec_sld(a.v, a.v, 8);
-  b = padd<Packet4f>(a.v, b);
-  return pfirst<Packet2cf>(Packet2cf(b));
+  // TODO optimize it for AltiVec
+  Packet1cd res = pmul(a,pconj(b));
+  Packet2d s = vec_madd(b.v, b.v, p2d_ZERO_);
+  return Packet1cd(pdiv(res.v, s + vec_perm(s, s, p16uc_REVERSE64)));
 }
 
-template<> EIGEN_STRONG_INLINE Packet2cf preduxp<Packet2cf>(const Packet2cf* vecs)
+EIGEN_STRONG_INLINE Packet1cd pcplxflip/*<Packet1cd>*/(const Packet1cd& x)
 {
-  Packet4f b1, b2;
-#ifdef _BIG_ENDIAN  
-  b1 = vec_sld(vecs[0].v, vecs[1].v, 8);
-  b2 = vec_sld(vecs[1].v, vecs[0].v, 8);
-#else
-  b1 = vec_sld(vecs[1].v, vecs[0].v, 8);
-  b2 = vec_sld(vecs[0].v, vecs[1].v, 8);
-#endif
-  b2 = vec_sld(b2, b2, 8);
-  b2 = padd<Packet4f>(b1, b2);
+  return Packet1cd(preverse(Packet2d(x.v)));
+}
 
-  return Packet2cf(b2);
+EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet1cd,2>& kernel)
+{
+  Packet2d tmp = vec_perm(kernel.packet[0].v, kernel.packet[1].v, p16uc_TRANSPOSE64_HI);
+  kernel.packet[1].v = vec_perm(kernel.packet[0].v, kernel.packet[1].v, p16uc_TRANSPOSE64_LO);
+  kernel.packet[0].v = tmp;
 }
 
-template<> EIGEN_STRONG_INLINE std::complex<float> predux_mul<Packet2cf>(const Packet2cf& a)
+/* complex<float> follows */
+template<> EIGEN_STRONG_INLINE Packet2cf pload <Packet2cf>(const std::complex<float>* from)  { EIGEN_DEBUG_ALIGNED_LOAD return Packet2cf(pload<Packet4f>((const float*)from)); }
+template<> EIGEN_STRONG_INLINE Packet2cf ploadu<Packet2cf>(const std::complex<float>* from)  { EIGEN_DEBUG_UNALIGNED_LOAD return Packet2cf(ploadu<Packet4f>((const float*)from)); }
+template<> EIGEN_STRONG_INLINE void pstore <std::complex<float> >(std::complex<float> *     to, const Packet2cf& from) { EIGEN_DEBUG_ALIGNED_STORE pstore((float*)to, from.v); }
+template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<float> >(std::complex<float> *     to, const Packet2cf& from) { EIGEN_DEBUG_UNALIGNED_STORE pstoreu((float*)to, from.v); }
+
+template<> EIGEN_STRONG_INLINE std::complex<float>  pfirst<Packet2cf>(const Packet2cf& a)
 {
-  Packet4f b;
-  Packet2cf prod;
-  b = vec_sld(a.v, a.v, 8);
-  prod = pmul<Packet2cf>(a, Packet2cf(b));
+  EIGEN_ALIGN16 std::complex<float> res[2];
+  pstore<std::complex<float> >(res, a);
 
-  return pfirst<Packet2cf>(prod);
+  return res[0];
 }
 
-template<int Offset>
-struct palign_impl<Offset,Packet2cf>
+
+#if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ < 12)
+template<> EIGEN_STRONG_INLINE Packet2cf pset1<Packet2cf>(const std::complex<float>&  from)
 {
-  static EIGEN_STRONG_INLINE void run(Packet2cf& first, const Packet2cf& second)
-  {
-    if (Offset==1)
-    {
-#ifdef _BIG_ENDIAN
-      first.v = vec_sld(first.v, second.v, 8);
+  Packet2cf res;
+  res.cd[0] = Packet1cd(vec_ld2f((const float *)&from));
+  res.cd[1] = res.cd[0];
+  return res;
+}
 #else
-      first.v = vec_sld(second.v, first.v, 8);
+template<> EIGEN_STRONG_INLINE Packet2cf pset1<Packet2cf>(const std::complex<float>&  from)
+{
+  Packet2cf res;
+  if((std::ptrdiff_t(&from) % 16) == 0)
+    res.v = pload<Packet4f>((const float *)&from);
+  else
+    res.v = ploadu<Packet4f>((const float *)&from);
+  res.v = vec_perm(res.v, res.v, p16uc_PSET64_HI);
+  return res;
+}
 #endif
-    }
-  }
-};
 
-template<> struct conj_helper<Packet2cf, Packet2cf, false,true>
+template<> EIGEN_DEVICE_FUNC inline Packet2cf pgather<std::complex<float>, Packet2cf>(const std::complex<float>* from, Index stride)
 {
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
+  EIGEN_ALIGN16 std::complex<float> af[2];
+  af[0] = from[0*stride];
+  af[1] = from[1*stride];
+  return pload<Packet2cf>(af);
+}
+template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<float>, Packet2cf>(std::complex<float>* to, const Packet2cf& from, Index stride)
+{
+  EIGEN_ALIGN16 std::complex<float> af[2];
+  pstore<std::complex<float> >((std::complex<float> *) af, from);
+  to[0*stride] = af[0];
+  to[1*stride] = af[1];
+}
 
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
+template<> EIGEN_STRONG_INLINE Packet2cf padd<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(padd<Packet4f>(a.v, b.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf psub<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(psub<Packet4f>(a.v, b.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf pnegate(const Packet2cf& a) { return Packet2cf(pnegate(Packet4f(a.v))); }
 
-template<> struct conj_helper<Packet2cf, Packet2cf, true,false>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
+template<> EIGEN_STRONG_INLINE Packet2cf pand   <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pand<Packet4f>(a.v,b.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf por    <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(por<Packet4f>(a.v,b.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf pxor   <Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pxor<Packet4f>(a.v,b.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf pandnot<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(pandnot<Packet4f>(a.v,b.v)); }
 
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
+template<> EIGEN_STRONG_INLINE Packet2cf ploaddup<Packet2cf>(const std::complex<float>*      from) {  return pset1<Packet2cf>(*from); }
 
-template<> struct conj_helper<Packet2cf, Packet2cf, true,true>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
+template<> EIGEN_STRONG_INLINE void prefetch<std::complex<float> >(const std::complex<float> *     addr) { EIGEN_ZVECTOR_PREFETCH(addr); }
 
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
 
-EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf,Packet4f)
+#if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ < 12)
 
-template<> EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
-{
-  // TODO optimize it for AltiVec
-  Packet2cf res = conj_helper<Packet2cf,Packet2cf,false,true>().pmul(a, b);
-  Packet4f s = pmul<Packet4f>(b.v, b.v);
-  return Packet2cf(pdiv(res.v, padd<Packet4f>(s, vec_perm(s, s, p16uc_COMPLEX32_REV))));
+template<> EIGEN_STRONG_INLINE Packet2cf pcmp_eq(const Packet2cf& a, const Packet2cf& b) {
+  Packet4f eq = pcmp_eq<Packet4f> (a.v, b.v);
+  Packet2cf res;
+  Packet2d tmp1 = { eq.v4f[0][1], eq.v4f[0][0] };
+  Packet2d tmp2 = { eq.v4f[1][1], eq.v4f[1][0] };
+  res.v.v4f[0] = pand<Packet2d>(eq.v4f[0], tmp1);
+  res.v.v4f[1] = pand<Packet2d>(eq.v4f[1], tmp2);
+  return res;
 }
 
-template<> EIGEN_STRONG_INLINE Packet2cf pcplxflip<Packet2cf>(const Packet2cf& x)
+template<> EIGEN_STRONG_INLINE Packet2cf pconj(const Packet2cf& a)
 {
-  return Packet2cf(vec_perm(x.v, x.v, p16uc_COMPLEX32_REV));
+  Packet2cf res;
+  res.v.v4f[0] = pconj(Packet1cd(reinterpret_cast<Packet2d>(a.v.v4f[0]))).v;
+  res.v.v4f[1] = pconj(Packet1cd(reinterpret_cast<Packet2d>(a.v.v4f[1]))).v;
+  return res;
 }
 
-EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet2cf,2>& kernel)
+template<> EIGEN_STRONG_INLINE Packet2cf pmul<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
 {
-  Packet4f tmp = vec_perm(kernel.packet[0].v, kernel.packet[1].v, p16uc_TRANSPOSE64_HI);
-  kernel.packet[1].v = vec_perm(kernel.packet[0].v, kernel.packet[1].v, p16uc_TRANSPOSE64_LO);
-  kernel.packet[0].v = tmp;
-}
-
-template<> EIGEN_STRONG_INLINE Packet2cf pcmp_eq(const Packet2cf& a, const Packet2cf& b) {
-  Packet4f eq = reinterpret_cast<Packet4f>(vec_cmpeq(a.v,b.v));
-  return Packet2cf(vec_and(eq, vec_perm(eq, eq, p16uc_COMPLEX32_REV)));
+  Packet2cf res;
+  res.v.v4f[0] = pmul(Packet1cd(reinterpret_cast<Packet2d>(a.v.v4f[0])), Packet1cd(reinterpret_cast<Packet2d>(b.v.v4f[0]))).v;
+  res.v.v4f[1] = pmul(Packet1cd(reinterpret_cast<Packet2d>(a.v.v4f[1])), Packet1cd(reinterpret_cast<Packet2d>(b.v.v4f[1]))).v;
+  return res;
 }
 
-#ifdef __VSX__
-template<> EIGEN_STRONG_INLINE Packet2cf pblend(const Selector<2>& ifPacket, const Packet2cf& thenPacket, const Packet2cf& elsePacket) {
-  Packet2cf result;
-  result.v = reinterpret_cast<Packet4f>(pblend<Packet2d>(ifPacket, reinterpret_cast<Packet2d>(thenPacket.v), reinterpret_cast<Packet2d>(elsePacket.v)));
-  return result;
+template<> EIGEN_STRONG_INLINE Packet2cf preverse(const Packet2cf& a)
+{
+  Packet2cf res;
+  res.cd[0] = a.cd[1];
+  res.cd[1] = a.cd[0];
+  return res;
 }
-#endif
 
-//---------- double ----------
-#ifdef __VSX__
-struct Packet1cd
+template<> EIGEN_STRONG_INLINE std::complex<float> predux<Packet2cf>(const Packet2cf& a)
 {
-  EIGEN_STRONG_INLINE Packet1cd() {}
-  EIGEN_STRONG_INLINE explicit Packet1cd(const Packet2d& a) : v(a) {}
-  Packet2d v;
-};
+  std::complex<float> res;
+  Packet1cd b = padd<Packet1cd>(a.cd[0], a.cd[1]);
+  vec_st2f(b.v, (float*)&res);
+  return res;
+}
 
-template<> struct packet_traits<std::complex<double> >  : default_packet_traits
+template<> EIGEN_STRONG_INLINE std::complex<float> predux_mul<Packet2cf>(const Packet2cf& a)
 {
-  typedef Packet1cd type;
-  typedef Packet1cd half;
-  enum {
-    Vectorizable = 1,
-    AlignedOnScalar = 0,
-    size = 1,
-    HasHalfPacket = 0,
-
-    HasAdd    = 1,
-    HasSub    = 1,
-    HasMul    = 1,
-    HasDiv    = 1,
-    HasNegate = 1,
-    HasAbs    = 0,
-    HasAbs2   = 0,
-    HasMin    = 0,
-    HasMax    = 0,
-    HasSetLinear = 0
-  };
-};
-
-template<> struct unpacket_traits<Packet1cd> { typedef std::complex<double> type; enum {size=1, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet1cd half; };
-
-template<> EIGEN_STRONG_INLINE Packet1cd pload <Packet1cd>(const std::complex<double>* from) { return Packet1cd(pload<Packet2d>((const double*)from)); }
-template<> EIGEN_STRONG_INLINE Packet1cd ploadu<Packet1cd>(const std::complex<double>* from) { return Packet1cd(ploadu<Packet2d>((const double*)from)); }
-template<> EIGEN_STRONG_INLINE void pstore <std::complex<double> >(std::complex<double> *   to, const Packet1cd& from) { pstore((double*)to, from.v); }
-template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<double> >(std::complex<double> *   to, const Packet1cd& from) { pstoreu((double*)to, from.v); }
+  std::complex<float> res;
+  Packet1cd b = pmul<Packet1cd>(a.cd[0], a.cd[1]);
+  vec_st2f(b.v, (float*)&res);
+  return res;
+}
 
-template<> EIGEN_STRONG_INLINE Packet1cd pset1<Packet1cd>(const std::complex<double>&  from)
-{ /* here we really have to use unaligned loads :( */ return ploadu<Packet1cd>(&from); }
+EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf,Packet4f)
 
-template<> EIGEN_DEVICE_FUNC inline Packet1cd pgather<std::complex<double>, Packet1cd>(const std::complex<double>* from, Index stride)
+template<> EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
 {
-  EIGEN_ALIGN16 std::complex<double> af[2];
-  af[0] = from[0*stride];
-  af[1] = from[1*stride];
-  return pload<Packet1cd>(af);
+  // TODO optimize it for AltiVec
+  Packet2cf res;
+  res.cd[0] = pdiv<Packet1cd>(a.cd[0], b.cd[0]);
+  res.cd[1] = pdiv<Packet1cd>(a.cd[1], b.cd[1]);
+  return res;
 }
-template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<double>, Packet1cd>(std::complex<double>* to, const Packet1cd& from, Index stride)
+
+EIGEN_STRONG_INLINE Packet2cf pcplxflip/*<Packet2cf>*/(const Packet2cf& x)
 {
-  EIGEN_ALIGN16 std::complex<double> af[2];
-  pstore<std::complex<double> >(af, from);
-  to[0*stride] = af[0];
-  to[1*stride] = af[1];
+  Packet2cf res;
+  res.cd[0] = pcplxflip(x.cd[0]);
+  res.cd[1] = pcplxflip(x.cd[1]);
+  return res;
 }
 
-template<> EIGEN_STRONG_INLINE Packet1cd padd<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(a.v + b.v); }
-template<> EIGEN_STRONG_INLINE Packet1cd psub<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(a.v - b.v); }
-template<> EIGEN_STRONG_INLINE Packet1cd pnegate(const Packet1cd& a) { return Packet1cd(pnegate(Packet2d(a.v))); }
-template<> EIGEN_STRONG_INLINE Packet1cd pconj(const Packet1cd& a) { return Packet1cd(pxor(a.v, reinterpret_cast<Packet2d>(p2ul_CONJ_XOR2))); }
+EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet2cf,2>& kernel)
+{
+  Packet1cd tmp = kernel.packet[0].cd[1];
+  kernel.packet[0].cd[1] = kernel.packet[1].cd[0];
+  kernel.packet[1].cd[0] = tmp;
+}
 
-template<> EIGEN_STRONG_INLINE Packet1cd pmul<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
+template<> EIGEN_STRONG_INLINE Packet2cf pblend(const Selector<2>& ifPacket, const Packet2cf& thenPacket, const Packet2cf& elsePacket) {
+  Packet2cf result;
+  const Selector<4> ifPacket4 = { ifPacket.select[0], ifPacket.select[0], ifPacket.select[1], ifPacket.select[1] };
+  result.v = pblend<Packet4f>(ifPacket4, thenPacket.v, elsePacket.v);
+  return result;
+}
+#else
+template<> EIGEN_STRONG_INLINE Packet2cf pcmp_eq(const Packet2cf& a, const Packet2cf& b) {
+  Packet4f eq = vec_cmpeq (a.v, b.v);
+  Packet4f tmp = { eq[1], eq[0], eq[3], eq[2] };
+  return (Packet2cf)pand<Packet4f>(eq, tmp);
+}
+template<> EIGEN_STRONG_INLINE Packet2cf pconj(const Packet2cf& a) { return Packet2cf(pxor<Packet4f>(a.v, reinterpret_cast<Packet4f>(p4ui_CONJ_XOR))); }
+template<> EIGEN_STRONG_INLINE Packet2cf pmul<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
 {
-  Packet2d a_re, a_im, v1, v2;
+  Packet4f a_re, a_im, prod, prod_im;
 
   // Permute and multiply the real parts of a and b
-  a_re = vec_perm(a.v, a.v, p16uc_PSET64_HI);
+  a_re = vec_perm(a.v, a.v, p16uc_PSET32_WODD);
+  
   // Get the imaginary parts of a
-  a_im = vec_perm(a.v, a.v, p16uc_PSET64_LO);
-  // multiply a_re * b
-  v1 = vec_madd(a_re, b.v, p2d_ZERO);
+  a_im = vec_perm(a.v, a.v, p16uc_PSET32_WEVEN);
+
   // multiply a_im * b and get the conjugate result
-  v2 = vec_madd(a_im, b.v, p2d_ZERO);
-  v2 = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4ui>(v2), reinterpret_cast<Packet4ui>(v2), 8));
-  v2 = pxor(v2, reinterpret_cast<Packet2d>(p2ul_CONJ_XOR1));
+  prod_im = a_im * b.v;
+  prod_im = pxor<Packet4f>(prod_im, reinterpret_cast<Packet4f>(p4ui_CONJ_XOR));
+  // permute back to a proper order
+  prod_im = vec_perm(prod_im, prod_im, p16uc_COMPLEX32_REV);
 
-  return Packet1cd(padd<Packet2d>(v1, v2));
+  // multiply a_re * b, add prod_im
+  prod = pmadd<Packet4f>(a_re, b.v, prod_im);
+ 
+  return Packet2cf(prod);
 }
 
-template<> EIGEN_STRONG_INLINE Packet1cd pand   <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(pand(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet1cd por    <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(por(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet1cd pxor   <Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(pxor(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet1cd pandnot<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(pandnot(a.v, b.v)); }
-
-template<> EIGEN_STRONG_INLINE Packet1cd ploaddup<Packet1cd>(const std::complex<double>*     from)  { return pset1<Packet1cd>(*from); }
-
-template<> EIGEN_STRONG_INLINE void prefetch<std::complex<double> >(const std::complex<double> * addr)    { EIGEN_PPC_PREFETCH(addr); }
-
-template<> EIGEN_STRONG_INLINE std::complex<double>  pfirst<Packet1cd>(const Packet1cd& a)
+template<> EIGEN_STRONG_INLINE Packet2cf preverse(const Packet2cf& a)
 {
-  EIGEN_ALIGN16 std::complex<double> res[2];
-  pstore<std::complex<double> >(res, a);
-
-  return res[0];
+  Packet4f rev_a;
+  rev_a = vec_perm(a.v, a.v, p16uc_COMPLEX32_REV2);
+  return Packet2cf(rev_a);
 }
 
-template<> EIGEN_STRONG_INLINE Packet1cd preverse(const Packet1cd& a) { return a; }
-
-template<> EIGEN_STRONG_INLINE std::complex<double> predux<Packet1cd>(const Packet1cd& a) { return pfirst(a); }
-template<> EIGEN_STRONG_INLINE Packet1cd preduxp<Packet1cd>(const Packet1cd* vecs)        { return vecs[0]; }
-
-template<> EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet1cd>(const Packet1cd& a) { return pfirst(a); }
-
-template<int Offset>
-struct palign_impl<Offset,Packet1cd>
-{
-  static EIGEN_STRONG_INLINE void run(Packet1cd& /*first*/, const Packet1cd& /*second*/)
-  {
-    // FIXME is it sure we never have to align a Packet1cd?
-    // Even though a std::complex<double> has 16 bytes, it is not necessarily aligned on a 16 bytes boundary...
-  }
-};
-
-template<> struct conj_helper<Packet1cd, Packet1cd, false,true>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet1cd, Packet1cd, true,false>
+template<> EIGEN_STRONG_INLINE std::complex<float> predux<Packet2cf>(const Packet2cf& a)
 {
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
+  Packet4f b;
+  b = vec_sld(a.v, a.v, 8);
+  b = padd<Packet4f>(a.v, b);
+  return pfirst<Packet2cf>(Packet2cf(b));
+}
 
-template<> struct conj_helper<Packet1cd, Packet1cd, true,true>
+template<> EIGEN_STRONG_INLINE std::complex<float> predux_mul<Packet2cf>(const Packet2cf& a)
 {
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
+  Packet4f b;
+  Packet2cf prod;
+  b = vec_sld(a.v, a.v, 8);
+  prod = pmul<Packet2cf>(a, Packet2cf(b));
 
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
+  return pfirst<Packet2cf>(prod);
+}
 
-EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cd,Packet2d)
+EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf,Packet4f)
 
-template<> EIGEN_STRONG_INLINE Packet1cd pdiv<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
+template<> EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
 {
   // TODO optimize it for AltiVec
-  Packet1cd res = conj_helper<Packet1cd,Packet1cd,false,true>().pmul(a,b);
-  Packet2d s = pmul<Packet2d>(b.v, b.v);
-  return Packet1cd(pdiv(res.v, padd<Packet2d>(s, vec_perm(s, s, p16uc_REVERSE64))));
+  Packet2cf res = pmul(a, pconj(b));
+  Packet4f s = pmul<Packet4f>(b.v, b.v);
+  return Packet2cf(pdiv(res.v, padd<Packet4f>(s, vec_perm(s, s, p16uc_COMPLEX32_REV))));
 }
 
-EIGEN_STRONG_INLINE Packet1cd pcplxflip/*<Packet1cd>*/(const Packet1cd& x)
+template<> EIGEN_STRONG_INLINE Packet2cf pcplxflip<Packet2cf>(const Packet2cf& x)
 {
-  return Packet1cd(preverse(Packet2d(x.v)));
+  return Packet2cf(vec_perm(x.v, x.v, p16uc_COMPLEX32_REV));
 }
 
-EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet1cd,2>& kernel)
+EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet2cf,2>& kernel)
 {
-  Packet2d tmp = vec_perm(kernel.packet[0].v, kernel.packet[1].v, p16uc_TRANSPOSE64_HI);
+  Packet4f tmp = vec_perm(kernel.packet[0].v, kernel.packet[1].v, p16uc_TRANSPOSE64_HI);
   kernel.packet[1].v = vec_perm(kernel.packet[0].v, kernel.packet[1].v, p16uc_TRANSPOSE64_LO);
   kernel.packet[0].v = tmp;
 }
 
-template<> EIGEN_STRONG_INLINE Packet1cd pcmp_eq(const Packet1cd& a, const Packet1cd& b) {
-  // Compare real and imaginary parts of a and b to get the mask vector:
-  // [re(a)==re(b), im(a)==im(b)]
-  Packet2d eq = reinterpret_cast<Packet2d>(vec_cmpeq(a.v,b.v));
-  // Swap real/imag elements in the mask in to get:
-  // [im(a)==im(b), re(a)==re(b)]
-  Packet2d eq_swapped = reinterpret_cast<Packet2d>(vec_sld(reinterpret_cast<Packet4ui>(eq), reinterpret_cast<Packet4ui>(eq), 8));
-  // Return re(a)==re(b) & im(a)==im(b) by computing bitwise AND of eq and eq_swapped
-  return Packet1cd(vec_and(eq, eq_swapped));
+template<> EIGEN_STRONG_INLINE Packet2cf pblend(const Selector<2>& ifPacket, const Packet2cf& thenPacket, const Packet2cf& elsePacket) {
+  Packet2cf result;
+  result.v = reinterpret_cast<Packet4f>(pblend<Packet2d>(ifPacket, reinterpret_cast<Packet2d>(thenPacket.v), reinterpret_cast<Packet2d>(elsePacket.v)));
+  return result;
 }
+#endif
 
-#endif // __VSX__
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_COMPLEX32_ALTIVEC_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/AltiVec/MathFunctions.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AltiVec/MathFunctions.h`

 * *Files 5% similar despite different names*

```diff
@@ -8,16 +8,14 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_MATH_FUNCTIONS_ALTIVEC_H
 #define EIGEN_MATH_FUNCTIONS_ALTIVEC_H
 
-#include "../Default/GenericPacketMathFunctions.h"
-
 namespace Eigen {
 
 namespace internal {
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4f plog<Packet4f>(const Packet4f& _x)
 {
@@ -74,12 +72,19 @@
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet2d pexp<Packet2d>(const Packet2d& _x)
 {
   return pexp_double(_x);
 }
 #endif
 
+// Hyperbolic Tangent function.
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet4f
+ptanh<Packet4f>(const Packet4f& x) {
+  return internal::generic_fast_tanh_float(x);
+}
+
 }  // end namespace internal
 
 }  // end namespace Eigen
 
 #endif  // EIGEN_MATH_FUNCTIONS_ALTIVEC_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/Default/Settings.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/Default/Settings.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/GPU/MathFunctions.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/GPU/MathFunctions.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/GPU/PacketMathHalf.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/GPU/PacketMath.h`

 * *Files 25% similar despite different names*

```diff
@@ -1,1630 +1,1649 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
-// Copyright (C) 2016 Benoit Steiner <benoit.steiner.goog@gmail.com>
+// Copyright (C) 2014 Benoit Steiner <benoit.steiner.goog@gmail.com>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
-#ifndef EIGEN_PACKET_MATH_HALF_GPU_H
-#define EIGEN_PACKET_MATH_HALF_GPU_H
-
+#ifndef EIGEN_PACKET_MATH_GPU_H
+#define EIGEN_PACKET_MATH_GPU_H
 
 namespace Eigen {
+
 namespace internal {
 
-// Most of the following operations require arch >= 3.0
-#if (defined(EIGEN_HAS_CUDA_FP16) && defined(EIGEN_CUDACC) && defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 300) || \
-  (defined(EIGEN_HAS_HIP_FP16) && defined(EIGEN_HIPCC) && defined(EIGEN_HIP_DEVICE_COMPILE)) || \
-  (defined(EIGEN_HAS_CUDA_FP16) && defined(__clang__) && defined(__CUDA__))
+// Read-only data cached load available.
+#if defined(EIGEN_HIP_DEVICE_COMPILE) || (defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 350)
+#define EIGEN_GPU_HAS_LDG 1
+#endif
+
+// FP16 math available.
+#if (defined(EIGEN_CUDA_ARCH) && EIGEN_CUDA_ARCH >= 530)
+#define EIGEN_CUDA_HAS_FP16_ARITHMETIC 1
+#endif
+
+#if defined(EIGEN_HIP_DEVICE_COMPILE) || defined(EIGEN_CUDA_HAS_FP16_ARITHMETIC)
+#define EIGEN_GPU_HAS_FP16_ARITHMETIC 1
+#endif
+
+// Make sure this is only available when targeting a GPU: we don't want to
+// introduce conflicts between these packet_traits definitions and the ones
+// we'll use on the host side (SSE, AVX, ...)
+#if defined(EIGEN_GPUCC) && defined(EIGEN_USE_GPU)
+
+template<> struct is_arithmetic<float4>  { enum { value = true }; };
+template<> struct is_arithmetic<double2> { enum { value = true }; };
+
+template<> struct packet_traits<float> : default_packet_traits
+{
+  typedef float4 type;
+  typedef float4 half;
+  enum {
+    Vectorizable = 1,
+    AlignedOnScalar = 1,
+    size=4,
+    HasHalfPacket = 0,
+
+    HasDiv  = 1,
+    HasSin  = 0,
+    HasCos  = 0,
+    HasLog  = 1,
+    HasExp  = 1,
+    HasSqrt = 1,
+    HasRsqrt = 1,
+    HasLGamma = 1,
+    HasDiGamma = 1,
+    HasZeta = 1,
+    HasPolygamma = 1,
+    HasErf = 1,
+    HasErfc = 1,
+    HasNdtri = 1,
+    HasBessel = 1,
+    HasIGamma = 1,
+    HasIGammaDerA = 1,
+    HasGammaSampleDerAlpha = 1,
+    HasIGammac = 1,
+    HasBetaInc = 1,
+
+    HasBlend = 0,
+    HasFloor = 1,
+  };
+};
+
+template<> struct packet_traits<double> : default_packet_traits
+{
+  typedef double2 type;
+  typedef double2 half;
+  enum {
+    Vectorizable = 1,
+    AlignedOnScalar = 1,
+    size=2,
+    HasHalfPacket = 0,
+
+    HasDiv  = 1,
+    HasLog  = 1,
+    HasExp  = 1,
+    HasSqrt = 1,
+    HasRsqrt = 1,
+    HasLGamma = 1,
+    HasDiGamma = 1,
+    HasZeta = 1,
+    HasPolygamma = 1,
+    HasErf = 1,
+    HasErfc = 1,
+    HasNdtri = 1,
+    HasBessel = 1,
+    HasIGamma = 1,
+    HasIGammaDerA = 1,
+    HasGammaSampleDerAlpha = 1,
+    HasIGammac = 1,
+    HasBetaInc = 1,
+
+    HasBlend = 0,
+    HasFloor = 1,
+  };
+};
+
+
+template<> struct unpacket_traits<float4>  { typedef float  type; enum {size=4, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef float4 half; };
+template<> struct unpacket_traits<double2> { typedef double type; enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef double2 half; };
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pset1<float4>(const float&  from) {
+  return make_float4(from, from, from, from);
+}
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 pset1<double2>(const double& from) {
+  return make_double2(from, from);
+}
+
+// We need to distinguish ‘clang as the CUDA compiler’ from ‘clang as the host compiler,
+// invoked by NVCC’ (e.g. on MacOS). The former needs to see both host and device implementation
+// of the functions, while the latter can only deal with one of them.
+#if defined(EIGEN_CUDA_ARCH) || defined(EIGEN_HIPCC) || (defined(EIGEN_CUDACC) && EIGEN_COMP_CLANG && !EIGEN_COMP_NVCC)
+namespace {
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float bitwise_and(const float& a,
+                                                        const float& b) {
+  return __int_as_float(__float_as_int(a) & __float_as_int(b));
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double bitwise_and(const double& a,
+                                                         const double& b) {
+  return __longlong_as_double(__double_as_longlong(a) &
+                              __double_as_longlong(b));
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float bitwise_or(const float& a,
+                                                       const float& b) {
+  return __int_as_float(__float_as_int(a) | __float_as_int(b));
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double bitwise_or(const double& a,
+                                                        const double& b) {
+  return __longlong_as_double(__double_as_longlong(a) |
+                              __double_as_longlong(b));
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float bitwise_xor(const float& a,
+                                                        const float& b) {
+  return __int_as_float(__float_as_int(a) ^ __float_as_int(b));
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double bitwise_xor(const double& a,
+                                                         const double& b) {
+  return __longlong_as_double(__double_as_longlong(a) ^
+                              __double_as_longlong(b));
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float bitwise_andnot(const float& a,
+                                                           const float& b) {
+  return __int_as_float(__float_as_int(a) & ~__float_as_int(b));
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double bitwise_andnot(const double& a,
+                                                            const double& b) {
+  return __longlong_as_double(__double_as_longlong(a) &
+                              ~__double_as_longlong(b));
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float eq_mask(const float& a,
+                                                    const float& b) {
+  return __int_as_float(a == b ? 0xffffffffu : 0u);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double eq_mask(const double& a,
+                                                     const double& b) {
+  return __longlong_as_double(a == b ? 0xffffffffffffffffull : 0ull);
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float lt_mask(const float& a,
+                                                    const float& b) {
+  return __int_as_float(a < b ? 0xffffffffu : 0u);
+}
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double lt_mask(const double& a,
+                                                     const double& b) {
+  return __longlong_as_double(a < b ? 0xffffffffffffffffull : 0ull);
+}
+
+}  // namespace
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pand<float4>(const float4& a,
+                                                          const float4& b) {
+  return make_float4(bitwise_and(a.x, b.x), bitwise_and(a.y, b.y),
+                     bitwise_and(a.z, b.z), bitwise_and(a.w, b.w));
+}
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 pand<double2>(const double2& a,
+                                                            const double2& b) {
+  return make_double2(bitwise_and(a.x, b.x), bitwise_and(a.y, b.y));
+}
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 por<float4>(const float4& a,
+                                                         const float4& b) {
+  return make_float4(bitwise_or(a.x, b.x), bitwise_or(a.y, b.y),
+                     bitwise_or(a.z, b.z), bitwise_or(a.w, b.w));
+}
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 por<double2>(const double2& a,
+                                                           const double2& b) {
+  return make_double2(bitwise_or(a.x, b.x), bitwise_or(a.y, b.y));
+}
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pxor<float4>(const float4& a,
+                                                          const float4& b) {
+  return make_float4(bitwise_xor(a.x, b.x), bitwise_xor(a.y, b.y),
+                     bitwise_xor(a.z, b.z), bitwise_xor(a.w, b.w));
+}
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 pxor<double2>(const double2& a,
+                                                            const double2& b) {
+  return make_double2(bitwise_xor(a.x, b.x), bitwise_xor(a.y, b.y));
+}
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pandnot<float4>(const float4& a,
+                                                             const float4& b) {
+  return make_float4(bitwise_andnot(a.x, b.x), bitwise_andnot(a.y, b.y),
+                     bitwise_andnot(a.z, b.z), bitwise_andnot(a.w, b.w));
+}
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2
+pandnot<double2>(const double2& a, const double2& b) {
+  return make_double2(bitwise_andnot(a.x, b.x), bitwise_andnot(a.y, b.y));
+}
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pcmp_eq<float4>(const float4& a,
+                                                             const float4& b) {
+  return make_float4(eq_mask(a.x, b.x), eq_mask(a.y, b.y), eq_mask(a.z, b.z),
+                     eq_mask(a.w, b.w));
+}
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pcmp_lt<float4>(const float4& a,
+                                                             const float4& b) {
+  return make_float4(lt_mask(a.x, b.x), lt_mask(a.y, b.y), lt_mask(a.z, b.z),
+                     lt_mask(a.w, b.w));
+}
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2
+pcmp_eq<double2>(const double2& a, const double2& b) {
+  return make_double2(eq_mask(a.x, b.x), eq_mask(a.y, b.y));
+}
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2
+pcmp_lt<double2>(const double2& a, const double2& b) {
+  return make_double2(lt_mask(a.x, b.x), lt_mask(a.y, b.y));
+}
+#endif // defined(EIGEN_CUDA_ARCH) || defined(EIGEN_HIPCC) || (defined(EIGEN_CUDACC) && EIGEN_COMP_CLANG && !EIGEN_COMP_NVCC)
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 plset<float4>(const float& a) {
+  return make_float4(a, a+1, a+2, a+3);
+}
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 plset<double2>(const double& a) {
+  return make_double2(a, a+1);
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 padd<float4>(const float4& a, const float4& b) {
+  return make_float4(a.x+b.x, a.y+b.y, a.z+b.z, a.w+b.w);
+}
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 padd<double2>(const double2& a, const double2& b) {
+  return make_double2(a.x+b.x, a.y+b.y);
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 psub<float4>(const float4& a, const float4& b) {
+  return make_float4(a.x-b.x, a.y-b.y, a.z-b.z, a.w-b.w);
+}
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 psub<double2>(const double2& a, const double2& b) {
+  return make_double2(a.x-b.x, a.y-b.y);
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pnegate(const float4& a) {
+  return make_float4(-a.x, -a.y, -a.z, -a.w);
+}
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 pnegate(const double2& a) {
+  return make_double2(-a.x, -a.y);
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pconj(const float4& a) { return a; }
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 pconj(const double2& a) { return a; }
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pmul<float4>(const float4& a, const float4& b) {
+  return make_float4(a.x*b.x, a.y*b.y, a.z*b.z, a.w*b.w);
+}
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 pmul<double2>(const double2& a, const double2& b) {
+  return make_double2(a.x*b.x, a.y*b.y);
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pdiv<float4>(const float4& a, const float4& b) {
+  return make_float4(a.x/b.x, a.y/b.y, a.z/b.z, a.w/b.w);
+}
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 pdiv<double2>(const double2& a, const double2& b) {
+  return make_double2(a.x/b.x, a.y/b.y);
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pmin<float4>(const float4& a, const float4& b) {
+  return make_float4(fminf(a.x, b.x), fminf(a.y, b.y), fminf(a.z, b.z), fminf(a.w, b.w));
+}
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 pmin<double2>(const double2& a, const double2& b) {
+  return make_double2(fmin(a.x, b.x), fmin(a.y, b.y));
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pmax<float4>(const float4& a, const float4& b) {
+  return make_float4(fmaxf(a.x, b.x), fmaxf(a.y, b.y), fmaxf(a.z, b.z), fmaxf(a.w, b.w));
+}
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 pmax<double2>(const double2& a, const double2& b) {
+  return make_double2(fmax(a.x, b.x), fmax(a.y, b.y));
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 pload<float4>(const float* from) {
+  return *reinterpret_cast<const float4*>(from);
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 pload<double2>(const double* from) {
+  return *reinterpret_cast<const double2*>(from);
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 ploadu<float4>(const float* from) {
+  return make_float4(from[0], from[1], from[2], from[3]);
+}
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 ploadu<double2>(const double* from) {
+  return make_double2(from[0], from[1]);
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float4 ploaddup<float4>(const float*   from) {
+  return make_float4(from[0], from[0], from[1], from[1]);
+}
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE double2 ploaddup<double2>(const double*  from) {
+  return make_double2(from[0], from[0]);
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstore<float>(float*   to, const float4& from) {
+  *reinterpret_cast<float4*>(to) = from;
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstore<double>(double* to, const double2& from) {
+  *reinterpret_cast<double2*>(to) = from;
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstoreu<float>(float*  to, const float4& from) {
+  to[0] = from.x;
+  to[1] = from.y;
+  to[2] = from.z;
+  to[3] = from.w;
+}
+
+template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstoreu<double>(double* to, const double2& from) {
+  to[0] = from.x;
+  to[1] = from.y;
+}
+
+template<>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float4 ploadt_ro<float4, Aligned>(const float* from) {
+#if defined(EIGEN_GPU_HAS_LDG)
+  return __ldg((const float4*)from);
+#else
+  return make_float4(from[0], from[1], from[2], from[3]);
+#endif
+}
+template<>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double2 ploadt_ro<double2, Aligned>(const double* from) {
+#if defined(EIGEN_GPU_HAS_LDG)
+  return __ldg((const double2*)from);
+#else
+  return make_double2(from[0], from[1]);
+#endif
+}
 
+template<>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE float4 ploadt_ro<float4, Unaligned>(const float* from) {
+#if defined(EIGEN_GPU_HAS_LDG)
+  return make_float4(__ldg(from+0), __ldg(from+1), __ldg(from+2), __ldg(from+3));
+#else
+  return make_float4(from[0], from[1], from[2], from[3]);
+#endif
+}
+template<>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE double2 ploadt_ro<double2, Unaligned>(const double* from) {
+#if defined(EIGEN_GPU_HAS_LDG)
+  return make_double2(__ldg(from+0), __ldg(from+1));
+#else
+  return make_double2(from[0], from[1]);
+#endif
+}
+
+template<> EIGEN_DEVICE_FUNC inline float4 pgather<float, float4>(const float* from, Index stride) {
+  return make_float4(from[0*stride], from[1*stride], from[2*stride], from[3*stride]);
+}
+
+template<> EIGEN_DEVICE_FUNC inline double2 pgather<double, double2>(const double* from, Index stride) {
+  return make_double2(from[0*stride], from[1*stride]);
+}
+
+template<> EIGEN_DEVICE_FUNC inline void pscatter<float, float4>(float* to, const float4& from, Index stride) {
+  to[stride*0] = from.x;
+  to[stride*1] = from.y;
+  to[stride*2] = from.z;
+  to[stride*3] = from.w;
+}
+template<> EIGEN_DEVICE_FUNC inline void pscatter<double, double2>(double* to, const double2& from, Index stride) {
+  to[stride*0] = from.x;
+  to[stride*1] = from.y;
+}
+
+template<> EIGEN_DEVICE_FUNC inline float  pfirst<float4>(const float4& a) {
+  return a.x;
+}
+template<> EIGEN_DEVICE_FUNC inline double pfirst<double2>(const double2& a) {
+  return a.x;
+}
+
+template<> EIGEN_DEVICE_FUNC inline float  predux<float4>(const float4& a) {
+  return a.x + a.y + a.z + a.w;
+}
+template<> EIGEN_DEVICE_FUNC inline double predux<double2>(const double2& a) {
+  return a.x + a.y;
+}
+
+template<> EIGEN_DEVICE_FUNC inline float  predux_max<float4>(const float4& a) {
+  return fmaxf(fmaxf(a.x, a.y), fmaxf(a.z, a.w));
+}
+template<> EIGEN_DEVICE_FUNC inline double predux_max<double2>(const double2& a) {
+  return fmax(a.x, a.y);
+}
+
+template<> EIGEN_DEVICE_FUNC inline float  predux_min<float4>(const float4& a) {
+  return fminf(fminf(a.x, a.y), fminf(a.z, a.w));
+}
+template<> EIGEN_DEVICE_FUNC inline double predux_min<double2>(const double2& a) {
+  return fmin(a.x, a.y);
+}
+
+template<> EIGEN_DEVICE_FUNC inline float  predux_mul<float4>(const float4& a) {
+  return a.x * a.y * a.z * a.w;
+}
+template<> EIGEN_DEVICE_FUNC inline double predux_mul<double2>(const double2& a) {
+  return a.x * a.y;
+}
+
+template<> EIGEN_DEVICE_FUNC inline float4  pabs<float4>(const float4& a) {
+  return make_float4(fabsf(a.x), fabsf(a.y), fabsf(a.z), fabsf(a.w));
+}
+template<> EIGEN_DEVICE_FUNC inline double2 pabs<double2>(const double2& a) {
+  return make_double2(fabs(a.x), fabs(a.y));
+}
+
+template<> EIGEN_DEVICE_FUNC inline float4  pfloor<float4>(const float4& a) {
+  return make_float4(floorf(a.x), floorf(a.y), floorf(a.z), floorf(a.w));
+}
+template<> EIGEN_DEVICE_FUNC inline double2 pfloor<double2>(const double2& a) {
+  return make_double2(floor(a.x), floor(a.y));
+}
+
+EIGEN_DEVICE_FUNC inline void
+ptranspose(PacketBlock<float4,4>& kernel) {
+  float tmp = kernel.packet[0].y;
+  kernel.packet[0].y = kernel.packet[1].x;
+  kernel.packet[1].x = tmp;
+
+  tmp = kernel.packet[0].z;
+  kernel.packet[0].z = kernel.packet[2].x;
+  kernel.packet[2].x = tmp;
+
+  tmp = kernel.packet[0].w;
+  kernel.packet[0].w = kernel.packet[3].x;
+  kernel.packet[3].x = tmp;
+
+  tmp = kernel.packet[1].z;
+  kernel.packet[1].z = kernel.packet[2].y;
+  kernel.packet[2].y = tmp;
+
+  tmp = kernel.packet[1].w;
+  kernel.packet[1].w = kernel.packet[3].y;
+  kernel.packet[3].y = tmp;
+
+  tmp = kernel.packet[2].w;
+  kernel.packet[2].w = kernel.packet[3].z;
+  kernel.packet[3].z = tmp;
+}
+
+EIGEN_DEVICE_FUNC inline void
+ptranspose(PacketBlock<double2,2>& kernel) {
+  double tmp = kernel.packet[0].y;
+  kernel.packet[0].y = kernel.packet[1].x;
+  kernel.packet[1].x = tmp;
+}
+
+#endif // defined(EIGEN_GPUCC) && defined(EIGEN_USE_GPU)
+
+// Half-packet functions are not available on the host for CUDA 9.0-9.2, only
+// on device. There is no benefit to using them on the host anyways, since they are
+// emulated.
+#if (defined(EIGEN_HAS_CUDA_FP16) || defined(EIGEN_HAS_HIP_FP16)) && defined(EIGEN_GPU_COMPILE_PHASE)
+
+typedef ulonglong2 Packet4h2;
+template<> struct unpacket_traits<Packet4h2> { typedef Eigen::half type; enum {size=8, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet4h2 half; };
+template<> struct is_arithmetic<Packet4h2> { enum { value = true }; };
+
+template<> struct unpacket_traits<half2> { typedef Eigen::half type; enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef half2 half; };
 template<> struct is_arithmetic<half2> { enum { value = true }; };
 
 template<> struct packet_traits<Eigen::half> : default_packet_traits
 {
-  typedef half2 type;
-  typedef half2 half;
+  typedef Packet4h2 type;
+  typedef Packet4h2 half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
-    size=2,
+    size=8,
     HasHalfPacket = 0,
     HasAdd    = 1,
     HasSub    = 1,
     HasMul    = 1,
     HasDiv    = 1,
     HasSqrt   = 1,
     HasRsqrt  = 1,
     HasExp    = 1,
     HasExpm1  = 1,
     HasLog    = 1,
     HasLog1p  = 1
   };
 };
 
-template<> struct unpacket_traits<half2> { typedef Eigen::half type; enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef half2 half; };
+template<>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pset1<half2>(const Eigen::half& from) {
+  return __half2half2(from);
+}
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pset1<half2>(const Eigen::half& from) {
-#if !defined(EIGEN_CUDA_ARCH) && !defined(EIGEN_HIP_DEVICE_COMPILE)
-  half2 r;
-  r.x = from;
-  r.y = from;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+pset1<Packet4h2>(const Eigen::half& from) {
+  Packet4h2 r;
+  half2* p_alias = reinterpret_cast<half2*>(&r);
+  p_alias[0] = pset1<half2>(from);
+  p_alias[1] = pset1<half2>(from);
+  p_alias[2] = pset1<half2>(from);
+  p_alias[3] = pset1<half2>(from);
   return r;
-#else
-  return __half2half2(from);
-#endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pload<half2>(const Eigen::half* from) {
+namespace {
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pload(const Eigen::half* from) {
   return *reinterpret_cast<const half2*>(from);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 ploadu<half2>(const Eigen::half* from) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 ploadu(const Eigen::half* from) {
   return __halves2half2(from[0], from[1]);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 ploaddup<half2>(const Eigen::half*  from) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 ploaddup(const Eigen::half*  from) {
   return __halves2half2(from[0], from[0]);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstore<Eigen::half>(Eigen::half* to, const half2& from) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstore(Eigen::half* to,
+                                                  const half2& from) {
   *reinterpret_cast<half2*>(to) = from;
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstoreu<Eigen::half>(Eigen::half* to, const half2& from) {
-#if !defined(EIGEN_CUDA_ARCH) && !defined(EIGEN_HIP_DEVICE_COMPILE)
-  to[0] = from.x;
-  to[1] = from.y;
-#else
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstoreu(Eigen::half* to,
+                                                   const half2& from) {
   to[0] = __low2half(from);
   to[1] = __high2half(from);
-#endif
 }
 
-template<>
- EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE half2 ploadt_ro<half2, Aligned>(const Eigen::half* from) {
 
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __ldg((const half2*)from);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 350
-   return __ldg((const half2*)from);
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE half2 ploadt_ro_aligned(
+    const Eigen::half* from) {
+#if defined(EIGEN_GPU_HAS_LDG)
+  // Input is guaranteed to be properly aligned.
+  return __ldg(reinterpret_cast<const half2*>(from));
 #else
   return __halves2half2(*(from+0), *(from+1));
 #endif
-
-#endif
 }
 
-template<>
-EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE half2 ploadt_ro<half2, Unaligned>(const Eigen::half* from) {
-
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE half2 ploadt_ro_unaligned(
+    const Eigen::half* from) {
+#if defined(EIGEN_GPU_HAS_LDG)
   return __halves2half2(__ldg(from+0), __ldg(from+1));
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 350
-   return __halves2half2(__ldg(from+0), __ldg(from+1));
 #else
   return __halves2half2(*(from+0), *(from+1));
 #endif
-
-#endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pgather<Eigen::half, half2>(const Eigen::half* from, Index stride) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pgather(const Eigen::half* from,
+                                                    Index stride) {
   return __halves2half2(from[0*stride], from[1*stride]);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<Eigen::half, half2>(Eigen::half* to, const half2& from, Index stride) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter(
+    Eigen::half* to, const half2& from, Index stride) {
   to[stride*0] = __low2half(from);
   to[stride*1] = __high2half(from);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half pfirst<half2>(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half pfirst(const half2& a) {
   return __low2half(a);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pabs<half2>(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pabs(const half2& a) {
   half a1 = __low2half(a);
   half a2 = __high2half(a);
   half result1 = half_impl::raw_uint16_to_half(a1.x & 0x7FFF);
   half result2 = half_impl::raw_uint16_to_half(a2.x & 0x7FFF);
   return __halves2half2(result1, result2);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 ptrue<half2>(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 ptrue(const half2& /*a*/) {
   half true_half = half_impl::raw_uint16_to_half(0xffffu);
   return pset1<half2>(true_half);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pzero<half2>(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pzero(const half2& /*a*/) {
   half false_half = half_impl::raw_uint16_to_half(0x0000u);
   return pset1<half2>(false_half);
 }
 
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void
 ptranspose(PacketBlock<half2,2>& kernel) {
   __half a1 = __low2half(kernel.packet[0]);
   __half a2 = __high2half(kernel.packet[0]);
   __half b1 = __low2half(kernel.packet[1]);
   __half b2 = __high2half(kernel.packet[1]);
   kernel.packet[0] = __halves2half2(a1, b1);
   kernel.packet[1] = __halves2half2(a2, b2);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 plset<half2>(const Eigen::half& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-  
-  return __halves2half2(a, __hadd(a, __float2half(1.0f)));
-  
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 plset(const Eigen::half& a) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __halves2half2(a, __hadd(a, __float2half(1.0f)));
 #else
   float f = __half2float(a) + 1.0f;
   return __halves2half2(a, __float2half(f));
 #endif
-
-#endif
 }
 
-template <>
-EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pselect<half2>(const half2& mask,
-                                                           const half2& a,
-                                                           const half2& b) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pselect(const half2& mask,
+                                                    const half2& a,
+                                                    const half2& b) {
   half mask_low = __low2half(mask);
   half mask_high = __high2half(mask);
   half result_low = mask_low == half(0) ? __low2half(b) : __low2half(a);
   half result_high = mask_high == half(0) ? __high2half(b) : __high2half(a);
   return __halves2half2(result_low, result_high);
 }
 
-template <>
-EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pcmp_eq<half2>(const half2& a,
-                                                           const half2& b) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pcmp_eq(const half2& a,
+                                                    const half2& b) {
   half true_half = half_impl::raw_uint16_to_half(0xffffu);
   half false_half = half_impl::raw_uint16_to_half(0x0000u);
   half a1 = __low2half(a);
   half a2 = __high2half(a);
   half b1 = __low2half(b);
   half b2 = __high2half(b);
   half eq1 = __half2float(a1) == __half2float(b1) ? true_half : false_half;
   half eq2 = __half2float(a2) == __half2float(b2) ? true_half : false_half;
   return __halves2half2(eq1, eq2);
 }
 
-template <>
-EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pand<half2>(const half2& a,
-                                                        const half2& b) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pcmp_lt(const half2& a,
+                                                    const half2& b) {
+  half true_half = half_impl::raw_uint16_to_half(0xffffu);
+  half false_half = half_impl::raw_uint16_to_half(0x0000u);
+  half a1 = __low2half(a);
+  half a2 = __high2half(a);
+  half b1 = __low2half(b);
+  half b2 = __high2half(b);
+  half eq1 = __half2float(a1) < __half2float(b1) ? true_half : false_half;
+  half eq2 = __half2float(a2) < __half2float(b2) ? true_half : false_half;
+  return __halves2half2(eq1, eq2);
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pand(const half2& a,
+                                                 const half2& b) {
   half a1 = __low2half(a);
   half a2 = __high2half(a);
   half b1 = __low2half(b);
   half b2 = __high2half(b);
   half result1 = half_impl::raw_uint16_to_half(a1.x & b1.x);
   half result2 = half_impl::raw_uint16_to_half(a2.x & b2.x);
   return __halves2half2(result1, result2);
 }
 
-template <>
-EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 por<half2>(const half2& a,
-                                                       const half2& b) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 por(const half2& a,
+                                                const half2& b) {
   half a1 = __low2half(a);
   half a2 = __high2half(a);
   half b1 = __low2half(b);
   half b2 = __high2half(b);
   half result1 = half_impl::raw_uint16_to_half(a1.x | b1.x);
   half result2 = half_impl::raw_uint16_to_half(a2.x | b2.x);
   return __halves2half2(result1, result2);
 }
 
-template <>
-EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pxor<half2>(const half2& a,
-                                                        const half2& b) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pxor(const half2& a,
+                                                 const half2& b) {
   half a1 = __low2half(a);
   half a2 = __high2half(a);
   half b1 = __low2half(b);
   half b2 = __high2half(b);
   half result1 = half_impl::raw_uint16_to_half(a1.x ^ b1.x);
   half result2 = half_impl::raw_uint16_to_half(a2.x ^ b2.x);
   return __halves2half2(result1, result2);
 }
 
-template <>
-EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pandnot<half2>(const half2& a,
-                                                           const half2& b) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pandnot(const half2& a,
+                                                    const half2& b) {
   half a1 = __low2half(a);
   half a2 = __high2half(a);
   half b1 = __low2half(b);
   half b2 = __high2half(b);
   half result1 = half_impl::raw_uint16_to_half(a1.x & ~b1.x);
   half result2 = half_impl::raw_uint16_to_half(a2.x & ~b2.x);
   return __halves2half2(result1, result2);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 padd<half2>(const half2& a, const half2& b) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hadd2(a, b);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 padd(const half2& a,
+                                                 const half2& b) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hadd2(a, b);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float r1 = a1 + b1;
   float r2 = a2 + b2;
   return __floats2half2_rn(r1, r2);
 #endif
-
-#endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 psub<half2>(const half2& a, const half2& b) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hsub2(a, b);
-  
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 psub(const half2& a,
+                                                 const half2& b) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hsub2(a, b);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float r1 = a1 - b1;
   float r2 = a2 - b2;
   return __floats2half2_rn(r1, r2);
 #endif
-
-#endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pnegate(const half2& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hneg2(a);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pnegate(const half2& a) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hneg2(a);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   return __floats2half2_rn(-a1, -a2);
 #endif
-
-#endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pconj(const half2& a) { return a; }
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pconj(const half2& a) { return a; }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmul<half2>(const half2& a, const half2& b) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hmul2(a, b);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmul(const half2& a,
+                                                 const half2& b) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hmul2(a, b);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float r1 = a1 * b1;
   float r2 = a2 * b2;
   return __floats2half2_rn(r1, r2);
 #endif
-
-#endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmadd<half2>(const half2& a, const half2& b, const half2& c) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-   return __hfma2(a, b, c);
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmadd(const half2& a,
+                                                  const half2& b,
+                                                  const half2& c) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
    return __hfma2(a, b, c);
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float c1 = __low2float(c);
   float c2 = __high2float(c);
   float r1 = a1 * b1 + c1;
   float r2 = a2 * b2 + c2;
   return __floats2half2_rn(r1, r2);
 #endif
-
-#endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pdiv<half2>(const half2& a, const half2& b) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-  
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pdiv(const half2& a,
+                                                 const half2& b) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __h2div(a, b);
-  
-#else // EIGEN_CUDA_ARCH
-  
+#else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   float r1 = a1 / b1;
   float r2 = a2 / b2;
   return __floats2half2_rn(r1, r2);
-
 #endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmin<half2>(const half2& a, const half2& b) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmin(const half2& a,
+                                                 const half2& b) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   __half r1 = a1 < b1 ? __low2half(a) : __low2half(b);
   __half r2 = a2 < b2 ? __high2half(a) : __high2half(b);
   return __halves2half2(r1, r2);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmax<half2>(const half2& a, const half2& b) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmax(const half2& a,
+                                                 const half2& b) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float b1 = __low2float(b);
   float b2 = __high2float(b);
   __half r1 = a1 > b1 ? __low2half(a) : __low2half(b);
   __half r2 = a2 > b2 ? __high2half(a) : __high2half(b);
   return __halves2half2(r1, r2);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux<half2>(const half2& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hadd(__low2half(a), __high2half(a));
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux(const half2& a) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hadd(__low2half(a), __high2half(a));
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   return Eigen::half(__float2half(a1 + a2));
 #endif
-
-#endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_max<half2>(const half2& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  __half first = __low2half(a);
-  __half second = __high2half(a);
-  return __hgt(first, second) ? first : second;
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_max(const half2& a) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   __half first = __low2half(a);
   __half second = __high2half(a);
   return __hgt(first, second) ? first : second;
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   return a1 > a2 ? __low2half(a) : __high2half(a);
 #endif
-
-#endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_min<half2>(const half2& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  __half first = __low2half(a);
-  __half second = __high2half(a);
-  return __hlt(first, second) ? first : second;
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_min(const half2& a) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   __half first = __low2half(a);
   __half second = __high2half(a);
   return __hlt(first, second) ? first : second;
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   return a1 < a2 ? __low2half(a) : __high2half(a);
 #endif
-
-#endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_mul<half2>(const half2& a) {
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
-
-  return __hmul(__low2half(a), __high2half(a));
-
-#else  // EIGEN_CUDA_ARCH
-
-#if EIGEN_CUDA_ARCH >= 530
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_mul(const half2& a) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
   return __hmul(__low2half(a), __high2half(a));
 #else
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   return Eigen::half(__float2half(a1 * a2));
 #endif
-
-#endif
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 plog1p<half2>(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 plog1p(const half2& a) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float r1 = log1pf(a1);
   float r2 = log1pf(a2);
   return __floats2half2_rn(r1, r2);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pexpm1<half2>(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pexpm1(const half2& a) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float r1 = expm1f(a1);
   float r2 = expm1f(a2);
   return __floats2half2_rn(r1, r2);
 }
 
-#if (EIGEN_CUDA_SDK_VER >= 80000 && defined EIGEN_CUDA_ARCH && EIGEN_CUDA_ARCH >= 530) || \
+#if (EIGEN_CUDA_SDK_VER >= 80000 && defined(EIGEN_CUDA_HAS_FP16_ARITHMETIC)) || \
   defined(EIGEN_HIP_DEVICE_COMPILE)
 
-template<>  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-half2 plog<half2>(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+half2 plog(const half2& a) {
   return h2log(a);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-half2 pexp<half2>(const half2& a) {
+ EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+half2 pexp(const half2& a) {
   return h2exp(a);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-half2 psqrt<half2>(const half2& a) {
+ EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+half2 psqrt(const half2& a) {
   return h2sqrt(a);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
-half2 prsqrt<half2>(const half2& a) {
+ EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+half2 prsqrt(const half2& a) {
   return h2rsqrt(a);
 }
 
 #else
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 plog<half2>(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 plog(const half2& a) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float r1 = logf(a1);
   float r2 = logf(a2);
   return __floats2half2_rn(r1, r2);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pexp<half2>(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pexp(const half2& a) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float r1 = expf(a1);
   float r2 = expf(a2);
   return __floats2half2_rn(r1, r2);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 psqrt<half2>(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 psqrt(const half2& a) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float r1 = sqrtf(a1);
   float r2 = sqrtf(a2);
   return __floats2half2_rn(r1, r2);
 }
 
-template<> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 prsqrt<half2>(const half2& a) {
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 prsqrt(const half2& a) {
   float a1 = __low2float(a);
   float a2 = __high2float(a);
   float r1 = rsqrtf(a1);
   float r2 = rsqrtf(a2);
   return __floats2half2_rn(r1, r2);
 }
-
 #endif
-
-#elif defined EIGEN_VECTORIZE_AVX512
-
-typedef struct {
-  __m256i x;
-} Packet16h;
-
-
-template<> struct is_arithmetic<Packet16h> { enum { value = true }; };
+} // namespace
 
 template <>
-struct packet_traits<half> : default_packet_traits {
-  typedef Packet16h type;
-  // There is no half-size packet for Packet16h.
-  typedef Packet16h half;
-  enum {
-    Vectorizable = 1,
-    AlignedOnScalar = 1,
-    size = 16,
-    HasHalfPacket = 0,
-    HasAdd    = 1,
-    HasSub    = 1,
-    HasMul    = 1,
-    HasDiv    = 1,
-    HasNegate = 1,
-    HasAbs    = 0,
-    HasAbs2   = 0,
-    HasMin    = 0,
-    HasMax    = 0,
-    HasConj   = 0,
-    HasSetLinear = 0,
-    HasSqrt = 0,
-    HasRsqrt = 0,
-    HasExp = 0,
-    HasLog = 0,
-    HasBlend = 0
-  };
-};
-
-
-template<> struct unpacket_traits<Packet16h> { typedef Eigen::half type; enum {size=16, alignment=Aligned32, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet16h half; };
-
-template<> EIGEN_STRONG_INLINE Packet16h pset1<Packet16h>(const Eigen::half& from) {
-  Packet16h result;
-  result.x = _mm256_set1_epi16(from.x);
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE Eigen::half pfirst<Packet16h>(const Packet16h& from) {
-  return half_impl::raw_uint16_to_half(static_cast<unsigned short>(_mm256_extract_epi16(from.x, 0)));
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h pload<Packet16h>(const Eigen::half* from) {
-  Packet16h result;
-  result.x = _mm256_load_si256(reinterpret_cast<const __m256i*>(from));
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h ploadu<Packet16h>(const Eigen::half* from) {
-  Packet16h result;
-  result.x = _mm256_loadu_si256(reinterpret_cast<const __m256i*>(from));
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE void pstore<half>(Eigen::half* to, const Packet16h& from) {
-  // (void*) -> workaround clang warning:
-  // cast from 'Eigen::half *' to '__m256i *' increases required alignment from 2 to 32
-  _mm256_store_si256((__m256i*)(void*)to, from.x);
-}
-
-template<> EIGEN_STRONG_INLINE void pstoreu<half>(Eigen::half* to, const Packet16h& from) {
-  // (void*) -> workaround clang warning:
-  // cast from 'Eigen::half *' to '__m256i *' increases required alignment from 2 to 32
-  _mm256_storeu_si256((__m256i*)(void*)to, from.x);
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h
-ploaddup<Packet16h>(const Eigen::half*  from) {
-  Packet16h result;
-  unsigned short a = from[0].x;
-  unsigned short b = from[1].x;
-  unsigned short c = from[2].x;
-  unsigned short d = from[3].x;
-  unsigned short e = from[4].x;
-  unsigned short f = from[5].x;
-  unsigned short g = from[6].x;
-  unsigned short h = from[7].x;
-  result.x = _mm256_set_epi16(h, h, g, g, f, f, e, e, d, d, c, c, b, b, a, a);
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h
-ploadquad(const Eigen::half* from) {
-  Packet16h result;
-  unsigned short a = from[0].x;
-  unsigned short b = from[1].x;
-  unsigned short c = from[2].x;
-  unsigned short d = from[3].x;
-  result.x = _mm256_set_epi16(d, d, d, d, c, c, c, c, b, b, b, b, a, a, a, a);
-  return result;
-}
-
-EIGEN_STRONG_INLINE Packet16f half2float(const Packet16h& a) {
-#ifdef EIGEN_HAS_FP16_C
-  return _mm512_cvtph_ps(a.x);
-#else
-  EIGEN_ALIGN64 half aux[16];
-  pstore(aux, a);
-  float f0(aux[0]);
-  float f1(aux[1]);
-  float f2(aux[2]);
-  float f3(aux[3]);
-  float f4(aux[4]);
-  float f5(aux[5]);
-  float f6(aux[6]);
-  float f7(aux[7]);
-  float f8(aux[8]);
-  float f9(aux[9]);
-  float fa(aux[10]);
-  float fb(aux[11]);
-  float fc(aux[12]);
-  float fd(aux[13]);
-  float fe(aux[14]);
-  float ff(aux[15]);
-
-  return _mm512_set_ps(
-      ff, fe, fd, fc, fb, fa, f9, f8, f7, f6, f5, f4, f3, f2, f1, f0);
-#endif
-}
-
-EIGEN_STRONG_INLINE Packet16h float2half(const Packet16f& a) {
-#ifdef EIGEN_HAS_FP16_C
-  Packet16h result;
-  result.x = _mm512_cvtps_ph(a, _MM_FROUND_TO_NEAREST_INT|_MM_FROUND_NO_EXC);
-  return result;
-#else
-  EIGEN_ALIGN64 float aux[16];
-  pstore(aux, a);
-  half h0(aux[0]);
-  half h1(aux[1]);
-  half h2(aux[2]);
-  half h3(aux[3]);
-  half h4(aux[4]);
-  half h5(aux[5]);
-  half h6(aux[6]);
-  half h7(aux[7]);
-  half h8(aux[8]);
-  half h9(aux[9]);
-  half ha(aux[10]);
-  half hb(aux[11]);
-  half hc(aux[12]);
-  half hd(aux[13]);
-  half he(aux[14]);
-  half hf(aux[15]);
-
-  Packet16h result;
-  result.x = _mm256_set_epi16(
-      hf.x, he.x, hd.x, hc.x, hb.x, ha.x, h9.x, h8.x,
-      h7.x, h6.x, h5.x, h4.x, h3.x, h2.x, h1.x, h0.x);
-  return result;
-#endif
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h pnot(const Packet16h& a) {
-  Packet16h r; r.x = _mm256_xor_si256(a.x, pcmp_eq(a.x, a.x)); return r;
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h ptrue(const Packet16h& a) {
-  Packet16h r; r.x = Packet8i(ptrue(a.x)); return r;
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h por(const Packet16h& a,const Packet16h& b) {
-  // in some cases Packet8i is a wrapper around __m256i, so we need to 
-  // cast to Packet8i to call the correct overload.
-  Packet16h r; r.x = por(Packet8i(a.x),Packet8i(b.x)); return r;
-}
-template<> EIGEN_STRONG_INLINE Packet16h pxor(const Packet16h& a,const Packet16h& b) {
-  Packet16h r; r.x = pxor(Packet8i(a.x),Packet8i(b.x)); return r;
-}
-template<> EIGEN_STRONG_INLINE Packet16h pand(const Packet16h& a,const Packet16h& b) {
-  Packet16h r; r.x = pand(Packet8i(a.x),Packet8i(b.x)); return r;
-}
-template<> EIGEN_STRONG_INLINE Packet16h pandnot(const Packet16h& a,const Packet16h& b) {
-  Packet16h r; r.x = pandnot(Packet8i(a.x),Packet8i(b.x)); return r;
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h pselect(const Packet16h& mask, const Packet16h& a, const Packet16h& b) {
-  Packet16h r; r.x = _mm256_blendv_epi8(b.x, a.x, mask.x); return r;
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h pcmp_eq(const Packet16h& a,const Packet16h& b) {
-  Packet16f af = half2float(a);
-  Packet16f bf = half2float(b);
-  Packet16f rf = pcmp_eq(af, bf);
-  // Pack the 32-bit flags into 16-bits flags.
-  __m256i lo = _mm256_castps_si256(extract256<0>(rf));
-  __m256i hi = _mm256_castps_si256(extract256<1>(rf));
-  __m128i result_lo = _mm_packs_epi32(_mm256_extractf128_si256(lo, 0),
-                                      _mm256_extractf128_si256(lo, 1));
-  __m128i result_hi = _mm_packs_epi32(_mm256_extractf128_si256(hi, 0),
-                                      _mm256_extractf128_si256(hi, 1));
-  Packet16h result; result.x = _mm256_insertf128_si256(_mm256_castsi128_si256(result_lo), result_hi, 1);
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h pnegate(const Packet16h& a) {
-  Packet16h sign_mask; sign_mask.x = _mm256_set1_epi16(static_cast<unsigned short>(0x8000));
-  Packet16h result; result.x = _mm256_xor_si256(a.x, sign_mask.x);
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h padd<Packet16h>(const Packet16h& a, const Packet16h& b) {
-  Packet16f af = half2float(a);
-  Packet16f bf = half2float(b);
-  Packet16f rf = padd(af, bf);
-  return float2half(rf);
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h psub<Packet16h>(const Packet16h& a, const Packet16h& b) {
-  Packet16f af = half2float(a);
-  Packet16f bf = half2float(b);
-  Packet16f rf = psub(af, bf);
-  return float2half(rf);
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h pmul<Packet16h>(const Packet16h& a, const Packet16h& b) {
-  Packet16f af = half2float(a);
-  Packet16f bf = half2float(b);
-  Packet16f rf = pmul(af, bf);
-  return float2half(rf);
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h pdiv<Packet16h>(const Packet16h& a, const Packet16h& b) {
-  Packet16f af = half2float(a);
-  Packet16f bf = half2float(b);
-  Packet16f rf = pdiv(af, bf);
-  return float2half(rf);
-}
-
-template<> EIGEN_STRONG_INLINE half predux<Packet16h>(const Packet16h& from) {
-  Packet16f from_float = half2float(from);
-  return half(predux(from_float));
-}
-
-template<> EIGEN_STRONG_INLINE half predux_mul<Packet16h>(const Packet16h& from) {
-  Packet16f from_float = half2float(from);
-  return half(predux_mul(from_float));
-}
-
-template<> EIGEN_STRONG_INLINE Packet16h preduxp<Packet16h>(const Packet16h* p) {
-  Packet16f pf[16];
-  pf[0] = half2float(p[0]);
-  pf[1] = half2float(p[1]);
-  pf[2] = half2float(p[2]);
-  pf[3] = half2float(p[3]);
-  pf[4] = half2float(p[4]);
-  pf[5] = half2float(p[5]);
-  pf[6] = half2float(p[6]);
-  pf[7] = half2float(p[7]);
-  pf[8] = half2float(p[8]);
-  pf[9] = half2float(p[9]);
-  pf[10] = half2float(p[10]);
-  pf[11] = half2float(p[11]);
-  pf[12] = half2float(p[12]);
-  pf[13] = half2float(p[13]);
-  pf[14] = half2float(p[14]);
-  pf[15] = half2float(p[15]);
-  Packet16f reduced = preduxp<Packet16f>(pf);
-  return float2half(reduced);
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+pload<Packet4h2>(const Eigen::half* from) {
+  return *reinterpret_cast<const Packet4h2*>(from);
 }
 
-template<> EIGEN_STRONG_INLINE Packet16h preverse(const Packet16h& a)
-{
-  __m128i m = _mm_setr_epi8(14,15,12,13,10,11,8,9,6,7,4,5,2,3,0,1);
-  Packet16h res;
-  res.x = _mm256_insertf128_si256(
-                    _mm256_castsi128_si256(_mm_shuffle_epi8(_mm256_extractf128_si256(a.x,1),m)),
-                                           _mm_shuffle_epi8(_mm256_extractf128_si256(a.x,0),m), 1);
-  return res;
+// unaligned load;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+ploadu<Packet4h2>(const Eigen::half* from) {
+  Packet4h2 r;
+  half2* p_alias = reinterpret_cast<half2*>(&r);
+  p_alias[0] = ploadu(from + 0);
+  p_alias[1] = ploadu(from + 2);
+  p_alias[2] = ploadu(from + 4);
+  p_alias[3] = ploadu(from + 6);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet16h pinsertfirst(const Packet16h& a, Eigen::half b)
-{
-  Packet16h res;
-  res.x = _mm256_insert_epi16(a.x,b.x,0);
-  return res;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+ploaddup<Packet4h2>(const Eigen::half* from) {
+  Packet4h2 r;
+  half2* p_alias = reinterpret_cast<half2*>(&r);
+  p_alias[0] = ploaddup(from + 0);
+  p_alias[1] = ploaddup(from + 1);
+  p_alias[2] = ploaddup(from + 2);
+  p_alias[3] = ploaddup(from + 3);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet16h pinsertlast(const Packet16h& a, Eigen::half b)
-{
-  Packet16h res;
-  res.x = _mm256_insert_epi16(a.x,b.x,15);
-  return res;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstore<Eigen::half>(
+    Eigen::half* to, const Packet4h2& from) {
+  *reinterpret_cast<Packet4h2*>(to) = from;
 }
 
-template<> EIGEN_STRONG_INLINE Packet16h pgather<Eigen::half, Packet16h>(const Eigen::half* from, Index stride)
-{
-  Packet16h result;
-  result.x = _mm256_set_epi16(
-      from[15*stride].x, from[14*stride].x, from[13*stride].x, from[12*stride].x,
-      from[11*stride].x, from[10*stride].x, from[9*stride].x, from[8*stride].x,
-      from[7*stride].x, from[6*stride].x, from[5*stride].x, from[4*stride].x,
-      from[3*stride].x, from[2*stride].x, from[1*stride].x, from[0*stride].x);
-  return result;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pstoreu<Eigen::half>(
+    Eigen::half* to, const Packet4h2& from) {
+  const half2* from_alias = reinterpret_cast<const half2*>(&from);
+  pstoreu(to + 0,from_alias[0]);
+  pstoreu(to + 2,from_alias[1]);
+  pstoreu(to + 4,from_alias[2]);
+  pstoreu(to + 6,from_alias[3]);
 }
 
-template<> EIGEN_STRONG_INLINE void pscatter<half, Packet16h>(half* to, const Packet16h& from, Index stride)
-{
-  EIGEN_ALIGN64 half aux[16];
-  pstore(aux, from);
-  to[stride*0].x = aux[0].x;
-  to[stride*1].x = aux[1].x;
-  to[stride*2].x = aux[2].x;
-  to[stride*3].x = aux[3].x;
-  to[stride*4].x = aux[4].x;
-  to[stride*5].x = aux[5].x;
-  to[stride*6].x = aux[6].x;
-  to[stride*7].x = aux[7].x;
-  to[stride*8].x = aux[8].x;
-  to[stride*9].x = aux[9].x;
-  to[stride*10].x = aux[10].x;
-  to[stride*11].x = aux[11].x;
-  to[stride*12].x = aux[12].x;
-  to[stride*13].x = aux[13].x;
-  to[stride*14].x = aux[14].x;
-  to[stride*15].x = aux[15].x;
-}
-
-EIGEN_STRONG_INLINE void
-ptranspose(PacketBlock<Packet16h,16>& kernel) {
-  __m256i a = kernel.packet[0].x;
-  __m256i b = kernel.packet[1].x;
-  __m256i c = kernel.packet[2].x;
-  __m256i d = kernel.packet[3].x;
-  __m256i e = kernel.packet[4].x;
-  __m256i f = kernel.packet[5].x;
-  __m256i g = kernel.packet[6].x;
-  __m256i h = kernel.packet[7].x;
-  __m256i i = kernel.packet[8].x;
-  __m256i j = kernel.packet[9].x;
-  __m256i k = kernel.packet[10].x;
-  __m256i l = kernel.packet[11].x;
-  __m256i m = kernel.packet[12].x;
-  __m256i n = kernel.packet[13].x;
-  __m256i o = kernel.packet[14].x;
-  __m256i p = kernel.packet[15].x;
-
-  __m256i ab_07 = _mm256_unpacklo_epi16(a, b);
-  __m256i cd_07 = _mm256_unpacklo_epi16(c, d);
-  __m256i ef_07 = _mm256_unpacklo_epi16(e, f);
-  __m256i gh_07 = _mm256_unpacklo_epi16(g, h);
-  __m256i ij_07 = _mm256_unpacklo_epi16(i, j);
-  __m256i kl_07 = _mm256_unpacklo_epi16(k, l);
-  __m256i mn_07 = _mm256_unpacklo_epi16(m, n);
-  __m256i op_07 = _mm256_unpacklo_epi16(o, p);
-
-  __m256i ab_8f = _mm256_unpackhi_epi16(a, b);
-  __m256i cd_8f = _mm256_unpackhi_epi16(c, d);
-  __m256i ef_8f = _mm256_unpackhi_epi16(e, f);
-  __m256i gh_8f = _mm256_unpackhi_epi16(g, h);
-  __m256i ij_8f = _mm256_unpackhi_epi16(i, j);
-  __m256i kl_8f = _mm256_unpackhi_epi16(k, l);
-  __m256i mn_8f = _mm256_unpackhi_epi16(m, n);
-  __m256i op_8f = _mm256_unpackhi_epi16(o, p);
-
-  __m256i abcd_03 = _mm256_unpacklo_epi32(ab_07, cd_07);
-  __m256i abcd_47 = _mm256_unpackhi_epi32(ab_07, cd_07);
-  __m256i efgh_03 = _mm256_unpacklo_epi32(ef_07, gh_07);
-  __m256i efgh_47 = _mm256_unpackhi_epi32(ef_07, gh_07);
-  __m256i ijkl_03 = _mm256_unpacklo_epi32(ij_07, kl_07);
-  __m256i ijkl_47 = _mm256_unpackhi_epi32(ij_07, kl_07);
-  __m256i mnop_03 = _mm256_unpacklo_epi32(mn_07, op_07);
-  __m256i mnop_47 = _mm256_unpackhi_epi32(mn_07, op_07);
-
-  __m256i abcd_8b = _mm256_unpacklo_epi32(ab_8f, cd_8f);
-  __m256i abcd_cf = _mm256_unpackhi_epi32(ab_8f, cd_8f);
-  __m256i efgh_8b = _mm256_unpacklo_epi32(ef_8f, gh_8f);
-  __m256i efgh_cf = _mm256_unpackhi_epi32(ef_8f, gh_8f);
-  __m256i ijkl_8b = _mm256_unpacklo_epi32(ij_8f, kl_8f);
-  __m256i ijkl_cf = _mm256_unpackhi_epi32(ij_8f, kl_8f);
-  __m256i mnop_8b = _mm256_unpacklo_epi32(mn_8f, op_8f);
-  __m256i mnop_cf = _mm256_unpackhi_epi32(mn_8f, op_8f);
-
-  __m256i abcdefgh_01 = _mm256_unpacklo_epi64(abcd_03, efgh_03);
-  __m256i abcdefgh_23 = _mm256_unpackhi_epi64(abcd_03, efgh_03);
-  __m256i ijklmnop_01 = _mm256_unpacklo_epi64(ijkl_03, mnop_03);
-  __m256i ijklmnop_23 = _mm256_unpackhi_epi64(ijkl_03, mnop_03);
-  __m256i abcdefgh_45 = _mm256_unpacklo_epi64(abcd_47, efgh_47);
-  __m256i abcdefgh_67 = _mm256_unpackhi_epi64(abcd_47, efgh_47);
-  __m256i ijklmnop_45 = _mm256_unpacklo_epi64(ijkl_47, mnop_47);
-  __m256i ijklmnop_67 = _mm256_unpackhi_epi64(ijkl_47, mnop_47);
-  __m256i abcdefgh_89 = _mm256_unpacklo_epi64(abcd_8b, efgh_8b);
-  __m256i abcdefgh_ab = _mm256_unpackhi_epi64(abcd_8b, efgh_8b);
-  __m256i ijklmnop_89 = _mm256_unpacklo_epi64(ijkl_8b, mnop_8b);
-  __m256i ijklmnop_ab = _mm256_unpackhi_epi64(ijkl_8b, mnop_8b);
-  __m256i abcdefgh_cd = _mm256_unpacklo_epi64(abcd_cf, efgh_cf);
-  __m256i abcdefgh_ef = _mm256_unpackhi_epi64(abcd_cf, efgh_cf);
-  __m256i ijklmnop_cd = _mm256_unpacklo_epi64(ijkl_cf, mnop_cf);
-  __m256i ijklmnop_ef = _mm256_unpackhi_epi64(ijkl_cf, mnop_cf);
-
-  // NOTE: no unpacklo/hi instr in this case, so using permute instr.
-  __m256i a_p_0 = _mm256_permute2x128_si256(abcdefgh_01, ijklmnop_01, 0x20);
-  __m256i a_p_1 = _mm256_permute2x128_si256(abcdefgh_23, ijklmnop_23, 0x20);
-  __m256i a_p_2 = _mm256_permute2x128_si256(abcdefgh_45, ijklmnop_45, 0x20);
-  __m256i a_p_3 = _mm256_permute2x128_si256(abcdefgh_67, ijklmnop_67, 0x20);
-  __m256i a_p_4 = _mm256_permute2x128_si256(abcdefgh_89, ijklmnop_89, 0x20);
-  __m256i a_p_5 = _mm256_permute2x128_si256(abcdefgh_ab, ijklmnop_ab, 0x20);
-  __m256i a_p_6 = _mm256_permute2x128_si256(abcdefgh_cd, ijklmnop_cd, 0x20);
-  __m256i a_p_7 = _mm256_permute2x128_si256(abcdefgh_ef, ijklmnop_ef, 0x20);
-  __m256i a_p_8 = _mm256_permute2x128_si256(abcdefgh_01, ijklmnop_01, 0x31);
-  __m256i a_p_9 = _mm256_permute2x128_si256(abcdefgh_23, ijklmnop_23, 0x31);
-  __m256i a_p_a = _mm256_permute2x128_si256(abcdefgh_45, ijklmnop_45, 0x31);
-  __m256i a_p_b = _mm256_permute2x128_si256(abcdefgh_67, ijklmnop_67, 0x31);
-  __m256i a_p_c = _mm256_permute2x128_si256(abcdefgh_89, ijklmnop_89, 0x31);
-  __m256i a_p_d = _mm256_permute2x128_si256(abcdefgh_ab, ijklmnop_ab, 0x31);
-  __m256i a_p_e = _mm256_permute2x128_si256(abcdefgh_cd, ijklmnop_cd, 0x31);
-  __m256i a_p_f = _mm256_permute2x128_si256(abcdefgh_ef, ijklmnop_ef, 0x31);
-
-  kernel.packet[0].x = a_p_0;
-  kernel.packet[1].x = a_p_1;
-  kernel.packet[2].x = a_p_2;
-  kernel.packet[3].x = a_p_3;
-  kernel.packet[4].x = a_p_4;
-  kernel.packet[5].x = a_p_5;
-  kernel.packet[6].x = a_p_6;
-  kernel.packet[7].x = a_p_7;
-  kernel.packet[8].x = a_p_8;
-  kernel.packet[9].x = a_p_9;
-  kernel.packet[10].x = a_p_a;
-  kernel.packet[11].x = a_p_b;
-  kernel.packet[12].x = a_p_c;
-  kernel.packet[13].x = a_p_d;
-  kernel.packet[14].x = a_p_e;
-  kernel.packet[15].x = a_p_f;
-}
-
-EIGEN_STRONG_INLINE void
-ptranspose(PacketBlock<Packet16h,8>& kernel) {
-  EIGEN_ALIGN64 half in[8][16];
-  pstore<half>(in[0], kernel.packet[0]);
-  pstore<half>(in[1], kernel.packet[1]);
-  pstore<half>(in[2], kernel.packet[2]);
-  pstore<half>(in[3], kernel.packet[3]);
-  pstore<half>(in[4], kernel.packet[4]);
-  pstore<half>(in[5], kernel.packet[5]);
-  pstore<half>(in[6], kernel.packet[6]);
-  pstore<half>(in[7], kernel.packet[7]);
-
-  EIGEN_ALIGN64 half out[8][16];
-
-  for (int i = 0; i < 8; ++i) {
-    for (int j = 0; j < 8; ++j) {
-      out[i][j] = in[j][2*i];
-    }
-    for (int j = 0; j < 8; ++j) {
-      out[i][j+8] = in[j][2*i+1];
-    }
-  }
-
-  kernel.packet[0] = pload<Packet16h>(out[0]);
-  kernel.packet[1] = pload<Packet16h>(out[1]);
-  kernel.packet[2] = pload<Packet16h>(out[2]);
-  kernel.packet[3] = pload<Packet16h>(out[3]);
-  kernel.packet[4] = pload<Packet16h>(out[4]);
-  kernel.packet[5] = pload<Packet16h>(out[5]);
-  kernel.packet[6] = pload<Packet16h>(out[6]);
-  kernel.packet[7] = pload<Packet16h>(out[7]);
-}
-
-EIGEN_STRONG_INLINE void
-ptranspose(PacketBlock<Packet16h,4>& kernel) {
-  EIGEN_ALIGN64 half in[4][16];
-  pstore<half>(in[0], kernel.packet[0]);
-  pstore<half>(in[1], kernel.packet[1]);
-  pstore<half>(in[2], kernel.packet[2]);
-  pstore<half>(in[3], kernel.packet[3]);
-
-  EIGEN_ALIGN64 half out[4][16];
-
-  for (int i = 0; i < 4; ++i) {
-    for (int j = 0; j < 4; ++j) {
-      out[i][j] = in[j][4*i];
-    }
-    for (int j = 0; j < 4; ++j) {
-      out[i][j+4] = in[j][4*i+1];
-    }
-    for (int j = 0; j < 4; ++j) {
-      out[i][j+8] = in[j][4*i+2];
-    }
-    for (int j = 0; j < 4; ++j) {
-      out[i][j+12] = in[j][4*i+3];
-    }
-  }
-
-  kernel.packet[0] = pload<Packet16h>(out[0]);
-  kernel.packet[1] = pload<Packet16h>(out[1]);
-  kernel.packet[2] = pload<Packet16h>(out[2]);
-  kernel.packet[3] = pload<Packet16h>(out[3]);
-}
-
-
-#elif defined EIGEN_VECTORIZE_AVX
-
-typedef struct {
-  __m128i x;
-} Packet8h;
-
-
-template<> struct is_arithmetic<Packet8h> { enum { value = true }; };
-
-template <>
-struct packet_traits<Eigen::half> : default_packet_traits {
-  typedef Packet8h type;
-  // There is no half-size packet for Packet8h.
-  typedef Packet8h half;
-  enum {
-    Vectorizable = 1,
-    AlignedOnScalar = 1,
-    size = 8,
-    HasHalfPacket = 0,
-    HasAdd    = 1,
-    HasSub    = 1,
-    HasMul    = 1,
-    HasDiv    = 1,
-    HasNegate = 1,
-    HasAbs    = 0,
-    HasAbs2   = 0,
-    HasMin    = 0,
-    HasMax    = 0,
-    HasConj   = 0,
-    HasSetLinear = 0,
-    HasSqrt = 0,
-    HasRsqrt = 0,
-    HasExp = 0,
-    HasLog = 0,
-    HasBlend = 0
-  };
-};
-
+template <>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet4h2
+ploadt_ro<Packet4h2, Aligned>(const Eigen::half* from) {
+#if defined(EIGEN_GPU_HAS_LDG)
+  Packet4h2 r;
+  r = __ldg(reinterpret_cast<const Packet4h2*>(from));
+  return r;
+#else
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  r_alias[0] = ploadt_ro_aligned(from + 0);
+  r_alias[1] = ploadt_ro_aligned(from + 2);
+  r_alias[2] = ploadt_ro_aligned(from + 4);
+  r_alias[3] = ploadt_ro_aligned(from + 6);
+  return r;
+#endif
+}
 
-template<> struct unpacket_traits<Packet8h> { typedef Eigen::half type; enum {size=8, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet8h half; };
+template <>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet4h2
+ploadt_ro<Packet4h2, Unaligned>(const Eigen::half* from) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  r_alias[0] = ploadt_ro_unaligned(from + 0);
+  r_alias[1] = ploadt_ro_unaligned(from + 2);
+  r_alias[2] = ploadt_ro_unaligned(from + 4);
+  r_alias[3] = ploadt_ro_unaligned(from + 6);
+  return r;
+}
 
-template<> EIGEN_STRONG_INLINE Packet8h pset1<Packet8h>(const Eigen::half& from) {
-  Packet8h result;
-  result.x = _mm_set1_epi16(from.x);
-  return result;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+pgather<Eigen::half, Packet4h2>(const Eigen::half* from, Index stride) {
+  Packet4h2 r;
+  half2* p_alias = reinterpret_cast<half2*>(&r);
+  p_alias[0] = __halves2half2(from[0 * stride], from[1 * stride]);
+  p_alias[1] = __halves2half2(from[2 * stride], from[3 * stride]);
+  p_alias[2] = __halves2half2(from[4 * stride], from[5 * stride]);
+  p_alias[3] = __halves2half2(from[6 * stride], from[7 * stride]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Eigen::half pfirst<Packet8h>(const Packet8h& from) {
-  return half_impl::raw_uint16_to_half(static_cast<unsigned short>(_mm_extract_epi16(from.x, 0)));
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void pscatter<Eigen::half, Packet4h2>(
+    Eigen::half* to, const Packet4h2& from, Index stride) {
+  const half2* from_alias = reinterpret_cast<const half2*>(&from);
+  pscatter(to + stride * 0, from_alias[0], stride);
+  pscatter(to + stride * 2, from_alias[1], stride);
+  pscatter(to + stride * 4, from_alias[2], stride);
+  pscatter(to + stride * 6, from_alias[3], stride);
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h pload<Packet8h>(const Eigen::half* from) {
-  Packet8h result;
-  result.x = _mm_load_si128(reinterpret_cast<const __m128i*>(from));
-  return result;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half pfirst<Packet4h2>(
+    const Packet4h2& a) {
+  return pfirst(*(reinterpret_cast<const half2*>(&a)));
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h ploadu<Packet8h>(const Eigen::half* from) {
-  Packet8h result;
-  result.x = _mm_loadu_si128(reinterpret_cast<const __m128i*>(from));
-  return result;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pabs<Packet4h2>(
+    const Packet4h2& a) {
+  Packet4h2 r;
+  half2* p_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  p_alias[0] = pabs(a_alias[0]);
+  p_alias[1] = pabs(a_alias[1]);
+  p_alias[2] = pabs(a_alias[2]);
+  p_alias[3] = pabs(a_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE void pstore<Eigen::half>(Eigen::half* to, const Packet8h& from) {
-  _mm_store_si128(reinterpret_cast<__m128i*>(to), from.x);
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 ptrue<Packet4h2>(
+    const Packet4h2& /*a*/) {
+  half true_half = half_impl::raw_uint16_to_half(0xffffu);
+  return pset1<Packet4h2>(true_half);
 }
 
-template<> EIGEN_STRONG_INLINE void pstoreu<Eigen::half>(Eigen::half* to, const Packet8h& from) {
-  _mm_storeu_si128(reinterpret_cast<__m128i*>(to), from.x);
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pzero<Packet4h2>(const Packet4h2& /*a*/) {
+  half false_half = half_impl::raw_uint16_to_half(0x0000u);
+  return pset1<Packet4h2>(false_half);
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h
-ploaddup<Packet8h>(const Eigen::half*  from) {
-  Packet8h result;
-  unsigned short a = from[0].x;
-  unsigned short b = from[1].x;
-  unsigned short c = from[2].x;
-  unsigned short d = from[3].x;
-  result.x = _mm_set_epi16(d, d, c, c, b, b, a, a);
-  return result;
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose_double(
+    double* d_row0, double* d_row1, double* d_row2, double* d_row3,
+    double* d_row4, double* d_row5, double* d_row6, double* d_row7) {
+  double d_tmp;
+  d_tmp = d_row0[1];
+  d_row0[1] = d_row4[0];
+  d_row4[0] = d_tmp;
+
+  d_tmp = d_row1[1];
+  d_row1[1] = d_row5[0];
+  d_row5[0] = d_tmp;
+
+  d_tmp = d_row2[1];
+  d_row2[1] = d_row6[0];
+  d_row6[0] = d_tmp;
+
+  d_tmp = d_row3[1];
+  d_row3[1] = d_row7[0];
+  d_row7[0] = d_tmp;
+}
+
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void ptranspose_half2(
+    half2* f_row0, half2* f_row1, half2* f_row2, half2* f_row3) {
+  half2 f_tmp;
+  f_tmp = f_row0[1];
+  f_row0[1] = f_row2[0];
+  f_row2[0] = f_tmp;
+
+  f_tmp = f_row1[1];
+  f_row1[1] = f_row3[0];
+  f_row3[0] = f_tmp;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h
-ploadquad<Packet8h>(const Eigen::half* from) {
-  Packet8h result;
-  unsigned short a = from[0].x;
-  unsigned short b = from[1].x;
-  result.x = _mm_set_epi16(b, b, b, b, a, a, a, a);
-  return result;
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void
+ptranspose_half(half2& f0, half2& f1) {
+  __half a1 = __low2half(f0);
+  __half a2 = __high2half(f0);
+  __half b1 = __low2half(f1);
+  __half b2 = __high2half(f1);
+  f0 = __halves2half2(a1, b1);
+  f1 = __halves2half2(a2, b2);
 }
 
-EIGEN_STRONG_INLINE Packet8f half2float(const Packet8h& a) {
-#ifdef EIGEN_HAS_FP16_C
-  return _mm256_cvtph_ps(a.x);
-#else
-  EIGEN_ALIGN32 Eigen::half aux[8];
-  pstore(aux, a);
-  float f0(aux[0]);
-  float f1(aux[1]);
-  float f2(aux[2]);
-  float f3(aux[3]);
-  float f4(aux[4]);
-  float f5(aux[5]);
-  float f6(aux[6]);
-  float f7(aux[7]);
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void
+ptranspose(PacketBlock<Packet4h2,8>& kernel) {
+  double* d_row0 = reinterpret_cast<double*>(&kernel.packet[0]);
+  double* d_row1 = reinterpret_cast<double*>(&kernel.packet[1]);
+  double* d_row2 = reinterpret_cast<double*>(&kernel.packet[2]);
+  double* d_row3 = reinterpret_cast<double*>(&kernel.packet[3]);
+  double* d_row4 = reinterpret_cast<double*>(&kernel.packet[4]);
+  double* d_row5 = reinterpret_cast<double*>(&kernel.packet[5]);
+  double* d_row6 = reinterpret_cast<double*>(&kernel.packet[6]);
+  double* d_row7 = reinterpret_cast<double*>(&kernel.packet[7]);
+  ptranspose_double(d_row0, d_row1, d_row2, d_row3,
+                    d_row4, d_row5, d_row6, d_row7);
+
+
+  half2* f_row0 = reinterpret_cast<half2*>(d_row0);
+  half2* f_row1 = reinterpret_cast<half2*>(d_row1);
+  half2* f_row2 = reinterpret_cast<half2*>(d_row2);
+  half2* f_row3 = reinterpret_cast<half2*>(d_row3);
+  ptranspose_half2(f_row0, f_row1, f_row2, f_row3);
+  ptranspose_half(f_row0[0], f_row1[0]);
+  ptranspose_half(f_row0[1], f_row1[1]);
+  ptranspose_half(f_row2[0], f_row3[0]);
+  ptranspose_half(f_row2[1], f_row3[1]);
+
+  f_row0 = reinterpret_cast<half2*>(d_row0 + 1);
+  f_row1 = reinterpret_cast<half2*>(d_row1 + 1);
+  f_row2 = reinterpret_cast<half2*>(d_row2 + 1);
+  f_row3 = reinterpret_cast<half2*>(d_row3 + 1);
+  ptranspose_half2(f_row0, f_row1, f_row2, f_row3);
+  ptranspose_half(f_row0[0], f_row1[0]);
+  ptranspose_half(f_row0[1], f_row1[1]);
+  ptranspose_half(f_row2[0], f_row3[0]);
+  ptranspose_half(f_row2[1], f_row3[1]);
+
+  f_row0 = reinterpret_cast<half2*>(d_row4);
+  f_row1 = reinterpret_cast<half2*>(d_row5);
+  f_row2 = reinterpret_cast<half2*>(d_row6);
+  f_row3 = reinterpret_cast<half2*>(d_row7);
+  ptranspose_half2(f_row0, f_row1, f_row2, f_row3);
+  ptranspose_half(f_row0[0], f_row1[0]);
+  ptranspose_half(f_row0[1], f_row1[1]);
+  ptranspose_half(f_row2[0], f_row3[0]);
+  ptranspose_half(f_row2[1], f_row3[1]);
+
+  f_row0 = reinterpret_cast<half2*>(d_row4 + 1);
+  f_row1 = reinterpret_cast<half2*>(d_row5 + 1);
+  f_row2 = reinterpret_cast<half2*>(d_row6 + 1);
+  f_row3 = reinterpret_cast<half2*>(d_row7 + 1);
+  ptranspose_half2(f_row0, f_row1, f_row2, f_row3);
+  ptranspose_half(f_row0[0], f_row1[0]);
+  ptranspose_half(f_row0[1], f_row1[1]);
+  ptranspose_half(f_row2[0], f_row3[0]);
+  ptranspose_half(f_row2[1], f_row3[1]);
 
-  return _mm256_set_ps(f7, f6, f5, f4, f3, f2, f1, f0);
-#endif
 }
 
-EIGEN_STRONG_INLINE Packet8h float2half(const Packet8f& a) {
-#ifdef EIGEN_HAS_FP16_C
-  Packet8h result;
-  result.x = _mm256_cvtps_ph(a, _MM_FROUND_TO_NEAREST_INT|_MM_FROUND_NO_EXC);
-  return result;
-#else
-  EIGEN_ALIGN32 float aux[8];
-  pstore(aux, a);
-  Eigen::half h0(aux[0]);
-  Eigen::half h1(aux[1]);
-  Eigen::half h2(aux[2]);
-  Eigen::half h3(aux[3]);
-  Eigen::half h4(aux[4]);
-  Eigen::half h5(aux[5]);
-  Eigen::half h6(aux[6]);
-  Eigen::half h7(aux[7]);
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+plset<Packet4h2>(const Eigen::half& a) {
+#if defined(EIGEN_HIP_DEVICE_COMPILE)
+
+  Packet4h2 r;
+  half2* p_alias = reinterpret_cast<half2*>(&r);
+  p_alias[0] = __halves2half2(a, __hadd(a, __float2half(1.0f)));
+  p_alias[1] = __halves2half2(__hadd(a, __float2half(2.0f)),
+                              __hadd(a, __float2half(3.0f)));
+  p_alias[2] = __halves2half2(__hadd(a, __float2half(4.0f)),
+                              __hadd(a, __float2half(5.0f)));
+  p_alias[3] = __halves2half2(__hadd(a, __float2half(6.0f)),
+                              __hadd(a, __float2half(7.0f)));
+  return r;
+#elif defined(EIGEN_CUDA_HAS_FP16_ARITHMETIC)
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+
+  half2 b = pset1<half2>(a);
+  half2 c;
+  half2 half_offset0 = __halves2half2(__float2half(0.0f),__float2half(2.0f));
+  half2 half_offset1 = __halves2half2(__float2half(4.0f),__float2half(6.0f));
+
+  c = __hadd2(b, half_offset0);
+  r_alias[0] = plset(__low2half(c));
+  r_alias[1] = plset(__high2half(c));
+
+  c = __hadd2(b, half_offset1);
+  r_alias[2] = plset(__low2half(c));
+  r_alias[3] = plset(__high2half(c));
+
+  return r;
 
-  Packet8h result;
-  result.x = _mm_set_epi16(h7.x, h6.x, h5.x, h4.x, h3.x, h2.x, h1.x, h0.x);
-  return result;
+#else
+  float f = __half2float(a);
+  Packet4h2 r;
+  half2* p_alias = reinterpret_cast<half2*>(&r);
+  p_alias[0] = __halves2half2(a, __float2half(f + 1.0f));
+  p_alias[1] = __halves2half2(__float2half(f + 2.0f), __float2half(f + 3.0f));
+  p_alias[2] = __halves2half2(__float2half(f + 4.0f), __float2half(f + 5.0f));
+  p_alias[3] = __halves2half2(__float2half(f + 6.0f), __float2half(f + 7.0f));
+  return r;
 #endif
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h ptrue(const Packet8h& a) {
-  Packet8h r; r.x = _mm_cmpeq_epi32(a.x, a.x); return r;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+pselect<Packet4h2>(const Packet4h2& mask, const Packet4h2& a,
+                   const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* mask_alias = reinterpret_cast<const half2*>(&mask);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = pselect(mask_alias[0], a_alias[0], b_alias[0]);
+  r_alias[1] = pselect(mask_alias[1], a_alias[1], b_alias[1]);
+  r_alias[2] = pselect(mask_alias[2], a_alias[2], b_alias[2]);
+  r_alias[3] = pselect(mask_alias[3], a_alias[3], b_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h por(const Packet8h& a,const Packet8h& b) {
-  // in some cases Packet4i is a wrapper around __m128i, so we either need to 
-  // cast to Packet4i to directly call the intrinsics as below:
-  Packet8h r; r.x = _mm_or_si128(a.x,b.x); return r;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+pcmp_eq<Packet4h2>(const Packet4h2& a, const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = pcmp_eq(a_alias[0], b_alias[0]);
+  r_alias[1] = pcmp_eq(a_alias[1], b_alias[1]);
+  r_alias[2] = pcmp_eq(a_alias[2], b_alias[2]);
+  r_alias[3] = pcmp_eq(a_alias[3], b_alias[3]);
+  return r;
 }
-template<> EIGEN_STRONG_INLINE Packet8h pxor(const Packet8h& a,const Packet8h& b) {
-  Packet8h r; r.x = _mm_xor_si128(a.x,b.x); return r;
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pand<Packet4h2>(
+    const Packet4h2& a, const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = pand(a_alias[0], b_alias[0]);
+  r_alias[1] = pand(a_alias[1], b_alias[1]);
+  r_alias[2] = pand(a_alias[2], b_alias[2]);
+  r_alias[3] = pand(a_alias[3], b_alias[3]);
+  return r;
 }
-template<> EIGEN_STRONG_INLINE Packet8h pand(const Packet8h& a,const Packet8h& b) {
-  Packet8h r; r.x = _mm_and_si128(a.x,b.x); return r;
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 por<Packet4h2>(
+    const Packet4h2& a, const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = por(a_alias[0], b_alias[0]);
+  r_alias[1] = por(a_alias[1], b_alias[1]);
+  r_alias[2] = por(a_alias[2], b_alias[2]);
+  r_alias[3] = por(a_alias[3], b_alias[3]);
+  return r;
 }
-template<> EIGEN_STRONG_INLINE Packet8h pandnot(const Packet8h& a,const Packet8h& b) {
-  Packet8h r; r.x = _mm_andnot_si128(b.x,a.x); return r;
+
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pxor<Packet4h2>(
+    const Packet4h2& a, const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = pxor(a_alias[0], b_alias[0]);
+  r_alias[1] = pxor(a_alias[1], b_alias[1]);
+  r_alias[2] = pxor(a_alias[2], b_alias[2]);
+  r_alias[3] = pxor(a_alias[3], b_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h pselect(const Packet8h& mask, const Packet8h& a, const Packet8h& b) {
-  Packet8h r; r.x = _mm_blendv_epi8(b.x, a.x, mask.x); return r;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+pandnot<Packet4h2>(const Packet4h2& a, const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = pandnot(a_alias[0], b_alias[0]);
+  r_alias[1] = pandnot(a_alias[1], b_alias[1]);
+  r_alias[2] = pandnot(a_alias[2], b_alias[2]);
+  r_alias[3] = pandnot(a_alias[3], b_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h pcmp_eq(const Packet8h& a,const Packet8h& b) {
-  Packet8f af = half2float(a);
-  Packet8f bf = half2float(b);
-  Packet8f rf = pcmp_eq(af, bf);
-  // Pack the 32-bit flags into 16-bits flags.
-  Packet8h result; result.x = _mm_packs_epi32(_mm256_extractf128_si256(_mm256_castps_si256(rf), 0),
-                                              _mm256_extractf128_si256(_mm256_castps_si256(rf), 1));
-  return result;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 padd<Packet4h2>(
+    const Packet4h2& a, const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = padd(a_alias[0], b_alias[0]);
+  r_alias[1] = padd(a_alias[1], b_alias[1]);
+  r_alias[2] = padd(a_alias[2], b_alias[2]);
+  r_alias[3] = padd(a_alias[3], b_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h pconj(const Packet8h& a) { return a; }
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 psub<Packet4h2>(
+    const Packet4h2& a, const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = psub(a_alias[0], b_alias[0]);
+  r_alias[1] = psub(a_alias[1], b_alias[1]);
+  r_alias[2] = psub(a_alias[2], b_alias[2]);
+  r_alias[3] = psub(a_alias[3], b_alias[3]);
+  return r;
+}
 
-template<> EIGEN_STRONG_INLINE Packet8h pnegate(const Packet8h& a) {
-  Packet8h sign_mask; sign_mask.x = _mm_set1_epi16(static_cast<unsigned short>(0x8000));
-  Packet8h result; result.x = _mm_xor_si128(a.x, sign_mask.x);
-  return result;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pnegate(const Packet4h2& a) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  r_alias[0] = pnegate(a_alias[0]);
+  r_alias[1] = pnegate(a_alias[1]);
+  r_alias[2] = pnegate(a_alias[2]);
+  r_alias[3] = pnegate(a_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h padd<Packet8h>(const Packet8h& a, const Packet8h& b) {
-  Packet8f af = half2float(a);
-  Packet8f bf = half2float(b);
-  Packet8f rf = padd(af, bf);
-  return float2half(rf);
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pconj(const Packet4h2& a) {
+  return a;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h psub<Packet8h>(const Packet8h& a, const Packet8h& b) {
-  Packet8f af = half2float(a);
-  Packet8f bf = half2float(b);
-  Packet8f rf = psub(af, bf);
-  return float2half(rf);
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pmul<Packet4h2>(
+    const Packet4h2& a, const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = pmul(a_alias[0], b_alias[0]);
+  r_alias[1] = pmul(a_alias[1], b_alias[1]);
+  r_alias[2] = pmul(a_alias[2], b_alias[2]);
+  r_alias[3] = pmul(a_alias[3], b_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h pmul<Packet8h>(const Packet8h& a, const Packet8h& b) {
-  Packet8f af = half2float(a);
-  Packet8f bf = half2float(b);
-  Packet8f rf = pmul(af, bf);
-  return float2half(rf);
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pmadd<Packet4h2>(
+    const Packet4h2& a, const Packet4h2& b, const Packet4h2& c) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  const half2* c_alias = reinterpret_cast<const half2*>(&c);
+  r_alias[0] = pmadd(a_alias[0], b_alias[0], c_alias[0]);
+  r_alias[1] = pmadd(a_alias[1], b_alias[1], c_alias[1]);
+  r_alias[2] = pmadd(a_alias[2], b_alias[2], c_alias[2]);
+  r_alias[3] = pmadd(a_alias[3], b_alias[3], c_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h pdiv<Packet8h>(const Packet8h& a, const Packet8h& b) {
-  Packet8f af = half2float(a);
-  Packet8f bf = half2float(b);
-  Packet8f rf = pdiv(af, bf);
-  return float2half(rf);
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pdiv<Packet4h2>(
+    const Packet4h2& a, const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = pdiv(a_alias[0], b_alias[0]);
+  r_alias[1] = pdiv(a_alias[1], b_alias[1]);
+  r_alias[2] = pdiv(a_alias[2], b_alias[2]);
+  r_alias[3] = pdiv(a_alias[3], b_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h pgather<Eigen::half, Packet8h>(const Eigen::half* from, Index stride)
-{
-  Packet8h result;
-  result.x = _mm_set_epi16(from[7*stride].x, from[6*stride].x, from[5*stride].x, from[4*stride].x, from[3*stride].x, from[2*stride].x, from[1*stride].x, from[0*stride].x);
-  return result;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pmin<Packet4h2>(
+    const Packet4h2& a, const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = pmin(a_alias[0], b_alias[0]);
+  r_alias[1] = pmin(a_alias[1], b_alias[1]);
+  r_alias[2] = pmin(a_alias[2], b_alias[2]);
+  r_alias[3] = pmin(a_alias[3], b_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE void pscatter<Eigen::half, Packet8h>(Eigen::half* to, const Packet8h& from, Index stride)
-{
-  EIGEN_ALIGN32 Eigen::half aux[8];
-  pstore(aux, from);
-  to[stride*0].x = aux[0].x;
-  to[stride*1].x = aux[1].x;
-  to[stride*2].x = aux[2].x;
-  to[stride*3].x = aux[3].x;
-  to[stride*4].x = aux[4].x;
-  to[stride*5].x = aux[5].x;
-  to[stride*6].x = aux[6].x;
-  to[stride*7].x = aux[7].x;
-}
-
-template<> EIGEN_STRONG_INLINE Eigen::half predux<Packet8h>(const Packet8h& a) {
-  Packet8f af = half2float(a);
-  float reduced = predux<Packet8f>(af);
-  return Eigen::half(reduced);
-}
-
-template<> EIGEN_STRONG_INLINE Eigen::half predux_max<Packet8h>(const Packet8h& a) {
-  Packet8f af = half2float(a);
-  float reduced = predux_max<Packet8f>(af);
-  return Eigen::half(reduced);
-}
-
-template<> EIGEN_STRONG_INLINE Eigen::half predux_min<Packet8h>(const Packet8h& a) {
-  Packet8f af = half2float(a);
-  float reduced = predux_min<Packet8f>(af);
-  return Eigen::half(reduced);
-}
-
-template<> EIGEN_STRONG_INLINE Eigen::half predux_mul<Packet8h>(const Packet8h& a) {
-  Packet8f af = half2float(a);
-  float reduced = predux_mul<Packet8f>(af);
-  return Eigen::half(reduced);
-}
-
-template<> EIGEN_STRONG_INLINE Packet8h preduxp<Packet8h>(const Packet8h* p) {
-  Packet8f pf[8];
-  pf[0] = half2float(p[0]);
-  pf[1] = half2float(p[1]);
-  pf[2] = half2float(p[2]);
-  pf[3] = half2float(p[3]);
-  pf[4] = half2float(p[4]);
-  pf[5] = half2float(p[5]);
-  pf[6] = half2float(p[6]);
-  pf[7] = half2float(p[7]);
-  Packet8f reduced = preduxp<Packet8f>(pf);
-  return float2half(reduced);
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pmax<Packet4h2>(
+    const Packet4h2& a, const Packet4h2& b) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  const half2* b_alias = reinterpret_cast<const half2*>(&b);
+  r_alias[0] = pmax(a_alias[0], b_alias[0]);
+  r_alias[1] = pmax(a_alias[1], b_alias[1]);
+  r_alias[2] = pmax(a_alias[2], b_alias[2]);
+  r_alias[3] = pmax(a_alias[3], b_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h preverse(const Packet8h& a)
-{
-  __m128i m = _mm_setr_epi8(14,15,12,13,10,11,8,9,6,7,4,5,2,3,0,1);
-  Packet8h res;
-  res.x = _mm_shuffle_epi8(a.x,m);
-  return res;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux<Packet4h2>(
+    const Packet4h2& a) {
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+
+  return predux(a_alias[0]) + predux(a_alias[1]) +
+         predux(a_alias[2]) + predux(a_alias[3]);
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h pinsertfirst(const Packet8h& a, Eigen::half b)
-{
-  Packet8h res;
-  res.x = _mm_insert_epi16(a.x,int(b.x),0);
-  return res;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_max<Packet4h2>(
+    const Packet4h2& a) {
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  half2 m0 = __halves2half2(predux_max(a_alias[0]),
+                            predux_max(a_alias[1]));
+  half2 m1 = __halves2half2(predux_max(a_alias[2]),
+                            predux_max(a_alias[3]));
+  __half first  = predux_max(m0);
+  __half second = predux_max(m1);
+#if defined(EIGEN_CUDA_HAS_FP16_ARITHMETIC)
+  return (__hgt(first, second) ? first : second);
+#else
+  float ffirst  = __half2float(first);
+  float fsecond = __half2float(second);
+  return (ffirst > fsecond)? first: second;
+#endif
 }
 
-template<> EIGEN_STRONG_INLINE Packet8h pinsertlast(const Packet8h& a, Eigen::half b)
-{
-  Packet8h res;
-  res.x = _mm_insert_epi16(a.x,int(b.x),7);
-  return res;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_min<Packet4h2>(
+    const Packet4h2& a) {
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  half2 m0 = __halves2half2(predux_min(a_alias[0]),
+                            predux_min(a_alias[1]));
+  half2 m1 = __halves2half2(predux_min(a_alias[2]),
+                            predux_min(a_alias[3]));
+  __half first  = predux_min(m0);
+  __half second = predux_min(m1);
+#if defined(EIGEN_CUDA_HAS_FP16_ARITHMETIC)
+  return (__hlt(first, second) ? first : second);
+#else
+  float ffirst  = __half2float(first);
+  float fsecond = __half2float(second);
+  return (ffirst < fsecond)? first: second;
+#endif
 }
 
-template<int Offset>
-struct palign_impl<Offset,Packet8h>
-{
-  static EIGEN_STRONG_INLINE void run(Packet8h& first, const Packet8h& second)
-  {
-    if (Offset!=0)
-      first.x = _mm_alignr_epi8(second.x,first.x, Offset*2);
-  }
-};
+// likely overflow/underflow
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Eigen::half predux_mul<Packet4h2>(
+    const Packet4h2& a) {
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  return predux_mul(pmul(pmul(a_alias[0], a_alias[1]),
+                                       pmul(a_alias[2], a_alias[3])));
+}
 
-EIGEN_STRONG_INLINE void
-ptranspose(PacketBlock<Packet8h,8>& kernel) {
-  __m128i a = kernel.packet[0].x;
-  __m128i b = kernel.packet[1].x;
-  __m128i c = kernel.packet[2].x;
-  __m128i d = kernel.packet[3].x;
-  __m128i e = kernel.packet[4].x;
-  __m128i f = kernel.packet[5].x;
-  __m128i g = kernel.packet[6].x;
-  __m128i h = kernel.packet[7].x;
-
-  __m128i a03b03 = _mm_unpacklo_epi16(a, b);
-  __m128i c03d03 = _mm_unpacklo_epi16(c, d);
-  __m128i e03f03 = _mm_unpacklo_epi16(e, f);
-  __m128i g03h03 = _mm_unpacklo_epi16(g, h);
-  __m128i a47b47 = _mm_unpackhi_epi16(a, b);
-  __m128i c47d47 = _mm_unpackhi_epi16(c, d);
-  __m128i e47f47 = _mm_unpackhi_epi16(e, f);
-  __m128i g47h47 = _mm_unpackhi_epi16(g, h);
-
-  __m128i a01b01c01d01 = _mm_unpacklo_epi32(a03b03, c03d03);
-  __m128i a23b23c23d23 = _mm_unpackhi_epi32(a03b03, c03d03);
-  __m128i e01f01g01h01 = _mm_unpacklo_epi32(e03f03, g03h03);
-  __m128i e23f23g23h23 = _mm_unpackhi_epi32(e03f03, g03h03);
-  __m128i a45b45c45d45 = _mm_unpacklo_epi32(a47b47, c47d47);
-  __m128i a67b67c67d67 = _mm_unpackhi_epi32(a47b47, c47d47);
-  __m128i e45f45g45h45 = _mm_unpacklo_epi32(e47f47, g47h47);
-  __m128i e67f67g67h67 = _mm_unpackhi_epi32(e47f47, g47h47);
-
-  __m128i a0b0c0d0e0f0g0h0 = _mm_unpacklo_epi64(a01b01c01d01, e01f01g01h01);
-  __m128i a1b1c1d1e1f1g1h1 = _mm_unpackhi_epi64(a01b01c01d01, e01f01g01h01);
-  __m128i a2b2c2d2e2f2g2h2 = _mm_unpacklo_epi64(a23b23c23d23, e23f23g23h23);
-  __m128i a3b3c3d3e3f3g3h3 = _mm_unpackhi_epi64(a23b23c23d23, e23f23g23h23);
-  __m128i a4b4c4d4e4f4g4h4 = _mm_unpacklo_epi64(a45b45c45d45, e45f45g45h45);
-  __m128i a5b5c5d5e5f5g5h5 = _mm_unpackhi_epi64(a45b45c45d45, e45f45g45h45);
-  __m128i a6b6c6d6e6f6g6h6 = _mm_unpacklo_epi64(a67b67c67d67, e67f67g67h67);
-  __m128i a7b7c7d7e7f7g7h7 = _mm_unpackhi_epi64(a67b67c67d67, e67f67g67h67);
-
-  kernel.packet[0].x = a0b0c0d0e0f0g0h0;
-  kernel.packet[1].x = a1b1c1d1e1f1g1h1;
-  kernel.packet[2].x = a2b2c2d2e2f2g2h2;
-  kernel.packet[3].x = a3b3c3d3e3f3g3h3;
-  kernel.packet[4].x = a4b4c4d4e4f4g4h4;
-  kernel.packet[5].x = a5b5c5d5e5f5g5h5;
-  kernel.packet[6].x = a6b6c6d6e6f6g6h6;
-  kernel.packet[7].x = a7b7c7d7e7f7g7h7;
-}
-
-EIGEN_STRONG_INLINE void
-ptranspose(PacketBlock<Packet8h,4>& kernel) {
-  EIGEN_ALIGN32 Eigen::half in[4][8];
-  pstore<Eigen::half>(in[0], kernel.packet[0]);
-  pstore<Eigen::half>(in[1], kernel.packet[1]);
-  pstore<Eigen::half>(in[2], kernel.packet[2]);
-  pstore<Eigen::half>(in[3], kernel.packet[3]);
-
-  EIGEN_ALIGN32 Eigen::half out[4][8];
-
-  for (int i = 0; i < 4; ++i) {
-    for (int j = 0; j < 4; ++j) {
-      out[i][j] = in[j][2*i];
-    }
-    for (int j = 0; j < 4; ++j) {
-      out[i][j+4] = in[j][2*i+1];
-    }
-  }
-
-  kernel.packet[0] = pload<Packet8h>(out[0]);
-  kernel.packet[1] = pload<Packet8h>(out[1]);
-  kernel.packet[2] = pload<Packet8h>(out[2]);
-  kernel.packet[3] = pload<Packet8h>(out[3]);
-}
-
-
-// Disable the following code since it's broken on too many platforms / compilers.
-//#elif defined(EIGEN_VECTORIZE_SSE) && (!EIGEN_ARCH_x86_64) && (!EIGEN_COMP_MSVC)
-#elif 0
-
-typedef struct {
-  __m64 x;
-} Packet4h;
-
-
-template<> struct is_arithmetic<Packet4h> { enum { value = true }; };
-
-template <>
-struct packet_traits<Eigen::half> : default_packet_traits {
-  typedef Packet4h type;
-  // There is no half-size packet for Packet4h.
-  typedef Packet4h half;
-  enum {
-    Vectorizable = 1,
-    AlignedOnScalar = 1,
-    size = 4,
-    HasHalfPacket = 0,
-    HasAdd    = 1,
-    HasSub    = 1,
-    HasMul    = 1,
-    HasDiv    = 1,
-    HasNegate = 0,
-    HasAbs    = 0,
-    HasAbs2   = 0,
-    HasMin    = 0,
-    HasMax    = 0,
-    HasConj   = 0,
-    HasSetLinear = 0,
-    HasSqrt = 0,
-    HasRsqrt = 0,
-    HasExp = 0,
-    HasLog = 0,
-    HasBlend = 0
-  };
-};
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+plog1p<Packet4h2>(const Packet4h2& a) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  r_alias[0] = plog1p(a_alias[0]);
+  r_alias[1] = plog1p(a_alias[1]);
+  r_alias[2] = plog1p(a_alias[2]);
+  r_alias[3] = plog1p(a_alias[3]);
+  return r;
+}
 
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+pexpm1<Packet4h2>(const Packet4h2& a) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  r_alias[0] = pexpm1(a_alias[0]);
+  r_alias[1] = pexpm1(a_alias[1]);
+  r_alias[2] = pexpm1(a_alias[2]);
+  r_alias[3] = pexpm1(a_alias[3]);
+  return r;
+}
 
-template<> struct unpacket_traits<Packet4h> { typedef Eigen::half type; enum {size=4, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet4h half; };
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 plog<Packet4h2>(const Packet4h2& a) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  r_alias[0] = plog(a_alias[0]);
+  r_alias[1] = plog(a_alias[1]);
+  r_alias[2] = plog(a_alias[2]);
+  r_alias[3] = plog(a_alias[3]);
+  return r;
+}
 
-template<> EIGEN_STRONG_INLINE Packet4h pset1<Packet4h>(const Eigen::half& from) {
-  Packet4h result;
-  result.x = _mm_set1_pi16(from.x);
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE Eigen::half pfirst<Packet4h>(const Packet4h& from) {
-  return half_impl::raw_uint16_to_half(static_cast<unsigned short>(_mm_cvtsi64_si32(from.x)));
-}
-
-template<> EIGEN_STRONG_INLINE Packet4h pconj(const Packet4h& a) { return a; }
-
-template<> EIGEN_STRONG_INLINE Packet4h padd<Packet4h>(const Packet4h& a, const Packet4h& b) {
-  __int64_t a64 = _mm_cvtm64_si64(a.x);
-  __int64_t b64 = _mm_cvtm64_si64(b.x);
-
-  Eigen::half h[4];
-
-  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
-  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
-  h[0] = ha + hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
-  h[1] = ha + hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
-  h[2] = ha + hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
-  h[3] = ha + hb;
-  Packet4h result;
-  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE Packet4h psub<Packet4h>(const Packet4h& a, const Packet4h& b) {
-  __int64_t a64 = _mm_cvtm64_si64(a.x);
-  __int64_t b64 = _mm_cvtm64_si64(b.x);
-
-  Eigen::half h[4];
-
-  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
-  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
-  h[0] = ha - hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
-  h[1] = ha - hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
-  h[2] = ha - hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
-  h[3] = ha - hb;
-  Packet4h result;
-  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE Packet4h pmul<Packet4h>(const Packet4h& a, const Packet4h& b) {
-  __int64_t a64 = _mm_cvtm64_si64(a.x);
-  __int64_t b64 = _mm_cvtm64_si64(b.x);
-
-  Eigen::half h[4];
-
-  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
-  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
-  h[0] = ha * hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
-  h[1] = ha * hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
-  h[2] = ha * hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
-  h[3] = ha * hb;
-  Packet4h result;
-  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE Packet4h pdiv<Packet4h>(const Packet4h& a, const Packet4h& b) {
-  __int64_t a64 = _mm_cvtm64_si64(a.x);
-  __int64_t b64 = _mm_cvtm64_si64(b.x);
-
-  Eigen::half h[4];
-
-  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
-  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
-  h[0] = ha / hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
-  h[1] = ha / hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
-  h[2] = ha / hb;
-  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
-  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
-  h[3] = ha / hb;
-  Packet4h result;
-  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE Packet4h pload<Packet4h>(const Eigen::half* from) {
-  Packet4h result;
-  result.x = _mm_cvtsi64_m64(*reinterpret_cast<const __int64_t*>(from));
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE Packet4h ploadu<Packet4h>(const Eigen::half* from) {
-  Packet4h result;
-  result.x = _mm_cvtsi64_m64(*reinterpret_cast<const __int64_t*>(from));
-  return result;
-}
-
-template<> EIGEN_STRONG_INLINE void pstore<Eigen::half>(Eigen::half* to, const Packet4h& from) {
-  __int64_t r = _mm_cvtm64_si64(from.x);
-  *(reinterpret_cast<__int64_t*>(to)) = r;
-}
-
-template<> EIGEN_STRONG_INLINE void pstoreu<Eigen::half>(Eigen::half* to, const Packet4h& from) {
-  __int64_t r = _mm_cvtm64_si64(from.x);
-  *(reinterpret_cast<__int64_t*>(to)) = r;
-}
-
-template<> EIGEN_STRONG_INLINE Packet4h
-ploadquad<Packet4h>(const Eigen::half* from) {
-  return pset1<Packet4h>(*from);
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 pexp<Packet4h2>(const Packet4h2& a) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  r_alias[0] = pexp(a_alias[0]);
+  r_alias[1] = pexp(a_alias[1]);
+  r_alias[2] = pexp(a_alias[2]);
+  r_alias[3] = pexp(a_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE Packet4h pgather<Eigen::half, Packet4h>(const Eigen::half* from, Index stride)
-{
-  Packet4h result;
-  result.x = _mm_set_pi16(from[3*stride].x, from[2*stride].x, from[1*stride].x, from[0*stride].x);
-  return result;
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2 psqrt<Packet4h2>(const Packet4h2& a) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  r_alias[0] = psqrt(a_alias[0]);
+  r_alias[1] = psqrt(a_alias[1]);
+  r_alias[2] = psqrt(a_alias[2]);
+  r_alias[3] = psqrt(a_alias[3]);
+  return r;
 }
 
-template<> EIGEN_STRONG_INLINE void pscatter<Eigen::half, Packet4h>(Eigen::half* to, const Packet4h& from, Index stride)
-{
-  __int64_t a = _mm_cvtm64_si64(from.x);
-  to[stride*0].x = static_cast<unsigned short>(a);
-  to[stride*1].x = static_cast<unsigned short>(a >> 16);
-  to[stride*2].x = static_cast<unsigned short>(a >> 32);
-  to[stride*3].x = static_cast<unsigned short>(a >> 48);
+template <>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet4h2
+prsqrt<Packet4h2>(const Packet4h2& a) {
+  Packet4h2 r;
+  half2* r_alias = reinterpret_cast<half2*>(&r);
+  const half2* a_alias = reinterpret_cast<const half2*>(&a);
+  r_alias[0] = prsqrt(a_alias[0]);
+  r_alias[1] = prsqrt(a_alias[1]);
+  r_alias[2] = prsqrt(a_alias[2]);
+  r_alias[3] = prsqrt(a_alias[3]);
+  return r;
 }
 
-EIGEN_STRONG_INLINE void
-ptranspose(PacketBlock<Packet4h,4>& kernel) {
-  __m64 T0 = _mm_unpacklo_pi16(kernel.packet[0].x, kernel.packet[1].x);
-  __m64 T1 = _mm_unpacklo_pi16(kernel.packet[2].x, kernel.packet[3].x);
-  __m64 T2 = _mm_unpackhi_pi16(kernel.packet[0].x, kernel.packet[1].x);
-  __m64 T3 = _mm_unpackhi_pi16(kernel.packet[2].x, kernel.packet[3].x);
+// The following specialized padd, pmul, pdiv, pmin, pmax, pset1 are needed for
+// the implementation of GPU half reduction.
+template<>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 padd<half2>(const half2& a,
+                                                        const half2& b) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
+  return __hadd2(a, b);
+#else
+  float a1 = __low2float(a);
+  float a2 = __high2float(a);
+  float b1 = __low2float(b);
+  float b2 = __high2float(b);
+  float r1 = a1 + b1;
+  float r2 = a2 + b2;
+  return __floats2half2_rn(r1, r2);
+#endif
+}
 
-  kernel.packet[0].x = _mm_unpacklo_pi32(T0, T1);
-  kernel.packet[1].x = _mm_unpackhi_pi32(T0, T1);
-  kernel.packet[2].x = _mm_unpacklo_pi32(T2, T3);
-  kernel.packet[3].x = _mm_unpackhi_pi32(T2, T3);
+template<>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmul<half2>(const half2& a,
+                                                        const half2& b) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
+  return __hmul2(a, b);
+#else
+  float a1 = __low2float(a);
+  float a2 = __high2float(a);
+  float b1 = __low2float(b);
+  float b2 = __high2float(b);
+  float r1 = a1 * b1;
+  float r2 = a2 * b2;
+  return __floats2half2_rn(r1, r2);
+#endif
 }
 
+template<>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pdiv<half2>(const half2& a,
+                                                        const half2& b) {
+#if defined(EIGEN_GPU_HAS_FP16_ARITHMETIC)
+  return __h2div(a, b);
+#else
+  float a1 = __low2float(a);
+  float a2 = __high2float(a);
+  float b1 = __low2float(b);
+  float b2 = __high2float(b);
+  float r1 = a1 / b1;
+  float r2 = a2 / b2;
+  return __floats2half2_rn(r1, r2);
 #endif
+}
 
+template<>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmin<half2>(const half2& a,
+                                                        const half2& b) {
+  float a1 = __low2float(a);
+  float a2 = __high2float(a);
+  float b1 = __low2float(b);
+  float b2 = __high2float(b);
+  __half r1 = a1 < b1 ? __low2half(a) : __low2half(b);
+  __half r2 = a2 < b2 ? __high2half(a) : __high2half(b);
+  return __halves2half2(r1, r2);
 }
+
+template<>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE half2 pmax<half2>(const half2& a,
+                                                        const half2& b) {
+  float a1 = __low2float(a);
+  float a2 = __high2float(a);
+  float b1 = __low2float(b);
+  float b2 = __high2float(b);
+  __half r1 = a1 > b1 ? __low2half(a) : __low2half(b);
+  __half r2 = a2 > b2 ? __high2half(a) : __high2half(b);
+  return __halves2half2(r1, r2);
 }
 
-#endif // EIGEN_PACKET_MATH_HALF_GPU_H
+#endif // (defined(EIGEN_HAS_CUDA_FP16) || defined(EIGEN_HAS_HIP_FP16)) && defined(EIGEN_GPU_COMPILE_PHASE)
+
+#undef EIGEN_GPU_HAS_LDG
+#undef EIGEN_CUDA_HAS_FP16_ARITHMETIC
+#undef EIGEN_GPU_HAS_FP16_ARITHMETIC
+
+} // end namespace internal
+
+} // end namespace Eigen
+
+
+#endif // EIGEN_PACKET_MATH_GPU_H
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/HIP/hcc/math_constants.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/HIP/hcc/math_constants.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/MSA/Complex.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/MSA/Complex.h`

 * *Files 20% similar despite different names*

```diff
@@ -294,80 +294,21 @@
 
   Packet4f value = (Packet4f)preverse((Packet2d)a.v);
   value += a.v;
   return std::complex<float>(value[0], value[1]);
 }
 
 template <>
-EIGEN_STRONG_INLINE Packet2cf preduxp<Packet2cf>(const Packet2cf* vecs) {
-  EIGEN_MSA_DEBUG;
-
-  Packet4f sum1, sum2, sum;
-
-  // Add the first two 64-bit float32x2_t of vecs[0]
-  sum1 = (Packet4f)__builtin_msa_ilvr_d((v2i64)vecs[1].v, (v2i64)vecs[0].v);
-  sum2 = (Packet4f)__builtin_msa_ilvl_d((v2i64)vecs[1].v, (v2i64)vecs[0].v);
-  sum = padd(sum1, sum2);
-
-  return Packet2cf(sum);
-}
-
-template <>
 EIGEN_STRONG_INLINE std::complex<float> predux_mul<Packet2cf>(const Packet2cf& a) {
   EIGEN_MSA_DEBUG;
 
   return std::complex<float>((a.v[0] * a.v[2]) - (a.v[1] * a.v[3]),
                              (a.v[0] * a.v[3]) + (a.v[1] * a.v[2]));
 }
 
-template <int Offset>
-struct palign_impl<Offset, Packet2cf> {
-  EIGEN_STRONG_INLINE static void run(Packet2cf& first, const Packet2cf& second) {
-    if (Offset == 1) {
-      first.v = (Packet4f)__builtin_msa_sldi_b((v16i8)second.v, (v16i8)first.v, Offset * 8);
-    }
-  }
-};
-
-template <>
-struct conj_helper<Packet2cf, Packet2cf, false, true> {
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y,
-                                      const Packet2cf& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template <>
-struct conj_helper<Packet2cf, Packet2cf, true, false> {
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y,
-                                      const Packet2cf& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template <>
-struct conj_helper<Packet2cf, Packet2cf, true, true> {
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y,
-                                      const Packet2cf& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf, Packet4f)
 
 template <>
 EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b) {
   EIGEN_MSA_DEBUG;
 
   return a / b;
@@ -657,72 +598,20 @@
 EIGEN_STRONG_INLINE std::complex<double> predux<Packet1cd>(const Packet1cd& a) {
   EIGEN_MSA_DEBUG;
 
   return pfirst(a);
 }
 
 template <>
-EIGEN_STRONG_INLINE Packet1cd preduxp<Packet1cd>(const Packet1cd* vecs) {
-  EIGEN_MSA_DEBUG;
-
-  return vecs[0];
-}
-
-template <>
 EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet1cd>(const Packet1cd& a) {
   EIGEN_MSA_DEBUG;
 
   return pfirst(a);
 }
 
-template <int Offset>
-struct palign_impl<Offset, Packet1cd> {
-  static EIGEN_STRONG_INLINE void run(Packet1cd& /*first*/, const Packet1cd& /*second*/) {
-    // FIXME is it sure we never have to align a Packet1cd?
-    // Even though a std::complex<double> has 16 bytes, it is not necessarily aligned on a 16 bytes
-    // boundary...
-  }
-};
-
-template <>
-struct conj_helper<Packet1cd, Packet1cd, false, true> {
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y,
-                                      const Packet1cd& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template <>
-struct conj_helper<Packet1cd, Packet1cd, true, false> {
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y,
-                                      const Packet1cd& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template <>
-struct conj_helper<Packet1cd, Packet1cd, true, true> {
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y,
-                                      const Packet1cd& c) const {
-    return padd(pmul(x, y), c);
-  }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cd, Packet2d)
 
 template <>
 EIGEN_STRONG_INLINE Packet1cd pdiv<Packet1cd>(const Packet1cd& a, const Packet1cd& b) {
   EIGEN_MSA_DEBUG;
 
   return a / b;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/MSA/MathFunctions.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/MSA/MathFunctions.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/MSA/PacketMath.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/MSA/PacketMath.h`

 * *Files 4% similar despite different names*

```diff
@@ -24,18 +24,14 @@
 #define EIGEN_CACHEFRIENDLY_PRODUCT_THRESHOLD 8
 #endif
 
 #ifndef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #define EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #endif
 
-#ifndef EIGEN_HAS_SINGLE_INSTRUCTION_CJMADD
-#define EIGEN_HAS_SINGLE_INSTRUCTION_CJMADD
-#endif
-
 #ifndef EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS
 #define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS 32
 #endif
 
 #if 0
 #define EIGEN_MSA_DEBUG                                                             \
   static bool firstTime = true;                                                     \
@@ -84,14 +80,15 @@
     size = 4,
     HasHalfPacket = 0,  // Packet2f intrinsics not implemented yet
     // FIXME check the Has*
     HasDiv = 1,
     HasSin = EIGEN_FAST_MATH,
     HasCos = EIGEN_FAST_MATH,
     HasTanh = EIGEN_FAST_MATH,
+    HasErf = EIGEN_FAST_MATH,
     HasLog = 1,
     HasExp = 1,
     HasSqrt = 1,
     HasRsqrt = 1,
     HasRound = 1,
     HasFloor = 1,
     HasCeil = 1,
@@ -570,53 +567,14 @@
   EIGEN_MSA_DEBUG;
 
   Packet4f s = padd(a, (Packet4f)__builtin_msa_shf_w((v4i32)a, EIGEN_MSA_SHF_I8(2, 3, 0, 1)));
   s = padd(s, (Packet4f)__builtin_msa_shf_w((v4i32)s, EIGEN_MSA_SHF_I8(1, 0, 3, 2)));
   return s[0];
 }
 
-template <>
-EIGEN_STRONG_INLINE Packet4f preduxp<Packet4f>(const Packet4f* vecs) {
-  EIGEN_MSA_DEBUG;
-
-  v4i32 tmp1, tmp2, tmp3, tmp4;
-  Packet4f sum;
-
-  tmp1 = __builtin_msa_ilvr_w((v4i32)vecs[1], (v4i32)vecs[0]);
-  tmp2 = __builtin_msa_ilvr_w((v4i32)vecs[3], (v4i32)vecs[2]);
-  tmp3 = __builtin_msa_ilvl_w((v4i32)vecs[1], (v4i32)vecs[0]);
-  tmp4 = __builtin_msa_ilvl_w((v4i32)vecs[3], (v4i32)vecs[2]);
-
-  sum = (Packet4f)__builtin_msa_ilvr_d((v2i64)tmp2, (v2i64)tmp1);
-  sum = padd(sum, (Packet4f)__builtin_msa_ilvod_d((v2i64)tmp2, (v2i64)tmp1));
-  sum = padd(sum, (Packet4f)__builtin_msa_ilvr_d((v2i64)tmp4, (v2i64)tmp3));
-  sum = padd(sum, (Packet4f)__builtin_msa_ilvod_d((v2i64)tmp4, (v2i64)tmp3));
-
-  return sum;
-}
-
-template <>
-EIGEN_STRONG_INLINE Packet4i preduxp<Packet4i>(const Packet4i* vecs) {
-  EIGEN_MSA_DEBUG;
-
-  v4i32 tmp1, tmp2, tmp3, tmp4;
-  Packet4i sum;
-
-  tmp1 = __builtin_msa_ilvr_w((v4i32)vecs[1], (v4i32)vecs[0]);
-  tmp2 = __builtin_msa_ilvr_w((v4i32)vecs[3], (v4i32)vecs[2]);
-  tmp3 = __builtin_msa_ilvl_w((v4i32)vecs[1], (v4i32)vecs[0]);
-  tmp4 = __builtin_msa_ilvl_w((v4i32)vecs[3], (v4i32)vecs[2]);
-
-  sum = (Packet4i)__builtin_msa_ilvr_d((v2i64)tmp2, (v2i64)tmp1);
-  sum = padd(sum, (Packet4i)__builtin_msa_ilvod_d((v2i64)tmp2, (v2i64)tmp1));
-  sum = padd(sum, (Packet4i)__builtin_msa_ilvr_d((v2i64)tmp4, (v2i64)tmp3));
-  sum = padd(sum, (Packet4i)__builtin_msa_ilvod_d((v2i64)tmp4, (v2i64)tmp3));
-
-  return sum;
-}
 
 template <>
 EIGEN_STRONG_INLINE int32_t predux<Packet4i>(const Packet4i& a) {
   EIGEN_MSA_DEBUG;
 
   Packet4i s = padd(a, __builtin_msa_shf_w(a, EIGEN_MSA_SHF_I8(2, 3, 0, 1)));
   s = padd(s, __builtin_msa_shf_w(s, EIGEN_MSA_SHF_I8(1, 0, 3, 2)));
@@ -709,33 +667,14 @@
   EIGEN_MSA_DEBUG;
 
   Packet4i m = pmax(a, __builtin_msa_shf_w(a, EIGEN_MSA_SHF_I8(2, 3, 0, 1)));
   m = pmax(m, __builtin_msa_shf_w(m, EIGEN_MSA_SHF_I8(1, 0, 3, 2)));
   return m[0];
 }
 
-#define PALIGN_MSA(Offset, Type, Command)                                                \
-  template <>                                                                            \
-  struct palign_impl<Offset, Type> {                                                     \
-    EIGEN_STRONG_INLINE static void run(Type& first, const Type& second) {               \
-      if (Offset != 0) first = (Type)(Command((v16i8)second, (v16i8)first, Offset * 4)); \
-    }                                                                                    \
-  };
-
-PALIGN_MSA(0, Packet4f, __builtin_msa_sldi_b)
-PALIGN_MSA(1, Packet4f, __builtin_msa_sldi_b)
-PALIGN_MSA(2, Packet4f, __builtin_msa_sldi_b)
-PALIGN_MSA(3, Packet4f, __builtin_msa_sldi_b)
-PALIGN_MSA(0, Packet4i, __builtin_msa_sldi_b)
-PALIGN_MSA(1, Packet4i, __builtin_msa_sldi_b)
-PALIGN_MSA(2, Packet4i, __builtin_msa_sldi_b)
-PALIGN_MSA(3, Packet4i, __builtin_msa_sldi_b)
-
-#undef PALIGN_MSA
-
 inline std::ostream& operator<<(std::ostream& os, const PacketBlock<Packet4f, 4>& value) {
   os << "[ " << value.packet[0] << "," << std::endl
      << "  " << value.packet[1] << "," << std::endl
      << "  " << value.packet[2] << "," << std::endl
      << "  " << value.packet[3] << " ]";
   return os;
 }
@@ -1143,24 +1082,14 @@
 EIGEN_STRONG_INLINE double predux<Packet2d>(const Packet2d& a) {
   EIGEN_MSA_DEBUG;
 
   Packet2d s = padd(a, preverse(a));
   return s[0];
 }
 
-template <>
-EIGEN_STRONG_INLINE Packet2d preduxp<Packet2d>(const Packet2d* vecs) {
-  EIGEN_MSA_DEBUG;
-
-  Packet2d v0 = (Packet2d)__builtin_msa_ilvev_d((v2i64)vecs[1], (v2i64)vecs[0]);
-  Packet2d v1 = (Packet2d)__builtin_msa_ilvod_d((v2i64)vecs[1], (v2i64)vecs[0]);
-
-  return padd(v0, v1);
-}
-
 // Other reduction functions:
 // mul
 template <>
 EIGEN_STRONG_INLINE double predux_mul<Packet2d>(const Packet2d& a) {
   EIGEN_MSA_DEBUG;
 
   Packet2d p = pmul(a, preverse(a));
@@ -1212,27 +1141,14 @@
   return __builtin_msa_frsqrt_d(a);
 #else
   Packet2d ones = __builtin_msa_ffint_s_d(__builtin_msa_ldi_d(1));
   return pdiv(ones, psqrt(a));
 #endif
 }
 
-#define PALIGN_MSA(Offset, Type, Command)                                                \
-  template <>                                                                            \
-  struct palign_impl<Offset, Type> {                                                     \
-    EIGEN_STRONG_INLINE static void run(Type& first, const Type& second) {               \
-      if (Offset != 0) first = (Type)(Command((v16i8)second, (v16i8)first, Offset * 8)); \
-    }                                                                                    \
-  };
-
-PALIGN_MSA(0, Packet2d, __builtin_msa_sldi_b)
-PALIGN_MSA(1, Packet2d, __builtin_msa_sldi_b)
-
-#undef PALIGN_MSA
-
 inline std::ostream& operator<<(std::ostream& os, const PacketBlock<Packet2d, 2>& value) {
   os << "[ " << value.packet[0] << "," << std::endl << "  " << value.packet[1] << " ]";
   return os;
 }
 
 EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet2d, 2>& kernel) {
   EIGEN_MSA_DEBUG;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/NEON/Complex.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/NEON/Complex.h`

 * *Files 20% similar despite different names*

```diff
@@ -11,204 +11,314 @@
 #ifndef EIGEN_COMPLEX_NEON_H
 #define EIGEN_COMPLEX_NEON_H
 
 namespace Eigen {
 
 namespace internal {
 
-inline uint32x4_t p4ui_CONJ_XOR() {
+inline uint32x4_t p4ui_CONJ_XOR()
+{
 // See bug 1325, clang fails to call vld1q_u64.
-#if EIGEN_COMP_CLANG
+#if EIGEN_COMP_CLANG || EIGEN_COMP_CASTXML
   uint32x4_t ret = { 0x00000000, 0x80000000, 0x00000000, 0x80000000 };
   return ret;
 #else
   static const uint32_t conj_XOR_DATA[] = { 0x00000000, 0x80000000, 0x00000000, 0x80000000 };
   return vld1q_u32( conj_XOR_DATA );
 #endif
 }
 
-inline uint32x2_t p2ui_CONJ_XOR() {
+inline uint32x2_t p2ui_CONJ_XOR()
+{
   static const uint32_t conj_XOR_DATA[] = { 0x00000000, 0x80000000 };
   return vld1_u32( conj_XOR_DATA );
 }
 
 //---------- float ----------
+
+struct Packet1cf
+{
+  EIGEN_STRONG_INLINE Packet1cf() {}
+  EIGEN_STRONG_INLINE explicit Packet1cf(const Packet2f& a) : v(a) {}
+  Packet2f v;
+};
 struct Packet2cf
 {
   EIGEN_STRONG_INLINE Packet2cf() {}
   EIGEN_STRONG_INLINE explicit Packet2cf(const Packet4f& a) : v(a) {}
-  Packet4f  v;
+  Packet4f v;
 };
 
-template<> struct packet_traits<std::complex<float> >  : default_packet_traits
+template<> struct packet_traits<std::complex<float> > : default_packet_traits
 {
   typedef Packet2cf type;
-  typedef Packet2cf half;
-  enum {
+  typedef Packet1cf half;
+  enum
+  {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size = 2,
-    HasHalfPacket = 0,
+    HasHalfPacket = 1,
 
-    HasAdd    = 1,
-    HasSub    = 1,
-    HasMul    = 1,
-    HasDiv    = 1,
-    HasNegate = 1,
-    HasAbs    = 0,
-    HasAbs2   = 0,
-    HasMin    = 0,
-    HasMax    = 0,
+    HasAdd       = 1,
+    HasSub       = 1,
+    HasMul       = 1,
+    HasDiv       = 1,
+    HasNegate    = 1,
+    HasAbs       = 0,
+    HasAbs2      = 0,
+    HasMin       = 0,
+    HasMax       = 0,
     HasSetLinear = 0
   };
 };
 
-template<> struct unpacket_traits<Packet2cf> { typedef std::complex<float> type; enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet2cf half; };
-
-template<> EIGEN_STRONG_INLINE Packet2cf pset1<Packet2cf>(const std::complex<float>&  from)
+template<> struct unpacket_traits<Packet1cf>
 {
-  float32x2_t r64;
-  r64 = vld1_f32((const float *)&from);
+  typedef std::complex<float> type;
+  typedef Packet1cf half;
+  typedef Packet2f as_real;
+  enum
+  {
+    size = 1,
+    alignment = Aligned16,
+    vectorizable = true,
+    masked_load_available = false,
+    masked_store_available = false
+  };
+};
+template<> struct unpacket_traits<Packet2cf>
+{
+  typedef std::complex<float> type;
+  typedef Packet1cf half;
+  typedef Packet4f as_real;
+  enum
+  {
+    size = 2,
+    alignment = Aligned16,
+    vectorizable = true,
+    masked_load_available = false,
+    masked_store_available = false
+  };
+};
 
+template<> EIGEN_STRONG_INLINE Packet1cf pcast<float,Packet1cf>(const float& a)
+{ return Packet1cf(vset_lane_f32(a, vdup_n_f32(0.f), 0)); }
+template<> EIGEN_STRONG_INLINE Packet2cf pcast<Packet2f,Packet2cf>(const Packet2f& a)
+{ return Packet2cf(vreinterpretq_f32_u64(vmovl_u32(vreinterpret_u32_f32(a)))); }
+
+template<> EIGEN_STRONG_INLINE Packet1cf pset1<Packet1cf>(const std::complex<float>& from)
+{ return Packet1cf(vld1_f32(reinterpret_cast<const float*>(&from))); }
+template<> EIGEN_STRONG_INLINE Packet2cf pset1<Packet2cf>(const std::complex<float>& from)
+{
+  const float32x2_t r64 = vld1_f32(reinterpret_cast<const float*>(&from));
   return Packet2cf(vcombine_f32(r64, r64));
 }
 
-template<> EIGEN_STRONG_INLINE Packet2cf padd<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(padd<Packet4f>(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet2cf psub<Packet2cf>(const Packet2cf& a, const Packet2cf& b) { return Packet2cf(psub<Packet4f>(a.v,b.v)); }
+template<> EIGEN_STRONG_INLINE Packet1cf padd<Packet1cf>(const Packet1cf& a, const Packet1cf& b)
+{ return Packet1cf(padd<Packet2f>(a.v, b.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf padd<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
+{ return Packet2cf(padd<Packet4f>(a.v, b.v)); }
+
+template<> EIGEN_STRONG_INLINE Packet1cf psub<Packet1cf>(const Packet1cf& a, const Packet1cf& b)
+{ return Packet1cf(psub<Packet2f>(a.v, b.v)); }
+template<> EIGEN_STRONG_INLINE Packet2cf psub<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
+{ return Packet2cf(psub<Packet4f>(a.v, b.v)); }
+
+template<> EIGEN_STRONG_INLINE Packet1cf pnegate(const Packet1cf& a) { return Packet1cf(pnegate<Packet2f>(a.v)); }
 template<> EIGEN_STRONG_INLINE Packet2cf pnegate(const Packet2cf& a) { return Packet2cf(pnegate<Packet4f>(a.v)); }
+
+template<> EIGEN_STRONG_INLINE Packet1cf pconj(const Packet1cf& a)
+{
+  const Packet2ui b = vreinterpret_u32_f32(a.v);
+  return Packet1cf(vreinterpret_f32_u32(veor_u32(b, p2ui_CONJ_XOR())));
+}
 template<> EIGEN_STRONG_INLINE Packet2cf pconj(const Packet2cf& a)
 {
-  Packet4ui b = vreinterpretq_u32_f32(a.v);
+  const Packet4ui b = vreinterpretq_u32_f32(a.v);
   return Packet2cf(vreinterpretq_f32_u32(veorq_u32(b, p4ui_CONJ_XOR())));
 }
 
+template<> EIGEN_STRONG_INLINE Packet1cf pmul<Packet1cf>(const Packet1cf& a, const Packet1cf& b)
+{
+  Packet2f v1, v2;
+
+  // Get the real values of a | a1_re | a1_re |
+  v1 = vdup_lane_f32(a.v, 0);
+  // Get the imag values of a | a1_im | a1_im |
+  v2 = vdup_lane_f32(a.v, 1);
+  // Multiply the real a with b
+  v1 = vmul_f32(v1, b.v);
+  // Multiply the imag a with b
+  v2 = vmul_f32(v2, b.v);
+  // Conjugate v2
+  v2 = vreinterpret_f32_u32(veor_u32(vreinterpret_u32_f32(v2), p2ui_CONJ_XOR()));
+  // Swap real/imag elements in v2.
+  v2 = vrev64_f32(v2);
+  // Add and return the result
+  return Packet1cf(vadd_f32(v1, v2));
+}
 template<> EIGEN_STRONG_INLINE Packet2cf pmul<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
 {
   Packet4f v1, v2;
 
   // Get the real values of a | a1_re | a1_re | a2_re | a2_re |
   v1 = vcombine_f32(vdup_lane_f32(vget_low_f32(a.v), 0), vdup_lane_f32(vget_high_f32(a.v), 0));
   // Get the imag values of a | a1_im | a1_im | a2_im | a2_im |
   v2 = vcombine_f32(vdup_lane_f32(vget_low_f32(a.v), 1), vdup_lane_f32(vget_high_f32(a.v), 1));
   // Multiply the real a with b
   v1 = vmulq_f32(v1, b.v);
   // Multiply the imag a with b
   v2 = vmulq_f32(v2, b.v);
-  // Conjugate v2 
+  // Conjugate v2
   v2 = vreinterpretq_f32_u32(veorq_u32(vreinterpretq_u32_f32(v2), p4ui_CONJ_XOR()));
   // Swap real/imag elements in v2.
   v2 = vrev64q_f32(v2);
   // Add and return the result
   return Packet2cf(vaddq_f32(v1, v2));
 }
 
+template<> EIGEN_STRONG_INLINE Packet1cf pcmp_eq(const Packet1cf& a, const Packet1cf& b)
+{
+  // Compare real and imaginary parts of a and b to get the mask vector:
+  // [re(a[0])==re(b[0]), im(a[0])==im(b[0])]
+  Packet2f eq = pcmp_eq<Packet2f>(a.v, b.v);
+  // Swap real/imag elements in the mask in to get:
+  // [im(a[0])==im(b[0]), re(a[0])==re(b[0])]
+  Packet2f eq_swapped = vrev64_f32(eq);
+  // Return re(a)==re(b) && im(a)==im(b) by computing bitwise AND of eq and eq_swapped
+  return Packet1cf(pand<Packet2f>(eq, eq_swapped));
+}
 template<> EIGEN_STRONG_INLINE Packet2cf pcmp_eq(const Packet2cf& a, const Packet2cf& b)
 {
   // Compare real and imaginary parts of a and b to get the mask vector:
   // [re(a[0])==re(b[0]), im(a[0])==im(b[0]), re(a[1])==re(b[1]), im(a[1])==im(b[1])]
   Packet4f eq = pcmp_eq<Packet4f>(a.v, b.v);
   // Swap real/imag elements in the mask in to get:
   // [im(a[0])==im(b[0]), re(a[0])==re(b[0]), im(a[1])==im(b[1]), re(a[1])==re(b[1])]
   Packet4f eq_swapped = vrev64q_f32(eq);
   // Return re(a)==re(b) && im(a)==im(b) by computing bitwise AND of eq and eq_swapped
   return Packet2cf(pand<Packet4f>(eq, eq_swapped));
 }
 
-template<> EIGEN_STRONG_INLINE Packet2cf pand   <Packet2cf>(const Packet2cf& a, const Packet2cf& b)
-{
-  return Packet2cf(vreinterpretq_f32_u32(vandq_u32(vreinterpretq_u32_f32(a.v),vreinterpretq_u32_f32(b.v))));
-}
-template<> EIGEN_STRONG_INLINE Packet2cf por    <Packet2cf>(const Packet2cf& a, const Packet2cf& b)
-{
-  return Packet2cf(vreinterpretq_f32_u32(vorrq_u32(vreinterpretq_u32_f32(a.v),vreinterpretq_u32_f32(b.v))));
-}
-template<> EIGEN_STRONG_INLINE Packet2cf pxor   <Packet2cf>(const Packet2cf& a, const Packet2cf& b)
-{
-  return Packet2cf(vreinterpretq_f32_u32(veorq_u32(vreinterpretq_u32_f32(a.v),vreinterpretq_u32_f32(b.v))));
-}
+template<> EIGEN_STRONG_INLINE Packet1cf pand<Packet1cf>(const Packet1cf& a, const Packet1cf& b)
+{ return Packet1cf(vreinterpret_f32_u32(vand_u32(vreinterpret_u32_f32(a.v), vreinterpret_u32_f32(b.v)))); }
+template<> EIGEN_STRONG_INLINE Packet2cf pand<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
+{ return Packet2cf(vreinterpretq_f32_u32(vandq_u32(vreinterpretq_u32_f32(a.v), vreinterpretq_u32_f32(b.v)))); }
+
+template<> EIGEN_STRONG_INLINE Packet1cf por<Packet1cf>(const Packet1cf& a, const Packet1cf& b)
+{ return Packet1cf(vreinterpret_f32_u32(vorr_u32(vreinterpret_u32_f32(a.v), vreinterpret_u32_f32(b.v)))); }
+template<> EIGEN_STRONG_INLINE Packet2cf por<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
+{ return Packet2cf(vreinterpretq_f32_u32(vorrq_u32(vreinterpretq_u32_f32(a.v), vreinterpretq_u32_f32(b.v)))); }
+
+template<> EIGEN_STRONG_INLINE Packet1cf pxor<Packet1cf>(const Packet1cf& a, const Packet1cf& b)
+{ return Packet1cf(vreinterpret_f32_u32(veor_u32(vreinterpret_u32_f32(a.v), vreinterpret_u32_f32(b.v)))); }
+template<> EIGEN_STRONG_INLINE Packet2cf pxor<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
+{ return Packet2cf(vreinterpretq_f32_u32(veorq_u32(vreinterpretq_u32_f32(a.v), vreinterpretq_u32_f32(b.v)))); }
+
+template<> EIGEN_STRONG_INLINE Packet1cf pandnot<Packet1cf>(const Packet1cf& a, const Packet1cf& b)
+{ return Packet1cf(vreinterpret_f32_u32(vbic_u32(vreinterpret_u32_f32(a.v), vreinterpret_u32_f32(b.v)))); }
 template<> EIGEN_STRONG_INLINE Packet2cf pandnot<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
+{ return Packet2cf(vreinterpretq_f32_u32(vbicq_u32(vreinterpretq_u32_f32(a.v), vreinterpretq_u32_f32(b.v)))); }
+
+template<> EIGEN_STRONG_INLINE Packet1cf pload<Packet1cf>(const std::complex<float>* from)
+{ EIGEN_DEBUG_ALIGNED_LOAD return Packet1cf(pload<Packet2f>((const float*)from)); }
+template<> EIGEN_STRONG_INLINE Packet2cf pload<Packet2cf>(const std::complex<float>* from)
+{ EIGEN_DEBUG_ALIGNED_LOAD return Packet2cf(pload<Packet4f>(reinterpret_cast<const float*>(from))); }
+
+template<> EIGEN_STRONG_INLINE Packet1cf ploadu<Packet1cf>(const std::complex<float>* from)
+{ EIGEN_DEBUG_UNALIGNED_LOAD return Packet1cf(ploadu<Packet2f>((const float*)from)); }
+template<> EIGEN_STRONG_INLINE Packet2cf ploadu<Packet2cf>(const std::complex<float>* from)
+{ EIGEN_DEBUG_UNALIGNED_LOAD return Packet2cf(ploadu<Packet4f>(reinterpret_cast<const float*>(from))); }
+
+template<> EIGEN_STRONG_INLINE Packet1cf ploaddup<Packet1cf>(const std::complex<float>* from)
+{ return pset1<Packet1cf>(*from); }
+template<> EIGEN_STRONG_INLINE Packet2cf ploaddup<Packet2cf>(const std::complex<float>* from)
+{ return pset1<Packet2cf>(*from); }
+
+template<> EIGEN_STRONG_INLINE void pstore <std::complex<float> >(std::complex<float> *to, const Packet1cf& from)
+{ EIGEN_DEBUG_ALIGNED_STORE pstore((float*)to, from.v); }
+template<> EIGEN_STRONG_INLINE void pstore <std::complex<float> >(std::complex<float> *to, const Packet2cf& from)
+{ EIGEN_DEBUG_ALIGNED_STORE pstore(reinterpret_cast<float*>(to), from.v); }
+
+template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<float> >(std::complex<float> *to, const Packet1cf& from)
+{ EIGEN_DEBUG_UNALIGNED_STORE pstoreu((float*)to, from.v); }
+template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<float> >(std::complex<float> *to, const Packet2cf& from)
+{ EIGEN_DEBUG_UNALIGNED_STORE pstoreu(reinterpret_cast<float*>(to), from.v); }
+
+template<> EIGEN_DEVICE_FUNC inline Packet1cf pgather<std::complex<float>, Packet1cf>(
+    const std::complex<float>* from, Index stride)
 {
-  return Packet2cf(vreinterpretq_f32_u32(vbicq_u32(vreinterpretq_u32_f32(a.v),vreinterpretq_u32_f32(b.v))));
+  const Packet2f tmp = vdup_n_f32(std::real(from[0*stride]));
+  return Packet1cf(vset_lane_f32(std::imag(from[0*stride]), tmp, 1));
 }
-
-template<> EIGEN_STRONG_INLINE Packet2cf pload<Packet2cf>(const std::complex<float>* from) { EIGEN_DEBUG_ALIGNED_LOAD return Packet2cf(pload<Packet4f>((const float*)from)); }
-template<> EIGEN_STRONG_INLINE Packet2cf ploadu<Packet2cf>(const std::complex<float>* from) { EIGEN_DEBUG_UNALIGNED_LOAD return Packet2cf(ploadu<Packet4f>((const float*)from)); }
-
-template<> EIGEN_STRONG_INLINE Packet2cf ploaddup<Packet2cf>(const std::complex<float>* from) { return pset1<Packet2cf>(*from); }
-
-template<> EIGEN_STRONG_INLINE void pstore <std::complex<float> >(std::complex<float> *   to, const Packet2cf& from) { EIGEN_DEBUG_ALIGNED_STORE pstore((float*)to, from.v); }
-template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<float> >(std::complex<float> *   to, const Packet2cf& from) { EIGEN_DEBUG_UNALIGNED_STORE pstoreu((float*)to, from.v); }
-
-template<> EIGEN_DEVICE_FUNC inline Packet2cf pgather<std::complex<float>, Packet2cf>(const std::complex<float>* from, Index stride)
+template<> EIGEN_DEVICE_FUNC inline Packet2cf pgather<std::complex<float>, Packet2cf>(
+    const std::complex<float>* from, Index stride)
 {
-  Packet4f res = pset1<Packet4f>(0.f);
-  res = vsetq_lane_f32(std::real(from[0*stride]), res, 0);
+  Packet4f res = vdupq_n_f32(std::real(from[0*stride]));
   res = vsetq_lane_f32(std::imag(from[0*stride]), res, 1);
   res = vsetq_lane_f32(std::real(from[1*stride]), res, 2);
   res = vsetq_lane_f32(std::imag(from[1*stride]), res, 3);
   return Packet2cf(res);
 }
 
-template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<float>, Packet2cf>(std::complex<float>* to, const Packet2cf& from, Index stride)
+template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<float>, Packet1cf>(
+    std::complex<float>* to, const Packet1cf& from, Index stride)
+{ to[stride*0] = std::complex<float>(vget_lane_f32(from.v, 0), vget_lane_f32(from.v, 1)); }
+template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<float>, Packet2cf>(
+    std::complex<float>* to, const Packet2cf& from, Index stride)
 {
   to[stride*0] = std::complex<float>(vgetq_lane_f32(from.v, 0), vgetq_lane_f32(from.v, 1));
   to[stride*1] = std::complex<float>(vgetq_lane_f32(from.v, 2), vgetq_lane_f32(from.v, 3));
 }
 
-template<> EIGEN_STRONG_INLINE void prefetch<std::complex<float> >(const std::complex<float> *   addr) { EIGEN_ARM_PREFETCH((const float *)addr); }
+template<> EIGEN_STRONG_INLINE void prefetch<std::complex<float> >(const std::complex<float> *addr)
+{ EIGEN_ARM_PREFETCH(reinterpret_cast<const float*>(addr)); }
 
-template<> EIGEN_STRONG_INLINE std::complex<float>  pfirst<Packet2cf>(const Packet2cf& a)
+template<> EIGEN_STRONG_INLINE std::complex<float> pfirst<Packet1cf>(const Packet1cf& a)
+{
+  EIGEN_ALIGN16 std::complex<float> x;
+  vst1_f32(reinterpret_cast<float*>(&x), a.v);
+  return x;
+}
+template<> EIGEN_STRONG_INLINE std::complex<float> pfirst<Packet2cf>(const Packet2cf& a)
 {
   EIGEN_ALIGN16 std::complex<float> x[2];
-  vst1q_f32((float *)x, a.v);
+  vst1q_f32(reinterpret_cast<float*>(x), a.v);
   return x[0];
 }
 
+template<> EIGEN_STRONG_INLINE Packet1cf preverse(const Packet1cf& a) { return a; }
 template<> EIGEN_STRONG_INLINE Packet2cf preverse(const Packet2cf& a)
-{
-  float32x2_t a_lo, a_hi;
-  Packet4f a_r128;
-
-  a_lo = vget_low_f32(a.v);
-  a_hi = vget_high_f32(a.v);
-  a_r128 = vcombine_f32(a_hi, a_lo);
-
-  return Packet2cf(a_r128);
-}
+{ return Packet2cf(vcombine_f32(vget_high_f32(a.v), vget_low_f32(a.v))); }
 
+template<> EIGEN_STRONG_INLINE Packet1cf pcplxflip<Packet1cf>(const Packet1cf& a)
+{ return Packet1cf(vrev64_f32(a.v)); }
 template<> EIGEN_STRONG_INLINE Packet2cf pcplxflip<Packet2cf>(const Packet2cf& a)
+{ return Packet2cf(vrev64q_f32(a.v)); }
+
+template<> EIGEN_STRONG_INLINE std::complex<float> predux<Packet1cf>(const Packet1cf& a)
 {
-  return Packet2cf(vrev64q_f32(a.v));
+  std::complex<float> s;
+  vst1_f32((float *)&s, a.v);
+  return s;
 }
-
 template<> EIGEN_STRONG_INLINE std::complex<float> predux<Packet2cf>(const Packet2cf& a)
 {
-  float32x2_t a1, a2;
   std::complex<float> s;
-
-  a1 = vget_low_f32(a.v);
-  a2 = vget_high_f32(a.v);
-  a2 = vadd_f32(a1, a2);
-  vst1_f32((float *)&s, a2);
-
+  vst1_f32(reinterpret_cast<float*>(&s), vadd_f32(vget_low_f32(a.v), vget_high_f32(a.v)));
   return s;
 }
 
-template<> EIGEN_STRONG_INLINE Packet2cf preduxp<Packet2cf>(const Packet2cf* vecs)
+template<> EIGEN_STRONG_INLINE std::complex<float> predux_mul<Packet1cf>(const Packet1cf& a)
 {
-  Packet4f sum1, sum2, sum;
-
-  // Add the first two 64-bit float32x2_t of vecs[0]
-  sum1 = vcombine_f32(vget_low_f32(vecs[0].v), vget_low_f32(vecs[1].v));
-  sum2 = vcombine_f32(vget_high_f32(vecs[0].v), vget_high_f32(vecs[1].v));
-  sum = vaddq_f32(sum1, sum2);
-
-  return Packet2cf(sum);
+  std::complex<float> s;
+  vst1_f32((float *)&s, a.v);
+  return s;
 }
-
 template<> EIGEN_STRONG_INLINE std::complex<float> predux_mul<Packet2cf>(const Packet2cf& a)
 {
   float32x2_t a1, a2, v1, v2, prod;
   std::complex<float> s;
 
   a1 = vget_low_f32(a.v);
   a2 = vget_high_f32(a.v);
@@ -216,98 +326,75 @@
   v1 = vdup_lane_f32(a1, 0);
   // Get the real values of a | a1_im | a1_im | a2_im | a2_im |
   v2 = vdup_lane_f32(a1, 1);
   // Multiply the real a with b
   v1 = vmul_f32(v1, a2);
   // Multiply the imag a with b
   v2 = vmul_f32(v2, a2);
-  // Conjugate v2 
+  // Conjugate v2
   v2 = vreinterpret_f32_u32(veor_u32(vreinterpret_u32_f32(v2), p2ui_CONJ_XOR()));
   // Swap real/imag elements in v2.
   v2 = vrev64_f32(v2);
   // Add v1, v2
   prod = vadd_f32(v1, v2);
 
-  vst1_f32((float *)&s, prod);
+  vst1_f32(reinterpret_cast<float*>(&s), prod);
 
   return s;
 }
 
-template<int Offset>
-struct palign_impl<Offset,Packet2cf>
-{
-  EIGEN_STRONG_INLINE static void run(Packet2cf& first, const Packet2cf& second)
-  {
-    if (Offset==1)
-    {
-      first.v = vextq_f32(first.v, second.v, 2);
-    }
-  }
-};
-
-template<> struct conj_helper<Packet2cf, Packet2cf, false,true>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet2cf, Packet2cf, true,false>
-{
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
+EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cf,Packet2f)
+EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf,Packet4f)
 
-template<> struct conj_helper<Packet2cf, Packet2cf, true,true>
+template<> EIGEN_STRONG_INLINE Packet1cf pdiv<Packet1cf>(const Packet1cf& a, const Packet1cf& b)
 {
-  EIGEN_STRONG_INLINE Packet2cf pmadd(const Packet2cf& x, const Packet2cf& y, const Packet2cf& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet2cf pmul(const Packet2cf& a, const Packet2cf& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
+  // TODO optimize it for NEON
+  Packet1cf res = pmul(a, pconj(b));
+  Packet2f s, rev_s;
 
-EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet2cf,Packet4f)
+  // this computes the norm
+  s = vmul_f32(b.v, b.v);
+  rev_s = vrev64_f32(s);
 
+  return Packet1cf(pdiv<Packet2f>(res.v, vadd_f32(s, rev_s)));
+}
 template<> EIGEN_STRONG_INLINE Packet2cf pdiv<Packet2cf>(const Packet2cf& a, const Packet2cf& b)
 {
   // TODO optimize it for NEON
-  Packet2cf res = conj_helper<Packet2cf,Packet2cf,false,true>().pmul(a,b);
+  Packet2cf res = pmul(a,pconj(b));
   Packet4f s, rev_s;
 
   // this computes the norm
   s = vmulq_f32(b.v, b.v);
   rev_s = vrev64q_f32(s);
 
-  return Packet2cf(pdiv<Packet4f>(res.v, vaddq_f32(s,rev_s)));
+  return Packet2cf(pdiv<Packet4f>(res.v, vaddq_f32(s, rev_s)));
 }
 
-EIGEN_DEVICE_FUNC inline void
-ptranspose(PacketBlock<Packet2cf,2>& kernel) {
+EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet1cf, 1>& /*kernel*/) {}
+EIGEN_DEVICE_FUNC inline void ptranspose(PacketBlock<Packet2cf, 2>& kernel)
+{
   Packet4f tmp = vcombine_f32(vget_high_f32(kernel.packet[0].v), vget_high_f32(kernel.packet[1].v));
   kernel.packet[0].v = vcombine_f32(vget_low_f32(kernel.packet[0].v), vget_low_f32(kernel.packet[1].v));
   kernel.packet[1].v = tmp;
 }
 
+template<> EIGEN_STRONG_INLINE Packet1cf psqrt<Packet1cf>(const Packet1cf& a) {
+  return psqrt_complex<Packet1cf>(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet2cf psqrt<Packet2cf>(const Packet2cf& a) {
+  return psqrt_complex<Packet2cf>(a);
+}
+
 //---------- double ----------
 #if EIGEN_ARCH_ARM64 && !EIGEN_APPLE_DOUBLE_NEON_BUG
 
 // See bug 1325, clang fails to call vld1q_u64.
-#if EIGEN_COMP_CLANG
+#if EIGEN_COMP_CLANG || EIGEN_COMP_CASTXML
   static uint64x2_t p2ul_CONJ_XOR = {0x0, 0x8000000000000000};
 #else
   const uint64_t  p2ul_conj_XOR_DATA[] = { 0x0, 0x8000000000000000 };
   static uint64x2_t p2ul_CONJ_XOR = vld1q_u64( p2ul_conj_XOR_DATA );
 #endif
 
 struct Packet1cd
@@ -317,15 +404,16 @@
   Packet2d v;
 };
 
 template<> struct packet_traits<std::complex<double> >  : default_packet_traits
 {
   typedef Packet1cd type;
   typedef Packet1cd half;
-  enum {
+  enum
+  {
     Vectorizable = 1,
     AlignedOnScalar = 0,
     size = 1,
     HasHalfPacket = 0,
 
     HasAdd    = 1,
     HasSub    = 1,
@@ -336,40 +424,66 @@
     HasAbs2   = 0,
     HasMin    = 0,
     HasMax    = 0,
     HasSetLinear = 0
   };
 };
 
-template<> struct unpacket_traits<Packet1cd> { typedef std::complex<double> type; enum {size=1, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet1cd half; };
+template<> struct unpacket_traits<Packet1cd>
+{
+  typedef std::complex<double> type;
+  typedef Packet1cd half;
+  typedef Packet2d as_real;
+  enum
+  {
+    size=1,
+    alignment=Aligned16,
+    vectorizable=true,
+    masked_load_available=false,
+    masked_store_available=false
+  };
+};
 
-template<> EIGEN_STRONG_INLINE Packet1cd pload<Packet1cd>(const std::complex<double>* from) { EIGEN_DEBUG_ALIGNED_LOAD return Packet1cd(pload<Packet2d>((const double*)from)); }
-template<> EIGEN_STRONG_INLINE Packet1cd ploadu<Packet1cd>(const std::complex<double>* from) { EIGEN_DEBUG_UNALIGNED_LOAD return Packet1cd(ploadu<Packet2d>((const double*)from)); }
+template<> EIGEN_STRONG_INLINE Packet1cd pload<Packet1cd>(const std::complex<double>* from)
+{ EIGEN_DEBUG_ALIGNED_LOAD return Packet1cd(pload<Packet2d>(reinterpret_cast<const double*>(from))); }
 
-template<> EIGEN_STRONG_INLINE Packet1cd pset1<Packet1cd>(const std::complex<double>&  from)
-{ /* here we really have to use unaligned loads :( */ return ploadu<Packet1cd>(&from); }
+template<> EIGEN_STRONG_INLINE Packet1cd ploadu<Packet1cd>(const std::complex<double>* from)
+{ EIGEN_DEBUG_UNALIGNED_LOAD return Packet1cd(ploadu<Packet2d>(reinterpret_cast<const double*>(from))); }
 
-template<> EIGEN_STRONG_INLINE Packet1cd padd<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(padd<Packet2d>(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet1cd psub<Packet1cd>(const Packet1cd& a, const Packet1cd& b) { return Packet1cd(psub<Packet2d>(a.v,b.v)); }
-template<> EIGEN_STRONG_INLINE Packet1cd pnegate(const Packet1cd& a) { return Packet1cd(pnegate<Packet2d>(a.v)); }
-template<> EIGEN_STRONG_INLINE Packet1cd pconj(const Packet1cd& a) { return Packet1cd(vreinterpretq_f64_u64(veorq_u64(vreinterpretq_u64_f64(a.v), p2ul_CONJ_XOR))); }
+template<> EIGEN_STRONG_INLINE Packet1cd pset1<Packet1cd>(const std::complex<double>& from)
+{
+  /* here we really have to use unaligned loads :( */
+  return ploadu<Packet1cd>(&from);
+}
+
+template<> EIGEN_STRONG_INLINE Packet1cd padd<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
+{ return Packet1cd(padd<Packet2d>(a.v, b.v)); }
+
+template<> EIGEN_STRONG_INLINE Packet1cd psub<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
+{ return Packet1cd(psub<Packet2d>(a.v, b.v)); }
+
+template<> EIGEN_STRONG_INLINE Packet1cd pnegate(const Packet1cd& a)
+{ return Packet1cd(pnegate<Packet2d>(a.v)); }
+
+template<> EIGEN_STRONG_INLINE Packet1cd pconj(const Packet1cd& a)
+{ return Packet1cd(vreinterpretq_f64_u64(veorq_u64(vreinterpretq_u64_f64(a.v), p2ul_CONJ_XOR))); }
 
 template<> EIGEN_STRONG_INLINE Packet1cd pmul<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
 {
   Packet2d v1, v2;
 
-  // Get the real values of a 
+  // Get the real values of a
   v1 = vdupq_lane_f64(vget_low_f64(a.v), 0);
   // Get the imag values of a
   v2 = vdupq_lane_f64(vget_high_f64(a.v), 0);
   // Multiply the real a with b
   v1 = vmulq_f64(v1, b.v);
   // Multiply the imag a with b
   v2 = vmulq_f64(v2, b.v);
-  // Conjugate v2 
+  // Conjugate v2
   v2 = vreinterpretq_f64_u64(veorq_u64(vreinterpretq_u64_f64(v2), p2ul_CONJ_XOR));
   // Swap real/imag elements in v2.
   v2 = preverse<Packet2d>(v2);
   // Add and return the result
   return Packet1cd(vaddq_f64(v1, v2));
 }
 
@@ -381,134 +495,90 @@
   // Swap real/imag elements in the mask in to get:
   // [im(a)==im(b), re(a)==re(b)]
   Packet2d eq_swapped = vreinterpretq_f64_u32(vrev64q_u32(vreinterpretq_u32_f64(eq)));
   // Return re(a)==re(b) & im(a)==im(b) by computing bitwise AND of eq and eq_swapped
   return Packet1cd(pand<Packet2d>(eq, eq_swapped));
 }
 
-template<> EIGEN_STRONG_INLINE Packet1cd pand   <Packet1cd>(const Packet1cd& a, const Packet1cd& b)
-{
-  return Packet1cd(vreinterpretq_f64_u64(vandq_u64(vreinterpretq_u64_f64(a.v),vreinterpretq_u64_f64(b.v))));
-}
-template<> EIGEN_STRONG_INLINE Packet1cd por    <Packet1cd>(const Packet1cd& a, const Packet1cd& b)
-{
-  return Packet1cd(vreinterpretq_f64_u64(vorrq_u64(vreinterpretq_u64_f64(a.v),vreinterpretq_u64_f64(b.v))));
-}
-template<> EIGEN_STRONG_INLINE Packet1cd pxor   <Packet1cd>(const Packet1cd& a, const Packet1cd& b)
-{
-  return Packet1cd(vreinterpretq_f64_u64(veorq_u64(vreinterpretq_u64_f64(a.v),vreinterpretq_u64_f64(b.v))));
-}
+template<> EIGEN_STRONG_INLINE Packet1cd pand<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
+{ return Packet1cd(vreinterpretq_f64_u64(vandq_u64(vreinterpretq_u64_f64(a.v),vreinterpretq_u64_f64(b.v)))); }
+
+template<> EIGEN_STRONG_INLINE Packet1cd por<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
+{ return Packet1cd(vreinterpretq_f64_u64(vorrq_u64(vreinterpretq_u64_f64(a.v),vreinterpretq_u64_f64(b.v)))); }
+
+template<> EIGEN_STRONG_INLINE Packet1cd pxor<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
+{ return Packet1cd(vreinterpretq_f64_u64(veorq_u64(vreinterpretq_u64_f64(a.v),vreinterpretq_u64_f64(b.v)))); }
+
 template<> EIGEN_STRONG_INLINE Packet1cd pandnot<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
-{
-  return Packet1cd(vreinterpretq_f64_u64(vbicq_u64(vreinterpretq_u64_f64(a.v),vreinterpretq_u64_f64(b.v))));
-}
+{ return Packet1cd(vreinterpretq_f64_u64(vbicq_u64(vreinterpretq_u64_f64(a.v),vreinterpretq_u64_f64(b.v)))); }
 
-template<> EIGEN_STRONG_INLINE Packet1cd ploaddup<Packet1cd>(const std::complex<double>* from) { return pset1<Packet1cd>(*from); }
+template<> EIGEN_STRONG_INLINE Packet1cd ploaddup<Packet1cd>(const std::complex<double>* from)
+{ return pset1<Packet1cd>(*from); }
 
-template<> EIGEN_STRONG_INLINE void pstore <std::complex<double> >(std::complex<double> *   to, const Packet1cd& from) { EIGEN_DEBUG_ALIGNED_STORE pstore((double*)to, from.v); }
-template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<double> >(std::complex<double> *   to, const Packet1cd& from) { EIGEN_DEBUG_UNALIGNED_STORE pstoreu((double*)to, from.v); }
+template<> EIGEN_STRONG_INLINE void pstore <std::complex<double> >(std::complex<double> *to, const Packet1cd& from)
+{ EIGEN_DEBUG_ALIGNED_STORE pstore(reinterpret_cast<double*>(to), from.v); }
 
-template<> EIGEN_STRONG_INLINE void prefetch<std::complex<double> >(const std::complex<double> *   addr) { EIGEN_ARM_PREFETCH((const double *)addr); }
+template<> EIGEN_STRONG_INLINE void pstoreu<std::complex<double> >(std::complex<double> *to, const Packet1cd& from)
+{ EIGEN_DEBUG_UNALIGNED_STORE pstoreu(reinterpret_cast<double*>(to), from.v); }
 
-template<> EIGEN_DEVICE_FUNC inline Packet1cd pgather<std::complex<double>, Packet1cd>(const std::complex<double>* from, Index stride)
+template<> EIGEN_STRONG_INLINE void prefetch<std::complex<double> >(const std::complex<double> *addr)
+{ EIGEN_ARM_PREFETCH(reinterpret_cast<const double*>(addr)); }
+
+template<> EIGEN_DEVICE_FUNC inline Packet1cd pgather<std::complex<double>, Packet1cd>(
+    const std::complex<double>* from, Index stride)
 {
   Packet2d res = pset1<Packet2d>(0.0);
   res = vsetq_lane_f64(std::real(from[0*stride]), res, 0);
   res = vsetq_lane_f64(std::imag(from[0*stride]), res, 1);
   return Packet1cd(res);
 }
 
-template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<double>, Packet1cd>(std::complex<double>* to, const Packet1cd& from, Index stride)
-{
-  to[stride*0] = std::complex<double>(vgetq_lane_f64(from.v, 0), vgetq_lane_f64(from.v, 1));
-}
-
+template<> EIGEN_DEVICE_FUNC inline void pscatter<std::complex<double>, Packet1cd>(
+    std::complex<double>* to, const Packet1cd& from, Index stride)
+{ to[stride*0] = std::complex<double>(vgetq_lane_f64(from.v, 0), vgetq_lane_f64(from.v, 1)); }
 
-template<> EIGEN_STRONG_INLINE std::complex<double>  pfirst<Packet1cd>(const Packet1cd& a)
+template<> EIGEN_STRONG_INLINE std::complex<double> pfirst<Packet1cd>(const Packet1cd& a)
 {
   EIGEN_ALIGN16 std::complex<double> res;
   pstore<std::complex<double> >(&res, a);
-
   return res;
 }
 
 template<> EIGEN_STRONG_INLINE Packet1cd preverse(const Packet1cd& a) { return a; }
 
 template<> EIGEN_STRONG_INLINE std::complex<double> predux<Packet1cd>(const Packet1cd& a) { return pfirst(a); }
 
-template<> EIGEN_STRONG_INLINE Packet1cd preduxp<Packet1cd>(const Packet1cd* vecs) { return vecs[0]; }
-
 template<> EIGEN_STRONG_INLINE std::complex<double> predux_mul<Packet1cd>(const Packet1cd& a) { return pfirst(a); }
 
-template<int Offset>
-struct palign_impl<Offset,Packet1cd>
-{
-  static EIGEN_STRONG_INLINE void run(Packet1cd& /*first*/, const Packet1cd& /*second*/)
-  {
-    // FIXME is it sure we never have to align a Packet1cd?
-    // Even though a std::complex<double> has 16 bytes, it is not necessarily aligned on a 16 bytes boundary...
-  }
-};
-
-template<> struct conj_helper<Packet1cd, Packet1cd, false,true>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return internal::pmul(a, pconj(b));
-  }
-};
-
-template<> struct conj_helper<Packet1cd, Packet1cd, true,false>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return internal::pmul(pconj(a), b);
-  }
-};
-
-template<> struct conj_helper<Packet1cd, Packet1cd, true,true>
-{
-  EIGEN_STRONG_INLINE Packet1cd pmadd(const Packet1cd& x, const Packet1cd& y, const Packet1cd& c) const
-  { return padd(pmul(x,y),c); }
-
-  EIGEN_STRONG_INLINE Packet1cd pmul(const Packet1cd& a, const Packet1cd& b) const
-  {
-    return pconj(internal::pmul(a, b));
-  }
-};
-
 EIGEN_MAKE_CONJ_HELPER_CPLX_REAL(Packet1cd,Packet2d)
 
 template<> EIGEN_STRONG_INLINE Packet1cd pdiv<Packet1cd>(const Packet1cd& a, const Packet1cd& b)
 {
   // TODO optimize it for NEON
-  Packet1cd res = conj_helper<Packet1cd,Packet1cd,false,true>().pmul(a,b);
+  Packet1cd res = pmul(a,pconj(b));
   Packet2d s = pmul<Packet2d>(b.v, b.v);
   Packet2d rev_s = preverse<Packet2d>(s);
 
   return Packet1cd(pdiv(res.v, padd<Packet2d>(s,rev_s)));
 }
 
 EIGEN_STRONG_INLINE Packet1cd pcplxflip/*<Packet1cd>*/(const Packet1cd& x)
-{
-  return Packet1cd(preverse(Packet2d(x.v)));
-}
+{ return Packet1cd(preverse(Packet2d(x.v))); }
 
 EIGEN_STRONG_INLINE void ptranspose(PacketBlock<Packet1cd,2>& kernel)
 {
   Packet2d tmp = vcombine_f64(vget_high_f64(kernel.packet[0].v), vget_high_f64(kernel.packet[1].v));
   kernel.packet[0].v = vcombine_f64(vget_low_f64(kernel.packet[0].v), vget_low_f64(kernel.packet[1].v));
   kernel.packet[1].v = tmp;
 }
+
+template<> EIGEN_STRONG_INLINE Packet1cd psqrt<Packet1cd>(const Packet1cd& a) {
+  return psqrt_complex<Packet1cd>(a);
+}
+
 #endif // EIGEN_ARCH_ARM64
 
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_COMPLEX_NEON_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/NEON/TypeCasting.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/AVX512/TypeCasting.h`

 * *Files 26% similar despite different names*

```diff
@@ -1,56 +1,89 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
-// Copyright (C) 2018 Rasmus Munk Larsen <rmlarsen@google.com>
+// Copyright (C) 2019 Rasmus Munk Larsen <rmlarsen@google.com>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
-#ifndef EIGEN_TYPE_CASTING_NEON_H
-#define EIGEN_TYPE_CASTING_NEON_H
+#ifndef EIGEN_TYPE_CASTING_AVX512_H
+#define EIGEN_TYPE_CASTING_AVX512_H
 
 namespace Eigen {
 
 namespace internal {
 
+template<> EIGEN_STRONG_INLINE Packet16i pcast<Packet16f, Packet16i>(const Packet16f& a) {
+  return _mm512_cvttps_epi32(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16f pcast<Packet16i, Packet16f>(const Packet16i& a) {
+  return _mm512_cvtepi32_ps(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16i preinterpret<Packet16i, Packet16f>(const Packet16f& a) {
+  return _mm512_castps_si512(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet16f preinterpret<Packet16f, Packet16i>(const Packet16i& a) {
+  return _mm512_castsi512_ps(a);
+}
+
 template <>
-struct type_casting_traits<float, int> {
+struct type_casting_traits<half, float> {
   enum {
     VectorizedCast = 1,
     SrcCoeffRatio = 1,
     TgtCoeffRatio = 1
   };
 };
 
+template<> EIGEN_STRONG_INLINE Packet16f pcast<Packet16h, Packet16f>(const Packet16h& a) {
+  return half2float(a);
+}
+
 template <>
-struct type_casting_traits<int, float> {
+struct type_casting_traits<float, half> {
   enum {
     VectorizedCast = 1,
     SrcCoeffRatio = 1,
     TgtCoeffRatio = 1
   };
 };
 
-
-template<> EIGEN_STRONG_INLINE Packet4i pcast<Packet4f, Packet4i>(const Packet4f& a) {
-  return vcvtq_s32_f32(a);
+template<> EIGEN_STRONG_INLINE Packet16h pcast<Packet16f, Packet16h>(const Packet16f& a) {
+  return float2half(a);
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f pcast<Packet4i, Packet4f>(const Packet4i& a) {
-  return vcvtq_f32_s32(a);
-}
+template <>
+struct type_casting_traits<bfloat16, float> {
+  enum {
+    VectorizedCast = 1,
+    SrcCoeffRatio = 1,
+    TgtCoeffRatio = 1
+  };
+};
 
-template<> EIGEN_STRONG_INLINE Packet4i preinterpret<Packet4i,Packet4f>(const Packet4f& a) {
-  return vreinterpretq_s32_f32(a);
+template<> EIGEN_STRONG_INLINE Packet16f pcast<Packet16bf, Packet16f>(const Packet16bf& a) {
+  return Bf16ToF32(a);
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f preinterpret<Packet4f,Packet4i>(const Packet4i& a) {
-  return vreinterpretq_f32_s32(a);
+template <>
+struct type_casting_traits<float, bfloat16> {
+  enum {
+    VectorizedCast = 1,
+    SrcCoeffRatio = 1,
+    TgtCoeffRatio = 1
+  };
+};
+
+template<> EIGEN_STRONG_INLINE Packet16bf pcast<Packet16f, Packet16bf>(const Packet16f& a) {
+  return F32ToBf16(a);
 }
 
 } // end namespace internal
 
 } // end namespace Eigen
 
-#endif // EIGEN_TYPE_CASTING_NEON_H
+#endif // EIGEN_TYPE_CASTING_AVX512_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SSE/PacketMath.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SSE/PacketMath.h`

 * *Files 21% similar despite different names*

```diff
@@ -22,67 +22,93 @@
 // 32 bits =>  8 registers
 // 64 bits => 16 registers
 #define EIGEN_ARCH_DEFAULT_NUMBER_OF_REGISTERS (2*sizeof(void*))
 #endif
 
 #ifdef EIGEN_VECTORIZE_FMA
 #ifndef EIGEN_HAS_SINGLE_INSTRUCTION_MADD
-#define EIGEN_HAS_SINGLE_INSTRUCTION_MADD 1
+#define EIGEN_HAS_SINGLE_INSTRUCTION_MADD
 #endif
 #endif
 
 #if ((defined EIGEN_VECTORIZE_AVX) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_MINGW) && (__GXX_ABI_VERSION < 1004)) || EIGEN_OS_QNX
 // With GCC's default ABI version, a __m128 or __m256 are the same types and therefore we cannot
 // have overloads for both types without linking error.
 // One solution is to increase ABI version using -fabi-version=4 (or greater).
 // Otherwise, we workaround this inconvenience by wrapping 128bit types into the following helper
 // structure:
-template<typename T>
-struct eigen_packet_wrapper
-{
-  EIGEN_ALWAYS_INLINE operator T&() { return m_val; }
-  EIGEN_ALWAYS_INLINE operator const T&() const { return m_val; }
-  EIGEN_ALWAYS_INLINE eigen_packet_wrapper() {}
-  EIGEN_ALWAYS_INLINE eigen_packet_wrapper(const T &v) : m_val(v) {}
-  EIGEN_ALWAYS_INLINE eigen_packet_wrapper& operator=(const T &v) {
-    m_val = v;
-    return *this;
-  }
-
-  T m_val;
-};
 typedef eigen_packet_wrapper<__m128>  Packet4f;
-typedef eigen_packet_wrapper<__m128i> Packet4i;
 typedef eigen_packet_wrapper<__m128d> Packet2d;
 #else
 typedef __m128  Packet4f;
-typedef __m128i Packet4i;
 typedef __m128d Packet2d;
 #endif
 
+typedef eigen_packet_wrapper<__m128i, 0> Packet4i;
+typedef eigen_packet_wrapper<__m128i, 1> Packet16b;
+
 template<> struct is_arithmetic<__m128>  { enum { value = true }; };
 template<> struct is_arithmetic<__m128i> { enum { value = true }; };
 template<> struct is_arithmetic<__m128d> { enum { value = true }; };
+template<> struct is_arithmetic<Packet4i>  { enum { value = true }; };
+template<> struct is_arithmetic<Packet16b>  { enum { value = true }; };
 
-#define EIGEN_SSE_SHUFFLE_MASK(p,q,r,s) ((s)<<6|(r)<<4|(q)<<2|(p))
+template<int p, int q, int r, int s>
+struct shuffle_mask{
+ enum { mask = (s)<<6|(r)<<4|(q)<<2|(p) };
+};
 
+// TODO: change the implementation of all swizzle* ops from macro to template,
 #define vec4f_swizzle1(v,p,q,r,s) \
-  (_mm_castsi128_ps(_mm_shuffle_epi32( _mm_castps_si128(v), EIGEN_SSE_SHUFFLE_MASK(p,q,r,s))))
+  Packet4f(_mm_castsi128_ps(_mm_shuffle_epi32( _mm_castps_si128(v), (shuffle_mask<p,q,r,s>::mask))))
 
 #define vec4i_swizzle1(v,p,q,r,s) \
-  (_mm_shuffle_epi32( v, EIGEN_SSE_SHUFFLE_MASK(p,q,r,s)))
+  Packet4i(_mm_shuffle_epi32( v, (shuffle_mask<p,q,r,s>::mask)))
 
 #define vec2d_swizzle1(v,p,q) \
-  (_mm_castsi128_pd(_mm_shuffle_epi32( _mm_castpd_si128(v), EIGEN_SSE_SHUFFLE_MASK(2*p,2*p+1,2*q,2*q+1))))
+  Packet2d(_mm_castsi128_pd(_mm_shuffle_epi32( _mm_castpd_si128(v), (shuffle_mask<2*p,2*p+1,2*q,2*q+1>::mask))))
 
 #define vec4f_swizzle2(a,b,p,q,r,s) \
-  (_mm_shuffle_ps( (a), (b), EIGEN_SSE_SHUFFLE_MASK(p,q,r,s)))
+  Packet4f(_mm_shuffle_ps( (a), (b), (shuffle_mask<p,q,r,s>::mask)))
 
 #define vec4i_swizzle2(a,b,p,q,r,s) \
-  (_mm_castps_si128( (_mm_shuffle_ps( _mm_castsi128_ps(a), _mm_castsi128_ps(b), EIGEN_SSE_SHUFFLE_MASK(p,q,r,s)))))
+  Packet4i(_mm_castps_si128( (_mm_shuffle_ps( _mm_castsi128_ps(a), _mm_castsi128_ps(b), (shuffle_mask<p,q,r,s>::mask)))))
+
+EIGEN_STRONG_INLINE Packet4f vec4f_movelh(const Packet4f& a, const Packet4f& b)
+{
+  return Packet4f(_mm_movelh_ps(a,b));
+}
+EIGEN_STRONG_INLINE Packet4f vec4f_movehl(const Packet4f& a, const Packet4f& b)
+{
+  return Packet4f(_mm_movehl_ps(a,b));
+}
+EIGEN_STRONG_INLINE Packet4f vec4f_unpacklo(const Packet4f& a, const Packet4f& b)
+{
+  return Packet4f(_mm_unpacklo_ps(a,b));
+}
+EIGEN_STRONG_INLINE Packet4f vec4f_unpackhi(const Packet4f& a, const Packet4f& b)
+{
+  return Packet4f(_mm_unpackhi_ps(a,b));
+}
+#define vec4f_duplane(a,p) \
+  vec4f_swizzle2(a,a,p,p,p,p)
+
+#define vec2d_swizzle2(a,b,mask) \
+  Packet2d(_mm_shuffle_pd(a,b,mask))
+
+EIGEN_STRONG_INLINE Packet2d vec2d_unpacklo(const Packet2d& a, const Packet2d& b)
+{
+  return Packet2d(_mm_unpacklo_pd(a,b));
+}
+EIGEN_STRONG_INLINE Packet2d vec2d_unpackhi(const Packet2d& a, const Packet2d& b)
+{
+  return Packet2d(_mm_unpackhi_pd(a,b));
+}
+#define vec2d_duplane(a,p) \
+  vec2d_swizzle2(a,a,(p<<1)|p)
 
 #define _EIGEN_DECLARE_CONST_Packet4f(NAME,X) \
   const Packet4f p4f_##NAME = pset1<Packet4f>(X)
 
 #define _EIGEN_DECLARE_CONST_Packet2d(NAME,X) \
   const Packet2d p2d_##NAME = pset1<Packet2d>(X)
 
@@ -92,80 +118,111 @@
 #define _EIGEN_DECLARE_CONST_Packet4i(NAME,X) \
   const Packet4i p4i_##NAME = pset1<Packet4i>(X)
 
 
 // Use the packet_traits defined in AVX/PacketMath.h instead if we're going
 // to leverage AVX instructions.
 #ifndef EIGEN_VECTORIZE_AVX
-template<> struct packet_traits<float>  : default_packet_traits
-{
+template <>
+struct packet_traits<float> : default_packet_traits {
   typedef Packet4f type;
   typedef Packet4f half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
-    size=4,
+    size = 4,
     HasHalfPacket = 0,
 
-    HasDiv  = 1,
-    HasSin  = EIGEN_FAST_MATH,
-    HasCos  = EIGEN_FAST_MATH,
-    HasLog  = 1,
-    HasExp  = 1,
+    HasCmp  = 1,
+    HasDiv = 1,
+    HasSin = EIGEN_FAST_MATH,
+    HasCos = EIGEN_FAST_MATH,
+    HasLog = 1,
+    HasLog1p = 1,
+    HasExpm1 = 1,
+    HasNdtri = 1,
+    HasExp = 1,
+    HasBessel = 1,
     HasSqrt = 1,
     HasRsqrt = 1,
-    HasTanh  = EIGEN_FAST_MATH,
+    HasTanh = EIGEN_FAST_MATH,
+    HasErf = EIGEN_FAST_MATH,
     HasBlend = 1,
-    HasFloor = 1
-
+    HasCeil = 1,
+    HasFloor = 1,
 #ifdef EIGEN_VECTORIZE_SSE4_1
-    ,
     HasRound = 1,
-    HasCeil = 1
 #endif
+    HasRint = 1
   };
 };
-template<> struct packet_traits<double> : default_packet_traits
-{
+template <>
+struct packet_traits<double> : default_packet_traits {
   typedef Packet2d type;
   typedef Packet2d half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size=2,
     HasHalfPacket = 0,
 
+    HasCmp  = 1,
     HasDiv  = 1,
+    HasLog  = 1,
     HasExp  = 1,
     HasSqrt = 1,
     HasRsqrt = 1,
-    HasBlend = 1
-
+    HasBlend = 1,
+    HasFloor = 1,
+    HasCeil = 1,
 #ifdef EIGEN_VECTORIZE_SSE4_1
-    ,
     HasRound = 1,
-    HasFloor = 1,
-    HasCeil = 1
 #endif
+    HasRint = 1
   };
 };
 #endif
 template<> struct packet_traits<int>    : default_packet_traits
 {
   typedef Packet4i type;
   typedef Packet4i half;
   enum {
     Vectorizable = 1,
     AlignedOnScalar = 1,
     size=4,
 
+    HasShift = 1,
     HasBlend = 1
   };
 };
 
+template<> struct packet_traits<bool> : default_packet_traits
+{
+  typedef Packet16b type;
+  typedef Packet16b half;
+  enum {
+    Vectorizable = 1,
+    AlignedOnScalar = 1,
+    HasHalfPacket = 0,
+    size=16,
+
+    HasAdd       = 1,
+    HasSub       = 1,
+    HasShift     = 0,
+    HasMul       = 1,
+    HasNegate    = 1,
+    HasAbs       = 0,
+    HasAbs2      = 0,
+    HasMin       = 0,
+    HasMax       = 0,
+    HasConj      = 0,
+    HasSqrt      = 1
+  };
+};
+
 template<> struct unpacket_traits<Packet4f> {
   typedef float     type;
   typedef Packet4f  half;
   typedef Packet4i  integer_packet;
   enum {size=4, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false};
 };
 template<> struct unpacket_traits<Packet2d> {
@@ -174,14 +231,19 @@
   enum {size=2, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false};
 };
 template<> struct unpacket_traits<Packet4i> {
   typedef int       type;
   typedef Packet4i  half;
   enum {size=4, alignment=Aligned16, vectorizable=false, masked_load_available=false, masked_store_available=false};
 };
+template<> struct unpacket_traits<Packet16b> {
+  typedef bool       type;
+  typedef Packet16b  half;
+  enum {size=16, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false};
+};
 
 #ifndef EIGEN_VECTORIZE_AVX
 template<> struct scalar_div_cost<float,true> { enum { value = 7 }; };
 template<> struct scalar_div_cost<double,true> { enum { value = 8 }; };
 #endif
 
 #if EIGEN_COMP_MSVC==1500
@@ -192,16 +254,22 @@
 template<> EIGEN_STRONG_INLINE Packet2d pset1<Packet2d>(const double& from) { return _mm_set_pd(from,from); }
 template<> EIGEN_STRONG_INLINE Packet4i pset1<Packet4i>(const int&    from) { return _mm_set_epi32(from,from,from,from); }
 #else
 template<> EIGEN_STRONG_INLINE Packet4f pset1<Packet4f>(const float&  from) { return _mm_set_ps1(from); }
 template<> EIGEN_STRONG_INLINE Packet2d pset1<Packet2d>(const double& from) { return _mm_set1_pd(from); }
 template<> EIGEN_STRONG_INLINE Packet4i pset1<Packet4i>(const int&    from) { return _mm_set1_epi32(from); }
 #endif
+template<> EIGEN_STRONG_INLINE Packet16b pset1<Packet16b>(const bool&    from) { return _mm_set1_epi8(static_cast<char>(from)); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pset1frombits<Packet4f>(unsigned int from) { return _mm_castsi128_ps(pset1<Packet4i>(from)); }
+template<> EIGEN_STRONG_INLINE Packet2d pset1frombits<Packet2d>(uint64_t from) { return _mm_castsi128_pd(_mm_set1_epi64x(from)); }
+
+template<> EIGEN_STRONG_INLINE Packet4f peven_mask(const Packet4f& /*a*/) { return _mm_castsi128_ps(_mm_set_epi32(0, -1, 0, -1)); }
+template<> EIGEN_STRONG_INLINE Packet4i peven_mask(const Packet4i& /*a*/) { return _mm_set_epi32(0, -1, 0, -1); }
+template<> EIGEN_STRONG_INLINE Packet2d peven_mask(const Packet2d& /*a*/) { return _mm_castsi128_pd(_mm_set_epi32(0, 0, -1, -1)); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pzero(const Packet4f& /*a*/) { return _mm_setzero_ps(); }
 template<> EIGEN_STRONG_INLINE Packet2d pzero(const Packet2d& /*a*/) { return _mm_setzero_pd(); }
 template<> EIGEN_STRONG_INLINE Packet4i pzero(const Packet4i& /*a*/) { return _mm_setzero_si128(); }
 
 // GCC generates a shufps instruction for _mm_set1_ps/_mm_load1_ps instead of the more efficient pshufd instruction.
 // However, using inrinsics for pset1 makes gcc to generate crappy code in some cases (see bug 203)
@@ -218,17 +286,42 @@
 template<> EIGEN_STRONG_INLINE Packet2d plset<Packet2d>(const double& a) { return _mm_add_pd(pset1<Packet2d>(a),_mm_set_pd(1,0)); }
 template<> EIGEN_STRONG_INLINE Packet4i plset<Packet4i>(const int& a) { return _mm_add_epi32(pset1<Packet4i>(a),_mm_set_epi32(3,2,1,0)); }
 
 template<> EIGEN_STRONG_INLINE Packet4f padd<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_add_ps(a,b); }
 template<> EIGEN_STRONG_INLINE Packet2d padd<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_add_pd(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4i padd<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_add_epi32(a,b); }
 
+template<> EIGEN_STRONG_INLINE Packet16b padd<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_or_si128(a,b); }
+
 template<> EIGEN_STRONG_INLINE Packet4f psub<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_sub_ps(a,b); }
 template<> EIGEN_STRONG_INLINE Packet2d psub<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_sub_pd(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4i psub<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_sub_epi32(a,b); }
+template<> EIGEN_STRONG_INLINE Packet16b psub<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_xor_si128(a,b); }
+
+template<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b);
+template<> EIGEN_STRONG_INLINE Packet4f paddsub<Packet4f>(const Packet4f& a, const Packet4f& b)
+{
+#ifdef EIGEN_VECTORIZE_SSE3
+  return _mm_addsub_ps(a,b);
+#else
+  const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x80000000,0x0,0x80000000,0x0));
+  return padd(a, pxor(mask, b));
+#endif
+}
+
+template<> EIGEN_STRONG_INLINE Packet2d pxor<Packet2d>(const Packet2d& , const Packet2d& );
+template<> EIGEN_STRONG_INLINE Packet2d paddsub<Packet2d>(const Packet2d& a, const Packet2d& b) 
+{
+#ifdef EIGEN_VECTORIZE_SSE3  
+  return _mm_addsub_pd(a,b); 
+#else
+  const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0x0,0x80000000,0x0,0x0)); 
+  return padd(a, pxor(mask, b));
+#endif
+}
 
 template<> EIGEN_STRONG_INLINE Packet4f pnegate(const Packet4f& a)
 {
   const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x80000000,0x80000000,0x80000000,0x80000000));
   return _mm_xor_ps(a,mask);
 }
 template<> EIGEN_STRONG_INLINE Packet2d pnegate(const Packet2d& a)
@@ -237,14 +330,19 @@
   return _mm_xor_pd(a,mask);
 }
 template<> EIGEN_STRONG_INLINE Packet4i pnegate(const Packet4i& a)
 {
   return psub(Packet4i(_mm_setr_epi32(0,0,0,0)), a);
 }
 
+template<> EIGEN_STRONG_INLINE Packet16b pnegate(const Packet16b& a)
+{
+  return psub(pset1<Packet16b>(false), a);
+}
+
 template<> EIGEN_STRONG_INLINE Packet4f pconj(const Packet4f& a) { return a; }
 template<> EIGEN_STRONG_INLINE Packet2d pconj(const Packet2d& a) { return a; }
 template<> EIGEN_STRONG_INLINE Packet4i pconj(const Packet4i& a) { return a; }
 
 template<> EIGEN_STRONG_INLINE Packet4f pmul<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_mul_ps(a,b); }
 template<> EIGEN_STRONG_INLINE Packet2d pmul<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_mul_pd(a,b); }
 template<> EIGEN_STRONG_INLINE Packet4i pmul<Packet4i>(const Packet4i& a, const Packet4i& b)
@@ -259,30 +357,96 @@
               _mm_mul_epu32(vec4i_swizzle1(a,1,0,3,2),
                             vec4i_swizzle1(b,1,0,3,2)),
               0,2,0,2),
             0,2,1,3);
 #endif
 }
 
+template<> EIGEN_STRONG_INLINE Packet16b pmul<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_and_si128(a,b); }
+
 template<> EIGEN_STRONG_INLINE Packet4f pdiv<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_div_ps(a,b); }
 template<> EIGEN_STRONG_INLINE Packet2d pdiv<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_div_pd(a,b); }
 
 // for some weird raisons, it has to be overloaded for packet of integers
 template<> EIGEN_STRONG_INLINE Packet4i pmadd(const Packet4i& a, const Packet4i& b, const Packet4i& c) { return padd(pmul(a,b), c); }
 #ifdef EIGEN_VECTORIZE_FMA
 template<> EIGEN_STRONG_INLINE Packet4f pmadd(const Packet4f& a, const Packet4f& b, const Packet4f& c) { return _mm_fmadd_ps(a,b,c); }
 template<> EIGEN_STRONG_INLINE Packet2d pmadd(const Packet2d& a, const Packet2d& b, const Packet2d& c) { return _mm_fmadd_pd(a,b,c); }
 #endif
 
 #ifdef EIGEN_VECTORIZE_SSE4_1
-template<> EIGEN_DEVICE_FUNC inline Packet4f pselect(const Packet4f& mask, const Packet4f& a, const Packet4f& b) {  return _mm_blendv_ps(b,a,mask); }
+template<> EIGEN_DEVICE_FUNC inline Packet4f pselect(const Packet4f& mask, const Packet4f& a, const Packet4f& b) {
+  return _mm_blendv_ps(b,a,mask);
+}
+
+template<> EIGEN_DEVICE_FUNC inline Packet4i pselect(const Packet4i& mask, const Packet4i& a, const Packet4i& b) {
+  return _mm_castps_si128(_mm_blendv_ps(_mm_castsi128_ps(b),_mm_castsi128_ps(a),_mm_castsi128_ps(mask)));
+}
 
 template<> EIGEN_DEVICE_FUNC inline Packet2d pselect(const Packet2d& mask, const Packet2d& a, const Packet2d& b) {  return _mm_blendv_pd(b,a,mask); }
+
+template<> EIGEN_DEVICE_FUNC inline Packet16b pselect(const Packet16b& mask, const Packet16b& a, const Packet16b& b) {
+  return _mm_blendv_epi8(b,a,mask);
+}
+#else
+template<> EIGEN_DEVICE_FUNC inline Packet16b pselect(const Packet16b& mask, const Packet16b& a, const Packet16b& b) {
+  Packet16b a_part = _mm_and_si128(mask, a);
+  Packet16b b_part = _mm_andnot_si128(mask, b);
+  return _mm_or_si128(a_part, b_part);
+}
 #endif
 
+template<> EIGEN_STRONG_INLINE Packet4i ptrue<Packet4i>(const Packet4i& a) { return _mm_cmpeq_epi32(a, a); }
+template<> EIGEN_STRONG_INLINE Packet16b ptrue<Packet16b>(const Packet16b& a) { return _mm_cmpeq_epi8(a, a); }
+template<> EIGEN_STRONG_INLINE Packet4f
+ptrue<Packet4f>(const Packet4f& a) {
+  Packet4i b = _mm_castps_si128(a);
+  return _mm_castsi128_ps(_mm_cmpeq_epi32(b, b));
+}
+template<> EIGEN_STRONG_INLINE Packet2d
+ptrue<Packet2d>(const Packet2d& a) {
+  Packet4i b = _mm_castpd_si128(a);
+  return _mm_castsi128_pd(_mm_cmpeq_epi32(b, b));
+}
+
+
+template<> EIGEN_STRONG_INLINE Packet4f pand<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_and_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d pand<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_and_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4i pand<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_and_si128(a,b); }
+template<> EIGEN_STRONG_INLINE Packet16b pand<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_and_si128(a,b); }
+
+template<> EIGEN_STRONG_INLINE Packet4f por<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_or_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d por<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_or_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4i por<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_or_si128(a,b); }
+template<> EIGEN_STRONG_INLINE Packet16b por<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_or_si128(a,b); }
+
+template<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_xor_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d pxor<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_xor_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4i pxor<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_xor_si128(a,b); }
+template<> EIGEN_STRONG_INLINE Packet16b pxor<Packet16b>(const Packet16b& a, const Packet16b& b) { return _mm_xor_si128(a,b); }
+
+template<> EIGEN_STRONG_INLINE Packet4f pandnot<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_andnot_ps(b,a); }
+template<> EIGEN_STRONG_INLINE Packet2d pandnot<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_andnot_pd(b,a); }
+template<> EIGEN_STRONG_INLINE Packet4i pandnot<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_andnot_si128(b,a); }
+
+template<> EIGEN_STRONG_INLINE Packet4f pcmp_le(const Packet4f& a, const Packet4f& b) { return _mm_cmple_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4f pcmp_lt(const Packet4f& a, const Packet4f& b) { return _mm_cmplt_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4f pcmp_lt_or_nan(const Packet4f& a, const Packet4f& b) { return _mm_cmpnge_ps(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4f pcmp_eq(const Packet4f& a, const Packet4f& b) { return _mm_cmpeq_ps(a,b); }
+
+template<> EIGEN_STRONG_INLINE Packet2d pcmp_le(const Packet2d& a, const Packet2d& b) { return _mm_cmple_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d pcmp_lt(const Packet2d& a, const Packet2d& b) { return _mm_cmplt_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d pcmp_lt_or_nan(const Packet2d& a, const Packet2d& b) { return _mm_cmpnge_pd(a,b); }
+template<> EIGEN_STRONG_INLINE Packet2d pcmp_eq(const Packet2d& a, const Packet2d& b) { return _mm_cmpeq_pd(a,b); }
+
+template<> EIGEN_STRONG_INLINE Packet4i pcmp_lt(const Packet4i& a, const Packet4i& b) { return _mm_cmplt_epi32(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4i pcmp_eq(const Packet4i& a, const Packet4i& b) { return _mm_cmpeq_epi32(a,b); }
+template<> EIGEN_STRONG_INLINE Packet16b pcmp_eq(const Packet16b& a, const Packet16b& b) { return _mm_cmpeq_epi8(a,b); }
+template<> EIGEN_STRONG_INLINE Packet4i pcmp_le(const Packet4i& a, const Packet4i& b) { return por(pcmp_lt(a,b), pcmp_eq(a,b)); }
+
 template<> EIGEN_STRONG_INLINE Packet4f pmin<Packet4f>(const Packet4f& a, const Packet4f& b) {
 #if EIGEN_COMP_GNUC && EIGEN_COMP_GNUC < 63
   // There appears to be a bug in GCC, by which the optimizer may
   // flip the argument order in calls to _mm_min_ps, so we have to
   // resort to inline ASM here. This is supposed to be fixed in gcc6.3,
   // see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867
   #ifdef EIGEN_VECTORIZE_AVX
@@ -324,14 +488,15 @@
 #else
   // after some bench, this version *is* faster than a scalar implementation
   Packet4i mask = _mm_cmplt_epi32(a,b);
   return _mm_or_si128(_mm_and_si128(mask,a),_mm_andnot_si128(mask,b));
 #endif
 }
 
+
 template<> EIGEN_STRONG_INLINE Packet4f pmax<Packet4f>(const Packet4f& a, const Packet4f& b) {
 #if EIGEN_COMP_GNUC && EIGEN_COMP_GNUC < 63
   // There appears to be a bug in GCC, by which the optimizer may
   // flip the argument order in calls to _mm_max_ps, so we have to
   // resort to inline ASM here. This is supposed to be fixed in gcc6.3,
   // see also: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=72867
   #ifdef EIGEN_VECTORIZE_AVX
@@ -373,90 +538,188 @@
 #else
   // after some bench, this version *is* faster than a scalar implementation
   Packet4i mask = _mm_cmpgt_epi32(a,b);
   return _mm_or_si128(_mm_and_si128(mask,a),_mm_andnot_si128(mask,b));
 #endif
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f pcmp_le(const Packet4f& a, const Packet4f& b) { return _mm_cmple_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4f pcmp_lt(const Packet4f& a, const Packet4f& b) { return _mm_cmplt_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4f pcmp_eq(const Packet4f& a, const Packet4f& b) { return _mm_cmpeq_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4i pcmp_eq(const Packet4i& a, const Packet4i& b) { return _mm_cmpeq_epi32(a,b); }
-template<> EIGEN_STRONG_INLINE Packet2d pcmp_eq(const Packet2d& a, const Packet2d& b) { return _mm_cmpeq_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4f pcmp_lt_or_nan(const Packet4f& a, const Packet4f& b) { return _mm_cmpnge_ps(a,b); }
+template <typename Packet, typename Op>
+EIGEN_STRONG_INLINE Packet pminmax_propagate_numbers(const Packet& a, const Packet& b, Op op) {
+  // In this implementation, we take advantage of the fact that pmin/pmax for SSE
+  // always return a if either a or b is NaN.
+  Packet not_nan_mask_a = pcmp_eq(a, a);
+  Packet m = op(a, b);
+  return pselect<Packet>(not_nan_mask_a, m, b);
+}
+
+template <typename Packet, typename Op>
+EIGEN_STRONG_INLINE Packet pminmax_propagate_nan(const Packet& a, const Packet& b, Op op) {
+  // In this implementation, we take advantage of the fact that pmin/pmax for SSE
+  // always return a if either a or b is NaN.
+  Packet not_nan_mask_a = pcmp_eq(a, a);
+  Packet m = op(b, a);
+  return pselect<Packet>(not_nan_mask_a, m, a);
+}
+
+// Add specializations for min/max with prescribed NaN progation.
+template<>
+EIGEN_STRONG_INLINE Packet4f pmin<PropagateNumbers, Packet4f>(const Packet4f& a, const Packet4f& b) {
+  return pminmax_propagate_numbers(a, b, pmin<Packet4f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet2d pmin<PropagateNumbers, Packet2d>(const Packet2d& a, const Packet2d& b) {
+  return pminmax_propagate_numbers(a, b, pmin<Packet2d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet4f pmax<PropagateNumbers, Packet4f>(const Packet4f& a, const Packet4f& b) {
+  return pminmax_propagate_numbers(a, b, pmax<Packet4f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet2d pmax<PropagateNumbers, Packet2d>(const Packet2d& a, const Packet2d& b) {
+  return pminmax_propagate_numbers(a, b, pmax<Packet2d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet4f pmin<PropagateNaN, Packet4f>(const Packet4f& a, const Packet4f& b) {
+  return pminmax_propagate_nan(a, b, pmin<Packet4f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet2d pmin<PropagateNaN, Packet2d>(const Packet2d& a, const Packet2d& b) {
+  return pminmax_propagate_nan(a, b, pmin<Packet2d>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet4f pmax<PropagateNaN, Packet4f>(const Packet4f& a, const Packet4f& b) {
+  return pminmax_propagate_nan(a, b, pmax<Packet4f>);
+}
+template<>
+EIGEN_STRONG_INLINE Packet2d pmax<PropagateNaN, Packet2d>(const Packet2d& a, const Packet2d& b) {
+  return pminmax_propagate_nan(a, b, pmax<Packet2d>);
+}
+
+template<int N> EIGEN_STRONG_INLINE Packet4i parithmetic_shift_right(const Packet4i& a) { return _mm_srai_epi32(a,N); }
+template<int N> EIGEN_STRONG_INLINE Packet4i plogical_shift_right   (const Packet4i& a) { return _mm_srli_epi32(a,N); }
+template<int N> EIGEN_STRONG_INLINE Packet4i plogical_shift_left    (const Packet4i& a) { return _mm_slli_epi32(a,N); }
 
-template<> EIGEN_STRONG_INLINE Packet4i ptrue<Packet4i>(const Packet4i& a) { return _mm_cmpeq_epi32(a, a); }
-template<> EIGEN_STRONG_INLINE Packet4f
-ptrue<Packet4f>(const Packet4f& a) {
-  Packet4i b = _mm_castps_si128(a);
-  return _mm_castsi128_ps(_mm_cmpeq_epi32(b, b));
+template<> EIGEN_STRONG_INLINE Packet4f pabs(const Packet4f& a)
+{
+  const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF));
+  return _mm_and_ps(a,mask);
 }
-template<> EIGEN_STRONG_INLINE Packet2d
-ptrue<Packet2d>(const Packet2d& a) {
-  Packet4i b = _mm_castpd_si128(a);
-  return _mm_castsi128_pd(_mm_cmpeq_epi32(b, b));
+template<> EIGEN_STRONG_INLINE Packet2d pabs(const Packet2d& a)
+{
+  const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0xFFFFFFFF,0x7FFFFFFF,0xFFFFFFFF,0x7FFFFFFF));
+  return _mm_and_pd(a,mask);
+}
+template<> EIGEN_STRONG_INLINE Packet4i pabs(const Packet4i& a)
+{
+  #ifdef EIGEN_VECTORIZE_SSSE3
+  return _mm_abs_epi32(a);
+  #else
+  Packet4i aux = _mm_srai_epi32(a,31);
+  return _mm_sub_epi32(_mm_xor_si128(a,aux),aux);
+  #endif
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f pand<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_and_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet2d pand<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_and_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4i pand<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_and_si128(a,b); }
-
-template<> EIGEN_STRONG_INLINE Packet4f por<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_or_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet2d por<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_or_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4i por<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_or_si128(a,b); }
-
-template<> EIGEN_STRONG_INLINE Packet4f pxor<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_xor_ps(a,b); }
-template<> EIGEN_STRONG_INLINE Packet2d pxor<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_xor_pd(a,b); }
-template<> EIGEN_STRONG_INLINE Packet4i pxor<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_xor_si128(a,b); }
-
-template<> EIGEN_STRONG_INLINE Packet4f pandnot<Packet4f>(const Packet4f& a, const Packet4f& b) { return _mm_andnot_ps(b,a); }
-template<> EIGEN_STRONG_INLINE Packet2d pandnot<Packet2d>(const Packet2d& a, const Packet2d& b) { return _mm_andnot_pd(b,a); }
-template<> EIGEN_STRONG_INLINE Packet4i pandnot<Packet4i>(const Packet4i& a, const Packet4i& b) { return _mm_andnot_si128(b,a); }
+#ifdef EIGEN_VECTORIZE_SSE4_1
+template<> EIGEN_STRONG_INLINE Packet4f pround<Packet4f>(const Packet4f& a)
+{
+  // Unfortunatly _mm_round_ps doesn't have a rounding mode to implement numext::round.
+  const Packet4f mask = pset1frombits<Packet4f>(0x80000000u);
+  const Packet4f prev0dot5 = pset1frombits<Packet4f>(0x3EFFFFFFu);
+  return _mm_round_ps(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);
+}
 
-template<int N> EIGEN_STRONG_INLINE Packet4i pshiftright(Packet4i a) { return _mm_srli_epi32(a,N); }
-template<int N> EIGEN_STRONG_INLINE Packet4i pshiftleft(Packet4i a) { return _mm_slli_epi32(a,N); }
+template<> EIGEN_STRONG_INLINE Packet2d pround<Packet2d>(const Packet2d& a)
+{
+  const Packet2d mask = _mm_castsi128_pd(_mm_set_epi64x(0x8000000000000000ull, 0x8000000000000000ull));
+  const Packet2d prev0dot5 = _mm_castsi128_pd(_mm_set_epi64x(0x3FDFFFFFFFFFFFFFull, 0x3FDFFFFFFFFFFFFFull));
+  return _mm_round_pd(padd(por(pand(a, mask), prev0dot5), a), _MM_FROUND_TO_ZERO);
+}
 
-#ifdef EIGEN_VECTORIZE_SSE4_1
-template<> EIGEN_STRONG_INLINE Packet4f pround<Packet4f>(const Packet4f& a) { return _mm_round_ps(a, 0); }
-template<> EIGEN_STRONG_INLINE Packet2d pround<Packet2d>(const Packet2d& a) { return _mm_round_pd(a, 0); }
+template<> EIGEN_STRONG_INLINE Packet4f print<Packet4f>(const Packet4f& a) { return _mm_round_ps(a, _MM_FROUND_CUR_DIRECTION); }
+template<> EIGEN_STRONG_INLINE Packet2d print<Packet2d>(const Packet2d& a) { return _mm_round_pd(a, _MM_FROUND_CUR_DIRECTION); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pceil<Packet4f>(const Packet4f& a) { return _mm_ceil_ps(a); }
 template<> EIGEN_STRONG_INLINE Packet2d pceil<Packet2d>(const Packet2d& a) { return _mm_ceil_pd(a); }
 
 template<> EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f>(const Packet4f& a) { return _mm_floor_ps(a); }
 template<> EIGEN_STRONG_INLINE Packet2d pfloor<Packet2d>(const Packet2d& a) { return _mm_floor_pd(a); }
 #else
+template<> EIGEN_STRONG_INLINE Packet4f print(const Packet4f& a) {
+  // Adds and subtracts signum(a) * 2^23 to force rounding.
+  const Packet4f limit = pset1<Packet4f>(static_cast<float>(1<<23));
+  const Packet4f abs_a = pabs(a);
+  Packet4f r = padd(abs_a, limit);
+  // Don't compile-away addition and subtraction.
+  EIGEN_OPTIMIZATION_BARRIER(r);
+  r = psub(r, limit);
+  // If greater than limit, simply return a.  Otherwise, account for sign.
+  r = pselect(pcmp_lt(abs_a, limit),
+              pselect(pcmp_lt(a, pzero(a)), pnegate(r), r), a);
+  return r;
+}
+
+template<> EIGEN_STRONG_INLINE Packet2d print(const Packet2d& a) {
+  // Adds and subtracts signum(a) * 2^52 to force rounding.
+  const Packet2d limit = pset1<Packet2d>(static_cast<double>(1ull<<52));
+  const Packet2d abs_a = pabs(a);
+  Packet2d r = padd(abs_a, limit);
+  // Don't compile-away addition and subtraction.
+  EIGEN_OPTIMIZATION_BARRIER(r);
+  r = psub(r, limit);
+  // If greater than limit, simply return a.  Otherwise, account for sign.
+  r = pselect(pcmp_lt(abs_a, limit),
+              pselect(pcmp_lt(a, pzero(a)), pnegate(r), r), a);
+  return r;
+}
+
 template<> EIGEN_STRONG_INLINE Packet4f pfloor<Packet4f>(const Packet4f& a)
 {
   const Packet4f cst_1 = pset1<Packet4f>(1.0f);
-  Packet4i emm0 = _mm_cvttps_epi32(a);
-  Packet4f tmp  = _mm_cvtepi32_ps(emm0);
-  /* if greater, substract 1 */
+  Packet4f tmp  = print<Packet4f>(a);
+  // If greater, subtract one.
   Packet4f mask = _mm_cmpgt_ps(tmp, a);
   mask = pand(mask, cst_1);
   return psub(tmp, mask);
 }
 
-// WARNING: this pfloor implementation makes sense for small inputs only,
-// It is currently only used by pexp and not exposed through HasFloor.
 template<> EIGEN_STRONG_INLINE Packet2d pfloor<Packet2d>(const Packet2d& a)
 {
   const Packet2d cst_1 = pset1<Packet2d>(1.0);
-  Packet4i emm0 = _mm_cvttpd_epi32(a);
-  Packet2d tmp  = _mm_cvtepi32_pd(emm0);
-  /* if greater, substract 1 */
+  Packet2d tmp  = print<Packet2d>(a);
+  // If greater, subtract one.
   Packet2d mask = _mm_cmpgt_pd(tmp, a);
   mask = pand(mask, cst_1);
   return psub(tmp, mask);
 }
+
+template<> EIGEN_STRONG_INLINE Packet4f pceil<Packet4f>(const Packet4f& a)
+{
+  const Packet4f cst_1 = pset1<Packet4f>(1.0f);
+  Packet4f tmp  = print<Packet4f>(a);
+  // If smaller, add one.
+  Packet4f mask = _mm_cmplt_ps(tmp, a);
+  mask = pand(mask, cst_1);
+  return padd(tmp, mask);
+}
+
+template<> EIGEN_STRONG_INLINE Packet2d pceil<Packet2d>(const Packet2d& a)
+{
+  const Packet2d cst_1 = pset1<Packet2d>(1.0);
+  Packet2d tmp  = print<Packet2d>(a);
+  // If smaller, add one.
+  Packet2d mask = _mm_cmplt_pd(tmp, a);
+  mask = pand(mask, cst_1);
+  return padd(tmp, mask);
+}
 #endif
 
 template<> EIGEN_STRONG_INLINE Packet4f pload<Packet4f>(const float*   from) { EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_ps(from); }
 template<> EIGEN_STRONG_INLINE Packet2d pload<Packet2d>(const double*  from) { EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_pd(from); }
 template<> EIGEN_STRONG_INLINE Packet4i pload<Packet4i>(const int*     from) { EIGEN_DEBUG_ALIGNED_LOAD return _mm_load_si128(reinterpret_cast<const __m128i*>(from)); }
+template<> EIGEN_STRONG_INLINE Packet16b pload<Packet16b>(const bool*     from) { EIGEN_DEBUG_ALIGNED_LOAD return  _mm_load_si128(reinterpret_cast<const __m128i*>(from)); }
 
 #if EIGEN_COMP_MSVC
   template<> EIGEN_STRONG_INLINE Packet4f ploadu<Packet4f>(const float*  from) {
     EIGEN_DEBUG_UNALIGNED_LOAD
     #if (EIGEN_COMP_MSVC==1600)
     // NOTE Some version of MSVC10 generates bad code when using _mm_loadu_ps
     // (i.e., it does not generate an unaligned load!!
@@ -483,14 +746,18 @@
   return _mm_loadu_pd(from);
 }
 template<> EIGEN_STRONG_INLINE Packet4i ploadu<Packet4i>(const int* from)
 {
   EIGEN_DEBUG_UNALIGNED_LOAD
   return _mm_loadu_si128(reinterpret_cast<const __m128i*>(from));
 }
+template<> EIGEN_STRONG_INLINE Packet16b ploadu<Packet16b>(const bool*     from) {
+  EIGEN_DEBUG_UNALIGNED_LOAD
+  return _mm_loadu_si128(reinterpret_cast<const __m128i*>(from));
+}
 
 
 template<> EIGEN_STRONG_INLINE Packet4f ploaddup<Packet4f>(const float*   from)
 {
   return vec4f_swizzle1(_mm_castpd_ps(_mm_load_sd(reinterpret_cast<const double*>(from))), 0, 0, 1, 1);
 }
 template<> EIGEN_STRONG_INLINE Packet2d ploaddup<Packet2d>(const double*  from)
@@ -498,34 +765,61 @@
 template<> EIGEN_STRONG_INLINE Packet4i ploaddup<Packet4i>(const int*     from)
 {
   Packet4i tmp;
   tmp = _mm_loadl_epi64(reinterpret_cast<const __m128i*>(from));
   return vec4i_swizzle1(tmp, 0, 0, 1, 1);
 }
 
+// Loads 8 bools from memory and returns the packet
+// {b0, b0, b1, b1, b2, b2, b3, b3, b4, b4, b5, b5, b6, b6, b7, b7}
+template<> EIGEN_STRONG_INLINE Packet16b ploaddup<Packet16b>(const bool*     from)
+{
+  __m128i tmp = _mm_castpd_si128(pload1<Packet2d>(reinterpret_cast<const double*>(from)));
+  return  _mm_unpacklo_epi8(tmp, tmp);
+}
+
+// Loads 4 bools from memory and returns the packet
+// {b0, b0  b0, b0, b1, b1, b1, b1, b2, b2, b2, b2, b3, b3, b3, b3}
+template<> EIGEN_STRONG_INLINE Packet16b
+ploadquad<Packet16b>(const bool* from) {
+  __m128i tmp = _mm_castps_si128(pload1<Packet4f>(reinterpret_cast<const float*>(from)));
+  tmp = _mm_unpacklo_epi8(tmp, tmp);
+  return  _mm_unpacklo_epi16(tmp, tmp);
+}
+
 template<> EIGEN_STRONG_INLINE void pstore<float>(float*   to, const Packet4f& from) { EIGEN_DEBUG_ALIGNED_STORE _mm_store_ps(to, from); }
 template<> EIGEN_STRONG_INLINE void pstore<double>(double* to, const Packet2d& from) { EIGEN_DEBUG_ALIGNED_STORE _mm_store_pd(to, from); }
 template<> EIGEN_STRONG_INLINE void pstore<int>(int*       to, const Packet4i& from) { EIGEN_DEBUG_ALIGNED_STORE _mm_store_si128(reinterpret_cast<__m128i*>(to), from); }
+template<> EIGEN_STRONG_INLINE void pstore<bool>(bool*     to, const Packet16b& from) { EIGEN_DEBUG_ALIGNED_STORE _mm_store_si128(reinterpret_cast<__m128i*>(to), from); }
 
 template<> EIGEN_STRONG_INLINE void pstoreu<double>(double* to, const Packet2d& from) { EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_pd(to, from); }
 template<> EIGEN_STRONG_INLINE void pstoreu<float>(float*   to, const Packet4f& from) { EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_ps(to, from); }
 template<> EIGEN_STRONG_INLINE void pstoreu<int>(int*       to, const Packet4i& from) { EIGEN_DEBUG_UNALIGNED_STORE _mm_storeu_si128(reinterpret_cast<__m128i*>(to), from); }
+template<> EIGEN_STRONG_INLINE void pstoreu<bool>(bool*     to, const Packet16b& from) { EIGEN_DEBUG_ALIGNED_STORE _mm_storeu_si128(reinterpret_cast<__m128i*>(to), from); }
 
 template<> EIGEN_DEVICE_FUNC inline Packet4f pgather<float, Packet4f>(const float* from, Index stride)
 {
  return _mm_set_ps(from[3*stride], from[2*stride], from[1*stride], from[0*stride]);
 }
 template<> EIGEN_DEVICE_FUNC inline Packet2d pgather<double, Packet2d>(const double* from, Index stride)
 {
  return _mm_set_pd(from[1*stride], from[0*stride]);
 }
 template<> EIGEN_DEVICE_FUNC inline Packet4i pgather<int, Packet4i>(const int* from, Index stride)
 {
  return _mm_set_epi32(from[3*stride], from[2*stride], from[1*stride], from[0*stride]);
- }
+}
+
+template<> EIGEN_DEVICE_FUNC inline Packet16b pgather<bool, Packet16b>(const bool* from, Index stride)
+{
+  return _mm_set_epi8(from[15*stride], from[14*stride], from[13*stride], from[12*stride],
+                      from[11*stride], from[10*stride], from[9*stride], from[8*stride],
+                      from[7*stride], from[6*stride], from[5*stride], from[4*stride],
+                      from[3*stride], from[2*stride], from[1*stride], from[0*stride]);
+}
 
 template<> EIGEN_DEVICE_FUNC inline void pscatter<float, Packet4f>(float* to, const Packet4f& from, Index stride)
 {
   to[stride*0] = _mm_cvtss_f32(from);
   to[stride*1] = _mm_cvtss_f32(_mm_shuffle_ps(from, from, 1));
   to[stride*2] = _mm_cvtss_f32(_mm_shuffle_ps(from, from, 2));
   to[stride*3] = _mm_cvtss_f32(_mm_shuffle_ps(from, from, 3));
@@ -538,14 +832,22 @@
 template<> EIGEN_DEVICE_FUNC inline void pscatter<int, Packet4i>(int* to, const Packet4i& from, Index stride)
 {
   to[stride*0] = _mm_cvtsi128_si32(from);
   to[stride*1] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 1));
   to[stride*2] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 2));
   to[stride*3] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 3));
 }
+template<> EIGEN_DEVICE_FUNC inline void pscatter<bool, Packet16b>(bool* to, const Packet16b& from, Index stride)
+{
+  to[4*stride*0] = _mm_cvtsi128_si32(from);
+  to[4*stride*1] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 1));
+  to[4*stride*2] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 2));
+  to[4*stride*3] = _mm_cvtsi128_si32(_mm_shuffle_epi32(from, 3));
+}
+
 
 // some compilers might be tempted to perform multiple moves instead of using a vector path.
 template<> EIGEN_STRONG_INLINE void pstore1<Packet4f>(float* to, const float& a)
 {
   Packet4f pa = _mm_set_ss(a);
   pstore(to, Packet4f(vec4f_swizzle1(pa,0,0,0,0)));
 }
@@ -580,57 +882,70 @@
 template<> EIGEN_STRONG_INLINE double pfirst<Packet2d>(const Packet2d& a) { double x = _mm_cvtsd_f64(a); return x; }
 template<> EIGEN_STRONG_INLINE int    pfirst<Packet4i>(const Packet4i& a) { int x = _mm_cvtsi128_si32(a); return x; }
 #else
 template<> EIGEN_STRONG_INLINE float  pfirst<Packet4f>(const Packet4f& a) { return _mm_cvtss_f32(a); }
 template<> EIGEN_STRONG_INLINE double pfirst<Packet2d>(const Packet2d& a) { return _mm_cvtsd_f64(a); }
 template<> EIGEN_STRONG_INLINE int    pfirst<Packet4i>(const Packet4i& a) { return _mm_cvtsi128_si32(a); }
 #endif
+template<> EIGEN_STRONG_INLINE bool   pfirst<Packet16b>(const Packet16b& a) { int x = _mm_cvtsi128_si32(a); return static_cast<bool>(x & 1); }
 
-template<> EIGEN_STRONG_INLINE Packet4f preverse(const Packet4f& a)
-{ return _mm_shuffle_ps(a,a,0x1B); }
-template<> EIGEN_STRONG_INLINE Packet2d preverse(const Packet2d& a)
-{ return _mm_shuffle_pd(a,a,0x1); }
-template<> EIGEN_STRONG_INLINE Packet4i preverse(const Packet4i& a)
-{ return _mm_shuffle_epi32(a,0x1B); }
-
-template<> EIGEN_STRONG_INLINE Packet4f pabs(const Packet4f& a)
-{
-  const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF,0x7FFFFFFF));
-  return _mm_and_ps(a,mask);
+template<> EIGEN_STRONG_INLINE Packet4f preverse(const Packet4f& a) { return _mm_shuffle_ps(a,a,0x1B); }
+template<> EIGEN_STRONG_INLINE Packet2d preverse(const Packet2d& a) { return _mm_shuffle_pd(a,a,0x1); }
+template<> EIGEN_STRONG_INLINE Packet4i preverse(const Packet4i& a) { return _mm_shuffle_epi32(a,0x1B); }
+template<> EIGEN_STRONG_INLINE Packet16b preverse(const Packet16b& a) {
+#ifdef EIGEN_VECTORIZE_SSSE3
+  __m128i mask = _mm_set_epi8(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15);
+  return _mm_shuffle_epi8(a, mask);
+#else
+  Packet16b tmp = _mm_shuffle_epi32(a, _MM_SHUFFLE(0, 1, 2, 3));
+  tmp = _mm_shufflehi_epi16(_mm_shufflelo_epi16(tmp, _MM_SHUFFLE(2, 3, 0, 1)), _MM_SHUFFLE(2, 3, 0, 1));
+  return _mm_or_si128(_mm_slli_epi16(tmp, 8), _mm_srli_epi16(tmp, 8));
+#endif
 }
-template<> EIGEN_STRONG_INLINE Packet2d pabs(const Packet2d& a)
-{
-  const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0xFFFFFFFF,0x7FFFFFFF,0xFFFFFFFF,0x7FFFFFFF));
-  return _mm_and_pd(a,mask);
+
+template<> EIGEN_STRONG_INLINE Packet4f pfrexp<Packet4f>(const Packet4f& a, Packet4f& exponent) {
+  return pfrexp_generic(a,exponent);
 }
-template<> EIGEN_STRONG_INLINE Packet4i pabs(const Packet4i& a)
-{
-  #ifdef EIGEN_VECTORIZE_SSSE3
-  return _mm_abs_epi32(a);
-  #else
-  Packet4i aux = _mm_srai_epi32(a,31);
-  return _mm_sub_epi32(_mm_xor_si128(a,aux),aux);
-  #endif
+
+// Extract exponent without existence of Packet2l.
+template<>
+EIGEN_STRONG_INLINE  
+Packet2d pfrexp_generic_get_biased_exponent(const Packet2d& a) {
+  const Packet2d cst_exp_mask  = pset1frombits<Packet2d>(static_cast<uint64_t>(0x7ff0000000000000ull));
+  __m128i a_expo = _mm_srli_epi64(_mm_castpd_si128(pand(a, cst_exp_mask)), 52);
+  return _mm_cvtepi32_pd(vec4i_swizzle1(a_expo, 0, 2, 1, 3));
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f pfrexp<Packet4f>(const Packet4f& a, Packet4f& exponent) {
-  return pfrexp_float(a,exponent);
+template<> EIGEN_STRONG_INLINE Packet2d pfrexp<Packet2d>(const Packet2d& a, Packet2d& exponent) {
+  return pfrexp_generic(a, exponent);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4f pldexp<Packet4f>(const Packet4f& a, const Packet4f& exponent) {
-  return pldexp_float(a,exponent);
+  return pldexp_generic(a,exponent);
 }
 
+// We specialize pldexp here, since the generic implementation uses Packet2l, which is not well
+// supported by SSE, and has more range than is needed for exponents.
 template<> EIGEN_STRONG_INLINE Packet2d pldexp<Packet2d>(const Packet2d& a, const Packet2d& exponent) {
-  const Packet4i cst_1023_0 = _mm_setr_epi32(1023, 1023, 0, 0);
-  Packet4i emm0 = _mm_cvttpd_epi32(exponent);
-  emm0 = padd(emm0, cst_1023_0);
-  emm0 = _mm_slli_epi32(emm0, 20);
-  emm0 = _mm_shuffle_epi32(emm0, _MM_SHUFFLE(1,2,0,3));
-  return pmul(a, Packet2d(_mm_castsi128_pd(emm0)));
+  // Clamp exponent to [-2099, 2099]
+  const Packet2d max_exponent = pset1<Packet2d>(2099.0);
+  const Packet2d e = pmin(pmax(exponent, pnegate(max_exponent)), max_exponent);
+  
+  // Convert e to integer and swizzle to low-order bits.
+  const Packet4i ei = vec4i_swizzle1(_mm_cvtpd_epi32(e), 0, 3, 1, 3);
+  
+  // Split 2^e into four factors and multiply:
+  const Packet4i bias = _mm_set_epi32(0, 1023, 0, 1023);
+  Packet4i b = parithmetic_shift_right<2>(ei);  // floor(e/4)
+  Packet2d c = _mm_castsi128_pd(_mm_slli_epi64(padd(b, bias), 52));  // 2^b
+  Packet2d out = pmul(pmul(pmul(a, c), c), c); // a * 2^(3b)
+  b = psub(psub(psub(ei, b), b), b);  // e - 3b
+  c = _mm_castsi128_pd(_mm_slli_epi64(padd(b, bias), 52));  // 2^(e - 3b)
+  out = pmul(out, c);  // a * 2^e
+  return out;
 }
 
 // with AVX, the default implementations based on pload1 are faster
 #ifndef __AVX__
 template<> EIGEN_STRONG_INLINE void
 pbroadcast4<Packet4f>(const float *a,
                       Packet4f& a0, Packet4f& a1, Packet4f& a2, Packet4f& a3)
@@ -665,46 +980,14 @@
 {
   vecs[1] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0x55));
   vecs[2] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0xAA));
   vecs[3] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0xFF));
   vecs[0] = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(vecs[0]), 0x00));
 }
 
-#ifdef EIGEN_VECTORIZE_SSE3
-template<> EIGEN_STRONG_INLINE Packet4f preduxp<Packet4f>(const Packet4f* vecs)
-{
-  return _mm_hadd_ps(_mm_hadd_ps(vecs[0], vecs[1]),_mm_hadd_ps(vecs[2], vecs[3]));
-}
-
-template<> EIGEN_STRONG_INLINE Packet2d preduxp<Packet2d>(const Packet2d* vecs)
-{
-  return _mm_hadd_pd(vecs[0], vecs[1]);
-}
-
-#else
-template<> EIGEN_STRONG_INLINE Packet4f preduxp<Packet4f>(const Packet4f* vecs)
-{
-  Packet4f tmp0, tmp1, tmp2;
-  tmp0 = _mm_unpacklo_ps(vecs[0], vecs[1]);
-  tmp1 = _mm_unpackhi_ps(vecs[0], vecs[1]);
-  tmp2 = _mm_unpackhi_ps(vecs[2], vecs[3]);
-  tmp0 = _mm_add_ps(tmp0, tmp1);
-  tmp1 = _mm_unpacklo_ps(vecs[2], vecs[3]);
-  tmp1 = _mm_add_ps(tmp1, tmp2);
-  tmp2 = _mm_movehl_ps(tmp1, tmp0);
-  tmp0 = _mm_movelh_ps(tmp0, tmp1);
-  return _mm_add_ps(tmp0, tmp2);
-}
-
-template<> EIGEN_STRONG_INLINE Packet2d preduxp<Packet2d>(const Packet2d* vecs)
-{
-  return _mm_add_pd(_mm_unpacklo_pd(vecs[0], vecs[1]), _mm_unpackhi_pd(vecs[0], vecs[1]));
-}
-#endif  // SSE3
-
 template<> EIGEN_STRONG_INLINE float predux<Packet4f>(const Packet4f& a)
 {
   // Disable SSE3 _mm_hadd_pd that is extremely slow on all existing Intel's architectures
   // (from Nehalem to Haswell)
 // #ifdef EIGEN_VECTORIZE_SSE3
 //   Packet4f tmp = _mm_add_ps(a, vec4f_swizzle1(a,2,3,2,3));
 //   return pfirst<Packet4f>(_mm_hadd_ps(tmp, tmp));
@@ -722,46 +1005,36 @@
 //   return pfirst<Packet2d>(_mm_hadd_pd(a, a));
 // #else
   return pfirst<Packet2d>(_mm_add_sd(a, _mm_unpackhi_pd(a,a)));
 // #endif
 }
 
 #ifdef EIGEN_VECTORIZE_SSSE3
-template<> EIGEN_STRONG_INLINE Packet4i preduxp<Packet4i>(const Packet4i* vecs)
-{
-  return _mm_hadd_epi32(_mm_hadd_epi32(vecs[0], vecs[1]),_mm_hadd_epi32(vecs[2], vecs[3]));
-}
 template<> EIGEN_STRONG_INLINE int predux<Packet4i>(const Packet4i& a)
 {
   Packet4i tmp0 = _mm_hadd_epi32(a,a);
   return pfirst<Packet4i>(_mm_hadd_epi32(tmp0,tmp0));
 }
+
 #else
 template<> EIGEN_STRONG_INLINE int predux<Packet4i>(const Packet4i& a)
 {
   Packet4i tmp = _mm_add_epi32(a, _mm_unpackhi_epi64(a,a));
   return pfirst(tmp) + pfirst<Packet4i>(_mm_shuffle_epi32(tmp, 1));
 }
+#endif
 
-template<> EIGEN_STRONG_INLINE Packet4i preduxp<Packet4i>(const Packet4i* vecs)
-{
-  Packet4i tmp0, tmp1, tmp2;
-  tmp0 = _mm_unpacklo_epi32(vecs[0], vecs[1]);
-  tmp1 = _mm_unpackhi_epi32(vecs[0], vecs[1]);
-  tmp2 = _mm_unpackhi_epi32(vecs[2], vecs[3]);
-  tmp0 = _mm_add_epi32(tmp0, tmp1);
-  tmp1 = _mm_unpacklo_epi32(vecs[2], vecs[3]);
-  tmp1 = _mm_add_epi32(tmp1, tmp2);
-  tmp2 = _mm_unpacklo_epi64(tmp0, tmp1);
-  tmp0 = _mm_unpackhi_epi64(tmp0, tmp1);
-  return _mm_add_epi32(tmp0, tmp2);
+template<> EIGEN_STRONG_INLINE bool predux<Packet16b>(const Packet16b& a) {
+  Packet4i tmp = _mm_or_si128(a, _mm_unpackhi_epi64(a,a));
+  return (pfirst(tmp) != 0) || (pfirst<Packet4i>(_mm_shuffle_epi32(tmp, 1)) != 0);
 }
-#endif
+
 // Other reduction functions:
 
+
 // mul
 template<> EIGEN_STRONG_INLINE float predux_mul<Packet4f>(const Packet4f& a)
 {
   Packet4f tmp = _mm_mul_ps(a, _mm_movehl_ps(a,a));
   return pfirst<Packet4f>(_mm_mul_ss(tmp, _mm_shuffle_ps(tmp,tmp, 1)));
 }
 template<> EIGEN_STRONG_INLINE double predux_mul<Packet2d>(const Packet2d& a)
@@ -774,14 +1047,20 @@
   // for GCC (eg., reusing pmul is very slow !)
   // TODO try to call _mm_mul_epu32 directly
   EIGEN_ALIGN16 int aux[4];
   pstore(aux, a);
   return  (aux[0] * aux[1]) * (aux[2] * aux[3]);
 }
 
+template<> EIGEN_STRONG_INLINE bool predux_mul<Packet16b>(const Packet16b& a) {
+  Packet4i tmp = _mm_and_si128(a, _mm_unpackhi_epi64(a,a));
+  return ((pfirst<Packet4i>(tmp) == 0x01010101) &&
+          (pfirst<Packet4i>(_mm_shuffle_epi32(tmp, 1)) == 0x01010101));
+}
+
 // min
 template<> EIGEN_STRONG_INLINE float predux_min<Packet4f>(const Packet4f& a)
 {
   Packet4f tmp = _mm_min_ps(a, _mm_movehl_ps(a,a));
   return pfirst<Packet4f>(_mm_min_ss(tmp, _mm_shuffle_ps(tmp,tmp, 1)));
 }
 template<> EIGEN_STRONG_INLINE double predux_min<Packet2d>(const Packet2d& a)
@@ -837,122 +1116,14 @@
 // }
 
 template<> EIGEN_STRONG_INLINE bool predux_any(const Packet4f& x)
 {
   return _mm_movemask_ps(x) != 0x0;
 }
 
-#if EIGEN_COMP_GNUC
-// template <> EIGEN_STRONG_INLINE Packet4f pmadd(const Packet4f&  a, const Packet4f&  b, const Packet4f&  c)
-// {
-//   Packet4f res = b;
-//   asm("mulps %[a], %[b] \n\taddps %[c], %[b]" : [b] "+x" (res) : [a] "x" (a), [c] "x" (c));
-//   return res;
-// }
-// EIGEN_STRONG_INLINE Packet4i _mm_alignr_epi8(const Packet4i&  a, const Packet4i&  b, const int i)
-// {
-//   Packet4i res = a;
-//   asm("palignr %[i], %[a], %[b] " : [b] "+x" (res) : [a] "x" (a), [i] "i" (i));
-//   return res;
-// }
-#endif
-
-#ifdef EIGEN_VECTORIZE_SSSE3
-// SSSE3 versions
-template<int Offset>
-struct palign_impl<Offset,Packet4f>
-{
-  static EIGEN_STRONG_INLINE void run(Packet4f& first, const Packet4f& second)
-  {
-    if (Offset!=0)
-      first = _mm_castsi128_ps(_mm_alignr_epi8(_mm_castps_si128(second), _mm_castps_si128(first), Offset*4));
-  }
-};
-
-template<int Offset>
-struct palign_impl<Offset,Packet4i>
-{
-  static EIGEN_STRONG_INLINE void run(Packet4i& first, const Packet4i& second)
-  {
-    if (Offset!=0)
-      first = _mm_alignr_epi8(second,first, Offset*4);
-  }
-};
-
-template<int Offset>
-struct palign_impl<Offset,Packet2d>
-{
-  static EIGEN_STRONG_INLINE void run(Packet2d& first, const Packet2d& second)
-  {
-    if (Offset==1)
-      first = _mm_castsi128_pd(_mm_alignr_epi8(_mm_castpd_si128(second), _mm_castpd_si128(first), 8));
-  }
-};
-#else
-// SSE2 versions
-template<int Offset>
-struct palign_impl<Offset,Packet4f>
-{
-  static EIGEN_STRONG_INLINE void run(Packet4f& first, const Packet4f& second)
-  {
-    if (Offset==1)
-    {
-      first = _mm_move_ss(first,second);
-      first = _mm_castsi128_ps(_mm_shuffle_epi32(_mm_castps_si128(first),0x39));
-    }
-    else if (Offset==2)
-    {
-      first = _mm_movehl_ps(first,first);
-      first = _mm_movelh_ps(first,second);
-    }
-    else if (Offset==3)
-    {
-      first = _mm_move_ss(first,second);
-      first = _mm_shuffle_ps(first,second,0x93);
-    }
-  }
-};
-
-template<int Offset>
-struct palign_impl<Offset,Packet4i>
-{
-  static EIGEN_STRONG_INLINE void run(Packet4i& first, const Packet4i& second)
-  {
-    if (Offset==1)
-    {
-      first = _mm_castps_si128(_mm_move_ss(_mm_castsi128_ps(first),_mm_castsi128_ps(second)));
-      first = _mm_shuffle_epi32(first,0x39);
-    }
-    else if (Offset==2)
-    {
-      first = _mm_castps_si128(_mm_movehl_ps(_mm_castsi128_ps(first),_mm_castsi128_ps(first)));
-      first = _mm_castps_si128(_mm_movelh_ps(_mm_castsi128_ps(first),_mm_castsi128_ps(second)));
-    }
-    else if (Offset==3)
-    {
-      first = _mm_castps_si128(_mm_move_ss(_mm_castsi128_ps(first),_mm_castsi128_ps(second)));
-      first = _mm_castps_si128(_mm_shuffle_ps(_mm_castsi128_ps(first),_mm_castsi128_ps(second),0x93));
-    }
-  }
-};
-
-template<int Offset>
-struct palign_impl<Offset,Packet2d>
-{
-  static EIGEN_STRONG_INLINE void run(Packet2d& first, const Packet2d& second)
-  {
-    if (Offset==1)
-    {
-      first = _mm_castps_pd(_mm_movehl_ps(_mm_castpd_ps(first),_mm_castpd_ps(first)));
-      first = _mm_castps_pd(_mm_movelh_ps(_mm_castpd_ps(first),_mm_castpd_ps(second)));
-    }
-  }
-};
-#endif
-
 EIGEN_DEVICE_FUNC inline void
 ptranspose(PacketBlock<Packet4f,4>& kernel) {
   _MM_TRANSPOSE4_PS(kernel.packet[0], kernel.packet[1], kernel.packet[2], kernel.packet[3]);
 }
 
 EIGEN_DEVICE_FUNC inline void
 ptranspose(PacketBlock<Packet2d,2>& kernel) {
@@ -970,14 +1141,108 @@
 
   kernel.packet[0] = _mm_unpacklo_epi64(T0, T1);
   kernel.packet[1] = _mm_unpackhi_epi64(T0, T1);
   kernel.packet[2] = _mm_unpacklo_epi64(T2, T3);
   kernel.packet[3] = _mm_unpackhi_epi64(T2, T3);
 }
 
+EIGEN_DEVICE_FUNC inline void
+ptranspose(PacketBlock<Packet16b,4>& kernel) {
+  __m128i T0 =  _mm_unpacklo_epi8(kernel.packet[0], kernel.packet[1]);
+  __m128i T1 =  _mm_unpackhi_epi8(kernel.packet[0], kernel.packet[1]);
+  __m128i T2 =  _mm_unpacklo_epi8(kernel.packet[2], kernel.packet[3]);
+  __m128i T3 =  _mm_unpackhi_epi8(kernel.packet[2], kernel.packet[3]);
+  kernel.packet[0] = _mm_unpacklo_epi16(T0, T2);
+  kernel.packet[1] = _mm_unpackhi_epi16(T0, T2);
+  kernel.packet[2] = _mm_unpacklo_epi16(T1, T3);
+  kernel.packet[3] = _mm_unpackhi_epi16(T1, T3);
+}
+
+EIGEN_DEVICE_FUNC inline void
+ptranspose(PacketBlock<Packet16b,16>& kernel) {
+  // If we number the elements in the input thus:
+  // kernel.packet[ 0] = {00, 01, 02, 03, 04, 05, 06, 07, 08, 09, 0a, 0b, 0c, 0d, 0e, 0f}
+  // kernel.packet[ 1] = {10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 1a, 1b, 1c, 1d, 1e, 1f}
+  // ...
+  // kernel.packet[15] = {f0, f1, f2, f3, f4, f5, f6, f7, f8, f9, fa, fb, fc, fd, fe, ff},
+  //
+  // the desired output is:
+  // kernel.packet[ 0] = {00, 10, 20, 30, 40, 50, 60, 70, 80, 90, a0, b0, c0, d0, e0, f0}
+  // kernel.packet[ 1] = {01, 11, 21, 31, 41, 51, 61, 71, 81, 91, a1, b1, c1, d1, e1, f1}
+  // ...
+  // kernel.packet[15] = {0f, 1f, 2f, 3f, 4f, 5f, 6f, 7f, 8f, 9f, af, bf, cf, df, ef, ff},
+  __m128i t0 =  _mm_unpacklo_epi8(kernel.packet[0], kernel.packet[1]); // 00 10 01 11 02 12 03 13 04 14 05 15 06 16 07 17
+  __m128i t1 =  _mm_unpackhi_epi8(kernel.packet[0], kernel.packet[1]); // 08 18 09 19 0a 1a 0b 1b 0c 1c 0d 1d 0e 1e 0f 1f
+  __m128i t2 =  _mm_unpacklo_epi8(kernel.packet[2], kernel.packet[3]); // 20 30 21 31 22 32 ...                     27 37
+  __m128i t3 =  _mm_unpackhi_epi8(kernel.packet[2], kernel.packet[3]); // 28 38 29 39 2a 3a ...                     2f 3f
+  __m128i t4 =  _mm_unpacklo_epi8(kernel.packet[4], kernel.packet[5]); // 40 50 41 51 42 52                         47 57
+  __m128i t5 =  _mm_unpackhi_epi8(kernel.packet[4], kernel.packet[5]); // 48 58 49 59 4a 5a
+  __m128i t6 =  _mm_unpacklo_epi8(kernel.packet[6], kernel.packet[7]);
+  __m128i t7 =  _mm_unpackhi_epi8(kernel.packet[6], kernel.packet[7]);
+  __m128i t8 =  _mm_unpacklo_epi8(kernel.packet[8], kernel.packet[9]);
+  __m128i t9 =  _mm_unpackhi_epi8(kernel.packet[8], kernel.packet[9]);
+  __m128i ta =  _mm_unpacklo_epi8(kernel.packet[10], kernel.packet[11]);
+  __m128i tb =  _mm_unpackhi_epi8(kernel.packet[10], kernel.packet[11]);
+  __m128i tc =  _mm_unpacklo_epi8(kernel.packet[12], kernel.packet[13]);
+  __m128i td =  _mm_unpackhi_epi8(kernel.packet[12], kernel.packet[13]);
+  __m128i te =  _mm_unpacklo_epi8(kernel.packet[14], kernel.packet[15]);
+  __m128i tf =  _mm_unpackhi_epi8(kernel.packet[14], kernel.packet[15]);
+
+  __m128i s0 =  _mm_unpacklo_epi16(t0, t2); // 00 10 20 30 01 11 21 31 02 12 22 32 03 13 23 33
+  __m128i s1 =  _mm_unpackhi_epi16(t0, t2); // 04 14 24 34
+  __m128i s2 =  _mm_unpacklo_epi16(t1, t3); // 08 18 28 38 ...
+  __m128i s3 =  _mm_unpackhi_epi16(t1, t3); // 0c 1c 2c 3c ...
+  __m128i s4 =  _mm_unpacklo_epi16(t4, t6); // 40 50 60 70 41 51 61 71 42 52 62 72 43 53 63 73
+  __m128i s5 =  _mm_unpackhi_epi16(t4, t6); // 44 54 64 74 ...
+  __m128i s6 =  _mm_unpacklo_epi16(t5, t7);
+  __m128i s7 =  _mm_unpackhi_epi16(t5, t7);
+  __m128i s8 =  _mm_unpacklo_epi16(t8, ta);
+  __m128i s9 =  _mm_unpackhi_epi16(t8, ta);
+  __m128i sa =  _mm_unpacklo_epi16(t9, tb);
+  __m128i sb =  _mm_unpackhi_epi16(t9, tb);
+  __m128i sc =  _mm_unpacklo_epi16(tc, te);
+  __m128i sd =  _mm_unpackhi_epi16(tc, te);
+  __m128i se =  _mm_unpacklo_epi16(td, tf);
+  __m128i sf =  _mm_unpackhi_epi16(td, tf);
+
+  __m128i u0 =  _mm_unpacklo_epi32(s0, s4); // 00 10 20 30 40 50 60 70 01 11 21 31 41 51 61 71
+  __m128i u1 =  _mm_unpackhi_epi32(s0, s4); // 02 12 22 32 42 52 62 72 03 13 23 33 43 53 63 73
+  __m128i u2 =  _mm_unpacklo_epi32(s1, s5);
+  __m128i u3 =  _mm_unpackhi_epi32(s1, s5);
+  __m128i u4 =  _mm_unpacklo_epi32(s2, s6);
+  __m128i u5 =  _mm_unpackhi_epi32(s2, s6);
+  __m128i u6 =  _mm_unpacklo_epi32(s3, s7);
+  __m128i u7 =  _mm_unpackhi_epi32(s3, s7);
+  __m128i u8 =  _mm_unpacklo_epi32(s8, sc);
+  __m128i u9 =  _mm_unpackhi_epi32(s8, sc);
+  __m128i ua =  _mm_unpacklo_epi32(s9, sd);
+  __m128i ub =  _mm_unpackhi_epi32(s9, sd);
+  __m128i uc =  _mm_unpacklo_epi32(sa, se);
+  __m128i ud =  _mm_unpackhi_epi32(sa, se);
+  __m128i ue =  _mm_unpacklo_epi32(sb, sf);
+  __m128i uf =  _mm_unpackhi_epi32(sb, sf);
+
+  kernel.packet[0]  = _mm_unpacklo_epi64(u0, u8);
+  kernel.packet[1]  = _mm_unpackhi_epi64(u0, u8);
+  kernel.packet[2]  = _mm_unpacklo_epi64(u1, u9);
+  kernel.packet[3]  = _mm_unpackhi_epi64(u1, u9);
+  kernel.packet[4]  = _mm_unpacklo_epi64(u2, ua);
+  kernel.packet[5]  = _mm_unpackhi_epi64(u2, ua);
+  kernel.packet[6]  = _mm_unpacklo_epi64(u3, ub);
+  kernel.packet[7]  = _mm_unpackhi_epi64(u3, ub);
+  kernel.packet[8]  = _mm_unpacklo_epi64(u4, uc);
+  kernel.packet[9]  = _mm_unpackhi_epi64(u4, uc);
+  kernel.packet[10] = _mm_unpacklo_epi64(u5, ud);
+  kernel.packet[11] = _mm_unpackhi_epi64(u5, ud);
+  kernel.packet[12] = _mm_unpacklo_epi64(u6, ue);
+  kernel.packet[13] = _mm_unpackhi_epi64(u6, ue);
+  kernel.packet[14] = _mm_unpacklo_epi64(u7, uf);
+  kernel.packet[15] = _mm_unpackhi_epi64(u7, uf);
+}
+
 template<> EIGEN_STRONG_INLINE Packet4i pblend(const Selector<4>& ifPacket, const Packet4i& thenPacket, const Packet4i& elsePacket) {
   const __m128i zero = _mm_setzero_si128();
   const __m128i select = _mm_set_epi32(ifPacket.select[3], ifPacket.select[2], ifPacket.select[1], ifPacket.select[0]);
   __m128i false_mask = _mm_cmpeq_epi32(select, zero);
 #ifdef EIGEN_VECTORIZE_SSE4_1
   return _mm_blendv_epi8(thenPacket, elsePacket, false_mask);
 #else
@@ -1001,62 +1266,232 @@
 #ifdef EIGEN_VECTORIZE_SSE4_1
   return _mm_blendv_pd(thenPacket, elsePacket, false_mask);
 #else
   return _mm_or_pd(_mm_andnot_pd(false_mask, thenPacket), _mm_and_pd(false_mask, elsePacket));
 #endif
 }
 
-template<> EIGEN_STRONG_INLINE Packet4f pinsertfirst(const Packet4f& a, float b)
-{
-#ifdef EIGEN_VECTORIZE_SSE4_1
-  return _mm_blend_ps(a,pset1<Packet4f>(b),1);
-#else
-  return _mm_move_ss(a, _mm_load_ss(&b));
-#endif
-}
-
-template<> EIGEN_STRONG_INLINE Packet2d pinsertfirst(const Packet2d& a, double b)
-{
-#ifdef EIGEN_VECTORIZE_SSE4_1
-  return _mm_blend_pd(a,pset1<Packet2d>(b),1);
-#else
-  return _mm_move_sd(a, _mm_load_sd(&b));
-#endif
-}
-
-template<> EIGEN_STRONG_INLINE Packet4f pinsertlast(const Packet4f& a, float b)
-{
-#ifdef EIGEN_VECTORIZE_SSE4_1
-  return _mm_blend_ps(a,pset1<Packet4f>(b),(1<<3));
-#else
-  const Packet4f mask = _mm_castsi128_ps(_mm_setr_epi32(0x0,0x0,0x0,0xFFFFFFFF));
-  return _mm_or_ps(_mm_andnot_ps(mask, a), _mm_and_ps(mask, pset1<Packet4f>(b)));
-#endif
-}
-
-template<> EIGEN_STRONG_INLINE Packet2d pinsertlast(const Packet2d& a, double b)
-{
-#ifdef EIGEN_VECTORIZE_SSE4_1
-  return _mm_blend_pd(a,pset1<Packet2d>(b),(1<<1));
-#else
-  const Packet2d mask = _mm_castsi128_pd(_mm_setr_epi32(0x0,0x0,0xFFFFFFFF,0xFFFFFFFF));
-  return _mm_or_pd(_mm_andnot_pd(mask, a), _mm_and_pd(mask, pset1<Packet2d>(b)));
-#endif
-}
-
 // Scalar path for pmadd with FMA to ensure consistency with vectorized path.
 #ifdef EIGEN_VECTORIZE_FMA
 template<> EIGEN_STRONG_INLINE float pmadd(const float& a, const float& b, const float& c) {
   return ::fmaf(a,b,c);
 }
 template<> EIGEN_STRONG_INLINE double pmadd(const double& a, const double& b, const double& c) {
   return ::fma(a,b,c);
 }
 #endif
 
+
+// Packet math for Eigen::half
+// Disable the following code since it's broken on too many platforms / compilers.
+//#elif defined(EIGEN_VECTORIZE_SSE) && (!EIGEN_ARCH_x86_64) && (!EIGEN_COMP_MSVC)
+#if 0
+
+typedef struct {
+  __m64 x;
+} Packet4h;
+
+
+template<> struct is_arithmetic<Packet4h> { enum { value = true }; };
+
+template <>
+struct packet_traits<Eigen::half> : default_packet_traits {
+  typedef Packet4h type;
+  // There is no half-size packet for Packet4h.
+  typedef Packet4h half;
+  enum {
+    Vectorizable = 1,
+    AlignedOnScalar = 1,
+    size = 4,
+    HasHalfPacket = 0,
+    HasAdd    = 1,
+    HasSub    = 1,
+    HasMul    = 1,
+    HasDiv    = 1,
+    HasNegate = 0,
+    HasAbs    = 0,
+    HasAbs2   = 0,
+    HasMin    = 0,
+    HasMax    = 0,
+    HasConj   = 0,
+    HasSetLinear = 0,
+    HasSqrt = 0,
+    HasRsqrt = 0,
+    HasExp = 0,
+    HasLog = 0,
+    HasBlend = 0
+  };
+};
+
+
+template<> struct unpacket_traits<Packet4h> { typedef Eigen::half type; enum {size=4, alignment=Aligned16, vectorizable=true, masked_load_available=false, masked_store_available=false}; typedef Packet4h half; };
+
+template<> EIGEN_STRONG_INLINE Packet4h pset1<Packet4h>(const Eigen::half& from) {
+  Packet4h result;
+  result.x = _mm_set1_pi16(from.x);
+  return result;
+}
+
+template<> EIGEN_STRONG_INLINE Eigen::half pfirst<Packet4h>(const Packet4h& from) {
+  return half_impl::raw_uint16_to_half(static_cast<unsigned short>(_mm_cvtsi64_si32(from.x)));
+}
+
+template<> EIGEN_STRONG_INLINE Packet4h pconj(const Packet4h& a) { return a; }
+
+template<> EIGEN_STRONG_INLINE Packet4h padd<Packet4h>(const Packet4h& a, const Packet4h& b) {
+  __int64_t a64 = _mm_cvtm64_si64(a.x);
+  __int64_t b64 = _mm_cvtm64_si64(b.x);
+
+  Eigen::half h[4];
+
+  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
+  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
+  h[0] = ha + hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
+  h[1] = ha + hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
+  h[2] = ha + hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
+  h[3] = ha + hb;
+  Packet4h result;
+  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
+  return result;
+}
+
+template<> EIGEN_STRONG_INLINE Packet4h psub<Packet4h>(const Packet4h& a, const Packet4h& b) {
+  __int64_t a64 = _mm_cvtm64_si64(a.x);
+  __int64_t b64 = _mm_cvtm64_si64(b.x);
+
+  Eigen::half h[4];
+
+  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
+  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
+  h[0] = ha - hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
+  h[1] = ha - hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
+  h[2] = ha - hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
+  h[3] = ha - hb;
+  Packet4h result;
+  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
+  return result;
+}
+
+template<> EIGEN_STRONG_INLINE Packet4h pmul<Packet4h>(const Packet4h& a, const Packet4h& b) {
+  __int64_t a64 = _mm_cvtm64_si64(a.x);
+  __int64_t b64 = _mm_cvtm64_si64(b.x);
+
+  Eigen::half h[4];
+
+  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
+  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
+  h[0] = ha * hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
+  h[1] = ha * hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
+  h[2] = ha * hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
+  h[3] = ha * hb;
+  Packet4h result;
+  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
+  return result;
+}
+
+template<> EIGEN_STRONG_INLINE Packet4h pdiv<Packet4h>(const Packet4h& a, const Packet4h& b) {
+  __int64_t a64 = _mm_cvtm64_si64(a.x);
+  __int64_t b64 = _mm_cvtm64_si64(b.x);
+
+  Eigen::half h[4];
+
+  Eigen::half ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64));
+  Eigen::half hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64));
+  h[0] = ha / hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 16));
+  h[1] = ha / hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 32));
+  h[2] = ha / hb;
+  ha = half_impl::raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
+  hb = half_impl::raw_uint16_to_half(static_cast<unsigned short>(b64 >> 48));
+  h[3] = ha / hb;
+  Packet4h result;
+  result.x = _mm_set_pi16(h[3].x, h[2].x, h[1].x, h[0].x);
+  return result;
+}
+
+template<> EIGEN_STRONG_INLINE Packet4h pload<Packet4h>(const Eigen::half* from) {
+  Packet4h result;
+  result.x = _mm_cvtsi64_m64(*reinterpret_cast<const __int64_t*>(from));
+  return result;
+}
+
+template<> EIGEN_STRONG_INLINE Packet4h ploadu<Packet4h>(const Eigen::half* from) {
+  Packet4h result;
+  result.x = _mm_cvtsi64_m64(*reinterpret_cast<const __int64_t*>(from));
+  return result;
+}
+
+template<> EIGEN_STRONG_INLINE void pstore<Eigen::half>(Eigen::half* to, const Packet4h& from) {
+  __int64_t r = _mm_cvtm64_si64(from.x);
+  *(reinterpret_cast<__int64_t*>(to)) = r;
+}
+
+template<> EIGEN_STRONG_INLINE void pstoreu<Eigen::half>(Eigen::half* to, const Packet4h& from) {
+  __int64_t r = _mm_cvtm64_si64(from.x);
+  *(reinterpret_cast<__int64_t*>(to)) = r;
+}
+
+template<> EIGEN_STRONG_INLINE Packet4h
+ploadquad<Packet4h>(const Eigen::half* from) {
+  return pset1<Packet4h>(*from);
+}
+
+template<> EIGEN_STRONG_INLINE Packet4h pgather<Eigen::half, Packet4h>(const Eigen::half* from, Index stride)
+{
+  Packet4h result;
+  result.x = _mm_set_pi16(from[3*stride].x, from[2*stride].x, from[1*stride].x, from[0*stride].x);
+  return result;
+}
+
+template<> EIGEN_STRONG_INLINE void pscatter<Eigen::half, Packet4h>(Eigen::half* to, const Packet4h& from, Index stride)
+{
+  __int64_t a = _mm_cvtm64_si64(from.x);
+  to[stride*0].x = static_cast<unsigned short>(a);
+  to[stride*1].x = static_cast<unsigned short>(a >> 16);
+  to[stride*2].x = static_cast<unsigned short>(a >> 32);
+  to[stride*3].x = static_cast<unsigned short>(a >> 48);
+}
+
+EIGEN_STRONG_INLINE void
+ptranspose(PacketBlock<Packet4h,4>& kernel) {
+  __m64 T0 = _mm_unpacklo_pi16(kernel.packet[0].x, kernel.packet[1].x);
+  __m64 T1 = _mm_unpacklo_pi16(kernel.packet[2].x, kernel.packet[3].x);
+  __m64 T2 = _mm_unpackhi_pi16(kernel.packet[0].x, kernel.packet[1].x);
+  __m64 T3 = _mm_unpackhi_pi16(kernel.packet[2].x, kernel.packet[3].x);
+
+  kernel.packet[0].x = _mm_unpacklo_pi32(T0, T1);
+  kernel.packet[1].x = _mm_unpackhi_pi32(T0, T1);
+  kernel.packet[2].x = _mm_unpacklo_pi32(T2, T3);
+  kernel.packet[3].x = _mm_unpackhi_pi32(T2, T3);
+}
+
+#endif
+
+
 } // end namespace internal
 
 } // end namespace Eigen
 
 #if EIGEN_COMP_PGI && EIGEN_COMP_PGI < 1900
 // PGI++ does not define the following intrinsics in C++ mode.
 static inline __m128  _mm_castpd_ps   (__m128d x) { return reinterpret_cast<__m128&>(x);  }
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SSE/TypeCasting.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SSE/TypeCasting.h`

 * *Files 17% similar despite different names*

```diff
@@ -73,12 +73,70 @@
   return _mm_castps_si128(a);
 }
 
 template<> EIGEN_STRONG_INLINE Packet4f preinterpret<Packet4f,Packet4i>(const Packet4i& a) {
   return _mm_castsi128_ps(a);
 }
 
+template<> EIGEN_STRONG_INLINE Packet2d preinterpret<Packet2d,Packet4i>(const Packet4i& a) {
+  return _mm_castsi128_pd(a);
+}
+
+template<> EIGEN_STRONG_INLINE Packet4i preinterpret<Packet4i,Packet2d>(const Packet2d& a) {
+  return _mm_castpd_si128(a);
+}
+
+// Disable the following code since it's broken on too many platforms / compilers.
+//#elif defined(EIGEN_VECTORIZE_SSE) && (!EIGEN_ARCH_x86_64) && (!EIGEN_COMP_MSVC)
+#if 0
+
+template <>
+struct type_casting_traits<Eigen::half, float> {
+  enum {
+    VectorizedCast = 1,
+    SrcCoeffRatio = 1,
+    TgtCoeffRatio = 1
+  };
+};
+
+template<> EIGEN_STRONG_INLINE Packet4f pcast<Packet4h, Packet4f>(const Packet4h& a) {
+  __int64_t a64 = _mm_cvtm64_si64(a.x);
+  Eigen::half h = raw_uint16_to_half(static_cast<unsigned short>(a64));
+  float f1 = static_cast<float>(h);
+  h = raw_uint16_to_half(static_cast<unsigned short>(a64 >> 16));
+  float f2 = static_cast<float>(h);
+  h = raw_uint16_to_half(static_cast<unsigned short>(a64 >> 32));
+  float f3 = static_cast<float>(h);
+  h = raw_uint16_to_half(static_cast<unsigned short>(a64 >> 48));
+  float f4 = static_cast<float>(h);
+  return _mm_set_ps(f4, f3, f2, f1);
+}
+
+template <>
+struct type_casting_traits<float, Eigen::half> {
+  enum {
+    VectorizedCast = 1,
+    SrcCoeffRatio = 1,
+    TgtCoeffRatio = 1
+  };
+};
+
+template<> EIGEN_STRONG_INLINE Packet4h pcast<Packet4f, Packet4h>(const Packet4f& a) {
+  EIGEN_ALIGN16 float aux[4];
+  pstore(aux, a);
+  Eigen::half h0(aux[0]);
+  Eigen::half h1(aux[1]);
+  Eigen::half h2(aux[2]);
+  Eigen::half h3(aux[3]);
+
+  Packet4h result;
+  result.x = _mm_set_pi16(h3.x, h2.x, h1.x, h0.x);
+  return result;
+}
+
+#endif
+
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_TYPE_CASTING_SSE_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SYCL/InteropHeaders.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SYCL/InteropHeaders.h`

 * *Files 11% similar despite different names*

```diff
@@ -50,24 +50,29 @@
     HasTanh = 1,
     HasLGamma = 0,
     HasDiGamma = 0,
     HasZeta = 0,
     HasPolygamma = 0,
     HasErf = 0,
     HasErfc = 0,
+    HasNdtri = 0,
     HasIGamma = 0,
     HasIGammac = 0,
     HasBetaInc = 0,
     HasBlend = has_blend,
+    // This flag is used to indicate whether packet comparison is supported.
+    // pcmp_eq, pcmp_lt and pcmp_le should be defined for it to be true.
+    HasCmp = 1,
     HasMax = 1,
     HasMin = 1,
     HasMul = 1,
     HasAdd = 1,
     HasFloor = 1,
     HasRound = 1,
+    HasRint = 1,
     HasLog1p = 1,
     HasExpm1 = 1,
     HasCeil = 1,
   };
 };
 
 #ifdef SYCL_DEVICE_ONLY
@@ -142,76 +147,82 @@
 
 #elif defined(SYCL_DEVICE_ONLY)
 template <typename PacketReturnType>
 struct PacketWrapper<PacketReturnType, 4> {
   typedef typename ::Eigen::internal::unpacket_traits<PacketReturnType>::type
       Scalar;
   template <typename Index>
-  EIGEN_DEVICE_FUNC static Scalar scalarize(Index index, PacketReturnType &in) {
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE static Scalar scalarize(Index index, PacketReturnType &in) {
     switch (index) {
       case 0:
         return in.x();
       case 1:
         return in.y();
       case 2:
         return in.z();
       case 3:
         return in.w();
       default:
-        eigen_assert(false && "INDEX MUST BE BETWEEN 0 and 3");
-        abort();
+      //INDEX MUST BE BETWEEN 0 and 3.There is no abort function in SYCL kernel. so we cannot use abort here. 
+      // The code will never reach here
+      __builtin_unreachable();
     }
+    __builtin_unreachable();
   }
-  EIGEN_DEVICE_FUNC static PacketReturnType convert_to_packet_type(
+
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE static PacketReturnType convert_to_packet_type(
       Scalar in, Scalar other) {
     return PacketReturnType(in, other, other, other);
   }
-  EIGEN_DEVICE_FUNC static void set_packet(PacketReturnType &lhs, Scalar *rhs) {
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE static void set_packet(PacketReturnType &lhs, Scalar *rhs) {
     lhs = PacketReturnType(rhs[0], rhs[1], rhs[2], rhs[3]);
   }
 };
 
 template <typename PacketReturnType>
 struct PacketWrapper<PacketReturnType, 1> {
   typedef typename ::Eigen::internal::unpacket_traits<PacketReturnType>::type
       Scalar;
   template <typename Index>
-  EIGEN_DEVICE_FUNC static Scalar scalarize(Index, PacketReturnType &in) {
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE static Scalar scalarize(Index, PacketReturnType &in) {
     return in;
   }
-  EIGEN_DEVICE_FUNC static PacketReturnType convert_to_packet_type(Scalar in,
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE static PacketReturnType convert_to_packet_type(Scalar in,
                                                                    Scalar) {
     return PacketReturnType(in);
   }
-  EIGEN_DEVICE_FUNC static void set_packet(PacketReturnType &lhs, Scalar *rhs) {
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE static void set_packet(PacketReturnType &lhs, Scalar *rhs) {
     lhs = rhs[0];
   }
 };
 
 template <typename PacketReturnType>
 struct PacketWrapper<PacketReturnType, 2> {
   typedef typename ::Eigen::internal::unpacket_traits<PacketReturnType>::type
       Scalar;
   template <typename Index>
-  EIGEN_DEVICE_FUNC static Scalar scalarize(Index index, PacketReturnType &in) {
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE static Scalar scalarize(Index index, PacketReturnType &in) {
     switch (index) {
       case 0:
         return in.x();
       case 1:
         return in.y();
       default:
-        eigen_assert(false && "INDEX MUST BE BETWEEN 0 and 1");
-        abort();
+        //INDEX MUST BE BETWEEN 0 and 1.There is no abort function in SYCL kernel. so we cannot use abort here. 
+      // The code will never reach here
+        __builtin_unreachable();
     }
+    __builtin_unreachable();
   }
-  EIGEN_DEVICE_FUNC static PacketReturnType convert_to_packet_type(
+  
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE static PacketReturnType convert_to_packet_type(
       Scalar in, Scalar other) {
     return PacketReturnType(in, other);
   }
-  EIGEN_DEVICE_FUNC static void set_packet(PacketReturnType &lhs, Scalar *rhs) {
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE static void set_packet(PacketReturnType &lhs, Scalar *rhs) {
     lhs = PacketReturnType(rhs[0], rhs[1]);
   }
 };
 
 #endif
 
 }  // end namespace internal
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SYCL/MathFunctions.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SYCL/MathFunctions.h`

 * *Files 2% similar despite different names*

```diff
@@ -16,15 +16,14 @@
  * \brief:
  *  MathFunctions
  *
  *****************************************************************/
 
 #ifndef EIGEN_MATH_FUNCTIONS_SYCL_H
 #define EIGEN_MATH_FUNCTIONS_SYCL_H
-
 namespace Eigen {
 
 namespace internal {
 
 // Make sure this is only available when targeting a GPU: we don't want to
 // introduce conflicts between these packet_traits definitions and the ones
 // we'll use on the host side (SSE, AVX, ...)
@@ -66,14 +65,15 @@
   template <>                                                          \
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE packet_type pexp<packet_type>( \
       const packet_type& a) {                                          \
     return cl::sycl::exp(a);                                           \
   }
 
 SYCL_PEXP(cl::sycl::cl_float4)
+SYCL_PEXP(cl::sycl::cl_float)
 SYCL_PEXP(cl::sycl::cl_double2)
 #undef SYCL_PEXP
 
 #define SYCL_PEXPM1(packet_type)                                         \
   template <>                                                            \
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE packet_type pexpm1<packet_type>( \
       const packet_type& a) {                                            \
@@ -232,14 +232,25 @@
     return cl::sycl::round(a);                                           \
   }
 
 SYCL_PROUND(cl::sycl::cl_float4)
 SYCL_PROUND(cl::sycl::cl_double2)
 #undef SYCL_PROUND
 
+#define SYCL_PRINT(packet_type)                                         \
+  template <>                                                           \
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE packet_type print<packet_type>( \
+      const packet_type& a) {                                           \
+    return cl::sycl::rint(a);                                           \
+  }
+
+SYCL_PRINT(cl::sycl::cl_float4)
+SYCL_PRINT(cl::sycl::cl_double2)
+#undef SYCL_PRINT
+
 #define SYCL_FLOOR(packet_type)                                          \
   template <>                                                            \
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE packet_type pfloor<packet_type>( \
       const packet_type& a) {                                            \
     return cl::sycl::floor(a);                                           \
   }
 
@@ -265,14 +276,26 @@
     return expr;                                                       \
   }
 
 SYCL_PMAX(cl::sycl::cl_float4, cl::sycl::fmax(a, b))
 SYCL_PMAX(cl::sycl::cl_double2, cl::sycl::fmax(a, b))
 #undef SYCL_PMAX
 
-#endif
+#define SYCL_PLDEXP(packet_type)                                             \
+  template <>                                                                \
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE packet_type pldexp(                  \
+      const packet_type& a, const packet_type& exponent) {                   \
+    return cl::sycl::ldexp(                                                  \
+        a, exponent.template convert<cl::sycl::cl_int,                       \
+                                     cl::sycl::rounding_mode::automatic>()); \
+  }
 
+SYCL_PLDEXP(cl::sycl::cl_float4)
+SYCL_PLDEXP(cl::sycl::cl_double2)
+#undef SYCL_PLDEXP
+
+#endif
 }  // end namespace internal
 
 }  // end namespace Eigen
 
 #endif  // EIGEN_MATH_FUNCTIONS_SYCL_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SYCL/PacketMath.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SYCL/PacketMath.h`

 * *Files 12% similar despite different names*

```diff
@@ -468,14 +468,123 @@
 }
 template <>
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE cl::sycl::cl_double2
 pabs<cl::sycl::cl_double2>(const cl::sycl::cl_double2& a) {
   return cl::sycl::cl_double2(cl::sycl::fabs(a.x()), cl::sycl::fabs(a.y()));
 }
 
+template <typename Packet>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet sycl_pcmp_le(const Packet &a,
+                                                          const Packet &b) {
+  return ((a <= b)
+              .template convert<typename unpacket_traits<Packet>::type,
+                                cl::sycl::rounding_mode::automatic>());
+}
+
+template <typename Packet>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet sycl_pcmp_lt(const Packet &a,
+                                                          const Packet &b) {
+  return ((a < b)
+              .template convert<typename unpacket_traits<Packet>::type,
+                                cl::sycl::rounding_mode::automatic>());
+}
+
+template <typename Packet>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Packet sycl_pcmp_eq(const Packet &a,
+                                                          const Packet &b) {
+  return ((a == b)
+              .template convert<typename unpacket_traits<Packet>::type,
+                                cl::sycl::rounding_mode::automatic>());
+}
+
+#define SYCL_PCMP(OP, TYPE)                                                    \
+  template <>                                                                  \
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE TYPE pcmp_##OP<TYPE>(const TYPE &a,    \
+                                                             const TYPE &b) {  \
+    return sycl_pcmp_##OP<TYPE>(a, b);                                         \
+  }
+
+SYCL_PCMP(le, cl::sycl::cl_float4)
+SYCL_PCMP(lt, cl::sycl::cl_float4)
+SYCL_PCMP(eq, cl::sycl::cl_float4)
+SYCL_PCMP(le, cl::sycl::cl_double2)
+SYCL_PCMP(lt, cl::sycl::cl_double2)
+SYCL_PCMP(eq, cl::sycl::cl_double2)
+#undef SYCL_PCMP
+
+template <typename T> struct convert_to_integer;
+
+template <> struct convert_to_integer<float> {
+  using type = std::int32_t;
+  using packet_type = cl::sycl::cl_int4;
+};
+template <> struct convert_to_integer<double> {
+  using type = std::int64_t;
+  using packet_type = cl::sycl::cl_long2;
+};
+
+template <typename PacketIn>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE typename convert_to_integer<
+    typename unpacket_traits<PacketIn>::type>::packet_type
+vector_as_int(const PacketIn &p) {
+  return (
+      p.template convert<typename convert_to_integer<
+                             typename unpacket_traits<PacketIn>::type>::type,
+                         cl::sycl::rounding_mode::automatic>());
+}
+
+template <typename packetOut, typename PacketIn>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE packetOut
+convert_vector(const PacketIn &p) {
+  return (p.template convert<typename unpacket_traits<packetOut>::type,
+                             cl::sycl::rounding_mode::automatic>());
+}
+
+#define SYCL_PAND(TYPE)                                                        \
+  template <>                                                                  \
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TYPE pand<TYPE>(const TYPE &a,         \
+                                                        const TYPE &b) {       \
+    return convert_vector<TYPE>(vector_as_int(a) & vector_as_int(b));          \
+  }
+SYCL_PAND(cl::sycl::cl_float4)
+SYCL_PAND(cl::sycl::cl_double2)
+#undef SYCL_PAND
+
+#define SYCL_POR(TYPE)                                                         \
+  template <>                                                                  \
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TYPE por<TYPE>(const TYPE &a,          \
+                                                       const TYPE &b) {        \
+    return convert_vector<TYPE>(vector_as_int(a) | vector_as_int(b));          \
+  }
+
+SYCL_POR(cl::sycl::cl_float4)
+SYCL_POR(cl::sycl::cl_double2)
+#undef SYCL_POR
+
+#define SYCL_PXOR(TYPE)                                                        \
+  template <>                                                                  \
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TYPE pxor<TYPE>(const TYPE &a,         \
+                                                        const TYPE &b) {       \
+    return convert_vector<TYPE>(vector_as_int(a) ^ vector_as_int(b));          \
+  }
+
+SYCL_PXOR(cl::sycl::cl_float4)
+SYCL_PXOR(cl::sycl::cl_double2)
+#undef SYCL_PXOR
+
+#define SYCL_PANDNOT(TYPE)                                                     \
+  template <>                                                                  \
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE TYPE pandnot<TYPE>(const TYPE &a,      \
+                                                           const TYPE &b) {    \
+    return convert_vector<TYPE>(vector_as_int(a) & (~vector_as_int(b)));       \
+  }
+SYCL_PANDNOT(cl::sycl::cl_float4)
+SYCL_PANDNOT(cl::sycl::cl_double2)
+#undef SYCL_PANDNOT
+
 EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void ptranspose(
     PacketBlock<cl::sycl::cl_float4, 4>& kernel) {
   float tmp = kernel.packet[0].y();
   kernel.packet[0].y() = kernel.packet[1].x();
   kernel.packet[1].x() = tmp;
 
   tmp = kernel.packet[0].z();
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SYCL/SyclMemoryModel.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SYCL/SyclMemoryModel.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/SYCL/TypeCasting.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/SYCL/TypeCasting.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/arch/ZVector/MathFunctions.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/arch/ZVector/MathFunctions.h`

 * *Files 2% similar despite different names*

```diff
@@ -136,15 +136,14 @@
                  isnumber_mask);
 }
 
 template<> EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED
 Packet4f pexp<Packet4f>(const Packet4f& _x)
 {
 #if !defined(__ARCH__) || (defined(__ARCH__) && __ARCH__ >= 12)
-/*
   Packet4f x = _x;
 
   Packet4f tmp, fx;
   Packet4i emm0;
 
   // clamp x
   x = pmax(pmin(x, p4f_exp_hi), p4f_exp_lo);
@@ -167,24 +166,19 @@
   y = pmadd(y, x, p4f_cephes_exp_p3);
   y = pmadd(y, x, p4f_cephes_exp_p4);
   y = pmadd(y, x, p4f_cephes_exp_p5);
   y = pmadd(y, z, x);
   y = padd(y, p4f_1);
 
   // build 2^n
-  emm0 = vec_cts(fx, 0);
+  emm0 = (Packet4i){ (int)fx[0], (int)fx[1], (int)fx[2], (int)fx[3] };
   emm0 = emm0 + p4i_0x7f;
   emm0 = emm0 << reinterpret_cast<Packet4i>(p4i_23);
 
-  // Altivec's max & min operators just drop silent NaNs. Check NaNs in 
-  // inputs and return them unmodified.
-  Packet4ui isnumber_mask = reinterpret_cast<Packet4ui>(vec_cmpeq(_x, _x));
-  return vec_sel(_x, pmax(pmul(y, reinterpret_cast<Packet4f>(emm0)), _x),
-                 isnumber_mask);*/
-  return _x;
+  return pmax(pmul(y, reinterpret_cast<Packet4f>(emm0)), _x);
 #else
   Packet4f res;
   res.v4f[0] = pexp<Packet2d>(_x.v4f[0]);
   res.v4f[1] = pexp<Packet2d>(_x.v4f[1]);
   return res;
 #endif
 }
@@ -221,12 +215,19 @@
 #else
   res.v4f[0] = prsqrt<Packet2d>(x.v4f[0]);
   res.v4f[1] = prsqrt<Packet2d>(x.v4f[1]);
 #endif
   return res;
 }
 
+// Hyperbolic Tangent function.
+template <>
+EIGEN_DEFINE_FUNCTION_ALLOWING_MULTIPLE_DEFINITIONS EIGEN_UNUSED Packet4f
+ptanh<Packet4f>(const Packet4f& x) {
+  return internal::generic_fast_tanh_float(x);
+}
+
 }  // end namespace internal
 
 }  // end namespace Eigen
 
 #endif  // EIGEN_MATH_FUNCTIONS_ALTIVEC_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/AssignmentFunctors.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/AssignmentFunctors.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/BinaryFunctors.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/BinaryFunctors.h`

 * *Files 4% similar despite different names*

```diff
@@ -35,40 +35,34 @@
 #ifndef EIGEN_SCALAR_BINARY_OP_PLUGIN
   EIGEN_EMPTY_STRUCT_CTOR(scalar_sum_op)
 #else
   scalar_sum_op() {
     EIGEN_SCALAR_BINARY_OP_PLUGIN
   }
 #endif
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a + b; }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a + b; }
   template<typename Packet>
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const
   { return internal::padd(a,b); }
   template<typename Packet>
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type predux(const Packet& a) const
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type predux(const Packet& a) const
   { return internal::predux(a); }
 };
 template<typename LhsScalar,typename RhsScalar>
 struct functor_traits<scalar_sum_op<LhsScalar,RhsScalar> > {
   enum {
-    Cost = (NumTraits<LhsScalar>::AddCost+NumTraits<RhsScalar>::AddCost)/2, // rough estimate!
+    Cost = (int(NumTraits<LhsScalar>::AddCost) + int(NumTraits<RhsScalar>::AddCost)) / 2, // rough estimate!
     PacketAccess = is_same<LhsScalar,RhsScalar>::value && packet_traits<LhsScalar>::HasAdd && packet_traits<RhsScalar>::HasAdd
     // TODO vectorize mixed sum
   };
 };
 
-/** \internal
-  * \brief Template specialization to deprecate the summation of boolean expressions.
-  * This is required to solve Bug 426.
-  * \sa DenseBase::count(), DenseBase::any(), ArrayBase::cast(), MatrixBase::cast()
-  */
-template<> struct scalar_sum_op<bool,bool> : scalar_sum_op<int,int> {
-  EIGEN_DEPRECATED
-  scalar_sum_op() {}
-};
+
+template<>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool scalar_sum_op<bool,bool>::operator() (const bool& a, const bool& b) const { return a || b; }
 
 
 /** \internal
   * \brief Template functor to compute the product of two scalars
   *
   * \sa class CwiseBinaryOp, Cwise::operator*(), class VectorwiseOp, MatrixBase::redux()
   */
@@ -79,31 +73,35 @@
 #ifndef EIGEN_SCALAR_BINARY_OP_PLUGIN
   EIGEN_EMPTY_STRUCT_CTOR(scalar_product_op)
 #else
   scalar_product_op() {
     EIGEN_SCALAR_BINARY_OP_PLUGIN
   }
 #endif
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a * b; }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return a * b; }
   template<typename Packet>
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const
   { return internal::pmul(a,b); }
   template<typename Packet>
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type predux(const Packet& a) const
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type predux(const Packet& a) const
   { return internal::predux_mul(a); }
 };
 template<typename LhsScalar,typename RhsScalar>
 struct functor_traits<scalar_product_op<LhsScalar,RhsScalar> > {
   enum {
-    Cost = (NumTraits<LhsScalar>::MulCost + NumTraits<RhsScalar>::MulCost)/2, // rough estimate!
+    Cost = (int(NumTraits<LhsScalar>::MulCost) + int(NumTraits<RhsScalar>::MulCost))/2, // rough estimate!
     PacketAccess = is_same<LhsScalar,RhsScalar>::value && packet_traits<LhsScalar>::HasMul && packet_traits<RhsScalar>::HasMul
     // TODO vectorize mixed product
   };
 };
 
+template<>
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool scalar_product_op<bool,bool>::operator() (const bool& a, const bool& b) const { return a && b; }
+
+
 /** \internal
   * \brief Template functor to compute the conjugate product of two scalars
   *
   * This is a short cut for conj(x) * y which is needed for optimization purpose; in Eigen2 support mode, this becomes x * conj(y)
   */
 template<typename LhsScalar,typename RhsScalar>
 struct scalar_conj_product_op  : binary_op_base<LhsScalar,RhsScalar>
@@ -112,19 +110,19 @@
   enum {
     Conj = NumTraits<LhsScalar>::IsComplex
   };
   
   typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar,scalar_conj_product_op>::ReturnType result_type;
   
   EIGEN_EMPTY_STRUCT_CTOR(scalar_conj_product_op)
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator() (const LhsScalar& a, const RhsScalar& b) const
   { return conj_helper<LhsScalar,RhsScalar,Conj,false>().pmul(a,b); }
   
   template<typename Packet>
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const
   { return conj_helper<Packet,Packet,Conj,false>().pmul(a,b); }
 };
 template<typename LhsScalar,typename RhsScalar>
 struct functor_traits<scalar_conj_product_op<LhsScalar,RhsScalar> > {
   enum {
     Cost = NumTraits<LhsScalar>::MulCost,
     PacketAccess = internal::is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasMul
@@ -132,55 +130,69 @@
 };
 
 /** \internal
   * \brief Template functor to compute the min of two scalars
   *
   * \sa class CwiseBinaryOp, MatrixBase::cwiseMin, class VectorwiseOp, MatrixBase::minCoeff()
   */
-template<typename LhsScalar,typename RhsScalar>
+template<typename LhsScalar,typename RhsScalar, int NaNPropagation>
 struct scalar_min_op : binary_op_base<LhsScalar,RhsScalar>
 {
   typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar,scalar_min_op>::ReturnType result_type;
   EIGEN_EMPTY_STRUCT_CTOR(scalar_min_op)
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return numext::mini(a, b); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator() (const LhsScalar& a, const RhsScalar& b) const {
+    return internal::pmin<NaNPropagation>(a, b);
+  }
   template<typename Packet>
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const
-  { return internal::pmin(a,b); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const
+  {
+    return internal::pmin<NaNPropagation>(a,b);
+  }
   template<typename Packet>
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type predux(const Packet& a) const
-  { return internal::predux_min(a); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type predux(const Packet& a) const
+  {
+    return internal::predux_min<NaNPropagation>(a);
+  }
 };
-template<typename LhsScalar,typename RhsScalar>
-struct functor_traits<scalar_min_op<LhsScalar,RhsScalar> > {
+
+template<typename LhsScalar,typename RhsScalar, int NaNPropagation>
+struct functor_traits<scalar_min_op<LhsScalar,RhsScalar, NaNPropagation> > {
   enum {
     Cost = (NumTraits<LhsScalar>::AddCost+NumTraits<RhsScalar>::AddCost)/2,
     PacketAccess = internal::is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasMin
   };
 };
 
 /** \internal
   * \brief Template functor to compute the max of two scalars
   *
   * \sa class CwiseBinaryOp, MatrixBase::cwiseMax, class VectorwiseOp, MatrixBase::maxCoeff()
   */
-template<typename LhsScalar,typename RhsScalar>
-struct scalar_max_op  : binary_op_base<LhsScalar,RhsScalar>
+template<typename LhsScalar,typename RhsScalar, int NaNPropagation>
+struct scalar_max_op : binary_op_base<LhsScalar,RhsScalar>
 {
   typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar,scalar_max_op>::ReturnType result_type;
   EIGEN_EMPTY_STRUCT_CTOR(scalar_max_op)
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const { return numext::maxi(a, b); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type operator() (const LhsScalar& a, const RhsScalar& b) const {
+    return internal::pmax<NaNPropagation>(a,b);
+  }
   template<typename Packet>
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const
-  { return internal::pmax(a,b); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Packet packetOp(const Packet& a, const Packet& b) const
+  {
+    return internal::pmax<NaNPropagation>(a,b);
+  }
   template<typename Packet>
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type predux(const Packet& a) const
-  { return internal::predux_max(a); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE result_type predux(const Packet& a) const
+  {
+    return internal::predux_max<NaNPropagation>(a);
+  }
 };
-template<typename LhsScalar,typename RhsScalar>
-struct functor_traits<scalar_max_op<LhsScalar,RhsScalar> > {
+
+template<typename LhsScalar,typename RhsScalar, int NaNPropagation>
+struct functor_traits<scalar_max_op<LhsScalar,RhsScalar, NaNPropagation> > {
   enum {
     Cost = (NumTraits<LhsScalar>::AddCost+NumTraits<RhsScalar>::AddCost)/2,
     PacketAccess = internal::is_same<LhsScalar, RhsScalar>::value && packet_traits<LhsScalar>::HasMax
   };
 };
 
 /** \internal
@@ -249,15 +261,14 @@
 struct scalar_cmp_op<LhsScalar,RhsScalar, cmp_NEQ> : binary_op_base<LhsScalar,RhsScalar>
 {
   typedef bool result_type;
   EIGEN_EMPTY_STRUCT_CTOR(scalar_cmp_op)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool operator()(const LhsScalar& a, const RhsScalar& b) const {return a!=b;}
 };
 
-
 /** \internal
   * \brief Template functor to compute the hypot of two \b positive \b and \b real scalars
   *
   * \sa MatrixBase::stableNorm(), class Redux
   */
 template<typename Scalar>
 struct scalar_hypot_op<Scalar,Scalar> : binary_op_base<Scalar,Scalar>
@@ -283,38 +294,54 @@
            2 * scalar_div_cost<Scalar,false>::value,
     PacketAccess = false
   };
 };
 
 /** \internal
   * \brief Template functor to compute the pow of two scalars
+  * See the specification of pow in https://en.cppreference.com/w/cpp/numeric/math/pow
   */
 template<typename Scalar, typename Exponent>
 struct scalar_pow_op  : binary_op_base<Scalar,Exponent>
 {
   typedef typename ScalarBinaryOpTraits<Scalar,Exponent,scalar_pow_op>::ReturnType result_type;
 #ifndef EIGEN_SCALAR_BINARY_OP_PLUGIN
   EIGEN_EMPTY_STRUCT_CTOR(scalar_pow_op)
 #else
   scalar_pow_op() {
     typedef Scalar LhsScalar;
     typedef Exponent RhsScalar;
     EIGEN_SCALAR_BINARY_OP_PLUGIN
   }
 #endif
+
   EIGEN_DEVICE_FUNC
   inline result_type operator() (const Scalar& a, const Exponent& b) const { return numext::pow(a, b); }
+
+  template<typename Packet>
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const
+  {
+    return generic_pow(a,b);
+  }
 };
+
 template<typename Scalar, typename Exponent>
 struct functor_traits<scalar_pow_op<Scalar,Exponent> > {
-  enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = false };
+  enum {
+    Cost = 5 * NumTraits<Scalar>::MulCost,
+    PacketAccess = (!NumTraits<Scalar>::IsComplex && !NumTraits<Scalar>::IsInteger &&
+                    packet_traits<Scalar>::HasExp && packet_traits<Scalar>::HasLog &&
+                    packet_traits<Scalar>::HasRound && packet_traits<Scalar>::HasCmp &&
+                    // Temporarly disable packet access for half/bfloat16 until
+                    // accuracy is improved.
+                    !is_same<Scalar, half>::value && !is_same<Scalar, bfloat16>::value
+                    )
+  };
 };
 
-
-
 //---------- non associative binary functors ----------
 
 /** \internal
   * \brief Template functor to compute the difference of two scalars
   *
   * \sa class CwiseBinaryOp, MatrixBase::operator-
   */
@@ -333,15 +360,15 @@
   template<typename Packet>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const
   { return internal::psub(a,b); }
 };
 template<typename LhsScalar,typename RhsScalar>
 struct functor_traits<scalar_difference_op<LhsScalar,RhsScalar> > {
   enum {
-    Cost = (NumTraits<LhsScalar>::AddCost+NumTraits<RhsScalar>::AddCost)/2,
+    Cost = (int(NumTraits<LhsScalar>::AddCost) + int(NumTraits<RhsScalar>::AddCost)) / 2,
     PacketAccess = is_same<LhsScalar,RhsScalar>::value && packet_traits<LhsScalar>::HasSub && packet_traits<RhsScalar>::HasSub
   };
 };
 
 /** \internal
   * \brief Template functor to compute the quotient of two scalars
   *
@@ -378,51 +405,90 @@
   * \brief Template functor to compute the and of two booleans
   *
   * \sa class CwiseBinaryOp, ArrayBase::operator&&
   */
 struct scalar_boolean_and_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_boolean_and_op)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool operator() (const bool& a, const bool& b) const { return a && b; }
+  template<typename Packet>
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const
+  { return internal::pand(a,b); }
 };
 template<> struct functor_traits<scalar_boolean_and_op> {
   enum {
     Cost = NumTraits<bool>::AddCost,
-    PacketAccess = false
+    PacketAccess = true
   };
 };
 
 /** \internal
   * \brief Template functor to compute the or of two booleans
   *
   * \sa class CwiseBinaryOp, ArrayBase::operator||
   */
 struct scalar_boolean_or_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_boolean_or_op)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool operator() (const bool& a, const bool& b) const { return a || b; }
+  template<typename Packet>
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const
+  { return internal::por(a,b); }
 };
 template<> struct functor_traits<scalar_boolean_or_op> {
   enum {
     Cost = NumTraits<bool>::AddCost,
-    PacketAccess = false
+    PacketAccess = true
   };
 };
 
 /** \internal
  * \brief Template functor to compute the xor of two booleans
  *
  * \sa class CwiseBinaryOp, ArrayBase::operator^
  */
 struct scalar_boolean_xor_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_boolean_xor_op)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE bool operator() (const bool& a, const bool& b) const { return a ^ b; }
+  template<typename Packet>
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const
+  { return internal::pxor(a,b); }
 };
 template<> struct functor_traits<scalar_boolean_xor_op> {
   enum {
     Cost = NumTraits<bool>::AddCost,
-    PacketAccess = false
+    PacketAccess = true
+  };
+};
+
+/** \internal
+  * \brief Template functor to compute the absolute difference of two scalars
+  *
+  * \sa class CwiseBinaryOp, MatrixBase::absolute_difference
+  */
+template<typename LhsScalar,typename RhsScalar>
+struct scalar_absolute_difference_op : binary_op_base<LhsScalar,RhsScalar>
+{
+  typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar,scalar_absolute_difference_op>::ReturnType result_type;
+#ifndef EIGEN_SCALAR_BINARY_OP_PLUGIN
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_absolute_difference_op)
+#else
+  scalar_absolute_difference_op() {
+    EIGEN_SCALAR_BINARY_OP_PLUGIN
+  }
+#endif
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const LhsScalar& a, const RhsScalar& b) const
+  { return numext::absdiff(a,b); }
+  template<typename Packet>
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a, const Packet& b) const
+  { return internal::pabsdiff(a,b); }
+};
+template<typename LhsScalar,typename RhsScalar>
+struct functor_traits<scalar_absolute_difference_op<LhsScalar,RhsScalar> > {
+  enum {
+    Cost = (NumTraits<LhsScalar>::AddCost+NumTraits<RhsScalar>::AddCost)/2,
+    PacketAccess = is_same<LhsScalar,RhsScalar>::value && packet_traits<LhsScalar>::HasAbsDiff
   };
 };
 
 
 
 //---------- binary functors bound to a constant, thus appearing as a unary functor ----------
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/NullaryFunctors.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/NullaryFunctors.h`

 * *Files 6% similar despite different names*

```diff
@@ -40,61 +40,61 @@
 template <typename Scalar, bool IsInteger> struct linspaced_op_impl;
 
 template <typename Scalar>
 struct linspaced_op_impl<Scalar,/*IsInteger*/false>
 {
   typedef typename NumTraits<Scalar>::Real RealScalar;
 
-  linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps) :
-    m_low(low), m_high(high), m_size1(num_steps==1 ? 1 : num_steps-1), m_step(num_steps==1 ? Scalar() : (high-low)/RealScalar(num_steps-1)),
+  EIGEN_DEVICE_FUNC linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps) :
+    m_low(low), m_high(high), m_size1(num_steps==1 ? 1 : num_steps-1), m_step(num_steps==1 ? Scalar() : Scalar((high-low)/RealScalar(num_steps-1))),
     m_flip(numext::abs(high)<numext::abs(low))
   {}
 
   template<typename IndexType>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (IndexType i) const {
     if(m_flip)
-      return (i==0)? m_low : (m_high - RealScalar(m_size1-i)*m_step);
+      return (i==0)? m_low : Scalar(m_high - RealScalar(m_size1-i)*m_step);
     else
-      return (i==m_size1)? m_high : (m_low + RealScalar(i)*m_step);
+      return (i==m_size1)? m_high : Scalar(m_low + RealScalar(i)*m_step);
   }
 
   template<typename Packet, typename IndexType>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(IndexType i) const
   {
     // Principle:
     // [low, ..., low] + ( [step, ..., step] * ( [i, ..., i] + [0, ..., size] ) )
     if(m_flip)
     {
       Packet pi = plset<Packet>(Scalar(i-m_size1));
       Packet res = padd(pset1<Packet>(m_high), pmul(pset1<Packet>(m_step), pi));
-      if(i==0)
-        res = pinsertfirst(res, m_low);
-      return res;
+      if (EIGEN_PREDICT_TRUE(i != 0)) return res;
+      Packet mask = pcmp_lt(pset1<Packet>(0), plset<Packet>(0));
+      return pselect<Packet>(mask, res, pset1<Packet>(m_low));
     }
     else
     {
       Packet pi = plset<Packet>(Scalar(i));
       Packet res = padd(pset1<Packet>(m_low), pmul(pset1<Packet>(m_step), pi));
-      if(i==m_size1-unpacket_traits<Packet>::size+1)
-        res = pinsertlast(res, m_high);
-      return res;
+      if(EIGEN_PREDICT_TRUE(i != m_size1-unpacket_traits<Packet>::size+1)) return res;
+      Packet mask = pcmp_lt(plset<Packet>(0), pset1<Packet>(unpacket_traits<Packet>::size-1));
+      return pselect<Packet>(mask, res, pset1<Packet>(m_high));
     }
   }
 
   const Scalar m_low;
   const Scalar m_high;
   const Index m_size1;
   const Scalar m_step;
   const bool m_flip;
 };
 
 template <typename Scalar>
 struct linspaced_op_impl<Scalar,/*IsInteger*/true>
 {
-  linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps) :
+  EIGEN_DEVICE_FUNC linspaced_op_impl(const Scalar& low, const Scalar& high, Index num_steps) :
     m_low(low),
     m_multiplier((high-low)/convert_index<Scalar>(num_steps<=1 ? 1 : num_steps-1)),
     m_divisor(convert_index<Scalar>((high>=low?num_steps:-num_steps)+(high-low))/((numext::abs(high-low)+1)==0?1:(numext::abs(high-low)+1))),
     m_use_divisor(num_steps>1 && (numext::abs(high-low)+1)<num_steps)
   {}
 
   template<typename IndexType>
@@ -125,15 +125,15 @@
     PacketAccess =   (!NumTraits<Scalar>::IsInteger) && packet_traits<Scalar>::HasSetLinear && packet_traits<Scalar>::HasBlend,
                   /*&& ((!NumTraits<Scalar>::IsInteger) || packet_traits<Scalar>::HasDiv),*/ // <- vectorization for integer is currently disabled
     IsRepeatable = true
   };
 };
 template <typename Scalar> struct linspaced_op
 {
-  linspaced_op(const Scalar& low, const Scalar& high, Index num_steps)
+  EIGEN_DEVICE_FUNC linspaced_op(const Scalar& low, const Scalar& high, Index num_steps)
     : impl((num_steps==1 ? high : low),high,num_steps)
   {}
 
   template<typename IndexType>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (IndexType i) const { return impl(i); }
 
   template<typename Packet,typename IndexType>
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/StlFunctors.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/StlFunctors.h`

 * *Files 11% similar despite different names*

```diff
@@ -8,14 +8,36 @@
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_STL_FUNCTORS_H
 #define EIGEN_STL_FUNCTORS_H
 
 namespace Eigen {
 
+// Portable replacements for certain functors.
+namespace numext {
+
+template<typename T = void>
+struct equal_to {
+  typedef bool result_type;
+  EIGEN_DEVICE_FUNC bool operator()(const T& lhs, const T& rhs) const {
+    return lhs == rhs;
+  }
+};
+
+template<typename T = void>
+struct not_equal_to {
+  typedef bool result_type;
+  EIGEN_DEVICE_FUNC bool operator()(const T& lhs, const T& rhs) const {
+    return lhs != rhs;
+  }
+};
+
+}
+
+
 namespace internal {
 
 // default functor traits for STL functors:
 
 template<typename T>
 struct functor_traits<std::multiplies<T> >
 { enum { Cost = NumTraits<T>::MulCost, PacketAccess = false }; };
@@ -65,29 +87,37 @@
 { enum { Cost = 1, PacketAccess = false }; };
 
 template<typename T>
 struct functor_traits<std::equal_to<T> >
 { enum { Cost = 1, PacketAccess = false }; };
 
 template<typename T>
+struct functor_traits<numext::equal_to<T> >
+  : functor_traits<std::equal_to<T> > {};
+
+template<typename T>
 struct functor_traits<std::not_equal_to<T> >
 { enum { Cost = 1, PacketAccess = false }; };
 
-#if (__cplusplus < 201103L) && (EIGEN_COMP_MSVC <= 1900)
+template<typename T>
+struct functor_traits<numext::not_equal_to<T> >
+  : functor_traits<std::not_equal_to<T> > {};
+
+#if (EIGEN_COMP_CXXVER < 11)
 // std::binder* are deprecated since c++11 and will be removed in c++17
 template<typename T>
 struct functor_traits<std::binder2nd<T> >
 { enum { Cost = functor_traits<T>::Cost, PacketAccess = false }; };
 
 template<typename T>
 struct functor_traits<std::binder1st<T> >
 { enum { Cost = functor_traits<T>::Cost, PacketAccess = false }; };
 #endif
 
-#if (__cplusplus < 201703L) && (EIGEN_COMP_MSVC < 1910)
+#if (EIGEN_COMP_CXXVER < 17)
 // std::unary_negate is deprecated since c++17 and will be removed in c++20
 template<typename T>
 struct functor_traits<std::unary_negate<T> >
 { enum { Cost = 1 + functor_traits<T>::Cost, PacketAccess = false }; };
 
 // std::binary_negate is deprecated since c++17 and will be removed in c++20
 template<typename T>
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/TernaryFunctors.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/TernaryFunctors.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/functors/UnaryFunctors.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/functors/UnaryFunctors.h`

 * *Files 2% similar despite different names*

```diff
@@ -105,15 +105,15 @@
   * \brief Template functor to compute the conjugate of a complex value
   *
   * \sa class CwiseUnaryOp, MatrixBase::conjugate()
   */
 template<typename Scalar> struct scalar_conjugate_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_conjugate_op)
   EIGEN_DEVICE_FUNC
-  EIGEN_STRONG_INLINE const Scalar operator() (const Scalar& a) const { using numext::conj; return conj(a); }
+  EIGEN_STRONG_INLINE const Scalar operator() (const Scalar& a) const { return numext::conj(a); }
   template<typename Packet>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const { return internal::pconj(a); }
 };
 template<typename Scalar>
 struct functor_traits<scalar_conjugate_op<Scalar> >
 {
   enum {
@@ -134,15 +134,15 @@
   * \brief Template functor to compute the phase angle of a complex
   *
   * \sa class CwiseUnaryOp, Cwise::arg
   */
 template<typename Scalar> struct scalar_arg_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_arg_op)
   typedef typename NumTraits<Scalar>::Real result_type;
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const Scalar& a) const { using numext::arg; return arg(a); }
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const result_type operator() (const Scalar& a) const { return numext::arg(a); }
   template<typename Packet>
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const
   { return internal::parg(a); }
 };
 template<typename Scalar>
 struct functor_traits<scalar_arg_op<Scalar> >
 {
@@ -163,14 +163,52 @@
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const NewType operator() (const Scalar& a) const { return cast<Scalar, NewType>(a); }
 };
 template<typename Scalar, typename NewType>
 struct functor_traits<scalar_cast_op<Scalar,NewType> >
 { enum { Cost = is_same<Scalar, NewType>::value ? 0 : NumTraits<NewType>::AddCost, PacketAccess = false }; };
 
 /** \internal
+  * \brief Template functor to arithmetically shift a scalar right by a number of bits
+  *
+  * \sa class CwiseUnaryOp, MatrixBase::shift_right()
+  */
+template<typename Scalar, int N>
+struct scalar_shift_right_op {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_shift_right_op)
+
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (const Scalar& a) const
+  { return a >> N; }
+  template<typename Packet>
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const
+  { return internal::parithmetic_shift_right<N>(a); }
+};
+template<typename Scalar, int N>
+struct functor_traits<scalar_shift_right_op<Scalar,N> >
+{ enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasShift }; };
+
+/** \internal
+  * \brief Template functor to logically shift a scalar left by a number of bits
+  *
+  * \sa class CwiseUnaryOp, MatrixBase::shift_left()
+  */
+template<typename Scalar, int N>
+struct scalar_shift_left_op {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_shift_left_op)
+
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (const Scalar& a) const
+  { return a << N; }
+  template<typename Packet>
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Packet packetOp(const Packet& a) const
+  { return internal::plogical_shift_left<N>(a); }
+};
+template<typename Scalar, int N>
+struct functor_traits<scalar_shift_left_op<Scalar,N> >
+{ enum { Cost = NumTraits<Scalar>::AddCost, PacketAccess = packet_traits<Scalar>::HasShift }; };
+
+/** \internal
   * \brief Template functor to extract the real part of a complex
   *
   * \sa class CwiseUnaryOp, MatrixBase::real()
   */
 template<typename Scalar>
 struct scalar_real_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_real_op)
@@ -345,23 +383,39 @@
   *
   * \brief Template functor to compute the base-10 logarithm of a scalar
   *
   * \sa class CwiseUnaryOp, Cwise::log10()
   */
 template<typename Scalar> struct scalar_log10_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_log10_op)
-  EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { EIGEN_USING_STD_MATH(log10) return log10(a); }
+  EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { EIGEN_USING_STD(log10) return log10(a); }
   template <typename Packet>
   EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return internal::plog10(a); }
 };
 template<typename Scalar>
 struct functor_traits<scalar_log10_op<Scalar> >
 { enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasLog10 }; };
 
 /** \internal
+  *
+  * \brief Template functor to compute the base-2 logarithm of a scalar
+  *
+  * \sa class CwiseUnaryOp, Cwise::log2()
+  */
+template<typename Scalar> struct scalar_log2_op {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_log2_op)
+  EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { return Scalar(EIGEN_LOG2E) * numext::log(a); }
+  template <typename Packet>
+  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return internal::plog2(a); }
+};
+template<typename Scalar>
+struct functor_traits<scalar_log2_op<Scalar> >
+{ enum { Cost = 5 * NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasLog }; };
+
+/** \internal
   * \brief Template functor to compute the square root of a scalar
   * \sa class CwiseUnaryOp, Cwise::sqrt()
   */
 template<typename Scalar> struct scalar_sqrt_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_sqrt_op)
   EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { return numext::sqrt(a); }
   template <typename Packet>
@@ -380,21 +434,33 @@
     // The following numbers are based on min VSQRT throughput on Haswell.
     Cost = (sizeof(Scalar) == 8 ? 28 : 14),
 #endif
     PacketAccess = packet_traits<Scalar>::HasSqrt
   };
 };
 
+// Boolean specialization to eliminate -Wimplicit-conversion-floating-point-to-bool warnings.
+template<> struct scalar_sqrt_op<bool> {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_sqrt_op)
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline bool operator() (const bool& a) const { return a; }
+  template <typename Packet>
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return a; }
+};
+template <>
+struct functor_traits<scalar_sqrt_op<bool> > {
+  enum { Cost = 1, PacketAccess = packet_traits<bool>::Vectorizable };
+};
+
 /** \internal
   * \brief Template functor to compute the reciprocal square root of a scalar
   * \sa class CwiseUnaryOp, Cwise::rsqrt()
   */
 template<typename Scalar> struct scalar_rsqrt_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_rsqrt_op)
-  EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { return Scalar(1)/numext::sqrt(a); }
+  EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const { return numext::rsqrt(a); }
   template <typename Packet>
   EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return internal::prsqrt(a); }
 };
 
 template<typename Scalar>
 struct functor_traits<scalar_rsqrt_op<Scalar> >
 { enum {
@@ -677,14 +743,27 @@
   EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const
   { return internal::pmul(a,a); }
 };
 template<typename Scalar>
 struct functor_traits<scalar_square_op<Scalar> >
 { enum { Cost = NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasMul }; };
 
+// Boolean specialization to avoid -Wint-in-bool-context warnings on GCC.
+template<>
+struct scalar_square_op<bool> {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_square_op)
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline bool operator() (const bool& a) const { return a; }
+  template<typename Packet>
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const
+  { return a; }
+};
+template<>
+struct functor_traits<scalar_square_op<bool> >
+{ enum { Cost = 0, PacketAccess = packet_traits<bool>::Vectorizable }; };
+
 /** \internal
   * \brief Template functor to compute the cube of a scalar
   * \sa class CwiseUnaryOp, Cwise::cube()
   */
 template<typename Scalar>
 struct scalar_cube_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_cube_op)
@@ -693,14 +772,27 @@
   EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const
   { return internal::pmul(a,pmul(a,a)); }
 };
 template<typename Scalar>
 struct functor_traits<scalar_cube_op<Scalar> >
 { enum { Cost = 2*NumTraits<Scalar>::MulCost, PacketAccess = packet_traits<Scalar>::HasMul }; };
 
+// Boolean specialization to avoid -Wint-in-bool-context warnings on GCC.
+template<>
+struct scalar_cube_op<bool> {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_cube_op)
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline bool operator() (const bool& a) const { return a; }
+  template<typename Packet>
+  EIGEN_DEPRECATED EIGEN_DEVICE_FUNC inline const Packet packetOp(const Packet& a) const
+  { return a; }
+};
+template<>
+struct functor_traits<scalar_cube_op<bool> >
+{ enum { Cost = 0, PacketAccess = packet_traits<bool>::Vectorizable }; };
+
 /** \internal
   * \brief Template functor to compute the rounded value of a scalar
   * \sa class CwiseUnaryOp, ArrayBase::round()
   */
 template<typename Scalar> struct scalar_round_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_round_op)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (const Scalar& a) const { return numext::round(a); }
@@ -732,14 +824,33 @@
   enum {
     Cost = NumTraits<Scalar>::MulCost,
     PacketAccess = packet_traits<Scalar>::HasFloor
   };
 };
 
 /** \internal
+  * \brief Template functor to compute the rounded (with current rounding mode)  value of a scalar
+  * \sa class CwiseUnaryOp, ArrayBase::rint()
+  */
+template<typename Scalar> struct scalar_rint_op {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_rint_op)
+  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (const Scalar& a) const { return numext::rint(a); }
+  template <typename Packet>
+  EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return internal::print(a); }
+};
+template<typename Scalar>
+struct functor_traits<scalar_rint_op<Scalar> >
+{
+  enum {
+    Cost = NumTraits<Scalar>::MulCost,
+    PacketAccess = packet_traits<Scalar>::HasRint
+  };
+};
+
+/** \internal
   * \brief Template functor to compute the ceil of a scalar
   * \sa class CwiseUnaryOp, ArrayBase::ceil()
   */
 template<typename Scalar> struct scalar_ceil_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_ceil_op)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Scalar operator() (const Scalar& a) const { return numext::ceil(a); }
   template <typename Packet>
@@ -843,37 +954,50 @@
   };
 };
 
 /** \internal
   * \brief Template functor to compute the signum of a scalar
   * \sa class CwiseUnaryOp, Cwise::sign()
   */
-template<typename Scalar,bool iscpx=(NumTraits<Scalar>::IsComplex!=0) > struct scalar_sign_op;
+template<typename Scalar,bool is_complex=(NumTraits<Scalar>::IsComplex!=0), bool is_integer=(NumTraits<Scalar>::IsInteger!=0) > struct scalar_sign_op;
 template<typename Scalar>
-struct scalar_sign_op<Scalar,false> {
+struct scalar_sign_op<Scalar, false, true> {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_sign_op)
   EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const
   {
       return Scalar( (a>Scalar(0)) - (a<Scalar(0)) );
   }
   //TODO
   //template <typename Packet>
   //EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return internal::psign(a); }
 };
+
 template<typename Scalar>
-struct scalar_sign_op<Scalar,true> {
+struct scalar_sign_op<Scalar, false, false> {
+  EIGEN_EMPTY_STRUCT_CTOR(scalar_sign_op)
+  EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const
+  {
+    return (numext::isnan)(a) ? a : Scalar( (a>Scalar(0)) - (a<Scalar(0)) );
+  }
+  //TODO
+  //template <typename Packet>
+  //EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return internal::psign(a); }
+};
+
+template<typename Scalar, bool is_integer>
+struct scalar_sign_op<Scalar,true, is_integer> {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_sign_op)
   EIGEN_DEVICE_FUNC inline const Scalar operator() (const Scalar& a) const
   {
     typedef typename NumTraits<Scalar>::Real real_type;
     real_type aa = numext::abs(a);
     if (aa==real_type(0))
       return Scalar(0);
     aa = real_type(1)/aa;
-    return Scalar(real(a)*aa, imag(a)*aa );
+    return Scalar(a.real()*aa, a.imag()*aa );
   }
   //TODO
   //template <typename Packet>
   //EIGEN_DEVICE_FUNC inline Packet packetOp(const Packet& a) const { return internal::psign(a); }
 };
 template<typename Scalar>
 struct functor_traits<scalar_sign_op<Scalar> >
@@ -890,94 +1014,109 @@
   * \brief Template functor to compute the logistic function of a scalar
   * \sa class CwiseUnaryOp, ArrayBase::logistic()
   */
 template <typename T>
 struct scalar_logistic_op {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_logistic_op)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T operator()(const T& x) const {
-    const T one = T(1);
-    return one / (one + numext::exp(-x));
+    return packetOp(x);
   }
 
   template <typename Packet> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   Packet packetOp(const Packet& x) const {
     const Packet one = pset1<Packet>(T(1));
     return pdiv(one, padd(one, pexp(pnegate(x))));
   }
 };
 
+#ifndef EIGEN_GPU_COMPILE_PHASE
 /** \internal
   * \brief Template specialization of the logistic function for float.
   *
   *  Uses just a 9/10-degree rational interpolant which
-  *  interpolates 1/(1+exp(-x)) - 0.5 up to a couple of ulp in the range
-  *  [-18, 18], outside of which the fl(logistic(x)) = {0|1}. The shifted
-  *  logistic is interpolated because it was easier to make the fit converge.
+  *  interpolates 1/(1+exp(-x)) - 0.5 up to a couple of ulps in the range
+  *  [-9, 18]. Below -9 we use the more accurate approximation
+  *  1/(1+exp(-x)) ~= exp(x), and above 18 the logistic function is 1 withing
+  *  one ulp. The shifted logistic is interpolated because it was easier to
+  *  make the fit converge.
   *
   */
-
 template <>
 struct scalar_logistic_op<float> {
   EIGEN_EMPTY_STRUCT_CTOR(scalar_logistic_op)
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE float operator()(const float& x) const {
-    if (x < -18.0f) return 0.0f;
-    else if (x > 18.0f) return 1.0f;
-    else return 1.0f / (1.0f + numext::exp(-x));
+    return packetOp(x);
   }
 
   template <typename Packet> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
   Packet packetOp(const Packet& _x) const {
-    // Clamp the inputs to the range [-18, 18] since anything outside
-    // this range is 0.0f or 1.0f in single-precision.
-    const Packet x = pmax(pmin(_x, pset1<Packet>(18.0)), pset1<Packet>(-18.0));
+    const Packet cutoff_lower = pset1<Packet>(-9.f);
+    const Packet lt_mask = pcmp_lt<Packet>(_x, cutoff_lower);
+    const bool any_small = predux_any(lt_mask);
+
+    // The upper cut-off is the smallest x for which the rational approximation evaluates to 1.
+    // Choosing this value saves us a few instructions clamping the results at the end.
+#ifdef EIGEN_VECTORIZE_FMA
+    const Packet cutoff_upper = pset1<Packet>(15.7243833541870117f);
+#else
+    const Packet cutoff_upper = pset1<Packet>(15.6437711715698242f);
+#endif
+    const Packet x = pmin(_x, cutoff_upper);
 
     // The monomial coefficients of the numerator polynomial (odd).
-    const Packet alpha_1 = pset1<Packet>(2.48287947061529e-01);
-    const Packet alpha_3 = pset1<Packet>(8.51377133304701e-03);
-    const Packet alpha_5 = pset1<Packet>(6.08574864600143e-05);
-    const Packet alpha_7 = pset1<Packet>(1.15627324459942e-07);
-    const Packet alpha_9 = pset1<Packet>(4.37031012579801e-11);
+    const Packet alpha_1 = pset1<Packet>(2.48287947061529e-01f);
+    const Packet alpha_3 = pset1<Packet>(8.51377133304701e-03f);
+    const Packet alpha_5 = pset1<Packet>(6.08574864600143e-05f);
+    const Packet alpha_7 = pset1<Packet>(1.15627324459942e-07f);
+    const Packet alpha_9 = pset1<Packet>(4.37031012579801e-11f);
 
     // The monomial coefficients of the denominator polynomial (even).
-    const Packet beta_0 = pset1<Packet>(9.93151921023180e-01);
-    const Packet beta_2 = pset1<Packet>(1.16817656904453e-01);
-    const Packet beta_4 = pset1<Packet>(1.70198817374094e-03);
-    const Packet beta_6 = pset1<Packet>(6.29106785017040e-06);
-    const Packet beta_8 = pset1<Packet>(5.76102136993427e-09);
-    const Packet beta_10 = pset1<Packet>(6.10247389755681e-13);
+    const Packet beta_0 = pset1<Packet>(9.93151921023180e-01f);
+    const Packet beta_2 = pset1<Packet>(1.16817656904453e-01f);
+    const Packet beta_4 = pset1<Packet>(1.70198817374094e-03f);
+    const Packet beta_6 = pset1<Packet>(6.29106785017040e-06f);
+    const Packet beta_8 = pset1<Packet>(5.76102136993427e-09f);
+    const Packet beta_10 = pset1<Packet>(6.10247389755681e-13f);
 
     // Since the polynomials are odd/even, we need x^2.
     const Packet x2 = pmul(x, x);
 
     // Evaluate the numerator polynomial p.
     Packet p = pmadd(x2, alpha_9, alpha_7);
     p = pmadd(x2, p, alpha_5);
     p = pmadd(x2, p, alpha_3);
     p = pmadd(x2, p, alpha_1);
     p = pmul(x, p);
 
-    // Evaluate the denominator polynomial p.
+    // Evaluate the denominator polynomial q.
     Packet q = pmadd(x2, beta_10, beta_8);
     q = pmadd(x2, q, beta_6);
     q = pmadd(x2, q, beta_4);
     q = pmadd(x2, q, beta_2);
     q = pmadd(x2, q, beta_0);
-
     // Divide the numerator by the denominator and shift it up.
-    return pmax(pmin(padd(pdiv(p, q), pset1<Packet>(0.5)), pset1<Packet>(1.0)),
-                pset1<Packet>(0.0));
+    const Packet logistic = padd(pdiv(p, q), pset1<Packet>(0.5f));
+    if (EIGEN_PREDICT_FALSE(any_small)) {
+      const Packet exponential = pexp(_x);
+      return pselect(lt_mask, exponential, logistic);
+    } else {
+      return logistic;
+    }
   }
 };
+#endif  // #ifndef EIGEN_GPU_COMPILE_PHASE
 
 template <typename T>
 struct functor_traits<scalar_logistic_op<T> > {
   enum {
+    // The cost estimate for float here here is for the common(?) case where
+    // all arguments are greater than -9.
     Cost = scalar_div_cost<T, packet_traits<T>::HasDiv>::value +
            (internal::is_same<T, float>::value
-                ? NumTraits<T>::AddCost * 12 + NumTraits<T>::MulCost * 11
+                ? NumTraits<T>::AddCost * 15 + NumTraits<T>::MulCost * 11
                 : NumTraits<T>::AddCost * 2 +
                       functor_traits<scalar_exp_op<T> >::Cost),
     PacketAccess =
         packet_traits<T>::HasAdd && packet_traits<T>::HasDiv &&
         (internal::is_same<T, float>::value
              ? packet_traits<T>::HasMul && packet_traits<T>::HasMax &&
                    packet_traits<T>::HasMin
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralBlockPanelKernel.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralBlockPanelKernel.h`

 * *Files 8% similar despite different names*

```diff
@@ -52,6992 +52,6727 @@
 00000330: 6520 7374 643a 3a70 7472 6469 6666 5f74  e std::ptrdiff_t
 00000340: 206d 616e 6167 655f 6361 6368 696e 675f   manage_caching_
 00000350: 7369 7a65 735f 6865 6c70 6572 2873 7464  sizes_helper(std
 00000360: 3a3a 7074 7264 6966 665f 7420 612c 2073  ::ptrdiff_t a, s
 00000370: 7464 3a3a 7074 7264 6966 665f 7420 6229  td::ptrdiff_t b)
 00000380: 0a7b 0a20 2072 6574 7572 6e20 613c 3d30  .{.  return a<=0
 00000390: 203f 2062 203a 2061 3b0a 7d0a 0a23 6966   ? b : a;.}..#if
-000003a0: 2045 4947 454e 5f41 5243 485f 6933 3836   EIGEN_ARCH_i386
-000003b0: 5f4f 525f 7838 365f 3634 0a63 6f6e 7374  _OR_x86_64.const
-000003c0: 2073 7464 3a3a 7074 7264 6966 665f 7420   std::ptrdiff_t 
-000003d0: 6465 6661 756c 744c 3143 6163 6865 5369  defaultL1CacheSi
-000003e0: 7a65 203d 2033 322a 3130 3234 3b0a 636f  ze = 32*1024;.co
-000003f0: 6e73 7420 7374 643a 3a70 7472 6469 6666  nst std::ptrdiff
-00000400: 5f74 2064 6566 6175 6c74 4c32 4361 6368  _t defaultL2Cach
-00000410: 6553 697a 6520 3d20 3235 362a 3130 3234  eSize = 256*1024
-00000420: 3b0a 636f 6e73 7420 7374 643a 3a70 7472  ;.const std::ptr
-00000430: 6469 6666 5f74 2064 6566 6175 6c74 4c33  diff_t defaultL3
-00000440: 4361 6368 6553 697a 6520 3d20 322a 3130  CacheSize = 2*10
-00000450: 3234 2a31 3032 343b 0a23 656c 7365 0a63  24*1024;.#else.c
-00000460: 6f6e 7374 2073 7464 3a3a 7074 7264 6966  onst std::ptrdif
-00000470: 665f 7420 6465 6661 756c 744c 3143 6163  f_t defaultL1Cac
-00000480: 6865 5369 7a65 203d 2031 362a 3130 3234  heSize = 16*1024
-00000490: 3b0a 636f 6e73 7420 7374 643a 3a70 7472  ;.const std::ptr
-000004a0: 6469 6666 5f74 2064 6566 6175 6c74 4c32  diff_t defaultL2
-000004b0: 4361 6368 6553 697a 6520 3d20 3531 322a  CacheSize = 512*
-000004c0: 3130 3234 3b0a 636f 6e73 7420 7374 643a  1024;.const std:
-000004d0: 3a70 7472 6469 6666 5f74 2064 6566 6175  :ptrdiff_t defau
-000004e0: 6c74 4c33 4361 6368 6553 697a 6520 3d20  ltL3CacheSize = 
-000004f0: 3531 322a 3130 3234 3b0a 2365 6e64 6966  512*1024;.#endif
-00000500: 0a0a 2f2a 2a20 5c69 6e74 6572 6e61 6c20  ../** \internal 
-00000510: 2a2f 0a73 7472 7563 7420 4361 6368 6553  */.struct CacheS
-00000520: 697a 6573 207b 0a20 2043 6163 6865 5369  izes {.  CacheSi
-00000530: 7a65 7328 293a 206d 5f6c 3128 2d31 292c  zes(): m_l1(-1),
-00000540: 6d5f 6c32 282d 3129 2c6d 5f6c 3328 2d31  m_l2(-1),m_l3(-1
-00000550: 2920 7b0a 2020 2020 696e 7420 6c31 4361  ) {.    int l1Ca
-00000560: 6368 6553 697a 652c 206c 3243 6163 6865  cheSize, l2Cache
-00000570: 5369 7a65 2c20 6c33 4361 6368 6553 697a  Size, l3CacheSiz
-00000580: 653b 0a20 2020 2071 7565 7279 4361 6368  e;.    queryCach
-00000590: 6553 697a 6573 286c 3143 6163 6865 5369  eSizes(l1CacheSi
-000005a0: 7a65 2c20 6c32 4361 6368 6553 697a 652c  ze, l2CacheSize,
-000005b0: 206c 3343 6163 6865 5369 7a65 293b 0a20   l3CacheSize);. 
-000005c0: 2020 206d 5f6c 3120 3d20 6d61 6e61 6765     m_l1 = manage
-000005d0: 5f63 6163 6869 6e67 5f73 697a 6573 5f68  _caching_sizes_h
-000005e0: 656c 7065 7228 6c31 4361 6368 6553 697a  elper(l1CacheSiz
-000005f0: 652c 2064 6566 6175 6c74 4c31 4361 6368  e, defaultL1Cach
-00000600: 6553 697a 6529 3b0a 2020 2020 6d5f 6c32  eSize);.    m_l2
-00000610: 203d 206d 616e 6167 655f 6361 6368 696e   = manage_cachin
-00000620: 675f 7369 7a65 735f 6865 6c70 6572 286c  g_sizes_helper(l
-00000630: 3243 6163 6865 5369 7a65 2c20 6465 6661  2CacheSize, defa
-00000640: 756c 744c 3243 6163 6865 5369 7a65 293b  ultL2CacheSize);
-00000650: 0a20 2020 206d 5f6c 3320 3d20 6d61 6e61  .    m_l3 = mana
-00000660: 6765 5f63 6163 6869 6e67 5f73 697a 6573  ge_caching_sizes
-00000670: 5f68 656c 7065 7228 6c33 4361 6368 6553  _helper(l3CacheS
-00000680: 697a 652c 2064 6566 6175 6c74 4c33 4361  ize, defaultL3Ca
-00000690: 6368 6553 697a 6529 3b0a 2020 7d0a 0a20  cheSize);.  }.. 
-000006a0: 2073 7464 3a3a 7074 7264 6966 665f 7420   std::ptrdiff_t 
-000006b0: 6d5f 6c31 3b0a 2020 7374 643a 3a70 7472  m_l1;.  std::ptr
-000006c0: 6469 6666 5f74 206d 5f6c 323b 0a20 2073  diff_t m_l2;.  s
-000006d0: 7464 3a3a 7074 7264 6966 665f 7420 6d5f  td::ptrdiff_t m_
-000006e0: 6c33 3b0a 7d3b 0a0a 0a2f 2a2a 205c 696e  l3;.};.../** \in
-000006f0: 7465 726e 616c 202a 2f0a 696e 6c69 6e65  ternal */.inline
-00000700: 2076 6f69 6420 6d61 6e61 6765 5f63 6163   void manage_cac
-00000710: 6869 6e67 5f73 697a 6573 2841 6374 696f  hing_sizes(Actio
-00000720: 6e20 6163 7469 6f6e 2c20 7374 643a 3a70  n action, std::p
-00000730: 7472 6469 6666 5f74 2a20 6c31 2c20 7374  trdiff_t* l1, st
-00000740: 643a 3a70 7472 6469 6666 5f74 2a20 6c32  d::ptrdiff_t* l2
-00000750: 2c20 7374 643a 3a70 7472 6469 6666 5f74  , std::ptrdiff_t
-00000760: 2a20 6c33 290a 7b0a 2020 7374 6174 6963  * l3).{.  static
-00000770: 2043 6163 6865 5369 7a65 7320 6d5f 6361   CacheSizes m_ca
-00000780: 6368 6553 697a 6573 3b0a 0a20 2069 6628  cheSizes;..  if(
-00000790: 6163 7469 6f6e 3d3d 5365 7441 6374 696f  action==SetActio
-000007a0: 6e29 0a20 207b 0a20 2020 202f 2f20 7365  n).  {.    // se
-000007b0: 7420 7468 6520 6370 7520 6361 6368 6520  t the cpu cache 
-000007c0: 7369 7a65 2061 6e64 2063 6163 6865 2061  size and cache a
-000007d0: 6c6c 2062 6c6f 636b 2073 697a 6573 2066  ll block sizes f
-000007e0: 726f 6d20 6120 676c 6f62 616c 2063 6163  rom a global cac
-000007f0: 6865 2073 697a 6520 696e 2062 7974 650a  he size in byte.
-00000800: 2020 2020 6569 6765 6e5f 696e 7465 726e      eigen_intern
-00000810: 616c 5f61 7373 6572 7428 6c31 213d 3020  al_assert(l1!=0 
-00000820: 2626 206c 3221 3d30 293b 0a20 2020 206d  && l2!=0);.    m
-00000830: 5f63 6163 6865 5369 7a65 732e 6d5f 6c31  _cacheSizes.m_l1
-00000840: 203d 202a 6c31 3b0a 2020 2020 6d5f 6361   = *l1;.    m_ca
-00000850: 6368 6553 697a 6573 2e6d 5f6c 3220 3d20  cheSizes.m_l2 = 
-00000860: 2a6c 323b 0a20 2020 206d 5f63 6163 6865  *l2;.    m_cache
-00000870: 5369 7a65 732e 6d5f 6c33 203d 202a 6c33  Sizes.m_l3 = *l3
-00000880: 3b0a 2020 7d0a 2020 656c 7365 2069 6628  ;.  }.  else if(
-00000890: 6163 7469 6f6e 3d3d 4765 7441 6374 696f  action==GetActio
-000008a0: 6e29 0a20 207b 0a20 2020 2065 6967 656e  n).  {.    eigen
-000008b0: 5f69 6e74 6572 6e61 6c5f 6173 7365 7274  _internal_assert
-000008c0: 286c 3121 3d30 2026 2620 6c32 213d 3029  (l1!=0 && l2!=0)
-000008d0: 3b0a 2020 2020 2a6c 3120 3d20 6d5f 6361  ;.    *l1 = m_ca
-000008e0: 6368 6553 697a 6573 2e6d 5f6c 313b 0a20  cheSizes.m_l1;. 
-000008f0: 2020 202a 6c32 203d 206d 5f63 6163 6865     *l2 = m_cache
-00000900: 5369 7a65 732e 6d5f 6c32 3b0a 2020 2020  Sizes.m_l2;.    
-00000910: 2a6c 3320 3d20 6d5f 6361 6368 6553 697a  *l3 = m_cacheSiz
-00000920: 6573 2e6d 5f6c 333b 0a20 207d 0a20 2065  es.m_l3;.  }.  e
-00000930: 6c73 650a 2020 7b0a 2020 2020 6569 6765  lse.  {.    eige
-00000940: 6e5f 696e 7465 726e 616c 5f61 7373 6572  n_internal_asser
-00000950: 7428 6661 6c73 6529 3b0a 2020 7d0a 7d0a  t(false);.  }.}.
-00000960: 0a2f 2a20 4865 6c70 6572 2066 6f72 2063  ./* Helper for c
-00000970: 6f6d 7075 7465 5072 6f64 7563 7442 6c6f  omputeProductBlo
-00000980: 636b 696e 6753 697a 6573 2e0a 202a 0a20  ckingSizes.. *. 
-00000990: 2a20 4769 7665 6e20 6120 6d20 7820 6b20  * Given a m x k 
-000009a0: 7469 6d65 7320 6b20 7820 6e20 6d61 7472  times k x n matr
-000009b0: 6978 2070 726f 6475 6374 206f 6620 7363  ix product of sc
-000009c0: 616c 6172 2074 7970 6573 205c 6320 4c68  alar types \c Lh
-000009d0: 7353 6361 6c61 7220 616e 6420 5c63 2052  sScalar and \c R
-000009e0: 6873 5363 616c 6172 2c0a 202a 2074 6869  hsScalar,. * thi
-000009f0: 7320 6675 6e63 7469 6f6e 2063 6f6d 7075  s function compu
-00000a00: 7465 7320 7468 6520 626c 6f63 6b69 6e67  tes the blocking
-00000a10: 2073 697a 6520 7061 7261 6d65 7465 7273   size parameters
-00000a20: 2061 6c6f 6e67 2074 6865 2072 6573 7065   along the respe
-00000a30: 6374 6976 6520 6469 6d65 6e73 696f 6e73  ctive dimensions
-00000a40: 0a20 2a20 666f 7220 6d61 7472 6978 2070  . * for matrix p
-00000a50: 726f 6475 6374 7320 616e 6420 7265 6c61  roducts and rela
-00000a60: 7465 6420 616c 676f 7269 7468 6d73 2e20  ted algorithms. 
-00000a70: 5468 6520 626c 6f63 6b69 6e67 2073 697a  The blocking siz
-00000a80: 6573 2064 6570 656e 6473 206f 6e20 7661  es depends on va
-00000a90: 7269 6f75 730a 202a 2070 6172 616d 6574  rious. * paramet
-00000aa0: 6572 733a 0a20 2a20 2d20 7468 6520 4c31  ers:. * - the L1
-00000ab0: 2061 6e64 204c 3220 6361 6368 6520 7369   and L2 cache si
-00000ac0: 7a65 732c 0a20 2a20 2d20 7468 6520 7265  zes,. * - the re
-00000ad0: 6769 7374 6572 206c 6576 656c 2062 6c6f  gister level blo
-00000ae0: 636b 696e 6720 7369 7a65 7320 6465 6669  cking sizes defi
-00000af0: 6e65 6420 6279 2067 6562 705f 7472 6169  ned by gebp_trai
-00000b00: 7473 2c0a 202a 202d 2074 6865 206e 756d  ts,. * - the num
-00000b10: 6265 7220 6f66 2073 6361 6c61 7273 2074  ber of scalars t
-00000b20: 6861 7420 6669 7420 696e 746f 2061 2070  hat fit into a p
-00000b30: 6163 6b65 7420 2877 6865 6e20 7665 6374  acket (when vect
-00000b40: 6f72 697a 6174 696f 6e20 6973 2065 6e61  orization is ena
-00000b50: 626c 6564 292e 0a20 2a0a 202a 205c 7361  bled).. *. * \sa
-00000b60: 2073 6574 4370 7543 6163 6865 5369 7a65   setCpuCacheSize
-00000b70: 7320 2a2f 0a0a 7465 6d70 6c61 7465 3c74  s */..template<t
-00000b80: 7970 656e 616d 6520 4c68 7353 6361 6c61  ypename LhsScala
-00000b90: 722c 2074 7970 656e 616d 6520 5268 7353  r, typename RhsS
-00000ba0: 6361 6c61 722c 2069 6e74 204b 6346 6163  calar, int KcFac
-00000bb0: 746f 722c 2074 7970 656e 616d 6520 496e  tor, typename In
-00000bc0: 6465 783e 0a76 6f69 6420 6576 616c 7561  dex>.void evalua
-00000bd0: 7465 5072 6f64 7563 7442 6c6f 636b 696e  teProductBlockin
-00000be0: 6753 697a 6573 4865 7572 6973 7469 6328  gSizesHeuristic(
-00000bf0: 496e 6465 7826 206b 2c20 496e 6465 7826  Index& k, Index&
-00000c00: 206d 2c20 496e 6465 7826 206e 2c20 496e   m, Index& n, In
-00000c10: 6465 7820 6e75 6d5f 7468 7265 6164 7320  dex num_threads 
-00000c20: 3d20 3129 0a7b 0a20 2074 7970 6564 6566  = 1).{.  typedef
-00000c30: 2067 6562 705f 7472 6169 7473 3c4c 6873   gebp_traits<Lhs
-00000c40: 5363 616c 6172 2c52 6873 5363 616c 6172  Scalar,RhsScalar
-00000c50: 3e20 5472 6169 7473 3b0a 0a20 202f 2f20  > Traits;..  // 
-00000c60: 4578 706c 616e 6174 696f 6e73 3a0a 2020  Explanations:.  
-00000c70: 2f2f 204c 6574 2773 2072 6563 616c 6c20  // Let's recall 
-00000c80: 7468 6174 2074 6865 2070 726f 6475 6374  that the product
-00000c90: 2061 6c67 6f72 6974 686d 7320 666f 726d   algorithms form
-00000ca0: 206d 6320 7820 6b63 2076 6572 7469 6361   mc x kc vertica
-00000cb0: 6c20 7061 6e65 6c73 2041 2720 6f6e 2074  l panels A' on t
-00000cc0: 6865 206c 6873 2061 6e64 0a20 202f 2f20  he lhs and.  // 
-00000cd0: 6b63 2078 206e 6320 626c 6f63 6b73 2042  kc x nc blocks B
-00000ce0: 2720 6f6e 2074 6865 2072 6873 2e20 4227  ' on the rhs. B'
-00000cf0: 2068 6173 2074 6f20 6669 7420 696e 746f   has to fit into
-00000d00: 204c 322f 4c33 2063 6163 6865 2e20 4d6f   L2/L3 cache. Mo
-00000d10: 7265 6f76 6572 2c20 4127 2069 7320 7072  reover, A' is pr
-00000d20: 6f63 6573 7365 640a 2020 2f2f 2070 6572  ocessed.  // per
-00000d30: 206d 7220 7820 6b63 2068 6f72 697a 6f6e   mr x kc horizon
-00000d40: 7461 6c20 736d 616c 6c20 7061 6e65 6c73  tal small panels
-00000d50: 2077 6865 7265 206d 7220 6973 2074 6865   where mr is the
-00000d60: 2062 6c6f 636b 696e 6720 7369 7a65 2061   blocking size a
-00000d70: 6c6f 6e67 2074 6865 206d 2064 696d 656e  long the m dimen
-00000d80: 7369 6f6e 0a20 202f 2f20 6174 2074 6865  sion.  // at the
-00000d90: 2072 6567 6973 7465 7220 6c65 7665 6c2e   register level.
-00000da0: 2054 6869 7320 736d 616c 6c20 686f 7269   This small hori
-00000db0: 7a6f 6e74 616c 2070 616e 656c 2068 6173  zontal panel has
-00000dc0: 2074 6f20 7374 6179 2077 6974 6869 6e20   to stay within 
-00000dd0: 4c31 2063 6163 6865 2e0a 2020 7374 643a  L1 cache..  std:
-00000de0: 3a70 7472 6469 6666 5f74 206c 312c 206c  :ptrdiff_t l1, l
-00000df0: 322c 206c 333b 0a20 206d 616e 6167 655f  2, l3;.  manage_
-00000e00: 6361 6368 696e 675f 7369 7a65 7328 4765  caching_sizes(Ge
-00000e10: 7441 6374 696f 6e2c 2026 6c31 2c20 266c  tAction, &l1, &l
-00000e20: 322c 2026 6c33 293b 0a20 2023 6966 6465  2, &l3);.  #ifde
-00000e30: 6620 4549 4745 4e5f 5645 4354 4f52 495a  f EIGEN_VECTORIZ
-00000e40: 455f 4156 5835 3132 0a20 202f 2f20 5765  E_AVX512.  // We
-00000e50: 206e 6565 6420 746f 2066 696e 6420 6120   need to find a 
-00000e60: 7261 7469 6f6e 616c 6520 666f 7220 7468  rationale for th
-00000e70: 6174 2c20 6275 7420 7769 7468 6f75 7420  at, but without 
-00000e80: 7468 6973 2061 646a 7573 746d 656e 742c  this adjustment,
-00000e90: 0a20 202f 2f20 7065 7266 6f72 6d61 6e63  .  // performanc
-00000ea0: 6520 7769 7468 2041 5658 3531 3220 6973  e with AVX512 is
-00000eb0: 2070 7265 7474 7920 6261 642c 206c 696b   pretty bad, lik
-00000ec0: 6520 2d32 3025 2073 6c6f 7765 722e 0a20  e -20% slower.. 
-00000ed0: 202f 2f20 4f6e 6520 7265 6173 6f6e 2069   // One reason i
-00000ee0: 7320 7468 6174 2077 6974 6820 696e 6372  s that with incr
-00000ef0: 6561 7369 6e67 2070 6163 6b65 742d 7369  easing packet-si
-00000f00: 7a65 2c20 7468 6520 626c 6f63 6b69 6e67  ze, the blocking
-00000f10: 2073 697a 6520 6b0a 2020 2f2f 2068 6173   size k.  // has
-00000f20: 2074 6f20 6265 636f 6d65 2070 7265 7474   to become prett
-00000f30: 7920 736d 616c 6c20 6966 2077 6520 7761  y small if we wa
-00000f40: 6e74 2074 6861 7420 3120 6c68 7320 7061  nt that 1 lhs pa
-00000f50: 6e65 6c20 6669 7420 7769 7468 696e 204c  nel fit within L
-00000f60: 312e 0a20 202f 2f20 466f 7220 696e 7374  1..  // For inst
-00000f70: 616e 6365 2c20 7769 7468 2074 6865 2033  ance, with the 3
-00000f80: 7058 3420 6b65 726e 656c 2061 6e64 2064  pX4 kernel and d
-00000f90: 6f75 626c 652c 2074 6865 2073 697a 6520  ouble, the size 
-00000fa0: 6f66 2074 6865 206c 6873 2b72 6873 2070  of the lhs+rhs p
-00000fb0: 616e 656c 7320 6172 653a 0a20 202f 2f20  anels are:.  // 
-00000fc0: 2020 6b2a 2833 2a36 3420 2b20 342a 3829    k*(3*64 + 4*8)
-00000fd0: 2042 7974 6573 2c20 7769 7468 206c 313d   Bytes, with l1=
-00000fe0: 3332 6b42 7974 6573 2c20 616e 6420 6b25  32kBytes, and k%
-00000ff0: 383d 302c 2077 6520 6861 7665 206b 3d31  8=0, we have k=1
-00001000: 3434 2e0a 2020 2f2f 2054 6869 7320 6973  44..  // This is
-00001010: 2071 7569 7465 2073 6d61 6c6c 2066 6f72   quite small for
-00001020: 2061 2067 6f6f 6420 7265 7573 6520 6f66   a good reuse of
-00001030: 2074 6865 2061 6363 756d 756c 6174 696f   the accumulatio
-00001040: 6e20 7265 6769 7374 6572 732e 0a20 206c  n registers..  l
-00001050: 3120 2a3d 2034 3b0a 2020 2365 6e64 6966  1 *= 4;.  #endif
-00001060: 0a0a 2020 6966 2028 6e75 6d5f 7468 7265  ..  if (num_thre
-00001070: 6164 7320 3e20 3129 207b 0a20 2020 2074  ads > 1) {.    t
-00001080: 7970 6564 6566 2074 7970 656e 616d 6520  ypedef typename 
-00001090: 5472 6169 7473 3a3a 5265 7353 6361 6c61  Traits::ResScala
-000010a0: 7220 5265 7353 6361 6c61 723b 0a20 2020  r ResScalar;.   
-000010b0: 2065 6e75 6d20 7b0a 2020 2020 2020 6b64   enum {.      kd
-000010c0: 6976 203d 204b 6346 6163 746f 7220 2a20  iv = KcFactor * 
-000010d0: 2854 7261 6974 733a 3a6d 7220 2a20 7369  (Traits::mr * si
-000010e0: 7a65 6f66 284c 6873 5363 616c 6172 2920  zeof(LhsScalar) 
-000010f0: 2b20 5472 6169 7473 3a3a 6e72 202a 2073  + Traits::nr * s
-00001100: 697a 656f 6628 5268 7353 6361 6c61 7229  izeof(RhsScalar)
-00001110: 292c 0a20 2020 2020 206b 7375 6220 3d20  ),.      ksub = 
-00001120: 5472 6169 7473 3a3a 6d72 202a 2054 7261  Traits::mr * Tra
-00001130: 6974 733a 3a6e 7220 2a20 7369 7a65 6f66  its::nr * sizeof
-00001140: 2852 6573 5363 616c 6172 292c 0a20 2020  (ResScalar),.   
-00001150: 2020 206b 7220 3d20 382c 0a20 2020 2020     kr = 8,.     
-00001160: 206d 7220 3d20 5472 6169 7473 3a3a 6d72   mr = Traits::mr
-00001170: 2c0a 2020 2020 2020 6e72 203d 2054 7261  ,.      nr = Tra
-00001180: 6974 733a 3a6e 720a 2020 2020 7d3b 0a20  its::nr.    };. 
-00001190: 2020 202f 2f20 496e 6372 6561 7369 6e67     // Increasing
-000011a0: 206b 2067 6976 6573 2075 7320 6d6f 7265   k gives us more
-000011b0: 2074 696d 6520 746f 2070 7265 6665 7463   time to prefetc
-000011c0: 6820 7468 6520 636f 6e74 656e 7420 6f66  h the content of
-000011d0: 2074 6865 2022 4322 0a20 2020 202f 2f20   the "C".    // 
-000011e0: 7265 6769 7374 6572 732e 2048 6f77 6576  registers. Howev
-000011f0: 6572 206f 6e63 6520 7468 6520 6c61 7465  er once the late
-00001200: 6e63 7920 6973 2068 6964 6465 6e20 7468  ncy is hidden th
-00001210: 6572 6520 6973 206e 6f20 706f 696e 7420  ere is no point 
-00001220: 696e 0a20 2020 202f 2f20 696e 6372 6561  in.    // increa
-00001230: 7369 6e67 2074 6865 2076 616c 7565 206f  sing the value o
-00001240: 6620 6b2c 2073 6f20 7765 276c 6c20 6361  f k, so we'll ca
-00001250: 7020 6974 2061 7420 3332 3020 2876 616c  p it at 320 (val
-00001260: 7565 2064 6574 6572 6d69 6e65 640a 2020  ue determined.  
-00001270: 2020 2f2f 2065 7870 6572 696d 656e 7461    // experimenta
-00001280: 6c6c 7929 2e0a 2020 2020 636f 6e73 7420  lly)..    const 
-00001290: 496e 6465 7820 6b5f 6361 6368 6520 3d20  Index k_cache = 
-000012a0: 286e 756d 6578 743a 3a6d 696e 693c 496e  (numext::mini<In
-000012b0: 6465 783e 2928 286c 312d 6b73 7562 292f  dex>)((l1-ksub)/
-000012c0: 6b64 6976 2c20 3332 3029 3b0a 2020 2020  kdiv, 320);.    
-000012d0: 6966 2028 6b5f 6361 6368 6520 3c20 6b29  if (k_cache < k)
-000012e0: 207b 0a20 2020 2020 206b 203d 206b 5f63   {.      k = k_c
-000012f0: 6163 6865 202d 2028 6b5f 6361 6368 6520  ache - (k_cache 
-00001300: 2520 6b72 293b 0a20 2020 2020 2065 6967  % kr);.      eig
-00001310: 656e 5f69 6e74 6572 6e61 6c5f 6173 7365  en_internal_asse
-00001320: 7274 286b 203e 2030 293b 0a20 2020 207d  rt(k > 0);.    }
-00001330: 0a0a 2020 2020 636f 6e73 7420 496e 6465  ..    const Inde
-00001340: 7820 6e5f 6361 6368 6520 3d20 286c 322d  x n_cache = (l2-
-00001350: 6c31 2920 2f20 286e 7220 2a20 7369 7a65  l1) / (nr * size
-00001360: 6f66 2852 6873 5363 616c 6172 2920 2a20  of(RhsScalar) * 
-00001370: 6b29 3b0a 2020 2020 636f 6e73 7420 496e  k);.    const In
-00001380: 6465 7820 6e5f 7065 725f 7468 7265 6164  dex n_per_thread
-00001390: 203d 206e 756d 6578 743a 3a64 6976 5f63   = numext::div_c
-000013a0: 6569 6c28 6e2c 206e 756d 5f74 6872 6561  eil(n, num_threa
-000013b0: 6473 293b 0a20 2020 2069 6620 286e 5f63  ds);.    if (n_c
-000013c0: 6163 6865 203c 3d20 6e5f 7065 725f 7468  ache <= n_per_th
-000013d0: 7265 6164 2920 7b0a 2020 2020 2020 2f2f  read) {.      //
-000013e0: 2044 6f6e 2774 2065 7863 6565 6420 7468   Don't exceed th
-000013f0: 6520 6361 7061 6369 7479 206f 6620 7468  e capacity of th
-00001400: 6520 6c32 2063 6163 6865 2e0a 2020 2020  e l2 cache..    
-00001410: 2020 6569 6765 6e5f 696e 7465 726e 616c    eigen_internal
-00001420: 5f61 7373 6572 7428 6e5f 6361 6368 6520  _assert(n_cache 
-00001430: 3e3d 2073 7461 7469 635f 6361 7374 3c49  >= static_cast<I
-00001440: 6e64 6578 3e28 6e72 2929 3b0a 2020 2020  ndex>(nr));.    
-00001450: 2020 6e20 3d20 6e5f 6361 6368 6520 2d20    n = n_cache - 
-00001460: 286e 5f63 6163 6865 2025 206e 7229 3b0a  (n_cache % nr);.
-00001470: 2020 2020 2020 6569 6765 6e5f 696e 7465        eigen_inte
-00001480: 726e 616c 5f61 7373 6572 7428 6e20 3e20  rnal_assert(n > 
-00001490: 3029 3b0a 2020 2020 7d20 656c 7365 207b  0);.    } else {
-000014a0: 0a20 2020 2020 206e 203d 2028 6e75 6d65  .      n = (nume
-000014b0: 7874 3a3a 6d69 6e69 3c49 6e64 6578 3e29  xt::mini<Index>)
-000014c0: 286e 2c20 286e 5f70 6572 5f74 6872 6561  (n, (n_per_threa
-000014d0: 6420 2b20 6e72 202d 2031 2920 2d20 2828  d + nr - 1) - ((
-000014e0: 6e5f 7065 725f 7468 7265 6164 202b 206e  n_per_thread + n
-000014f0: 7220 2d20 3129 2025 206e 7229 293b 0a20  r - 1) % nr));. 
-00001500: 2020 207d 0a0a 2020 2020 6966 2028 6c33     }..    if (l3
-00001510: 203e 206c 3229 207b 0a20 2020 2020 202f   > l2) {.      /
-00001520: 2f20 6c33 2069 7320 7368 6172 6564 2062  / l3 is shared b
-00001530: 6574 7765 656e 2061 6c6c 2063 6f72 6573  etween all cores
-00001540: 2c20 736f 2077 6527 6c6c 2067 6976 6520  , so we'll give 
-00001550: 6561 6368 2074 6872 6561 6420 6974 7320  each thread its 
-00001560: 6f77 6e20 6368 756e 6b20 6f66 206c 332e  own chunk of l3.
-00001570: 0a20 2020 2020 2063 6f6e 7374 2049 6e64  .      const Ind
-00001580: 6578 206d 5f63 6163 6865 203d 2028 6c33  ex m_cache = (l3
-00001590: 2d6c 3229 202f 2028 7369 7a65 6f66 284c  -l2) / (sizeof(L
-000015a0: 6873 5363 616c 6172 2920 2a20 6b20 2a20  hsScalar) * k * 
-000015b0: 6e75 6d5f 7468 7265 6164 7329 3b0a 2020  num_threads);.  
-000015c0: 2020 2020 636f 6e73 7420 496e 6465 7820      const Index 
-000015d0: 6d5f 7065 725f 7468 7265 6164 203d 206e  m_per_thread = n
-000015e0: 756d 6578 743a 3a64 6976 5f63 6569 6c28  umext::div_ceil(
-000015f0: 6d2c 206e 756d 5f74 6872 6561 6473 293b  m, num_threads);
-00001600: 0a20 2020 2020 2069 6628 6d5f 6361 6368  .      if(m_cach
-00001610: 6520 3c20 6d5f 7065 725f 7468 7265 6164  e < m_per_thread
-00001620: 2026 2620 6d5f 6361 6368 6520 3e3d 2073   && m_cache >= s
-00001630: 7461 7469 635f 6361 7374 3c49 6e64 6578  tatic_cast<Index
-00001640: 3e28 6d72 2929 207b 0a20 2020 2020 2020  >(mr)) {.       
-00001650: 206d 203d 206d 5f63 6163 6865 202d 2028   m = m_cache - (
-00001660: 6d5f 6361 6368 6520 2520 6d72 293b 0a20  m_cache % mr);. 
-00001670: 2020 2020 2020 2065 6967 656e 5f69 6e74         eigen_int
-00001680: 6572 6e61 6c5f 6173 7365 7274 286d 203e  ernal_assert(m >
-00001690: 2030 293b 0a20 2020 2020 207d 2065 6c73   0);.      } els
-000016a0: 6520 7b0a 2020 2020 2020 2020 6d20 3d20  e {.        m = 
-000016b0: 286e 756d 6578 743a 3a6d 696e 693c 496e  (numext::mini<In
-000016c0: 6465 783e 2928 6d2c 2028 6d5f 7065 725f  dex>)(m, (m_per_
-000016d0: 7468 7265 6164 202b 206d 7220 2d20 3129  thread + mr - 1)
-000016e0: 202d 2028 286d 5f70 6572 5f74 6872 6561   - ((m_per_threa
-000016f0: 6420 2b20 6d72 202d 2031 2920 2520 6d72  d + mr - 1) % mr
-00001700: 2929 3b0a 2020 2020 2020 7d0a 2020 2020  ));.      }.    
-00001710: 7d0a 2020 7d0a 2020 656c 7365 207b 0a20  }.  }.  else {. 
-00001720: 2020 202f 2f20 496e 2075 6e69 7420 7465     // In unit te
-00001730: 7374 7320 7765 2064 6f20 6e6f 7420 7761  sts we do not wa
-00001740: 6e74 2074 6f20 7573 6520 6578 7472 6120  nt to use extra 
-00001750: 6c61 7267 6520 6d61 7472 6963 6573 2c0a  large matrices,.
-00001760: 2020 2020 2f2f 2073 6f20 7765 2072 6564      // so we red
-00001770: 7563 6520 7468 6520 6361 6368 6520 7369  uce the cache si
-00001780: 7a65 2074 6f20 6368 6563 6b20 7468 6520  ze to check the 
-00001790: 626c 6f63 6b69 6e67 2073 7472 6174 6567  blocking strateg
-000017a0: 7920 6973 206e 6f74 2066 6c61 7765 640a  y is not flawed.
-000017b0: 2369 6664 6566 2045 4947 454e 5f44 4542  #ifdef EIGEN_DEB
-000017c0: 5547 5f53 4d41 4c4c 5f50 524f 4455 4354  UG_SMALL_PRODUCT
-000017d0: 5f42 4c4f 434b 530a 2020 2020 6c31 203d  _BLOCKS.    l1 =
-000017e0: 2039 2a31 3032 343b 0a20 2020 206c 3220   9*1024;.    l2 
-000017f0: 3d20 3332 2a31 3032 343b 0a20 2020 206c  = 32*1024;.    l
-00001800: 3320 3d20 3531 322a 3130 3234 3b0a 2365  3 = 512*1024;.#e
-00001810: 6e64 6966 0a0a 2020 2020 2f2f 2045 6172  ndif..    // Ear
-00001820: 6c79 2072 6574 7572 6e20 666f 7220 736d  ly return for sm
-00001830: 616c 6c20 7072 6f62 6c65 6d73 2062 6563  all problems bec
-00001840: 6175 7365 2074 6865 2063 6f6d 7075 7461  ause the computa
-00001850: 7469 6f6e 2062 656c 6f77 2061 7265 2074  tion below are t
-00001860: 696d 6520 636f 6e73 756d 696e 6720 666f  ime consuming fo
-00001870: 7220 736d 616c 6c20 7072 6f62 6c65 6d73  r small problems
-00001880: 2e0a 2020 2020 2f2f 2050 6572 6861 7073  ..    // Perhaps
-00001890: 2069 7420 776f 756c 6420 6d61 6b65 206d   it would make m
-000018a0: 6f72 6520 7365 6e73 6520 746f 2063 6f6e  ore sense to con
-000018b0: 7369 6465 7220 6b2a 6e2a 6d3f 3f0a 2020  sider k*n*m??.  
-000018c0: 2020 2f2f 204e 6f74 6520 7468 6174 2066    // Note that f
-000018d0: 6f72 2076 6572 7920 7469 6e79 2070 726f  or very tiny pro
-000018e0: 626c 656d 2c20 7468 6973 2066 756e 6374  blem, this funct
-000018f0: 696f 6e20 7368 6f75 6c64 2062 6520 6279  ion should be by
-00001900: 7061 7373 6564 2061 6e79 7761 790a 2020  passed anyway.  
-00001910: 2020 2f2f 2062 6563 6175 7365 2077 6520    // because we 
-00001920: 7573 6520 7468 6520 636f 6566 6669 6369  use the coeffici
-00001930: 656e 742d 6261 7365 6420 696d 706c 656d  ent-based implem
-00001940: 656e 7461 7469 6f6e 2066 6f72 2074 6865  entation for the
-00001950: 6d2e 0a20 2020 2069 6628 286e 756d 6578  m..    if((numex
-00001960: 743a 3a6d 6178 6929 286b 2c28 6e75 6d65  t::maxi)(k,(nume
-00001970: 7874 3a3a 6d61 7869 2928 6d2c 6e29 293c  xt::maxi)(m,n))<
-00001980: 3438 290a 2020 2020 2020 7265 7475 726e  48).      return
-00001990: 3b0a 0a20 2020 2074 7970 6564 6566 2074  ;..    typedef t
-000019a0: 7970 656e 616d 6520 5472 6169 7473 3a3a  ypename Traits::
-000019b0: 5265 7353 6361 6c61 7220 5265 7353 6361  ResScalar ResSca
-000019c0: 6c61 723b 0a20 2020 2065 6e75 6d20 7b0a  lar;.    enum {.
-000019d0: 2020 2020 2020 6b5f 7065 656c 696e 6720        k_peeling 
-000019e0: 3d20 382c 0a20 2020 2020 206b 5f64 6976  = 8,.      k_div
-000019f0: 203d 204b 6346 6163 746f 7220 2a20 2854   = KcFactor * (T
-00001a00: 7261 6974 733a 3a6d 7220 2a20 7369 7a65  raits::mr * size
-00001a10: 6f66 284c 6873 5363 616c 6172 2920 2b20  of(LhsScalar) + 
-00001a20: 5472 6169 7473 3a3a 6e72 202a 2073 697a  Traits::nr * siz
-00001a30: 656f 6628 5268 7353 6361 6c61 7229 292c  eof(RhsScalar)),
-00001a40: 0a20 2020 2020 206b 5f73 7562 203d 2054  .      k_sub = T
-00001a50: 7261 6974 733a 3a6d 7220 2a20 5472 6169  raits::mr * Trai
-00001a60: 7473 3a3a 6e72 202a 2073 697a 656f 6628  ts::nr * sizeof(
-00001a70: 5265 7353 6361 6c61 7229 0a20 2020 207d  ResScalar).    }
-00001a80: 3b0a 0a20 2020 202f 2f20 2d2d 2d2d 2031  ;..    // ---- 1
-00001a90: 7374 206c 6576 656c 206f 6620 626c 6f63  st level of bloc
-00001aa0: 6b69 6e67 206f 6e20 4c31 2c20 7969 656c  king on L1, yiel
-00001ab0: 6473 206b 6320 2d2d 2d2d 0a0a 2020 2020  ds kc ----..    
-00001ac0: 2f2f 2042 6c6f 636b 696e 6720 6f6e 2074  // Blocking on t
-00001ad0: 6865 2074 6869 7264 2064 696d 656e 7369  he third dimensi
-00001ae0: 6f6e 2028 692e 652e 2c20 6b29 2069 7320  on (i.e., k) is 
-00001af0: 6368 6f73 656e 2073 6f20 7468 6174 2061  chosen so that a
-00001b00: 6e20 686f 7269 7a6f 6e74 616c 2070 616e  n horizontal pan
-00001b10: 656c 0a20 2020 202f 2f20 6f66 2073 697a  el.    // of siz
-00001b20: 6520 6d72 2078 206b 6320 6f66 2074 6865  e mr x kc of the
-00001b30: 206c 6873 2070 6c75 7320 6120 7665 7274   lhs plus a vert
-00001b40: 6963 616c 2070 616e 656c 206f 6620 6b63  ical panel of kc
-00001b50: 2078 206e 7220 6f66 2074 6865 2072 6873   x nr of the rhs
-00001b60: 2062 6f74 6820 6669 7473 2077 6974 6869   both fits withi
-00001b70: 6e20 4c31 2063 6163 6865 2e0a 2020 2020  n L1 cache..    
-00001b80: 2f2f 2057 6520 616c 736f 2069 6e63 6c75  // We also inclu
-00001b90: 6465 2061 2072 6567 6973 7465 722d 6c65  de a register-le
-00001ba0: 7665 6c20 626c 6f63 6b20 6f66 2074 6865  vel block of the
-00001bb0: 2072 6573 756c 7420 286d 7820 7820 6e72   result (mx x nr
-00001bc0: 292e 0a20 2020 202f 2f20 2849 6e20 616e  )..    // (In an
-00001bd0: 2069 6465 616c 2077 6f72 6c64 206f 6e6c   ideal world onl
-00001be0: 7920 7468 6520 6c68 7320 7061 6e65 6c20  y the lhs panel 
-00001bf0: 776f 756c 6420 7374 6179 2069 6e20 4c31  would stay in L1
-00001c00: 290a 2020 2020 2f2f 204d 6f72 656f 7665  ).    // Moreove
-00001c10: 722c 206b 6320 6861 7320 746f 2062 6520  r, kc has to be 
-00001c20: 6120 6d75 6c74 6970 6c65 206f 6620 3820  a multiple of 8 
-00001c30: 746f 2062 6520 636f 6d70 6174 6962 6c65  to be compatible
-00001c40: 2077 6974 6820 6c6f 6f70 2070 6565 6c69   with loop peeli
-00001c50: 6e67 2c20 6c65 6164 696e 6720 746f 2061  ng, leading to a
-00001c60: 206d 6178 696d 756d 2062 6c6f 636b 696e   maximum blockin
-00001c70: 6720 7369 7a65 206f 663a 0a20 2020 2063  g size of:.    c
-00001c80: 6f6e 7374 2049 6e64 6578 206d 6178 5f6b  onst Index max_k
-00001c90: 6320 3d20 6e75 6d65 7874 3a3a 6d61 7869  c = numext::maxi
-00001ca0: 3c49 6e64 6578 3e28 2828 6c31 2d6b 5f73  <Index>(((l1-k_s
-00001cb0: 7562 292f 6b5f 6469 7629 2026 2028 7e28  ub)/k_div) & (~(
-00001cc0: 6b5f 7065 656c 696e 672d 3129 292c 3129  k_peeling-1)),1)
-00001cd0: 3b0a 2020 2020 636f 6e73 7420 496e 6465  ;.    const Inde
-00001ce0: 7820 6f6c 645f 6b20 3d20 6b3b 0a20 2020  x old_k = k;.   
-00001cf0: 2069 6628 6b3e 6d61 785f 6b63 290a 2020   if(k>max_kc).  
-00001d00: 2020 7b0a 2020 2020 2020 2f2f 2057 6520    {.      // We 
-00001d10: 6172 6520 7265 616c 6c79 2062 6c6f 636b  are really block
-00001d20: 696e 6720 6f6e 2074 6865 2074 6869 7264  ing on the third
-00001d30: 2064 696d 656e 7369 6f6e 3a0a 2020 2020   dimension:.    
-00001d40: 2020 2f2f 202d 3e20 7265 6475 6365 2062    // -> reduce b
-00001d50: 6c6f 636b 696e 6720 7369 7a65 2074 6f20  locking size to 
-00001d60: 6d61 6b65 2073 7572 6520 7468 6520 6c61  make sure the la
-00001d70: 7374 2062 6c6f 636b 2069 7320 6173 206c  st block is as l
-00001d80: 6172 6765 2061 7320 706f 7373 6962 6c65  arge as possible
-00001d90: 0a20 2020 2020 202f 2f20 2020 2077 6869  .      //    whi
-00001da0: 6c65 206b 6565 7069 6e67 2074 6865 2073  le keeping the s
-00001db0: 616d 6520 6e75 6d62 6572 206f 6620 7377  ame number of sw
-00001dc0: 6565 7073 206f 7665 7220 7468 6520 7265  eeps over the re
-00001dd0: 7375 6c74 2e0a 2020 2020 2020 6b20 3d20  sult..      k = 
-00001de0: 286b 256d 6178 5f6b 6329 3d3d 3020 3f20  (k%max_kc)==0 ? 
-00001df0: 6d61 785f 6b63 0a20 2020 2020 2020 2020  max_kc.         
-00001e00: 2020 2020 2020 2020 2020 2020 2020 203a                 :
-00001e10: 206d 6178 5f6b 6320 2d20 6b5f 7065 656c   max_kc - k_peel
-00001e20: 696e 6720 2a20 2828 6d61 785f 6b63 2d31  ing * ((max_kc-1
-00001e30: 2d28 6b25 6d61 785f 6b63 2929 2f28 6b5f  -(k%max_kc))/(k_
-00001e40: 7065 656c 696e 672a 286b 2f6d 6178 5f6b  peeling*(k/max_k
-00001e50: 632b 3129 2929 3b0a 0a20 2020 2020 2065  c+1)));..      e
-00001e60: 6967 656e 5f69 6e74 6572 6e61 6c5f 6173  igen_internal_as
-00001e70: 7365 7274 2828 286f 6c64 5f6b 2f6b 2920  sert(((old_k/k) 
-00001e80: 3d3d 2028 6f6c 645f 6b2f 6d61 785f 6b63  == (old_k/max_kc
-00001e90: 2929 2026 2620 2274 6865 206e 756d 6265  )) && "the numbe
-00001ea0: 7220 6f66 2073 7765 6570 7320 6861 7320  r of sweeps has 
-00001eb0: 746f 2072 656d 6169 6e20 7468 6520 7361  to remain the sa
-00001ec0: 6d65 2229 3b0a 2020 2020 7d0a 0a20 2020  me");.    }..   
-00001ed0: 202f 2f20 2d2d 2d2d 2032 6e64 206c 6576   // ---- 2nd lev
-00001ee0: 656c 206f 6620 626c 6f63 6b69 6e67 206f  el of blocking o
-00001ef0: 6e20 6d61 7828 4c32 2c4c 3329 2c20 7969  n max(L2,L3), yi
-00001f00: 656c 6473 206e 6320 2d2d 2d2d 0a0a 2020  elds nc ----..  
-00001f10: 2020 2f2f 2054 4f44 4f20 6669 6e64 2061    // TODO find a
-00001f20: 2072 656c 6961 626c 6520 7761 7920 746f   reliable way to
-00001f30: 2067 6574 2074 6865 2061 6374 7561 6c20   get the actual 
-00001f40: 616d 6f75 6e74 206f 6620 6361 6368 6520  amount of cache 
-00001f50: 7065 7220 636f 7265 2074 6f20 7573 6520  per core to use 
-00001f60: 666f 7220 326e 6420 6c65 7665 6c20 626c  for 2nd level bl
-00001f70: 6f63 6b69 6e67 2c20 7468 6174 2069 733a  ocking, that is:
-00001f80: 0a20 2020 202f 2f20 2020 2020 2061 6374  .    //      act
-00001f90: 7561 6c5f 6c32 203d 206d 6178 286c 322c  ual_l2 = max(l2,
-00001fa0: 206c 332f 6e62 5f63 6f72 655f 7368 6172   l3/nb_core_shar
-00001fb0: 696e 675f 6c33 290a 2020 2020 2f2f 2054  ing_l3).    // T
-00001fc0: 6865 206e 756d 6265 7220 6265 6c6f 7720  he number below 
-00001fd0: 6973 2071 7569 7465 2063 6f6e 7365 7276  is quite conserv
-00001fe0: 6174 6976 653a 2069 7420 6973 2062 6574  ative: it is bet
-00001ff0: 7465 7220 746f 2075 6e64 6572 6573 7469  ter to underesti
-00002000: 6d61 7465 2074 6865 2063 6163 6865 2073  mate the cache s
-00002010: 697a 6520 7261 7468 6572 2074 6861 6e20  ize rather than 
-00002020: 6f76 6572 6573 7469 6d61 7469 6e67 2069  overestimating i
-00002030: 7429 0a20 2020 202f 2f20 466f 7220 696e  t).    // For in
-00002040: 7374 616e 6365 2c20 6974 2063 6f72 7265  stance, it corre
-00002050: 7370 6f6e 6473 2074 6f20 364d 4220 6f66  sponds to 6MB of
-00002060: 204c 3320 7368 6172 6564 2061 6d6f 6e67   L3 shared among
-00002070: 2034 2063 6f72 6573 2e0a 2020 2020 2369   4 cores..    #i
-00002080: 6664 6566 2045 4947 454e 5f44 4542 5547  fdef EIGEN_DEBUG
-00002090: 5f53 4d41 4c4c 5f50 524f 4455 4354 5f42  _SMALL_PRODUCT_B
-000020a0: 4c4f 434b 530a 2020 2020 636f 6e73 7420  LOCKS.    const 
-000020b0: 496e 6465 7820 6163 7475 616c 5f6c 3220  Index actual_l2 
-000020c0: 3d20 6c33 3b0a 2020 2020 2365 6c73 650a  = l3;.    #else.
-000020d0: 2020 2020 636f 6e73 7420 496e 6465 7820      const Index 
-000020e0: 6163 7475 616c 5f6c 3220 3d20 3135 3732  actual_l2 = 1572
-000020f0: 3836 343b 202f 2f20 3d3d 2031 2e35 204d  864; // == 1.5 M
-00002100: 420a 2020 2020 2365 6e64 6966 0a0a 2020  B.    #endif..  
-00002110: 2020 2f2f 2048 6572 652c 206e 6320 6973    // Here, nc is
-00002120: 2063 686f 7365 6e20 7375 6368 2074 6861   chosen such tha
-00002130: 7420 6120 626c 6f63 6b20 6f66 206b 6320  t a block of kc 
-00002140: 7820 6e63 206f 6620 7468 6520 7268 7320  x nc of the rhs 
-00002150: 6669 7420 7769 7468 696e 2068 616c 6620  fit within half 
-00002160: 6f66 204c 322e 0a20 2020 202f 2f20 5468  of L2..    // Th
-00002170: 6520 7365 636f 6e64 2068 616c 6620 6973  e second half is
-00002180: 2069 6d70 6c69 6369 746c 7920 7265 7365   implicitly rese
-00002190: 7276 6564 2074 6f20 6163 6365 7373 2074  rved to access t
-000021a0: 6865 2072 6573 756c 7420 616e 6420 6c68  he result and lh
-000021b0: 7320 636f 6566 6669 6369 656e 7473 2e0a  s coefficients..
-000021c0: 2020 2020 2f2f 2057 6865 6e20 6b3c 6d61      // When k<ma
-000021d0: 785f 6b63 2c20 7468 656e 206e 6320 6361  x_kc, then nc ca
-000021e0: 6e20 6172 6269 7472 6172 696c 7920 6772  n arbitrarily gr
-000021f0: 6f77 7468 2e20 496e 2070 7261 6374 6963  owth. In practic
-00002200: 652c 2069 7420 7365 656d 7320 746f 2062  e, it seems to b
-00002210: 6520 6672 7569 7466 756c 0a20 2020 202f  e fruitful.    /
-00002220: 2f20 746f 206c 696d 6974 2074 6869 7320  / to limit this 
-00002230: 6772 6f77 7468 3a20 7765 2062 6f75 6e64  growth: we bound
-00002240: 206e 6320 746f 2067 726f 7774 6820 6279   nc to growth by
-00002250: 2061 2066 6163 746f 7220 7831 2e35 2e0a   a factor x1.5..
-00002260: 2020 2020 2f2f 2048 6f77 6576 6572 2c20      // However, 
-00002270: 6966 2074 6865 2065 6e74 6972 6520 6c68  if the entire lh
-00002280: 7320 626c 6f63 6b20 6669 7420 7769 7468  s block fit with
-00002290: 696e 204c 312c 2074 6865 6e20 7765 2061  in L1, then we a
-000022a0: 7265 206e 6f74 2067 6f69 6e67 2074 6f20  re not going to 
-000022b0: 626c 6f63 6b20 6f6e 2074 6865 2072 6f77  block on the row
-000022c0: 7320 6174 2061 6c6c 2c0a 2020 2020 2f2f  s at all,.    //
-000022d0: 2061 6e64 2069 7420 6265 636f 6d65 7320   and it becomes 
-000022e0: 6672 7569 7466 756c 2074 6f20 6b65 6570  fruitful to keep
-000022f0: 2074 6865 2070 6163 6b65 6420 7268 7320   the packed rhs 
-00002300: 626c 6f63 6b73 2069 6e20 4c31 2069 6620  blocks in L1 if 
-00002310: 7468 6572 6520 6973 2065 6e6f 7567 6820  there is enough 
-00002320: 7265 6d61 696e 696e 6720 7370 6163 652e  remaining space.
-00002330: 0a20 2020 2049 6e64 6578 206d 6178 5f6e  .    Index max_n
-00002340: 633b 0a20 2020 2063 6f6e 7374 2049 6e64  c;.    const Ind
-00002350: 6578 206c 6873 5f62 7974 6573 203d 206d  ex lhs_bytes = m
-00002360: 202a 206b 202a 2073 697a 656f 6628 4c68   * k * sizeof(Lh
-00002370: 7353 6361 6c61 7229 3b0a 2020 2020 636f  sScalar);.    co
-00002380: 6e73 7420 496e 6465 7820 7265 6d61 696e  nst Index remain
-00002390: 696e 675f 6c31 203d 206c 312d 206b 5f73  ing_l1 = l1- k_s
-000023a0: 7562 202d 206c 6873 5f62 7974 6573 3b0a  ub - lhs_bytes;.
-000023b0: 2020 2020 6966 2872 656d 6169 6e69 6e67      if(remaining
-000023c0: 5f6c 3120 3e3d 2049 6e64 6578 2854 7261  _l1 >= Index(Tra
-000023d0: 6974 733a 3a6e 722a 7369 7a65 6f66 2852  its::nr*sizeof(R
-000023e0: 6873 5363 616c 6172 2929 2a6b 290a 2020  hsScalar))*k).  
-000023f0: 2020 7b0a 2020 2020 2020 2f2f 204c 3120    {.      // L1 
-00002400: 626c 6f63 6b69 6e67 0a20 2020 2020 206d  blocking.      m
-00002410: 6178 5f6e 6320 3d20 7265 6d61 696e 696e  ax_nc = remainin
-00002420: 675f 6c31 202f 2028 6b2a 7369 7a65 6f66  g_l1 / (k*sizeof
-00002430: 2852 6873 5363 616c 6172 2929 3b0a 2020  (RhsScalar));.  
-00002440: 2020 7d0a 2020 2020 656c 7365 0a20 2020    }.    else.   
-00002450: 207b 0a20 2020 2020 202f 2f20 4c32 2062   {.      // L2 b
-00002460: 6c6f 636b 696e 670a 2020 2020 2020 6d61  locking.      ma
-00002470: 785f 6e63 203d 2028 332a 6163 7475 616c  x_nc = (3*actual
-00002480: 5f6c 3229 2f28 322a 322a 6d61 785f 6b63  _l2)/(2*2*max_kc
-00002490: 2a73 697a 656f 6628 5268 7353 6361 6c61  *sizeof(RhsScala
-000024a0: 7229 293b 0a20 2020 207d 0a20 2020 202f  r));.    }.    /
-000024b0: 2f20 5741 524e 494e 4720 4265 6c6f 772c  / WARNING Below,
-000024c0: 2077 6520 6173 7375 6d65 2074 6861 7420   we assume that 
-000024d0: 5472 6169 7473 3a3a 6e72 2069 7320 6120  Traits::nr is a 
-000024e0: 706f 7765 7220 6f66 2074 776f 2e0a 2020  power of two..  
-000024f0: 2020 496e 6465 7820 6e63 203d 206e 756d    Index nc = num
-00002500: 6578 743a 3a6d 696e 693c 496e 6465 783e  ext::mini<Index>
-00002510: 2861 6374 7561 6c5f 6c32 2f28 322a 6b2a  (actual_l2/(2*k*
-00002520: 7369 7a65 6f66 2852 6873 5363 616c 6172  sizeof(RhsScalar
-00002530: 2929 2c20 6d61 785f 6e63 2920 2620 287e  )), max_nc) & (~
-00002540: 2854 7261 6974 733a 3a6e 722d 3129 293b  (Traits::nr-1));
-00002550: 0a20 2020 2069 6628 6e3e 6e63 290a 2020  .    if(n>nc).  
-00002560: 2020 7b0a 2020 2020 2020 2f2f 2057 6520    {.      // We 
-00002570: 6172 6520 7265 616c 6c79 2062 6c6f 636b  are really block
-00002580: 696e 6720 6f76 6572 2074 6865 2063 6f6c  ing over the col
-00002590: 756d 6e73 3a0a 2020 2020 2020 2f2f 202d  umns:.      // -
-000025a0: 3e20 7265 6475 6365 2062 6c6f 636b 696e  > reduce blockin
-000025b0: 6720 7369 7a65 2074 6f20 6d61 6b65 2073  g size to make s
-000025c0: 7572 6520 7468 6520 6c61 7374 2062 6c6f  ure the last blo
-000025d0: 636b 2069 7320 6173 206c 6172 6765 2061  ck is as large a
-000025e0: 7320 706f 7373 6962 6c65 0a20 2020 2020  s possible.     
-000025f0: 202f 2f20 2020 2077 6869 6c65 206b 6565   //    while kee
-00002600: 7069 6e67 2074 6865 2073 616d 6520 6e75  ping the same nu
-00002610: 6d62 6572 206f 6620 7377 6565 7073 206f  mber of sweeps o
-00002620: 7665 7220 7468 6520 7061 636b 6564 206c  ver the packed l
-00002630: 6873 2e0a 2020 2020 2020 2f2f 2020 2020  hs..      //    
-00002640: 4865 7265 2077 6520 616c 6c6f 7720 6f6e  Here we allow on
-00002650: 6520 6d6f 7265 2073 7765 6570 2069 6620  e more sweep if 
-00002660: 7468 6973 2067 6976 6573 2075 7320 6120  this gives us a 
-00002670: 7065 7266 6563 7420 6d61 7463 682c 2074  perfect match, t
-00002680: 6875 7320 7468 6520 636f 6d6d 656e 7465  hus the commente
-00002690: 6420 222d 3122 0a20 2020 2020 206e 203d  d "-1".      n =
-000026a0: 2028 6e25 6e63 293d 3d30 203f 206e 630a   (n%nc)==0 ? nc.
-000026b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000026c0: 2020 2020 3a20 286e 6320 2d20 5472 6169      : (nc - Trai
-000026d0: 7473 3a3a 6e72 202a 2028 286e 632f 2a2d  ts::nr * ((nc/*-
-000026e0: 312a 2f2d 286e 256e 6329 292f 2854 7261  1*/-(n%nc))/(Tra
-000026f0: 6974 733a 3a6e 722a 286e 2f6e 632b 3129  its::nr*(n/nc+1)
-00002700: 2929 293b 0a20 2020 207d 0a20 2020 2065  )));.    }.    e
-00002710: 6c73 6520 6966 286f 6c64 5f6b 3d3d 6b29  lse if(old_k==k)
-00002720: 0a20 2020 207b 0a20 2020 2020 202f 2f20  .    {.      // 
-00002730: 536f 2066 6172 2c20 6e6f 2062 6c6f 636b  So far, no block
-00002740: 696e 6720 6174 2061 6c6c 2c20 692e 652e  ing at all, i.e.
-00002750: 2c20 6b63 3d3d 6b2c 2061 6e64 206e 633d  , kc==k, and nc=
-00002760: 3d6e 2e0a 2020 2020 2020 2f2f 2049 6e20  =n..      // In 
-00002770: 7468 6973 2063 6173 652c 206c 6574 2773  this case, let's
-00002780: 2070 6572 666f 726d 2061 2062 6c6f 636b   perform a block
-00002790: 696e 6720 6f76 6572 2074 6865 2072 6f77  ing over the row
-000027a0: 7320 7375 6368 2074 6861 7420 7468 6520  s such that the 
-000027b0: 7061 636b 6564 206c 6873 2064 6174 6120  packed lhs data 
-000027c0: 6973 206b 6570 7420 696e 2063 6163 6865  is kept in cache
-000027d0: 204c 312f 4c32 0a20 2020 2020 202f 2f20   L1/L2.      // 
-000027e0: 544f 444f 3a20 7061 7274 206f 6620 7468  TODO: part of th
-000027f0: 6973 2062 6c6f 636b 696e 6720 7374 7261  is blocking stra
-00002800: 7465 6779 2069 7320 6e6f 7720 696d 706c  tegy is now impl
-00002810: 656d 656e 7465 6420 7769 7468 696e 2074  emented within t
-00002820: 6865 206b 6572 6e65 6c20 6974 7365 6c66  he kernel itself
-00002830: 2c20 736f 2074 6865 204c 312d 6261 7365  , so the L1-base
-00002840: 6420 6865 7572 6973 7469 6320 6865 7265  d heuristic here
-00002850: 2073 686f 756c 6420 6265 206f 6273 6f6c   should be obsol
-00002860: 6574 652e 0a20 2020 2020 2049 6e64 6578  ete..      Index
-00002870: 2070 726f 626c 656d 5f73 697a 6520 3d20   problem_size = 
-00002880: 6b2a 6e2a 7369 7a65 6f66 284c 6873 5363  k*n*sizeof(LhsSc
-00002890: 616c 6172 293b 0a20 2020 2020 2049 6e64  alar);.      Ind
-000028a0: 6578 2061 6374 7561 6c5f 6c6d 203d 2061  ex actual_lm = a
-000028b0: 6374 7561 6c5f 6c32 3b0a 2020 2020 2020  ctual_l2;.      
-000028c0: 496e 6465 7820 6d61 785f 6d63 203d 206d  Index max_mc = m
-000028d0: 3b0a 2020 2020 2020 6966 2870 726f 626c  ;.      if(probl
-000028e0: 656d 5f73 697a 653c 3d31 3032 3429 0a20  em_size<=1024). 
-000028f0: 2020 2020 207b 0a20 2020 2020 2020 202f       {.        /
-00002900: 2f20 7072 6f62 6c65 6d20 6973 2073 6d61  / problem is sma
-00002910: 6c6c 2065 6e6f 7567 6820 746f 206b 6565  ll enough to kee
-00002920: 7020 696e 204c 310a 2020 2020 2020 2020  p in L1.        
-00002930: 2f2f 204c 6574 2773 2063 686f 6f73 6520  // Let's choose 
-00002940: 6d20 7375 6368 2074 6861 7420 6c68 7327  m such that lhs'
-00002950: 7320 626c 6f63 6b20 6669 7420 696e 2031  s block fit in 1
-00002960: 2f33 206f 6620 4c31 0a20 2020 2020 2020  /3 of L1.       
-00002970: 2061 6374 7561 6c5f 6c6d 203d 206c 313b   actual_lm = l1;
-00002980: 0a20 2020 2020 207d 0a20 2020 2020 2065  .      }.      e
-00002990: 6c73 6520 6966 286c 3321 3d30 2026 2620  lse if(l3!=0 && 
-000029a0: 7072 6f62 6c65 6d5f 7369 7a65 3c3d 3332  problem_size<=32
-000029b0: 3736 3829 0a20 2020 2020 207b 0a20 2020  768).      {.   
-000029c0: 2020 2020 202f 2f20 7765 2068 6176 6520       // we have 
-000029d0: 626f 7468 204c 3220 616e 6420 4c33 2c20  both L2 and L3, 
-000029e0: 616e 6420 7072 6f62 6c65 6d20 6973 2073  and problem is s
-000029f0: 6d61 6c6c 2065 6e6f 7567 6820 746f 2062  mall enough to b
-00002a00: 6520 6b65 7074 2069 6e20 4c32 0a20 2020  e kept in L2.   
-00002a10: 2020 2020 202f 2f20 4c65 7427 7320 6368       // Let's ch
-00002a20: 6f6f 7365 206d 2073 7563 6820 7468 6174  oose m such that
-00002a30: 206c 6873 2773 2062 6c6f 636b 2066 6974   lhs's block fit
-00002a40: 2069 6e20 312f 3320 6f66 204c 320a 2020   in 1/3 of L2.  
-00002a50: 2020 2020 2020 6163 7475 616c 5f6c 6d20        actual_lm 
-00002a60: 3d20 6c32 3b0a 2020 2020 2020 2020 6d61  = l2;.        ma
-00002a70: 785f 6d63 203d 2028 6e75 6d65 7874 3a3a  x_mc = (numext::
-00002a80: 6d69 6e69 3c49 6e64 6578 3e29 2835 3736  mini<Index>)(576
-00002a90: 2c6d 6178 5f6d 6329 3b0a 2020 2020 2020  ,max_mc);.      
-00002aa0: 7d0a 2020 2020 2020 496e 6465 7820 6d63  }.      Index mc
-00002ab0: 203d 2028 6e75 6d65 7874 3a3a 6d69 6e69   = (numext::mini
-00002ac0: 3c49 6e64 6578 3e29 2861 6374 7561 6c5f  <Index>)(actual_
-00002ad0: 6c6d 2f28 332a 6b2a 7369 7a65 6f66 284c  lm/(3*k*sizeof(L
-00002ae0: 6873 5363 616c 6172 2929 2c20 6d61 785f  hsScalar)), max_
-00002af0: 6d63 293b 0a20 2020 2020 2069 6620 286d  mc);.      if (m
-00002b00: 6320 3e20 5472 6169 7473 3a3a 6d72 2920  c > Traits::mr) 
-00002b10: 6d63 202d 3d20 6d63 2025 2054 7261 6974  mc -= mc % Trait
-00002b20: 733a 3a6d 723b 0a20 2020 2020 2065 6c73  s::mr;.      els
-00002b30: 6520 6966 2028 6d63 3d3d 3029 2072 6574  e if (mc==0) ret
-00002b40: 7572 6e3b 0a20 2020 2020 206d 203d 2028  urn;.      m = (
-00002b50: 6d25 6d63 293d 3d30 203f 206d 630a 2020  m%mc)==0 ? mc.  
-00002b60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00002b70: 2020 3a20 286d 6320 2d20 5472 6169 7473    : (mc - Traits
-00002b80: 3a3a 6d72 202a 2028 286d 632f 2a2d 312a  ::mr * ((mc/*-1*
-00002b90: 2f2d 286d 256d 6329 292f 2854 7261 6974  /-(m%mc))/(Trait
-00002ba0: 733a 3a6d 722a 286d 2f6d 632b 3129 2929  s::mr*(m/mc+1)))
-00002bb0: 293b 0a20 2020 207d 0a20 207d 0a7d 0a0a  );.    }.  }.}..
-00002bc0: 7465 6d70 6c61 7465 203c 7479 7065 6e61  template <typena
-00002bd0: 6d65 2049 6e64 6578 3e0a 696e 6c69 6e65  me Index>.inline
-00002be0: 2062 6f6f 6c20 7573 6553 7065 6369 6669   bool useSpecifi
-00002bf0: 6342 6c6f 636b 696e 6753 697a 6573 2849  cBlockingSizes(I
-00002c00: 6e64 6578 2620 6b2c 2049 6e64 6578 2620  ndex& k, Index& 
-00002c10: 6d2c 2049 6e64 6578 2620 6e29 0a7b 0a23  m, Index& n).{.#
-00002c20: 6966 6465 6620 4549 4745 4e5f 5445 5354  ifdef EIGEN_TEST
-00002c30: 5f53 5045 4349 4649 435f 424c 4f43 4b49  _SPECIFIC_BLOCKI
-00002c40: 4e47 5f53 495a 4553 0a20 2069 6620 2845  NG_SIZES.  if (E
-00002c50: 4947 454e 5f54 4553 545f 5350 4543 4946  IGEN_TEST_SPECIF
-00002c60: 4943 5f42 4c4f 434b 494e 475f 5349 5a45  IC_BLOCKING_SIZE
-00002c70: 5329 207b 0a20 2020 206b 203d 206e 756d  S) {.    k = num
-00002c80: 6578 743a 3a6d 696e 693c 496e 6465 783e  ext::mini<Index>
-00002c90: 286b 2c20 4549 4745 4e5f 5445 5354 5f53  (k, EIGEN_TEST_S
-00002ca0: 5045 4349 4649 435f 424c 4f43 4b49 4e47  PECIFIC_BLOCKING
-00002cb0: 5f53 495a 455f 4b29 3b0a 2020 2020 6d20  _SIZE_K);.    m 
-00002cc0: 3d20 6e75 6d65 7874 3a3a 6d69 6e69 3c49  = numext::mini<I
-00002cd0: 6e64 6578 3e28 6d2c 2045 4947 454e 5f54  ndex>(m, EIGEN_T
-00002ce0: 4553 545f 5350 4543 4946 4943 5f42 4c4f  EST_SPECIFIC_BLO
-00002cf0: 434b 494e 475f 5349 5a45 5f4d 293b 0a20  CKING_SIZE_M);. 
-00002d00: 2020 206e 203d 206e 756d 6578 743a 3a6d     n = numext::m
-00002d10: 696e 693c 496e 6465 783e 286e 2c20 4549  ini<Index>(n, EI
-00002d20: 4745 4e5f 5445 5354 5f53 5045 4349 4649  GEN_TEST_SPECIFI
-00002d30: 435f 424c 4f43 4b49 4e47 5f53 495a 455f  C_BLOCKING_SIZE_
-00002d40: 4e29 3b0a 2020 2020 7265 7475 726e 2074  N);.    return t
-00002d50: 7275 653b 0a20 207d 0a23 656c 7365 0a20  rue;.  }.#else. 
-00002d60: 2045 4947 454e 5f55 4e55 5345 445f 5641   EIGEN_UNUSED_VA
-00002d70: 5249 4142 4c45 286b 290a 2020 4549 4745  RIABLE(k).  EIGE
-00002d80: 4e5f 554e 5553 4544 5f56 4152 4941 424c  N_UNUSED_VARIABL
-00002d90: 4528 6d29 0a20 2045 4947 454e 5f55 4e55  E(m).  EIGEN_UNU
-00002da0: 5345 445f 5641 5249 4142 4c45 286e 290a  SED_VARIABLE(n).
-00002db0: 2365 6e64 6966 0a20 2072 6574 7572 6e20  #endif.  return 
-00002dc0: 6661 6c73 653b 0a7d 0a0a 2f2a 2a20 5c62  false;.}../** \b
-00002dd0: 7269 6566 2043 6f6d 7075 7465 7320 7468  rief Computes th
-00002de0: 6520 626c 6f63 6b69 6e67 2070 6172 616d  e blocking param
-00002df0: 6574 6572 7320 666f 7220 6120 6d20 7820  eters for a m x 
-00002e00: 6b20 7469 6d65 7320 6b20 7820 6e20 6d61  k times k x n ma
-00002e10: 7472 6978 2070 726f 6475 6374 0a20 202a  trix product.  *
-00002e20: 0a20 202a 205c 7061 7261 6d5b 696e 2c6f  .  * \param[in,o
-00002e30: 7574 5d20 6b20 496e 7075 743a 2074 6865  ut] k Input: the
-00002e40: 2074 6869 7264 2064 696d 656e 7369 6f6e   third dimension
-00002e50: 206f 6620 7468 6520 7072 6f64 7563 742e   of the product.
-00002e60: 204f 7574 7075 743a 2074 6865 2062 6c6f   Output: the blo
-00002e70: 636b 696e 6720 7369 7a65 2061 6c6f 6e67  cking size along
-00002e80: 2074 6865 2073 616d 6520 6469 6d65 6e73   the same dimens
-00002e90: 696f 6e2e 0a20 202a 205c 7061 7261 6d5b  ion..  * \param[
-00002ea0: 696e 2c6f 7574 5d20 6d20 496e 7075 743a  in,out] m Input:
-00002eb0: 2074 6865 206e 756d 6265 7220 6f66 2072   the number of r
-00002ec0: 6f77 7320 6f66 2074 6865 206c 6566 7420  ows of the left 
-00002ed0: 6861 6e64 2073 6964 652e 204f 7574 7075  hand side. Outpu
-00002ee0: 743a 2074 6865 2062 6c6f 636b 696e 6720  t: the blocking 
-00002ef0: 7369 7a65 2061 6c6f 6e67 2074 6865 2073  size along the s
-00002f00: 616d 6520 6469 6d65 6e73 696f 6e2e 0a20  ame dimension.. 
-00002f10: 202a 205c 7061 7261 6d5b 696e 2c6f 7574   * \param[in,out
-00002f20: 5d20 6e20 496e 7075 743a 2074 6865 206e  ] n Input: the n
-00002f30: 756d 6265 7220 6f66 2063 6f6c 756d 6e73  umber of columns
-00002f40: 206f 6620 7468 6520 7269 6768 7420 6861   of the right ha
-00002f50: 6e64 2073 6964 652e 204f 7574 7075 743a  nd side. Output:
-00002f60: 2074 6865 2062 6c6f 636b 696e 6720 7369   the blocking si
-00002f70: 7a65 2061 6c6f 6e67 2074 6865 2073 616d  ze along the sam
-00002f80: 6520 6469 6d65 6e73 696f 6e2e 0a20 202a  e dimension..  *
-00002f90: 0a20 202a 2047 6976 656e 2061 206d 2078  .  * Given a m x
-00002fa0: 206b 2074 696d 6573 206b 2078 206e 206d   k times k x n m
-00002fb0: 6174 7269 7820 7072 6f64 7563 7420 6f66  atrix product of
-00002fc0: 2073 6361 6c61 7220 7479 7065 7320 5c63   scalar types \c
-00002fd0: 204c 6873 5363 616c 6172 2061 6e64 205c   LhsScalar and \
-00002fe0: 6320 5268 7353 6361 6c61 722c 0a20 202a  c RhsScalar,.  *
-00002ff0: 2074 6869 7320 6675 6e63 7469 6f6e 2063   this function c
-00003000: 6f6d 7075 7465 7320 7468 6520 626c 6f63  omputes the bloc
-00003010: 6b69 6e67 2073 697a 6520 7061 7261 6d65  king size parame
-00003020: 7465 7273 2061 6c6f 6e67 2074 6865 2072  ters along the r
-00003030: 6573 7065 6374 6976 6520 6469 6d65 6e73  espective dimens
-00003040: 696f 6e73 0a20 202a 2066 6f72 206d 6174  ions.  * for mat
-00003050: 7269 7820 7072 6f64 7563 7473 2061 6e64  rix products and
-00003060: 2072 656c 6174 6564 2061 6c67 6f72 6974   related algorit
-00003070: 686d 732e 0a20 202a 0a20 202a 2054 6865  hms..  *.  * The
-00003080: 2062 6c6f 636b 696e 6720 7369 7a65 2070   blocking size p
-00003090: 6172 616d 6574 6572 7320 6d61 7920 6265  arameters may be
-000030a0: 2065 7661 6c75 6174 6564 3a0a 2020 2a20   evaluated:.  * 
-000030b0: 2020 2d20 6569 7468 6572 2062 7920 6120    - either by a 
-000030c0: 6865 7572 6973 7469 6320 6261 7365 6420  heuristic based 
-000030d0: 6f6e 2063 6163 6865 2073 697a 6573 3b0a  on cache sizes;.
-000030e0: 2020 2a20 2020 2d20 6f72 2075 7369 6e67    *   - or using
-000030f0: 2066 6978 6564 2070 7265 7363 7269 6265   fixed prescribe
-00003100: 6420 7661 6c75 6573 2028 666f 7220 7465  d values (for te
-00003110: 7374 696e 6720 7075 7270 6f73 6573 292e  sting purposes).
-00003120: 0a20 202a 0a20 202a 205c 7361 2073 6574  .  *.  * \sa set
-00003130: 4370 7543 6163 6865 5369 7a65 7320 2a2f  CpuCacheSizes */
-00003140: 0a0a 7465 6d70 6c61 7465 3c74 7970 656e  ..template<typen
-00003150: 616d 6520 4c68 7353 6361 6c61 722c 2074  ame LhsScalar, t
-00003160: 7970 656e 616d 6520 5268 7353 6361 6c61  ypename RhsScala
-00003170: 722c 2069 6e74 204b 6346 6163 746f 722c  r, int KcFactor,
-00003180: 2074 7970 656e 616d 6520 496e 6465 783e   typename Index>
-00003190: 0a76 6f69 6420 636f 6d70 7574 6550 726f  .void computePro
-000031a0: 6475 6374 426c 6f63 6b69 6e67 5369 7a65  ductBlockingSize
-000031b0: 7328 496e 6465 7826 206b 2c20 496e 6465  s(Index& k, Inde
-000031c0: 7826 206d 2c20 496e 6465 7826 206e 2c20  x& m, Index& n, 
-000031d0: 496e 6465 7820 6e75 6d5f 7468 7265 6164  Index num_thread
-000031e0: 7320 3d20 3129 0a7b 0a20 2069 6620 2821  s = 1).{.  if (!
-000031f0: 7573 6553 7065 6369 6669 6342 6c6f 636b  useSpecificBlock
-00003200: 696e 6753 697a 6573 286b 2c20 6d2c 206e  ingSizes(k, m, n
-00003210: 2929 207b 0a20 2020 2065 7661 6c75 6174  )) {.    evaluat
-00003220: 6550 726f 6475 6374 426c 6f63 6b69 6e67  eProductBlocking
-00003230: 5369 7a65 7348 6575 7269 7374 6963 3c4c  SizesHeuristic<L
-00003240: 6873 5363 616c 6172 2c20 5268 7353 6361  hsScalar, RhsSca
-00003250: 6c61 722c 204b 6346 6163 746f 722c 2049  lar, KcFactor, I
-00003260: 6e64 6578 3e28 6b2c 206d 2c20 6e2c 206e  ndex>(k, m, n, n
-00003270: 756d 5f74 6872 6561 6473 293b 0a20 207d  um_threads);.  }
-00003280: 0a7d 0a0a 7465 6d70 6c61 7465 3c74 7970  .}..template<typ
-00003290: 656e 616d 6520 4c68 7353 6361 6c61 722c  ename LhsScalar,
-000032a0: 2074 7970 656e 616d 6520 5268 7353 6361   typename RhsSca
-000032b0: 6c61 722c 2074 7970 656e 616d 6520 496e  lar, typename In
-000032c0: 6465 783e 0a69 6e6c 696e 6520 766f 6964  dex>.inline void
-000032d0: 2063 6f6d 7075 7465 5072 6f64 7563 7442   computeProductB
-000032e0: 6c6f 636b 696e 6753 697a 6573 2849 6e64  lockingSizes(Ind
-000032f0: 6578 2620 6b2c 2049 6e64 6578 2620 6d2c  ex& k, Index& m,
-00003300: 2049 6e64 6578 2620 6e2c 2049 6e64 6578   Index& n, Index
-00003310: 206e 756d 5f74 6872 6561 6473 203d 2031   num_threads = 1
-00003320: 290a 7b0a 2020 636f 6d70 7574 6550 726f  ).{.  computePro
-00003330: 6475 6374 426c 6f63 6b69 6e67 5369 7a65  ductBlockingSize
-00003340: 733c 4c68 7353 6361 6c61 722c 5268 7353  s<LhsScalar,RhsS
-00003350: 6361 6c61 722c 312c 496e 6465 783e 286b  calar,1,Index>(k
-00003360: 2c20 6d2c 206e 2c20 6e75 6d5f 7468 7265  , m, n, num_thre
-00003370: 6164 7329 3b0a 7d0a 0a23 6966 6465 6620  ads);.}..#ifdef 
-00003380: 4549 4745 4e5f 4841 535f 5349 4e47 4c45  EIGEN_HAS_SINGLE
-00003390: 5f49 4e53 5452 5543 5449 4f4e 5f43 4a4d  _INSTRUCTION_CJM
-000033a0: 4144 440a 2020 2364 6566 696e 6520 434a  ADD.  #define CJ
-000033b0: 4d41 4444 2843 4a2c 412c 422c 432c 5429  MADD(CJ,A,B,C,T)
-000033c0: 2020 4320 3d20 434a 2e70 6d61 6464 2841    C = CJ.pmadd(A
-000033d0: 2c42 2c43 293b 0a23 656c 7365 0a0a 2020  ,B,C);.#else..  
-000033e0: 2f2f 2046 4958 4d45 2028 6120 6269 7420  // FIXME (a bit 
-000033f0: 6f76 6572 6b69 6c6c 206d 6179 6265 203f  overkill maybe ?
-00003400: 290a 0a20 2074 656d 706c 6174 653c 7479  )..  template<ty
-00003410: 7065 6e61 6d65 2043 4a2c 2074 7970 656e  pename CJ, typen
-00003420: 616d 6520 412c 2074 7970 656e 616d 6520  ame A, typename 
-00003430: 422c 2074 7970 656e 616d 6520 432c 2074  B, typename C, t
-00003440: 7970 656e 616d 6520 543e 2073 7472 7563  ypename T> struc
-00003450: 7420 6765 6270 5f6d 6164 645f 7365 6c65  t gebp_madd_sele
-00003460: 6374 6f72 207b 0a20 2020 2045 4947 454e  ctor {.    EIGEN
-00003470: 5f41 4c57 4159 535f 494e 4c49 4e45 2073  _ALWAYS_INLINE s
-00003480: 7461 7469 6320 766f 6964 2072 756e 2863  tatic void run(c
-00003490: 6f6e 7374 2043 4a26 2063 6a2c 2041 2620  onst CJ& cj, A& 
-000034a0: 612c 2042 2620 622c 2043 2620 632c 2054  a, B& b, C& c, T
-000034b0: 2620 2f2a 742a 2f29 0a20 2020 207b 0a20  & /*t*/).    {. 
-000034c0: 2020 2020 2063 203d 2063 6a2e 706d 6164       c = cj.pmad
-000034d0: 6428 612c 622c 6329 3b0a 2020 2020 7d0a  d(a,b,c);.    }.
-000034e0: 2020 7d3b 0a0a 2020 7465 6d70 6c61 7465    };..  template
-000034f0: 3c74 7970 656e 616d 6520 434a 2c20 7479  <typename CJ, ty
-00003500: 7065 6e61 6d65 2054 3e20 7374 7275 6374  pename T> struct
-00003510: 2067 6562 705f 6d61 6464 5f73 656c 6563   gebp_madd_selec
-00003520: 746f 723c 434a 2c54 2c54 2c54 2c54 3e20  tor<CJ,T,T,T,T> 
-00003530: 7b0a 2020 2020 4549 4745 4e5f 414c 5741  {.    EIGEN_ALWA
-00003540: 5953 5f49 4e4c 494e 4520 7374 6174 6963  YS_INLINE static
-00003550: 2076 6f69 6420 7275 6e28 636f 6e73 7420   void run(const 
-00003560: 434a 2620 636a 2c20 5426 2061 2c20 5426  CJ& cj, T& a, T&
-00003570: 2062 2c20 5426 2063 2c20 5426 2074 290a   b, T& c, T& t).
-00003580: 2020 2020 7b0a 2020 2020 2020 7420 3d20      {.      t = 
-00003590: 623b 2074 203d 2063 6a2e 706d 756c 2861  b; t = cj.pmul(a
-000035a0: 2c74 293b 2063 203d 2070 6164 6428 632c  ,t); c = padd(c,
-000035b0: 7429 3b0a 2020 2020 7d0a 2020 7d3b 0a0a  t);.    }.  };..
-000035c0: 2020 7465 6d70 6c61 7465 3c74 7970 656e    template<typen
-000035d0: 616d 6520 434a 2c20 7479 7065 6e61 6d65  ame CJ, typename
-000035e0: 2041 2c20 7479 7065 6e61 6d65 2042 2c20   A, typename B, 
-000035f0: 7479 7065 6e61 6d65 2043 2c20 7479 7065  typename C, type
-00003600: 6e61 6d65 2054 3e0a 2020 4549 4745 4e5f  name T>.  EIGEN_
-00003610: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
-00003620: 6964 2067 6562 705f 6d61 6464 2863 6f6e  id gebp_madd(con
-00003630: 7374 2043 4a26 2063 6a2c 2041 2620 612c  st CJ& cj, A& a,
-00003640: 2042 2620 622c 2043 2620 632c 2054 2620   B& b, C& c, T& 
-00003650: 7429 0a20 207b 0a20 2020 2067 6562 705f  t).  {.    gebp_
-00003660: 6d61 6464 5f73 656c 6563 746f 723c 434a  madd_selector<CJ
-00003670: 2c41 2c42 2c43 2c54 3e3a 3a72 756e 2863  ,A,B,C,T>::run(c
-00003680: 6a2c 612c 622c 632c 7429 3b0a 2020 7d0a  j,a,b,c,t);.  }.
-00003690: 0a20 2023 6465 6669 6e65 2043 4a4d 4144  .  #define CJMAD
-000036a0: 4428 434a 2c41 2c42 2c43 2c54 2920 2067  D(CJ,A,B,C,T)  g
-000036b0: 6562 705f 6d61 6464 2843 4a2c 412c 422c  ebp_madd(CJ,A,B,
-000036c0: 432c 5429 3b0a 2f2f 2020 2023 6465 6669  C,T);.//   #defi
-000036d0: 6e65 2043 4a4d 4144 4428 434a 2c41 2c42  ne CJMADD(CJ,A,B
-000036e0: 2c43 2c54 2920 2054 203d 2042 3b20 5420  ,C,T)  T = B; T 
-000036f0: 3d20 434a 2e70 6d75 6c28 412c 5429 3b20  = CJ.pmul(A,T); 
-00003700: 4320 3d20 7061 6464 2843 2c54 293b 0a23  C = padd(C,T);.#
-00003710: 656e 6469 660a 0a74 656d 706c 6174 6520  endif..template 
-00003720: 3c74 7970 656e 616d 6520 5268 7350 6163  <typename RhsPac
-00003730: 6b65 742c 2074 7970 656e 616d 6520 5268  ket, typename Rh
-00003740: 7350 6163 6b65 7478 342c 2069 6e74 2072  sPacketx4, int r
-00003750: 6567 6973 7465 7273 5f74 616b 656e 3e0a  egisters_taken>.
-00003760: 7374 7275 6374 2052 6873 5061 6e65 6c48  struct RhsPanelH
-00003770: 656c 7065 7220 7b0a 2070 7269 7661 7465  elper {. private
-00003780: 3a0a 2020 7374 6174 6963 2063 6f6e 7374  :.  static const
-00003790: 2069 6e74 2072 656d 6169 6e69 6e67 5f72   int remaining_r
-000037a0: 6567 6973 7465 7273 203d 2045 4947 454e  egisters = EIGEN
-000037b0: 5f41 5243 485f 4445 4641 554c 545f 4e55  _ARCH_DEFAULT_NU
-000037c0: 4d42 4552 5f4f 465f 5245 4749 5354 4552  MBER_OF_REGISTER
-000037d0: 5320 2d20 7265 6769 7374 6572 735f 7461  S - registers_ta
-000037e0: 6b65 6e3b 0a20 7075 626c 6963 3a0a 2020  ken;. public:.  
-000037f0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
-00003800: 2063 6f6e 6469 7469 6f6e 616c 3c72 656d   conditional<rem
-00003810: 6169 6e69 6e67 5f72 6567 6973 7465 7273  aining_registers
-00003820: 3e3d 342c 2052 6873 5061 636b 6574 7834  >=4, RhsPacketx4
-00003830: 2c20 5268 7350 6163 6b65 743e 3a3a 7479  , RhsPacket>::ty
-00003840: 7065 2074 7970 653b 0a7d 3b0a 0a74 656d  pe type;.};..tem
-00003850: 706c 6174 6520 3c74 7970 656e 616d 6520  plate <typename 
-00003860: 5061 636b 6574 3e0a 7374 7275 6374 2051  Packet>.struct Q
-00003870: 7561 6450 6163 6b65 740a 7b0a 2020 5061  uadPacket.{.  Pa
-00003880: 636b 6574 2042 5f30 2c20 4231 2c20 4232  cket B_0, B1, B2
-00003890: 2c20 4233 3b0a 2020 636f 6e73 7420 5061  , B3;.  const Pa
-000038a0: 636b 6574 2620 6765 7428 636f 6e73 7420  cket& get(const 
-000038b0: 4669 7865 6449 6e74 3c30 3e26 2920 636f  FixedInt<0>&) co
-000038c0: 6e73 7420 7b20 7265 7475 726e 2042 5f30  nst { return B_0
-000038d0: 3b20 7d0a 2020 636f 6e73 7420 5061 636b  ; }.  const Pack
-000038e0: 6574 2620 6765 7428 636f 6e73 7420 4669  et& get(const Fi
-000038f0: 7865 6449 6e74 3c31 3e26 2920 636f 6e73  xedInt<1>&) cons
-00003900: 7420 7b20 7265 7475 726e 2042 313b 207d  t { return B1; }
-00003910: 0a20 2063 6f6e 7374 2050 6163 6b65 7426  .  const Packet&
-00003920: 2067 6574 2863 6f6e 7374 2046 6978 6564   get(const Fixed
-00003930: 496e 743c 323e 2629 2063 6f6e 7374 207b  Int<2>&) const {
-00003940: 2072 6574 7572 6e20 4232 3b20 7d0a 2020   return B2; }.  
-00003950: 636f 6e73 7420 5061 636b 6574 2620 6765  const Packet& ge
-00003960: 7428 636f 6e73 7420 4669 7865 6449 6e74  t(const FixedInt
-00003970: 3c33 3e26 2920 636f 6e73 7420 7b20 7265  <3>&) const { re
-00003980: 7475 726e 2042 333b 207d 0a7d 3b0a 0a74  turn B3; }.};..t
-00003990: 656d 706c 6174 6520 3c69 6e74 204e 2c20  emplate <int N, 
-000039a0: 7479 7065 6e61 6d65 2054 312c 2074 7970  typename T1, typ
-000039b0: 656e 616d 6520 5432 2c20 7479 7065 6e61  ename T2, typena
-000039c0: 6d65 2054 333e 0a73 7472 7563 7420 7061  me T3>.struct pa
-000039d0: 636b 6574 5f63 6f6e 6469 7469 6f6e 616c  cket_conditional
-000039e0: 207b 2074 7970 6564 6566 2054 3320 7479   { typedef T3 ty
-000039f0: 7065 3b20 7d3b 0a0a 7465 6d70 6c61 7465  pe; };..template
-00003a00: 203c 7479 7065 6e61 6d65 2054 312c 2074   <typename T1, t
-00003a10: 7970 656e 616d 6520 5432 2c20 7479 7065  ypename T2, type
-00003a20: 6e61 6d65 2054 333e 0a73 7472 7563 7420  name T3>.struct 
-00003a30: 7061 636b 6574 5f63 6f6e 6469 7469 6f6e  packet_condition
-00003a40: 616c 3c47 4542 5050 6163 6b65 7446 756c  al<GEBPPacketFul
-00003a50: 6c2c 2054 312c 2054 322c 2054 333e 207b  l, T1, T2, T3> {
-00003a60: 2074 7970 6564 6566 2054 3120 7479 7065   typedef T1 type
-00003a70: 3b20 7d3b 0a0a 7465 6d70 6c61 7465 203c  ; };..template <
-00003a80: 7479 7065 6e61 6d65 2054 312c 2074 7970  typename T1, typ
-00003a90: 656e 616d 6520 5432 2c20 7479 7065 6e61  ename T2, typena
-00003aa0: 6d65 2054 333e 0a73 7472 7563 7420 7061  me T3>.struct pa
-00003ab0: 636b 6574 5f63 6f6e 6469 7469 6f6e 616c  cket_conditional
-00003ac0: 3c47 4542 5050 6163 6b65 7448 616c 662c  <GEBPPacketHalf,
-00003ad0: 2054 312c 2054 322c 2054 333e 207b 2074   T1, T2, T3> { t
-00003ae0: 7970 6564 6566 2054 3220 7479 7065 3b20  ypedef T2 type; 
-00003af0: 7d3b 0a0a 2364 6566 696e 6520 5041 434b  };..#define PACK
-00003b00: 4554 5f44 4543 4c5f 434f 4e44 5f50 5245  ET_DECL_COND_PRE
-00003b10: 4649 5828 7072 6566 6978 2c20 6e61 6d65  FIX(prefix, name
-00003b20: 2c20 7061 636b 6574 5f73 697a 6529 2020  , packet_size)  
-00003b30: 2020 2020 2020 205c 0a20 2074 7970 6564         \.  typed
-00003b40: 6566 2074 7970 656e 616d 6520 7061 636b  ef typename pack
-00003b50: 6574 5f63 6f6e 6469 7469 6f6e 616c 3c70  et_conditional<p
-00003b60: 6163 6b65 745f 7369 7a65 2c20 2020 2020  acket_size,     
-00003b70: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
-00003b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003b90: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003ba0: 2020 2020 7479 7065 6e61 6d65 2070 6163      typename pac
-00003bb0: 6b65 745f 7472 6169 7473 3c6e 616d 6520  ket_traits<name 
-00003bc0: 2323 2053 6361 6c61 723e 3a3a 7479 7065  ## Scalar>::type
-00003bd0: 2c20 5c0a 2020 2020 2020 2020 2020 2020  , \.            
-00003be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003bf0: 2020 2020 2020 2020 2020 7479 7065 6e61            typena
-00003c00: 6d65 2070 6163 6b65 745f 7472 6169 7473  me packet_traits
-00003c10: 3c6e 616d 6520 2323 2053 6361 6c61 723e  <name ## Scalar>
-00003c20: 3a3a 6861 6c66 2c20 5c0a 2020 2020 2020  ::half, \.      
-00003c30: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003c40: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003c50: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
-00003c60: 745f 7472 6169 7473 3c74 7970 656e 616d  t_traits<typenam
-00003c70: 6520 7061 636b 6574 5f74 7261 6974 733c  e packet_traits<
-00003c80: 6e61 6d65 2023 2320 5363 616c 6172 3e3a  name ## Scalar>:
-00003c90: 3a68 616c 663e 3a3a 6861 6c66 3e3a 3a74  :half>::half>::t
-00003ca0: 7970 6520 5c0a 2020 7072 6566 6978 2023  ype \.  prefix #
-00003cb0: 2320 6e61 6d65 2023 2320 5061 636b 6574  # name ## Packet
-00003cc0: 0a0a 2364 6566 696e 6520 5041 434b 4554  ..#define PACKET
-00003cd0: 5f44 4543 4c5f 434f 4e44 286e 616d 652c  _DECL_COND(name,
-00003ce0: 2070 6163 6b65 745f 7369 7a65 2920 2020   packet_size)   
-00003cf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003d00: 2020 2020 205c 0a20 2074 7970 6564 6566       \.  typedef
-00003d10: 2074 7970 656e 616d 6520 7061 636b 6574   typename packet
-00003d20: 5f63 6f6e 6469 7469 6f6e 616c 3c70 6163  _conditional<pac
-00003d30: 6b65 745f 7369 7a65 2c20 2020 2020 2020  ket_size,       
-00003d40: 2020 2020 2020 2020 2020 5c0a 2020 2020            \.    
-00003d50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003d60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003d70: 2020 7479 7065 6e61 6d65 2070 6163 6b65    typename packe
-00003d80: 745f 7472 6169 7473 3c6e 616d 6520 2323  t_traits<name ##
-00003d90: 2053 6361 6c61 723e 3a3a 7479 7065 2c20   Scalar>::type, 
-00003da0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-00003db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003dc0: 2020 2020 2020 2020 7479 7065 6e61 6d65          typename
-00003dd0: 2070 6163 6b65 745f 7472 6169 7473 3c6e   packet_traits<n
-00003de0: 616d 6520 2323 2053 6361 6c61 723e 3a3a  ame ## Scalar>::
-00003df0: 6861 6c66 2c20 5c0a 2020 2020 2020 2020  half, \.        
-00003e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003e10: 2020 2020 2020 2020 2020 2020 2020 7479                ty
-00003e20: 7065 6e61 6d65 2075 6e70 6163 6b65 745f  pename unpacket_
-00003e30: 7472 6169 7473 3c74 7970 656e 616d 6520  traits<typename 
-00003e40: 7061 636b 6574 5f74 7261 6974 733c 6e61  packet_traits<na
-00003e50: 6d65 2023 2320 5363 616c 6172 3e3a 3a68  me ## Scalar>::h
-00003e60: 616c 663e 3a3a 6861 6c66 3e3a 3a74 7970  alf>::half>::typ
-00003e70: 6520 5c0a 2020 6e61 6d65 2023 2320 5061  e \.  name ## Pa
-00003e80: 636b 6574 0a0a 2364 6566 696e 6520 5041  cket..#define PA
-00003e90: 434b 4554 5f44 4543 4c5f 434f 4e44 5f53  CKET_DECL_COND_S
-00003ea0: 4341 4c41 525f 5052 4546 4958 2870 7265  CALAR_PREFIX(pre
-00003eb0: 6669 782c 2070 6163 6b65 745f 7369 7a65  fix, packet_size
-00003ec0: 2920 2020 2020 2020 205c 0a20 2074 7970  )        \.  typ
-00003ed0: 6564 6566 2074 7970 656e 616d 6520 7061  edef typename pa
-00003ee0: 636b 6574 5f63 6f6e 6469 7469 6f6e 616c  cket_conditional
-00003ef0: 3c70 6163 6b65 745f 7369 7a65 2c20 2020  <packet_size,   
-00003f00: 2020 2020 2020 2020 2020 2020 2020 5c0a                \.
-00003f10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003f30: 2020 2020 2020 7479 7065 6e61 6d65 2070        typename p
-00003f40: 6163 6b65 745f 7472 6169 7473 3c53 6361  acket_traits<Sca
-00003f50: 6c61 723e 3a3a 7479 7065 2c20 5c0a 2020  lar>::type, \.  
-00003f60: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003f70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003f80: 2020 2020 7479 7065 6e61 6d65 2070 6163      typename pac
-00003f90: 6b65 745f 7472 6169 7473 3c53 6361 6c61  ket_traits<Scala
-00003fa0: 723e 3a3a 6861 6c66 2c20 5c0a 2020 2020  r>::half, \.    
-00003fb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003fc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00003fd0: 2020 7479 7065 6e61 6d65 2075 6e70 6163    typename unpac
-00003fe0: 6b65 745f 7472 6169 7473 3c74 7970 656e  ket_traits<typen
-00003ff0: 616d 6520 7061 636b 6574 5f74 7261 6974  ame packet_trait
-00004000: 733c 5363 616c 6172 3e3a 3a68 616c 663e  s<Scalar>::half>
-00004010: 3a3a 6861 6c66 3e3a 3a74 7970 6520 5c0a  ::half>::type \.
-00004020: 2020 7072 6566 6978 2023 2320 5363 616c    prefix ## Scal
-00004030: 6172 5061 636b 6574 0a0a 2364 6566 696e  arPacket..#defin
-00004040: 6520 5041 434b 4554 5f44 4543 4c5f 434f  e PACKET_DECL_CO
-00004050: 4e44 5f53 4341 4c41 5228 7061 636b 6574  ND_SCALAR(packet
-00004060: 5f73 697a 6529 2020 2020 2020 2020 2020  _size)          
-00004070: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
-00004080: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
-00004090: 6520 7061 636b 6574 5f63 6f6e 6469 7469  e packet_conditi
-000040a0: 6f6e 616c 3c70 6163 6b65 745f 7369 7a65  onal<packet_size
-000040b0: 2c20 2020 2020 2020 2020 2020 2020 2020  ,               
-000040c0: 2020 5c0a 2020 2020 2020 2020 2020 2020    \.            
-000040d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000040e0: 2020 2020 2020 2020 2020 7479 7065 6e61            typena
-000040f0: 6d65 2070 6163 6b65 745f 7472 6169 7473  me packet_traits
-00004100: 3c53 6361 6c61 723e 3a3a 7479 7065 2c20  <Scalar>::type, 
-00004110: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-00004120: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004130: 2020 2020 2020 2020 7479 7065 6e61 6d65          typename
-00004140: 2070 6163 6b65 745f 7472 6169 7473 3c53   packet_traits<S
-00004150: 6361 6c61 723e 3a3a 6861 6c66 2c20 5c0a  calar>::half, \.
+000003a0: 2064 6566 696e 6564 2845 4947 454e 5f44   defined(EIGEN_D
+000003b0: 4546 4155 4c54 5f4c 315f 4341 4348 455f  EFAULT_L1_CACHE_
+000003c0: 5349 5a45 290a 2364 6566 696e 6520 4549  SIZE).#define EI
+000003d0: 4745 4e5f 5345 545f 4445 4641 554c 545f  GEN_SET_DEFAULT_
+000003e0: 4c31 5f43 4143 4845 5f53 495a 4528 7661  L1_CACHE_SIZE(va
+000003f0: 6c29 2045 4947 454e 5f44 4546 4155 4c54  l) EIGEN_DEFAULT
+00000400: 5f4c 315f 4341 4348 455f 5349 5a45 0a23  _L1_CACHE_SIZE.#
+00000410: 656c 7365 0a23 6465 6669 6e65 2045 4947  else.#define EIG
+00000420: 454e 5f53 4554 5f44 4546 4155 4c54 5f4c  EN_SET_DEFAULT_L
+00000430: 315f 4341 4348 455f 5349 5a45 2876 616c  1_CACHE_SIZE(val
+00000440: 2920 7661 6c0a 2365 6e64 6966 202f 2f20  ) val.#endif // 
+00000450: 6465 6669 6e65 6428 4549 4745 4e5f 4445  defined(EIGEN_DE
+00000460: 4641 554c 545f 4c31 5f43 4143 4845 5f53  FAULT_L1_CACHE_S
+00000470: 495a 4529 0a0a 2369 6620 6465 6669 6e65  IZE)..#if define
+00000480: 6428 4549 4745 4e5f 4445 4641 554c 545f  d(EIGEN_DEFAULT_
+00000490: 4c32 5f43 4143 4845 5f53 495a 4529 0a23  L2_CACHE_SIZE).#
+000004a0: 6465 6669 6e65 2045 4947 454e 5f53 4554  define EIGEN_SET
+000004b0: 5f44 4546 4155 4c54 5f4c 325f 4341 4348  _DEFAULT_L2_CACH
+000004c0: 455f 5349 5a45 2876 616c 2920 4549 4745  E_SIZE(val) EIGE
+000004d0: 4e5f 4445 4641 554c 545f 4c32 5f43 4143  N_DEFAULT_L2_CAC
+000004e0: 4845 5f53 495a 450a 2365 6c73 650a 2364  HE_SIZE.#else.#d
+000004f0: 6566 696e 6520 4549 4745 4e5f 5345 545f  efine EIGEN_SET_
+00000500: 4445 4641 554c 545f 4c32 5f43 4143 4845  DEFAULT_L2_CACHE
+00000510: 5f53 495a 4528 7661 6c29 2076 616c 0a23  _SIZE(val) val.#
+00000520: 656e 6469 6620 2f2f 2064 6566 696e 6564  endif // defined
+00000530: 2845 4947 454e 5f44 4546 4155 4c54 5f4c  (EIGEN_DEFAULT_L
+00000540: 325f 4341 4348 455f 5349 5a45 290a 0a23  2_CACHE_SIZE)..#
+00000550: 6966 2064 6566 696e 6564 2845 4947 454e  if defined(EIGEN
+00000560: 5f44 4546 4155 4c54 5f4c 335f 4341 4348  _DEFAULT_L3_CACH
+00000570: 455f 5349 5a45 290a 2364 6566 696e 6520  E_SIZE).#define 
+00000580: 4549 4745 4e5f 5345 545f 4445 4641 554c  EIGEN_SET_DEFAUL
+00000590: 545f 4c33 5f43 4143 4845 5f53 495a 4528  T_L3_CACHE_SIZE(
+000005a0: 7661 6c29 2045 4947 454e 5f44 4546 4155  val) EIGEN_DEFAU
+000005b0: 4c54 5f4c 335f 4341 4348 455f 5349 5a45  LT_L3_CACHE_SIZE
+000005c0: 0a23 656c 7365 0a23 6465 6669 6e65 2045  .#else.#define E
+000005d0: 4947 454e 5f53 4554 5f44 4546 4155 4c54  IGEN_SET_DEFAULT
+000005e0: 5f4c 335f 4341 4348 455f 5349 5a45 2876  _L3_CACHE_SIZE(v
+000005f0: 616c 2920 7661 6c0a 2365 6e64 6966 202f  al) val.#endif /
+00000600: 2f20 6465 6669 6e65 6428 4549 4745 4e5f  / defined(EIGEN_
+00000610: 4445 4641 554c 545f 4c33 5f43 4143 4845  DEFAULT_L3_CACHE
+00000620: 5f53 495a 4529 0a20 200a 2369 6620 4549  _SIZE).  .#if EI
+00000630: 4745 4e5f 4152 4348 5f69 3338 365f 4f52  GEN_ARCH_i386_OR
+00000640: 5f78 3836 5f36 340a 636f 6e73 7420 7374  _x86_64.const st
+00000650: 643a 3a70 7472 6469 6666 5f74 2064 6566  d::ptrdiff_t def
+00000660: 6175 6c74 4c31 4361 6368 6553 697a 6520  aultL1CacheSize 
+00000670: 3d20 4549 4745 4e5f 5345 545f 4445 4641  = EIGEN_SET_DEFA
+00000680: 554c 545f 4c31 5f43 4143 4845 5f53 495a  ULT_L1_CACHE_SIZ
+00000690: 4528 3332 2a31 3032 3429 3b0a 636f 6e73  E(32*1024);.cons
+000006a0: 7420 7374 643a 3a70 7472 6469 6666 5f74  t std::ptrdiff_t
+000006b0: 2064 6566 6175 6c74 4c32 4361 6368 6553   defaultL2CacheS
+000006c0: 697a 6520 3d20 4549 4745 4e5f 5345 545f  ize = EIGEN_SET_
+000006d0: 4445 4641 554c 545f 4c32 5f43 4143 4845  DEFAULT_L2_CACHE
+000006e0: 5f53 495a 4528 3235 362a 3130 3234 293b  _SIZE(256*1024);
+000006f0: 0a63 6f6e 7374 2073 7464 3a3a 7074 7264  .const std::ptrd
+00000700: 6966 665f 7420 6465 6661 756c 744c 3343  iff_t defaultL3C
+00000710: 6163 6865 5369 7a65 203d 2045 4947 454e  acheSize = EIGEN
+00000720: 5f53 4554 5f44 4546 4155 4c54 5f4c 335f  _SET_DEFAULT_L3_
+00000730: 4341 4348 455f 5349 5a45 2832 2a31 3032  CACHE_SIZE(2*102
+00000740: 342a 3130 3234 293b 0a23 656c 6966 2045  4*1024);.#elif E
+00000750: 4947 454e 5f41 5243 485f 5050 430a 636f  IGEN_ARCH_PPC.co
+00000760: 6e73 7420 7374 643a 3a70 7472 6469 6666  nst std::ptrdiff
+00000770: 5f74 2064 6566 6175 6c74 4c31 4361 6368  _t defaultL1Cach
+00000780: 6553 697a 6520 3d20 4549 4745 4e5f 5345  eSize = EIGEN_SE
+00000790: 545f 4445 4641 554c 545f 4c31 5f43 4143  T_DEFAULT_L1_CAC
+000007a0: 4845 5f53 495a 4528 3634 2a31 3032 3429  HE_SIZE(64*1024)
+000007b0: 3b0a 636f 6e73 7420 7374 643a 3a70 7472  ;.const std::ptr
+000007c0: 6469 6666 5f74 2064 6566 6175 6c74 4c32  diff_t defaultL2
+000007d0: 4361 6368 6553 697a 6520 3d20 4549 4745  CacheSize = EIGE
+000007e0: 4e5f 5345 545f 4445 4641 554c 545f 4c32  N_SET_DEFAULT_L2
+000007f0: 5f43 4143 4845 5f53 495a 4528 3531 322a  _CACHE_SIZE(512*
+00000800: 3130 3234 293b 0a63 6f6e 7374 2073 7464  1024);.const std
+00000810: 3a3a 7074 7264 6966 665f 7420 6465 6661  ::ptrdiff_t defa
+00000820: 756c 744c 3343 6163 6865 5369 7a65 203d  ultL3CacheSize =
+00000830: 2045 4947 454e 5f53 4554 5f44 4546 4155   EIGEN_SET_DEFAU
+00000840: 4c54 5f4c 335f 4341 4348 455f 5349 5a45  LT_L3_CACHE_SIZE
+00000850: 2834 2a31 3032 342a 3130 3234 293b 0a23  (4*1024*1024);.#
+00000860: 656c 7365 0a63 6f6e 7374 2073 7464 3a3a  else.const std::
+00000870: 7074 7264 6966 665f 7420 6465 6661 756c  ptrdiff_t defaul
+00000880: 744c 3143 6163 6865 5369 7a65 203d 2045  tL1CacheSize = E
+00000890: 4947 454e 5f53 4554 5f44 4546 4155 4c54  IGEN_SET_DEFAULT
+000008a0: 5f4c 315f 4341 4348 455f 5349 5a45 2831  _L1_CACHE_SIZE(1
+000008b0: 362a 3130 3234 293b 0a63 6f6e 7374 2073  6*1024);.const s
+000008c0: 7464 3a3a 7074 7264 6966 665f 7420 6465  td::ptrdiff_t de
+000008d0: 6661 756c 744c 3243 6163 6865 5369 7a65  faultL2CacheSize
+000008e0: 203d 2045 4947 454e 5f53 4554 5f44 4546   = EIGEN_SET_DEF
+000008f0: 4155 4c54 5f4c 325f 4341 4348 455f 5349  AULT_L2_CACHE_SI
+00000900: 5a45 2835 3132 2a31 3032 3429 3b0a 636f  ZE(512*1024);.co
+00000910: 6e73 7420 7374 643a 3a70 7472 6469 6666  nst std::ptrdiff
+00000920: 5f74 2064 6566 6175 6c74 4c33 4361 6368  _t defaultL3Cach
+00000930: 6553 697a 6520 3d20 4549 4745 4e5f 5345  eSize = EIGEN_SE
+00000940: 545f 4445 4641 554c 545f 4c33 5f43 4143  T_DEFAULT_L3_CAC
+00000950: 4845 5f53 495a 4528 3531 322a 3130 3234  HE_SIZE(512*1024
+00000960: 293b 0a23 656e 6469 660a 0a23 756e 6465  );.#endif..#unde
+00000970: 6620 4549 4745 4e5f 5345 545f 4445 4641  f EIGEN_SET_DEFA
+00000980: 554c 545f 4c31 5f43 4143 4845 5f53 495a  ULT_L1_CACHE_SIZ
+00000990: 450a 2375 6e64 6566 2045 4947 454e 5f53  E.#undef EIGEN_S
+000009a0: 4554 5f44 4546 4155 4c54 5f4c 325f 4341  ET_DEFAULT_L2_CA
+000009b0: 4348 455f 5349 5a45 0a23 756e 6465 6620  CHE_SIZE.#undef 
+000009c0: 4549 4745 4e5f 5345 545f 4445 4641 554c  EIGEN_SET_DEFAUL
+000009d0: 545f 4c33 5f43 4143 4845 5f53 495a 450a  T_L3_CACHE_SIZE.
+000009e0: 0a2f 2a2a 205c 696e 7465 726e 616c 202a  ./** \internal *
+000009f0: 2f0a 7374 7275 6374 2043 6163 6865 5369  /.struct CacheSi
+00000a00: 7a65 7320 7b0a 2020 4361 6368 6553 697a  zes {.  CacheSiz
+00000a10: 6573 2829 3a20 6d5f 6c31 282d 3129 2c6d  es(): m_l1(-1),m
+00000a20: 5f6c 3228 2d31 292c 6d5f 6c33 282d 3129  _l2(-1),m_l3(-1)
+00000a30: 207b 0a20 2020 2069 6e74 206c 3143 6163   {.    int l1Cac
+00000a40: 6865 5369 7a65 2c20 6c32 4361 6368 6553  heSize, l2CacheS
+00000a50: 697a 652c 206c 3343 6163 6865 5369 7a65  ize, l3CacheSize
+00000a60: 3b0a 2020 2020 7175 6572 7943 6163 6865  ;.    queryCache
+00000a70: 5369 7a65 7328 6c31 4361 6368 6553 697a  Sizes(l1CacheSiz
+00000a80: 652c 206c 3243 6163 6865 5369 7a65 2c20  e, l2CacheSize, 
+00000a90: 6c33 4361 6368 6553 697a 6529 3b0a 2020  l3CacheSize);.  
+00000aa0: 2020 6d5f 6c31 203d 206d 616e 6167 655f    m_l1 = manage_
+00000ab0: 6361 6368 696e 675f 7369 7a65 735f 6865  caching_sizes_he
+00000ac0: 6c70 6572 286c 3143 6163 6865 5369 7a65  lper(l1CacheSize
+00000ad0: 2c20 6465 6661 756c 744c 3143 6163 6865  , defaultL1Cache
+00000ae0: 5369 7a65 293b 0a20 2020 206d 5f6c 3220  Size);.    m_l2 
+00000af0: 3d20 6d61 6e61 6765 5f63 6163 6869 6e67  = manage_caching
+00000b00: 5f73 697a 6573 5f68 656c 7065 7228 6c32  _sizes_helper(l2
+00000b10: 4361 6368 6553 697a 652c 2064 6566 6175  CacheSize, defau
+00000b20: 6c74 4c32 4361 6368 6553 697a 6529 3b0a  ltL2CacheSize);.
+00000b30: 2020 2020 6d5f 6c33 203d 206d 616e 6167      m_l3 = manag
+00000b40: 655f 6361 6368 696e 675f 7369 7a65 735f  e_caching_sizes_
+00000b50: 6865 6c70 6572 286c 3343 6163 6865 5369  helper(l3CacheSi
+00000b60: 7a65 2c20 6465 6661 756c 744c 3343 6163  ze, defaultL3Cac
+00000b70: 6865 5369 7a65 293b 0a20 207d 0a0a 2020  heSize);.  }..  
+00000b80: 7374 643a 3a70 7472 6469 6666 5f74 206d  std::ptrdiff_t m
+00000b90: 5f6c 313b 0a20 2073 7464 3a3a 7074 7264  _l1;.  std::ptrd
+00000ba0: 6966 665f 7420 6d5f 6c32 3b0a 2020 7374  iff_t m_l2;.  st
+00000bb0: 643a 3a70 7472 6469 6666 5f74 206d 5f6c  d::ptrdiff_t m_l
+00000bc0: 333b 0a7d 3b0a 0a2f 2a2a 205c 696e 7465  3;.};../** \inte
+00000bd0: 726e 616c 202a 2f0a 696e 6c69 6e65 2076  rnal */.inline v
+00000be0: 6f69 6420 6d61 6e61 6765 5f63 6163 6869  oid manage_cachi
+00000bf0: 6e67 5f73 697a 6573 2841 6374 696f 6e20  ng_sizes(Action 
+00000c00: 6163 7469 6f6e 2c20 7374 643a 3a70 7472  action, std::ptr
+00000c10: 6469 6666 5f74 2a20 6c31 2c20 7374 643a  diff_t* l1, std:
+00000c20: 3a70 7472 6469 6666 5f74 2a20 6c32 2c20  :ptrdiff_t* l2, 
+00000c30: 7374 643a 3a70 7472 6469 6666 5f74 2a20  std::ptrdiff_t* 
+00000c40: 6c33 290a 7b0a 2020 7374 6174 6963 2043  l3).{.  static C
+00000c50: 6163 6865 5369 7a65 7320 6d5f 6361 6368  acheSizes m_cach
+00000c60: 6553 697a 6573 3b0a 0a20 2069 6628 6163  eSizes;..  if(ac
+00000c70: 7469 6f6e 3d3d 5365 7441 6374 696f 6e29  tion==SetAction)
+00000c80: 0a20 207b 0a20 2020 202f 2f20 7365 7420  .  {.    // set 
+00000c90: 7468 6520 6370 7520 6361 6368 6520 7369  the cpu cache si
+00000ca0: 7a65 2061 6e64 2063 6163 6865 2061 6c6c  ze and cache all
+00000cb0: 2062 6c6f 636b 2073 697a 6573 2066 726f   block sizes fro
+00000cc0: 6d20 6120 676c 6f62 616c 2063 6163 6865  m a global cache
+00000cd0: 2073 697a 6520 696e 2062 7974 650a 2020   size in byte.  
+00000ce0: 2020 6569 6765 6e5f 696e 7465 726e 616c    eigen_internal
+00000cf0: 5f61 7373 6572 7428 6c31 213d 3020 2626  _assert(l1!=0 &&
+00000d00: 206c 3221 3d30 293b 0a20 2020 206d 5f63   l2!=0);.    m_c
+00000d10: 6163 6865 5369 7a65 732e 6d5f 6c31 203d  acheSizes.m_l1 =
+00000d20: 202a 6c31 3b0a 2020 2020 6d5f 6361 6368   *l1;.    m_cach
+00000d30: 6553 697a 6573 2e6d 5f6c 3220 3d20 2a6c  eSizes.m_l2 = *l
+00000d40: 323b 0a20 2020 206d 5f63 6163 6865 5369  2;.    m_cacheSi
+00000d50: 7a65 732e 6d5f 6c33 203d 202a 6c33 3b0a  zes.m_l3 = *l3;.
+00000d60: 2020 7d0a 2020 656c 7365 2069 6628 6163    }.  else if(ac
+00000d70: 7469 6f6e 3d3d 4765 7441 6374 696f 6e29  tion==GetAction)
+00000d80: 0a20 207b 0a20 2020 2065 6967 656e 5f69  .  {.    eigen_i
+00000d90: 6e74 6572 6e61 6c5f 6173 7365 7274 286c  nternal_assert(l
+00000da0: 3121 3d30 2026 2620 6c32 213d 3029 3b0a  1!=0 && l2!=0);.
+00000db0: 2020 2020 2a6c 3120 3d20 6d5f 6361 6368      *l1 = m_cach
+00000dc0: 6553 697a 6573 2e6d 5f6c 313b 0a20 2020  eSizes.m_l1;.   
+00000dd0: 202a 6c32 203d 206d 5f63 6163 6865 5369   *l2 = m_cacheSi
+00000de0: 7a65 732e 6d5f 6c32 3b0a 2020 2020 2a6c  zes.m_l2;.    *l
+00000df0: 3320 3d20 6d5f 6361 6368 6553 697a 6573  3 = m_cacheSizes
+00000e00: 2e6d 5f6c 333b 0a20 207d 0a20 2065 6c73  .m_l3;.  }.  els
+00000e10: 650a 2020 7b0a 2020 2020 6569 6765 6e5f  e.  {.    eigen_
+00000e20: 696e 7465 726e 616c 5f61 7373 6572 7428  internal_assert(
+00000e30: 6661 6c73 6529 3b0a 2020 7d0a 7d0a 0a2f  false);.  }.}../
+00000e40: 2a20 4865 6c70 6572 2066 6f72 2063 6f6d  * Helper for com
+00000e50: 7075 7465 5072 6f64 7563 7442 6c6f 636b  puteProductBlock
+00000e60: 696e 6753 697a 6573 2e0a 202a 0a20 2a20  ingSizes.. *. * 
+00000e70: 4769 7665 6e20 6120 6d20 7820 6b20 7469  Given a m x k ti
+00000e80: 6d65 7320 6b20 7820 6e20 6d61 7472 6978  mes k x n matrix
+00000e90: 2070 726f 6475 6374 206f 6620 7363 616c   product of scal
+00000ea0: 6172 2074 7970 6573 205c 6320 4c68 7353  ar types \c LhsS
+00000eb0: 6361 6c61 7220 616e 6420 5c63 2052 6873  calar and \c Rhs
+00000ec0: 5363 616c 6172 2c0a 202a 2074 6869 7320  Scalar,. * this 
+00000ed0: 6675 6e63 7469 6f6e 2063 6f6d 7075 7465  function compute
+00000ee0: 7320 7468 6520 626c 6f63 6b69 6e67 2073  s the blocking s
+00000ef0: 697a 6520 7061 7261 6d65 7465 7273 2061  ize parameters a
+00000f00: 6c6f 6e67 2074 6865 2072 6573 7065 6374  long the respect
+00000f10: 6976 6520 6469 6d65 6e73 696f 6e73 0a20  ive dimensions. 
+00000f20: 2a20 666f 7220 6d61 7472 6978 2070 726f  * for matrix pro
+00000f30: 6475 6374 7320 616e 6420 7265 6c61 7465  ducts and relate
+00000f40: 6420 616c 676f 7269 7468 6d73 2e20 5468  d algorithms. Th
+00000f50: 6520 626c 6f63 6b69 6e67 2073 697a 6573  e blocking sizes
+00000f60: 2064 6570 656e 6473 206f 6e20 7661 7269   depends on vari
+00000f70: 6f75 730a 202a 2070 6172 616d 6574 6572  ous. * parameter
+00000f80: 733a 0a20 2a20 2d20 7468 6520 4c31 2061  s:. * - the L1 a
+00000f90: 6e64 204c 3220 6361 6368 6520 7369 7a65  nd L2 cache size
+00000fa0: 732c 0a20 2a20 2d20 7468 6520 7265 6769  s,. * - the regi
+00000fb0: 7374 6572 206c 6576 656c 2062 6c6f 636b  ster level block
+00000fc0: 696e 6720 7369 7a65 7320 6465 6669 6e65  ing sizes define
+00000fd0: 6420 6279 2067 6562 705f 7472 6169 7473  d by gebp_traits
+00000fe0: 2c0a 202a 202d 2074 6865 206e 756d 6265  ,. * - the numbe
+00000ff0: 7220 6f66 2073 6361 6c61 7273 2074 6861  r of scalars tha
+00001000: 7420 6669 7420 696e 746f 2061 2070 6163  t fit into a pac
+00001010: 6b65 7420 2877 6865 6e20 7665 6374 6f72  ket (when vector
+00001020: 697a 6174 696f 6e20 6973 2065 6e61 626c  ization is enabl
+00001030: 6564 292e 0a20 2a0a 202a 205c 7361 2073  ed).. *. * \sa s
+00001040: 6574 4370 7543 6163 6865 5369 7a65 7320  etCpuCacheSizes 
+00001050: 2a2f 0a0a 7465 6d70 6c61 7465 3c74 7970  */..template<typ
+00001060: 656e 616d 6520 4c68 7353 6361 6c61 722c  ename LhsScalar,
+00001070: 2074 7970 656e 616d 6520 5268 7353 6361   typename RhsSca
+00001080: 6c61 722c 2069 6e74 204b 6346 6163 746f  lar, int KcFacto
+00001090: 722c 2074 7970 656e 616d 6520 496e 6465  r, typename Inde
+000010a0: 783e 0a76 6f69 6420 6576 616c 7561 7465  x>.void evaluate
+000010b0: 5072 6f64 7563 7442 6c6f 636b 696e 6753  ProductBlockingS
+000010c0: 697a 6573 4865 7572 6973 7469 6328 496e  izesHeuristic(In
+000010d0: 6465 7826 206b 2c20 496e 6465 7826 206d  dex& k, Index& m
+000010e0: 2c20 496e 6465 7826 206e 2c20 496e 6465  , Index& n, Inde
+000010f0: 7820 6e75 6d5f 7468 7265 6164 7320 3d20  x num_threads = 
+00001100: 3129 0a7b 0a20 2074 7970 6564 6566 2067  1).{.  typedef g
+00001110: 6562 705f 7472 6169 7473 3c4c 6873 5363  ebp_traits<LhsSc
+00001120: 616c 6172 2c52 6873 5363 616c 6172 3e20  alar,RhsScalar> 
+00001130: 5472 6169 7473 3b0a 0a20 202f 2f20 4578  Traits;..  // Ex
+00001140: 706c 616e 6174 696f 6e73 3a0a 2020 2f2f  planations:.  //
+00001150: 204c 6574 2773 2072 6563 616c 6c20 7468   Let's recall th
+00001160: 6174 2074 6865 2070 726f 6475 6374 2061  at the product a
+00001170: 6c67 6f72 6974 686d 7320 666f 726d 206d  lgorithms form m
+00001180: 6320 7820 6b63 2076 6572 7469 6361 6c20  c x kc vertical 
+00001190: 7061 6e65 6c73 2041 2720 6f6e 2074 6865  panels A' on the
+000011a0: 206c 6873 2061 6e64 0a20 202f 2f20 6b63   lhs and.  // kc
+000011b0: 2078 206e 6320 626c 6f63 6b73 2042 2720   x nc blocks B' 
+000011c0: 6f6e 2074 6865 2072 6873 2e20 4227 2068  on the rhs. B' h
+000011d0: 6173 2074 6f20 6669 7420 696e 746f 204c  as to fit into L
+000011e0: 322f 4c33 2063 6163 6865 2e20 4d6f 7265  2/L3 cache. More
+000011f0: 6f76 6572 2c20 4127 2069 7320 7072 6f63  over, A' is proc
+00001200: 6573 7365 640a 2020 2f2f 2070 6572 206d  essed.  // per m
+00001210: 7220 7820 6b63 2068 6f72 697a 6f6e 7461  r x kc horizonta
+00001220: 6c20 736d 616c 6c20 7061 6e65 6c73 2077  l small panels w
+00001230: 6865 7265 206d 7220 6973 2074 6865 2062  here mr is the b
+00001240: 6c6f 636b 696e 6720 7369 7a65 2061 6c6f  locking size alo
+00001250: 6e67 2074 6865 206d 2064 696d 656e 7369  ng the m dimensi
+00001260: 6f6e 0a20 202f 2f20 6174 2074 6865 2072  on.  // at the r
+00001270: 6567 6973 7465 7220 6c65 7665 6c2e 2054  egister level. T
+00001280: 6869 7320 736d 616c 6c20 686f 7269 7a6f  his small horizo
+00001290: 6e74 616c 2070 616e 656c 2068 6173 2074  ntal panel has t
+000012a0: 6f20 7374 6179 2077 6974 6869 6e20 4c31  o stay within L1
+000012b0: 2063 6163 6865 2e0a 2020 7374 643a 3a70   cache..  std::p
+000012c0: 7472 6469 6666 5f74 206c 312c 206c 322c  trdiff_t l1, l2,
+000012d0: 206c 333b 0a20 206d 616e 6167 655f 6361   l3;.  manage_ca
+000012e0: 6368 696e 675f 7369 7a65 7328 4765 7441  ching_sizes(GetA
+000012f0: 6374 696f 6e2c 2026 6c31 2c20 266c 322c  ction, &l1, &l2,
+00001300: 2026 6c33 293b 0a20 2023 6966 6465 6620   &l3);.  #ifdef 
+00001310: 4549 4745 4e5f 5645 4354 4f52 495a 455f  EIGEN_VECTORIZE_
+00001320: 4156 5835 3132 0a20 202f 2f20 5765 206e  AVX512.  // We n
+00001330: 6565 6420 746f 2066 696e 6420 6120 7261  eed to find a ra
+00001340: 7469 6f6e 616c 6520 666f 7220 7468 6174  tionale for that
+00001350: 2c20 6275 7420 7769 7468 6f75 7420 7468  , but without th
+00001360: 6973 2061 646a 7573 746d 656e 742c 0a20  is adjustment,. 
+00001370: 202f 2f20 7065 7266 6f72 6d61 6e63 6520   // performance 
+00001380: 7769 7468 2041 5658 3531 3220 6973 2070  with AVX512 is p
+00001390: 7265 7474 7920 6261 642c 206c 696b 6520  retty bad, like 
+000013a0: 2d32 3025 2073 6c6f 7765 722e 0a20 202f  -20% slower..  /
+000013b0: 2f20 4f6e 6520 7265 6173 6f6e 2069 7320  / One reason is 
+000013c0: 7468 6174 2077 6974 6820 696e 6372 6561  that with increa
+000013d0: 7369 6e67 2070 6163 6b65 742d 7369 7a65  sing packet-size
+000013e0: 2c20 7468 6520 626c 6f63 6b69 6e67 2073  , the blocking s
+000013f0: 697a 6520 6b0a 2020 2f2f 2068 6173 2074  ize k.  // has t
+00001400: 6f20 6265 636f 6d65 2070 7265 7474 7920  o become pretty 
+00001410: 736d 616c 6c20 6966 2077 6520 7761 6e74  small if we want
+00001420: 2074 6861 7420 3120 6c68 7320 7061 6e65   that 1 lhs pane
+00001430: 6c20 6669 7420 7769 7468 696e 204c 312e  l fit within L1.
+00001440: 0a20 202f 2f20 466f 7220 696e 7374 616e  .  // For instan
+00001450: 6365 2c20 7769 7468 2074 6865 2033 7058  ce, with the 3pX
+00001460: 3420 6b65 726e 656c 2061 6e64 2064 6f75  4 kernel and dou
+00001470: 626c 652c 2074 6865 2073 697a 6520 6f66  ble, the size of
+00001480: 2074 6865 206c 6873 2b72 6873 2070 616e   the lhs+rhs pan
+00001490: 656c 7320 6172 653a 0a20 202f 2f20 2020  els are:.  //   
+000014a0: 6b2a 2833 2a36 3420 2b20 342a 3829 2042  k*(3*64 + 4*8) B
+000014b0: 7974 6573 2c20 7769 7468 206c 313d 3332  ytes, with l1=32
+000014c0: 6b42 7974 6573 2c20 616e 6420 6b25 383d  kBytes, and k%8=
+000014d0: 302c 2077 6520 6861 7665 206b 3d31 3434  0, we have k=144
+000014e0: 2e0a 2020 2f2f 2054 6869 7320 6973 2071  ..  // This is q
+000014f0: 7569 7465 2073 6d61 6c6c 2066 6f72 2061  uite small for a
+00001500: 2067 6f6f 6420 7265 7573 6520 6f66 2074   good reuse of t
+00001510: 6865 2061 6363 756d 756c 6174 696f 6e20  he accumulation 
+00001520: 7265 6769 7374 6572 732e 0a20 206c 3120  registers..  l1 
+00001530: 2a3d 2034 3b0a 2020 2365 6e64 6966 0a0a  *= 4;.  #endif..
+00001540: 2020 6966 2028 6e75 6d5f 7468 7265 6164    if (num_thread
+00001550: 7320 3e20 3129 207b 0a20 2020 2074 7970  s > 1) {.    typ
+00001560: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00001570: 6169 7473 3a3a 5265 7353 6361 6c61 7220  aits::ResScalar 
+00001580: 5265 7353 6361 6c61 723b 0a20 2020 2065  ResScalar;.    e
+00001590: 6e75 6d20 7b0a 2020 2020 2020 6b64 6976  num {.      kdiv
+000015a0: 203d 204b 6346 6163 746f 7220 2a20 2854   = KcFactor * (T
+000015b0: 7261 6974 733a 3a6d 7220 2a20 7369 7a65  raits::mr * size
+000015c0: 6f66 284c 6873 5363 616c 6172 2920 2b20  of(LhsScalar) + 
+000015d0: 5472 6169 7473 3a3a 6e72 202a 2073 697a  Traits::nr * siz
+000015e0: 656f 6628 5268 7353 6361 6c61 7229 292c  eof(RhsScalar)),
+000015f0: 0a20 2020 2020 206b 7375 6220 3d20 5472  .      ksub = Tr
+00001600: 6169 7473 3a3a 6d72 202a 2054 7261 6974  aits::mr * Trait
+00001610: 733a 3a6e 7220 2a20 7369 7a65 6f66 2852  s::nr * sizeof(R
+00001620: 6573 5363 616c 6172 292c 0a20 2020 2020  esScalar),.     
+00001630: 206b 7220 3d20 382c 0a20 2020 2020 206d   kr = 8,.      m
+00001640: 7220 3d20 5472 6169 7473 3a3a 6d72 2c0a  r = Traits::mr,.
+00001650: 2020 2020 2020 6e72 203d 2054 7261 6974        nr = Trait
+00001660: 733a 3a6e 720a 2020 2020 7d3b 0a20 2020  s::nr.    };.   
+00001670: 202f 2f20 496e 6372 6561 7369 6e67 206b   // Increasing k
+00001680: 2067 6976 6573 2075 7320 6d6f 7265 2074   gives us more t
+00001690: 696d 6520 746f 2070 7265 6665 7463 6820  ime to prefetch 
+000016a0: 7468 6520 636f 6e74 656e 7420 6f66 2074  the content of t
+000016b0: 6865 2022 4322 0a20 2020 202f 2f20 7265  he "C".    // re
+000016c0: 6769 7374 6572 732e 2048 6f77 6576 6572  gisters. However
+000016d0: 206f 6e63 6520 7468 6520 6c61 7465 6e63   once the latenc
+000016e0: 7920 6973 2068 6964 6465 6e20 7468 6572  y is hidden ther
+000016f0: 6520 6973 206e 6f20 706f 696e 7420 696e  e is no point in
+00001700: 0a20 2020 202f 2f20 696e 6372 6561 7369  .    // increasi
+00001710: 6e67 2074 6865 2076 616c 7565 206f 6620  ng the value of 
+00001720: 6b2c 2073 6f20 7765 276c 6c20 6361 7020  k, so we'll cap 
+00001730: 6974 2061 7420 3332 3020 2876 616c 7565  it at 320 (value
+00001740: 2064 6574 6572 6d69 6e65 640a 2020 2020   determined.    
+00001750: 2f2f 2065 7870 6572 696d 656e 7461 6c6c  // experimentall
+00001760: 7929 2e0a 2020 2020 2f2f 2054 6f20 6176  y)..    // To av
+00001770: 6f69 6420 7468 6174 206b 2076 616e 6973  oid that k vanis
+00001780: 6865 732c 2077 6520 6d61 6b65 206b 5f63  hes, we make k_c
+00001790: 6163 6865 2061 7420 6c65 6173 7420 6173  ache at least as
+000017a0: 2062 6967 2061 7320 6b72 0a20 2020 2063   big as kr.    c
+000017b0: 6f6e 7374 2049 6e64 6578 206b 5f63 6163  onst Index k_cac
+000017c0: 6865 203d 206e 756d 6578 743a 3a6d 6178  he = numext::max
+000017d0: 693c 496e 6465 783e 286b 722c 2028 6e75  i<Index>(kr, (nu
+000017e0: 6d65 7874 3a3a 6d69 6e69 3c49 6e64 6578  mext::mini<Index
+000017f0: 3e29 2828 6c31 2d6b 7375 6229 2f6b 6469  >)((l1-ksub)/kdi
+00001800: 762c 2033 3230 2929 3b0a 2020 2020 6966  v, 320));.    if
+00001810: 2028 6b5f 6361 6368 6520 3c20 6b29 207b   (k_cache < k) {
+00001820: 0a20 2020 2020 206b 203d 206b 5f63 6163  .      k = k_cac
+00001830: 6865 202d 2028 6b5f 6361 6368 6520 2520  he - (k_cache % 
+00001840: 6b72 293b 0a20 2020 2020 2065 6967 656e  kr);.      eigen
+00001850: 5f69 6e74 6572 6e61 6c5f 6173 7365 7274  _internal_assert
+00001860: 286b 203e 2030 293b 0a20 2020 207d 0a0a  (k > 0);.    }..
+00001870: 2020 2020 636f 6e73 7420 496e 6465 7820      const Index 
+00001880: 6e5f 6361 6368 6520 3d20 286c 322d 6c31  n_cache = (l2-l1
+00001890: 2920 2f20 286e 7220 2a20 7369 7a65 6f66  ) / (nr * sizeof
+000018a0: 2852 6873 5363 616c 6172 2920 2a20 6b29  (RhsScalar) * k)
+000018b0: 3b0a 2020 2020 636f 6e73 7420 496e 6465  ;.    const Inde
+000018c0: 7820 6e5f 7065 725f 7468 7265 6164 203d  x n_per_thread =
+000018d0: 206e 756d 6578 743a 3a64 6976 5f63 6569   numext::div_cei
+000018e0: 6c28 6e2c 206e 756d 5f74 6872 6561 6473  l(n, num_threads
+000018f0: 293b 0a20 2020 2069 6620 286e 5f63 6163  );.    if (n_cac
+00001900: 6865 203c 3d20 6e5f 7065 725f 7468 7265  he <= n_per_thre
+00001910: 6164 2920 7b0a 2020 2020 2020 2f2f 2044  ad) {.      // D
+00001920: 6f6e 2774 2065 7863 6565 6420 7468 6520  on't exceed the 
+00001930: 6361 7061 6369 7479 206f 6620 7468 6520  capacity of the 
+00001940: 6c32 2063 6163 6865 2e0a 2020 2020 2020  l2 cache..      
+00001950: 6569 6765 6e5f 696e 7465 726e 616c 5f61  eigen_internal_a
+00001960: 7373 6572 7428 6e5f 6361 6368 6520 3e3d  ssert(n_cache >=
+00001970: 2073 7461 7469 635f 6361 7374 3c49 6e64   static_cast<Ind
+00001980: 6578 3e28 6e72 2929 3b0a 2020 2020 2020  ex>(nr));.      
+00001990: 6e20 3d20 6e5f 6361 6368 6520 2d20 286e  n = n_cache - (n
+000019a0: 5f63 6163 6865 2025 206e 7229 3b0a 2020  _cache % nr);.  
+000019b0: 2020 2020 6569 6765 6e5f 696e 7465 726e      eigen_intern
+000019c0: 616c 5f61 7373 6572 7428 6e20 3e20 3029  al_assert(n > 0)
+000019d0: 3b0a 2020 2020 7d20 656c 7365 207b 0a20  ;.    } else {. 
+000019e0: 2020 2020 206e 203d 2028 6e75 6d65 7874       n = (numext
+000019f0: 3a3a 6d69 6e69 3c49 6e64 6578 3e29 286e  ::mini<Index>)(n
+00001a00: 2c20 286e 5f70 6572 5f74 6872 6561 6420  , (n_per_thread 
+00001a10: 2b20 6e72 202d 2031 2920 2d20 2828 6e5f  + nr - 1) - ((n_
+00001a20: 7065 725f 7468 7265 6164 202b 206e 7220  per_thread + nr 
+00001a30: 2d20 3129 2025 206e 7229 293b 0a20 2020  - 1) % nr));.   
+00001a40: 207d 0a0a 2020 2020 6966 2028 6c33 203e   }..    if (l3 >
+00001a50: 206c 3229 207b 0a20 2020 2020 202f 2f20   l2) {.      // 
+00001a60: 6c33 2069 7320 7368 6172 6564 2062 6574  l3 is shared bet
+00001a70: 7765 656e 2061 6c6c 2063 6f72 6573 2c20  ween all cores, 
+00001a80: 736f 2077 6527 6c6c 2067 6976 6520 6561  so we'll give ea
+00001a90: 6368 2074 6872 6561 6420 6974 7320 6f77  ch thread its ow
+00001aa0: 6e20 6368 756e 6b20 6f66 206c 332e 0a20  n chunk of l3.. 
+00001ab0: 2020 2020 2063 6f6e 7374 2049 6e64 6578       const Index
+00001ac0: 206d 5f63 6163 6865 203d 2028 6c33 2d6c   m_cache = (l3-l
+00001ad0: 3229 202f 2028 7369 7a65 6f66 284c 6873  2) / (sizeof(Lhs
+00001ae0: 5363 616c 6172 2920 2a20 6b20 2a20 6e75  Scalar) * k * nu
+00001af0: 6d5f 7468 7265 6164 7329 3b0a 2020 2020  m_threads);.    
+00001b00: 2020 636f 6e73 7420 496e 6465 7820 6d5f    const Index m_
+00001b10: 7065 725f 7468 7265 6164 203d 206e 756d  per_thread = num
+00001b20: 6578 743a 3a64 6976 5f63 6569 6c28 6d2c  ext::div_ceil(m,
+00001b30: 206e 756d 5f74 6872 6561 6473 293b 0a20   num_threads);. 
+00001b40: 2020 2020 2069 6628 6d5f 6361 6368 6520       if(m_cache 
+00001b50: 3c20 6d5f 7065 725f 7468 7265 6164 2026  < m_per_thread &
+00001b60: 2620 6d5f 6361 6368 6520 3e3d 2073 7461  & m_cache >= sta
+00001b70: 7469 635f 6361 7374 3c49 6e64 6578 3e28  tic_cast<Index>(
+00001b80: 6d72 2929 207b 0a20 2020 2020 2020 206d  mr)) {.        m
+00001b90: 203d 206d 5f63 6163 6865 202d 2028 6d5f   = m_cache - (m_
+00001ba0: 6361 6368 6520 2520 6d72 293b 0a20 2020  cache % mr);.   
+00001bb0: 2020 2020 2065 6967 656e 5f69 6e74 6572       eigen_inter
+00001bc0: 6e61 6c5f 6173 7365 7274 286d 203e 2030  nal_assert(m > 0
+00001bd0: 293b 0a20 2020 2020 207d 2065 6c73 6520  );.      } else 
+00001be0: 7b0a 2020 2020 2020 2020 6d20 3d20 286e  {.        m = (n
+00001bf0: 756d 6578 743a 3a6d 696e 693c 496e 6465  umext::mini<Inde
+00001c00: 783e 2928 6d2c 2028 6d5f 7065 725f 7468  x>)(m, (m_per_th
+00001c10: 7265 6164 202b 206d 7220 2d20 3129 202d  read + mr - 1) -
+00001c20: 2028 286d 5f70 6572 5f74 6872 6561 6420   ((m_per_thread 
+00001c30: 2b20 6d72 202d 2031 2920 2520 6d72 2929  + mr - 1) % mr))
+00001c40: 3b0a 2020 2020 2020 7d0a 2020 2020 7d0a  ;.      }.    }.
+00001c50: 2020 7d0a 2020 656c 7365 207b 0a20 2020    }.  else {.   
+00001c60: 202f 2f20 496e 2075 6e69 7420 7465 7374   // In unit test
+00001c70: 7320 7765 2064 6f20 6e6f 7420 7761 6e74  s we do not want
+00001c80: 2074 6f20 7573 6520 6578 7472 6120 6c61   to use extra la
+00001c90: 7267 6520 6d61 7472 6963 6573 2c0a 2020  rge matrices,.  
+00001ca0: 2020 2f2f 2073 6f20 7765 2072 6564 7563    // so we reduc
+00001cb0: 6520 7468 6520 6361 6368 6520 7369 7a65  e the cache size
+00001cc0: 2074 6f20 6368 6563 6b20 7468 6520 626c   to check the bl
+00001cd0: 6f63 6b69 6e67 2073 7472 6174 6567 7920  ocking strategy 
+00001ce0: 6973 206e 6f74 2066 6c61 7765 640a 2369  is not flawed.#i
+00001cf0: 6664 6566 2045 4947 454e 5f44 4542 5547  fdef EIGEN_DEBUG
+00001d00: 5f53 4d41 4c4c 5f50 524f 4455 4354 5f42  _SMALL_PRODUCT_B
+00001d10: 4c4f 434b 530a 2020 2020 6c31 203d 2039  LOCKS.    l1 = 9
+00001d20: 2a31 3032 343b 0a20 2020 206c 3220 3d20  *1024;.    l2 = 
+00001d30: 3332 2a31 3032 343b 0a20 2020 206c 3320  32*1024;.    l3 
+00001d40: 3d20 3531 322a 3130 3234 3b0a 2365 6e64  = 512*1024;.#end
+00001d50: 6966 0a0a 2020 2020 2f2f 2045 6172 6c79  if..    // Early
+00001d60: 2072 6574 7572 6e20 666f 7220 736d 616c   return for smal
+00001d70: 6c20 7072 6f62 6c65 6d73 2062 6563 6175  l problems becau
+00001d80: 7365 2074 6865 2063 6f6d 7075 7461 7469  se the computati
+00001d90: 6f6e 2062 656c 6f77 2061 7265 2074 696d  on below are tim
+00001da0: 6520 636f 6e73 756d 696e 6720 666f 7220  e consuming for 
+00001db0: 736d 616c 6c20 7072 6f62 6c65 6d73 2e0a  small problems..
+00001dc0: 2020 2020 2f2f 2050 6572 6861 7073 2069      // Perhaps i
+00001dd0: 7420 776f 756c 6420 6d61 6b65 206d 6f72  t would make mor
+00001de0: 6520 7365 6e73 6520 746f 2063 6f6e 7369  e sense to consi
+00001df0: 6465 7220 6b2a 6e2a 6d3f 3f0a 2020 2020  der k*n*m??.    
+00001e00: 2f2f 204e 6f74 6520 7468 6174 2066 6f72  // Note that for
+00001e10: 2076 6572 7920 7469 6e79 2070 726f 626c   very tiny probl
+00001e20: 656d 2c20 7468 6973 2066 756e 6374 696f  em, this functio
+00001e30: 6e20 7368 6f75 6c64 2062 6520 6279 7061  n should be bypa
+00001e40: 7373 6564 2061 6e79 7761 790a 2020 2020  ssed anyway.    
+00001e50: 2f2f 2062 6563 6175 7365 2077 6520 7573  // because we us
+00001e60: 6520 7468 6520 636f 6566 6669 6369 656e  e the coefficien
+00001e70: 742d 6261 7365 6420 696d 706c 656d 656e  t-based implemen
+00001e80: 7461 7469 6f6e 2066 6f72 2074 6865 6d2e  tation for them.
+00001e90: 0a20 2020 2069 6628 286e 756d 6578 743a  .    if((numext:
+00001ea0: 3a6d 6178 6929 286b 2c28 6e75 6d65 7874  :maxi)(k,(numext
+00001eb0: 3a3a 6d61 7869 2928 6d2c 6e29 293c 3438  ::maxi)(m,n))<48
+00001ec0: 290a 2020 2020 2020 7265 7475 726e 3b0a  ).      return;.
+00001ed0: 0a20 2020 2074 7970 6564 6566 2074 7970  .    typedef typ
+00001ee0: 656e 616d 6520 5472 6169 7473 3a3a 5265  ename Traits::Re
+00001ef0: 7353 6361 6c61 7220 5265 7353 6361 6c61  sScalar ResScala
+00001f00: 723b 0a20 2020 2065 6e75 6d20 7b0a 2020  r;.    enum {.  
+00001f10: 2020 2020 6b5f 7065 656c 696e 6720 3d20      k_peeling = 
+00001f20: 382c 0a20 2020 2020 206b 5f64 6976 203d  8,.      k_div =
+00001f30: 204b 6346 6163 746f 7220 2a20 2854 7261   KcFactor * (Tra
+00001f40: 6974 733a 3a6d 7220 2a20 7369 7a65 6f66  its::mr * sizeof
+00001f50: 284c 6873 5363 616c 6172 2920 2b20 5472  (LhsScalar) + Tr
+00001f60: 6169 7473 3a3a 6e72 202a 2073 697a 656f  aits::nr * sizeo
+00001f70: 6628 5268 7353 6361 6c61 7229 292c 0a20  f(RhsScalar)),. 
+00001f80: 2020 2020 206b 5f73 7562 203d 2054 7261       k_sub = Tra
+00001f90: 6974 733a 3a6d 7220 2a20 5472 6169 7473  its::mr * Traits
+00001fa0: 3a3a 6e72 202a 2073 697a 656f 6628 5265  ::nr * sizeof(Re
+00001fb0: 7353 6361 6c61 7229 0a20 2020 207d 3b0a  sScalar).    };.
+00001fc0: 0a20 2020 202f 2f20 2d2d 2d2d 2031 7374  .    // ---- 1st
+00001fd0: 206c 6576 656c 206f 6620 626c 6f63 6b69   level of blocki
+00001fe0: 6e67 206f 6e20 4c31 2c20 7969 656c 6473  ng on L1, yields
+00001ff0: 206b 6320 2d2d 2d2d 0a0a 2020 2020 2f2f   kc ----..    //
+00002000: 2042 6c6f 636b 696e 6720 6f6e 2074 6865   Blocking on the
+00002010: 2074 6869 7264 2064 696d 656e 7369 6f6e   third dimension
+00002020: 2028 692e 652e 2c20 6b29 2069 7320 6368   (i.e., k) is ch
+00002030: 6f73 656e 2073 6f20 7468 6174 2061 6e20  osen so that an 
+00002040: 686f 7269 7a6f 6e74 616c 2070 616e 656c  horizontal panel
+00002050: 0a20 2020 202f 2f20 6f66 2073 697a 6520  .    // of size 
+00002060: 6d72 2078 206b 6320 6f66 2074 6865 206c  mr x kc of the l
+00002070: 6873 2070 6c75 7320 6120 7665 7274 6963  hs plus a vertic
+00002080: 616c 2070 616e 656c 206f 6620 6b63 2078  al panel of kc x
+00002090: 206e 7220 6f66 2074 6865 2072 6873 2062   nr of the rhs b
+000020a0: 6f74 6820 6669 7473 2077 6974 6869 6e20  oth fits within 
+000020b0: 4c31 2063 6163 6865 2e0a 2020 2020 2f2f  L1 cache..    //
+000020c0: 2057 6520 616c 736f 2069 6e63 6c75 6465   We also include
+000020d0: 2061 2072 6567 6973 7465 722d 6c65 7665   a register-leve
+000020e0: 6c20 626c 6f63 6b20 6f66 2074 6865 2072  l block of the r
+000020f0: 6573 756c 7420 286d 7820 7820 6e72 292e  esult (mx x nr).
+00002100: 0a20 2020 202f 2f20 2849 6e20 616e 2069  .    // (In an i
+00002110: 6465 616c 2077 6f72 6c64 206f 6e6c 7920  deal world only 
+00002120: 7468 6520 6c68 7320 7061 6e65 6c20 776f  the lhs panel wo
+00002130: 756c 6420 7374 6179 2069 6e20 4c31 290a  uld stay in L1).
+00002140: 2020 2020 2f2f 204d 6f72 656f 7665 722c      // Moreover,
+00002150: 206b 6320 6861 7320 746f 2062 6520 6120   kc has to be a 
+00002160: 6d75 6c74 6970 6c65 206f 6620 3820 746f  multiple of 8 to
+00002170: 2062 6520 636f 6d70 6174 6962 6c65 2077   be compatible w
+00002180: 6974 6820 6c6f 6f70 2070 6565 6c69 6e67  ith loop peeling
+00002190: 2c20 6c65 6164 696e 6720 746f 2061 206d  , leading to a m
+000021a0: 6178 696d 756d 2062 6c6f 636b 696e 6720  aximum blocking 
+000021b0: 7369 7a65 206f 663a 0a20 2020 2063 6f6e  size of:.    con
+000021c0: 7374 2049 6e64 6578 206d 6178 5f6b 6320  st Index max_kc 
+000021d0: 3d20 6e75 6d65 7874 3a3a 6d61 7869 3c49  = numext::maxi<I
+000021e0: 6e64 6578 3e28 2828 6c31 2d6b 5f73 7562  ndex>(((l1-k_sub
+000021f0: 292f 6b5f 6469 7629 2026 2028 7e28 6b5f  )/k_div) & (~(k_
+00002200: 7065 656c 696e 672d 3129 292c 3129 3b0a  peeling-1)),1);.
+00002210: 2020 2020 636f 6e73 7420 496e 6465 7820      const Index 
+00002220: 6f6c 645f 6b20 3d20 6b3b 0a20 2020 2069  old_k = k;.    i
+00002230: 6628 6b3e 6d61 785f 6b63 290a 2020 2020  f(k>max_kc).    
+00002240: 7b0a 2020 2020 2020 2f2f 2057 6520 6172  {.      // We ar
+00002250: 6520 7265 616c 6c79 2062 6c6f 636b 696e  e really blockin
+00002260: 6720 6f6e 2074 6865 2074 6869 7264 2064  g on the third d
+00002270: 696d 656e 7369 6f6e 3a0a 2020 2020 2020  imension:.      
+00002280: 2f2f 202d 3e20 7265 6475 6365 2062 6c6f  // -> reduce blo
+00002290: 636b 696e 6720 7369 7a65 2074 6f20 6d61  cking size to ma
+000022a0: 6b65 2073 7572 6520 7468 6520 6c61 7374  ke sure the last
+000022b0: 2062 6c6f 636b 2069 7320 6173 206c 6172   block is as lar
+000022c0: 6765 2061 7320 706f 7373 6962 6c65 0a20  ge as possible. 
+000022d0: 2020 2020 202f 2f20 2020 2077 6869 6c65       //    while
+000022e0: 206b 6565 7069 6e67 2074 6865 2073 616d   keeping the sam
+000022f0: 6520 6e75 6d62 6572 206f 6620 7377 6565  e number of swee
+00002300: 7073 206f 7665 7220 7468 6520 7265 7375  ps over the resu
+00002310: 6c74 2e0a 2020 2020 2020 6b20 3d20 286b  lt..      k = (k
+00002320: 256d 6178 5f6b 6329 3d3d 3020 3f20 6d61  %max_kc)==0 ? ma
+00002330: 785f 6b63 0a20 2020 2020 2020 2020 2020  x_kc.           
+00002340: 2020 2020 2020 2020 2020 2020 203a 206d               : m
+00002350: 6178 5f6b 6320 2d20 6b5f 7065 656c 696e  ax_kc - k_peelin
+00002360: 6720 2a20 2828 6d61 785f 6b63 2d31 2d28  g * ((max_kc-1-(
+00002370: 6b25 6d61 785f 6b63 2929 2f28 6b5f 7065  k%max_kc))/(k_pe
+00002380: 656c 696e 672a 286b 2f6d 6178 5f6b 632b  eling*(k/max_kc+
+00002390: 3129 2929 3b0a 0a20 2020 2020 2065 6967  1)));..      eig
+000023a0: 656e 5f69 6e74 6572 6e61 6c5f 6173 7365  en_internal_asse
+000023b0: 7274 2828 286f 6c64 5f6b 2f6b 2920 3d3d  rt(((old_k/k) ==
+000023c0: 2028 6f6c 645f 6b2f 6d61 785f 6b63 2929   (old_k/max_kc))
+000023d0: 2026 2620 2274 6865 206e 756d 6265 7220   && "the number 
+000023e0: 6f66 2073 7765 6570 7320 6861 7320 746f  of sweeps has to
+000023f0: 2072 656d 6169 6e20 7468 6520 7361 6d65   remain the same
+00002400: 2229 3b0a 2020 2020 7d0a 0a20 2020 202f  ");.    }..    /
+00002410: 2f20 2d2d 2d2d 2032 6e64 206c 6576 656c  / ---- 2nd level
+00002420: 206f 6620 626c 6f63 6b69 6e67 206f 6e20   of blocking on 
+00002430: 6d61 7828 4c32 2c4c 3329 2c20 7969 656c  max(L2,L3), yiel
+00002440: 6473 206e 6320 2d2d 2d2d 0a0a 2020 2020  ds nc ----..    
+00002450: 2f2f 2054 4f44 4f20 6669 6e64 2061 2072  // TODO find a r
+00002460: 656c 6961 626c 6520 7761 7920 746f 2067  eliable way to g
+00002470: 6574 2074 6865 2061 6374 7561 6c20 616d  et the actual am
+00002480: 6f75 6e74 206f 6620 6361 6368 6520 7065  ount of cache pe
+00002490: 7220 636f 7265 2074 6f20 7573 6520 666f  r core to use fo
+000024a0: 7220 326e 6420 6c65 7665 6c20 626c 6f63  r 2nd level bloc
+000024b0: 6b69 6e67 2c20 7468 6174 2069 733a 0a20  king, that is:. 
+000024c0: 2020 202f 2f20 2020 2020 2061 6374 7561     //      actua
+000024d0: 6c5f 6c32 203d 206d 6178 286c 322c 206c  l_l2 = max(l2, l
+000024e0: 332f 6e62 5f63 6f72 655f 7368 6172 696e  3/nb_core_sharin
+000024f0: 675f 6c33 290a 2020 2020 2f2f 2054 6865  g_l3).    // The
+00002500: 206e 756d 6265 7220 6265 6c6f 7720 6973   number below is
+00002510: 2071 7569 7465 2063 6f6e 7365 7276 6174   quite conservat
+00002520: 6976 653a 2069 7420 6973 2062 6574 7465  ive: it is bette
+00002530: 7220 746f 2075 6e64 6572 6573 7469 6d61  r to underestima
+00002540: 7465 2074 6865 2063 6163 6865 2073 697a  te the cache siz
+00002550: 6520 7261 7468 6572 2074 6861 6e20 6f76  e rather than ov
+00002560: 6572 6573 7469 6d61 7469 6e67 2069 7429  erestimating it)
+00002570: 0a20 2020 202f 2f20 466f 7220 696e 7374  .    // For inst
+00002580: 616e 6365 2c20 6974 2063 6f72 7265 7370  ance, it corresp
+00002590: 6f6e 6473 2074 6f20 364d 4220 6f66 204c  onds to 6MB of L
+000025a0: 3320 7368 6172 6564 2061 6d6f 6e67 2034  3 shared among 4
+000025b0: 2063 6f72 6573 2e0a 2020 2020 2369 6664   cores..    #ifd
+000025c0: 6566 2045 4947 454e 5f44 4542 5547 5f53  ef EIGEN_DEBUG_S
+000025d0: 4d41 4c4c 5f50 524f 4455 4354 5f42 4c4f  MALL_PRODUCT_BLO
+000025e0: 434b 530a 2020 2020 636f 6e73 7420 496e  CKS.    const In
+000025f0: 6465 7820 6163 7475 616c 5f6c 3220 3d20  dex actual_l2 = 
+00002600: 6c33 3b0a 2020 2020 2365 6c73 650a 2020  l3;.    #else.  
+00002610: 2020 636f 6e73 7420 496e 6465 7820 6163    const Index ac
+00002620: 7475 616c 5f6c 3220 3d20 3135 3732 3836  tual_l2 = 157286
+00002630: 343b 202f 2f20 3d3d 2031 2e35 204d 420a  4; // == 1.5 MB.
+00002640: 2020 2020 2365 6e64 6966 0a0a 2020 2020      #endif..    
+00002650: 2f2f 2048 6572 652c 206e 6320 6973 2063  // Here, nc is c
+00002660: 686f 7365 6e20 7375 6368 2074 6861 7420  hosen such that 
+00002670: 6120 626c 6f63 6b20 6f66 206b 6320 7820  a block of kc x 
+00002680: 6e63 206f 6620 7468 6520 7268 7320 6669  nc of the rhs fi
+00002690: 7420 7769 7468 696e 2068 616c 6620 6f66  t within half of
+000026a0: 204c 322e 0a20 2020 202f 2f20 5468 6520   L2..    // The 
+000026b0: 7365 636f 6e64 2068 616c 6620 6973 2069  second half is i
+000026c0: 6d70 6c69 6369 746c 7920 7265 7365 7276  mplicitly reserv
+000026d0: 6564 2074 6f20 6163 6365 7373 2074 6865  ed to access the
+000026e0: 2072 6573 756c 7420 616e 6420 6c68 7320   result and lhs 
+000026f0: 636f 6566 6669 6369 656e 7473 2e0a 2020  coefficients..  
+00002700: 2020 2f2f 2057 6865 6e20 6b3c 6d61 785f    // When k<max_
+00002710: 6b63 2c20 7468 656e 206e 6320 6361 6e20  kc, then nc can 
+00002720: 6172 6269 7472 6172 696c 7920 6772 6f77  arbitrarily grow
+00002730: 7468 2e20 496e 2070 7261 6374 6963 652c  th. In practice,
+00002740: 2069 7420 7365 656d 7320 746f 2062 6520   it seems to be 
+00002750: 6672 7569 7466 756c 0a20 2020 202f 2f20  fruitful.    // 
+00002760: 746f 206c 696d 6974 2074 6869 7320 6772  to limit this gr
+00002770: 6f77 7468 3a20 7765 2062 6f75 6e64 206e  owth: we bound n
+00002780: 6320 746f 2067 726f 7774 6820 6279 2061  c to growth by a
+00002790: 2066 6163 746f 7220 7831 2e35 2e0a 2020   factor x1.5..  
+000027a0: 2020 2f2f 2048 6f77 6576 6572 2c20 6966    // However, if
+000027b0: 2074 6865 2065 6e74 6972 6520 6c68 7320   the entire lhs 
+000027c0: 626c 6f63 6b20 6669 7420 7769 7468 696e  block fit within
+000027d0: 204c 312c 2074 6865 6e20 7765 2061 7265   L1, then we are
+000027e0: 206e 6f74 2067 6f69 6e67 2074 6f20 626c   not going to bl
+000027f0: 6f63 6b20 6f6e 2074 6865 2072 6f77 7320  ock on the rows 
+00002800: 6174 2061 6c6c 2c0a 2020 2020 2f2f 2061  at all,.    // a
+00002810: 6e64 2069 7420 6265 636f 6d65 7320 6672  nd it becomes fr
+00002820: 7569 7466 756c 2074 6f20 6b65 6570 2074  uitful to keep t
+00002830: 6865 2070 6163 6b65 6420 7268 7320 626c  he packed rhs bl
+00002840: 6f63 6b73 2069 6e20 4c31 2069 6620 7468  ocks in L1 if th
+00002850: 6572 6520 6973 2065 6e6f 7567 6820 7265  ere is enough re
+00002860: 6d61 696e 696e 6720 7370 6163 652e 0a20  maining space.. 
+00002870: 2020 2049 6e64 6578 206d 6178 5f6e 633b     Index max_nc;
+00002880: 0a20 2020 2063 6f6e 7374 2049 6e64 6578  .    const Index
+00002890: 206c 6873 5f62 7974 6573 203d 206d 202a   lhs_bytes = m *
+000028a0: 206b 202a 2073 697a 656f 6628 4c68 7353   k * sizeof(LhsS
+000028b0: 6361 6c61 7229 3b0a 2020 2020 636f 6e73  calar);.    cons
+000028c0: 7420 496e 6465 7820 7265 6d61 696e 696e  t Index remainin
+000028d0: 675f 6c31 203d 206c 312d 206b 5f73 7562  g_l1 = l1- k_sub
+000028e0: 202d 206c 6873 5f62 7974 6573 3b0a 2020   - lhs_bytes;.  
+000028f0: 2020 6966 2872 656d 6169 6e69 6e67 5f6c    if(remaining_l
+00002900: 3120 3e3d 2049 6e64 6578 2854 7261 6974  1 >= Index(Trait
+00002910: 733a 3a6e 722a 7369 7a65 6f66 2852 6873  s::nr*sizeof(Rhs
+00002920: 5363 616c 6172 2929 2a6b 290a 2020 2020  Scalar))*k).    
+00002930: 7b0a 2020 2020 2020 2f2f 204c 3120 626c  {.      // L1 bl
+00002940: 6f63 6b69 6e67 0a20 2020 2020 206d 6178  ocking.      max
+00002950: 5f6e 6320 3d20 7265 6d61 696e 696e 675f  _nc = remaining_
+00002960: 6c31 202f 2028 6b2a 7369 7a65 6f66 2852  l1 / (k*sizeof(R
+00002970: 6873 5363 616c 6172 2929 3b0a 2020 2020  hsScalar));.    
+00002980: 7d0a 2020 2020 656c 7365 0a20 2020 207b  }.    else.    {
+00002990: 0a20 2020 2020 202f 2f20 4c32 2062 6c6f  .      // L2 blo
+000029a0: 636b 696e 670a 2020 2020 2020 6d61 785f  cking.      max_
+000029b0: 6e63 203d 2028 332a 6163 7475 616c 5f6c  nc = (3*actual_l
+000029c0: 3229 2f28 322a 322a 6d61 785f 6b63 2a73  2)/(2*2*max_kc*s
+000029d0: 697a 656f 6628 5268 7353 6361 6c61 7229  izeof(RhsScalar)
+000029e0: 293b 0a20 2020 207d 0a20 2020 202f 2f20  );.    }.    // 
+000029f0: 5741 524e 494e 4720 4265 6c6f 772c 2077  WARNING Below, w
+00002a00: 6520 6173 7375 6d65 2074 6861 7420 5472  e assume that Tr
+00002a10: 6169 7473 3a3a 6e72 2069 7320 6120 706f  aits::nr is a po
+00002a20: 7765 7220 6f66 2074 776f 2e0a 2020 2020  wer of two..    
+00002a30: 496e 6465 7820 6e63 203d 206e 756d 6578  Index nc = numex
+00002a40: 743a 3a6d 696e 693c 496e 6465 783e 2861  t::mini<Index>(a
+00002a50: 6374 7561 6c5f 6c32 2f28 322a 6b2a 7369  ctual_l2/(2*k*si
+00002a60: 7a65 6f66 2852 6873 5363 616c 6172 2929  zeof(RhsScalar))
+00002a70: 2c20 6d61 785f 6e63 2920 2620 287e 2854  , max_nc) & (~(T
+00002a80: 7261 6974 733a 3a6e 722d 3129 293b 0a20  raits::nr-1));. 
+00002a90: 2020 2069 6628 6e3e 6e63 290a 2020 2020     if(n>nc).    
+00002aa0: 7b0a 2020 2020 2020 2f2f 2057 6520 6172  {.      // We ar
+00002ab0: 6520 7265 616c 6c79 2062 6c6f 636b 696e  e really blockin
+00002ac0: 6720 6f76 6572 2074 6865 2063 6f6c 756d  g over the colum
+00002ad0: 6e73 3a0a 2020 2020 2020 2f2f 202d 3e20  ns:.      // -> 
+00002ae0: 7265 6475 6365 2062 6c6f 636b 696e 6720  reduce blocking 
+00002af0: 7369 7a65 2074 6f20 6d61 6b65 2073 7572  size to make sur
+00002b00: 6520 7468 6520 6c61 7374 2062 6c6f 636b  e the last block
+00002b10: 2069 7320 6173 206c 6172 6765 2061 7320   is as large as 
+00002b20: 706f 7373 6962 6c65 0a20 2020 2020 202f  possible.      /
+00002b30: 2f20 2020 2077 6869 6c65 206b 6565 7069  /    while keepi
+00002b40: 6e67 2074 6865 2073 616d 6520 6e75 6d62  ng the same numb
+00002b50: 6572 206f 6620 7377 6565 7073 206f 7665  er of sweeps ove
+00002b60: 7220 7468 6520 7061 636b 6564 206c 6873  r the packed lhs
+00002b70: 2e0a 2020 2020 2020 2f2f 2020 2020 4865  ..      //    He
+00002b80: 7265 2077 6520 616c 6c6f 7720 6f6e 6520  re we allow one 
+00002b90: 6d6f 7265 2073 7765 6570 2069 6620 7468  more sweep if th
+00002ba0: 6973 2067 6976 6573 2075 7320 6120 7065  is gives us a pe
+00002bb0: 7266 6563 7420 6d61 7463 682c 2074 6875  rfect match, thu
+00002bc0: 7320 7468 6520 636f 6d6d 656e 7465 6420  s the commented 
+00002bd0: 222d 3122 0a20 2020 2020 206e 203d 2028  "-1".      n = (
+00002be0: 6e25 6e63 293d 3d30 203f 206e 630a 2020  n%nc)==0 ? nc.  
+00002bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00002c00: 2020 3a20 286e 6320 2d20 5472 6169 7473    : (nc - Traits
+00002c10: 3a3a 6e72 202a 2028 286e 632f 2a2d 312a  ::nr * ((nc/*-1*
+00002c20: 2f2d 286e 256e 6329 292f 2854 7261 6974  /-(n%nc))/(Trait
+00002c30: 733a 3a6e 722a 286e 2f6e 632b 3129 2929  s::nr*(n/nc+1)))
+00002c40: 293b 0a20 2020 207d 0a20 2020 2065 6c73  );.    }.    els
+00002c50: 6520 6966 286f 6c64 5f6b 3d3d 6b29 0a20  e if(old_k==k). 
+00002c60: 2020 207b 0a20 2020 2020 202f 2f20 536f     {.      // So
+00002c70: 2066 6172 2c20 6e6f 2062 6c6f 636b 696e   far, no blockin
+00002c80: 6720 6174 2061 6c6c 2c20 692e 652e 2c20  g at all, i.e., 
+00002c90: 6b63 3d3d 6b2c 2061 6e64 206e 633d 3d6e  kc==k, and nc==n
+00002ca0: 2e0a 2020 2020 2020 2f2f 2049 6e20 7468  ..      // In th
+00002cb0: 6973 2063 6173 652c 206c 6574 2773 2070  is case, let's p
+00002cc0: 6572 666f 726d 2061 2062 6c6f 636b 696e  erform a blockin
+00002cd0: 6720 6f76 6572 2074 6865 2072 6f77 7320  g over the rows 
+00002ce0: 7375 6368 2074 6861 7420 7468 6520 7061  such that the pa
+00002cf0: 636b 6564 206c 6873 2064 6174 6120 6973  cked lhs data is
+00002d00: 206b 6570 7420 696e 2063 6163 6865 204c   kept in cache L
+00002d10: 312f 4c32 0a20 2020 2020 202f 2f20 544f  1/L2.      // TO
+00002d20: 444f 3a20 7061 7274 206f 6620 7468 6973  DO: part of this
+00002d30: 2062 6c6f 636b 696e 6720 7374 7261 7465   blocking strate
+00002d40: 6779 2069 7320 6e6f 7720 696d 706c 656d  gy is now implem
+00002d50: 656e 7465 6420 7769 7468 696e 2074 6865  ented within the
+00002d60: 206b 6572 6e65 6c20 6974 7365 6c66 2c20   kernel itself, 
+00002d70: 736f 2074 6865 204c 312d 6261 7365 6420  so the L1-based 
+00002d80: 6865 7572 6973 7469 6320 6865 7265 2073  heuristic here s
+00002d90: 686f 756c 6420 6265 206f 6273 6f6c 6574  hould be obsolet
+00002da0: 652e 0a20 2020 2020 2049 6e64 6578 2070  e..      Index p
+00002db0: 726f 626c 656d 5f73 697a 6520 3d20 6b2a  roblem_size = k*
+00002dc0: 6e2a 7369 7a65 6f66 284c 6873 5363 616c  n*sizeof(LhsScal
+00002dd0: 6172 293b 0a20 2020 2020 2049 6e64 6578  ar);.      Index
+00002de0: 2061 6374 7561 6c5f 6c6d 203d 2061 6374   actual_lm = act
+00002df0: 7561 6c5f 6c32 3b0a 2020 2020 2020 496e  ual_l2;.      In
+00002e00: 6465 7820 6d61 785f 6d63 203d 206d 3b0a  dex max_mc = m;.
+00002e10: 2020 2020 2020 6966 2870 726f 626c 656d        if(problem
+00002e20: 5f73 697a 653c 3d31 3032 3429 0a20 2020  _size<=1024).   
+00002e30: 2020 207b 0a20 2020 2020 2020 202f 2f20     {.        // 
+00002e40: 7072 6f62 6c65 6d20 6973 2073 6d61 6c6c  problem is small
+00002e50: 2065 6e6f 7567 6820 746f 206b 6565 7020   enough to keep 
+00002e60: 696e 204c 310a 2020 2020 2020 2020 2f2f  in L1.        //
+00002e70: 204c 6574 2773 2063 686f 6f73 6520 6d20   Let's choose m 
+00002e80: 7375 6368 2074 6861 7420 6c68 7327 7320  such that lhs's 
+00002e90: 626c 6f63 6b20 6669 7420 696e 2031 2f33  block fit in 1/3
+00002ea0: 206f 6620 4c31 0a20 2020 2020 2020 2061   of L1.        a
+00002eb0: 6374 7561 6c5f 6c6d 203d 206c 313b 0a20  ctual_lm = l1;. 
+00002ec0: 2020 2020 207d 0a20 2020 2020 2065 6c73       }.      els
+00002ed0: 6520 6966 286c 3321 3d30 2026 2620 7072  e if(l3!=0 && pr
+00002ee0: 6f62 6c65 6d5f 7369 7a65 3c3d 3332 3736  oblem_size<=3276
+00002ef0: 3829 0a20 2020 2020 207b 0a20 2020 2020  8).      {.     
+00002f00: 2020 202f 2f20 7765 2068 6176 6520 626f     // we have bo
+00002f10: 7468 204c 3220 616e 6420 4c33 2c20 616e  th L2 and L3, an
+00002f20: 6420 7072 6f62 6c65 6d20 6973 2073 6d61  d problem is sma
+00002f30: 6c6c 2065 6e6f 7567 6820 746f 2062 6520  ll enough to be 
+00002f40: 6b65 7074 2069 6e20 4c32 0a20 2020 2020  kept in L2.     
+00002f50: 2020 202f 2f20 4c65 7427 7320 6368 6f6f     // Let's choo
+00002f60: 7365 206d 2073 7563 6820 7468 6174 206c  se m such that l
+00002f70: 6873 2773 2062 6c6f 636b 2066 6974 2069  hs's block fit i
+00002f80: 6e20 312f 3320 6f66 204c 320a 2020 2020  n 1/3 of L2.    
+00002f90: 2020 2020 6163 7475 616c 5f6c 6d20 3d20      actual_lm = 
+00002fa0: 6c32 3b0a 2020 2020 2020 2020 6d61 785f  l2;.        max_
+00002fb0: 6d63 203d 2028 6e75 6d65 7874 3a3a 6d69  mc = (numext::mi
+00002fc0: 6e69 3c49 6e64 6578 3e29 2835 3736 2c6d  ni<Index>)(576,m
+00002fd0: 6178 5f6d 6329 3b0a 2020 2020 2020 7d0a  ax_mc);.      }.
+00002fe0: 2020 2020 2020 496e 6465 7820 6d63 203d        Index mc =
+00002ff0: 2028 6e75 6d65 7874 3a3a 6d69 6e69 3c49   (numext::mini<I
+00003000: 6e64 6578 3e29 2861 6374 7561 6c5f 6c6d  ndex>)(actual_lm
+00003010: 2f28 332a 6b2a 7369 7a65 6f66 284c 6873  /(3*k*sizeof(Lhs
+00003020: 5363 616c 6172 2929 2c20 6d61 785f 6d63  Scalar)), max_mc
+00003030: 293b 0a20 2020 2020 2069 6620 286d 6320  );.      if (mc 
+00003040: 3e20 5472 6169 7473 3a3a 6d72 2920 6d63  > Traits::mr) mc
+00003050: 202d 3d20 6d63 2025 2054 7261 6974 733a   -= mc % Traits:
+00003060: 3a6d 723b 0a20 2020 2020 2065 6c73 6520  :mr;.      else 
+00003070: 6966 2028 6d63 3d3d 3029 2072 6574 7572  if (mc==0) retur
+00003080: 6e3b 0a20 2020 2020 206d 203d 2028 6d25  n;.      m = (m%
+00003090: 6d63 293d 3d30 203f 206d 630a 2020 2020  mc)==0 ? mc.    
+000030a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000030b0: 3a20 286d 6320 2d20 5472 6169 7473 3a3a  : (mc - Traits::
+000030c0: 6d72 202a 2028 286d 632f 2a2d 312a 2f2d  mr * ((mc/*-1*/-
+000030d0: 286d 256d 6329 292f 2854 7261 6974 733a  (m%mc))/(Traits:
+000030e0: 3a6d 722a 286d 2f6d 632b 3129 2929 293b  :mr*(m/mc+1))));
+000030f0: 0a20 2020 207d 0a20 207d 0a7d 0a0a 7465  .    }.  }.}..te
+00003100: 6d70 6c61 7465 203c 7479 7065 6e61 6d65  mplate <typename
+00003110: 2049 6e64 6578 3e0a 696e 6c69 6e65 2062   Index>.inline b
+00003120: 6f6f 6c20 7573 6553 7065 6369 6669 6342  ool useSpecificB
+00003130: 6c6f 636b 696e 6753 697a 6573 2849 6e64  lockingSizes(Ind
+00003140: 6578 2620 6b2c 2049 6e64 6578 2620 6d2c  ex& k, Index& m,
+00003150: 2049 6e64 6578 2620 6e29 0a7b 0a23 6966   Index& n).{.#if
+00003160: 6465 6620 4549 4745 4e5f 5445 5354 5f53  def EIGEN_TEST_S
+00003170: 5045 4349 4649 435f 424c 4f43 4b49 4e47  PECIFIC_BLOCKING
+00003180: 5f53 495a 4553 0a20 2069 6620 2845 4947  _SIZES.  if (EIG
+00003190: 454e 5f54 4553 545f 5350 4543 4946 4943  EN_TEST_SPECIFIC
+000031a0: 5f42 4c4f 434b 494e 475f 5349 5a45 5329  _BLOCKING_SIZES)
+000031b0: 207b 0a20 2020 206b 203d 206e 756d 6578   {.    k = numex
+000031c0: 743a 3a6d 696e 693c 496e 6465 783e 286b  t::mini<Index>(k
+000031d0: 2c20 4549 4745 4e5f 5445 5354 5f53 5045  , EIGEN_TEST_SPE
+000031e0: 4349 4649 435f 424c 4f43 4b49 4e47 5f53  CIFIC_BLOCKING_S
+000031f0: 495a 455f 4b29 3b0a 2020 2020 6d20 3d20  IZE_K);.    m = 
+00003200: 6e75 6d65 7874 3a3a 6d69 6e69 3c49 6e64  numext::mini<Ind
+00003210: 6578 3e28 6d2c 2045 4947 454e 5f54 4553  ex>(m, EIGEN_TES
+00003220: 545f 5350 4543 4946 4943 5f42 4c4f 434b  T_SPECIFIC_BLOCK
+00003230: 494e 475f 5349 5a45 5f4d 293b 0a20 2020  ING_SIZE_M);.   
+00003240: 206e 203d 206e 756d 6578 743a 3a6d 696e   n = numext::min
+00003250: 693c 496e 6465 783e 286e 2c20 4549 4745  i<Index>(n, EIGE
+00003260: 4e5f 5445 5354 5f53 5045 4349 4649 435f  N_TEST_SPECIFIC_
+00003270: 424c 4f43 4b49 4e47 5f53 495a 455f 4e29  BLOCKING_SIZE_N)
+00003280: 3b0a 2020 2020 7265 7475 726e 2074 7275  ;.    return tru
+00003290: 653b 0a20 207d 0a23 656c 7365 0a20 2045  e;.  }.#else.  E
+000032a0: 4947 454e 5f55 4e55 5345 445f 5641 5249  IGEN_UNUSED_VARI
+000032b0: 4142 4c45 286b 290a 2020 4549 4745 4e5f  ABLE(k).  EIGEN_
+000032c0: 554e 5553 4544 5f56 4152 4941 424c 4528  UNUSED_VARIABLE(
+000032d0: 6d29 0a20 2045 4947 454e 5f55 4e55 5345  m).  EIGEN_UNUSE
+000032e0: 445f 5641 5249 4142 4c45 286e 290a 2365  D_VARIABLE(n).#e
+000032f0: 6e64 6966 0a20 2072 6574 7572 6e20 6661  ndif.  return fa
+00003300: 6c73 653b 0a7d 0a0a 2f2a 2a20 5c62 7269  lse;.}../** \bri
+00003310: 6566 2043 6f6d 7075 7465 7320 7468 6520  ef Computes the 
+00003320: 626c 6f63 6b69 6e67 2070 6172 616d 6574  blocking paramet
+00003330: 6572 7320 666f 7220 6120 6d20 7820 6b20  ers for a m x k 
+00003340: 7469 6d65 7320 6b20 7820 6e20 6d61 7472  times k x n matr
+00003350: 6978 2070 726f 6475 6374 0a20 202a 0a20  ix product.  *. 
+00003360: 202a 205c 7061 7261 6d5b 696e 2c6f 7574   * \param[in,out
+00003370: 5d20 6b20 496e 7075 743a 2074 6865 2074  ] k Input: the t
+00003380: 6869 7264 2064 696d 656e 7369 6f6e 206f  hird dimension o
+00003390: 6620 7468 6520 7072 6f64 7563 742e 204f  f the product. O
+000033a0: 7574 7075 743a 2074 6865 2062 6c6f 636b  utput: the block
+000033b0: 696e 6720 7369 7a65 2061 6c6f 6e67 2074  ing size along t
+000033c0: 6865 2073 616d 6520 6469 6d65 6e73 696f  he same dimensio
+000033d0: 6e2e 0a20 202a 205c 7061 7261 6d5b 696e  n..  * \param[in
+000033e0: 2c6f 7574 5d20 6d20 496e 7075 743a 2074  ,out] m Input: t
+000033f0: 6865 206e 756d 6265 7220 6f66 2072 6f77  he number of row
+00003400: 7320 6f66 2074 6865 206c 6566 7420 6861  s of the left ha
+00003410: 6e64 2073 6964 652e 204f 7574 7075 743a  nd side. Output:
+00003420: 2074 6865 2062 6c6f 636b 696e 6720 7369   the blocking si
+00003430: 7a65 2061 6c6f 6e67 2074 6865 2073 616d  ze along the sam
+00003440: 6520 6469 6d65 6e73 696f 6e2e 0a20 202a  e dimension..  *
+00003450: 205c 7061 7261 6d5b 696e 2c6f 7574 5d20   \param[in,out] 
+00003460: 6e20 496e 7075 743a 2074 6865 206e 756d  n Input: the num
+00003470: 6265 7220 6f66 2063 6f6c 756d 6e73 206f  ber of columns o
+00003480: 6620 7468 6520 7269 6768 7420 6861 6e64  f the right hand
+00003490: 2073 6964 652e 204f 7574 7075 743a 2074   side. Output: t
+000034a0: 6865 2062 6c6f 636b 696e 6720 7369 7a65  he blocking size
+000034b0: 2061 6c6f 6e67 2074 6865 2073 616d 6520   along the same 
+000034c0: 6469 6d65 6e73 696f 6e2e 0a20 202a 0a20  dimension..  *. 
+000034d0: 202a 2047 6976 656e 2061 206d 2078 206b   * Given a m x k
+000034e0: 2074 696d 6573 206b 2078 206e 206d 6174   times k x n mat
+000034f0: 7269 7820 7072 6f64 7563 7420 6f66 2073  rix product of s
+00003500: 6361 6c61 7220 7479 7065 7320 5c63 204c  calar types \c L
+00003510: 6873 5363 616c 6172 2061 6e64 205c 6320  hsScalar and \c 
+00003520: 5268 7353 6361 6c61 722c 0a20 202a 2074  RhsScalar,.  * t
+00003530: 6869 7320 6675 6e63 7469 6f6e 2063 6f6d  his function com
+00003540: 7075 7465 7320 7468 6520 626c 6f63 6b69  putes the blocki
+00003550: 6e67 2073 697a 6520 7061 7261 6d65 7465  ng size paramete
+00003560: 7273 2061 6c6f 6e67 2074 6865 2072 6573  rs along the res
+00003570: 7065 6374 6976 6520 6469 6d65 6e73 696f  pective dimensio
+00003580: 6e73 0a20 202a 2066 6f72 206d 6174 7269  ns.  * for matri
+00003590: 7820 7072 6f64 7563 7473 2061 6e64 2072  x products and r
+000035a0: 656c 6174 6564 2061 6c67 6f72 6974 686d  elated algorithm
+000035b0: 732e 0a20 202a 0a20 202a 2054 6865 2062  s..  *.  * The b
+000035c0: 6c6f 636b 696e 6720 7369 7a65 2070 6172  locking size par
+000035d0: 616d 6574 6572 7320 6d61 7920 6265 2065  ameters may be e
+000035e0: 7661 6c75 6174 6564 3a0a 2020 2a20 2020  valuated:.  *   
+000035f0: 2d20 6569 7468 6572 2062 7920 6120 6865  - either by a he
+00003600: 7572 6973 7469 6320 6261 7365 6420 6f6e  uristic based on
+00003610: 2063 6163 6865 2073 697a 6573 3b0a 2020   cache sizes;.  
+00003620: 2a20 2020 2d20 6f72 2075 7369 6e67 2066  *   - or using f
+00003630: 6978 6564 2070 7265 7363 7269 6265 6420  ixed prescribed 
+00003640: 7661 6c75 6573 2028 666f 7220 7465 7374  values (for test
+00003650: 696e 6720 7075 7270 6f73 6573 292e 0a20  ing purposes).. 
+00003660: 202a 0a20 202a 205c 7361 2073 6574 4370   *.  * \sa setCp
+00003670: 7543 6163 6865 5369 7a65 7320 2a2f 0a0a  uCacheSizes */..
+00003680: 7465 6d70 6c61 7465 3c74 7970 656e 616d  template<typenam
+00003690: 6520 4c68 7353 6361 6c61 722c 2074 7970  e LhsScalar, typ
+000036a0: 656e 616d 6520 5268 7353 6361 6c61 722c  ename RhsScalar,
+000036b0: 2069 6e74 204b 6346 6163 746f 722c 2074   int KcFactor, t
+000036c0: 7970 656e 616d 6520 496e 6465 783e 0a76  ypename Index>.v
+000036d0: 6f69 6420 636f 6d70 7574 6550 726f 6475  oid computeProdu
+000036e0: 6374 426c 6f63 6b69 6e67 5369 7a65 7328  ctBlockingSizes(
+000036f0: 496e 6465 7826 206b 2c20 496e 6465 7826  Index& k, Index&
+00003700: 206d 2c20 496e 6465 7826 206e 2c20 496e   m, Index& n, In
+00003710: 6465 7820 6e75 6d5f 7468 7265 6164 7320  dex num_threads 
+00003720: 3d20 3129 0a7b 0a20 2069 6620 2821 7573  = 1).{.  if (!us
+00003730: 6553 7065 6369 6669 6342 6c6f 636b 696e  eSpecificBlockin
+00003740: 6753 697a 6573 286b 2c20 6d2c 206e 2929  gSizes(k, m, n))
+00003750: 207b 0a20 2020 2065 7661 6c75 6174 6550   {.    evaluateP
+00003760: 726f 6475 6374 426c 6f63 6b69 6e67 5369  roductBlockingSi
+00003770: 7a65 7348 6575 7269 7374 6963 3c4c 6873  zesHeuristic<Lhs
+00003780: 5363 616c 6172 2c20 5268 7353 6361 6c61  Scalar, RhsScala
+00003790: 722c 204b 6346 6163 746f 722c 2049 6e64  r, KcFactor, Ind
+000037a0: 6578 3e28 6b2c 206d 2c20 6e2c 206e 756d  ex>(k, m, n, num
+000037b0: 5f74 6872 6561 6473 293b 0a20 207d 0a7d  _threads);.  }.}
+000037c0: 0a0a 7465 6d70 6c61 7465 3c74 7970 656e  ..template<typen
+000037d0: 616d 6520 4c68 7353 6361 6c61 722c 2074  ame LhsScalar, t
+000037e0: 7970 656e 616d 6520 5268 7353 6361 6c61  ypename RhsScala
+000037f0: 722c 2074 7970 656e 616d 6520 496e 6465  r, typename Inde
+00003800: 783e 0a69 6e6c 696e 6520 766f 6964 2063  x>.inline void c
+00003810: 6f6d 7075 7465 5072 6f64 7563 7442 6c6f  omputeProductBlo
+00003820: 636b 696e 6753 697a 6573 2849 6e64 6578  ckingSizes(Index
+00003830: 2620 6b2c 2049 6e64 6578 2620 6d2c 2049  & k, Index& m, I
+00003840: 6e64 6578 2620 6e2c 2049 6e64 6578 206e  ndex& n, Index n
+00003850: 756d 5f74 6872 6561 6473 203d 2031 290a  um_threads = 1).
+00003860: 7b0a 2020 636f 6d70 7574 6550 726f 6475  {.  computeProdu
+00003870: 6374 426c 6f63 6b69 6e67 5369 7a65 733c  ctBlockingSizes<
+00003880: 4c68 7353 6361 6c61 722c 5268 7353 6361  LhsScalar,RhsSca
+00003890: 6c61 722c 312c 496e 6465 783e 286b 2c20  lar,1,Index>(k, 
+000038a0: 6d2c 206e 2c20 6e75 6d5f 7468 7265 6164  m, n, num_thread
+000038b0: 7329 3b0a 7d0a 0a74 656d 706c 6174 6520  s);.}..template 
+000038c0: 3c74 7970 656e 616d 6520 5268 7350 6163  <typename RhsPac
+000038d0: 6b65 742c 2074 7970 656e 616d 6520 5268  ket, typename Rh
+000038e0: 7350 6163 6b65 7478 342c 2069 6e74 2072  sPacketx4, int r
+000038f0: 6567 6973 7465 7273 5f74 616b 656e 3e0a  egisters_taken>.
+00003900: 7374 7275 6374 2052 6873 5061 6e65 6c48  struct RhsPanelH
+00003910: 656c 7065 7220 7b0a 2070 7269 7661 7465  elper {. private
+00003920: 3a0a 2020 7374 6174 6963 2063 6f6e 7374  :.  static const
+00003930: 2069 6e74 2072 656d 6169 6e69 6e67 5f72   int remaining_r
+00003940: 6567 6973 7465 7273 203d 2045 4947 454e  egisters = EIGEN
+00003950: 5f41 5243 485f 4445 4641 554c 545f 4e55  _ARCH_DEFAULT_NU
+00003960: 4d42 4552 5f4f 465f 5245 4749 5354 4552  MBER_OF_REGISTER
+00003970: 5320 2d20 7265 6769 7374 6572 735f 7461  S - registers_ta
+00003980: 6b65 6e3b 0a20 7075 626c 6963 3a0a 2020  ken;. public:.  
+00003990: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
+000039a0: 2063 6f6e 6469 7469 6f6e 616c 3c72 656d   conditional<rem
+000039b0: 6169 6e69 6e67 5f72 6567 6973 7465 7273  aining_registers
+000039c0: 3e3d 342c 2052 6873 5061 636b 6574 7834  >=4, RhsPacketx4
+000039d0: 2c20 5268 7350 6163 6b65 743e 3a3a 7479  , RhsPacket>::ty
+000039e0: 7065 2074 7970 653b 0a7d 3b0a 0a74 656d  pe type;.};..tem
+000039f0: 706c 6174 6520 3c74 7970 656e 616d 6520  plate <typename 
+00003a00: 5061 636b 6574 3e0a 7374 7275 6374 2051  Packet>.struct Q
+00003a10: 7561 6450 6163 6b65 740a 7b0a 2020 5061  uadPacket.{.  Pa
+00003a20: 636b 6574 2042 5f30 2c20 4231 2c20 4232  cket B_0, B1, B2
+00003a30: 2c20 4233 3b0a 2020 636f 6e73 7420 5061  , B3;.  const Pa
+00003a40: 636b 6574 2620 6765 7428 636f 6e73 7420  cket& get(const 
+00003a50: 4669 7865 6449 6e74 3c30 3e26 2920 636f  FixedInt<0>&) co
+00003a60: 6e73 7420 7b20 7265 7475 726e 2042 5f30  nst { return B_0
+00003a70: 3b20 7d0a 2020 636f 6e73 7420 5061 636b  ; }.  const Pack
+00003a80: 6574 2620 6765 7428 636f 6e73 7420 4669  et& get(const Fi
+00003a90: 7865 6449 6e74 3c31 3e26 2920 636f 6e73  xedInt<1>&) cons
+00003aa0: 7420 7b20 7265 7475 726e 2042 313b 207d  t { return B1; }
+00003ab0: 0a20 2063 6f6e 7374 2050 6163 6b65 7426  .  const Packet&
+00003ac0: 2067 6574 2863 6f6e 7374 2046 6978 6564   get(const Fixed
+00003ad0: 496e 743c 323e 2629 2063 6f6e 7374 207b  Int<2>&) const {
+00003ae0: 2072 6574 7572 6e20 4232 3b20 7d0a 2020   return B2; }.  
+00003af0: 636f 6e73 7420 5061 636b 6574 2620 6765  const Packet& ge
+00003b00: 7428 636f 6e73 7420 4669 7865 6449 6e74  t(const FixedInt
+00003b10: 3c33 3e26 2920 636f 6e73 7420 7b20 7265  <3>&) const { re
+00003b20: 7475 726e 2042 333b 207d 0a7d 3b0a 0a74  turn B3; }.};..t
+00003b30: 656d 706c 6174 6520 3c69 6e74 204e 2c20  emplate <int N, 
+00003b40: 7479 7065 6e61 6d65 2054 312c 2074 7970  typename T1, typ
+00003b50: 656e 616d 6520 5432 2c20 7479 7065 6e61  ename T2, typena
+00003b60: 6d65 2054 333e 0a73 7472 7563 7420 7061  me T3>.struct pa
+00003b70: 636b 6574 5f63 6f6e 6469 7469 6f6e 616c  cket_conditional
+00003b80: 207b 2074 7970 6564 6566 2054 3320 7479   { typedef T3 ty
+00003b90: 7065 3b20 7d3b 0a0a 7465 6d70 6c61 7465  pe; };..template
+00003ba0: 203c 7479 7065 6e61 6d65 2054 312c 2074   <typename T1, t
+00003bb0: 7970 656e 616d 6520 5432 2c20 7479 7065  ypename T2, type
+00003bc0: 6e61 6d65 2054 333e 0a73 7472 7563 7420  name T3>.struct 
+00003bd0: 7061 636b 6574 5f63 6f6e 6469 7469 6f6e  packet_condition
+00003be0: 616c 3c47 4542 5050 6163 6b65 7446 756c  al<GEBPPacketFul
+00003bf0: 6c2c 2054 312c 2054 322c 2054 333e 207b  l, T1, T2, T3> {
+00003c00: 2074 7970 6564 6566 2054 3120 7479 7065   typedef T1 type
+00003c10: 3b20 7d3b 0a0a 7465 6d70 6c61 7465 203c  ; };..template <
+00003c20: 7479 7065 6e61 6d65 2054 312c 2074 7970  typename T1, typ
+00003c30: 656e 616d 6520 5432 2c20 7479 7065 6e61  ename T2, typena
+00003c40: 6d65 2054 333e 0a73 7472 7563 7420 7061  me T3>.struct pa
+00003c50: 636b 6574 5f63 6f6e 6469 7469 6f6e 616c  cket_conditional
+00003c60: 3c47 4542 5050 6163 6b65 7448 616c 662c  <GEBPPacketHalf,
+00003c70: 2054 312c 2054 322c 2054 333e 207b 2074   T1, T2, T3> { t
+00003c80: 7970 6564 6566 2054 3220 7479 7065 3b20  ypedef T2 type; 
+00003c90: 7d3b 0a0a 2364 6566 696e 6520 5041 434b  };..#define PACK
+00003ca0: 4554 5f44 4543 4c5f 434f 4e44 5f50 5245  ET_DECL_COND_PRE
+00003cb0: 4649 5828 7072 6566 6978 2c20 6e61 6d65  FIX(prefix, name
+00003cc0: 2c20 7061 636b 6574 5f73 697a 6529 2020  , packet_size)  
+00003cd0: 2020 2020 2020 205c 0a20 2074 7970 6564         \.  typed
+00003ce0: 6566 2074 7970 656e 616d 6520 7061 636b  ef typename pack
+00003cf0: 6574 5f63 6f6e 6469 7469 6f6e 616c 3c70  et_conditional<p
+00003d00: 6163 6b65 745f 7369 7a65 2c20 2020 2020  acket_size,     
+00003d10: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+00003d20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003d30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003d40: 2020 2020 7479 7065 6e61 6d65 2070 6163      typename pac
+00003d50: 6b65 745f 7472 6169 7473 3c6e 616d 6520  ket_traits<name 
+00003d60: 2323 2053 6361 6c61 723e 3a3a 7479 7065  ## Scalar>::type
+00003d70: 2c20 5c0a 2020 2020 2020 2020 2020 2020  , \.            
+00003d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003d90: 2020 2020 2020 2020 2020 7479 7065 6e61            typena
+00003da0: 6d65 2070 6163 6b65 745f 7472 6169 7473  me packet_traits
+00003db0: 3c6e 616d 6520 2323 2053 6361 6c61 723e  <name ## Scalar>
+00003dc0: 3a3a 6861 6c66 2c20 5c0a 2020 2020 2020  ::half, \.      
+00003dd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003de0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003df0: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
+00003e00: 745f 7472 6169 7473 3c74 7970 656e 616d  t_traits<typenam
+00003e10: 6520 7061 636b 6574 5f74 7261 6974 733c  e packet_traits<
+00003e20: 6e61 6d65 2023 2320 5363 616c 6172 3e3a  name ## Scalar>:
+00003e30: 3a68 616c 663e 3a3a 6861 6c66 3e3a 3a74  :half>::half>::t
+00003e40: 7970 6520 5c0a 2020 7072 6566 6978 2023  ype \.  prefix #
+00003e50: 2320 6e61 6d65 2023 2320 5061 636b 6574  # name ## Packet
+00003e60: 0a0a 2364 6566 696e 6520 5041 434b 4554  ..#define PACKET
+00003e70: 5f44 4543 4c5f 434f 4e44 286e 616d 652c  _DECL_COND(name,
+00003e80: 2070 6163 6b65 745f 7369 7a65 2920 2020   packet_size)   
+00003e90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003ea0: 2020 2020 205c 0a20 2074 7970 6564 6566       \.  typedef
+00003eb0: 2074 7970 656e 616d 6520 7061 636b 6574   typename packet
+00003ec0: 5f63 6f6e 6469 7469 6f6e 616c 3c70 6163  _conditional<pac
+00003ed0: 6b65 745f 7369 7a65 2c20 2020 2020 2020  ket_size,       
+00003ee0: 2020 2020 2020 2020 2020 5c0a 2020 2020            \.    
+00003ef0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f00: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f10: 2020 7479 7065 6e61 6d65 2070 6163 6b65    typename packe
+00003f20: 745f 7472 6169 7473 3c6e 616d 6520 2323  t_traits<name ##
+00003f30: 2053 6361 6c61 723e 3a3a 7479 7065 2c20   Scalar>::type, 
+00003f40: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00003f50: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003f60: 2020 2020 2020 2020 7479 7065 6e61 6d65          typename
+00003f70: 2070 6163 6b65 745f 7472 6169 7473 3c6e   packet_traits<n
+00003f80: 616d 6520 2323 2053 6361 6c61 723e 3a3a  ame ## Scalar>::
+00003f90: 6861 6c66 2c20 5c0a 2020 2020 2020 2020  half, \.        
+00003fa0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00003fb0: 2020 2020 2020 2020 2020 2020 2020 7479                ty
+00003fc0: 7065 6e61 6d65 2075 6e70 6163 6b65 745f  pename unpacket_
+00003fd0: 7472 6169 7473 3c74 7970 656e 616d 6520  traits<typename 
+00003fe0: 7061 636b 6574 5f74 7261 6974 733c 6e61  packet_traits<na
+00003ff0: 6d65 2023 2320 5363 616c 6172 3e3a 3a68  me ## Scalar>::h
+00004000: 616c 663e 3a3a 6861 6c66 3e3a 3a74 7970  alf>::half>::typ
+00004010: 6520 5c0a 2020 6e61 6d65 2023 2320 5061  e \.  name ## Pa
+00004020: 636b 6574 0a0a 2364 6566 696e 6520 5041  cket..#define PA
+00004030: 434b 4554 5f44 4543 4c5f 434f 4e44 5f53  CKET_DECL_COND_S
+00004040: 4341 4c41 525f 5052 4546 4958 2870 7265  CALAR_PREFIX(pre
+00004050: 6669 782c 2070 6163 6b65 745f 7369 7a65  fix, packet_size
+00004060: 2920 2020 2020 2020 205c 0a20 2074 7970  )        \.  typ
+00004070: 6564 6566 2074 7970 656e 616d 6520 7061  edef typename pa
+00004080: 636b 6574 5f63 6f6e 6469 7469 6f6e 616c  cket_conditional
+00004090: 3c70 6163 6b65 745f 7369 7a65 2c20 2020  <packet_size,   
+000040a0: 2020 2020 2020 2020 2020 2020 2020 5c0a                \.
+000040b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000040c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000040d0: 2020 2020 2020 7479 7065 6e61 6d65 2070        typename p
+000040e0: 6163 6b65 745f 7472 6169 7473 3c53 6361  acket_traits<Sca
+000040f0: 6c61 723e 3a3a 7479 7065 2c20 5c0a 2020  lar>::type, \.  
+00004100: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004110: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004120: 2020 2020 7479 7065 6e61 6d65 2070 6163      typename pac
+00004130: 6b65 745f 7472 6169 7473 3c53 6361 6c61  ket_traits<Scala
+00004140: 723e 3a3a 6861 6c66 2c20 5c0a 2020 2020  r>::half, \.    
+00004150: 2020 2020 2020 2020 2020 2020 2020 2020                  
 00004160: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004170: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00004180: 2020 2020 2020 7479 7065 6e61 6d65 2075        typename u
-00004190: 6e70 6163 6b65 745f 7472 6169 7473 3c74  npacket_traits<t
-000041a0: 7970 656e 616d 6520 7061 636b 6574 5f74  ypename packet_t
-000041b0: 7261 6974 733c 5363 616c 6172 3e3a 3a68  raits<Scalar>::h
-000041c0: 616c 663e 3a3a 6861 6c66 3e3a 3a74 7970  alf>::half>::typ
-000041d0: 6520 5c0a 2020 5363 616c 6172 5061 636b  e \.  ScalarPack
-000041e0: 6574 0a0a 2f2a 2056 6563 746f 7269 7a61  et../* Vectoriza
-000041f0: 7469 6f6e 206c 6f67 6963 0a20 2a20 2072  tion logic. *  r
-00004200: 6561 6c2a 7265 616c 3a20 756e 7061 636b  eal*real: unpack
-00004210: 2072 6873 2074 6f20 636f 6e73 7461 6e74   rhs to constant
-00004220: 2070 6163 6b65 7473 2c20 2e2e 2e0a 202a   packets, .... *
-00004230: 200a 202a 2020 6364 2a63 6420 3a20 756e   . *  cd*cd : un
-00004240: 7061 636b 2072 6873 2074 6f20 2862 5f72  pack rhs to (b_r
-00004250: 2c62 5f72 292c 2028 625f 692c 625f 6929  ,b_r), (b_i,b_i)
-00004260: 2c20 6d75 6c20 746f 2067 6574 2028 615f  , mul to get (a_
-00004270: 7220 625f 722c 615f 6920 625f 7229 2028  r b_r,a_i b_r) (
-00004280: 615f 7220 625f 692c 615f 6920 625f 6929  a_r b_i,a_i b_i)
-00004290: 2c0a 202a 2020 2020 2020 2020 2020 7374  ,. *          st
-000042a0: 6f72 696e 6720 6561 6368 2072 6573 2070  oring each res p
-000042b0: 6163 6b65 7420 696e 746f 2074 776f 2070  acket into two p
-000042c0: 6163 6b65 7473 2028 3278 3229 2c0a 202a  ackets (2x2),. *
-000042d0: 2020 2020 2020 2020 2020 6174 2074 6865            at the
-000042e0: 2065 6e64 2063 6f6d 6269 6e65 2074 6865   end combine the
-000042f0: 6d3a 2073 7761 7020 7468 6520 7365 636f  m: swap the seco
-00004300: 6e64 2061 6e64 2061 6464 7375 6220 7468  nd and addsub th
-00004310: 656d 200a 202a 2020 6366 2a63 6620 3a20  em . *  cf*cf : 
-00004320: 7361 6d65 2062 7574 2077 6974 6820 3278  same but with 2x
-00004330: 3420 626c 6f63 6b73 0a20 2a20 2063 706c  4 blocks. *  cpl
-00004340: 782a 7265 616c 203a 2075 6e70 6163 6b20  x*real : unpack 
-00004350: 7268 7320 746f 2063 6f6e 7374 616e 7420  rhs to constant 
-00004360: 7061 636b 6574 732c 202e 2e2e 0a20 2a20  packets, .... * 
-00004370: 2072 6561 6c2a 6370 6c78 203a 206c 6f61   real*cplx : loa
-00004380: 6420 6c68 7320 6173 2028 6130 2c61 302c  d lhs as (a0,a0,
-00004390: 6131 2c61 3129 2c20 616e 6420 6d75 6c20  a1,a1), and mul 
-000043a0: 6173 2075 7375 616c 0a20 2a2f 0a74 656d  as usual. */.tem
-000043b0: 706c 6174 653c 7479 7065 6e61 6d65 205f  plate<typename _
-000043c0: 4c68 7353 6361 6c61 722c 2074 7970 656e  LhsScalar, typen
-000043d0: 616d 6520 5f52 6873 5363 616c 6172 2c20  ame _RhsScalar, 
-000043e0: 626f 6f6c 205f 436f 6e6a 4c68 732c 2062  bool _ConjLhs, b
-000043f0: 6f6f 6c20 5f43 6f6e 6a52 6873 2c20 696e  ool _ConjRhs, in
-00004400: 7420 4172 6368 2c20 696e 7420 5f50 6163  t Arch, int _Pac
-00004410: 6b65 7453 697a 653e 0a63 6c61 7373 2067  ketSize>.class g
-00004420: 6562 705f 7472 6169 7473 0a7b 0a70 7562  ebp_traits.{.pub
-00004430: 6c69 633a 0a20 2074 7970 6564 6566 205f  lic:.  typedef _
-00004440: 4c68 7353 6361 6c61 7220 4c68 7353 6361  LhsScalar LhsSca
-00004450: 6c61 723b 0a20 2074 7970 6564 6566 205f  lar;.  typedef _
-00004460: 5268 7353 6361 6c61 7220 5268 7353 6361  RhsScalar RhsSca
-00004470: 6c61 723b 0a20 2074 7970 6564 6566 2074  lar;.  typedef t
-00004480: 7970 656e 616d 6520 5363 616c 6172 4269  ypename ScalarBi
-00004490: 6e61 7279 4f70 5472 6169 7473 3c4c 6873  naryOpTraits<Lhs
-000044a0: 5363 616c 6172 2c20 5268 7353 6361 6c61  Scalar, RhsScala
-000044b0: 723e 3a3a 5265 7475 726e 5479 7065 2052  r>::ReturnType R
-000044c0: 6573 5363 616c 6172 3b0a 0a20 2050 4143  esScalar;..  PAC
-000044d0: 4b45 545f 4445 434c 5f43 4f4e 445f 5052  KET_DECL_COND_PR
-000044e0: 4546 4958 285f 2c20 4c68 732c 205f 5061  EFIX(_, Lhs, _Pa
-000044f0: 636b 6574 5369 7a65 293b 0a20 2050 4143  cketSize);.  PAC
-00004500: 4b45 545f 4445 434c 5f43 4f4e 445f 5052  KET_DECL_COND_PR
-00004510: 4546 4958 285f 2c20 5268 732c 205f 5061  EFIX(_, Rhs, _Pa
-00004520: 636b 6574 5369 7a65 293b 0a20 2050 4143  cketSize);.  PAC
-00004530: 4b45 545f 4445 434c 5f43 4f4e 445f 5052  KET_DECL_COND_PR
-00004540: 4546 4958 285f 2c20 5265 732c 205f 5061  EFIX(_, Res, _Pa
-00004550: 636b 6574 5369 7a65 293b 0a0a 2020 656e  cketSize);..  en
-00004560: 756d 207b 0a20 2020 2043 6f6e 6a4c 6873  um {.    ConjLhs
-00004570: 203d 205f 436f 6e6a 4c68 732c 0a20 2020   = _ConjLhs,.   
-00004580: 2043 6f6e 6a52 6873 203d 205f 436f 6e6a   ConjRhs = _Conj
-00004590: 5268 732c 0a20 2020 2056 6563 746f 7269  Rhs,.    Vectori
-000045a0: 7a61 626c 6520 3d20 756e 7061 636b 6574  zable = unpacket
-000045b0: 5f74 7261 6974 733c 5f4c 6873 5061 636b  _traits<_LhsPack
-000045c0: 6574 3e3a 3a76 6563 746f 7269 7a61 626c  et>::vectorizabl
-000045d0: 6520 2626 2075 6e70 6163 6b65 745f 7472  e && unpacket_tr
-000045e0: 6169 7473 3c5f 5268 7350 6163 6b65 743e  aits<_RhsPacket>
-000045f0: 3a3a 7665 6374 6f72 697a 6162 6c65 2c0a  ::vectorizable,.
-00004600: 2020 2020 4c68 7350 6163 6b65 7453 697a      LhsPacketSiz
-00004610: 6520 3d20 5665 6374 6f72 697a 6162 6c65  e = Vectorizable
-00004620: 203f 2075 6e70 6163 6b65 745f 7472 6169   ? unpacket_trai
-00004630: 7473 3c5f 4c68 7350 6163 6b65 743e 3a3a  ts<_LhsPacket>::
-00004640: 7369 7a65 203a 2031 2c0a 2020 2020 5268  size : 1,.    Rh
-00004650: 7350 6163 6b65 7453 697a 6520 3d20 5665  sPacketSize = Ve
-00004660: 6374 6f72 697a 6162 6c65 203f 2075 6e70  ctorizable ? unp
-00004670: 6163 6b65 745f 7472 6169 7473 3c5f 5268  acket_traits<_Rh
-00004680: 7350 6163 6b65 743e 3a3a 7369 7a65 203a  sPacket>::size :
-00004690: 2031 2c0a 2020 2020 5265 7350 6163 6b65   1,.    ResPacke
-000046a0: 7453 697a 6520 3d20 5665 6374 6f72 697a  tSize = Vectoriz
-000046b0: 6162 6c65 203f 2075 6e70 6163 6b65 745f  able ? unpacket_
-000046c0: 7472 6169 7473 3c5f 5265 7350 6163 6b65  traits<_ResPacke
-000046d0: 743e 3a3a 7369 7a65 203a 2031 2c0a 2020  t>::size : 1,.  
-000046e0: 2020 0a20 2020 204e 756d 6265 724f 6652    .    NumberOfR
-000046f0: 6567 6973 7465 7273 203d 2045 4947 454e  egisters = EIGEN
-00004700: 5f41 5243 485f 4445 4641 554c 545f 4e55  _ARCH_DEFAULT_NU
-00004710: 4d42 4552 5f4f 465f 5245 4749 5354 4552  MBER_OF_REGISTER
-00004720: 532c 0a0a 2020 2020 2f2f 2072 6567 6973  S,..    // regis
-00004730: 7465 7220 626c 6f63 6b20 7369 7a65 2061  ter block size a
-00004740: 6c6f 6e67 2074 6865 204e 2064 6972 6563  long the N direc
-00004750: 7469 6f6e 206d 7573 7420 6265 2031 206f  tion must be 1 o
-00004760: 7220 340a 2020 2020 6e72 203d 2034 2c0a  r 4.    nr = 4,.
-00004770: 0a20 2020 202f 2f20 7265 6769 7374 6572  .    // register
-00004780: 2062 6c6f 636b 2073 697a 6520 616c 6f6e   block size alon
-00004790: 6720 7468 6520 4d20 6469 7265 6374 696f  g the M directio
-000047a0: 6e20 2863 7572 7265 6e74 6c79 2c20 7468  n (currently, th
-000047b0: 6973 206f 6e65 2063 616e 6e6f 7420 6265  is one cannot be
-000047c0: 206d 6f64 6966 6965 6429 0a20 2020 2064   modified).    d
-000047d0: 6566 6175 6c74 5f6d 7220 3d20 2845 4947  efault_mr = (EIG
-000047e0: 454e 5f50 4c41 494e 5f45 4e55 4d5f 4d49  EN_PLAIN_ENUM_MI
-000047f0: 4e28 3136 2c4e 756d 6265 724f 6652 6567  N(16,NumberOfReg
-00004800: 6973 7465 7273 292f 322f 6e72 292a 4c68  isters)/2/nr)*Lh
-00004810: 7350 6163 6b65 7453 697a 652c 0a23 6966  sPacketSize,.#if
-00004820: 2064 6566 696e 6564 2845 4947 454e 5f48   defined(EIGEN_H
-00004830: 4153 5f53 494e 474c 455f 494e 5354 5255  AS_SINGLE_INSTRU
-00004840: 4354 494f 4e5f 4d41 4444 2920 2626 2021  CTION_MADD) && !
-00004850: 6465 6669 6e65 6428 4549 4745 4e5f 5645  defined(EIGEN_VE
-00004860: 4354 4f52 495a 455f 414c 5449 5645 4329  CTORIZE_ALTIVEC)
-00004870: 2026 2620 2164 6566 696e 6564 2845 4947   && !defined(EIG
-00004880: 454e 5f56 4543 544f 5249 5a45 5f56 5358  EN_VECTORIZE_VSX
-00004890: 2920 5c0a 2020 2020 2626 2028 2821 4549  ) \.    && ((!EI
-000048a0: 4745 4e5f 434f 4d50 5f4d 5356 4329 207c  GEN_COMP_MSVC) |
-000048b0: 7c20 2845 4947 454e 5f43 4f4d 505f 4d53  | (EIGEN_COMP_MS
-000048c0: 5643 3e3d 3139 3134 2929 0a20 2020 202f  VC>=1914)).    /
-000048d0: 2f20 7765 2061 7373 756d 6520 3136 2072  / we assume 16 r
-000048e0: 6567 6973 7465 7273 206f 7220 6d6f 7265  egisters or more
-000048f0: 0a20 2020 202f 2f20 5365 6520 6275 6720  .    // See bug 
-00004900: 3939 322c 2069 6620 7468 6520 7363 616c  992, if the scal
-00004910: 6172 2074 7970 6520 6973 206e 6f74 2076  ar type is not v
-00004920: 6563 746f 7269 7a61 626c 6520 6275 7420  ectorizable but 
-00004930: 7468 6174 2045 4947 454e 5f48 4153 5f53  that EIGEN_HAS_S
-00004940: 494e 474c 455f 494e 5354 5255 4354 494f  INGLE_INSTRUCTIO
-00004950: 4e5f 4d41 4444 2069 7320 6465 6669 6e65  N_MADD is define
-00004960: 642c 0a20 2020 202f 2f20 7468 656e 2075  d,.    // then u
-00004970: 7369 6e67 2033 2a4c 6873 5061 636b 6574  sing 3*LhsPacket
-00004980: 5369 7a65 2074 7269 6767 6572 7320 6e6f  Size triggers no
-00004990: 6e2d 696d 706c 656d 656e 7465 6420 7061  n-implemented pa
-000049a0: 7468 7320 696e 2073 7972 6b2e 0a20 2020  ths in syrk..   
-000049b0: 202f 2f20 4275 6720 3135 3135 3a20 4d53   // Bug 1515: MS
-000049c0: 5643 2070 7269 6f72 2074 6f20 7631 392e  VC prior to v19.
-000049d0: 3134 2079 6965 6c64 7320 746f 2072 6567  14 yields to reg
-000049e0: 6973 7465 7220 7370 696c 6c69 6e67 2e0a  ister spilling..
-000049f0: 2020 2020 6d72 203d 2056 6563 746f 7269      mr = Vectori
-00004a00: 7a61 626c 6520 3f20 332a 4c68 7350 6163  zable ? 3*LhsPac
-00004a10: 6b65 7453 697a 6520 3a20 6465 6661 756c  ketSize : defaul
-00004a20: 745f 6d72 2c0a 2365 6c73 650a 2020 2020  t_mr,.#else.    
-00004a30: 6d72 203d 2064 6566 6175 6c74 5f6d 722c  mr = default_mr,
-00004a40: 0a23 656e 6469 660a 2020 2020 0a20 2020  .#endif.    .   
-00004a50: 204c 6873 5072 6f67 7265 7373 203d 204c   LhsProgress = L
-00004a60: 6873 5061 636b 6574 5369 7a65 2c0a 2020  hsPacketSize,.  
-00004a70: 2020 5268 7350 726f 6772 6573 7320 3d20    RhsProgress = 
-00004a80: 310a 2020 7d3b 0a0a 0a20 2074 7970 6564  1.  };...  typed
-00004a90: 6566 2074 7970 656e 616d 6520 636f 6e64  ef typename cond
-00004aa0: 6974 696f 6e61 6c3c 5665 6374 6f72 697a  itional<Vectoriz
-00004ab0: 6162 6c65 2c5f 4c68 7350 6163 6b65 742c  able,_LhsPacket,
-00004ac0: 4c68 7353 6361 6c61 723e 3a3a 7479 7065  LhsScalar>::type
-00004ad0: 204c 6873 5061 636b 6574 3b0a 2020 7479   LhsPacket;.  ty
-00004ae0: 7065 6465 6620 7479 7065 6e61 6d65 2063  pedef typename c
-00004af0: 6f6e 6469 7469 6f6e 616c 3c56 6563 746f  onditional<Vecto
-00004b00: 7269 7a61 626c 652c 5f52 6873 5061 636b  rizable,_RhsPack
-00004b10: 6574 2c52 6873 5363 616c 6172 3e3a 3a74  et,RhsScalar>::t
-00004b20: 7970 6520 5268 7350 6163 6b65 743b 0a20  ype RhsPacket;. 
-00004b30: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
-00004b40: 6520 636f 6e64 6974 696f 6e61 6c3c 5665  e conditional<Ve
-00004b50: 6374 6f72 697a 6162 6c65 2c5f 5265 7350  ctorizable,_ResP
-00004b60: 6163 6b65 742c 5265 7353 6361 6c61 723e  acket,ResScalar>
-00004b70: 3a3a 7479 7065 2052 6573 5061 636b 6574  ::type ResPacket
-00004b80: 3b0a 2020 7479 7065 6465 6620 4c68 7350  ;.  typedef LhsP
-00004b90: 6163 6b65 7420 4c68 7350 6163 6b65 7434  acket LhsPacket4
-00004ba0: 5061 636b 696e 673b 0a0a 2020 7479 7065  Packing;..  type
-00004bb0: 6465 6620 5175 6164 5061 636b 6574 3c52  def QuadPacket<R
-00004bc0: 6873 5061 636b 6574 3e20 5268 7350 6163  hsPacket> RhsPac
-00004bd0: 6b65 7478 343b 0a20 2074 7970 6564 6566  ketx4;.  typedef
-00004be0: 2052 6573 5061 636b 6574 2041 6363 5061   ResPacket AccPa
-00004bf0: 636b 6574 3b0a 2020 0a20 2045 4947 454e  cket;.  .  EIGEN
-00004c00: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-00004c10: 6f69 6420 696e 6974 4163 6328 4163 6350  oid initAcc(AccP
-00004c20: 6163 6b65 7426 2070 290a 2020 7b0a 2020  acket& p).  {.  
-00004c30: 2020 7020 3d20 7073 6574 313c 5265 7350    p = pset1<ResP
-00004c40: 6163 6b65 743e 2852 6573 5363 616c 6172  acket>(ResScalar
-00004c50: 2830 2929 3b0a 2020 7d0a 0a20 2074 656d  (0));.  }..  tem
-00004c60: 706c 6174 653c 7479 7065 6e61 6d65 2052  plate<typename R
-00004c70: 6873 5061 636b 6574 5479 7065 3e0a 2020  hsPacketType>.  
-00004c80: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-00004c90: 494e 4520 766f 6964 206c 6f61 6452 6873  INE void loadRhs
-00004ca0: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
-00004cb0: 2a20 622c 2052 6873 5061 636b 6574 5479  * b, RhsPacketTy
-00004cc0: 7065 2620 6465 7374 2920 636f 6e73 740a  pe& dest) const.
-00004cd0: 2020 7b0a 2020 2020 6465 7374 203d 2070    {.    dest = p
-00004ce0: 7365 7431 3c52 6873 5061 636b 6574 5479  set1<RhsPacketTy
-00004cf0: 7065 3e28 2a62 293b 0a20 207d 0a0a 2020  pe>(*b);.  }..  
-00004d00: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-00004d10: 494e 4520 766f 6964 206c 6f61 6452 6873  INE void loadRhs
-00004d20: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
-00004d30: 2a20 622c 2052 6873 5061 636b 6574 7834  * b, RhsPacketx4
-00004d40: 2620 6465 7374 2920 636f 6e73 740a 2020  & dest) const.  
-00004d50: 7b0a 2020 2020 7062 726f 6164 6361 7374  {.    pbroadcast
-00004d60: 3428 622c 2064 6573 742e 425f 302c 2064  4(b, dest.B_0, d
-00004d70: 6573 742e 4231 2c20 6465 7374 2e42 322c  est.B1, dest.B2,
-00004d80: 2064 6573 742e 4233 293b 0a20 207d 0a0a   dest.B3);.  }..
-00004d90: 2020 7465 6d70 6c61 7465 3c74 7970 656e    template<typen
-00004da0: 616d 6520 5268 7350 6163 6b65 7454 7970  ame RhsPacketTyp
-00004db0: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
-00004dc0: 475f 494e 4c49 4e45 2076 6f69 6420 7570  G_INLINE void up
-00004dd0: 6461 7465 5268 7328 636f 6e73 7420 5268  dateRhs(const Rh
-00004de0: 7353 6361 6c61 722a 2062 2c20 5268 7350  sScalar* b, RhsP
-00004df0: 6163 6b65 7454 7970 6526 2064 6573 7429  acketType& dest)
-00004e00: 2063 6f6e 7374 0a20 207b 0a20 2020 206c   const.  {.    l
-00004e10: 6f61 6452 6873 2862 2c20 6465 7374 293b  oadRhs(b, dest);
-00004e20: 0a20 207d 0a0a 2020 4549 4745 4e5f 5354  .  }..  EIGEN_ST
-00004e30: 524f 4e47 5f49 4e4c 494e 4520 766f 6964  RONG_INLINE void
-00004e40: 2075 7064 6174 6552 6873 2863 6f6e 7374   updateRhs(const
-00004e50: 2052 6873 5363 616c 6172 2a2c 2052 6873   RhsScalar*, Rhs
-00004e60: 5061 636b 6574 7834 2629 2063 6f6e 7374  Packetx4&) const
-00004e70: 0a20 207b 0a20 207d 0a0a 2020 4549 4745  .  {.  }..  EIGE
-00004e80: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00004e90: 766f 6964 206c 6f61 6452 6873 5175 6164  void loadRhsQuad
-00004ea0: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
-00004eb0: 2a20 622c 2052 6873 5061 636b 6574 2620  * b, RhsPacket& 
-00004ec0: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
-00004ed0: 2020 2020 6465 7374 203d 2070 6c6f 6164      dest = pload
-00004ee0: 7175 6164 3c52 6873 5061 636b 6574 3e28  quad<RhsPacket>(
-00004ef0: 6229 3b0a 2020 7d0a 0a20 2074 656d 706c  b);.  }..  templ
-00004f00: 6174 653c 7479 7065 6e61 6d65 204c 6873  ate<typename Lhs
-00004f10: 5061 636b 6574 5479 7065 3e0a 2020 4549  PacketType>.  EI
-00004f20: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
-00004f30: 4520 766f 6964 206c 6f61 644c 6873 2863  E void loadLhs(c
-00004f40: 6f6e 7374 204c 6873 5363 616c 6172 2a20  onst LhsScalar* 
-00004f50: 612c 204c 6873 5061 636b 6574 5479 7065  a, LhsPacketType
-00004f60: 2620 6465 7374 2920 636f 6e73 740a 2020  & dest) const.  
-00004f70: 7b0a 2020 2020 6465 7374 203d 2070 6c6f  {.    dest = plo
-00004f80: 6164 3c4c 6873 5061 636b 6574 5479 7065  ad<LhsPacketType
-00004f90: 3e28 6129 3b0a 2020 7d0a 0a20 2074 656d  >(a);.  }..  tem
-00004fa0: 706c 6174 653c 7479 7065 6e61 6d65 204c  plate<typename L
-00004fb0: 6873 5061 636b 6574 5479 7065 3e0a 2020  hsPacketType>.  
-00004fc0: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-00004fd0: 494e 4520 766f 6964 206c 6f61 644c 6873  INE void loadLhs
-00004fe0: 556e 616c 6967 6e65 6428 636f 6e73 7420  Unaligned(const 
-00004ff0: 4c68 7353 6361 6c61 722a 2061 2c20 4c68  LhsScalar* a, Lh
-00005000: 7350 6163 6b65 7454 7970 6526 2064 6573  sPacketType& des
-00005010: 7429 2063 6f6e 7374 0a20 207b 0a20 2020  t) const.  {.   
-00005020: 2064 6573 7420 3d20 706c 6f61 6475 3c4c   dest = ploadu<L
-00005030: 6873 5061 636b 6574 5479 7065 3e28 6129  hsPacketType>(a)
-00005040: 3b0a 2020 7d0a 0a20 2074 656d 706c 6174  ;.  }..  templat
-00005050: 653c 7479 7065 6e61 6d65 204c 6873 5061  e<typename LhsPa
-00005060: 636b 6574 5479 7065 2c20 7479 7065 6e61  cketType, typena
-00005070: 6d65 2052 6873 5061 636b 6574 5479 7065  me RhsPacketType
-00005080: 2c20 7479 7065 6e61 6d65 2041 6363 5061  , typename AccPa
-00005090: 636b 6574 5479 7065 2c20 7479 7065 6e61  cketType, typena
-000050a0: 6d65 204c 616e 6549 6454 7970 653e 0a20  me LaneIdType>. 
-000050b0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-000050c0: 4c49 4e45 2076 6f69 6420 6d61 6464 2863  LINE void madd(c
-000050d0: 6f6e 7374 204c 6873 5061 636b 6574 5479  onst LhsPacketTy
-000050e0: 7065 2620 612c 2063 6f6e 7374 2052 6873  pe& a, const Rhs
-000050f0: 5061 636b 6574 5479 7065 2620 622c 2041  PacketType& b, A
-00005100: 6363 5061 636b 6574 5479 7065 2620 632c  ccPacketType& c,
-00005110: 2052 6873 5061 636b 6574 5479 7065 2620   RhsPacketType& 
-00005120: 746d 702c 2063 6f6e 7374 204c 616e 6549  tmp, const LaneI
-00005130: 6454 7970 6526 2920 636f 6e73 740a 2020  dType&) const.  
-00005140: 7b0a 2020 2020 636f 6e6a 5f68 656c 7065  {.    conj_helpe
-00005150: 723c 4c68 7350 6163 6b65 7454 7970 652c  r<LhsPacketType,
-00005160: 5268 7350 6163 6b65 7454 7970 652c 436f  RhsPacketType,Co
-00005170: 6e6a 4c68 732c 436f 6e6a 5268 733e 2063  njLhs,ConjRhs> c
-00005180: 6a3b 0a20 2020 202f 2f20 4974 2077 6f75  j;.    // It wou
-00005190: 6c64 2062 6520 6120 6c6f 7420 636c 6561  ld be a lot clea
-000051a0: 6e65 7220 746f 2063 616c 6c20 706d 6164  ner to call pmad
-000051b0: 6420 616c 6c20 7468 6520 7469 6d65 2e20  d all the time. 
-000051c0: 556e 666f 7274 756e 6174 656c 7920 6966  Unfortunately if
-000051d0: 2077 650a 2020 2020 2f2f 206c 6574 2067   we.    // let g
-000051e0: 6363 2061 6c6c 6f63 6174 6520 7468 6520  cc allocate the 
-000051f0: 7265 6769 7374 6572 2069 6e20 7768 6963  register in whic
-00005200: 6820 746f 2073 746f 7265 2074 6865 2072  h to store the r
-00005210: 6573 756c 7420 6f66 2074 6865 2070 6d75  esult of the pmu
-00005220: 6c0a 2020 2020 2f2f 2028 696e 2074 6865  l.    // (in the
-00005230: 2063 6173 6520 7768 6572 6520 7468 6572   case where ther
-00005240: 6520 6973 206e 6f20 464d 4129 2067 6363  e is no FMA) gcc
-00005250: 2066 6169 6c73 2074 6f20 6669 6775 7265   fails to figure
-00005260: 206f 7574 2068 6f77 2074 6f20 6176 6f69   out how to avoi
-00005270: 640a 2020 2020 2f2f 2073 7069 6c6c 696e  d.    // spillin
-00005280: 6720 7265 6769 7374 6572 2e0a 2369 6664  g register..#ifd
-00005290: 6566 2045 4947 454e 5f48 4153 5f53 494e  ef EIGEN_HAS_SIN
-000052a0: 474c 455f 494e 5354 5255 4354 494f 4e5f  GLE_INSTRUCTION_
-000052b0: 4d41 4444 0a20 2020 2045 4947 454e 5f55  MADD.    EIGEN_U
-000052c0: 4e55 5345 445f 5641 5249 4142 4c45 2874  NUSED_VARIABLE(t
-000052d0: 6d70 293b 0a20 2020 2063 203d 2063 6a2e  mp);.    c = cj.
-000052e0: 706d 6164 6428 612c 622c 6329 3b0a 2365  pmadd(a,b,c);.#e
-000052f0: 6c73 650a 2020 2020 746d 7020 3d20 623b  lse.    tmp = b;
-00005300: 2074 6d70 203d 2063 6a2e 706d 756c 2861   tmp = cj.pmul(a
-00005310: 2c74 6d70 293b 2063 203d 2070 6164 6428  ,tmp); c = padd(
-00005320: 632c 746d 7029 3b0a 2365 6e64 6966 0a20  c,tmp);.#endif. 
-00005330: 207d 0a0a 2020 7465 6d70 6c61 7465 3c74   }..  template<t
-00005340: 7970 656e 616d 6520 4c68 7350 6163 6b65  ypename LhsPacke
-00005350: 7454 7970 652c 2074 7970 656e 616d 6520  tType, typename 
-00005360: 4163 6350 6163 6b65 7454 7970 652c 2074  AccPacketType, t
-00005370: 7970 656e 616d 6520 4c61 6e65 4964 5479  ypename LaneIdTy
-00005380: 7065 3e0a 2020 4549 4745 4e5f 5354 524f  pe>.  EIGEN_STRO
-00005390: 4e47 5f49 4e4c 494e 4520 766f 6964 206d  NG_INLINE void m
-000053a0: 6164 6428 636f 6e73 7420 4c68 7350 6163  add(const LhsPac
-000053b0: 6b65 7454 7970 6526 2061 2c20 636f 6e73  ketType& a, cons
-000053c0: 7420 5268 7350 6163 6b65 7478 3426 2062  t RhsPacketx4& b
-000053d0: 2c20 4163 6350 6163 6b65 7454 7970 6526  , AccPacketType&
-000053e0: 2063 2c20 5268 7350 6163 6b65 7426 2074   c, RhsPacket& t
-000053f0: 6d70 2c20 636f 6e73 7420 4c61 6e65 4964  mp, const LaneId
-00005400: 5479 7065 2620 6c61 6e65 2920 636f 6e73  Type& lane) cons
-00005410: 740a 2020 7b0a 2020 2020 6d61 6464 2861  t.  {.    madd(a
-00005420: 2c20 622e 6765 7428 6c61 6e65 292c 2063  , b.get(lane), c
-00005430: 2c20 746d 702c 206c 616e 6529 3b0a 2020  , tmp, lane);.  
-00005440: 7d0a 0a20 2045 4947 454e 5f53 5452 4f4e  }..  EIGEN_STRON
-00005450: 475f 494e 4c49 4e45 2076 6f69 6420 6163  G_INLINE void ac
-00005460: 6328 636f 6e73 7420 4163 6350 6163 6b65  c(const AccPacke
-00005470: 7426 2063 2c20 636f 6e73 7420 5265 7350  t& c, const ResP
-00005480: 6163 6b65 7426 2061 6c70 6861 2c20 5265  acket& alpha, Re
-00005490: 7350 6163 6b65 7426 2072 2920 636f 6e73  sPacket& r) cons
-000054a0: 740a 2020 7b0a 2020 2020 7220 3d20 706d  t.  {.    r = pm
-000054b0: 6164 6428 632c 616c 7068 612c 7229 3b0a  add(c,alpha,r);.
-000054c0: 2020 7d0a 2020 0a20 2074 656d 706c 6174    }.  .  templat
-000054d0: 653c 7479 7065 6e61 6d65 2052 6573 5061  e<typename ResPa
-000054e0: 636b 6574 4861 6c66 3e0a 2020 4549 4745  cketHalf>.  EIGE
-000054f0: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00005500: 766f 6964 2061 6363 2863 6f6e 7374 2052  void acc(const R
-00005510: 6573 5061 636b 6574 4861 6c66 2620 632c  esPacketHalf& c,
-00005520: 2063 6f6e 7374 2052 6573 5061 636b 6574   const ResPacket
-00005530: 4861 6c66 2620 616c 7068 612c 2052 6573  Half& alpha, Res
-00005540: 5061 636b 6574 4861 6c66 2620 7229 2063  PacketHalf& r) c
-00005550: 6f6e 7374 0a20 207b 0a20 2020 2072 203d  onst.  {.    r =
-00005560: 2070 6d61 6464 2863 2c61 6c70 6861 2c72   pmadd(c,alpha,r
-00005570: 293b 0a20 207d 0a0a 7d3b 0a0a 7465 6d70  );.  }..};..temp
-00005580: 6c61 7465 3c74 7970 656e 616d 6520 5265  late<typename Re
-00005590: 616c 5363 616c 6172 2c20 626f 6f6c 205f  alScalar, bool _
-000055a0: 436f 6e6a 4c68 732c 2069 6e74 2041 7263  ConjLhs, int Arc
-000055b0: 682c 2069 6e74 205f 5061 636b 6574 5369  h, int _PacketSi
-000055c0: 7a65 3e0a 636c 6173 7320 6765 6270 5f74  ze>.class gebp_t
-000055d0: 7261 6974 733c 7374 643a 3a63 6f6d 706c  raits<std::compl
-000055e0: 6578 3c52 6561 6c53 6361 6c61 723e 2c20  ex<RealScalar>, 
-000055f0: 5265 616c 5363 616c 6172 2c20 5f43 6f6e  RealScalar, _Con
-00005600: 6a4c 6873 2c20 6661 6c73 652c 2041 7263  jLhs, false, Arc
-00005610: 682c 205f 5061 636b 6574 5369 7a65 3e0a  h, _PacketSize>.
-00005620: 7b0a 7075 626c 6963 3a0a 2020 7479 7065  {.public:.  type
-00005630: 6465 6620 7374 643a 3a63 6f6d 706c 6578  def std::complex
-00005640: 3c52 6561 6c53 6361 6c61 723e 204c 6873  <RealScalar> Lhs
-00005650: 5363 616c 6172 3b0a 2020 7479 7065 6465  Scalar;.  typede
-00005660: 6620 5265 616c 5363 616c 6172 2052 6873  f RealScalar Rhs
-00005670: 5363 616c 6172 3b0a 2020 7479 7065 6465  Scalar;.  typede
-00005680: 6620 7479 7065 6e61 6d65 2053 6361 6c61  f typename Scala
-00005690: 7242 696e 6172 794f 7054 7261 6974 733c  rBinaryOpTraits<
-000056a0: 4c68 7353 6361 6c61 722c 2052 6873 5363  LhsScalar, RhsSc
-000056b0: 616c 6172 3e3a 3a52 6574 7572 6e54 7970  alar>::ReturnTyp
-000056c0: 6520 5265 7353 6361 6c61 723b 0a0a 2020  e ResScalar;..  
-000056d0: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
-000056e0: 5f50 5245 4649 5828 5f2c 204c 6873 2c20  _PREFIX(_, Lhs, 
-000056f0: 5f50 6163 6b65 7453 697a 6529 3b0a 2020  _PacketSize);.  
-00005700: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
-00005710: 5f50 5245 4649 5828 5f2c 2052 6873 2c20  _PREFIX(_, Rhs, 
-00005720: 5f50 6163 6b65 7453 697a 6529 3b0a 2020  _PacketSize);.  
-00005730: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
-00005740: 5f50 5245 4649 5828 5f2c 2052 6573 2c20  _PREFIX(_, Res, 
-00005750: 5f50 6163 6b65 7453 697a 6529 3b0a 0a20  _PacketSize);.. 
-00005760: 2065 6e75 6d20 7b0a 2020 2020 436f 6e6a   enum {.    Conj
-00005770: 4c68 7320 3d20 5f43 6f6e 6a4c 6873 2c0a  Lhs = _ConjLhs,.
-00005780: 2020 2020 436f 6e6a 5268 7320 3d20 6661      ConjRhs = fa
-00005790: 6c73 652c 0a20 2020 2056 6563 746f 7269  lse,.    Vectori
-000057a0: 7a61 626c 6520 3d20 756e 7061 636b 6574  zable = unpacket
-000057b0: 5f74 7261 6974 733c 5f4c 6873 5061 636b  _traits<_LhsPack
-000057c0: 6574 3e3a 3a76 6563 746f 7269 7a61 626c  et>::vectorizabl
-000057d0: 6520 2626 2075 6e70 6163 6b65 745f 7472  e && unpacket_tr
-000057e0: 6169 7473 3c5f 5268 7350 6163 6b65 743e  aits<_RhsPacket>
-000057f0: 3a3a 7665 6374 6f72 697a 6162 6c65 2c0a  ::vectorizable,.
-00005800: 2020 2020 4c68 7350 6163 6b65 7453 697a      LhsPacketSiz
-00005810: 6520 3d20 5665 6374 6f72 697a 6162 6c65  e = Vectorizable
-00005820: 203f 2075 6e70 6163 6b65 745f 7472 6169   ? unpacket_trai
-00005830: 7473 3c5f 4c68 7350 6163 6b65 743e 3a3a  ts<_LhsPacket>::
-00005840: 7369 7a65 203a 2031 2c0a 2020 2020 5268  size : 1,.    Rh
-00005850: 7350 6163 6b65 7453 697a 6520 3d20 5665  sPacketSize = Ve
-00005860: 6374 6f72 697a 6162 6c65 203f 2075 6e70  ctorizable ? unp
-00005870: 6163 6b65 745f 7472 6169 7473 3c5f 5268  acket_traits<_Rh
-00005880: 7350 6163 6b65 743e 3a3a 7369 7a65 203a  sPacket>::size :
-00005890: 2031 2c0a 2020 2020 5265 7350 6163 6b65   1,.    ResPacke
-000058a0: 7453 697a 6520 3d20 5665 6374 6f72 697a  tSize = Vectoriz
-000058b0: 6162 6c65 203f 2075 6e70 6163 6b65 745f  able ? unpacket_
-000058c0: 7472 6169 7473 3c5f 5265 7350 6163 6b65  traits<_ResPacke
-000058d0: 743e 3a3a 7369 7a65 203a 2031 2c0a 2020  t>::size : 1,.  
-000058e0: 2020 0a20 2020 204e 756d 6265 724f 6652    .    NumberOfR
-000058f0: 6567 6973 7465 7273 203d 2045 4947 454e  egisters = EIGEN
-00005900: 5f41 5243 485f 4445 4641 554c 545f 4e55  _ARCH_DEFAULT_NU
-00005910: 4d42 4552 5f4f 465f 5245 4749 5354 4552  MBER_OF_REGISTER
-00005920: 532c 0a20 2020 206e 7220 3d20 342c 0a23  S,.    nr = 4,.#
-00005930: 6966 2064 6566 696e 6564 2845 4947 454e  if defined(EIGEN
-00005940: 5f48 4153 5f53 494e 474c 455f 494e 5354  _HAS_SINGLE_INST
-00005950: 5255 4354 494f 4e5f 4d41 4444 2920 2626  RUCTION_MADD) &&
-00005960: 2021 6465 6669 6e65 6428 4549 4745 4e5f   !defined(EIGEN_
-00005970: 5645 4354 4f52 495a 455f 414c 5449 5645  VECTORIZE_ALTIVE
-00005980: 4329 2026 2620 2164 6566 696e 6564 2845  C) && !defined(E
-00005990: 4947 454e 5f56 4543 544f 5249 5a45 5f56  IGEN_VECTORIZE_V
-000059a0: 5358 290a 2020 2020 2f2f 2077 6520 6173  SX).    // we as
-000059b0: 7375 6d65 2031 3620 7265 6769 7374 6572  sume 16 register
-000059c0: 730a 2020 2020 6d72 203d 2033 2a4c 6873  s.    mr = 3*Lhs
-000059d0: 5061 636b 6574 5369 7a65 2c0a 2365 6c73  PacketSize,.#els
-000059e0: 650a 2020 2020 6d72 203d 2028 4549 4745  e.    mr = (EIGE
-000059f0: 4e5f 504c 4149 4e5f 454e 554d 5f4d 494e  N_PLAIN_ENUM_MIN
-00005a00: 2831 362c 4e75 6d62 6572 4f66 5265 6769  (16,NumberOfRegi
-00005a10: 7374 6572 7329 2f32 2f6e 7229 2a4c 6873  sters)/2/nr)*Lhs
-00005a20: 5061 636b 6574 5369 7a65 2c0a 2365 6e64  PacketSize,.#end
-00005a30: 6966 0a0a 2020 2020 4c68 7350 726f 6772  if..    LhsProgr
-00005a40: 6573 7320 3d20 4c68 7350 6163 6b65 7453  ess = LhsPacketS
-00005a50: 697a 652c 0a20 2020 2052 6873 5072 6f67  ize,.    RhsProg
-00005a60: 7265 7373 203d 2031 0a20 207d 3b0a 0a20  ress = 1.  };.. 
-00005a70: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
-00005a80: 6520 636f 6e64 6974 696f 6e61 6c3c 5665  e conditional<Ve
-00005a90: 6374 6f72 697a 6162 6c65 2c5f 4c68 7350  ctorizable,_LhsP
-00005aa0: 6163 6b65 742c 4c68 7353 6361 6c61 723e  acket,LhsScalar>
-00005ab0: 3a3a 7479 7065 204c 6873 5061 636b 6574  ::type LhsPacket
-00005ac0: 3b0a 2020 7479 7065 6465 6620 7479 7065  ;.  typedef type
-00005ad0: 6e61 6d65 2063 6f6e 6469 7469 6f6e 616c  name conditional
-00005ae0: 3c56 6563 746f 7269 7a61 626c 652c 5f52  <Vectorizable,_R
-00005af0: 6873 5061 636b 6574 2c52 6873 5363 616c  hsPacket,RhsScal
-00005b00: 6172 3e3a 3a74 7970 6520 5268 7350 6163  ar>::type RhsPac
-00005b10: 6b65 743b 0a20 2074 7970 6564 6566 2074  ket;.  typedef t
-00005b20: 7970 656e 616d 6520 636f 6e64 6974 696f  ypename conditio
-00005b30: 6e61 6c3c 5665 6374 6f72 697a 6162 6c65  nal<Vectorizable
-00005b40: 2c5f 5265 7350 6163 6b65 742c 5265 7353  ,_ResPacket,ResS
-00005b50: 6361 6c61 723e 3a3a 7479 7065 2052 6573  calar>::type Res
-00005b60: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
-00005b70: 6620 4c68 7350 6163 6b65 7420 4c68 7350  f LhsPacket LhsP
-00005b80: 6163 6b65 7434 5061 636b 696e 673b 0a0a  acket4Packing;..
-00005b90: 2020 7479 7065 6465 6620 5175 6164 5061    typedef QuadPa
-00005ba0: 636b 6574 3c52 6873 5061 636b 6574 3e20  cket<RhsPacket> 
-00005bb0: 5268 7350 6163 6b65 7478 343b 0a0a 2020  RhsPacketx4;..  
-00005bc0: 7479 7065 6465 6620 5265 7350 6163 6b65  typedef ResPacke
-00005bd0: 7420 4163 6350 6163 6b65 743b 0a0a 2020  t AccPacket;..  
-00005be0: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-00005bf0: 494e 4520 766f 6964 2069 6e69 7441 6363  INE void initAcc
-00005c00: 2841 6363 5061 636b 6574 2620 7029 0a20  (AccPacket& p). 
-00005c10: 207b 0a20 2020 2070 203d 2070 7365 7431   {.    p = pset1
-00005c20: 3c52 6573 5061 636b 6574 3e28 5265 7353  <ResPacket>(ResS
-00005c30: 6361 6c61 7228 3029 293b 0a20 207d 0a0a  calar(0));.  }..
-00005c40: 2020 7465 6d70 6c61 7465 3c74 7970 656e    template<typen
-00005c50: 616d 6520 5268 7350 6163 6b65 7454 7970  ame RhsPacketTyp
-00005c60: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
-00005c70: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
-00005c80: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
-00005c90: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
-00005ca0: 6b65 7454 7970 6526 2064 6573 7429 2063  ketType& dest) c
-00005cb0: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
-00005cc0: 7420 3d20 7073 6574 313c 5268 7350 6163  t = pset1<RhsPac
-00005cd0: 6b65 7454 7970 653e 282a 6229 3b0a 2020  ketType>(*b);.  
-00005ce0: 7d0a 0a20 2045 4947 454e 5f53 5452 4f4e  }..  EIGEN_STRON
-00005cf0: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
-00005d00: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
-00005d10: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
-00005d20: 6b65 7478 3426 2064 6573 7429 2063 6f6e  ketx4& dest) con
-00005d30: 7374 0a20 207b 0a20 2020 2070 6272 6f61  st.  {.    pbroa
-00005d40: 6463 6173 7434 2862 2c20 6465 7374 2e42  dcast4(b, dest.B
-00005d50: 5f30 2c20 6465 7374 2e42 312c 2064 6573  _0, dest.B1, des
-00005d60: 742e 4232 2c20 6465 7374 2e42 3329 3b0a  t.B2, dest.B3);.
-00005d70: 2020 7d0a 0a20 2074 656d 706c 6174 653c    }..  template<
-00005d80: 7479 7065 6e61 6d65 2052 6873 5061 636b  typename RhsPack
-00005d90: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
-00005da0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
-00005db0: 6964 2075 7064 6174 6552 6873 2863 6f6e  id updateRhs(con
-00005dc0: 7374 2052 6873 5363 616c 6172 2a20 622c  st RhsScalar* b,
-00005dd0: 2052 6873 5061 636b 6574 5479 7065 2620   RhsPacketType& 
-00005de0: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
-00005df0: 2020 2020 6c6f 6164 5268 7328 622c 2064      loadRhs(b, d
-00005e00: 6573 7429 3b0a 2020 7d0a 0a20 2045 4947  est);.  }..  EIG
-00005e10: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
-00005e20: 2076 6f69 6420 7570 6461 7465 5268 7328   void updateRhs(
-00005e30: 636f 6e73 7420 5268 7353 6361 6c61 722a  const RhsScalar*
-00005e40: 2c20 5268 7350 6163 6b65 7478 3426 2920  , RhsPacketx4&) 
-00005e50: 636f 6e73 740a 2020 7b7d 0a20 200a 2020  const.  {}.  .  
-00005e60: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-00005e70: 494e 4520 766f 6964 206c 6f61 6452 6873  INE void loadRhs
-00005e80: 5175 6164 2863 6f6e 7374 2052 6873 5363  Quad(const RhsSc
-00005e90: 616c 6172 2a20 622c 2052 6873 5061 636b  alar* b, RhsPack
-00005ea0: 6574 2620 6465 7374 2920 636f 6e73 740a  et& dest) const.
-00005eb0: 2020 7b0a 2020 2020 6c6f 6164 5268 7351    {.    loadRhsQ
-00005ec0: 7561 645f 696d 706c 2862 2c64 6573 742c  uad_impl(b,dest,
-00005ed0: 2074 7970 656e 616d 6520 636f 6e64 6974   typename condit
-00005ee0: 696f 6e61 6c3c 5268 7350 6163 6b65 7453  ional<RhsPacketS
-00005ef0: 697a 653d 3d31 362c 7472 7565 5f74 7970  ize==16,true_typ
-00005f00: 652c 6661 6c73 655f 7479 7065 3e3a 3a74  e,false_type>::t
-00005f10: 7970 6528 2929 3b0a 2020 7d0a 0a20 2045  ype());.  }..  E
-00005f20: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
-00005f30: 4e45 2076 6f69 6420 6c6f 6164 5268 7351  NE void loadRhsQ
-00005f40: 7561 645f 696d 706c 2863 6f6e 7374 2052  uad_impl(const R
-00005f50: 6873 5363 616c 6172 2a20 622c 2052 6873  hsScalar* b, Rhs
-00005f60: 5061 636b 6574 2620 6465 7374 2c20 636f  Packet& dest, co
-00005f70: 6e73 7420 7472 7565 5f74 7970 6526 2920  nst true_type&) 
-00005f80: 636f 6e73 740a 2020 7b0a 2020 2020 2f2f  const.  {.    //
-00005f90: 2046 4958 4d45 2077 6520 6361 6e20 646f   FIXME we can do
-00005fa0: 2062 6574 7465 7221 0a20 2020 202f 2f20   better!.    // 
-00005fb0: 7768 6174 2077 6520 7761 6e74 2068 6572  what we want her
-00005fc0: 6520 6973 2061 2070 6c6f 6164 6865 6967  e is a ploadheig
-00005fd0: 6874 0a20 2020 2052 6873 5363 616c 6172  ht.    RhsScalar
-00005fe0: 2074 6d70 5b34 5d20 3d20 7b62 5b30 5d2c   tmp[4] = {b[0],
-00005ff0: 625b 305d 2c62 5b31 5d2c 625b 315d 7d3b  b[0],b[1],b[1]};
-00006000: 0a20 2020 2064 6573 7420 3d20 706c 6f61  .    dest = ploa
-00006010: 6471 7561 643c 5268 7350 6163 6b65 743e  dquad<RhsPacket>
-00006020: 2874 6d70 293b 0a20 207d 0a0a 2020 4549  (tmp);.  }..  EI
-00006030: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
-00006040: 4520 766f 6964 206c 6f61 6452 6873 5175  E void loadRhsQu
-00006050: 6164 5f69 6d70 6c28 636f 6e73 7420 5268  ad_impl(const Rh
-00006060: 7353 6361 6c61 722a 2062 2c20 5268 7350  sScalar* b, RhsP
-00006070: 6163 6b65 7426 2064 6573 742c 2063 6f6e  acket& dest, con
-00006080: 7374 2066 616c 7365 5f74 7970 6526 2920  st false_type&) 
-00006090: 636f 6e73 740a 2020 7b0a 2020 2020 6569  const.  {.    ei
-000060a0: 6765 6e5f 696e 7465 726e 616c 5f61 7373  gen_internal_ass
-000060b0: 6572 7428 5268 7350 6163 6b65 7453 697a  ert(RhsPacketSiz
-000060c0: 653c 3d38 293b 0a20 2020 2064 6573 7420  e<=8);.    dest 
-000060d0: 3d20 7073 6574 313c 5268 7350 6163 6b65  = pset1<RhsPacke
-000060e0: 743e 282a 6229 3b0a 2020 7d0a 0a20 2045  t>(*b);.  }..  E
-000060f0: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
-00006100: 4e45 2076 6f69 6420 6c6f 6164 4c68 7328  NE void loadLhs(
-00006110: 636f 6e73 7420 4c68 7353 6361 6c61 722a  const LhsScalar*
-00006120: 2061 2c20 4c68 7350 6163 6b65 7426 2064   a, LhsPacket& d
-00006130: 6573 7429 2063 6f6e 7374 0a20 207b 0a20  est) const.  {. 
-00006140: 2020 2064 6573 7420 3d20 706c 6f61 643c     dest = pload<
-00006150: 4c68 7350 6163 6b65 743e 2861 293b 0a20  LhsPacket>(a);. 
-00006160: 207d 0a0a 2020 7465 6d70 6c61 7465 3c74   }..  template<t
-00006170: 7970 656e 616d 6520 4c68 7350 6163 6b65  ypename LhsPacke
-00006180: 7454 7970 653e 0a20 2045 4947 454e 5f53  tType>.  EIGEN_S
-00006190: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
-000061a0: 6420 6c6f 6164 4c68 7355 6e61 6c69 676e  d loadLhsUnalign
-000061b0: 6564 2863 6f6e 7374 204c 6873 5363 616c  ed(const LhsScal
-000061c0: 6172 2a20 612c 204c 6873 5061 636b 6574  ar* a, LhsPacket
-000061d0: 5479 7065 2620 6465 7374 2920 636f 6e73  Type& dest) cons
-000061e0: 740a 2020 7b0a 2020 2020 6465 7374 203d  t.  {.    dest =
-000061f0: 2070 6c6f 6164 753c 4c68 7350 6163 6b65   ploadu<LhsPacke
-00006200: 7454 7970 653e 2861 293b 0a20 207d 0a0a  tType>(a);.  }..
-00006210: 2020 7465 6d70 6c61 7465 203c 7479 7065    template <type
-00006220: 6e61 6d65 204c 6873 5061 636b 6574 5479  name LhsPacketTy
-00006230: 7065 2c20 7479 7065 6e61 6d65 2052 6873  pe, typename Rhs
-00006240: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
-00006250: 6e61 6d65 2041 6363 5061 636b 6574 5479  name AccPacketTy
-00006260: 7065 2c20 7479 7065 6e61 6d65 204c 616e  pe, typename Lan
-00006270: 6549 6454 7970 653e 0a20 2045 4947 454e  eIdType>.  EIGEN
-00006280: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-00006290: 6f69 6420 6d61 6464 2863 6f6e 7374 204c  oid madd(const L
-000062a0: 6873 5061 636b 6574 5479 7065 2620 612c  hsPacketType& a,
-000062b0: 2063 6f6e 7374 2052 6873 5061 636b 6574   const RhsPacket
-000062c0: 5479 7065 2620 622c 2041 6363 5061 636b  Type& b, AccPack
-000062d0: 6574 5479 7065 2620 632c 2052 6873 5061  etType& c, RhsPa
-000062e0: 636b 6574 5479 7065 2620 746d 702c 2063  cketType& tmp, c
-000062f0: 6f6e 7374 204c 616e 6549 6454 7970 6526  onst LaneIdType&
-00006300: 2920 636f 6e73 740a 2020 7b0a 2020 2020  ) const.  {.    
-00006310: 6d61 6464 5f69 6d70 6c28 612c 2062 2c20  madd_impl(a, b, 
-00006320: 632c 2074 6d70 2c20 7479 7065 6e61 6d65  c, tmp, typename
-00006330: 2063 6f6e 6469 7469 6f6e 616c 3c56 6563   conditional<Vec
-00006340: 746f 7269 7a61 626c 652c 7472 7565 5f74  torizable,true_t
-00006350: 7970 652c 6661 6c73 655f 7479 7065 3e3a  ype,false_type>:
-00006360: 3a74 7970 6528 2929 3b0a 2020 7d0a 0a20  :type());.  }.. 
-00006370: 2074 656d 706c 6174 6520 3c74 7970 656e   template <typen
-00006380: 616d 6520 4c68 7350 6163 6b65 7454 7970  ame LhsPacketTyp
-00006390: 652c 2074 7970 656e 616d 6520 5268 7350  e, typename RhsP
-000063a0: 6163 6b65 7454 7970 652c 2074 7970 656e  acketType, typen
-000063b0: 616d 6520 4163 6350 6163 6b65 7454 7970  ame AccPacketTyp
-000063c0: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
-000063d0: 475f 494e 4c49 4e45 2076 6f69 6420 6d61  G_INLINE void ma
-000063e0: 6464 5f69 6d70 6c28 636f 6e73 7420 4c68  dd_impl(const Lh
-000063f0: 7350 6163 6b65 7454 7970 6526 2061 2c20  sPacketType& a, 
-00006400: 636f 6e73 7420 5268 7350 6163 6b65 7454  const RhsPacketT
-00006410: 7970 6526 2062 2c20 4163 6350 6163 6b65  ype& b, AccPacke
-00006420: 7454 7970 6526 2063 2c20 5268 7350 6163  tType& c, RhsPac
-00006430: 6b65 7454 7970 6526 2074 6d70 2c20 636f  ketType& tmp, co
-00006440: 6e73 7420 7472 7565 5f74 7970 6526 2920  nst true_type&) 
-00006450: 636f 6e73 740a 2020 7b0a 2369 6664 6566  const.  {.#ifdef
-00006460: 2045 4947 454e 5f48 4153 5f53 494e 474c   EIGEN_HAS_SINGL
-00006470: 455f 494e 5354 5255 4354 494f 4e5f 4d41  E_INSTRUCTION_MA
-00006480: 4444 0a20 2020 2045 4947 454e 5f55 4e55  DD.    EIGEN_UNU
-00006490: 5345 445f 5641 5249 4142 4c45 2874 6d70  SED_VARIABLE(tmp
-000064a0: 293b 0a20 2020 2063 2e76 203d 2070 6d61  );.    c.v = pma
-000064b0: 6464 2861 2e76 2c62 2c63 2e76 293b 0a23  dd(a.v,b,c.v);.#
-000064c0: 656c 7365 0a20 2020 2074 6d70 203d 2062  else.    tmp = b
-000064d0: 3b20 746d 7020 3d20 706d 756c 2861 2e76  ; tmp = pmul(a.v
-000064e0: 2c74 6d70 293b 2063 2e76 203d 2070 6164  ,tmp); c.v = pad
-000064f0: 6428 632e 762c 746d 7029 3b0a 2365 6e64  d(c.v,tmp);.#end
-00006500: 6966 0a20 207d 0a0a 2020 4549 4745 4e5f  if.  }..  EIGEN_
-00006510: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
-00006520: 6964 206d 6164 645f 696d 706c 2863 6f6e  id madd_impl(con
-00006530: 7374 204c 6873 5363 616c 6172 2620 612c  st LhsScalar& a,
-00006540: 2063 6f6e 7374 2052 6873 5363 616c 6172   const RhsScalar
-00006550: 2620 622c 2052 6573 5363 616c 6172 2620  & b, ResScalar& 
-00006560: 632c 2052 6873 5363 616c 6172 2620 2f2a  c, RhsScalar& /*
-00006570: 746d 702a 2f2c 2063 6f6e 7374 2066 616c  tmp*/, const fal
-00006580: 7365 5f74 7970 6526 2920 636f 6e73 740a  se_type&) const.
-00006590: 2020 7b0a 2020 2020 6320 2b3d 2061 202a    {.    c += a *
-000065a0: 2062 3b0a 2020 7d0a 0a20 2074 656d 706c   b;.  }..  templ
-000065b0: 6174 653c 7479 7065 6e61 6d65 204c 6873  ate<typename Lhs
-000065c0: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
-000065d0: 6e61 6d65 2041 6363 5061 636b 6574 5479  name AccPacketTy
-000065e0: 7065 2c20 7479 7065 6e61 6d65 204c 616e  pe, typename Lan
-000065f0: 6549 6454 7970 653e 0a20 2045 4947 454e  eIdType>.  EIGEN
-00006600: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-00006610: 6f69 6420 6d61 6464 2863 6f6e 7374 204c  oid madd(const L
-00006620: 6873 5061 636b 6574 5479 7065 2620 612c  hsPacketType& a,
-00006630: 2063 6f6e 7374 2052 6873 5061 636b 6574   const RhsPacket
-00006640: 7834 2620 622c 2041 6363 5061 636b 6574  x4& b, AccPacket
-00006650: 5479 7065 2620 632c 2052 6873 5061 636b  Type& c, RhsPack
-00006660: 6574 2620 746d 702c 2063 6f6e 7374 204c  et& tmp, const L
-00006670: 616e 6549 6454 7970 6526 206c 616e 6529  aneIdType& lane)
-00006680: 2063 6f6e 7374 0a20 207b 0a20 2020 206d   const.  {.    m
-00006690: 6164 6428 612c 2062 2e67 6574 286c 616e  add(a, b.get(lan
-000066a0: 6529 2c20 632c 2074 6d70 2c20 6c61 6e65  e), c, tmp, lane
-000066b0: 293b 0a20 207d 0a0a 2020 7465 6d70 6c61  );.  }..  templa
-000066c0: 7465 203c 7479 7065 6e61 6d65 2052 6573  te <typename Res
-000066d0: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
-000066e0: 6e61 6d65 2041 6363 5061 636b 6574 5479  name AccPacketTy
-000066f0: 7065 3e0a 2020 4549 4745 4e5f 5354 524f  pe>.  EIGEN_STRO
-00006700: 4e47 5f49 4e4c 494e 4520 766f 6964 2061  NG_INLINE void a
-00006710: 6363 2863 6f6e 7374 2041 6363 5061 636b  cc(const AccPack
-00006720: 6574 5479 7065 2620 632c 2063 6f6e 7374  etType& c, const
-00006730: 2052 6573 5061 636b 6574 5479 7065 2620   ResPacketType& 
-00006740: 616c 7068 612c 2052 6573 5061 636b 6574  alpha, ResPacket
-00006750: 5479 7065 2620 7229 2063 6f6e 7374 0a20  Type& r) const. 
-00006760: 207b 0a20 2020 2063 6f6e 6a5f 6865 6c70   {.    conj_help
-00006770: 6572 3c52 6573 5061 636b 6574 5479 7065  er<ResPacketType
-00006780: 2c52 6573 5061 636b 6574 5479 7065 2c43  ,ResPacketType,C
-00006790: 6f6e 6a4c 6873 2c66 616c 7365 3e20 636a  onjLhs,false> cj
-000067a0: 3b0a 2020 2020 7220 3d20 636a 2e70 6d61  ;.    r = cj.pma
-000067b0: 6464 2863 2c61 6c70 6861 2c72 293b 0a20  dd(c,alpha,r);. 
-000067c0: 207d 0a0a 7072 6f74 6563 7465 643a 0a7d   }..protected:.}
-000067d0: 3b0a 0a74 656d 706c 6174 653c 7479 7065  ;..template<type
-000067e0: 6e61 6d65 2050 6163 6b65 743e 0a73 7472  name Packet>.str
-000067f0: 7563 7420 446f 7562 6c65 5061 636b 6574  uct DoublePacket
-00006800: 0a7b 0a20 2050 6163 6b65 7420 6669 7273  .{.  Packet firs
-00006810: 743b 0a20 2050 6163 6b65 7420 7365 636f  t;.  Packet seco
-00006820: 6e64 3b0a 7d3b 0a0a 7465 6d70 6c61 7465  nd;.};..template
-00006830: 3c74 7970 656e 616d 6520 5061 636b 6574  <typename Packet
-00006840: 3e0a 446f 7562 6c65 5061 636b 6574 3c50  >.DoublePacket<P
-00006850: 6163 6b65 743e 2070 6164 6428 636f 6e73  acket> padd(cons
-00006860: 7420 446f 7562 6c65 5061 636b 6574 3c50  t DoublePacket<P
-00006870: 6163 6b65 743e 2026 612c 2063 6f6e 7374  acket> &a, const
-00006880: 2044 6f75 626c 6550 6163 6b65 743c 5061   DoublePacket<Pa
-00006890: 636b 6574 3e20 2662 290a 7b0a 2020 446f  cket> &b).{.  Do
-000068a0: 7562 6c65 5061 636b 6574 3c50 6163 6b65  ublePacket<Packe
-000068b0: 743e 2072 6573 3b0a 2020 7265 732e 6669  t> res;.  res.fi
-000068c0: 7273 7420 203d 2070 6164 6428 612e 6669  rst  = padd(a.fi
-000068d0: 7273 742c 2062 2e66 6972 7374 293b 0a20  rst, b.first);. 
-000068e0: 2072 6573 2e73 6563 6f6e 6420 3d20 7061   res.second = pa
-000068f0: 6464 2861 2e73 6563 6f6e 642c 622e 7365  dd(a.second,b.se
-00006900: 636f 6e64 293b 0a20 2072 6574 7572 6e20  cond);.  return 
-00006910: 7265 733b 0a7d 0a0a 2f2f 206e 6f74 6520  res;.}..// note 
-00006920: 7468 6174 2066 6f72 2044 6f75 626c 6550  that for DoubleP
-00006930: 6163 6b65 743c 5265 616c 5061 636b 6574  acket<RealPacket
-00006940: 3e20 7468 6520 2234 2220 696e 2022 646f  > the "4" in "do
-00006950: 776e 746f 3422 0a2f 2f20 636f 7272 6573  wnto4".// corres
-00006960: 706f 6e64 7320 746f 2074 6865 206e 756d  ponds to the num
-00006970: 6265 7220 6f66 2063 6f6d 706c 6578 6573  ber of complexes
-00006980: 2c20 736f 2069 7420 6d65 616e 7320 2238  , so it means "8
-00006990: 220a 2f2f 2069 7420 7465 726d 7320 6f66  ".// it terms of
-000069a0: 2072 6561 6c20 636f 6566 6669 6369 656e   real coefficien
-000069b0: 7473 2e0a 0a74 656d 706c 6174 653c 7479  ts...template<ty
-000069c0: 7065 6e61 6d65 2050 6163 6b65 743e 0a63  pename Packet>.c
-000069d0: 6f6e 7374 2044 6f75 626c 6550 6163 6b65  onst DoublePacke
-000069e0: 743c 5061 636b 6574 3e26 0a70 7265 6475  t<Packet>&.predu
-000069f0: 785f 6861 6c66 5f64 6f77 746f 3428 636f  x_half_dowto4(co
-00006a00: 6e73 7420 446f 7562 6c65 5061 636b 6574  nst DoublePacket
-00006a10: 3c50 6163 6b65 743e 2026 612c 0a20 2020  <Packet> &a,.   
-00006a20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006a30: 7479 7065 6e61 6d65 2065 6e61 626c 655f  typename enable_
-00006a40: 6966 3c75 6e70 6163 6b65 745f 7472 6169  if<unpacket_trai
-00006a50: 7473 3c50 6163 6b65 743e 3a3a 7369 7a65  ts<Packet>::size
-00006a60: 3c3d 383e 3a3a 7479 7065 2a20 3d20 3029  <=8>::type* = 0)
-00006a70: 0a7b 0a20 2072 6574 7572 6e20 613b 0a7d  .{.  return a;.}
-00006a80: 0a0a 7465 6d70 6c61 7465 3c74 7970 656e  ..template<typen
-00006a90: 616d 6520 5061 636b 6574 3e0a 446f 7562  ame Packet>.Doub
-00006aa0: 6c65 5061 636b 6574 3c74 7970 656e 616d  lePacket<typenam
-00006ab0: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
-00006ac0: 733c 5061 636b 6574 3e3a 3a68 616c 663e  s<Packet>::half>
-00006ad0: 0a70 7265 6475 785f 6861 6c66 5f64 6f77  .predux_half_dow
-00006ae0: 746f 3428 636f 6e73 7420 446f 7562 6c65  to4(const Double
-00006af0: 5061 636b 6574 3c50 6163 6b65 743e 2026  Packet<Packet> &
-00006b00: 612c 0a20 2020 2020 2020 2020 2020 2020  a,.             
-00006b10: 2020 2020 2020 7479 7065 6e61 6d65 2065        typename e
-00006b20: 6e61 626c 655f 6966 3c75 6e70 6163 6b65  nable_if<unpacke
-00006b30: 745f 7472 6169 7473 3c50 6163 6b65 743e  t_traits<Packet>
-00006b40: 3a3a 7369 7a65 3d3d 3136 3e3a 3a74 7970  ::size==16>::typ
-00006b50: 652a 203d 2030 290a 7b0a 2020 2f2f 2079  e* = 0).{.  // y
-00006b60: 6573 2c20 7468 6174 2773 2070 7265 7474  es, that's prett
-00006b70: 7920 6861 636b 6973 6820 3a28 0a20 2044  y hackish :(.  D
-00006b80: 6f75 626c 6550 6163 6b65 743c 7479 7065  oublePacket<type
-00006b90: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
-00006ba0: 6169 7473 3c50 6163 6b65 743e 3a3a 6861  aits<Packet>::ha
-00006bb0: 6c66 3e20 7265 733b 0a20 2074 7970 6564  lf> res;.  typed
-00006bc0: 6566 2073 7464 3a3a 636f 6d70 6c65 783c  ef std::complex<
-00006bd0: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
-00006be0: 745f 7472 6169 7473 3c50 6163 6b65 743e  t_traits<Packet>
-00006bf0: 3a3a 7479 7065 3e20 4370 6c78 3b0a 2020  ::type> Cplx;.  
-00006c00: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
-00006c10: 2070 6163 6b65 745f 7472 6169 7473 3c43   packet_traits<C
-00006c20: 706c 783e 3a3a 7479 7065 2043 706c 7850  plx>::type CplxP
-00006c30: 6163 6b65 743b 0a20 2072 6573 2e66 6972  acket;.  res.fir
-00006c40: 7374 2020 3d20 7072 6564 7578 5f68 616c  st  = predux_hal
-00006c50: 665f 646f 7774 6f34 2843 706c 7850 6163  f_dowto4(CplxPac
-00006c60: 6b65 7428 612e 6669 7273 7429 292e 763b  ket(a.first)).v;
-00006c70: 0a20 2072 6573 2e73 6563 6f6e 6420 3d20  .  res.second = 
-00006c80: 7072 6564 7578 5f68 616c 665f 646f 7774  predux_half_dowt
-00006c90: 6f34 2843 706c 7850 6163 6b65 7428 612e  o4(CplxPacket(a.
-00006ca0: 7365 636f 6e64 2929 2e76 3b0a 2020 7265  second)).v;.  re
-00006cb0: 7475 726e 2072 6573 3b0a 7d0a 0a2f 2f20  turn res;.}..// 
-00006cc0: 7361 6d65 2068 6572 652c 2022 7175 6164  same here, "quad
-00006cd0: 2220 6163 7475 616c 6c79 206d 6561 6e73  " actually means
-00006ce0: 2022 3822 2069 6e20 7465 726d 7320 6f66   "8" in terms of
-00006cf0: 2072 6561 6c20 636f 6566 6669 6369 656e   real coefficien
-00006d00: 7473 0a74 656d 706c 6174 653c 7479 7065  ts.template<type
-00006d10: 6e61 6d65 2053 6361 6c61 722c 2074 7970  name Scalar, typ
-00006d20: 656e 616d 6520 5265 616c 5061 636b 6574  ename RealPacket
-00006d30: 3e0a 766f 6964 206c 6f61 6451 7561 6454  >.void loadQuadT
-00006d40: 6f44 6f75 626c 6550 6163 6b65 7428 636f  oDoublePacket(co
-00006d50: 6e73 7420 5363 616c 6172 2a20 622c 2044  nst Scalar* b, D
-00006d60: 6f75 626c 6550 6163 6b65 743c 5265 616c  oublePacket<Real
-00006d70: 5061 636b 6574 3e26 2064 6573 742c 0a20  Packet>& dest,. 
-00006d80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006d90: 2020 2020 2020 2020 2020 2074 7970 656e             typen
-00006da0: 616d 6520 656e 6162 6c65 5f69 663c 756e  ame enable_if<un
-00006db0: 7061 636b 6574 5f74 7261 6974 733c 5265  packet_traits<Re
-00006dc0: 616c 5061 636b 6574 3e3a 3a73 697a 653c  alPacket>::size<
-00006dd0: 3d38 3e3a 3a74 7970 652a 203d 2030 290a  =8>::type* = 0).
-00006de0: 7b0a 2020 6465 7374 2e66 6972 7374 2020  {.  dest.first  
-00006df0: 3d20 7073 6574 313c 5265 616c 5061 636b  = pset1<RealPack
-00006e00: 6574 3e28 7265 616c 282a 6229 293b 0a20  et>(real(*b));. 
-00006e10: 2064 6573 742e 7365 636f 6e64 203d 2070   dest.second = p
-00006e20: 7365 7431 3c52 6561 6c50 6163 6b65 743e  set1<RealPacket>
-00006e30: 2869 6d61 6728 2a62 2929 3b0a 7d0a 0a74  (imag(*b));.}..t
-00006e40: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
-00006e50: 2053 6361 6c61 722c 2074 7970 656e 616d   Scalar, typenam
-00006e60: 6520 5265 616c 5061 636b 6574 3e0a 766f  e RealPacket>.vo
-00006e70: 6964 206c 6f61 6451 7561 6454 6f44 6f75  id loadQuadToDou
-00006e80: 626c 6550 6163 6b65 7428 636f 6e73 7420  blePacket(const 
-00006e90: 5363 616c 6172 2a20 622c 2044 6f75 626c  Scalar* b, Doubl
-00006ea0: 6550 6163 6b65 743c 5265 616c 5061 636b  ePacket<RealPack
-00006eb0: 6574 3e26 2064 6573 742c 0a20 2020 2020  et>& dest,.     
-00006ec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00006ed0: 2020 2020 2020 2074 7970 656e 616d 6520         typename 
-00006ee0: 656e 6162 6c65 5f69 663c 756e 7061 636b  enable_if<unpack
-00006ef0: 6574 5f74 7261 6974 733c 5265 616c 5061  et_traits<RealPa
-00006f00: 636b 6574 3e3a 3a73 697a 653d 3d31 363e  cket>::size==16>
-00006f10: 3a3a 7479 7065 2a20 3d20 3029 0a7b 0a20  ::type* = 0).{. 
-00006f20: 202f 2f20 7965 732c 2074 6861 7427 7320   // yes, that's 
-00006f30: 7072 6574 7479 2068 6163 6b69 7368 2074  pretty hackish t
-00006f40: 6f6f 203a 280a 2020 7479 7065 6465 6620  oo :(.  typedef 
-00006f50: 7479 7065 6e61 6d65 204e 756d 5472 6169  typename NumTrai
-00006f60: 7473 3c53 6361 6c61 723e 3a3a 5265 616c  ts<Scalar>::Real
-00006f70: 2052 6561 6c53 6361 6c61 723b 0a20 2052   RealScalar;.  R
-00006f80: 6561 6c53 6361 6c61 7220 725b 345d 203d  ealScalar r[4] =
-00006f90: 207b 7265 616c 2862 5b30 5d29 2c20 7265   {real(b[0]), re
-00006fa0: 616c 2862 5b30 5d29 2c20 7265 616c 2862  al(b[0]), real(b
-00006fb0: 5b31 5d29 2c20 7265 616c 2862 5b31 5d29  [1]), real(b[1])
-00006fc0: 7d3b 0a20 2052 6561 6c53 6361 6c61 7220  };.  RealScalar 
-00006fd0: 695b 345d 203d 207b 696d 6167 2862 5b30  i[4] = {imag(b[0
-00006fe0: 5d29 2c20 696d 6167 2862 5b30 5d29 2c20  ]), imag(b[0]), 
-00006ff0: 696d 6167 2862 5b31 5d29 2c20 696d 6167  imag(b[1]), imag
-00007000: 2862 5b31 5d29 7d3b 0a20 2064 6573 742e  (b[1])};.  dest.
-00007010: 6669 7273 7420 203d 2070 6c6f 6164 7175  first  = ploadqu
-00007020: 6164 3c52 6561 6c50 6163 6b65 743e 2872  ad<RealPacket>(r
-00007030: 293b 0a20 2064 6573 742e 7365 636f 6e64  );.  dest.second
-00007040: 203d 2070 6c6f 6164 7175 6164 3c52 6561   = ploadquad<Rea
-00007050: 6c50 6163 6b65 743e 2869 293b 0a7d 0a0a  lPacket>(i);.}..
-00007060: 0a74 656d 706c 6174 653c 7479 7065 6e61  .template<typena
-00007070: 6d65 2050 6163 6b65 743e 2073 7472 7563  me Packet> struc
-00007080: 7420 756e 7061 636b 6574 5f74 7261 6974  t unpacket_trait
-00007090: 733c 446f 7562 6c65 5061 636b 6574 3c50  s<DoublePacket<P
-000070a0: 6163 6b65 743e 203e 207b 0a20 2074 7970  acket> > {.  typ
-000070b0: 6564 6566 2044 6f75 626c 6550 6163 6b65  edef DoublePacke
-000070c0: 743c 7479 7065 6e61 6d65 2075 6e70 6163  t<typename unpac
-000070d0: 6b65 745f 7472 6169 7473 3c50 6163 6b65  ket_traits<Packe
-000070e0: 743e 3a3a 6861 6c66 3e20 6861 6c66 3b0a  t>::half> half;.
-000070f0: 7d3b 0a2f 2f20 7465 6d70 6c61 7465 3c74  };.// template<t
-00007100: 7970 656e 616d 6520 5061 636b 6574 3e0a  ypename Packet>.
-00007110: 2f2f 2044 6f75 626c 6550 6163 6b65 743c  // DoublePacket<
-00007120: 5061 636b 6574 3e20 706d 6164 6428 636f  Packet> pmadd(co
-00007130: 6e73 7420 446f 7562 6c65 5061 636b 6574  nst DoublePacket
-00007140: 3c50 6163 6b65 743e 2026 612c 2063 6f6e  <Packet> &a, con
-00007150: 7374 2044 6f75 626c 6550 6163 6b65 743c  st DoublePacket<
-00007160: 5061 636b 6574 3e20 2662 290a 2f2f 207b  Packet> &b).// {
-00007170: 0a2f 2f20 2020 446f 7562 6c65 5061 636b  .//   DoublePack
-00007180: 6574 3c50 6163 6b65 743e 2072 6573 3b0a  et<Packet> res;.
-00007190: 2f2f 2020 2072 6573 2e66 6972 7374 2020  //   res.first  
-000071a0: 3d20 7061 6464 2861 2e66 6972 7374 2c20  = padd(a.first, 
-000071b0: 622e 6669 7273 7429 3b0a 2f2f 2020 2072  b.first);.//   r
-000071c0: 6573 2e73 6563 6f6e 6420 3d20 7061 6464  es.second = padd
-000071d0: 2861 2e73 6563 6f6e 642c 622e 7365 636f  (a.second,b.seco
-000071e0: 6e64 293b 0a2f 2f20 2020 7265 7475 726e  nd);.//   return
-000071f0: 2072 6573 3b0a 2f2f 207d 0a0a 7465 6d70   res;.// }..temp
-00007200: 6c61 7465 3c74 7970 656e 616d 6520 5265  late<typename Re
-00007210: 616c 5363 616c 6172 2c20 626f 6f6c 205f  alScalar, bool _
-00007220: 436f 6e6a 4c68 732c 2062 6f6f 6c20 5f43  ConjLhs, bool _C
-00007230: 6f6e 6a52 6873 2c20 696e 7420 4172 6368  onjRhs, int Arch
-00007240: 2c20 696e 7420 5f50 6163 6b65 7453 697a  , int _PacketSiz
-00007250: 653e 0a63 6c61 7373 2067 6562 705f 7472  e>.class gebp_tr
-00007260: 6169 7473 3c73 7464 3a3a 636f 6d70 6c65  aits<std::comple
-00007270: 783c 5265 616c 5363 616c 6172 3e2c 2073  x<RealScalar>, s
-00007280: 7464 3a3a 636f 6d70 6c65 783c 5265 616c  td::complex<Real
-00007290: 5363 616c 6172 3e2c 205f 436f 6e6a 4c68  Scalar>, _ConjLh
-000072a0: 732c 205f 436f 6e6a 5268 732c 2041 7263  s, _ConjRhs, Arc
-000072b0: 682c 205f 5061 636b 6574 5369 7a65 203e  h, _PacketSize >
-000072c0: 0a7b 0a70 7562 6c69 633a 0a20 2074 7970  .{.public:.  typ
-000072d0: 6564 6566 2073 7464 3a3a 636f 6d70 6c65  edef std::comple
-000072e0: 783c 5265 616c 5363 616c 6172 3e20 2053  x<RealScalar>  S
-000072f0: 6361 6c61 723b 0a20 2074 7970 6564 6566  calar;.  typedef
-00007300: 2073 7464 3a3a 636f 6d70 6c65 783c 5265   std::complex<Re
-00007310: 616c 5363 616c 6172 3e20 204c 6873 5363  alScalar>  LhsSc
-00007320: 616c 6172 3b0a 2020 7479 7065 6465 6620  alar;.  typedef 
-00007330: 7374 643a 3a63 6f6d 706c 6578 3c52 6561  std::complex<Rea
-00007340: 6c53 6361 6c61 723e 2020 5268 7353 6361  lScalar>  RhsSca
-00007350: 6c61 723b 0a20 2074 7970 6564 6566 2073  lar;.  typedef s
-00007360: 7464 3a3a 636f 6d70 6c65 783c 5265 616c  td::complex<Real
-00007370: 5363 616c 6172 3e20 2052 6573 5363 616c  Scalar>  ResScal
-00007380: 6172 3b0a 2020 0a20 2050 4143 4b45 545f  ar;.  .  PACKET_
-00007390: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
-000073a0: 285f 2c20 4c68 732c 205f 5061 636b 6574  (_, Lhs, _Packet
-000073b0: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
-000073c0: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
-000073d0: 285f 2c20 5268 732c 205f 5061 636b 6574  (_, Rhs, _Packet
-000073e0: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
-000073f0: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
-00007400: 285f 2c20 5265 732c 205f 5061 636b 6574  (_, Res, _Packet
-00007410: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
-00007420: 4445 434c 5f43 4f4e 4428 5265 616c 2c20  DECL_COND(Real, 
-00007430: 5f50 6163 6b65 7453 697a 6529 3b0a 2020  _PacketSize);.  
-00007440: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
-00007450: 5f53 4341 4c41 5228 5f50 6163 6b65 7453  _SCALAR(_PacketS
-00007460: 697a 6529 3b0a 0a20 2065 6e75 6d20 7b0a  ize);..  enum {.
-00007470: 2020 2020 436f 6e6a 4c68 7320 3d20 5f43      ConjLhs = _C
-00007480: 6f6e 6a4c 6873 2c0a 2020 2020 436f 6e6a  onjLhs,.    Conj
-00007490: 5268 7320 3d20 5f43 6f6e 6a52 6873 2c0a  Rhs = _ConjRhs,.
-000074a0: 2020 2020 5665 6374 6f72 697a 6162 6c65      Vectorizable
-000074b0: 203d 2075 6e70 6163 6b65 745f 7472 6169   = unpacket_trai
-000074c0: 7473 3c52 6561 6c50 6163 6b65 743e 3a3a  ts<RealPacket>::
-000074d0: 7665 6374 6f72 697a 6162 6c65 0a20 2020  vectorizable.   
-000074e0: 2020 2020 2020 2020 2020 2020 2026 2620               && 
-000074f0: 756e 7061 636b 6574 5f74 7261 6974 733c  unpacket_traits<
-00007500: 5363 616c 6172 5061 636b 6574 3e3a 3a76  ScalarPacket>::v
-00007510: 6563 746f 7269 7a61 626c 652c 0a20 2020  ectorizable,.   
-00007520: 2052 6573 5061 636b 6574 5369 7a65 2020   ResPacketSize  
-00007530: 203d 2056 6563 746f 7269 7a61 626c 6520   = Vectorizable 
-00007540: 3f20 756e 7061 636b 6574 5f74 7261 6974  ? unpacket_trait
-00007550: 733c 5f52 6573 5061 636b 6574 3e3a 3a73  s<_ResPacket>::s
-00007560: 697a 6520 3a20 312c 0a20 2020 204c 6873  ize : 1,.    Lhs
-00007570: 5061 636b 6574 5369 7a65 203d 2056 6563  PacketSize = Vec
-00007580: 746f 7269 7a61 626c 6520 3f20 756e 7061  torizable ? unpa
-00007590: 636b 6574 5f74 7261 6974 733c 5f4c 6873  cket_traits<_Lhs
-000075a0: 5061 636b 6574 3e3a 3a73 697a 6520 3a20  Packet>::size : 
-000075b0: 312c 0a20 2020 2052 6873 5061 636b 6574  1,.    RhsPacket
-000075c0: 5369 7a65 203d 2056 6563 746f 7269 7a61  Size = Vectoriza
-000075d0: 626c 6520 3f20 756e 7061 636b 6574 5f74  ble ? unpacket_t
-000075e0: 7261 6974 733c 5268 7353 6361 6c61 723e  raits<RhsScalar>
-000075f0: 3a3a 7369 7a65 203a 2031 2c0a 2020 2020  ::size : 1,.    
-00007600: 5265 616c 5061 636b 6574 5369 7a65 2020  RealPacketSize  
-00007610: 3d20 5665 6374 6f72 697a 6162 6c65 203f  = Vectorizable ?
-00007620: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
-00007630: 3c52 6561 6c50 6163 6b65 743e 3a3a 7369  <RealPacket>::si
-00007640: 7a65 203a 2031 2c0a 0a20 2020 202f 2f20  ze : 1,..    // 
-00007650: 4649 584d 453a 2073 686f 756c 6420 6465  FIXME: should de
-00007660: 7065 6e64 206f 6e20 4e75 6d62 6572 4f66  pend on NumberOf
-00007670: 5265 6769 7374 6572 730a 2020 2020 6e72  Registers.    nr
-00007680: 203d 2034 2c0a 2020 2020 6d72 203d 2052   = 4,.    mr = R
-00007690: 6573 5061 636b 6574 5369 7a65 2c0a 0a20  esPacketSize,.. 
-000076a0: 2020 204c 6873 5072 6f67 7265 7373 203d     LhsProgress =
-000076b0: 2052 6573 5061 636b 6574 5369 7a65 2c0a   ResPacketSize,.
-000076c0: 2020 2020 5268 7350 726f 6772 6573 7320      RhsProgress 
-000076d0: 3d20 310a 2020 7d3b 0a20 200a 2020 7479  = 1.  };.  .  ty
-000076e0: 7065 6465 6620 446f 7562 6c65 5061 636b  pedef DoublePack
-000076f0: 6574 3c52 6561 6c50 6163 6b65 743e 2020  et<RealPacket>  
-00007700: 2020 2020 2020 2020 2020 2020 2020 2044                 D
-00007710: 6f75 626c 6550 6163 6b65 7454 7970 653b  oublePacketType;
-00007720: 0a0a 2020 7479 7065 6465 6620 7479 7065  ..  typedef type
-00007730: 6e61 6d65 2063 6f6e 6469 7469 6f6e 616c  name conditional
-00007740: 3c56 6563 746f 7269 7a61 626c 652c 5363  <Vectorizable,Sc
-00007750: 616c 6172 5061 636b 6574 2c53 6361 6c61  alarPacket,Scala
-00007760: 723e 3a3a 7479 7065 204c 6873 5061 636b  r>::type LhsPack
-00007770: 6574 3450 6163 6b69 6e67 3b0a 2020 7479  et4Packing;.  ty
-00007780: 7065 6465 6620 7479 7065 6e61 6d65 2063  pedef typename c
-00007790: 6f6e 6469 7469 6f6e 616c 3c56 6563 746f  onditional<Vecto
-000077a0: 7269 7a61 626c 652c 5265 616c 5061 636b  rizable,RealPack
-000077b0: 6574 2c20 2053 6361 6c61 723e 3a3a 7479  et,  Scalar>::ty
-000077c0: 7065 204c 6873 5061 636b 6574 3b0a 2020  pe LhsPacket;.  
-000077d0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
-000077e0: 2063 6f6e 6469 7469 6f6e 616c 3c56 6563   conditional<Vec
-000077f0: 746f 7269 7a61 626c 652c 446f 7562 6c65  torizable,Double
-00007800: 5061 636b 6574 5479 7065 2c53 6361 6c61  PacketType,Scala
-00007810: 723e 3a3a 7479 7065 2052 6873 5061 636b  r>::type RhsPack
-00007820: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
-00007830: 7065 6e61 6d65 2063 6f6e 6469 7469 6f6e  pename condition
-00007840: 616c 3c56 6563 746f 7269 7a61 626c 652c  al<Vectorizable,
-00007850: 5363 616c 6172 5061 636b 6574 2c53 6361  ScalarPacket,Sca
-00007860: 6c61 723e 3a3a 7479 7065 2052 6573 5061  lar>::type ResPa
-00007870: 636b 6574 3b0a 2020 7479 7065 6465 6620  cket;.  typedef 
-00007880: 7479 7065 6e61 6d65 2063 6f6e 6469 7469  typename conditi
-00007890: 6f6e 616c 3c56 6563 746f 7269 7a61 626c  onal<Vectorizabl
-000078a0: 652c 446f 7562 6c65 5061 636b 6574 5479  e,DoublePacketTy
-000078b0: 7065 2c53 6361 6c61 723e 3a3a 7479 7065  pe,Scalar>::type
-000078c0: 2041 6363 5061 636b 6574 3b0a 0a20 202f   AccPacket;..  /
-000078d0: 2f20 7468 6973 2061 6374 7561 6c79 2068  / this actualy h
-000078e0: 6f6c 6473 2038 2070 6163 6b65 7473 210a  olds 8 packets!.
-000078f0: 2020 7479 7065 6465 6620 5175 6164 5061    typedef QuadPa
-00007900: 636b 6574 3c52 6873 5061 636b 6574 3e20  cket<RhsPacket> 
-00007910: 5268 7350 6163 6b65 7478 343b 0a20 200a  RhsPacketx4;.  .
-00007920: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-00007930: 4e4c 494e 4520 766f 6964 2069 6e69 7441  NLINE void initA
-00007940: 6363 2853 6361 6c61 7226 2070 2920 7b20  cc(Scalar& p) { 
-00007950: 7020 3d20 5363 616c 6172 2830 293b 207d  p = Scalar(0); }
-00007960: 0a0a 2020 4549 4745 4e5f 5354 524f 4e47  ..  EIGEN_STRONG
-00007970: 5f49 4e4c 494e 4520 766f 6964 2069 6e69  _INLINE void ini
-00007980: 7441 6363 2844 6f75 626c 6550 6163 6b65  tAcc(DoublePacke
-00007990: 7454 7970 6526 2070 290a 2020 7b0a 2020  tType& p).  {.  
-000079a0: 2020 702e 6669 7273 7420 2020 3d20 7073    p.first   = ps
-000079b0: 6574 313c 5265 616c 5061 636b 6574 3e28  et1<RealPacket>(
-000079c0: 5265 616c 5363 616c 6172 2830 2929 3b0a  RealScalar(0));.
-000079d0: 2020 2020 702e 7365 636f 6e64 2020 3d20      p.second  = 
-000079e0: 7073 6574 313c 5265 616c 5061 636b 6574  pset1<RealPacket
-000079f0: 3e28 5265 616c 5363 616c 6172 2830 2929  >(RealScalar(0))
-00007a00: 3b0a 2020 7d0a 0a20 202f 2f20 5363 616c  ;.  }..  // Scal
-00007a10: 6172 2070 6174 680a 2020 4549 4745 4e5f  ar path.  EIGEN_
-00007a20: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
-00007a30: 6964 206c 6f61 6452 6873 2863 6f6e 7374  id loadRhs(const
-00007a40: 2052 6873 5363 616c 6172 2a20 622c 2053   RhsScalar* b, S
-00007a50: 6361 6c61 7250 6163 6b65 7426 2064 6573  calarPacket& des
-00007a60: 7429 2063 6f6e 7374 0a20 207b 0a20 2020  t) const.  {.   
-00007a70: 2064 6573 7420 3d20 7073 6574 313c 5363   dest = pset1<Sc
-00007a80: 616c 6172 5061 636b 6574 3e28 2a62 293b  alarPacket>(*b);
-00007a90: 0a20 207d 0a0a 2020 2f2f 2056 6563 746f  .  }..  // Vecto
-00007aa0: 7269 7a65 6420 7061 7468 0a20 2074 656d  rized path.  tem
-00007ab0: 706c 6174 653c 7479 7065 6e61 6d65 2052  plate<typename R
-00007ac0: 6561 6c50 6163 6b65 7454 7970 653e 0a20  ealPacketType>. 
-00007ad0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-00007ae0: 4c49 4e45 2076 6f69 6420 6c6f 6164 5268  LINE void loadRh
-00007af0: 7328 636f 6e73 7420 5268 7353 6361 6c61  s(const RhsScala
-00007b00: 722a 2062 2c20 446f 7562 6c65 5061 636b  r* b, DoublePack
-00007b10: 6574 3c52 6561 6c50 6163 6b65 7454 7970  et<RealPacketTyp
-00007b20: 653e 2620 6465 7374 2920 636f 6e73 740a  e>& dest) const.
-00007b30: 2020 7b0a 2020 2020 6465 7374 2e66 6972    {.    dest.fir
-00007b40: 7374 2020 3d20 7073 6574 313c 5265 616c  st  = pset1<Real
-00007b50: 5061 636b 6574 5479 7065 3e28 7265 616c  PacketType>(real
-00007b60: 282a 6229 293b 0a20 2020 2064 6573 742e  (*b));.    dest.
-00007b70: 7365 636f 6e64 203d 2070 7365 7431 3c52  second = pset1<R
-00007b80: 6561 6c50 6163 6b65 7454 7970 653e 2869  ealPacketType>(i
-00007b90: 6d61 6728 2a62 2929 3b0a 2020 7d0a 0a20  mag(*b));.  }.. 
-00007ba0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-00007bb0: 4c49 4e45 2076 6f69 6420 6c6f 6164 5268  LINE void loadRh
-00007bc0: 7328 636f 6e73 7420 5268 7353 6361 6c61  s(const RhsScala
-00007bd0: 722a 2062 2c20 5268 7350 6163 6b65 7478  r* b, RhsPacketx
-00007be0: 3426 2064 6573 7429 2063 6f6e 7374 0a20  4& dest) const. 
-00007bf0: 207b 0a20 2020 206c 6f61 6452 6873 2862   {.    loadRhs(b
-00007c00: 2c20 6465 7374 2e42 5f30 293b 0a20 2020  , dest.B_0);.   
-00007c10: 206c 6f61 6452 6873 2862 202b 2031 2c20   loadRhs(b + 1, 
-00007c20: 6465 7374 2e42 3129 3b0a 2020 2020 6c6f  dest.B1);.    lo
-00007c30: 6164 5268 7328 6220 2b20 322c 2064 6573  adRhs(b + 2, des
-00007c40: 742e 4232 293b 0a20 2020 206c 6f61 6452  t.B2);.    loadR
-00007c50: 6873 2862 202b 2033 2c20 6465 7374 2e42  hs(b + 3, dest.B
-00007c60: 3329 3b0a 2020 7d0a 0a20 202f 2f20 5363  3);.  }..  // Sc
-00007c70: 616c 6172 2070 6174 680a 2020 4549 4745  alar path.  EIGE
-00007c80: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00007c90: 766f 6964 2075 7064 6174 6552 6873 2863  void updateRhs(c
-00007ca0: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
-00007cb0: 622c 2053 6361 6c61 7250 6163 6b65 7426  b, ScalarPacket&
-00007cc0: 2064 6573 7429 2063 6f6e 7374 0a20 207b   dest) const.  {
-00007cd0: 0a20 2020 206c 6f61 6452 6873 2862 2c20  .    loadRhs(b, 
-00007ce0: 6465 7374 293b 0a20 207d 0a0a 2020 2f2f  dest);.  }..  //
-00007cf0: 2056 6563 746f 7269 7a65 6420 7061 7468   Vectorized path
-00007d00: 0a20 2074 656d 706c 6174 653c 7479 7065  .  template<type
-00007d10: 6e61 6d65 2052 6561 6c50 6163 6b65 7454  name RealPacketT
-00007d20: 7970 653e 0a20 2045 4947 454e 5f53 5452  ype>.  EIGEN_STR
-00007d30: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
-00007d40: 7570 6461 7465 5268 7328 636f 6e73 7420  updateRhs(const 
-00007d50: 5268 7353 6361 6c61 722a 2062 2c20 446f  RhsScalar* b, Do
-00007d60: 7562 6c65 5061 636b 6574 3c52 6561 6c50  ublePacket<RealP
-00007d70: 6163 6b65 7454 7970 653e 2620 6465 7374  acketType>& dest
-00007d80: 2920 636f 6e73 740a 2020 7b0a 2020 2020  ) const.  {.    
-00007d90: 6c6f 6164 5268 7328 622c 2064 6573 7429  loadRhs(b, dest)
-00007da0: 3b0a 2020 7d0a 0a20 2045 4947 454e 5f53  ;.  }..  EIGEN_S
-00007db0: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
-00007dc0: 6420 7570 6461 7465 5268 7328 636f 6e73  d updateRhs(cons
-00007dd0: 7420 5268 7353 6361 6c61 722a 2c20 5268  t RhsScalar*, Rh
-00007de0: 7350 6163 6b65 7478 3426 2920 636f 6e73  sPacketx4&) cons
-00007df0: 7420 7b7d 0a20 200a 2020 4549 4745 4e5f  t {}.  .  EIGEN_
-00007e00: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
-00007e10: 6964 206c 6f61 6452 6873 5175 6164 2863  id loadRhsQuad(c
-00007e20: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
-00007e30: 622c 2052 6573 5061 636b 6574 2620 6465  b, ResPacket& de
-00007e40: 7374 2920 636f 6e73 740a 2020 7b0a 2020  st) const.  {.  
-00007e50: 2020 6c6f 6164 5268 7328 622c 6465 7374    loadRhs(b,dest
-00007e60: 293b 0a20 207d 0a20 2045 4947 454e 5f53  );.  }.  EIGEN_S
-00007e70: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
-00007e80: 6420 6c6f 6164 5268 7351 7561 6428 636f  d loadRhsQuad(co
-00007e90: 6e73 7420 5268 7353 6361 6c61 722a 2062  nst RhsScalar* b
-00007ea0: 2c20 446f 7562 6c65 5061 636b 6574 5479  , DoublePacketTy
-00007eb0: 7065 2620 6465 7374 2920 636f 6e73 740a  pe& dest) const.
-00007ec0: 2020 7b0a 2020 2020 6c6f 6164 5175 6164    {.    loadQuad
-00007ed0: 546f 446f 7562 6c65 5061 636b 6574 2862  ToDoublePacket(b
-00007ee0: 2c64 6573 7429 3b0a 2020 7d0a 0a20 202f  ,dest);.  }..  /
-00007ef0: 2f20 6e6f 7468 696e 6720 7370 6563 6961  / nothing specia
-00007f00: 6c20 6865 7265 0a20 2045 4947 454e 5f53  l here.  EIGEN_S
-00007f10: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
-00007f20: 6420 6c6f 6164 4c68 7328 636f 6e73 7420  d loadLhs(const 
-00007f30: 4c68 7353 6361 6c61 722a 2061 2c20 4c68  LhsScalar* a, Lh
-00007f40: 7350 6163 6b65 7426 2064 6573 7429 2063  sPacket& dest) c
-00007f50: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
-00007f60: 7420 3d20 706c 6f61 643c 4c68 7350 6163  t = pload<LhsPac
-00007f70: 6b65 743e 2828 636f 6e73 7420 7479 7065  ket>((const type
-00007f80: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
-00007f90: 6169 7473 3c4c 6873 5061 636b 6574 3e3a  aits<LhsPacket>:
-00007fa0: 3a74 7970 652a 2928 6129 293b 0a20 207d  :type*)(a));.  }
-00007fb0: 0a0a 2020 7465 6d70 6c61 7465 3c74 7970  ..  template<typ
-00007fc0: 656e 616d 6520 4c68 7350 6163 6b65 7454  ename LhsPacketT
-00007fd0: 7970 653e 0a20 2045 4947 454e 5f53 5452  ype>.  EIGEN_STR
-00007fe0: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
-00007ff0: 6c6f 6164 4c68 7355 6e61 6c69 676e 6564  loadLhsUnaligned
-00008000: 2863 6f6e 7374 204c 6873 5363 616c 6172  (const LhsScalar
-00008010: 2a20 612c 204c 6873 5061 636b 6574 5479  * a, LhsPacketTy
-00008020: 7065 2620 6465 7374 2920 636f 6e73 740a  pe& dest) const.
-00008030: 2020 7b0a 2020 2020 6465 7374 203d 2070    {.    dest = p
-00008040: 6c6f 6164 753c 4c68 7350 6163 6b65 7454  loadu<LhsPacketT
-00008050: 7970 653e 2828 636f 6e73 7420 7479 7065  ype>((const type
-00008060: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
-00008070: 6169 7473 3c4c 6873 5061 636b 6574 5479  aits<LhsPacketTy
-00008080: 7065 3e3a 3a74 7970 652a 2928 6129 293b  pe>::type*)(a));
-00008090: 0a20 207d 0a0a 2020 7465 6d70 6c61 7465  .  }..  template
-000080a0: 3c74 7970 656e 616d 6520 4c68 7350 6163  <typename LhsPac
-000080b0: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
-000080c0: 6520 5268 7350 6163 6b65 7454 7970 652c  e RhsPacketType,
-000080d0: 2074 7970 656e 616d 6520 5265 7350 6163   typename ResPac
-000080e0: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
-000080f0: 6520 546d 7054 7970 652c 2074 7970 656e  e TmpType, typen
-00008100: 616d 6520 4c61 6e65 4964 5479 7065 3e0a  ame LaneIdType>.
-00008110: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-00008120: 4e4c 494e 450a 2020 7479 7065 6e61 6d65  NLINE.  typename
-00008130: 2065 6e61 626c 655f 6966 3c21 6973 5f73   enable_if<!is_s
-00008140: 616d 653c 5268 7350 6163 6b65 7454 7970  ame<RhsPacketTyp
-00008150: 652c 5268 7350 6163 6b65 7478 343e 3a3a  e,RhsPacketx4>::
-00008160: 7661 6c75 653e 3a3a 7479 7065 0a20 206d  value>::type.  m
-00008170: 6164 6428 636f 6e73 7420 4c68 7350 6163  add(const LhsPac
-00008180: 6b65 7454 7970 6526 2061 2c20 636f 6e73  ketType& a, cons
-00008190: 7420 5268 7350 6163 6b65 7454 7970 6526  t RhsPacketType&
-000081a0: 2062 2c20 446f 7562 6c65 5061 636b 6574   b, DoublePacket
-000081b0: 3c52 6573 5061 636b 6574 5479 7065 3e26  <ResPacketType>&
-000081c0: 2063 2c20 546d 7054 7970 6526 202f 2a74   c, TmpType& /*t
-000081d0: 6d70 2a2f 2c20 636f 6e73 7420 4c61 6e65  mp*/, const Lane
-000081e0: 4964 5479 7065 2629 2063 6f6e 7374 0a20  IdType&) const. 
-000081f0: 207b 0a20 2020 2063 2e66 6972 7374 2020   {.    c.first  
-00008200: 203d 2070 6164 6428 706d 756c 2861 2c62   = padd(pmul(a,b
-00008210: 2e66 6972 7374 292c 2063 2e66 6972 7374  .first), c.first
-00008220: 293b 0a20 2020 2063 2e73 6563 6f6e 6420  );.    c.second 
-00008230: 203d 2070 6164 6428 706d 756c 2861 2c62   = padd(pmul(a,b
-00008240: 2e73 6563 6f6e 6429 2c63 2e73 6563 6f6e  .second),c.secon
-00008250: 6429 3b0a 2020 7d0a 0a20 2074 656d 706c  d);.  }..  templ
-00008260: 6174 653c 7479 7065 6e61 6d65 204c 616e  ate<typename Lan
-00008270: 6549 6454 7970 653e 0a20 2045 4947 454e  eIdType>.  EIGEN
-00008280: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-00008290: 6f69 6420 6d61 6464 2863 6f6e 7374 204c  oid madd(const L
-000082a0: 6873 5061 636b 6574 2620 612c 2063 6f6e  hsPacket& a, con
-000082b0: 7374 2052 6873 5061 636b 6574 2620 622c  st RhsPacket& b,
-000082c0: 2052 6573 5061 636b 6574 2620 632c 2052   ResPacket& c, R
-000082d0: 6873 5061 636b 6574 2620 2f2a 746d 702a  hsPacket& /*tmp*
-000082e0: 2f2c 2063 6f6e 7374 204c 616e 6549 6454  /, const LaneIdT
-000082f0: 7970 6526 2920 636f 6e73 740a 2020 7b0a  ype&) const.  {.
-00008300: 2020 2020 6320 3d20 636a 2e70 6d61 6464      c = cj.pmadd
-00008310: 2861 2c62 2c63 293b 0a20 207d 0a0a 2020  (a,b,c);.  }..  
-00008320: 7465 6d70 6c61 7465 3c74 7970 656e 616d  template<typenam
-00008330: 6520 4c68 7350 6163 6b65 7454 7970 652c  e LhsPacketType,
-00008340: 2074 7970 656e 616d 6520 4163 6350 6163   typename AccPac
-00008350: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
-00008360: 6520 4c61 6e65 4964 5479 7065 3e0a 2020  e LaneIdType>.  
-00008370: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-00008380: 494e 4520 766f 6964 206d 6164 6428 636f  INE void madd(co
-00008390: 6e73 7420 4c68 7350 6163 6b65 7454 7970  nst LhsPacketTyp
-000083a0: 6526 2061 2c20 636f 6e73 7420 5268 7350  e& a, const RhsP
-000083b0: 6163 6b65 7478 3426 2062 2c20 4163 6350  acketx4& b, AccP
-000083c0: 6163 6b65 7454 7970 6526 2063 2c20 5268  acketType& c, Rh
-000083d0: 7350 6163 6b65 7426 2074 6d70 2c20 636f  sPacket& tmp, co
-000083e0: 6e73 7420 4c61 6e65 4964 5479 7065 2620  nst LaneIdType& 
-000083f0: 6c61 6e65 2920 636f 6e73 740a 2020 7b0a  lane) const.  {.
-00008400: 2020 2020 6d61 6464 2861 2c20 622e 6765      madd(a, b.ge
-00008410: 7428 6c61 6e65 292c 2063 2c20 746d 702c  t(lane), c, tmp,
-00008420: 206c 616e 6529 3b0a 2020 7d0a 2020 0a20   lane);.  }.  . 
-00008430: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-00008440: 4c49 4e45 2076 6f69 6420 6163 6328 636f  LINE void acc(co
-00008450: 6e73 7420 5363 616c 6172 2620 632c 2063  nst Scalar& c, c
-00008460: 6f6e 7374 2053 6361 6c61 7226 2061 6c70  onst Scalar& alp
-00008470: 6861 2c20 5363 616c 6172 2620 7229 2063  ha, Scalar& r) c
-00008480: 6f6e 7374 207b 2072 202b 3d20 616c 7068  onst { r += alph
-00008490: 6120 2a20 633b 207d 0a20 200a 2020 7465  a * c; }.  .  te
-000084a0: 6d70 6c61 7465 3c74 7970 656e 616d 6520  mplate<typename 
-000084b0: 5265 616c 5061 636b 6574 5479 7065 2c20  RealPacketType, 
-000084c0: 7479 7065 6e61 6d65 2052 6573 5061 636b  typename ResPack
-000084d0: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
-000084e0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
-000084f0: 6964 2061 6363 2863 6f6e 7374 2044 6f75  id acc(const Dou
-00008500: 626c 6550 6163 6b65 743c 5265 616c 5061  blePacket<RealPa
-00008510: 636b 6574 5479 7065 3e26 2063 2c20 636f  cketType>& c, co
-00008520: 6e73 7420 5265 7350 6163 6b65 7454 7970  nst ResPacketTyp
-00008530: 6526 2061 6c70 6861 2c20 5265 7350 6163  e& alpha, ResPac
-00008540: 6b65 7454 7970 6526 2072 2920 636f 6e73  ketType& r) cons
-00008550: 740a 2020 7b0a 2020 2020 2f2f 2061 7373  t.  {.    // ass
-00008560: 656d 626c 6520 630a 2020 2020 5265 7350  emble c.    ResP
-00008570: 6163 6b65 7454 7970 6520 746d 703b 0a20  acketType tmp;. 
-00008580: 2020 2069 6628 2821 436f 6e6a 4c68 7329     if((!ConjLhs)
-00008590: 2626 2821 436f 6e6a 5268 7329 290a 2020  &&(!ConjRhs)).  
-000085a0: 2020 7b0a 2020 2020 2020 746d 7020 3d20    {.      tmp = 
-000085b0: 7063 706c 7866 6c69 7028 7063 6f6e 6a28  pcplxflip(pconj(
-000085c0: 5265 7350 6163 6b65 7454 7970 6528 632e  ResPacketType(c.
-000085d0: 7365 636f 6e64 2929 293b 0a20 2020 2020  second)));.     
-000085e0: 2074 6d70 203d 2070 6164 6428 5265 7350   tmp = padd(ResP
-000085f0: 6163 6b65 7454 7970 6528 632e 6669 7273  acketType(c.firs
-00008600: 7429 2c74 6d70 293b 0a20 2020 207d 0a20  t),tmp);.    }. 
-00008610: 2020 2065 6c73 6520 6966 2828 2143 6f6e     else if((!Con
-00008620: 6a4c 6873 2926 2628 436f 6e6a 5268 7329  jLhs)&&(ConjRhs)
-00008630: 290a 2020 2020 7b0a 2020 2020 2020 746d  ).    {.      tm
-00008640: 7020 3d20 7063 6f6e 6a28 7063 706c 7866  p = pconj(pcplxf
-00008650: 6c69 7028 5265 7350 6163 6b65 7454 7970  lip(ResPacketTyp
-00008660: 6528 632e 7365 636f 6e64 2929 293b 0a20  e(c.second)));. 
-00008670: 2020 2020 2074 6d70 203d 2070 6164 6428       tmp = padd(
-00008680: 5265 7350 6163 6b65 7454 7970 6528 632e  ResPacketType(c.
-00008690: 6669 7273 7429 2c74 6d70 293b 0a20 2020  first),tmp);.   
-000086a0: 207d 0a20 2020 2065 6c73 6520 6966 2828   }.    else if((
-000086b0: 436f 6e6a 4c68 7329 2626 2821 436f 6e6a  ConjLhs)&&(!Conj
-000086c0: 5268 7329 290a 2020 2020 7b0a 2020 2020  Rhs)).    {.    
-000086d0: 2020 746d 7020 3d20 7063 706c 7866 6c69    tmp = pcplxfli
-000086e0: 7028 5265 7350 6163 6b65 7454 7970 6528  p(ResPacketType(
-000086f0: 632e 7365 636f 6e64 2929 3b0a 2020 2020  c.second));.    
-00008700: 2020 746d 7020 3d20 7061 6464 2870 636f    tmp = padd(pco
-00008710: 6e6a 2852 6573 5061 636b 6574 5479 7065  nj(ResPacketType
-00008720: 2863 2e66 6972 7374 2929 2c74 6d70 293b  (c.first)),tmp);
-00008730: 0a20 2020 207d 0a20 2020 2065 6c73 6520  .    }.    else 
-00008740: 6966 2828 436f 6e6a 4c68 7329 2626 2843  if((ConjLhs)&&(C
-00008750: 6f6e 6a52 6873 2929 0a20 2020 207b 0a20  onjRhs)).    {. 
-00008760: 2020 2020 2074 6d70 203d 2070 6370 6c78       tmp = pcplx
-00008770: 666c 6970 2852 6573 5061 636b 6574 5479  flip(ResPacketTy
-00008780: 7065 2863 2e73 6563 6f6e 6429 293b 0a20  pe(c.second));. 
-00008790: 2020 2020 2074 6d70 203d 2070 7375 6228       tmp = psub(
-000087a0: 7063 6f6e 6a28 5265 7350 6163 6b65 7454  pconj(ResPacketT
-000087b0: 7970 6528 632e 6669 7273 7429 292c 746d  ype(c.first)),tm
-000087c0: 7029 3b0a 2020 2020 7d0a 2020 2020 0a20  p);.    }.    . 
-000087d0: 2020 2072 203d 2070 6d61 6464 2874 6d70     r = pmadd(tmp
-000087e0: 2c61 6c70 6861 2c72 293b 0a20 207d 0a0a  ,alpha,r);.  }..
-000087f0: 7072 6f74 6563 7465 643a 0a20 2063 6f6e  protected:.  con
-00008800: 6a5f 6865 6c70 6572 3c4c 6873 5363 616c  j_helper<LhsScal
-00008810: 6172 2c52 6873 5363 616c 6172 2c43 6f6e  ar,RhsScalar,Con
-00008820: 6a4c 6873 2c43 6f6e 6a52 6873 3e20 636a  jLhs,ConjRhs> cj
-00008830: 3b0a 7d3b 0a0a 7465 6d70 6c61 7465 3c74  ;.};..template<t
-00008840: 7970 656e 616d 6520 5265 616c 5363 616c  ypename RealScal
-00008850: 6172 2c20 626f 6f6c 205f 436f 6e6a 5268  ar, bool _ConjRh
-00008860: 732c 2069 6e74 2041 7263 682c 2069 6e74  s, int Arch, int
-00008870: 205f 5061 636b 6574 5369 7a65 3e0a 636c   _PacketSize>.cl
-00008880: 6173 7320 6765 6270 5f74 7261 6974 733c  ass gebp_traits<
-00008890: 5265 616c 5363 616c 6172 2c20 7374 643a  RealScalar, std:
-000088a0: 3a63 6f6d 706c 6578 3c52 6561 6c53 6361  :complex<RealSca
-000088b0: 6c61 723e 2c20 6661 6c73 652c 205f 436f  lar>, false, _Co
-000088c0: 6e6a 5268 732c 2041 7263 682c 205f 5061  njRhs, Arch, _Pa
-000088d0: 636b 6574 5369 7a65 203e 0a7b 0a70 7562  cketSize >.{.pub
-000088e0: 6c69 633a 0a20 2074 7970 6564 6566 2073  lic:.  typedef s
-000088f0: 7464 3a3a 636f 6d70 6c65 783c 5265 616c  td::complex<Real
-00008900: 5363 616c 6172 3e20 2053 6361 6c61 723b  Scalar>  Scalar;
-00008910: 0a20 2074 7970 6564 6566 2052 6561 6c53  .  typedef RealS
-00008920: 6361 6c61 7220 204c 6873 5363 616c 6172  calar  LhsScalar
-00008930: 3b0a 2020 7479 7065 6465 6620 5363 616c  ;.  typedef Scal
-00008940: 6172 2020 2020 2020 5268 7353 6361 6c61  ar      RhsScala
-00008950: 723b 0a20 2074 7970 6564 6566 2053 6361  r;.  typedef Sca
-00008960: 6c61 7220 2020 2020 2052 6573 5363 616c  lar      ResScal
-00008970: 6172 3b0a 0a20 2050 4143 4b45 545f 4445  ar;..  PACKET_DE
-00008980: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
-00008990: 2c20 4c68 732c 205f 5061 636b 6574 5369  , Lhs, _PacketSi
-000089a0: 7a65 293b 0a20 2050 4143 4b45 545f 4445  ze);.  PACKET_DE
-000089b0: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
-000089c0: 2c20 5268 732c 205f 5061 636b 6574 5369  , Rhs, _PacketSi
-000089d0: 7a65 293b 0a20 2050 4143 4b45 545f 4445  ze);.  PACKET_DE
-000089e0: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
-000089f0: 2c20 5265 732c 205f 5061 636b 6574 5369  , Res, _PacketSi
-00008a00: 7a65 293b 0a20 2050 4143 4b45 545f 4445  ze);.  PACKET_DE
-00008a10: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
-00008a20: 2c20 5265 616c 2c20 5f50 6163 6b65 7453  , Real, _PacketS
-00008a30: 697a 6529 3b0a 2020 5041 434b 4554 5f44  ize);.  PACKET_D
-00008a40: 4543 4c5f 434f 4e44 5f53 4341 4c41 525f  ECL_COND_SCALAR_
-00008a50: 5052 4546 4958 285f 2c20 5f50 6163 6b65  PREFIX(_, _Packe
-00008a60: 7453 697a 6529 3b0a 0a23 756e 6465 6620  tSize);..#undef 
-00008a70: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
-00008a80: 5f53 4341 4c41 525f 5052 4546 4958 0a23  _SCALAR_PREFIX.#
-00008a90: 756e 6465 6620 5041 434b 4554 5f44 4543  undef PACKET_DEC
-00008aa0: 4c5f 434f 4e44 5f50 5245 4649 580a 2375  L_COND_PREFIX.#u
-00008ab0: 6e64 6566 2050 4143 4b45 545f 4445 434c  ndef PACKET_DECL
-00008ac0: 5f43 4f4e 445f 5343 414c 4152 0a23 756e  _COND_SCALAR.#un
-00008ad0: 6465 6620 5041 434b 4554 5f44 4543 4c5f  def PACKET_DECL_
-00008ae0: 434f 4e44 0a0a 2020 656e 756d 207b 0a20  COND..  enum {. 
-00008af0: 2020 2043 6f6e 6a4c 6873 203d 2066 616c     ConjLhs = fal
-00008b00: 7365 2c0a 2020 2020 436f 6e6a 5268 7320  se,.    ConjRhs 
-00008b10: 3d20 5f43 6f6e 6a52 6873 2c0a 2020 2020  = _ConjRhs,.    
-00008b20: 5665 6374 6f72 697a 6162 6c65 203d 2075  Vectorizable = u
-00008b30: 6e70 6163 6b65 745f 7472 6169 7473 3c5f  npacket_traits<_
-00008b40: 5265 616c 5061 636b 6574 3e3a 3a76 6563  RealPacket>::vec
-00008b50: 746f 7269 7a61 626c 650a 2020 2020 2020  torizable.      
-00008b60: 2020 2020 2020 2020 2020 2626 2075 6e70            && unp
-00008b70: 6163 6b65 745f 7472 6169 7473 3c5f 5363  acket_traits<_Sc
-00008b80: 616c 6172 5061 636b 6574 3e3a 3a76 6563  alarPacket>::vec
-00008b90: 746f 7269 7a61 626c 652c 0a20 2020 204c  torizable,.    L
-00008ba0: 6873 5061 636b 6574 5369 7a65 203d 2056  hsPacketSize = V
-00008bb0: 6563 746f 7269 7a61 626c 6520 3f20 756e  ectorizable ? un
-00008bc0: 7061 636b 6574 5f74 7261 6974 733c 5f4c  packet_traits<_L
-00008bd0: 6873 5061 636b 6574 3e3a 3a73 697a 6520  hsPacket>::size 
-00008be0: 3a20 312c 0a20 2020 2052 6873 5061 636b  : 1,.    RhsPack
-00008bf0: 6574 5369 7a65 203d 2056 6563 746f 7269  etSize = Vectori
-00008c00: 7a61 626c 6520 3f20 756e 7061 636b 6574  zable ? unpacket
-00008c10: 5f74 7261 6974 733c 5f52 6873 5061 636b  _traits<_RhsPack
-00008c20: 6574 3e3a 3a73 697a 6520 3a20 312c 0a20  et>::size : 1,. 
-00008c30: 2020 2052 6573 5061 636b 6574 5369 7a65     ResPacketSize
-00008c40: 203d 2056 6563 746f 7269 7a61 626c 6520   = Vectorizable 
-00008c50: 3f20 756e 7061 636b 6574 5f74 7261 6974  ? unpacket_trait
-00008c60: 733c 5f52 6573 5061 636b 6574 3e3a 3a73  s<_ResPacket>::s
-00008c70: 697a 6520 3a20 312c 0a20 2020 200a 2020  ize : 1,.    .  
-00008c80: 2020 4e75 6d62 6572 4f66 5265 6769 7374    NumberOfRegist
-00008c90: 6572 7320 3d20 4549 4745 4e5f 4152 4348  ers = EIGEN_ARCH
-00008ca0: 5f44 4546 4155 4c54 5f4e 554d 4245 525f  _DEFAULT_NUMBER_
-00008cb0: 4f46 5f52 4547 4953 5445 5253 2c0a 2020  OF_REGISTERS,.  
-00008cc0: 2020 2f2f 2046 4958 4d45 3a20 7368 6f75    // FIXME: shou
-00008cd0: 6c64 2064 6570 656e 6420 6f6e 204e 756d  ld depend on Num
-00008ce0: 6265 724f 6652 6567 6973 7465 7273 0a20  berOfRegisters. 
-00008cf0: 2020 206e 7220 3d20 342c 0a20 2020 206d     nr = 4,.    m
-00008d00: 7220 3d20 2845 4947 454e 5f50 4c41 494e  r = (EIGEN_PLAIN
-00008d10: 5f45 4e55 4d5f 4d49 4e28 3136 2c4e 756d  _ENUM_MIN(16,Num
-00008d20: 6265 724f 6652 6567 6973 7465 7273 292f  berOfRegisters)/
-00008d30: 322f 6e72 292a 5265 7350 6163 6b65 7453  2/nr)*ResPacketS
-00008d40: 697a 652c 0a0a 2020 2020 4c68 7350 726f  ize,..    LhsPro
-00008d50: 6772 6573 7320 3d20 5265 7350 6163 6b65  gress = ResPacke
-00008d60: 7453 697a 652c 0a20 2020 2052 6873 5072  tSize,.    RhsPr
-00008d70: 6f67 7265 7373 203d 2031 0a20 207d 3b0a  ogress = 1.  };.
-00008d80: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
-00008d90: 616d 6520 636f 6e64 6974 696f 6e61 6c3c  ame conditional<
-00008da0: 5665 6374 6f72 697a 6162 6c65 2c5f 4c68  Vectorizable,_Lh
-00008db0: 7350 6163 6b65 742c 4c68 7353 6361 6c61  sPacket,LhsScala
-00008dc0: 723e 3a3a 7479 7065 204c 6873 5061 636b  r>::type LhsPack
-00008dd0: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
-00008de0: 7065 6e61 6d65 2063 6f6e 6469 7469 6f6e  pename condition
-00008df0: 616c 3c56 6563 746f 7269 7a61 626c 652c  al<Vectorizable,
-00008e00: 5f52 6873 5061 636b 6574 2c52 6873 5363  _RhsPacket,RhsSc
-00008e10: 616c 6172 3e3a 3a74 7970 6520 5268 7350  alar>::type RhsP
-00008e20: 6163 6b65 743b 0a20 2074 7970 6564 6566  acket;.  typedef
-00008e30: 2074 7970 656e 616d 6520 636f 6e64 6974   typename condit
-00008e40: 696f 6e61 6c3c 5665 6374 6f72 697a 6162  ional<Vectorizab
-00008e50: 6c65 2c5f 5265 7350 6163 6b65 742c 5265  le,_ResPacket,Re
-00008e60: 7353 6361 6c61 723e 3a3a 7479 7065 2052  sScalar>::type R
-00008e70: 6573 5061 636b 6574 3b0a 2020 7479 7065  esPacket;.  type
-00008e80: 6465 6620 4c68 7350 6163 6b65 7420 4c68  def LhsPacket Lh
-00008e90: 7350 6163 6b65 7434 5061 636b 696e 673b  sPacket4Packing;
-00008ea0: 0a20 2074 7970 6564 6566 2051 7561 6450  .  typedef QuadP
-00008eb0: 6163 6b65 743c 5268 7350 6163 6b65 743e  acket<RhsPacket>
-00008ec0: 2052 6873 5061 636b 6574 7834 3b0a 2020   RhsPacketx4;.  
-00008ed0: 7479 7065 6465 6620 5265 7350 6163 6b65  typedef ResPacke
-00008ee0: 7420 4163 6350 6163 6b65 743b 0a0a 2020  t AccPacket;..  
-00008ef0: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-00008f00: 494e 4520 766f 6964 2069 6e69 7441 6363  INE void initAcc
-00008f10: 2841 6363 5061 636b 6574 2620 7029 0a20  (AccPacket& p). 
-00008f20: 207b 0a20 2020 2070 203d 2070 7365 7431   {.    p = pset1
-00008f30: 3c52 6573 5061 636b 6574 3e28 5265 7353  <ResPacket>(ResS
-00008f40: 6361 6c61 7228 3029 293b 0a20 207d 0a0a  calar(0));.  }..
-00008f50: 2020 7465 6d70 6c61 7465 3c74 7970 656e    template<typen
-00008f60: 616d 6520 5268 7350 6163 6b65 7454 7970  ame RhsPacketTyp
-00008f70: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
-00008f80: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
-00008f90: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
-00008fa0: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
-00008fb0: 6b65 7454 7970 6526 2064 6573 7429 2063  ketType& dest) c
-00008fc0: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
-00008fd0: 7420 3d20 7073 6574 313c 5268 7350 6163  t = pset1<RhsPac
-00008fe0: 6b65 7454 7970 653e 282a 6229 3b0a 2020  ketType>(*b);.  
-00008ff0: 7d0a 0a20 2045 4947 454e 5f53 5452 4f4e  }..  EIGEN_STRON
-00009000: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
-00009010: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
-00009020: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
-00009030: 6b65 7478 3426 2064 6573 7429 2063 6f6e  ketx4& dest) con
-00009040: 7374 0a20 207b 0a20 2020 2070 6272 6f61  st.  {.    pbroa
-00009050: 6463 6173 7434 2862 2c20 6465 7374 2e42  dcast4(b, dest.B
-00009060: 5f30 2c20 6465 7374 2e42 312c 2064 6573  _0, dest.B1, des
-00009070: 742e 4232 2c20 6465 7374 2e42 3329 3b0a  t.B2, dest.B3);.
-00009080: 2020 7d0a 0a20 2074 656d 706c 6174 653c    }..  template<
-00009090: 7479 7065 6e61 6d65 2052 6873 5061 636b  typename RhsPack
-000090a0: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
-000090b0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
-000090c0: 6964 2075 7064 6174 6552 6873 2863 6f6e  id updateRhs(con
-000090d0: 7374 2052 6873 5363 616c 6172 2a20 622c  st RhsScalar* b,
-000090e0: 2052 6873 5061 636b 6574 5479 7065 2620   RhsPacketType& 
-000090f0: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
-00009100: 2020 2020 6c6f 6164 5268 7328 622c 2064      loadRhs(b, d
-00009110: 6573 7429 3b0a 2020 7d0a 0a20 2045 4947  est);.  }..  EIG
-00009120: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
-00009130: 2076 6f69 6420 7570 6461 7465 5268 7328   void updateRhs(
-00009140: 636f 6e73 7420 5268 7353 6361 6c61 722a  const RhsScalar*
-00009150: 2c20 5268 7350 6163 6b65 7478 3426 2920  , RhsPacketx4&) 
-00009160: 636f 6e73 740a 2020 7b7d 0a0a 2020 4549  const.  {}..  EI
-00009170: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
-00009180: 4520 766f 6964 206c 6f61 644c 6873 2863  E void loadLhs(c
-00009190: 6f6e 7374 204c 6873 5363 616c 6172 2a20  onst LhsScalar* 
-000091a0: 612c 204c 6873 5061 636b 6574 2620 6465  a, LhsPacket& de
-000091b0: 7374 2920 636f 6e73 740a 2020 7b0a 2020  st) const.  {.  
-000091c0: 2020 6465 7374 203d 2070 6c6f 6164 6475    dest = ploaddu
-000091d0: 703c 4c68 7350 6163 6b65 743e 2861 293b  p<LhsPacket>(a);
-000091e0: 0a20 207d 0a20 200a 2020 4549 4745 4e5f  .  }.  .  EIGEN_
-000091f0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
-00009200: 6964 206c 6f61 6452 6873 5175 6164 2863  id loadRhsQuad(c
-00009210: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
-00009220: 622c 2052 6873 5061 636b 6574 2620 6465  b, RhsPacket& de
-00009230: 7374 2920 636f 6e73 740a 2020 7b0a 2020  st) const.  {.  
-00009240: 2020 6465 7374 203d 2070 6c6f 6164 7175    dest = ploadqu
-00009250: 6164 3c52 6873 5061 636b 6574 3e28 6229  ad<RhsPacket>(b)
-00009260: 3b0a 2020 7d0a 0a20 2074 656d 706c 6174  ;.  }..  templat
-00009270: 653c 7479 7065 6e61 6d65 204c 6873 5061  e<typename LhsPa
-00009280: 636b 6574 5479 7065 3e0a 2020 4549 4745  cketType>.  EIGE
-00009290: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-000092a0: 766f 6964 206c 6f61 644c 6873 556e 616c  void loadLhsUnal
-000092b0: 6967 6e65 6428 636f 6e73 7420 4c68 7353  igned(const LhsS
-000092c0: 6361 6c61 722a 2061 2c20 4c68 7350 6163  calar* a, LhsPac
-000092d0: 6b65 7454 7970 6526 2064 6573 7429 2063  ketType& dest) c
-000092e0: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
-000092f0: 7420 3d20 706c 6f61 6464 7570 3c4c 6873  t = ploaddup<Lhs
-00009300: 5061 636b 6574 5479 7065 3e28 6129 3b0a  PacketType>(a);.
-00009310: 2020 7d0a 0a20 2074 656d 706c 6174 6520    }..  template 
-00009320: 3c74 7970 656e 616d 6520 4c68 7350 6163  <typename LhsPac
-00009330: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
-00009340: 6520 5268 7350 6163 6b65 7454 7970 652c  e RhsPacketType,
-00009350: 2074 7970 656e 616d 6520 4163 6350 6163   typename AccPac
-00009360: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
-00009370: 6520 4c61 6e65 4964 5479 7065 3e0a 2020  e LaneIdType>.  
-00009380: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-00009390: 494e 4520 766f 6964 206d 6164 6428 636f  INE void madd(co
-000093a0: 6e73 7420 4c68 7350 6163 6b65 7454 7970  nst LhsPacketTyp
-000093b0: 6526 2061 2c20 636f 6e73 7420 5268 7350  e& a, const RhsP
-000093c0: 6163 6b65 7454 7970 6526 2062 2c20 4163  acketType& b, Ac
-000093d0: 6350 6163 6b65 7454 7970 6526 2063 2c20  cPacketType& c, 
-000093e0: 5268 7350 6163 6b65 7454 7970 6526 2074  RhsPacketType& t
-000093f0: 6d70 2c20 636f 6e73 7420 4c61 6e65 4964  mp, const LaneId
-00009400: 5479 7065 2629 2063 6f6e 7374 0a20 207b  Type&) const.  {
-00009410: 0a20 2020 206d 6164 645f 696d 706c 2861  .    madd_impl(a
-00009420: 2c20 622c 2063 2c20 746d 702c 2074 7970  , b, c, tmp, typ
-00009430: 656e 616d 6520 636f 6e64 6974 696f 6e61  ename conditiona
-00009440: 6c3c 5665 6374 6f72 697a 6162 6c65 2c74  l<Vectorizable,t
-00009450: 7275 655f 7479 7065 2c66 616c 7365 5f74  rue_type,false_t
-00009460: 7970 653e 3a3a 7479 7065 2829 293b 0a20  ype>::type());. 
-00009470: 207d 0a0a 2020 7465 6d70 6c61 7465 203c   }..  template <
-00009480: 7479 7065 6e61 6d65 204c 6873 5061 636b  typename LhsPack
-00009490: 6574 5479 7065 2c20 7479 7065 6e61 6d65  etType, typename
-000094a0: 2052 6873 5061 636b 6574 5479 7065 2c20   RhsPacketType, 
-000094b0: 7479 7065 6e61 6d65 2041 6363 5061 636b  typename AccPack
-000094c0: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
-000094d0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
-000094e0: 6964 206d 6164 645f 696d 706c 2863 6f6e  id madd_impl(con
-000094f0: 7374 204c 6873 5061 636b 6574 5479 7065  st LhsPacketType
-00009500: 2620 612c 2063 6f6e 7374 2052 6873 5061  & a, const RhsPa
-00009510: 636b 6574 5479 7065 2620 622c 2041 6363  cketType& b, Acc
-00009520: 5061 636b 6574 5479 7065 2620 632c 2052  PacketType& c, R
-00009530: 6873 5061 636b 6574 5479 7065 2620 746d  hsPacketType& tm
-00009540: 702c 2063 6f6e 7374 2074 7275 655f 7479  p, const true_ty
-00009550: 7065 2629 2063 6f6e 7374 0a20 207b 0a23  pe&) const.  {.#
-00009560: 6966 6465 6620 4549 4745 4e5f 4841 535f  ifdef EIGEN_HAS_
-00009570: 5349 4e47 4c45 5f49 4e53 5452 5543 5449  SINGLE_INSTRUCTI
-00009580: 4f4e 5f4d 4144 440a 2020 2020 4549 4745  ON_MADD.    EIGE
-00009590: 4e5f 554e 5553 4544 5f56 4152 4941 424c  N_UNUSED_VARIABL
-000095a0: 4528 746d 7029 3b0a 2020 2020 632e 7620  E(tmp);.    c.v 
-000095b0: 3d20 706d 6164 6428 612c 622e 762c 632e  = pmadd(a,b.v,c.
-000095c0: 7629 3b0a 2365 6c73 650a 2020 2020 746d  v);.#else.    tm
-000095d0: 7020 3d20 623b 2074 6d70 2e76 203d 2070  p = b; tmp.v = p
-000095e0: 6d75 6c28 612c 746d 702e 7629 3b20 6320  mul(a,tmp.v); c 
-000095f0: 3d20 7061 6464 2863 2c74 6d70 293b 0a23  = padd(c,tmp);.#
-00009600: 656e 6469 660a 2020 2020 0a20 207d 0a0a  endif.    .  }..
-00009610: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-00009620: 4e4c 494e 4520 766f 6964 206d 6164 645f  NLINE void madd_
-00009630: 696d 706c 2863 6f6e 7374 204c 6873 5363  impl(const LhsSc
-00009640: 616c 6172 2620 612c 2063 6f6e 7374 2052  alar& a, const R
-00009650: 6873 5363 616c 6172 2620 622c 2052 6573  hsScalar& b, Res
-00009660: 5363 616c 6172 2620 632c 2052 6873 5363  Scalar& c, RhsSc
-00009670: 616c 6172 2620 2f2a 746d 702a 2f2c 2063  alar& /*tmp*/, c
-00009680: 6f6e 7374 2066 616c 7365 5f74 7970 6526  onst false_type&
-00009690: 2920 636f 6e73 740a 2020 7b0a 2020 2020  ) const.  {.    
-000096a0: 6320 2b3d 2061 202a 2062 3b0a 2020 7d0a  c += a * b;.  }.
-000096b0: 0a20 2074 656d 706c 6174 653c 7479 7065  .  template<type
-000096c0: 6e61 6d65 204c 6873 5061 636b 6574 5479  name LhsPacketTy
-000096d0: 7065 2c20 7479 7065 6e61 6d65 2041 6363  pe, typename Acc
-000096e0: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
-000096f0: 6e61 6d65 204c 616e 6549 6454 7970 653e  name LaneIdType>
-00009700: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
-00009710: 494e 4c49 4e45 2076 6f69 6420 6d61 6464  INLINE void madd
-00009720: 2863 6f6e 7374 204c 6873 5061 636b 6574  (const LhsPacket
-00009730: 5479 7065 2620 612c 2063 6f6e 7374 2052  Type& a, const R
-00009740: 6873 5061 636b 6574 7834 2620 622c 2041  hsPacketx4& b, A
-00009750: 6363 5061 636b 6574 5479 7065 2620 632c  ccPacketType& c,
-00009760: 2052 6873 5061 636b 6574 2620 746d 702c   RhsPacket& tmp,
-00009770: 2063 6f6e 7374 204c 616e 6549 6454 7970   const LaneIdTyp
-00009780: 6526 206c 616e 6529 2063 6f6e 7374 0a20  e& lane) const. 
-00009790: 207b 0a20 2020 206d 6164 6428 612c 2062   {.    madd(a, b
-000097a0: 2e67 6574 286c 616e 6529 2c20 632c 2074  .get(lane), c, t
-000097b0: 6d70 2c20 6c61 6e65 293b 0a20 207d 0a0a  mp, lane);.  }..
-000097c0: 2020 7465 6d70 6c61 7465 203c 7479 7065    template <type
-000097d0: 6e61 6d65 2052 6573 5061 636b 6574 5479  name ResPacketTy
-000097e0: 7065 2c20 7479 7065 6e61 6d65 2041 6363  pe, typename Acc
-000097f0: 5061 636b 6574 5479 7065 3e0a 2020 4549  PacketType>.  EI
-00009800: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
-00009810: 4520 766f 6964 2061 6363 2863 6f6e 7374  E void acc(const
-00009820: 2041 6363 5061 636b 6574 5479 7065 2620   AccPacketType& 
-00009830: 632c 2063 6f6e 7374 2052 6573 5061 636b  c, const ResPack
-00009840: 6574 5479 7065 2620 616c 7068 612c 2052  etType& alpha, R
-00009850: 6573 5061 636b 6574 5479 7065 2620 7229  esPacketType& r)
-00009860: 2063 6f6e 7374 0a20 207b 0a20 2020 2063   const.  {.    c
-00009870: 6f6e 6a5f 6865 6c70 6572 3c52 6573 5061  onj_helper<ResPa
-00009880: 636b 6574 5479 7065 2c52 6573 5061 636b  cketType,ResPack
-00009890: 6574 5479 7065 2c66 616c 7365 2c43 6f6e  etType,false,Con
-000098a0: 6a52 6873 3e20 636a 3b0a 2020 2020 7220  jRhs> cj;.    r 
-000098b0: 3d20 636a 2e70 6d61 6464 2861 6c70 6861  = cj.pmadd(alpha
-000098c0: 2c63 2c72 293b 0a20 207d 0a0a 7072 6f74  ,c,r);.  }..prot
-000098d0: 6563 7465 643a 0a0a 7d3b 0a0a 0a23 6966  ected:..};...#if
-000098e0: 2045 4947 454e 5f41 5243 485f 4152 4d36   EIGEN_ARCH_ARM6
-000098f0: 3420 2626 2064 6566 696e 6564 2045 4947  4 && defined EIG
-00009900: 454e 5f56 4543 544f 5249 5a45 5f4e 454f  EN_VECTORIZE_NEO
-00009910: 4e0a 0a74 656d 706c 6174 653c 3e0a 7374  N..template<>.st
-00009920: 7275 6374 2067 6562 705f 7472 6169 7473  ruct gebp_traits
-00009930: 203c 666c 6f61 742c 2066 6c6f 6174 2c20   <float, float, 
-00009940: 6661 6c73 652c 2066 616c 7365 2c41 7263  false, false,Arc
-00009950: 6869 7465 6374 7572 653a 3a4e 454f 4e2c  hitecture::NEON,
-00009960: 4745 4250 5061 636b 6574 4675 6c6c 3e0a  GEBPPacketFull>.
-00009970: 203a 2067 6562 705f 7472 6169 7473 3c66   : gebp_traits<f
-00009980: 6c6f 6174 2c66 6c6f 6174 2c66 616c 7365  loat,float,false
-00009990: 2c66 616c 7365 2c41 7263 6869 7465 6374  ,false,Architect
-000099a0: 7572 653a 3a47 656e 6572 6963 2c47 4542  ure::Generic,GEB
-000099b0: 5050 6163 6b65 7446 756c 6c3e 0a7b 0a20  PPacketFull>.{. 
-000099c0: 2074 7970 6564 6566 2066 6c6f 6174 2052   typedef float R
-000099d0: 6873 5061 636b 6574 3b0a 0a20 2074 7970  hsPacket;..  typ
-000099e0: 6564 6566 2066 6c6f 6174 3332 7834 5f74  edef float32x4_t
-000099f0: 2052 6873 5061 636b 6574 7834 3b0a 0a20   RhsPacketx4;.. 
-00009a00: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-00009a10: 4c49 4e45 2076 6f69 6420 6c6f 6164 5268  LINE void loadRh
-00009a20: 7328 636f 6e73 7420 5268 7353 6361 6c61  s(const RhsScala
-00009a30: 722a 2062 2c20 5268 7350 6163 6b65 7426  r* b, RhsPacket&
-00009a40: 2064 6573 7429 2063 6f6e 7374 0a20 207b   dest) const.  {
-00009a50: 0a20 2020 2064 6573 7420 3d20 2a62 3b0a  .    dest = *b;.
-00009a60: 2020 7d0a 0a20 2045 4947 454e 5f53 5452    }..  EIGEN_STR
-00009a70: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
-00009a80: 6c6f 6164 5268 7328 636f 6e73 7420 5268  loadRhs(const Rh
-00009a90: 7353 6361 6c61 722a 2062 2c20 5268 7350  sScalar* b, RhsP
-00009aa0: 6163 6b65 7478 3426 2064 6573 7429 2063  acketx4& dest) c
-00009ab0: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
-00009ac0: 7420 3d20 766c 6431 715f 6633 3228 6229  t = vld1q_f32(b)
-00009ad0: 3b0a 2020 7d0a 0a20 2045 4947 454e 5f53  ;.  }..  EIGEN_S
-00009ae0: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
-00009af0: 6420 7570 6461 7465 5268 7328 636f 6e73  d updateRhs(cons
-00009b00: 7420 5268 7353 6361 6c61 722a 2062 2c20  t RhsScalar* b, 
-00009b10: 5268 7350 6163 6b65 7426 2064 6573 7429  RhsPacket& dest)
-00009b20: 2063 6f6e 7374 0a20 207b 0a20 2020 2064   const.  {.    d
-00009b30: 6573 7420 3d20 2a62 3b0a 2020 7d0a 0a20  est = *b;.  }.. 
-00009b40: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-00009b50: 4c49 4e45 2076 6f69 6420 7570 6461 7465  LINE void update
-00009b60: 5268 7328 636f 6e73 7420 5268 7353 6361  Rhs(const RhsSca
-00009b70: 6c61 722a 2062 2c20 5268 7350 6163 6b65  lar* b, RhsPacke
-00009b80: 7478 3426 2064 6573 7429 2063 6f6e 7374  tx4& dest) const
-00009b90: 0a20 207b 7d0a 0a20 2045 4947 454e 5f53  .  {}..  EIGEN_S
-00009ba0: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
-00009bb0: 6420 6c6f 6164 5268 7351 7561 6428 636f  d loadRhsQuad(co
-00009bc0: 6e73 7420 5268 7353 6361 6c61 722a 2062  nst RhsScalar* b
-00009bd0: 2c20 5268 7350 6163 6b65 7426 2064 6573  , RhsPacket& des
-00009be0: 7429 2063 6f6e 7374 0a20 207b 0a20 2020  t) const.  {.   
-00009bf0: 206c 6f61 6452 6873 2862 2c64 6573 7429   loadRhs(b,dest)
-00009c00: 3b0a 2020 7d0a 0a20 2045 4947 454e 5f53  ;.  }..  EIGEN_S
-00009c10: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
-00009c20: 6420 6d61 6464 2863 6f6e 7374 204c 6873  d madd(const Lhs
-00009c30: 5061 636b 6574 2620 612c 2063 6f6e 7374  Packet& a, const
-00009c40: 2052 6873 5061 636b 6574 2620 622c 2041   RhsPacket& b, A
-00009c50: 6363 5061 636b 6574 2620 632c 2052 6873  ccPacket& c, Rhs
-00009c60: 5061 636b 6574 2620 2f2a 746d 702a 2f2c  Packet& /*tmp*/,
-00009c70: 2063 6f6e 7374 2046 6978 6564 496e 743c   const FixedInt<
-00009c80: 303e 2629 2063 6f6e 7374 0a20 207b 0a20  0>&) const.  {. 
-00009c90: 2020 2063 203d 2076 666d 6171 5f6e 5f66     c = vfmaq_n_f
-00009ca0: 3332 2863 2c20 612c 2062 293b 0a20 207d  32(c, a, b);.  }
-00009cb0: 0a0a 2020 2f2f 204e 4f54 453a 2054 656d  ..  // NOTE: Tem
-00009cc0: 706c 6174 6520 7061 7261 6d65 7465 7220  plate parameter 
-00009cd0: 696e 6665 7265 6e63 6520 6661 696c 6564  inference failed
-00009ce0: 2077 6865 6e20 636f 6d70 696c 6564 2077   when compiled w
-00009cf0: 6974 6820 416e 6472 6f69 6420 4e44 4b3a  ith Android NDK:
-00009d00: 0a20 202f 2f20 2263 616e 6469 6461 7465  .  // "candidate
-00009d10: 2074 656d 706c 6174 6520 6967 6e6f 7265   template ignore
-00009d20: 643a 2063 6f75 6c64 206e 6f74 206d 6174  d: could not mat
-00009d30: 6368 2027 4669 7865 6449 6e74 3c4e 3e27  ch 'FixedInt<N>'
-00009d40: 2061 6761 696e 7374 2027 4569 6765 6e3a   against 'Eigen:
-00009d50: 3a69 6e74 6572 6e61 6c3a 3a46 6978 6564  :internal::Fixed
-00009d60: 496e 743c 303e 222e 0a0a 2020 4549 4745  Int<0>"...  EIGE
-00009d70: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-00009d80: 766f 6964 206d 6164 6428 636f 6e73 7420  void madd(const 
-00009d90: 4c68 7350 6163 6b65 7426 2061 2c20 636f  LhsPacket& a, co
-00009da0: 6e73 7420 5268 7350 6163 6b65 7478 3426  nst RhsPacketx4&
-00009db0: 2062 2c20 4163 6350 6163 6b65 7426 2063   b, AccPacket& c
-00009dc0: 2c20 5268 7350 6163 6b65 7426 202f 2a74  , RhsPacket& /*t
-00009dd0: 6d70 2a2f 2c20 636f 6e73 7420 4669 7865  mp*/, const Fixe
-00009de0: 6449 6e74 3c30 3e26 2920 636f 6e73 740a  dInt<0>&) const.
-00009df0: 2020 7b20 6d61 6464 5f68 656c 7065 723c    { madd_helper<
-00009e00: 303e 2861 2c20 622c 2063 293b 207d 0a20  0>(a, b, c); }. 
-00009e10: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-00009e20: 4c49 4e45 2076 6f69 6420 6d61 6464 2863  LINE void madd(c
-00009e30: 6f6e 7374 204c 6873 5061 636b 6574 2620  onst LhsPacket& 
-00009e40: 612c 2063 6f6e 7374 2052 6873 5061 636b  a, const RhsPack
-00009e50: 6574 7834 2620 622c 2041 6363 5061 636b  etx4& b, AccPack
-00009e60: 6574 2620 632c 2052 6873 5061 636b 6574  et& c, RhsPacket
-00009e70: 2620 2f2a 746d 702a 2f2c 2063 6f6e 7374  & /*tmp*/, const
-00009e80: 2046 6978 6564 496e 743c 313e 2629 2063   FixedInt<1>&) c
-00009e90: 6f6e 7374 0a20 207b 206d 6164 645f 6865  onst.  { madd_he
-00009ea0: 6c70 6572 3c31 3e28 612c 2062 2c20 6329  lper<1>(a, b, c)
-00009eb0: 3b20 7d0a 2020 4549 4745 4e5f 5354 524f  ; }.  EIGEN_STRO
-00009ec0: 4e47 5f49 4e4c 494e 4520 766f 6964 206d  NG_INLINE void m
-00009ed0: 6164 6428 636f 6e73 7420 4c68 7350 6163  add(const LhsPac
-00009ee0: 6b65 7426 2061 2c20 636f 6e73 7420 5268  ket& a, const Rh
-00009ef0: 7350 6163 6b65 7478 3426 2062 2c20 4163  sPacketx4& b, Ac
-00009f00: 6350 6163 6b65 7426 2063 2c20 5268 7350  cPacket& c, RhsP
-00009f10: 6163 6b65 7426 202f 2a74 6d70 2a2f 2c20  acket& /*tmp*/, 
-00009f20: 636f 6e73 7420 4669 7865 6449 6e74 3c32  const FixedInt<2
-00009f30: 3e26 2920 636f 6e73 740a 2020 7b20 6d61  >&) const.  { ma
-00009f40: 6464 5f68 656c 7065 723c 323e 2861 2c20  dd_helper<2>(a, 
-00009f50: 622c 2063 293b 207d 0a20 2045 4947 454e  b, c); }.  EIGEN
-00009f60: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-00009f70: 6f69 6420 6d61 6464 2863 6f6e 7374 204c  oid madd(const L
-00009f80: 6873 5061 636b 6574 2620 612c 2063 6f6e  hsPacket& a, con
-00009f90: 7374 2052 6873 5061 636b 6574 7834 2620  st RhsPacketx4& 
-00009fa0: 622c 2041 6363 5061 636b 6574 2620 632c  b, AccPacket& c,
-00009fb0: 2052 6873 5061 636b 6574 2620 2f2a 746d   RhsPacket& /*tm
-00009fc0: 702a 2f2c 2063 6f6e 7374 2046 6978 6564  p*/, const Fixed
-00009fd0: 496e 743c 333e 2629 2063 6f6e 7374 0a20  Int<3>&) const. 
-00009fe0: 207b 206d 6164 645f 6865 6c70 6572 3c33   { madd_helper<3
-00009ff0: 3e28 612c 2062 2c20 6329 3b20 7d0a 0a20  >(a, b, c); }.. 
-0000a000: 7072 6976 6174 653a 0a20 2074 656d 706c  private:.  templ
-0000a010: 6174 653c 696e 7420 4c61 6e65 4944 3e0a  ate<int LaneID>.
-0000a020: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
-0000a030: 4e4c 494e 4520 766f 6964 206d 6164 645f  NLINE void madd_
-0000a040: 6865 6c70 6572 2863 6f6e 7374 204c 6873  helper(const Lhs
-0000a050: 5061 636b 6574 2620 612c 2063 6f6e 7374  Packet& a, const
-0000a060: 2052 6873 5061 636b 6574 7834 2620 622c   RhsPacketx4& b,
-0000a070: 2041 6363 5061 636b 6574 2620 6329 2063   AccPacket& c) c
-0000a080: 6f6e 7374 0a20 207b 0a20 2020 2023 6966  onst.  {.    #if
-0000a090: 2045 4947 454e 5f43 4f4d 505f 474e 5543   EIGEN_COMP_GNUC
-0000a0a0: 5f53 5452 4943 5420 2626 2021 2845 4947  _STRICT && !(EIG
-0000a0b0: 454e 5f47 4e55 435f 4154 5f4c 4541 5354  EN_GNUC_AT_LEAST
-0000a0c0: 2839 2c30 2929 0a20 2020 202f 2f20 776f  (9,0)).    // wo
-0000a0d0: 726b 6172 6f75 6e64 2067 6363 2069 7373  rkaround gcc iss
-0000a0e0: 7565 2068 7474 7073 3a2f 2f67 6363 2e67  ue https://gcc.g
-0000a0f0: 6e75 2e6f 7267 2f62 7567 7a69 6c6c 612f  nu.org/bugzilla/
-0000a100: 7368 6f77 5f62 7567 2e63 6769 3f69 643d  show_bug.cgi?id=
-0000a110: 3839 3130 310a 2020 2020 2f2f 2076 666d  89101.    // vfm
-0000a120: 6171 5f6c 616e 6571 5f66 3332 2069 7320  aq_laneq_f32 is 
-0000a130: 696d 706c 656d 656e 7465 6420 7468 726f  implemented thro
-0000a140: 7567 6820 6120 636f 7374 6c79 2064 7570  ugh a costly dup
-0000a150: 0a20 2020 2020 2020 2020 6966 284c 616e  .         if(Lan
-0000a160: 6549 443d 3d30 2920 2061 736d 2822 666d  eID==0)  asm("fm
-0000a170: 6c61 2025 302e 3473 2c20 2531 2e34 732c  la %0.4s, %1.4s,
-0000a180: 2025 322e 735b 305d 5c6e 2220 3a20 222b   %2.s[0]\n" : "+
-0000a190: 7722 2028 6329 203a 2022 7722 2028 6129  w" (c) : "w" (a)
-0000a1a0: 2c20 2277 2220 2862 2920 3a20 2029 3b0a  , "w" (b) :  );.
-0000a1b0: 2020 2020 656c 7365 2069 6628 4c61 6e65      else if(Lane
-0000a1c0: 4944 3d3d 3129 2020 6173 6d28 2266 6d6c  ID==1)  asm("fml
-0000a1d0: 6120 2530 2e34 732c 2025 312e 3473 2c20  a %0.4s, %1.4s, 
-0000a1e0: 2532 2e73 5b31 5d5c 6e22 203a 2022 2b77  %2.s[1]\n" : "+w
-0000a1f0: 2220 2863 2920 3a20 2277 2220 2861 292c  " (c) : "w" (a),
-0000a200: 2022 7722 2028 6229 203a 2020 293b 0a20   "w" (b) :  );. 
-0000a210: 2020 2065 6c73 6520 6966 284c 616e 6549     else if(LaneI
-0000a220: 443d 3d32 2920 2061 736d 2822 666d 6c61  D==2)  asm("fmla
-0000a230: 2025 302e 3473 2c20 2531 2e34 732c 2025   %0.4s, %1.4s, %
-0000a240: 322e 735b 325d 5c6e 2220 3a20 222b 7722  2.s[2]\n" : "+w"
-0000a250: 2028 6329 203a 2022 7722 2028 6129 2c20   (c) : "w" (a), 
-0000a260: 2277 2220 2862 2920 3a20 2029 3b0a 2020  "w" (b) :  );.  
-0000a270: 2020 656c 7365 2069 6628 4c61 6e65 4944    else if(LaneID
-0000a280: 3d3d 3329 2020 6173 6d28 2266 6d6c 6120  ==3)  asm("fmla 
-0000a290: 2530 2e34 732c 2025 312e 3473 2c20 2532  %0.4s, %1.4s, %2
-0000a2a0: 2e73 5b33 5d5c 6e22 203a 2022 2b77 2220  .s[3]\n" : "+w" 
-0000a2b0: 2863 2920 3a20 2277 2220 2861 292c 2022  (c) : "w" (a), "
-0000a2c0: 7722 2028 6229 203a 2020 293b 0a20 2020  w" (b) :  );.   
-0000a2d0: 2023 656c 7365 0a20 2020 2063 203d 2076   #else.    c = v
-0000a2e0: 666d 6171 5f6c 616e 6571 5f66 3332 2863  fmaq_laneq_f32(c
-0000a2f0: 2c20 612c 2062 2c20 4c61 6e65 4944 293b  , a, b, LaneID);
-0000a300: 0a20 2020 2023 656e 6469 660a 2020 7d0a  .    #endif.  }.
-0000a310: 7d3b 0a0a 0a74 656d 706c 6174 653c 3e0a  };...template<>.
-0000a320: 7374 7275 6374 2067 6562 705f 7472 6169  struct gebp_trai
-0000a330: 7473 203c 646f 7562 6c65 2c20 646f 7562  ts <double, doub
-0000a340: 6c65 2c20 6661 6c73 652c 2066 616c 7365  le, false, false
-0000a350: 2c41 7263 6869 7465 6374 7572 653a 3a4e  ,Architecture::N
-0000a360: 454f 4e3e 0a20 3a20 6765 6270 5f74 7261  EON>. : gebp_tra
-0000a370: 6974 733c 646f 7562 6c65 2c64 6f75 626c  its<double,doubl
-0000a380: 652c 6661 6c73 652c 6661 6c73 652c 4172  e,false,false,Ar
-0000a390: 6368 6974 6563 7475 7265 3a3a 4765 6e65  chitecture::Gene
-0000a3a0: 7269 633e 0a7b 0a20 2074 7970 6564 6566  ric>.{.  typedef
-0000a3b0: 2064 6f75 626c 6520 5268 7350 6163 6b65   double RhsPacke
-0000a3c0: 743b 0a0a 2020 7374 7275 6374 2052 6873  t;..  struct Rhs
-0000a3d0: 5061 636b 6574 7834 207b 0a20 2020 2066  Packetx4 {.    f
-0000a3e0: 6c6f 6174 3634 7832 5f74 2042 5f30 2c20  loat64x2_t B_0, 
-0000a3f0: 425f 313b 0a20 207d 3b0a 0a20 2045 4947  B_1;.  };..  EIG
-0000a400: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
-0000a410: 2076 6f69 6420 6c6f 6164 5268 7328 636f   void loadRhs(co
-0000a420: 6e73 7420 5268 7353 6361 6c61 722a 2062  nst RhsScalar* b
-0000a430: 2c20 5268 7350 6163 6b65 7426 2064 6573  , RhsPacket& des
-0000a440: 7429 2063 6f6e 7374 0a20 207b 0a20 2020  t) const.  {.   
-0000a450: 2064 6573 7420 3d20 2a62 3b0a 2020 7d0a   dest = *b;.  }.
-0000a460: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
-0000a470: 494e 4c49 4e45 2076 6f69 6420 6c6f 6164  INLINE void load
-0000a480: 5268 7328 636f 6e73 7420 5268 7353 6361  Rhs(const RhsSca
-0000a490: 6c61 722a 2062 2c20 5268 7350 6163 6b65  lar* b, RhsPacke
-0000a4a0: 7478 3426 2064 6573 7429 2063 6f6e 7374  tx4& dest) const
-0000a4b0: 0a20 207b 0a20 2020 2064 6573 742e 425f  .  {.    dest.B_
-0000a4c0: 3020 3d20 766c 6431 715f 6636 3428 6229  0 = vld1q_f64(b)
-0000a4d0: 3b0a 2020 2020 6465 7374 2e42 5f31 203d  ;.    dest.B_1 =
-0000a4e0: 2076 6c64 3171 5f66 3634 2862 2b32 293b   vld1q_f64(b+2);
-0000a4f0: 0a20 207d 0a0a 2020 4549 4745 4e5f 5354  .  }..  EIGEN_ST
-0000a500: 524f 4e47 5f49 4e4c 494e 4520 766f 6964  RONG_INLINE void
-0000a510: 2075 7064 6174 6552 6873 2863 6f6e 7374   updateRhs(const
-0000a520: 2052 6873 5363 616c 6172 2a20 622c 2052   RhsScalar* b, R
-0000a530: 6873 5061 636b 6574 2620 6465 7374 2920  hsPacket& dest) 
-0000a540: 636f 6e73 740a 2020 7b0a 2020 2020 6c6f  const.  {.    lo
-0000a550: 6164 5268 7328 622c 6465 7374 293b 0a20  adRhs(b,dest);. 
-0000a560: 207d 0a0a 2020 4549 4745 4e5f 5354 524f   }..  EIGEN_STRO
-0000a570: 4e47 5f49 4e4c 494e 4520 766f 6964 2075  NG_INLINE void u
-0000a580: 7064 6174 6552 6873 2863 6f6e 7374 2052  pdateRhs(const R
-0000a590: 6873 5363 616c 6172 2a20 622c 2052 6873  hsScalar* b, Rhs
-0000a5a0: 5061 636b 6574 7834 2620 6465 7374 2920  Packetx4& dest) 
-0000a5b0: 636f 6e73 740a 2020 7b7d 0a0a 2020 4549  const.  {}..  EI
-0000a5c0: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
-0000a5d0: 4520 766f 6964 206c 6f61 6452 6873 5175  E void loadRhsQu
-0000a5e0: 6164 2863 6f6e 7374 2052 6873 5363 616c  ad(const RhsScal
-0000a5f0: 6172 2a20 622c 2052 6873 5061 636b 6574  ar* b, RhsPacket
-0000a600: 2620 6465 7374 2920 636f 6e73 740a 2020  & dest) const.  
-0000a610: 7b0a 2020 2020 6c6f 6164 5268 7328 622c  {.    loadRhs(b,
-0000a620: 6465 7374 293b 0a20 207d 0a0a 2020 4549  dest);.  }..  EI
-0000a630: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
-0000a640: 4520 766f 6964 206d 6164 6428 636f 6e73  E void madd(cons
-0000a650: 7420 4c68 7350 6163 6b65 7426 2061 2c20  t LhsPacket& a, 
-0000a660: 636f 6e73 7420 5268 7350 6163 6b65 7426  const RhsPacket&
-0000a670: 2062 2c20 4163 6350 6163 6b65 7426 2063   b, AccPacket& c
-0000a680: 2c20 5268 7350 6163 6b65 7426 202f 2a74  , RhsPacket& /*t
-0000a690: 6d70 2a2f 2c20 636f 6e73 7420 4669 7865  mp*/, const Fixe
-0000a6a0: 6449 6e74 3c30 3e26 2920 636f 6e73 740a  dInt<0>&) const.
-0000a6b0: 2020 7b0a 2020 2020 6320 3d20 7666 6d61    {.    c = vfma
-0000a6c0: 715f 6e5f 6636 3428 632c 2061 2c20 6229  q_n_f64(c, a, b)
-0000a6d0: 3b0a 2020 7d0a 0a20 202f 2f20 4e4f 5445  ;.  }..  // NOTE
-0000a6e0: 3a20 5465 6d70 6c61 7465 2070 6172 616d  : Template param
-0000a6f0: 6574 6572 2069 6e66 6572 656e 6365 2066  eter inference f
-0000a700: 6169 6c65 6420 7768 656e 2063 6f6d 7069  ailed when compi
-0000a710: 6c65 6420 7769 7468 2041 6e64 726f 6964  led with Android
-0000a720: 204e 444b 3a0a 2020 2f2f 2022 6361 6e64   NDK:.  // "cand
-0000a730: 6964 6174 6520 7465 6d70 6c61 7465 2069  idate template i
-0000a740: 676e 6f72 6564 3a20 636f 756c 6420 6e6f  gnored: could no
-0000a750: 7420 6d61 7463 6820 2746 6978 6564 496e  t match 'FixedIn
-0000a760: 743c 4e3e 2720 6167 6169 6e73 7420 2745  t<N>' against 'E
-0000a770: 6967 656e 3a3a 696e 7465 726e 616c 3a3a  igen::internal::
-0000a780: 4669 7865 6449 6e74 3c30 3e22 2e0a 0a20  FixedInt<0>"... 
-0000a790: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
-0000a7a0: 4c49 4e45 2076 6f69 6420 6d61 6464 2863  LINE void madd(c
-0000a7b0: 6f6e 7374 204c 6873 5061 636b 6574 2620  onst LhsPacket& 
-0000a7c0: 612c 2063 6f6e 7374 2052 6873 5061 636b  a, const RhsPack
-0000a7d0: 6574 7834 2620 622c 2041 6363 5061 636b  etx4& b, AccPack
-0000a7e0: 6574 2620 632c 2052 6873 5061 636b 6574  et& c, RhsPacket
-0000a7f0: 2620 2f2a 746d 702a 2f2c 2063 6f6e 7374  & /*tmp*/, const
-0000a800: 2046 6978 6564 496e 743c 303e 2629 2063   FixedInt<0>&) c
-0000a810: 6f6e 7374 0a20 207b 206d 6164 645f 6865  onst.  { madd_he
-0000a820: 6c70 6572 3c30 3e28 612c 2062 2c20 6329  lper<0>(a, b, c)
-0000a830: 3b20 7d0a 2020 4549 4745 4e5f 5354 524f  ; }.  EIGEN_STRO
-0000a840: 4e47 5f49 4e4c 494e 4520 766f 6964 206d  NG_INLINE void m
-0000a850: 6164 6428 636f 6e73 7420 4c68 7350 6163  add(const LhsPac
-0000a860: 6b65 7426 2061 2c20 636f 6e73 7420 5268  ket& a, const Rh
-0000a870: 7350 6163 6b65 7478 3426 2062 2c20 4163  sPacketx4& b, Ac
-0000a880: 6350 6163 6b65 7426 2063 2c20 5268 7350  cPacket& c, RhsP
-0000a890: 6163 6b65 7426 202f 2a74 6d70 2a2f 2c20  acket& /*tmp*/, 
-0000a8a0: 636f 6e73 7420 4669 7865 6449 6e74 3c31  const FixedInt<1
-0000a8b0: 3e26 2920 636f 6e73 740a 2020 7b20 6d61  >&) const.  { ma
-0000a8c0: 6464 5f68 656c 7065 723c 313e 2861 2c20  dd_helper<1>(a, 
-0000a8d0: 622c 2063 293b 207d 0a20 2045 4947 454e  b, c); }.  EIGEN
-0000a8e0: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-0000a8f0: 6f69 6420 6d61 6464 2863 6f6e 7374 204c  oid madd(const L
-0000a900: 6873 5061 636b 6574 2620 612c 2063 6f6e  hsPacket& a, con
-0000a910: 7374 2052 6873 5061 636b 6574 7834 2620  st RhsPacketx4& 
-0000a920: 622c 2041 6363 5061 636b 6574 2620 632c  b, AccPacket& c,
-0000a930: 2052 6873 5061 636b 6574 2620 2f2a 746d   RhsPacket& /*tm
-0000a940: 702a 2f2c 2063 6f6e 7374 2046 6978 6564  p*/, const Fixed
-0000a950: 496e 743c 323e 2629 2063 6f6e 7374 0a20  Int<2>&) const. 
-0000a960: 207b 206d 6164 645f 6865 6c70 6572 3c32   { madd_helper<2
-0000a970: 3e28 612c 2062 2c20 6329 3b20 7d0a 2020  >(a, b, c); }.  
-0000a980: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
-0000a990: 494e 4520 766f 6964 206d 6164 6428 636f  INE void madd(co
-0000a9a0: 6e73 7420 4c68 7350 6163 6b65 7426 2061  nst LhsPacket& a
-0000a9b0: 2c20 636f 6e73 7420 5268 7350 6163 6b65  , const RhsPacke
-0000a9c0: 7478 3426 2062 2c20 4163 6350 6163 6b65  tx4& b, AccPacke
-0000a9d0: 7426 2063 2c20 5268 7350 6163 6b65 7426  t& c, RhsPacket&
-0000a9e0: 202f 2a74 6d70 2a2f 2c20 636f 6e73 7420   /*tmp*/, const 
-0000a9f0: 4669 7865 6449 6e74 3c33 3e26 2920 636f  FixedInt<3>&) co
-0000aa00: 6e73 740a 2020 7b20 6d61 6464 5f68 656c  nst.  { madd_hel
-0000aa10: 7065 723c 333e 2861 2c20 622c 2063 293b  per<3>(a, b, c);
-0000aa20: 207d 0a0a 2070 7269 7661 7465 3a0a 2020   }.. private:.  
-0000aa30: 7465 6d70 6c61 7465 203c 696e 7420 4c61  template <int La
-0000aa40: 6e65 4944 3e0a 2020 4549 4745 4e5f 5354  neID>.  EIGEN_ST
-0000aa50: 524f 4e47 5f49 4e4c 494e 4520 766f 6964  RONG_INLINE void
-0000aa60: 206d 6164 645f 6865 6c70 6572 2863 6f6e   madd_helper(con
-0000aa70: 7374 204c 6873 5061 636b 6574 2620 612c  st LhsPacket& a,
-0000aa80: 2063 6f6e 7374 2052 6873 5061 636b 6574   const RhsPacket
-0000aa90: 7834 2620 622c 2041 6363 5061 636b 6574  x4& b, AccPacket
-0000aaa0: 2620 6329 2063 6f6e 7374 0a20 207b 0a20  & c) const.  {. 
-0000aab0: 2020 2023 6966 2045 4947 454e 5f43 4f4d     #if EIGEN_COM
-0000aac0: 505f 474e 5543 5f53 5452 4943 5420 2626  P_GNUC_STRICT &&
-0000aad0: 2021 2845 4947 454e 5f47 4e55 435f 4154   !(EIGEN_GNUC_AT
-0000aae0: 5f4c 4541 5354 2839 2c30 2929 0a20 2020  _LEAST(9,0)).   
-0000aaf0: 202f 2f20 776f 726b 6172 6f75 6e64 2067   // workaround g
-0000ab00: 6363 2069 7373 7565 2068 7474 7073 3a2f  cc issue https:/
-0000ab10: 2f67 6363 2e67 6e75 2e6f 7267 2f62 7567  /gcc.gnu.org/bug
-0000ab20: 7a69 6c6c 612f 7368 6f77 5f62 7567 2e63  zilla/show_bug.c
-0000ab30: 6769 3f69 643d 3839 3130 310a 2020 2020  gi?id=89101.    
-0000ab40: 2f2f 2076 666d 6171 5f6c 616e 6571 5f66  // vfmaq_laneq_f
-0000ab50: 3634 2069 7320 696d 706c 656d 656e 7465  64 is implemente
-0000ab60: 6420 7468 726f 7567 6820 6120 636f 7374  d through a cost
-0000ab70: 6c79 2064 7570 0a20 2020 2020 2020 2020  ly dup.         
-0000ab80: 6966 284c 616e 6549 443d 3d30 2920 2061  if(LaneID==0)  a
-0000ab90: 736d 2822 666d 6c61 2025 302e 3264 2c20  sm("fmla %0.2d, 
-0000aba0: 2531 2e32 642c 2025 322e 645b 305d 5c6e  %1.2d, %2.d[0]\n
-0000abb0: 2220 3a20 222b 7722 2028 6329 203a 2022  " : "+w" (c) : "
-0000abc0: 7722 2028 6129 2c20 2277 2220 2862 2e42  w" (a), "w" (b.B
-0000abd0: 5f30 2920 3a20 2029 3b0a 2020 2020 656c  _0) :  );.    el
-0000abe0: 7365 2069 6628 4c61 6e65 4944 3d3d 3129  se if(LaneID==1)
-0000abf0: 2020 6173 6d28 2266 6d6c 6120 2530 2e32    asm("fmla %0.2
-0000ac00: 642c 2025 312e 3264 2c20 2532 2e64 5b31  d, %1.2d, %2.d[1
-0000ac10: 5d5c 6e22 203a 2022 2b77 2220 2863 2920  ]\n" : "+w" (c) 
-0000ac20: 3a20 2277 2220 2861 292c 2022 7722 2028  : "w" (a), "w" (
-0000ac30: 622e 425f 3029 203a 2020 293b 0a20 2020  b.B_0) :  );.   
-0000ac40: 2065 6c73 6520 6966 284c 616e 6549 443d   else if(LaneID=
-0000ac50: 3d32 2920 2061 736d 2822 666d 6c61 2025  =2)  asm("fmla %
-0000ac60: 302e 3264 2c20 2531 2e32 642c 2025 322e  0.2d, %1.2d, %2.
-0000ac70: 645b 305d 5c6e 2220 3a20 222b 7722 2028  d[0]\n" : "+w" (
-0000ac80: 6329 203a 2022 7722 2028 6129 2c20 2277  c) : "w" (a), "w
-0000ac90: 2220 2862 2e42 5f31 2920 3a20 2029 3b0a  " (b.B_1) :  );.
-0000aca0: 2020 2020 656c 7365 2069 6628 4c61 6e65      else if(Lane
-0000acb0: 4944 3d3d 3329 2020 6173 6d28 2266 6d6c  ID==3)  asm("fml
-0000acc0: 6120 2530 2e32 642c 2025 312e 3264 2c20  a %0.2d, %1.2d, 
-0000acd0: 2532 2e64 5b31 5d5c 6e22 203a 2022 2b77  %2.d[1]\n" : "+w
-0000ace0: 2220 2863 2920 3a20 2277 2220 2861 292c  " (c) : "w" (a),
-0000acf0: 2022 7722 2028 622e 425f 3129 203a 2020   "w" (b.B_1) :  
-0000ad00: 293b 0a20 2020 2023 656c 7365 0a20 2020  );.    #else.   
-0000ad10: 2020 2020 2020 6966 284c 616e 6549 443d        if(LaneID=
-0000ad20: 3d30 2920 6320 3d20 7666 6d61 715f 6c61  =0) c = vfmaq_la
-0000ad30: 6e65 715f 6636 3428 632c 2061 2c20 622e  neq_f64(c, a, b.
-0000ad40: 425f 302c 2030 293b 0a20 2020 2065 6c73  B_0, 0);.    els
-0000ad50: 6520 6966 284c 616e 6549 443d 3d31 2920  e if(LaneID==1) 
-0000ad60: 6320 3d20 7666 6d61 715f 6c61 6e65 715f  c = vfmaq_laneq_
-0000ad70: 6636 3428 632c 2061 2c20 622e 425f 302c  f64(c, a, b.B_0,
-0000ad80: 2031 293b 0a20 2020 2065 6c73 6520 6966   1);.    else if
-0000ad90: 284c 616e 6549 443d 3d32 2920 6320 3d20  (LaneID==2) c = 
-0000ada0: 7666 6d61 715f 6c61 6e65 715f 6636 3428  vfmaq_laneq_f64(
-0000adb0: 632c 2061 2c20 622e 425f 312c 2030 293b  c, a, b.B_1, 0);
-0000adc0: 0a20 2020 2065 6c73 6520 6966 284c 616e  .    else if(Lan
-0000add0: 6549 443d 3d33 2920 6320 3d20 7666 6d61  eID==3) c = vfma
-0000ade0: 715f 6c61 6e65 715f 6636 3428 632c 2061  q_laneq_f64(c, a
-0000adf0: 2c20 622e 425f 312c 2031 293b 0a20 2020  , b.B_1, 1);.   
-0000ae00: 2023 656e 6469 660a 2020 7d0a 7d3b 0a0a   #endif.  }.};..
-0000ae10: 2365 6e64 6966 0a0a 2f2a 206f 7074 696d  #endif../* optim
-0000ae20: 697a 6564 2047 656e 6572 616c 2070 6163  ized General pac
-0000ae30: 6b65 6420 426c 6f63 6b20 2a20 7061 636b  ked Block * pack
-0000ae40: 6564 2050 616e 656c 2070 726f 6475 6374  ed Panel product
-0000ae50: 206b 6572 6e65 6c0a 202a 0a20 2a20 4d69   kernel. *. * Mi
-0000ae60: 7869 6e67 2074 7970 6520 6c6f 6769 633a  xing type logic:
-0000ae70: 2043 202b 3d20 4120 2a20 420a 202a 2020   C += A * B. *  
-0000ae80: 7c20 2041 2020 7c20 2042 2020 7c20 636f  |  A  |  B  | co
-0000ae90: 6d6d 656e 7473 0a20 2a20 207c 7265 616c  mments. *  |real
-0000aea0: 207c 6370 6c78 207c 206e 6f20 7665 6374   |cplx | no vect
-0000aeb0: 6f72 697a 6174 696f 6e20 7965 742c 2077  orization yet, w
-0000aec0: 6f75 6c64 2072 6571 7569 7265 2074 6f20  ould require to 
-0000aed0: 7061 636b 2041 2077 6974 6820 6475 706c  pack A with dupl
-0000aee0: 6963 6174 696f 6e0a 202a 2020 7c63 706c  ication. *  |cpl
-0000aef0: 7820 7c72 6561 6c20 7c20 6561 7379 2076  x |real | easy v
-0000af00: 6563 746f 7269 7a61 7469 6f6e 0a20 2a2f  ectorization. */
-0000af10: 0a74 656d 706c 6174 653c 7479 7065 6e61  .template<typena
-0000af20: 6d65 204c 6873 5363 616c 6172 2c20 7479  me LhsScalar, ty
-0000af30: 7065 6e61 6d65 2052 6873 5363 616c 6172  pename RhsScalar
-0000af40: 2c20 7479 7065 6e61 6d65 2049 6e64 6578  , typename Index
-0000af50: 2c20 7479 7065 6e61 6d65 2044 6174 614d  , typename DataM
-0000af60: 6170 7065 722c 2069 6e74 206d 722c 2069  apper, int mr, i
-0000af70: 6e74 206e 722c 2062 6f6f 6c20 436f 6e6a  nt nr, bool Conj
-0000af80: 7567 6174 654c 6873 2c20 626f 6f6c 2043  ugateLhs, bool C
-0000af90: 6f6e 6a75 6761 7465 5268 733e 0a73 7472  onjugateRhs>.str
-0000afa0: 7563 7420 6765 6270 5f6b 6572 6e65 6c0a  uct gebp_kernel.
-0000afb0: 7b0a 2020 7479 7065 6465 6620 6765 6270  {.  typedef gebp
-0000afc0: 5f74 7261 6974 733c 4c68 7353 6361 6c61  _traits<LhsScala
-0000afd0: 722c 5268 7353 6361 6c61 722c 436f 6e6a  r,RhsScalar,Conj
-0000afe0: 7567 6174 654c 6873 2c43 6f6e 6a75 6761  ugateLhs,Conjuga
-0000aff0: 7465 5268 732c 4172 6368 6974 6563 7475  teRhs,Architectu
-0000b000: 7265 3a3a 5461 7267 6574 3e20 5472 6169  re::Target> Trai
-0000b010: 7473 3b0a 2020 7479 7065 6465 6620 6765  ts;.  typedef ge
-0000b020: 6270 5f74 7261 6974 733c 4c68 7353 6361  bp_traits<LhsSca
-0000b030: 6c61 722c 5268 7353 6361 6c61 722c 436f  lar,RhsScalar,Co
-0000b040: 6e6a 7567 6174 654c 6873 2c43 6f6e 6a75  njugateLhs,Conju
-0000b050: 6761 7465 5268 732c 4172 6368 6974 6563  gateRhs,Architec
-0000b060: 7475 7265 3a3a 5461 7267 6574 2c47 4542  ture::Target,GEB
-0000b070: 5050 6163 6b65 7448 616c 663e 2048 616c  PPacketHalf> Hal
-0000b080: 6654 7261 6974 733b 0a20 2074 7970 6564  fTraits;.  typed
-0000b090: 6566 2067 6562 705f 7472 6169 7473 3c4c  ef gebp_traits<L
-0000b0a0: 6873 5363 616c 6172 2c52 6873 5363 616c  hsScalar,RhsScal
-0000b0b0: 6172 2c43 6f6e 6a75 6761 7465 4c68 732c  ar,ConjugateLhs,
-0000b0c0: 436f 6e6a 7567 6174 6552 6873 2c41 7263  ConjugateRhs,Arc
-0000b0d0: 6869 7465 6374 7572 653a 3a54 6172 6765  hitecture::Targe
-0000b0e0: 742c 4745 4250 5061 636b 6574 5175 6172  t,GEBPPacketQuar
-0000b0f0: 7465 723e 2051 7561 7274 6572 5472 6169  ter> QuarterTrai
-0000b100: 7473 3b0a 2020 0a20 2074 7970 6564 6566  ts;.  .  typedef
-0000b110: 2074 7970 656e 616d 6520 5472 6169 7473   typename Traits
-0000b120: 3a3a 5265 7353 6361 6c61 7220 5265 7353  ::ResScalar ResS
-0000b130: 6361 6c61 723b 0a20 2074 7970 6564 6566  calar;.  typedef
-0000b140: 2074 7970 656e 616d 6520 5472 6169 7473   typename Traits
-0000b150: 3a3a 4c68 7350 6163 6b65 7420 4c68 7350  ::LhsPacket LhsP
-0000b160: 6163 6b65 743b 0a20 2074 7970 6564 6566  acket;.  typedef
-0000b170: 2074 7970 656e 616d 6520 5472 6169 7473   typename Traits
-0000b180: 3a3a 5268 7350 6163 6b65 7420 5268 7350  ::RhsPacket RhsP
-0000b190: 6163 6b65 743b 0a20 2074 7970 6564 6566  acket;.  typedef
-0000b1a0: 2074 7970 656e 616d 6520 5472 6169 7473   typename Traits
-0000b1b0: 3a3a 5265 7350 6163 6b65 7420 5265 7350  ::ResPacket ResP
-0000b1c0: 6163 6b65 743b 0a20 2074 7970 6564 6566  acket;.  typedef
-0000b1d0: 2074 7970 656e 616d 6520 5472 6169 7473   typename Traits
-0000b1e0: 3a3a 4163 6350 6163 6b65 7420 4163 6350  ::AccPacket AccP
-0000b1f0: 6163 6b65 743b 0a20 2074 7970 6564 6566  acket;.  typedef
-0000b200: 2074 7970 656e 616d 6520 5472 6169 7473   typename Traits
-0000b210: 3a3a 5268 7350 6163 6b65 7478 3420 5268  ::RhsPacketx4 Rh
-0000b220: 7350 6163 6b65 7478 343b 0a0a 2020 7479  sPacketx4;..  ty
-0000b230: 7065 6465 6620 7479 7065 6e61 6d65 2052  pedef typename R
-0000b240: 6873 5061 6e65 6c48 656c 7065 723c 5268  hsPanelHelper<Rh
-0000b250: 7350 6163 6b65 742c 2052 6873 5061 636b  sPacket, RhsPack
-0000b260: 6574 7834 2c20 3135 3e3a 3a74 7970 6520  etx4, 15>::type 
-0000b270: 5268 7350 616e 656c 3135 3b0a 0a20 2074  RhsPanel15;..  t
-0000b280: 7970 6564 6566 2067 6562 705f 7472 6169  ypedef gebp_trai
-0000b290: 7473 3c52 6873 5363 616c 6172 2c4c 6873  ts<RhsScalar,Lhs
-0000b2a0: 5363 616c 6172 2c43 6f6e 6a75 6761 7465  Scalar,Conjugate
-0000b2b0: 5268 732c 436f 6e6a 7567 6174 654c 6873  Rhs,ConjugateLhs
-0000b2c0: 2c41 7263 6869 7465 6374 7572 653a 3a54  ,Architecture::T
-0000b2d0: 6172 6765 743e 2053 7761 7070 6564 5472  arget> SwappedTr
-0000b2e0: 6169 7473 3b0a 0a20 2074 7970 6564 6566  aits;..  typedef
-0000b2f0: 2074 7970 656e 616d 6520 5377 6170 7065   typename Swappe
-0000b300: 6454 7261 6974 733a 3a52 6573 5363 616c  dTraits::ResScal
-0000b310: 6172 2053 5265 7353 6361 6c61 723b 0a20  ar SResScalar;. 
-0000b320: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
-0000b330: 6520 5377 6170 7065 6454 7261 6974 733a  e SwappedTraits:
-0000b340: 3a4c 6873 5061 636b 6574 2053 4c68 7350  :LhsPacket SLhsP
-0000b350: 6163 6b65 743b 0a20 2074 7970 6564 6566  acket;.  typedef
-0000b360: 2074 7970 656e 616d 6520 5377 6170 7065   typename Swappe
-0000b370: 6454 7261 6974 733a 3a52 6873 5061 636b  dTraits::RhsPack
-0000b380: 6574 2053 5268 7350 6163 6b65 743b 0a20  et SRhsPacket;. 
-0000b390: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
-0000b3a0: 6520 5377 6170 7065 6454 7261 6974 733a  e SwappedTraits:
-0000b3b0: 3a52 6573 5061 636b 6574 2053 5265 7350  :ResPacket SResP
-0000b3c0: 6163 6b65 743b 0a20 2074 7970 6564 6566  acket;.  typedef
-0000b3d0: 2074 7970 656e 616d 6520 5377 6170 7065   typename Swappe
-0000b3e0: 6454 7261 6974 733a 3a41 6363 5061 636b  dTraits::AccPack
-0000b3f0: 6574 2053 4163 6350 6163 6b65 743b 0a0a  et SAccPacket;..
-0000b400: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
-0000b410: 6d65 2048 616c 6654 7261 6974 733a 3a4c  me HalfTraits::L
-0000b420: 6873 5061 636b 6574 204c 6873 5061 636b  hsPacket LhsPack
-0000b430: 6574 4861 6c66 3b0a 2020 7479 7065 6465  etHalf;.  typede
-0000b440: 6620 7479 7065 6e61 6d65 2048 616c 6654  f typename HalfT
-0000b450: 7261 6974 733a 3a52 6873 5061 636b 6574  raits::RhsPacket
-0000b460: 2052 6873 5061 636b 6574 4861 6c66 3b0a   RhsPacketHalf;.
-0000b470: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
-0000b480: 6d65 2048 616c 6654 7261 6974 733a 3a52  me HalfTraits::R
-0000b490: 6573 5061 636b 6574 2052 6573 5061 636b  esPacket ResPack
-0000b4a0: 6574 4861 6c66 3b0a 2020 7479 7065 6465  etHalf;.  typede
-0000b4b0: 6620 7479 7065 6e61 6d65 2048 616c 6654  f typename HalfT
-0000b4c0: 7261 6974 733a 3a41 6363 5061 636b 6574  raits::AccPacket
-0000b4d0: 2041 6363 5061 636b 6574 4861 6c66 3b0a   AccPacketHalf;.
-0000b4e0: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
-0000b4f0: 616d 6520 5175 6172 7465 7254 7261 6974  ame QuarterTrait
-0000b500: 733a 3a4c 6873 5061 636b 6574 204c 6873  s::LhsPacket Lhs
-0000b510: 5061 636b 6574 5175 6172 7465 723b 0a20  PacketQuarter;. 
-0000b520: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
-0000b530: 6520 5175 6172 7465 7254 7261 6974 733a  e QuarterTraits:
-0000b540: 3a52 6873 5061 636b 6574 2052 6873 5061  :RhsPacket RhsPa
-0000b550: 636b 6574 5175 6172 7465 723b 0a20 2074  cketQuarter;.  t
-0000b560: 7970 6564 6566 2074 7970 656e 616d 6520  ypedef typename 
-0000b570: 5175 6172 7465 7254 7261 6974 733a 3a52  QuarterTraits::R
-0000b580: 6573 5061 636b 6574 2052 6573 5061 636b  esPacket ResPack
-0000b590: 6574 5175 6172 7465 723b 0a20 2074 7970  etQuarter;.  typ
-0000b5a0: 6564 6566 2074 7970 656e 616d 6520 5175  edef typename Qu
-0000b5b0: 6172 7465 7254 7261 6974 733a 3a41 6363  arterTraits::Acc
-0000b5c0: 5061 636b 6574 2041 6363 5061 636b 6574  Packet AccPacket
-0000b5d0: 5175 6172 7465 723b 0a0a 2020 7479 7065  Quarter;..  type
-0000b5e0: 6465 6620 7479 7065 6e61 6d65 2044 6174  def typename Dat
-0000b5f0: 614d 6170 7065 723a 3a4c 696e 6561 724d  aMapper::LinearM
-0000b600: 6170 7065 7220 4c69 6e65 6172 4d61 7070  apper LinearMapp
-0000b610: 6572 3b0a 0a20 2065 6e75 6d20 7b0a 2020  er;..  enum {.  
-0000b620: 2020 5665 6374 6f72 697a 6162 6c65 2020    Vectorizable  
-0000b630: 3d20 5472 6169 7473 3a3a 5665 6374 6f72  = Traits::Vector
-0000b640: 697a 6162 6c65 2c0a 2020 2020 4c68 7350  izable,.    LhsP
-0000b650: 726f 6772 6573 7320 2020 3d20 5472 6169  rogress   = Trai
-0000b660: 7473 3a3a 4c68 7350 726f 6772 6573 732c  ts::LhsProgress,
-0000b670: 0a20 2020 204c 6873 5072 6f67 7265 7373  .    LhsProgress
-0000b680: 4861 6c66 2020 2020 2020 3d20 4861 6c66  Half      = Half
-0000b690: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
-0000b6a0: 6573 732c 0a20 2020 204c 6873 5072 6f67  ess,.    LhsProg
-0000b6b0: 7265 7373 5175 6172 7465 7220 2020 3d20  ressQuarter   = 
-0000b6c0: 5175 6172 7465 7254 7261 6974 733a 3a4c  QuarterTraits::L
-0000b6d0: 6873 5072 6f67 7265 7373 2c0a 2020 2020  hsProgress,.    
-0000b6e0: 5268 7350 726f 6772 6573 7320 2020 3d20  RhsProgress   = 
-0000b6f0: 5472 6169 7473 3a3a 5268 7350 726f 6772  Traits::RhsProgr
-0000b700: 6573 732c 0a20 2020 2052 6873 5072 6f67  ess,.    RhsProg
-0000b710: 7265 7373 4861 6c66 2020 2020 2020 3d20  ressHalf      = 
-0000b720: 4861 6c66 5472 6169 7473 3a3a 5268 7350  HalfTraits::RhsP
-0000b730: 726f 6772 6573 732c 0a20 2020 2052 6873  rogress,.    Rhs
-0000b740: 5072 6f67 7265 7373 5175 6172 7465 7220  ProgressQuarter 
-0000b750: 2020 3d20 5175 6172 7465 7254 7261 6974    = QuarterTrait
-0000b760: 733a 3a52 6873 5072 6f67 7265 7373 2c0a  s::RhsProgress,.
-0000b770: 2020 2020 5265 7350 6163 6b65 7453 697a      ResPacketSiz
-0000b780: 6520 3d20 5472 6169 7473 3a3a 5265 7350  e = Traits::ResP
-0000b790: 6163 6b65 7453 697a 650a 2020 7d3b 0a0a  acketSize.  };..
-0000b7a0: 2020 4549 4745 4e5f 444f 4e54 5f49 4e4c    EIGEN_DONT_INL
-0000b7b0: 494e 450a 2020 766f 6964 206f 7065 7261  INE.  void opera
-0000b7c0: 746f 7228 2928 636f 6e73 7420 4461 7461  tor()(const Data
-0000b7d0: 4d61 7070 6572 2620 7265 732c 2063 6f6e  Mapper& res, con
-0000b7e0: 7374 204c 6873 5363 616c 6172 2a20 626c  st LhsScalar* bl
-0000b7f0: 6f63 6b41 2c20 636f 6e73 7420 5268 7353  ockA, const RhsS
-0000b800: 6361 6c61 722a 2062 6c6f 636b 422c 0a20  calar* blockB,. 
-0000b810: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000b820: 2049 6e64 6578 2072 6f77 732c 2049 6e64   Index rows, Ind
-0000b830: 6578 2064 6570 7468 2c20 496e 6465 7820  ex depth, Index 
-0000b840: 636f 6c73 2c20 5265 7353 6361 6c61 7220  cols, ResScalar 
-0000b850: 616c 7068 612c 0a20 2020 2020 2020 2020  alpha,.         
-0000b860: 2020 2020 2020 2020 2049 6e64 6578 2073           Index s
-0000b870: 7472 6964 6541 3d2d 312c 2049 6e64 6578  trideA=-1, Index
-0000b880: 2073 7472 6964 6542 3d2d 312c 2049 6e64   strideB=-1, Ind
-0000b890: 6578 206f 6666 7365 7441 3d30 2c20 496e  ex offsetA=0, In
-0000b8a0: 6465 7820 6f66 6673 6574 423d 3029 3b0a  dex offsetB=0);.
-0000b8b0: 7d3b 0a0a 7465 6d70 6c61 7465 3c74 7970  };..template<typ
-0000b8c0: 656e 616d 6520 4c68 7353 6361 6c61 722c  ename LhsScalar,
-0000b8d0: 2074 7970 656e 616d 6520 5268 7353 6361   typename RhsSca
-0000b8e0: 6c61 722c 2074 7970 656e 616d 6520 496e  lar, typename In
-0000b8f0: 6465 782c 2074 7970 656e 616d 6520 4461  dex, typename Da
-0000b900: 7461 4d61 7070 6572 2c20 696e 7420 6d72  taMapper, int mr
-0000b910: 2c20 696e 7420 6e72 2c20 626f 6f6c 2043  , int nr, bool C
-0000b920: 6f6e 6a75 6761 7465 4c68 732c 2062 6f6f  onjugateLhs, boo
-0000b930: 6c20 436f 6e6a 7567 6174 6552 6873 2c0a  l ConjugateRhs,.
-0000b940: 696e 7420 5377 6170 7065 644c 6873 5072  int SwappedLhsPr
-0000b950: 6f67 7265 7373 203d 2067 6562 705f 7472  ogress = gebp_tr
-0000b960: 6169 7473 3c52 6873 5363 616c 6172 2c4c  aits<RhsScalar,L
-0000b970: 6873 5363 616c 6172 2c43 6f6e 6a75 6761  hsScalar,Conjuga
-0000b980: 7465 5268 732c 436f 6e6a 7567 6174 654c  teRhs,ConjugateL
-0000b990: 6873 2c41 7263 6869 7465 6374 7572 653a  hs,Architecture:
-0000b9a0: 3a54 6172 6765 743e 3a3a 4c68 7350 726f  :Target>::LhsPro
-0000b9b0: 6772 6573 733e 0a73 7472 7563 7420 6c61  gress>.struct la
-0000b9c0: 7374 5f72 6f77 5f70 726f 6365 7373 5f31  st_row_process_1
-0000b9d0: 365f 7061 636b 6574 730a 7b0a 2020 7479  6_packets.{.  ty
-0000b9e0: 7065 6465 6620 6765 6270 5f74 7261 6974  pedef gebp_trait
-0000b9f0: 733c 4c68 7353 6361 6c61 722c 5268 7353  s<LhsScalar,RhsS
-0000ba00: 6361 6c61 722c 436f 6e6a 7567 6174 654c  calar,ConjugateL
-0000ba10: 6873 2c43 6f6e 6a75 6761 7465 5268 732c  hs,ConjugateRhs,
-0000ba20: 4172 6368 6974 6563 7475 7265 3a3a 5461  Architecture::Ta
-0000ba30: 7267 6574 3e20 5472 6169 7473 3b0a 2020  rget> Traits;.  
-0000ba40: 7479 7065 6465 6620 6765 6270 5f74 7261  typedef gebp_tra
-0000ba50: 6974 733c 5268 7353 6361 6c61 722c 4c68  its<RhsScalar,Lh
-0000ba60: 7353 6361 6c61 722c 436f 6e6a 7567 6174  sScalar,Conjugat
-0000ba70: 6552 6873 2c43 6f6e 6a75 6761 7465 4c68  eRhs,ConjugateLh
-0000ba80: 732c 4172 6368 6974 6563 7475 7265 3a3a  s,Architecture::
-0000ba90: 5461 7267 6574 3e20 5377 6170 7065 6454  Target> SwappedT
-0000baa0: 7261 6974 733b 0a0a 2020 7479 7065 6465  raits;..  typede
-0000bab0: 6620 7479 7065 6e61 6d65 2054 7261 6974  f typename Trait
-0000bac0: 733a 3a52 6573 5363 616c 6172 2052 6573  s::ResScalar Res
-0000bad0: 5363 616c 6172 3b0a 2020 7479 7065 6465  Scalar;.  typede
-0000bae0: 6620 7479 7065 6e61 6d65 2053 7761 7070  f typename Swapp
-0000baf0: 6564 5472 6169 7473 3a3a 4c68 7350 6163  edTraits::LhsPac
-0000bb00: 6b65 7420 534c 6873 5061 636b 6574 3b0a  ket SLhsPacket;.
-0000bb10: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
-0000bb20: 6d65 2053 7761 7070 6564 5472 6169 7473  me SwappedTraits
-0000bb30: 3a3a 5268 7350 6163 6b65 7420 5352 6873  ::RhsPacket SRhs
-0000bb40: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
-0000bb50: 6620 7479 7065 6e61 6d65 2053 7761 7070  f typename Swapp
-0000bb60: 6564 5472 6169 7473 3a3a 5265 7350 6163  edTraits::ResPac
-0000bb70: 6b65 7420 5352 6573 5061 636b 6574 3b0a  ket SResPacket;.
-0000bb80: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
-0000bb90: 6d65 2053 7761 7070 6564 5472 6169 7473  me SwappedTraits
-0000bba0: 3a3a 4163 6350 6163 6b65 7420 5341 6363  ::AccPacket SAcc
-0000bbb0: 5061 636b 6574 3b0a 0a20 2045 4947 454e  Packet;..  EIGEN
-0000bbc0: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
-0000bbd0: 6f69 6420 6f70 6572 6174 6f72 2829 2863  oid operator()(c
-0000bbe0: 6f6e 7374 2044 6174 614d 6170 7065 7226  onst DataMapper&
-0000bbf0: 2072 6573 2c20 5377 6170 7065 6454 7261   res, SwappedTra
-0000bc00: 6974 7320 2673 7472 6169 7473 2c20 636f  its &straits, co
-0000bc10: 6e73 7420 4c68 7353 6361 6c61 722a 2062  nst LhsScalar* b
-0000bc20: 6c41 2c0a 2020 2020 2020 2020 2020 2020  lA,.            
-0000bc30: 2020 2020 2020 636f 6e73 7420 5268 7353        const RhsS
-0000bc40: 6361 6c61 722a 2062 6c42 2c20 496e 6465  calar* blB, Inde
-0000bc50: 7820 6465 7074 682c 2063 6f6e 7374 2049  x depth, const I
-0000bc60: 6e64 6578 2065 6e64 6b2c 2049 6e64 6578  ndex endk, Index
-0000bc70: 2069 2c20 496e 6465 7820 6a32 2c0a 2020   i, Index j2,.  
-0000bc80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000bc90: 5265 7353 6361 6c61 7220 616c 7068 612c  ResScalar alpha,
-0000bca0: 2053 4163 6350 6163 6b65 7420 2643 3029   SAccPacket &C0)
-0000bcb0: 0a20 2020 207b 0a20 2020 2020 2045 4947  .    {.      EIG
-0000bcc0: 454e 5f55 4e55 5345 445f 5641 5249 4142  EN_UNUSED_VARIAB
-0000bcd0: 4c45 2872 6573 293b 0a20 2020 2020 2045  LE(res);.      E
-0000bce0: 4947 454e 5f55 4e55 5345 445f 5641 5249  IGEN_UNUSED_VARI
-0000bcf0: 4142 4c45 2873 7472 6169 7473 293b 0a20  ABLE(straits);. 
-0000bd00: 2020 2020 2045 4947 454e 5f55 4e55 5345       EIGEN_UNUSE
-0000bd10: 445f 5641 5249 4142 4c45 2862 6c41 293b  D_VARIABLE(blA);
-0000bd20: 0a20 2020 2020 2045 4947 454e 5f55 4e55  .      EIGEN_UNU
-0000bd30: 5345 445f 5641 5249 4142 4c45 2862 6c42  SED_VARIABLE(blB
-0000bd40: 293b 0a20 2020 2020 2045 4947 454e 5f55  );.      EIGEN_U
-0000bd50: 4e55 5345 445f 5641 5249 4142 4c45 2864  NUSED_VARIABLE(d
-0000bd60: 6570 7468 293b 0a20 2020 2020 2045 4947  epth);.      EIG
-0000bd70: 454e 5f55 4e55 5345 445f 5641 5249 4142  EN_UNUSED_VARIAB
-0000bd80: 4c45 2865 6e64 6b29 3b0a 2020 2020 2020  LE(endk);.      
-0000bd90: 4549 4745 4e5f 554e 5553 4544 5f56 4152  EIGEN_UNUSED_VAR
-0000bda0: 4941 424c 4528 6929 3b0a 2020 2020 2020  IABLE(i);.      
-0000bdb0: 4549 4745 4e5f 554e 5553 4544 5f56 4152  EIGEN_UNUSED_VAR
-0000bdc0: 4941 424c 4528 6a32 293b 0a20 2020 2020  IABLE(j2);.     
-0000bdd0: 2045 4947 454e 5f55 4e55 5345 445f 5641   EIGEN_UNUSED_VA
-0000bde0: 5249 4142 4c45 2861 6c70 6861 293b 0a20  RIABLE(alpha);. 
-0000bdf0: 2020 2020 2045 4947 454e 5f55 4e55 5345       EIGEN_UNUSE
-0000be00: 445f 5641 5249 4142 4c45 2843 3029 3b0a  D_VARIABLE(C0);.
-0000be10: 2020 2020 7d0a 7d3b 0a0a 0a74 656d 706c      }.};...templ
-0000be20: 6174 653c 7479 7065 6e61 6d65 204c 6873  ate<typename Lhs
-0000be30: 5363 616c 6172 2c20 7479 7065 6e61 6d65  Scalar, typename
-0000be40: 2052 6873 5363 616c 6172 2c20 7479 7065   RhsScalar, type
-0000be50: 6e61 6d65 2049 6e64 6578 2c20 7479 7065  name Index, type
-0000be60: 6e61 6d65 2044 6174 614d 6170 7065 722c  name DataMapper,
-0000be70: 2069 6e74 206d 722c 2069 6e74 206e 722c   int mr, int nr,
-0000be80: 2062 6f6f 6c20 436f 6e6a 7567 6174 654c   bool ConjugateL
-0000be90: 6873 2c20 626f 6f6c 2043 6f6e 6a75 6761  hs, bool Conjuga
-0000bea0: 7465 5268 733e 0a73 7472 7563 7420 6c61  teRhs>.struct la
-0000beb0: 7374 5f72 6f77 5f70 726f 6365 7373 5f31  st_row_process_1
-0000bec0: 365f 7061 636b 6574 733c 4c68 7353 6361  6_packets<LhsSca
-0000bed0: 6c61 722c 2052 6873 5363 616c 6172 2c20  lar, RhsScalar, 
-0000bee0: 496e 6465 782c 2044 6174 614d 6170 7065  Index, DataMappe
-0000bef0: 722c 2020 6d72 2c20 206e 722c 2043 6f6e  r,  mr,  nr, Con
-0000bf00: 6a75 6761 7465 4c68 732c 2020 436f 6e6a  jugateLhs,  Conj
-0000bf10: 7567 6174 6552 6873 2c20 3136 3e20 7b0a  ugateRhs, 16> {.
-0000bf20: 2020 7479 7065 6465 6620 6765 6270 5f74    typedef gebp_t
-0000bf30: 7261 6974 733c 4c68 7353 6361 6c61 722c  raits<LhsScalar,
-0000bf40: 5268 7353 6361 6c61 722c 436f 6e6a 7567  RhsScalar,Conjug
-0000bf50: 6174 654c 6873 2c43 6f6e 6a75 6761 7465  ateLhs,Conjugate
-0000bf60: 5268 732c 4172 6368 6974 6563 7475 7265  Rhs,Architecture
-0000bf70: 3a3a 5461 7267 6574 3e20 5472 6169 7473  ::Target> Traits
-0000bf80: 3b0a 2020 7479 7065 6465 6620 6765 6270  ;.  typedef gebp
-0000bf90: 5f74 7261 6974 733c 5268 7353 6361 6c61  _traits<RhsScala
-0000bfa0: 722c 4c68 7353 6361 6c61 722c 436f 6e6a  r,LhsScalar,Conj
-0000bfb0: 7567 6174 6552 6873 2c43 6f6e 6a75 6761  ugateRhs,Conjuga
-0000bfc0: 7465 4c68 732c 4172 6368 6974 6563 7475  teLhs,Architectu
-0000bfd0: 7265 3a3a 5461 7267 6574 3e20 5377 6170  re::Target> Swap
-0000bfe0: 7065 6454 7261 6974 733b 0a0a 2020 7479  pedTraits;..  ty
-0000bff0: 7065 6465 6620 7479 7065 6e61 6d65 2054  pedef typename T
-0000c000: 7261 6974 733a 3a52 6573 5363 616c 6172  raits::ResScalar
-0000c010: 2052 6573 5363 616c 6172 3b0a 2020 7479   ResScalar;.  ty
-0000c020: 7065 6465 6620 7479 7065 6e61 6d65 2053  pedef typename S
-0000c030: 7761 7070 6564 5472 6169 7473 3a3a 4c68  wappedTraits::Lh
-0000c040: 7350 6163 6b65 7420 534c 6873 5061 636b  sPacket SLhsPack
-0000c050: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
-0000c060: 7065 6e61 6d65 2053 7761 7070 6564 5472  pename SwappedTr
-0000c070: 6169 7473 3a3a 5268 7350 6163 6b65 7420  aits::RhsPacket 
-0000c080: 5352 6873 5061 636b 6574 3b0a 2020 7479  SRhsPacket;.  ty
-0000c090: 7065 6465 6620 7479 7065 6e61 6d65 2053  pedef typename S
-0000c0a0: 7761 7070 6564 5472 6169 7473 3a3a 5265  wappedTraits::Re
-0000c0b0: 7350 6163 6b65 7420 5352 6573 5061 636b  sPacket SResPack
-0000c0c0: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
-0000c0d0: 7065 6e61 6d65 2053 7761 7070 6564 5472  pename SwappedTr
-0000c0e0: 6169 7473 3a3a 4163 6350 6163 6b65 7420  aits::AccPacket 
-0000c0f0: 5341 6363 5061 636b 6574 3b0a 0a20 2045  SAccPacket;..  E
-0000c100: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
-0000c110: 4e45 2076 6f69 6420 6f70 6572 6174 6f72  NE void operator
-0000c120: 2829 2863 6f6e 7374 2044 6174 614d 6170  ()(const DataMap
-0000c130: 7065 7226 2072 6573 2c20 5377 6170 7065  per& res, Swappe
-0000c140: 6454 7261 6974 7320 2673 7472 6169 7473  dTraits &straits
-0000c150: 2c20 636f 6e73 7420 4c68 7353 6361 6c61  , const LhsScala
-0000c160: 722a 2062 6c41 2c0a 2020 2020 2020 2020  r* blA,.        
-0000c170: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
-0000c180: 5268 7353 6361 6c61 722a 2062 6c42 2c20  RhsScalar* blB, 
-0000c190: 496e 6465 7820 6465 7074 682c 2063 6f6e  Index depth, con
-0000c1a0: 7374 2049 6e64 6578 2065 6e64 6b2c 2049  st Index endk, I
-0000c1b0: 6e64 6578 2069 2c20 496e 6465 7820 6a32  ndex i, Index j2
-0000c1c0: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
-0000c1d0: 2020 2020 5265 7353 6361 6c61 7220 616c      ResScalar al
-0000c1e0: 7068 612c 2053 4163 6350 6163 6b65 7420  pha, SAccPacket 
-0000c1f0: 2643 3029 0a20 207b 0a20 2020 2074 7970  &C0).  {.    typ
-0000c200: 6564 6566 2074 7970 656e 616d 6520 756e  edef typename un
-0000c210: 7061 636b 6574 5f74 7261 6974 733c 7479  packet_traits<ty
-0000c220: 7065 6e61 6d65 2075 6e70 6163 6b65 745f  pename unpacket_
-0000c230: 7472 6169 7473 3c53 5265 7350 6163 6b65  traits<SResPacke
-0000c240: 743e 3a3a 6861 6c66 3e3a 3a68 616c 6620  t>::half>::half 
-0000c250: 5352 6573 5061 636b 6574 5175 6172 7465  SResPacketQuarte
-0000c260: 723b 0a20 2020 2074 7970 6564 6566 2074  r;.    typedef t
-0000c270: 7970 656e 616d 6520 756e 7061 636b 6574  ypename unpacket
-0000c280: 5f74 7261 6974 733c 7479 7065 6e61 6d65  _traits<typename
-0000c290: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
-0000c2a0: 3c53 4c68 7350 6163 6b65 743e 3a3a 6861  <SLhsPacket>::ha
-0000c2b0: 6c66 3e3a 3a68 616c 6620 534c 6873 5061  lf>::half SLhsPa
-0000c2c0: 636b 6574 5175 6172 7465 723b 0a20 2020  cketQuarter;.   
-0000c2d0: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
-0000c2e0: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
-0000c2f0: 733c 7479 7065 6e61 6d65 2075 6e70 6163  s<typename unpac
-0000c300: 6b65 745f 7472 6169 7473 3c53 5268 7350  ket_traits<SRhsP
-0000c310: 6163 6b65 743e 3a3a 6861 6c66 3e3a 3a68  acket>::half>::h
-0000c320: 616c 6620 5352 6873 5061 636b 6574 5175  alf SRhsPacketQu
-0000c330: 6172 7465 723b 0a20 2020 2074 7970 6564  arter;.    typed
-0000c340: 6566 2074 7970 656e 616d 6520 756e 7061  ef typename unpa
-0000c350: 636b 6574 5f74 7261 6974 733c 7479 7065  cket_traits<type
-0000c360: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
-0000c370: 6169 7473 3c53 4163 6350 6163 6b65 743e  aits<SAccPacket>
-0000c380: 3a3a 6861 6c66 3e3a 3a68 616c 6620 5341  ::half>::half SA
-0000c390: 6363 5061 636b 6574 5175 6172 7465 723b  ccPacketQuarter;
-0000c3a0: 0a0a 2020 2020 5352 6573 5061 636b 6574  ..    SResPacket
-0000c3b0: 5175 6172 7465 7220 5220 3d20 7265 732e  Quarter R = res.
-0000c3c0: 7465 6d70 6c61 7465 2067 6174 6865 7250  template gatherP
-0000c3d0: 6163 6b65 743c 5352 6573 5061 636b 6574  acket<SResPacket
-0000c3e0: 5175 6172 7465 723e 2869 2c20 6a32 293b  Quarter>(i, j2);
-0000c3f0: 0a20 2020 2053 5265 7350 6163 6b65 7451  .    SResPacketQ
-0000c400: 7561 7274 6572 2061 6c70 6861 7620 3d20  uarter alphav = 
-0000c410: 7073 6574 313c 5352 6573 5061 636b 6574  pset1<SResPacket
-0000c420: 5175 6172 7465 723e 2861 6c70 6861 293b  Quarter>(alpha);
-0000c430: 0a0a 2020 2020 6966 2028 6465 7074 6820  ..    if (depth 
-0000c440: 2d20 656e 646b 203e 2030 290a 2020 2020  - endk > 0).    
-0000c450: 2020 7b0a 092f 2f20 5765 2068 6176 6520    {..// We have 
-0000c460: 746f 2068 616e 646c 6520 7468 6520 6c61  to handle the la
-0000c470: 7374 2072 6f77 2873 2920 6f66 2074 6865  st row(s) of the
-0000c480: 2072 6873 2c20 7768 6963 680a 092f 2f20   rhs, which..// 
-0000c490: 636f 7272 6573 706f 6e64 2074 6f20 6120  correspond to a 
-0000c4a0: 6861 6c66 2d70 6163 6b65 740a 0953 4163  half-packet..SAc
-0000c4b0: 6350 6163 6b65 7451 7561 7274 6572 2063  cPacketQuarter c
-0000c4c0: 3020 3d20 7072 6564 7578 5f68 616c 665f  0 = predux_half_
-0000c4d0: 646f 7774 6f34 2870 7265 6475 785f 6861  dowto4(predux_ha
-0000c4e0: 6c66 5f64 6f77 746f 3428 4330 2929 3b0a  lf_dowto4(C0));.
-0000c4f0: 0a09 666f 7220 2849 6e64 6578 206b 6b20  ..for (Index kk 
-0000c500: 3d20 656e 646b 3b20 6b6b 203c 2064 6570  = endk; kk < dep
-0000c510: 7468 3b20 6b6b 2b2b 290a 0920 207b 0a09  th; kk++)..  {..
-0000c520: 2020 2020 534c 6873 5061 636b 6574 5175      SLhsPacketQu
-0000c530: 6172 7465 7220 6130 3b0a 0920 2020 2053  arter a0;..    S
-0000c540: 5268 7350 6163 6b65 7451 7561 7274 6572  RhsPacketQuarter
-0000c550: 2062 303b 0a09 2020 2020 7374 7261 6974   b0;..    strait
-0000c560: 732e 6c6f 6164 4c68 7355 6e61 6c69 676e  s.loadLhsUnalign
-0000c570: 6564 2862 6c42 2c20 6130 293b 0a09 2020  ed(blB, a0);..  
-0000c580: 2020 7374 7261 6974 732e 6c6f 6164 5268    straits.loadRh
-0000c590: 7328 626c 412c 2062 3029 3b0a 0920 2020  s(blA, b0);..   
-0000c5a0: 2073 7472 6169 7473 2e6d 6164 6428 6130   straits.madd(a0
-0000c5b0: 2c62 302c 6330 2c62 302c 2066 6978 3c30  ,b0,c0,b0, fix<0
-0000c5c0: 3e29 3b0a 0920 2020 2062 6c42 202b 3d20  >);..    blB += 
-0000c5d0: 5377 6170 7065 6454 7261 6974 733a 3a4c  SwappedTraits::L
-0000c5e0: 6873 5072 6f67 7265 7373 2f34 3b0a 0920  hsProgress/4;.. 
-0000c5f0: 2020 2062 6c41 202b 3d20 313b 0a09 2020     blA += 1;..  
-0000c600: 7d0a 0973 7472 6169 7473 2e61 6363 2863  }..straits.acc(c
-0000c610: 302c 2061 6c70 6861 762c 2052 293b 0a20  0, alphav, R);. 
-0000c620: 2020 2020 207d 0a20 2020 2065 6c73 650a       }.    else.
-0000c630: 2020 2020 2020 7b0a 0973 7472 6169 7473        {..straits
-0000c640: 2e61 6363 2870 7265 6475 785f 6861 6c66  .acc(predux_half
-0000c650: 5f64 6f77 746f 3428 7072 6564 7578 5f68  _dowto4(predux_h
-0000c660: 616c 665f 646f 7774 6f34 2843 3029 292c  alf_dowto4(C0)),
-0000c670: 2061 6c70 6861 762c 2052 293b 0a20 2020   alphav, R);.   
-0000c680: 2020 207d 0a20 2020 2072 6573 2e73 6361     }.    res.sca
-0000c690: 7474 6572 5061 636b 6574 2869 2c20 6a32  tterPacket(i, j2
-0000c6a0: 2c20 5229 3b0a 2020 7d0a 7d3b 0a0a 7465  , R);.  }.};..te
-0000c6b0: 6d70 6c61 7465 3c69 6e74 206e 722c 2049  mplate<int nr, I
-0000c6c0: 6e64 6578 204c 6873 5072 6f67 7265 7373  ndex LhsProgress
-0000c6d0: 2c20 496e 6465 7820 5268 7350 726f 6772  , Index RhsProgr
-0000c6e0: 6573 732c 2074 7970 656e 616d 6520 4c68  ess, typename Lh
-0000c6f0: 7353 6361 6c61 722c 2074 7970 656e 616d  sScalar, typenam
-0000c700: 6520 5268 7353 6361 6c61 722c 2074 7970  e RhsScalar, typ
-0000c710: 656e 616d 6520 5265 7353 6361 6c61 722c  ename ResScalar,
-0000c720: 2074 7970 656e 616d 6520 4163 6350 6163   typename AccPac
-0000c730: 6b65 742c 2074 7970 656e 616d 6520 4c68  ket, typename Lh
-0000c740: 7350 6163 6b65 742c 2074 7970 656e 616d  sPacket, typenam
-0000c750: 6520 5268 7350 6163 6b65 742c 2074 7970  e RhsPacket, typ
-0000c760: 656e 616d 6520 5265 7350 6163 6b65 742c  ename ResPacket,
-0000c770: 2074 7970 656e 616d 6520 4745 4250 5472   typename GEBPTr
-0000c780: 6169 7473 2c20 7479 7065 6e61 6d65 204c  aits, typename L
-0000c790: 696e 6561 724d 6170 7065 722c 2074 7970  inearMapper, typ
-0000c7a0: 656e 616d 6520 4461 7461 4d61 7070 6572  ename DataMapper
-0000c7b0: 3e0a 7374 7275 6374 206c 6873 5f70 726f  >.struct lhs_pro
-0000c7c0: 6365 7373 5f6f 6e65 5f70 6163 6b65 740a  cess_one_packet.
-0000c7d0: 7b0a 2020 7479 7065 6465 6620 7479 7065  {.  typedef type
-0000c7e0: 6e61 6d65 2047 4542 5054 7261 6974 733a  name GEBPTraits:
-0000c7f0: 3a52 6873 5061 636b 6574 7834 2052 6873  :RhsPacketx4 Rhs
-0000c800: 5061 636b 6574 7834 3b0a 0a20 2045 4947  Packetx4;..  EIG
-0000c810: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
-0000c820: 2076 6f69 6420 7065 656c 6564 5f6b 635f   void peeled_kc_
-0000c830: 6f6e 6573 7465 7028 496e 6465 7820 4b2c  onestep(Index K,
-0000c840: 2063 6f6e 7374 204c 6873 5363 616c 6172   const LhsScalar
-0000c850: 2a20 626c 412c 2063 6f6e 7374 2052 6873  * blA, const Rhs
-0000c860: 5363 616c 6172 2a20 626c 422c 2047 4542  Scalar* blB, GEB
-0000c870: 5054 7261 6974 7320 7472 6169 7473 2c20  PTraits traits, 
-0000c880: 4c68 7350 6163 6b65 7420 2a41 302c 2052  LhsPacket *A0, R
-0000c890: 6873 5061 636b 6574 7834 202a 7268 735f  hsPacketx4 *rhs_
-0000c8a0: 7061 6e65 6c2c 2052 6873 5061 636b 6574  panel, RhsPacket
-0000c8b0: 202a 5430 2c20 4163 6350 6163 6b65 7420   *T0, AccPacket 
-0000c8c0: 2a43 302c 2041 6363 5061 636b 6574 202a  *C0, AccPacket *
-0000c8d0: 4331 2c20 4163 6350 6163 6b65 7420 2a43  C1, AccPacket *C
-0000c8e0: 322c 2041 6363 5061 636b 6574 202a 4333  2, AccPacket *C3
-0000c8f0: 290a 2020 7b0a 2020 2020 4549 4745 4e5f  ).  {.    EIGEN_
-0000c900: 4153 4d5f 434f 4d4d 454e 5428 2262 6567  ASM_COMMENT("beg
-0000c910: 696e 2073 7465 7020 6f66 2067 6562 7020  in step of gebp 
-0000c920: 6d69 6372 6f20 6b65 726e 656c 2031 5834  micro kernel 1X4
-0000c930: 2229 3b0a 2020 2020 4549 4745 4e5f 4153  ");.    EIGEN_AS
-0000c940: 4d5f 434f 4d4d 454e 5428 224e 6f74 653a  M_COMMENT("Note:
-0000c950: 2074 6865 7365 2061 736d 2063 6f6d 6d65   these asm comme
-0000c960: 6e74 7320 776f 726b 2061 726f 756e 6420  nts work around 
-0000c970: 6275 6720 3933 3521 2229 3b0a 2020 2020  bug 935!");.    
-0000c980: 7472 6169 7473 2e6c 6f61 644c 6873 2826  traits.loadLhs(&
-0000c990: 626c 415b 2830 2b31 2a4b 292a 4c68 7350  blA[(0+1*K)*LhsP
-0000c9a0: 726f 6772 6573 735d 2c20 2a41 3029 3b0a  rogress], *A0);.
-0000c9b0: 2020 2020 7472 6169 7473 2e6c 6f61 6452      traits.loadR
-0000c9c0: 6873 2826 626c 425b 2830 2b34 2a4b 292a  hs(&blB[(0+4*K)*
-0000c9d0: 5268 7350 726f 6772 6573 735d 2c20 2a72  RhsProgress], *r
-0000c9e0: 6873 5f70 616e 656c 293b 0a20 2020 2074  hs_panel);.    t
-0000c9f0: 7261 6974 732e 6d61 6464 282a 4130 2c20  raits.madd(*A0, 
-0000ca00: 2a72 6873 5f70 616e 656c 2c20 2a43 302c  *rhs_panel, *C0,
-0000ca10: 202a 5430 2c20 6669 783c 303e 293b 0a20   *T0, fix<0>);. 
-0000ca20: 2020 2074 7261 6974 732e 6d61 6464 282a     traits.madd(*
-0000ca30: 4130 2c20 2a72 6873 5f70 616e 656c 2c20  A0, *rhs_panel, 
-0000ca40: 2a43 312c 202a 5430 2c20 6669 783c 313e  *C1, *T0, fix<1>
-0000ca50: 293b 0a20 2020 2074 7261 6974 732e 6d61  );.    traits.ma
-0000ca60: 6464 282a 4130 2c20 2a72 6873 5f70 616e  dd(*A0, *rhs_pan
-0000ca70: 656c 2c20 2a43 322c 202a 5430 2c20 6669  el, *C2, *T0, fi
-0000ca80: 783c 323e 293b 0a20 2020 2074 7261 6974  x<2>);.    trait
-0000ca90: 732e 6d61 6464 282a 4130 2c20 2a72 6873  s.madd(*A0, *rhs
-0000caa0: 5f70 616e 656c 2c20 2a43 332c 202a 5430  _panel, *C3, *T0
-0000cab0: 2c20 6669 783c 333e 293b 0a20 2020 2023  , fix<3>);.    #
-0000cac0: 6966 2045 4947 454e 5f47 4e55 435f 4154  if EIGEN_GNUC_AT
-0000cad0: 5f4c 4541 5354 2836 2c30 2920 2626 2064  _LEAST(6,0) && d
-0000cae0: 6566 696e 6564 2845 4947 454e 5f56 4543  efined(EIGEN_VEC
-0000caf0: 544f 5249 5a45 5f53 5345 290a 2020 2020  TORIZE_SSE).    
-0000cb00: 5f5f 6173 6d5f 5f20 2028 2222 203a 2022  __asm__  ("" : "
-0000cb10: 2b78 2c6d 2220 282a 4130 2929 3b0a 2020  +x,m" (*A0));.  
-0000cb20: 2020 2365 6e64 6966 0a20 2020 2045 4947    #endif.    EIG
-0000cb30: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
-0000cb40: 656e 6420 7374 6570 206f 6620 6765 6270  end step of gebp
-0000cb50: 206d 6963 726f 206b 6572 6e65 6c20 3158   micro kernel 1X
-0000cb60: 3422 293b 0a20 207d 0a0a 2020 4549 4745  4");.  }..  EIGE
-0000cb70: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
-0000cb80: 766f 6964 206f 7065 7261 746f 7228 2928  void operator()(
-0000cb90: 0a20 2020 2063 6f6e 7374 2044 6174 614d  .    const DataM
-0000cba0: 6170 7065 7226 2072 6573 2c20 636f 6e73  apper& res, cons
-0000cbb0: 7420 4c68 7353 6361 6c61 722a 2062 6c6f  t LhsScalar* blo
-0000cbc0: 636b 412c 2063 6f6e 7374 2052 6873 5363  ckA, const RhsSc
-0000cbd0: 616c 6172 2a20 626c 6f63 6b42 2c20 5265  alar* blockB, Re
-0000cbe0: 7353 6361 6c61 7220 616c 7068 612c 0a20  sScalar alpha,. 
-0000cbf0: 2020 2049 6e64 6578 2070 6565 6c53 7461     Index peelSta
-0000cc00: 7274 2c20 496e 6465 7820 7065 656c 456e  rt, Index peelEn
-0000cc10: 642c 2049 6e64 6578 2073 7472 6964 6541  d, Index strideA
-0000cc20: 2c20 496e 6465 7820 7374 7269 6465 422c  , Index strideB,
-0000cc30: 2049 6e64 6578 206f 6666 7365 7441 2c20   Index offsetA, 
-0000cc40: 496e 6465 7820 6f66 6673 6574 422c 0a20  Index offsetB,. 
-0000cc50: 2020 2069 6e74 2070 7265 6665 7463 685f     int prefetch_
-0000cc60: 7265 735f 6f66 6673 6574 2c20 496e 6465  res_offset, Inde
-0000cc70: 7820 7065 656c 6564 5f6b 632c 2049 6e64  x peeled_kc, Ind
-0000cc80: 6578 2070 6b2c 2049 6e64 6578 2063 6f6c  ex pk, Index col
-0000cc90: 732c 2049 6e64 6578 2064 6570 7468 2c20  s, Index depth, 
-0000cca0: 496e 6465 7820 7061 636b 6574 5f63 6f6c  Index packet_col
-0000ccb0: 7334 290a 2020 7b0a 2020 2020 4745 4250  s4).  {.    GEBP
-0000ccc0: 5472 6169 7473 2074 7261 6974 733b 0a0a  Traits traits;..
-0000ccd0: 2020 2020 2f2f 206c 6f6f 7073 206f 6e20      // loops on 
-0000cce0: 6561 6368 206c 6172 6765 7374 206d 6963  each largest mic
-0000ccf0: 726f 2068 6f72 697a 6f6e 7461 6c20 7061  ro horizontal pa
-0000cd00: 6e65 6c20 6f66 206c 6873 0a20 2020 202f  nel of lhs.    /
-0000cd10: 2f20 284c 6873 5072 6f67 7265 7373 2078  / (LhsProgress x
-0000cd20: 2064 6570 7468 290a 2020 2020 666f 7228   depth).    for(
-0000cd30: 496e 6465 7820 693d 7065 656c 5374 6172  Index i=peelStar
-0000cd40: 743b 2069 3c70 6565 6c45 6e64 3b20 692b  t; i<peelEnd; i+
-0000cd50: 3d4c 6873 5072 6f67 7265 7373 290a 2020  =LhsProgress).  
-0000cd60: 2020 7b0a 2020 2020 2020 2f2f 206c 6f6f    {.      // loo
-0000cd70: 7073 206f 6e20 6561 6368 206c 6172 6765  ps on each large
-0000cd80: 7374 206d 6963 726f 2076 6572 7469 6361  st micro vertica
-0000cd90: 6c20 7061 6e65 6c20 6f66 2072 6873 2028  l panel of rhs (
-0000cda0: 6465 7074 6820 2a20 6e72 290a 2020 2020  depth * nr).    
-0000cdb0: 2020 666f 7228 496e 6465 7820 6a32 3d30    for(Index j2=0
-0000cdc0: 3b20 6a32 3c70 6163 6b65 745f 636f 6c73  ; j2<packet_cols
-0000cdd0: 343b 206a 322b 3d6e 7229 0a20 2020 2020  4; j2+=nr).     
-0000cde0: 207b 0a20 2020 2020 2020 202f 2f20 5765   {.        // We
-0000cdf0: 2073 656c 6563 7420 6120 4c68 7350 726f   select a LhsPro
-0000ce00: 6772 6573 7320 7820 6e72 206d 6963 726f  gress x nr micro
-0000ce10: 2062 6c6f 636b 206f 6620 7265 730a 2020   block of res.  
-0000ce20: 2020 2020 2020 2f2f 2077 6869 6368 2069        // which i
-0000ce30: 7320 656e 7469 7265 6c79 2073 746f 7265  s entirely store
-0000ce40: 6420 696e 746f 2031 2078 206e 7220 7265  d into 1 x nr re
-0000ce50: 6769 7374 6572 732e 0a0a 2020 2020 2020  gisters...      
-0000ce60: 2020 636f 6e73 7420 4c68 7353 6361 6c61    const LhsScala
-0000ce70: 722a 2062 6c41 203d 2026 626c 6f63 6b41  r* blA = &blockA
-0000ce80: 5b69 2a73 7472 6964 6541 2b6f 6666 7365  [i*strideA+offse
-0000ce90: 7441 2a28 4c68 7350 726f 6772 6573 7329  tA*(LhsProgress)
-0000cea0: 5d3b 0a20 2020 2020 2020 2070 7265 6665  ];.        prefe
-0000ceb0: 7463 6828 2662 6c41 5b30 5d29 3b0a 0a20  tch(&blA[0]);.. 
-0000cec0: 2020 2020 2020 202f 2f20 6765 7473 2072         // gets r
-0000ced0: 6573 2062 6c6f 636b 2061 7320 7265 6769  es block as regi
-0000cee0: 7374 6572 0a20 2020 2020 2020 2041 6363  ster.        Acc
-0000cef0: 5061 636b 6574 2043 302c 2043 312c 2043  Packet C0, C1, C
-0000cf00: 322c 2043 333b 0a20 2020 2020 2020 2074  2, C3;.        t
-0000cf10: 7261 6974 732e 696e 6974 4163 6328 4330  raits.initAcc(C0
-0000cf20: 293b 0a20 2020 2020 2020 2074 7261 6974  );.        trait
-0000cf30: 732e 696e 6974 4163 6328 4331 293b 0a20  s.initAcc(C1);. 
-0000cf40: 2020 2020 2020 2074 7261 6974 732e 696e         traits.in
-0000cf50: 6974 4163 6328 4332 293b 0a20 2020 2020  itAcc(C2);.     
-0000cf60: 2020 2074 7261 6974 732e 696e 6974 4163     traits.initAc
-0000cf70: 6328 4333 293b 0a20 2020 2020 2020 202f  c(C3);.        /
-0000cf80: 2f20 546f 2069 6d70 726f 7665 2069 6e73  / To improve ins
-0000cf90: 7472 7563 7469 6f6e 2070 6970 656c 696e  truction pipelin
-0000cfa0: 696e 672c 206c 6574 2773 2064 6f75 626c  ing, let's doubl
-0000cfb0: 6520 7468 6520 6163 6375 6d75 6c61 7469  e the accumulati
-0000cfc0: 6f6e 2072 6567 6973 7465 7273 3a0a 2020  on registers:.  
-0000cfd0: 2020 2020 2020 2f2f 2020 6576 656e 206b        //  even k
-0000cfe0: 2077 696c 6c20 6163 6375 6d75 6c61 7465   will accumulate
-0000cff0: 2069 6e20 432a 2c20 7768 696c 6520 6f64   in C*, while od
-0000d000: 6420 6b20 7769 6c6c 2061 6363 756d 756c  d k will accumul
-0000d010: 6174 6520 696e 2044 2a2e 0a20 2020 2020  ate in D*..     
-0000d020: 2020 202f 2f20 5468 6973 2074 7269 636b     // This trick
-0000d030: 2069 7320 6372 7574 6961 6c20 746f 2067   is crutial to g
-0000d040: 6574 2067 6f6f 6420 7065 7266 6f72 6d61  et good performa
-0000d050: 6e63 6520 7769 7468 2046 4d41 2c20 6f74  nce with FMA, ot
-0000d060: 6865 7277 6973 6520 6974 2069 7320 0a20  herwise it is . 
-0000d070: 2020 2020 2020 202f 2f20 6163 7475 616c         // actual
-0000d080: 6c79 2066 6173 7465 7220 746f 2070 6572  ly faster to per
-0000d090: 666f 726d 2073 6570 6172 6174 6564 204d  form separated M
-0000d0a0: 554c 2b41 4444 2062 6563 6175 7365 206f  UL+ADD because o
-0000d0b0: 6620 6120 6e61 7475 7261 6c6c 790a 2020  f a naturally.  
-0000d0c0: 2020 2020 2020 2f2f 2062 6574 7465 7220        // better 
-0000d0d0: 696e 7374 7275 6374 696f 6e2d 6c65 7665  instruction-leve
-0000d0e0: 6c20 7061 7261 6c6c 656c 6973 6d2e 0a20  l parallelism.. 
-0000d0f0: 2020 2020 2020 2041 6363 5061 636b 6574         AccPacket
-0000d100: 2044 302c 2044 312c 2044 322c 2044 333b   D0, D1, D2, D3;
-0000d110: 0a20 2020 2020 2020 2074 7261 6974 732e  .        traits.
-0000d120: 696e 6974 4163 6328 4430 293b 0a20 2020  initAcc(D0);.   
-0000d130: 2020 2020 2074 7261 6974 732e 696e 6974       traits.init
-0000d140: 4163 6328 4431 293b 0a20 2020 2020 2020  Acc(D1);.       
-0000d150: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
-0000d160: 4432 293b 0a20 2020 2020 2020 2074 7261  D2);.        tra
-0000d170: 6974 732e 696e 6974 4163 6328 4433 293b  its.initAcc(D3);
-0000d180: 0a0a 2020 2020 2020 2020 4c69 6e65 6172  ..        Linear
-0000d190: 4d61 7070 6572 2072 3020 3d20 7265 732e  Mapper r0 = res.
-0000d1a0: 6765 744c 696e 6561 724d 6170 7065 7228  getLinearMapper(
-0000d1b0: 692c 206a 3220 2b20 3029 3b0a 2020 2020  i, j2 + 0);.    
-0000d1c0: 2020 2020 4c69 6e65 6172 4d61 7070 6572      LinearMapper
-0000d1d0: 2072 3120 3d20 7265 732e 6765 744c 696e   r1 = res.getLin
-0000d1e0: 6561 724d 6170 7065 7228 692c 206a 3220  earMapper(i, j2 
-0000d1f0: 2b20 3129 3b0a 2020 2020 2020 2020 4c69  + 1);.        Li
-0000d200: 6e65 6172 4d61 7070 6572 2072 3220 3d20  nearMapper r2 = 
-0000d210: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
-0000d220: 7065 7228 692c 206a 3220 2b20 3229 3b0a  per(i, j2 + 2);.
-0000d230: 2020 2020 2020 2020 4c69 6e65 6172 4d61          LinearMa
-0000d240: 7070 6572 2072 3320 3d20 7265 732e 6765  pper r3 = res.ge
-0000d250: 744c 696e 6561 724d 6170 7065 7228 692c  tLinearMapper(i,
-0000d260: 206a 3220 2b20 3329 3b0a 0a20 2020 2020   j2 + 3);..     
-0000d270: 2020 2072 302e 7072 6566 6574 6368 2870     r0.prefetch(p
-0000d280: 7265 6665 7463 685f 7265 735f 6f66 6673  refetch_res_offs
-0000d290: 6574 293b 0a20 2020 2020 2020 2072 312e  et);.        r1.
-0000d2a0: 7072 6566 6574 6368 2870 7265 6665 7463  prefetch(prefetc
-0000d2b0: 685f 7265 735f 6f66 6673 6574 293b 0a20  h_res_offset);. 
-0000d2c0: 2020 2020 2020 2072 322e 7072 6566 6574         r2.prefet
-0000d2d0: 6368 2870 7265 6665 7463 685f 7265 735f  ch(prefetch_res_
-0000d2e0: 6f66 6673 6574 293b 0a20 2020 2020 2020  offset);.       
-0000d2f0: 2072 332e 7072 6566 6574 6368 2870 7265   r3.prefetch(pre
-0000d300: 6665 7463 685f 7265 735f 6f66 6673 6574  fetch_res_offset
-0000d310: 293b 0a0a 2020 2020 2020 2020 2f2f 2070  );..        // p
-0000d320: 6572 666f 726d 7320 2269 6e6e 6572 2220  erforms "inner" 
-0000d330: 7072 6f64 7563 7473 0a20 2020 2020 2020  products.       
-0000d340: 2063 6f6e 7374 2052 6873 5363 616c 6172   const RhsScalar
-0000d350: 2a20 626c 4220 3d20 2662 6c6f 636b 425b  * blB = &blockB[
-0000d360: 6a32 2a73 7472 6964 6542 2b6f 6666 7365  j2*strideB+offse
-0000d370: 7442 2a6e 725d 3b0a 2020 2020 2020 2020  tB*nr];.        
-0000d380: 7072 6566 6574 6368 2826 626c 425b 305d  prefetch(&blB[0]
-0000d390: 293b 0a20 2020 2020 2020 204c 6873 5061  );.        LhsPa
-0000d3a0: 636b 6574 2041 302c 2041 313b 0a0a 2020  cket A0, A1;..  
-0000d3b0: 2020 2020 2020 666f 7228 496e 6465 7820        for(Index 
-0000d3c0: 6b3d 303b 206b 3c70 6565 6c65 645f 6b63  k=0; k<peeled_kc
-0000d3d0: 3b20 6b2b 3d70 6b29 0a20 2020 2020 2020  ; k+=pk).       
-0000d3e0: 207b 0a20 2020 2020 2020 2020 2045 4947   {.          EIG
-0000d3f0: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
-0000d400: 6265 6769 6e20 6765 6270 206d 6963 726f  begin gebp micro
-0000d410: 206b 6572 6e65 6c20 312f 6861 6c66 2f71   kernel 1/half/q
-0000d420: 7561 7274 6572 5834 2229 3b0a 2020 2020  uarterX4");.    
-0000d430: 2020 2020 2020 5268 7350 6163 6b65 7478        RhsPacketx
-0000d440: 3420 7268 735f 7061 6e65 6c3b 0a20 2020  4 rhs_panel;.   
-0000d450: 2020 2020 2020 2052 6873 5061 636b 6574         RhsPacket
-0000d460: 2054 303b 0a0a 2020 2020 2020 2020 2020   T0;..          
-0000d470: 696e 7465 726e 616c 3a3a 7072 6566 6574  internal::prefet
-0000d480: 6368 2862 6c42 2b28 3438 2b30 2929 3b0a  ch(blB+(48+0));.
-0000d490: 2020 2020 2020 2020 2020 7065 656c 6564            peeled
-0000d4a0: 5f6b 635f 6f6e 6573 7465 7028 302c 2062  _kc_onestep(0, b
-0000d4b0: 6c41 2c20 626c 422c 2074 7261 6974 732c  lA, blB, traits,
-0000d4c0: 2026 4130 2c20 2672 6873 5f70 616e 656c   &A0, &rhs_panel
-0000d4d0: 2c20 2654 302c 2026 4330 2c20 2643 312c  , &T0, &C0, &C1,
-0000d4e0: 2026 4332 2c20 2643 3329 3b0a 2020 2020   &C2, &C3);.    
-0000d4f0: 2020 2020 2020 7065 656c 6564 5f6b 635f        peeled_kc_
-0000d500: 6f6e 6573 7465 7028 312c 2062 6c41 2c20  onestep(1, blA, 
-0000d510: 626c 422c 2074 7261 6974 732c 2026 4131  blB, traits, &A1
-0000d520: 2c20 2672 6873 5f70 616e 656c 2c20 2654  , &rhs_panel, &T
-0000d530: 302c 2026 4430 2c20 2644 312c 2026 4432  0, &D0, &D1, &D2
-0000d540: 2c20 2644 3329 3b0a 2020 2020 2020 2020  , &D3);.        
-0000d550: 2020 7065 656c 6564 5f6b 635f 6f6e 6573    peeled_kc_ones
-0000d560: 7465 7028 322c 2062 6c41 2c20 626c 422c  tep(2, blA, blB,
-0000d570: 2074 7261 6974 732c 2026 4130 2c20 2672   traits, &A0, &r
-0000d580: 6873 5f70 616e 656c 2c20 2654 302c 2026  hs_panel, &T0, &
-0000d590: 4330 2c20 2643 312c 2026 4332 2c20 2643  C0, &C1, &C2, &C
-0000d5a0: 3329 3b0a 2020 2020 2020 2020 2020 7065  3);.          pe
-0000d5b0: 656c 6564 5f6b 635f 6f6e 6573 7465 7028  eled_kc_onestep(
-0000d5c0: 332c 2062 6c41 2c20 626c 422c 2074 7261  3, blA, blB, tra
-0000d5d0: 6974 732c 2026 4131 2c20 2672 6873 5f70  its, &A1, &rhs_p
-0000d5e0: 616e 656c 2c20 2654 302c 2026 4430 2c20  anel, &T0, &D0, 
-0000d5f0: 2644 312c 2026 4432 2c20 2644 3329 3b0a  &D1, &D2, &D3);.
-0000d600: 2020 2020 2020 2020 2020 696e 7465 726e            intern
-0000d610: 616c 3a3a 7072 6566 6574 6368 2862 6c42  al::prefetch(blB
-0000d620: 2b28 3438 2b31 3629 293b 0a20 2020 2020  +(48+16));.     
-0000d630: 2020 2020 2070 6565 6c65 645f 6b63 5f6f       peeled_kc_o
-0000d640: 6e65 7374 6570 2834 2c20 626c 412c 2062  nestep(4, blA, b
-0000d650: 6c42 2c20 7472 6169 7473 2c20 2641 302c  lB, traits, &A0,
-0000d660: 2026 7268 735f 7061 6e65 6c2c 2026 5430   &rhs_panel, &T0
-0000d670: 2c20 2643 302c 2026 4331 2c20 2643 322c  , &C0, &C1, &C2,
-0000d680: 2026 4333 293b 0a20 2020 2020 2020 2020   &C3);.         
-0000d690: 2070 6565 6c65 645f 6b63 5f6f 6e65 7374   peeled_kc_onest
-0000d6a0: 6570 2835 2c20 626c 412c 2062 6c42 2c20  ep(5, blA, blB, 
-0000d6b0: 7472 6169 7473 2c20 2641 312c 2026 7268  traits, &A1, &rh
-0000d6c0: 735f 7061 6e65 6c2c 2026 5430 2c20 2644  s_panel, &T0, &D
-0000d6d0: 302c 2026 4431 2c20 2644 322c 2026 4433  0, &D1, &D2, &D3
-0000d6e0: 293b 0a20 2020 2020 2020 2020 2070 6565  );.          pee
-0000d6f0: 6c65 645f 6b63 5f6f 6e65 7374 6570 2836  led_kc_onestep(6
-0000d700: 2c20 626c 412c 2062 6c42 2c20 7472 6169  , blA, blB, trai
-0000d710: 7473 2c20 2641 302c 2026 7268 735f 7061  ts, &A0, &rhs_pa
-0000d720: 6e65 6c2c 2026 5430 2c20 2643 302c 2026  nel, &T0, &C0, &
-0000d730: 4331 2c20 2643 322c 2026 4333 293b 0a20  C1, &C2, &C3);. 
-0000d740: 2020 2020 2020 2020 2070 6565 6c65 645f           peeled_
-0000d750: 6b63 5f6f 6e65 7374 6570 2837 2c20 626c  kc_onestep(7, bl
-0000d760: 412c 2062 6c42 2c20 7472 6169 7473 2c20  A, blB, traits, 
-0000d770: 2641 312c 2026 7268 735f 7061 6e65 6c2c  &A1, &rhs_panel,
-0000d780: 2026 5430 2c20 2644 302c 2026 4431 2c20   &T0, &D0, &D1, 
-0000d790: 2644 322c 2026 4433 293b 0a0a 2020 2020  &D2, &D3);..    
-0000d7a0: 2020 2020 2020 626c 4220 2b3d 2070 6b2a        blB += pk*
-0000d7b0: 342a 5268 7350 726f 6772 6573 733b 0a20  4*RhsProgress;. 
-0000d7c0: 2020 2020 2020 2020 2062 6c41 202b 3d20           blA += 
-0000d7d0: 706b 2a4c 6873 5072 6f67 7265 7373 3b0a  pk*LhsProgress;.
-0000d7e0: 0a20 2020 2020 2020 2020 2045 4947 454e  .          EIGEN
-0000d7f0: 5f41 534d 5f43 4f4d 4d45 4e54 2822 656e  _ASM_COMMENT("en
-0000d800: 6420 6765 6270 206d 6963 726f 206b 6572  d gebp micro ker
-0000d810: 6e65 6c20 312f 6861 6c66 2f71 7561 7274  nel 1/half/quart
-0000d820: 6572 5834 2229 3b0a 2020 2020 2020 2020  erX4");.        
-0000d830: 7d0a 2020 2020 2020 2020 4330 203d 2070  }.        C0 = p
-0000d840: 6164 6428 4330 2c44 3029 3b0a 2020 2020  add(C0,D0);.    
-0000d850: 2020 2020 4331 203d 2070 6164 6428 4331      C1 = padd(C1
-0000d860: 2c44 3129 3b0a 2020 2020 2020 2020 4332  ,D1);.        C2
-0000d870: 203d 2070 6164 6428 4332 2c44 3229 3b0a   = padd(C2,D2);.
-0000d880: 2020 2020 2020 2020 4333 203d 2070 6164          C3 = pad
-0000d890: 6428 4333 2c44 3329 3b0a 0a20 2020 2020  d(C3,D3);..     
-0000d8a0: 2020 202f 2f20 7072 6f63 6573 7320 7265     // process re
-0000d8b0: 6d61 696e 696e 6720 7065 656c 6564 206c  maining peeled l
-0000d8c0: 6f6f 700a 2020 2020 2020 2020 666f 7228  oop.        for(
-0000d8d0: 496e 6465 7820 6b3d 7065 656c 6564 5f6b  Index k=peeled_k
-0000d8e0: 633b 206b 3c64 6570 7468 3b20 6b2b 2b29  c; k<depth; k++)
-0000d8f0: 0a20 2020 2020 2020 207b 0a20 2020 2020  .        {.     
-0000d900: 2020 2020 2052 6873 5061 636b 6574 7834       RhsPacketx4
-0000d910: 2072 6873 5f70 616e 656c 3b0a 2020 2020   rhs_panel;.    
-0000d920: 2020 2020 2020 5268 7350 6163 6b65 7420        RhsPacket 
-0000d930: 5430 3b0a 2020 2020 2020 2020 2020 7065  T0;.          pe
-0000d940: 656c 6564 5f6b 635f 6f6e 6573 7465 7028  eled_kc_onestep(
-0000d950: 302c 2062 6c41 2c20 626c 422c 2074 7261  0, blA, blB, tra
-0000d960: 6974 732c 2026 4130 2c20 2672 6873 5f70  its, &A0, &rhs_p
-0000d970: 616e 656c 2c20 2654 302c 2026 4330 2c20  anel, &T0, &C0, 
-0000d980: 2643 312c 2026 4332 2c20 2643 3329 3b0a  &C1, &C2, &C3);.
-0000d990: 2020 2020 2020 2020 2020 626c 4220 2b3d            blB +=
-0000d9a0: 2034 2a52 6873 5072 6f67 7265 7373 3b0a   4*RhsProgress;.
-0000d9b0: 2020 2020 2020 2020 2020 626c 4120 2b3d            blA +=
-0000d9c0: 204c 6873 5072 6f67 7265 7373 3b0a 2020   LhsProgress;.  
-0000d9d0: 2020 2020 2020 7d0a 0a20 2020 2020 2020        }..       
-0000d9e0: 2052 6573 5061 636b 6574 2052 302c 2052   ResPacket R0, R
-0000d9f0: 313b 0a20 2020 2020 2020 2052 6573 5061  1;.        ResPa
-0000da00: 636b 6574 2061 6c70 6861 7620 3d20 7073  cket alphav = ps
-0000da10: 6574 313c 5265 7350 6163 6b65 743e 2861  et1<ResPacket>(a
-0000da20: 6c70 6861 293b 0a0a 2020 2020 2020 2020  lpha);..        
-0000da30: 5230 203d 2072 302e 7465 6d70 6c61 7465  R0 = r0.template
-0000da40: 206c 6f61 6450 6163 6b65 743c 5265 7350   loadPacket<ResP
-0000da50: 6163 6b65 743e 2830 293b 0a20 2020 2020  acket>(0);.     
-0000da60: 2020 2052 3120 3d20 7231 2e74 656d 706c     R1 = r1.templ
-0000da70: 6174 6520 6c6f 6164 5061 636b 6574 3c52  ate loadPacket<R
-0000da80: 6573 5061 636b 6574 3e28 3029 3b0a 2020  esPacket>(0);.  
-0000da90: 2020 2020 2020 7472 6169 7473 2e61 6363        traits.acc
-0000daa0: 2843 302c 2061 6c70 6861 762c 2052 3029  (C0, alphav, R0)
-0000dab0: 3b0a 2020 2020 2020 2020 7472 6169 7473  ;.        traits
-0000dac0: 2e61 6363 2843 312c 2020 616c 7068 6176  .acc(C1,  alphav
-0000dad0: 2c20 5231 293b 0a20 2020 2020 2020 2072  , R1);.        r
-0000dae0: 302e 7374 6f72 6550 6163 6b65 7428 302c  0.storePacket(0,
-0000daf0: 2052 3029 3b0a 2020 2020 2020 2020 7231   R0);.        r1
-0000db00: 2e73 746f 7265 5061 636b 6574 2830 2c20  .storePacket(0, 
-0000db10: 5231 293b 0a0a 2020 2020 2020 2020 5230  R1);..        R0
-0000db20: 203d 2072 322e 7465 6d70 6c61 7465 206c   = r2.template l
-0000db30: 6f61 6450 6163 6b65 743c 5265 7350 6163  oadPacket<ResPac
-0000db40: 6b65 743e 2830 293b 0a20 2020 2020 2020  ket>(0);.       
-0000db50: 2052 3120 3d20 7233 2e74 656d 706c 6174   R1 = r3.templat
-0000db60: 6520 6c6f 6164 5061 636b 6574 3c52 6573  e loadPacket<Res
-0000db70: 5061 636b 6574 3e28 3029 3b0a 2020 2020  Packet>(0);.    
-0000db80: 2020 2020 7472 6169 7473 2e61 6363 2843      traits.acc(C
-0000db90: 322c 2020 616c 7068 6176 2c20 5230 293b  2,  alphav, R0);
-0000dba0: 0a20 2020 2020 2020 2074 7261 6974 732e  .        traits.
-0000dbb0: 6163 6328 4333 2c20 2061 6c70 6861 762c  acc(C3,  alphav,
-0000dbc0: 2052 3129 3b0a 2020 2020 2020 2020 7232   R1);.        r2
-0000dbd0: 2e73 746f 7265 5061 636b 6574 2830 2c20  .storePacket(0, 
-0000dbe0: 5230 293b 0a20 2020 2020 2020 2072 332e  R0);.        r3.
-0000dbf0: 7374 6f72 6550 6163 6b65 7428 302c 2052  storePacket(0, R
-0000dc00: 3129 3b0a 2020 2020 2020 7d0a 0a20 2020  1);.      }..   
-0000dc10: 2020 202f 2f20 4465 616c 2077 6974 6820     // Deal with 
-0000dc20: 7265 6d61 696e 696e 6720 636f 6c75 6d6e  remaining column
-0000dc30: 7320 6f66 2074 6865 2072 6873 0a20 2020  s of the rhs.   
-0000dc40: 2020 2066 6f72 2849 6e64 6578 206a 323d     for(Index j2=
-0000dc50: 7061 636b 6574 5f63 6f6c 7334 3b20 6a32  packet_cols4; j2
-0000dc60: 3c63 6f6c 733b 206a 322b 2b29 0a20 2020  <cols; j2++).   
-0000dc70: 2020 207b 0a20 2020 2020 2020 202f 2f20     {.        // 
-0000dc80: 4f6e 6520 636f 6c75 6d6e 2061 7420 6120  One column at a 
-0000dc90: 7469 6d65 0a20 2020 2020 2020 2063 6f6e  time.        con
-0000dca0: 7374 204c 6873 5363 616c 6172 2a20 626c  st LhsScalar* bl
-0000dcb0: 4120 3d20 2662 6c6f 636b 415b 692a 7374  A = &blockA[i*st
-0000dcc0: 7269 6465 412b 6f66 6673 6574 412a 284c  rideA+offsetA*(L
-0000dcd0: 6873 5072 6f67 7265 7373 295d 3b0a 2020  hsProgress)];.  
-0000dce0: 2020 2020 2020 7072 6566 6574 6368 2826        prefetch(&
-0000dcf0: 626c 415b 305d 293b 0a0a 2020 2020 2020  blA[0]);..      
-0000dd00: 2020 2f2f 2067 6574 7320 7265 7320 626c    // gets res bl
-0000dd10: 6f63 6b20 6173 2072 6567 6973 7465 720a  ock as register.
-0000dd20: 2020 2020 2020 2020 4163 6350 6163 6b65          AccPacke
-0000dd30: 7420 4330 3b0a 2020 2020 2020 2020 7472  t C0;.        tr
-0000dd40: 6169 7473 2e69 6e69 7441 6363 2843 3029  aits.initAcc(C0)
-0000dd50: 3b0a 0a20 2020 2020 2020 204c 696e 6561  ;..        Linea
-0000dd60: 724d 6170 7065 7220 7230 203d 2072 6573  rMapper r0 = res
-0000dd70: 2e67 6574 4c69 6e65 6172 4d61 7070 6572  .getLinearMapper
-0000dd80: 2869 2c20 6a32 293b 0a0a 2020 2020 2020  (i, j2);..      
-0000dd90: 2020 2f2f 2070 6572 666f 726d 7320 2269    // performs "i
-0000dda0: 6e6e 6572 2220 7072 6f64 7563 7473 0a20  nner" products. 
-0000ddb0: 2020 2020 2020 2063 6f6e 7374 2052 6873         const Rhs
-0000ddc0: 5363 616c 6172 2a20 626c 4220 3d20 2662  Scalar* blB = &b
-0000ddd0: 6c6f 636b 425b 6a32 2a73 7472 6964 6542  lockB[j2*strideB
-0000dde0: 2b6f 6666 7365 7442 5d3b 0a20 2020 2020  +offsetB];.     
-0000ddf0: 2020 204c 6873 5061 636b 6574 2041 303b     LhsPacket A0;
-0000de00: 0a0a 2020 2020 2020 2020 666f 7228 496e  ..        for(In
-0000de10: 6465 7820 6b3d 2030 3b20 6b3c 7065 656c  dex k= 0; k<peel
-0000de20: 6564 5f6b 633b 206b 2b3d 706b 290a 2020  ed_kc; k+=pk).  
-0000de30: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
-0000de40: 2020 4549 4745 4e5f 4153 4d5f 434f 4d4d    EIGEN_ASM_COMM
-0000de50: 454e 5428 2262 6567 696e 2067 6562 7020  ENT("begin gebp 
-0000de60: 6d69 6372 6f20 6b65 726e 656c 2031 2f68  micro kernel 1/h
-0000de70: 616c 662f 7175 6172 7465 7258 3122 293b  alf/quarterX1");
-0000de80: 0a20 2020 2020 2020 2020 2052 6873 5061  .          RhsPa
-0000de90: 636b 6574 2042 5f30 3b0a 0a23 6465 6669  cket B_0;..#defi
-0000dea0: 6e65 2045 4947 454e 5f47 4542 4750 5f4f  ne EIGEN_GEBGP_O
-0000deb0: 4e45 5354 4550 284b 2920 2020 2020 2020  NESTEP(K)       
-0000dec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ded0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000dee0: 2020 205c 0a09 2020 2020 2020 646f 207b     \..      do {
-0000def0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000df00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000df10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000df20: 2020 2020 2020 5c0a 0909 4549 4745 4e5f        \...EIGEN_
-0000df30: 4153 4d5f 434f 4d4d 454e 5428 2262 6567  ASM_COMMENT("beg
-0000df40: 696e 2073 7465 7020 6f66 2067 6562 7020  in step of gebp 
-0000df50: 6d69 6372 6f20 6b65 726e 656c 2031 2f68  micro kernel 1/h
-0000df60: 616c 662f 7175 6172 7465 7258 3122 293b  alf/quarterX1");
-0000df70: 205c 0a09 0945 4947 454e 5f41 534d 5f43   \...EIGEN_ASM_C
-0000df80: 4f4d 4d45 4e54 2822 4e6f 7465 3a20 7468  OMMENT("Note: th
-0000df90: 6573 6520 6173 6d20 636f 6d6d 656e 7473  ese asm comments
-0000dfa0: 2077 6f72 6b20 6172 6f75 6e64 2062 7567   work around bug
-0000dfb0: 2039 3335 2122 293b 205c 0a20 2020 202f   935!"); \.    /
-0000dfc0: 2a20 4649 584d 453a 2077 6879 2075 6e61  * FIXME: why una
-0000dfd0: 6c69 676e 6564 3f3f 3f3f 202a 2f20 5c0a  ligned???? */ \.
-0000dfe0: 0909 7472 6169 7473 2e6c 6f61 644c 6873  ..traits.loadLhs
-0000dff0: 556e 616c 6967 6e65 6428 2662 6c41 5b28  Unaligned(&blA[(
-0000e000: 302b 312a 4b29 2a4c 6873 5072 6f67 7265  0+1*K)*LhsProgre
-0000e010: 7373 5d2c 2041 3029 3b20 5c0a 0909 7472  ss], A0); \...tr
-0000e020: 6169 7473 2e6c 6f61 6452 6873 2826 626c  aits.loadRhs(&bl
-0000e030: 425b 2830 2b4b 292a 5268 7350 726f 6772  B[(0+K)*RhsProgr
-0000e040: 6573 735d 2c20 425f 3029 3b09 095c 0a09  ess], B_0);..\..
-0000e050: 0974 7261 6974 732e 6d61 6464 2841 302c  .traits.madd(A0,
-0000e060: 2042 5f30 2c20 4330 2c20 425f 302c 2066   B_0, C0, B_0, f
-0000e070: 6978 3c30 3e29 3b09 0909 095c 0a09 0945  ix<0>);....\...E
-0000e080: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
-0000e090: 2822 656e 6420 7374 6570 206f 6620 6765  ("end step of ge
-0000e0a0: 6270 206d 6963 726f 206b 6572 6e65 6c20  bp micro kernel 
-0000e0b0: 312f 6861 6c66 2f71 7561 7274 6572 5831  1/half/quarterX1
-0000e0c0: 2229 3b20 5c0a 0920 2020 2020 207d 2077  "); \..      } w
-0000e0d0: 6869 6c65 2866 616c 7365 293b 0a0a 2020  hile(false);..  
-0000e0e0: 2020 2020 2020 2020 4549 4745 4e5f 4745          EIGEN_GE
-0000e0f0: 4247 505f 4f4e 4553 5445 5028 3029 3b0a  BGP_ONESTEP(0);.
-0000e100: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
-0000e110: 4745 4247 505f 4f4e 4553 5445 5028 3129  GEBGP_ONESTEP(1)
-0000e120: 3b0a 2020 2020 2020 2020 2020 4549 4745  ;.          EIGE
-0000e130: 4e5f 4745 4247 505f 4f4e 4553 5445 5028  N_GEBGP_ONESTEP(
-0000e140: 3229 3b0a 2020 2020 2020 2020 2020 4549  2);.          EI
-0000e150: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
-0000e160: 5028 3329 3b0a 2020 2020 2020 2020 2020  P(3);.          
-0000e170: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
-0000e180: 5445 5028 3429 3b0a 2020 2020 2020 2020  TEP(4);.        
-0000e190: 2020 4549 4745 4e5f 4745 4247 505f 4f4e    EIGEN_GEBGP_ON
-0000e1a0: 4553 5445 5028 3529 3b0a 2020 2020 2020  ESTEP(5);.      
-0000e1b0: 2020 2020 4549 4745 4e5f 4745 4247 505f      EIGEN_GEBGP_
-0000e1c0: 4f4e 4553 5445 5028 3629 3b0a 2020 2020  ONESTEP(6);.    
-0000e1d0: 2020 2020 2020 4549 4745 4e5f 4745 4247        EIGEN_GEBG
-0000e1e0: 505f 4f4e 4553 5445 5028 3729 3b0a 0a20  P_ONESTEP(7);.. 
-0000e1f0: 2020 2020 2020 2020 2062 6c42 202b 3d20           blB += 
-0000e200: 706b 2a52 6873 5072 6f67 7265 7373 3b0a  pk*RhsProgress;.
-0000e210: 2020 2020 2020 2020 2020 626c 4120 2b3d            blA +=
-0000e220: 2070 6b2a 4c68 7350 726f 6772 6573 733b   pk*LhsProgress;
-0000e230: 0a0a 2020 2020 2020 2020 2020 4549 4745  ..          EIGE
-0000e240: 4e5f 4153 4d5f 434f 4d4d 454e 5428 2265  N_ASM_COMMENT("e
-0000e250: 6e64 2067 6562 7020 6d69 6372 6f20 6b65  nd gebp micro ke
-0000e260: 726e 656c 2031 2f68 616c 662f 7175 6172  rnel 1/half/quar
-0000e270: 7465 7258 3122 293b 0a20 2020 2020 2020  terX1");.       
-0000e280: 207d 0a0a 2020 2020 2020 2020 2f2f 2070   }..        // p
-0000e290: 726f 6365 7373 2072 656d 6169 6e69 6e67  rocess remaining
-0000e2a0: 2070 6565 6c65 6420 6c6f 6f70 0a20 2020   peeled loop.   
-0000e2b0: 2020 2020 2066 6f72 2849 6e64 6578 206b       for(Index k
-0000e2c0: 3d70 6565 6c65 645f 6b63 3b20 6b3c 6465  =peeled_kc; k<de
-0000e2d0: 7074 683b 206b 2b2b 290a 2020 2020 2020  pth; k++).      
-0000e2e0: 2020 7b0a 2020 2020 2020 2020 2020 5268    {.          Rh
-0000e2f0: 7350 6163 6b65 7420 425f 303b 0a20 2020  sPacket B_0;.   
-0000e300: 2020 2020 2020 2045 4947 454e 5f47 4542         EIGEN_GEB
-0000e310: 4750 5f4f 4e45 5354 4550 2830 293b 0a20  GP_ONESTEP(0);. 
-0000e320: 2020 2020 2020 2020 2062 6c42 202b 3d20           blB += 
-0000e330: 5268 7350 726f 6772 6573 733b 0a20 2020  RhsProgress;.   
-0000e340: 2020 2020 2020 2062 6c41 202b 3d20 4c68         blA += Lh
-0000e350: 7350 726f 6772 6573 733b 0a20 2020 2020  sProgress;.     
-0000e360: 2020 207d 0a23 756e 6465 6620 4549 4745     }.#undef EIGE
-0000e370: 4e5f 4745 4247 505f 4f4e 4553 5445 500a  N_GEBGP_ONESTEP.
-0000e380: 2020 2020 2020 2020 5265 7350 6163 6b65          ResPacke
-0000e390: 7420 5230 3b0a 2020 2020 2020 2020 5265  t R0;.        Re
-0000e3a0: 7350 6163 6b65 7420 616c 7068 6176 203d  sPacket alphav =
-0000e3b0: 2070 7365 7431 3c52 6573 5061 636b 6574   pset1<ResPacket
-0000e3c0: 3e28 616c 7068 6129 3b0a 2020 2020 2020  >(alpha);.      
-0000e3d0: 2020 5230 203d 2072 302e 7465 6d70 6c61    R0 = r0.templa
-0000e3e0: 7465 206c 6f61 6450 6163 6b65 743c 5265  te loadPacket<Re
-0000e3f0: 7350 6163 6b65 743e 2830 293b 0a20 2020  sPacket>(0);.   
-0000e400: 2020 2020 2074 7261 6974 732e 6163 6328       traits.acc(
-0000e410: 4330 2c20 616c 7068 6176 2c20 5230 293b  C0, alphav, R0);
-0000e420: 0a20 2020 2020 2020 2072 302e 7374 6f72  .        r0.stor
-0000e430: 6550 6163 6b65 7428 302c 2052 3029 3b0a  ePacket(0, R0);.
-0000e440: 2020 2020 2020 7d0a 2020 2020 7d0a 2020        }.    }.  
-0000e450: 7d0a 7d3b 0a0a 7465 6d70 6c61 7465 3c69  }.};..template<i
-0000e460: 6e74 206e 722c 2049 6e64 6578 204c 6873  nt nr, Index Lhs
-0000e470: 5072 6f67 7265 7373 2c20 496e 6465 7820  Progress, Index 
-0000e480: 5268 7350 726f 6772 6573 732c 2074 7970  RhsProgress, typ
-0000e490: 656e 616d 6520 4c68 7353 6361 6c61 722c  ename LhsScalar,
-0000e4a0: 2074 7970 656e 616d 6520 5268 7353 6361   typename RhsSca
-0000e4b0: 6c61 722c 2074 7970 656e 616d 6520 5265  lar, typename Re
-0000e4c0: 7353 6361 6c61 722c 2074 7970 656e 616d  sScalar, typenam
-0000e4d0: 6520 4163 6350 6163 6b65 742c 2074 7970  e AccPacket, typ
-0000e4e0: 656e 616d 6520 4c68 7350 6163 6b65 742c  ename LhsPacket,
-0000e4f0: 2074 7970 656e 616d 6520 5268 7350 6163   typename RhsPac
-0000e500: 6b65 742c 2074 7970 656e 616d 6520 5265  ket, typename Re
-0000e510: 7350 6163 6b65 742c 2074 7970 656e 616d  sPacket, typenam
-0000e520: 6520 4745 4250 5472 6169 7473 2c20 7479  e GEBPTraits, ty
-0000e530: 7065 6e61 6d65 204c 696e 6561 724d 6170  pename LinearMap
-0000e540: 7065 722c 2074 7970 656e 616d 6520 4461  per, typename Da
-0000e550: 7461 4d61 7070 6572 3e0a 7374 7275 6374  taMapper>.struct
-0000e560: 206c 6873 5f70 726f 6365 7373 5f66 7261   lhs_process_fra
-0000e570: 6374 696f 6e5f 6f66 5f70 6163 6b65 7420  ction_of_packet 
-0000e580: 3a20 6c68 735f 7072 6f63 6573 735f 6f6e  : lhs_process_on
-0000e590: 655f 7061 636b 6574 3c6e 722c 204c 6873  e_packet<nr, Lhs
-0000e5a0: 5072 6f67 7265 7373 2c20 5268 7350 726f  Progress, RhsPro
-0000e5b0: 6772 6573 732c 204c 6873 5363 616c 6172  gress, LhsScalar
-0000e5c0: 2c20 5268 7353 6361 6c61 722c 2052 6573  , RhsScalar, Res
-0000e5d0: 5363 616c 6172 2c20 4163 6350 6163 6b65  Scalar, AccPacke
-0000e5e0: 742c 204c 6873 5061 636b 6574 2c20 5268  t, LhsPacket, Rh
-0000e5f0: 7350 6163 6b65 742c 2052 6573 5061 636b  sPacket, ResPack
-0000e600: 6574 2c20 4745 4250 5472 6169 7473 2c20  et, GEBPTraits, 
-0000e610: 4c69 6e65 6172 4d61 7070 6572 2c20 4461  LinearMapper, Da
-0000e620: 7461 4d61 7070 6572 3e0a 7b0a 0a45 4947  taMapper>.{..EIG
-0000e630: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
-0000e640: 2076 6f69 6420 7065 656c 6564 5f6b 635f   void peeled_kc_
-0000e650: 6f6e 6573 7465 7028 496e 6465 7820 4b2c  onestep(Index K,
-0000e660: 2063 6f6e 7374 204c 6873 5363 616c 6172   const LhsScalar
-0000e670: 2a20 626c 412c 2063 6f6e 7374 2052 6873  * blA, const Rhs
-0000e680: 5363 616c 6172 2a20 626c 422c 2047 4542  Scalar* blB, GEB
-0000e690: 5054 7261 6974 7320 7472 6169 7473 2c20  PTraits traits, 
-0000e6a0: 4c68 7350 6163 6b65 7420 2a41 302c 2052  LhsPacket *A0, R
-0000e6b0: 6873 5061 636b 6574 202a 425f 302c 2052  hsPacket *B_0, R
-0000e6c0: 6873 5061 636b 6574 202a 4231 2c20 5268  hsPacket *B1, Rh
-0000e6d0: 7350 6163 6b65 7420 2a42 322c 2052 6873  sPacket *B2, Rhs
-0000e6e0: 5061 636b 6574 202a 4233 2c20 4163 6350  Packet *B3, AccP
-0000e6f0: 6163 6b65 7420 2a43 302c 2041 6363 5061  acket *C0, AccPa
-0000e700: 636b 6574 202a 4331 2c20 4163 6350 6163  cket *C1, AccPac
-0000e710: 6b65 7420 2a43 322c 2041 6363 5061 636b  ket *C2, AccPack
-0000e720: 6574 202a 4333 290a 2020 7b0a 2020 2020  et *C3).  {.    
-0000e730: 2020 2020 4549 4745 4e5f 4153 4d5f 434f      EIGEN_ASM_CO
-0000e740: 4d4d 454e 5428 2262 6567 696e 2073 7465  MMENT("begin ste
-0000e750: 7020 6f66 2067 6562 7020 6d69 6372 6f20  p of gebp micro 
-0000e760: 6b65 726e 656c 2031 5834 2229 3b0a 2020  kernel 1X4");.  
-0000e770: 2020 2020 2020 4549 4745 4e5f 4153 4d5f        EIGEN_ASM_
-0000e780: 434f 4d4d 454e 5428 224e 6f74 653a 2074  COMMENT("Note: t
-0000e790: 6865 7365 2061 736d 2063 6f6d 6d65 6e74  hese asm comment
-0000e7a0: 7320 776f 726b 2061 726f 756e 6420 6275  s work around bu
-0000e7b0: 6720 3933 3521 2229 3b0a 2020 2020 2020  g 935!");.      
-0000e7c0: 2020 7472 6169 7473 2e6c 6f61 644c 6873    traits.loadLhs
-0000e7d0: 556e 616c 6967 6e65 6428 2662 6c41 5b28  Unaligned(&blA[(
-0000e7e0: 302b 312a 4b29 2a28 4c68 7350 726f 6772  0+1*K)*(LhsProgr
-0000e7f0: 6573 7329 5d2c 202a 4130 293b 0a20 2020  ess)], *A0);.   
-0000e800: 2020 2020 2074 7261 6974 732e 6272 6f61       traits.broa
-0000e810: 6463 6173 7452 6873 2826 626c 425b 2830  dcastRhs(&blB[(0
-0000e820: 2b34 2a4b 292a 5268 7350 726f 6772 6573  +4*K)*RhsProgres
-0000e830: 735d 2c20 2a42 5f30 2c20 2a42 312c 202a  s], *B_0, *B1, *
-0000e840: 4232 2c20 2a42 3329 3b0a 2020 2020 2020  B2, *B3);.      
-0000e850: 2020 7472 6169 7473 2e6d 6164 6428 2a41    traits.madd(*A
-0000e860: 302c 202a 425f 302c 202a 4330 2c20 2a42  0, *B_0, *C0, *B
-0000e870: 5f30 293b 0a20 2020 2020 2020 2074 7261  _0);.        tra
-0000e880: 6974 732e 6d61 6464 282a 4130 2c20 2a42  its.madd(*A0, *B
-0000e890: 312c 2020 2a43 312c 202a 4231 293b 0a20  1,  *C1, *B1);. 
-0000e8a0: 2020 2020 2020 2074 7261 6974 732e 6d61         traits.ma
-0000e8b0: 6464 282a 4130 2c20 2a42 322c 2020 2a43  dd(*A0, *B2,  *C
-0000e8c0: 322c 202a 4232 293b 0a20 2020 2020 2020  2, *B2);.       
-0000e8d0: 2074 7261 6974 732e 6d61 6464 282a 4130   traits.madd(*A0
-0000e8e0: 2c20 2a42 332c 2020 2a43 332c 202a 4233  , *B3,  *C3, *B3
-0000e8f0: 293b 0a20 2020 2020 2020 2045 4947 454e  );.        EIGEN
-0000e900: 5f41 534d 5f43 4f4d 4d45 4e54 2822 656e  _ASM_COMMENT("en
-0000e910: 6420 7374 6570 206f 6620 6765 6270 206d  d step of gebp m
-0000e920: 6963 726f 206b 6572 6e65 6c20 3158 3422  icro kernel 1X4"
-0000e930: 293b 0a20 207d 0a7d 3b0a 0a74 656d 706c  );.  }.};..templ
-0000e940: 6174 653c 7479 7065 6e61 6d65 204c 6873  ate<typename Lhs
-0000e950: 5363 616c 6172 2c20 7479 7065 6e61 6d65  Scalar, typename
-0000e960: 2052 6873 5363 616c 6172 2c20 7479 7065   RhsScalar, type
-0000e970: 6e61 6d65 2049 6e64 6578 2c20 7479 7065  name Index, type
-0000e980: 6e61 6d65 2044 6174 614d 6170 7065 722c  name DataMapper,
-0000e990: 2069 6e74 206d 722c 2069 6e74 206e 722c   int mr, int nr,
-0000e9a0: 2062 6f6f 6c20 436f 6e6a 7567 6174 654c   bool ConjugateL
-0000e9b0: 6873 2c20 626f 6f6c 2043 6f6e 6a75 6761  hs, bool Conjuga
-0000e9c0: 7465 5268 733e 0a45 4947 454e 5f44 4f4e  teRhs>.EIGEN_DON
-0000e9d0: 545f 494e 4c49 4e45 0a76 6f69 6420 6765  T_INLINE.void ge
-0000e9e0: 6270 5f6b 6572 6e65 6c3c 4c68 7353 6361  bp_kernel<LhsSca
-0000e9f0: 6c61 722c 5268 7353 6361 6c61 722c 496e  lar,RhsScalar,In
-0000ea00: 6465 782c 4461 7461 4d61 7070 6572 2c6d  dex,DataMapper,m
-0000ea10: 722c 6e72 2c43 6f6e 6a75 6761 7465 4c68  r,nr,ConjugateLh
-0000ea20: 732c 436f 6e6a 7567 6174 6552 6873 3e0a  s,ConjugateRhs>.
-0000ea30: 2020 3a3a 6f70 6572 6174 6f72 2829 2863    ::operator()(c
-0000ea40: 6f6e 7374 2044 6174 614d 6170 7065 7226  onst DataMapper&
-0000ea50: 2072 6573 2c20 636f 6e73 7420 4c68 7353   res, const LhsS
-0000ea60: 6361 6c61 722a 2062 6c6f 636b 412c 2063  calar* blockA, c
-0000ea70: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
-0000ea80: 626c 6f63 6b42 2c0a 2020 2020 2020 2020  blockB,.        
-0000ea90: 2020 2020 2020 2049 6e64 6578 2072 6f77         Index row
-0000eaa0: 732c 2049 6e64 6578 2064 6570 7468 2c20  s, Index depth, 
-0000eab0: 496e 6465 7820 636f 6c73 2c20 5265 7353  Index cols, ResS
-0000eac0: 6361 6c61 7220 616c 7068 612c 0a20 2020  calar alpha,.   
-0000ead0: 2020 2020 2020 2020 2020 2020 496e 6465              Inde
-0000eae0: 7820 7374 7269 6465 412c 2049 6e64 6578  x strideA, Index
-0000eaf0: 2073 7472 6964 6542 2c20 496e 6465 7820   strideB, Index 
-0000eb00: 6f66 6673 6574 412c 2049 6e64 6578 206f  offsetA, Index o
-0000eb10: 6666 7365 7442 290a 2020 7b0a 2020 2020  ffsetB).  {.    
-0000eb20: 5472 6169 7473 2074 7261 6974 733b 0a20  Traits traits;. 
-0000eb30: 2020 2053 7761 7070 6564 5472 6169 7473     SwappedTraits
-0000eb40: 2073 7472 6169 7473 3b0a 2020 2020 0a20   straits;.    . 
-0000eb50: 2020 2069 6628 7374 7269 6465 413d 3d2d     if(strideA==-
-0000eb60: 3129 2073 7472 6964 6541 203d 2064 6570  1) strideA = dep
-0000eb70: 7468 3b0a 2020 2020 6966 2873 7472 6964  th;.    if(strid
-0000eb80: 6542 3d3d 2d31 2920 7374 7269 6465 4220  eB==-1) strideB 
-0000eb90: 3d20 6465 7074 683b 0a20 2020 2063 6f6e  = depth;.    con
-0000eba0: 6a5f 6865 6c70 6572 3c4c 6873 5363 616c  j_helper<LhsScal
-0000ebb0: 6172 2c52 6873 5363 616c 6172 2c43 6f6e  ar,RhsScalar,Con
-0000ebc0: 6a75 6761 7465 4c68 732c 436f 6e6a 7567  jugateLhs,Conjug
-0000ebd0: 6174 6552 6873 3e20 636a 3b0a 2020 2020  ateRhs> cj;.    
-0000ebe0: 496e 6465 7820 7061 636b 6574 5f63 6f6c  Index packet_col
-0000ebf0: 7334 203d 206e 723e 3d34 203f 2028 636f  s4 = nr>=4 ? (co
-0000ec00: 6c73 2f34 2920 2a20 3420 3a20 303b 0a20  ls/4) * 4 : 0;. 
-0000ec10: 2020 2063 6f6e 7374 2049 6e64 6578 2070     const Index p
-0000ec20: 6565 6c65 645f 6d63 3320 3d20 6d72 3e3d  eeled_mc3 = mr>=
-0000ec30: 332a 5472 6169 7473 3a3a 4c68 7350 726f  3*Traits::LhsPro
-0000ec40: 6772 6573 7320 3f20 2872 6f77 732f 2833  gress ? (rows/(3
-0000ec50: 2a4c 6873 5072 6f67 7265 7373 2929 2a28  *LhsProgress))*(
-0000ec60: 332a 4c68 7350 726f 6772 6573 7329 203a  3*LhsProgress) :
-0000ec70: 2030 3b0a 2020 2020 636f 6e73 7420 496e   0;.    const In
-0000ec80: 6465 7820 7065 656c 6564 5f6d 6332 203d  dex peeled_mc2 =
-0000ec90: 206d 723e 3d32 2a54 7261 6974 733a 3a4c   mr>=2*Traits::L
-0000eca0: 6873 5072 6f67 7265 7373 203f 2070 6565  hsProgress ? pee
-0000ecb0: 6c65 645f 6d63 332b 2828 726f 7773 2d70  led_mc3+((rows-p
-0000ecc0: 6565 6c65 645f 6d63 3329 2f28 322a 4c68  eeled_mc3)/(2*Lh
-0000ecd0: 7350 726f 6772 6573 7329 292a 2832 2a4c  sProgress))*(2*L
-0000ece0: 6873 5072 6f67 7265 7373 2920 3a20 303b  hsProgress) : 0;
-0000ecf0: 0a20 2020 2063 6f6e 7374 2049 6e64 6578  .    const Index
-0000ed00: 2070 6565 6c65 645f 6d63 3120 3d20 6d72   peeled_mc1 = mr
-0000ed10: 3e3d 312a 5472 6169 7473 3a3a 4c68 7350  >=1*Traits::LhsP
-0000ed20: 726f 6772 6573 7320 3f20 7065 656c 6564  rogress ? peeled
-0000ed30: 5f6d 6332 2b28 2872 6f77 732d 7065 656c  _mc2+((rows-peel
-0000ed40: 6564 5f6d 6332 292f 2831 2a4c 6873 5072  ed_mc2)/(1*LhsPr
-0000ed50: 6f67 7265 7373 2929 2a28 312a 4c68 7350  ogress))*(1*LhsP
-0000ed60: 726f 6772 6573 7329 203a 2030 3b0a 2020  rogress) : 0;.  
-0000ed70: 2020 636f 6e73 7420 496e 6465 7820 7065    const Index pe
-0000ed80: 656c 6564 5f6d 635f 6861 6c66 203d 206d  eled_mc_half = m
-0000ed90: 723e 3d4c 6873 5072 6f67 7265 7373 4861  r>=LhsProgressHa
-0000eda0: 6c66 203f 2070 6565 6c65 645f 6d63 312b  lf ? peeled_mc1+
-0000edb0: 2828 726f 7773 2d70 6565 6c65 645f 6d63  ((rows-peeled_mc
-0000edc0: 3129 2f28 4c68 7350 726f 6772 6573 7348  1)/(LhsProgressH
-0000edd0: 616c 6629 292a 284c 6873 5072 6f67 7265  alf))*(LhsProgre
-0000ede0: 7373 4861 6c66 2920 3a20 303b 0a20 2020  ssHalf) : 0;.   
-0000edf0: 2063 6f6e 7374 2049 6e64 6578 2070 6565   const Index pee
-0000ee00: 6c65 645f 6d63 5f71 7561 7274 6572 203d  led_mc_quarter =
-0000ee10: 206d 723e 3d4c 6873 5072 6f67 7265 7373   mr>=LhsProgress
-0000ee20: 5175 6172 7465 7220 3f20 7065 656c 6564  Quarter ? peeled
-0000ee30: 5f6d 635f 6861 6c66 2b28 2872 6f77 732d  _mc_half+((rows-
-0000ee40: 7065 656c 6564 5f6d 635f 6861 6c66 292f  peeled_mc_half)/
-0000ee50: 284c 6873 5072 6f67 7265 7373 5175 6172  (LhsProgressQuar
-0000ee60: 7465 7229 292a 284c 6873 5072 6f67 7265  ter))*(LhsProgre
-0000ee70: 7373 5175 6172 7465 7229 203a 2030 3b0a  ssQuarter) : 0;.
-0000ee80: 2020 2020 656e 756d 207b 2070 6b20 3d20      enum { pk = 
-0000ee90: 3820 7d3b 202f 2f20 4e4f 5445 2053 7563  8 }; // NOTE Suc
-0000eea0: 6820 6120 6c61 7267 6520 7065 656c 696e  h a large peelin
-0000eeb0: 6720 6661 6374 6f72 2069 7320 696d 706f  g factor is impo
-0000eec0: 7274 616e 7420 666f 7220 6c61 7267 6520  rtant for large 
-0000eed0: 6d61 7472 6963 6573 2028 7e20 2b35 2520  matrices (~ +5% 
-0000eee0: 7768 656e 203e 3130 3030 206f 6e20 4861  when >1000 on Ha
-0000eef0: 7377 656c 6c29 0a20 2020 2063 6f6e 7374  swell).    const
-0000ef00: 2049 6e64 6578 2070 6565 6c65 645f 6b63   Index peeled_kc
-0000ef10: 2020 3d20 6465 7074 6820 2620 7e28 706b    = depth & ~(pk
-0000ef20: 2d31 293b 0a20 2020 2063 6f6e 7374 2069  -1);.    const i
-0000ef30: 6e74 2070 7265 6665 7463 685f 7265 735f  nt prefetch_res_
-0000ef40: 6f66 6673 6574 203d 2033 322f 7369 7a65  offset = 32/size
-0000ef50: 6f66 2852 6573 5363 616c 6172 293b 2020  of(ResScalar);  
-0000ef60: 2020 0a2f 2f20 2020 2020 636f 6e73 7420    .//     const 
-0000ef70: 496e 6465 7820 6465 7074 6832 2020 2020  Index depth2    
-0000ef80: 203d 2064 6570 7468 2026 207e 313b 0a0a   = depth & ~1;..
-0000ef90: 2020 2020 2f2f 2d2d 2d2d 2d2d 2d2d 2d2d      //----------
-0000efa0: 2050 726f 6365 7373 2033 202a 204c 6873   Process 3 * Lhs
-0000efb0: 5072 6f67 7265 7373 2072 6f77 7320 6174  Progress rows at
-0000efc0: 206f 6e63 6520 2d2d 2d2d 2d2d 2d2d 2d2d   once ----------
-0000efd0: 0a20 2020 202f 2f20 5468 6973 2063 6f72  .    // This cor
-0000efe0: 7265 7370 6f6e 6473 2074 6f20 332a 4c68  responds to 3*Lh
-0000eff0: 7350 726f 6772 6573 7320 7820 6e72 2072  sProgress x nr r
-0000f000: 6567 6973 7465 7220 626c 6f63 6b73 2e0a  egister blocks..
-0000f010: 2020 2020 2f2f 2055 7375 616c 6c79 2c20      // Usually, 
-0000f020: 6d61 6b65 2073 656e 7365 206f 6e6c 7920  make sense only 
-0000f030: 7769 7468 2046 4d41 0a20 2020 2069 6628  with FMA.    if(
-0000f040: 6d72 3e3d 332a 5472 6169 7473 3a3a 4c68  mr>=3*Traits::Lh
-0000f050: 7350 726f 6772 6573 7329 0a20 2020 207b  sProgress).    {
-0000f060: 0a20 2020 2020 202f 2f20 4865 7265 2c20  .      // Here, 
-0000f070: 7468 6520 6765 6e65 7261 6c20 6964 6561  the general idea
-0000f080: 2069 7320 746f 206c 6f6f 7020 6f6e 2065   is to loop on e
-0000f090: 6163 6820 6c61 7267 6573 7420 6d69 6372  ach largest micr
-0000f0a0: 6f20 686f 7269 7a6f 6e74 616c 2070 616e  o horizontal pan
-0000f0b0: 656c 206f 6620 7468 6520 6c68 7320 2833  el of the lhs (3
-0000f0c0: 2a54 7261 6974 733a 3a4c 6873 5072 6f67  *Traits::LhsProg
-0000f0d0: 7265 7373 2078 2064 6570 7468 290a 2020  ress x depth).  
-0000f0e0: 2020 2020 2f2f 2061 6e64 206f 6e20 6561      // and on ea
-0000f0f0: 6368 206c 6172 6765 7374 206d 6963 726f  ch largest micro
-0000f100: 2076 6572 7469 6361 6c20 7061 6e65 6c20   vertical panel 
-0000f110: 6f66 2074 6865 2072 6873 2028 6465 7074  of the rhs (dept
-0000f120: 6820 2a20 6e72 292e 0a20 2020 2020 202f  h * nr)..      /
-0000f130: 2f20 426c 6f63 6b69 6e67 2073 697a 6573  / Blocking sizes
-0000f140: 2c20 692e 652e 2c20 2764 6570 7468 2720  , i.e., 'depth' 
-0000f150: 6861 7320 6265 656e 2063 6f6d 7075 7465  has been compute
-0000f160: 6420 736f 2074 6861 7420 7468 6520 6d69  d so that the mi
-0000f170: 6372 6f20 686f 7269 7a6f 6e74 616c 2070  cro horizontal p
-0000f180: 616e 656c 206f 6620 7468 6520 6c68 7320  anel of the lhs 
-0000f190: 6669 7420 696e 204c 312e 0a20 2020 2020  fit in L1..     
-0000f1a0: 202f 2f20 486f 7765 7665 722c 2069 6620   // However, if 
-0000f1b0: 6465 7074 6820 6973 2074 6f6f 2073 6d61  depth is too sma
-0000f1c0: 6c6c 2c20 7765 2063 616e 2065 7874 656e  ll, we can exten
-0000f1d0: 6420 7468 6520 6e75 6d62 6572 206f 6620  d the number of 
-0000f1e0: 726f 7773 206f 6620 7468 6573 6520 686f  rows of these ho
-0000f1f0: 7269 7a6f 6e74 616c 2070 616e 656c 732e  rizontal panels.
-0000f200: 0a20 2020 2020 202f 2f20 5468 6973 2061  .      // This a
-0000f210: 6374 7561 6c20 6e75 6d62 6572 206f 6620  ctual number of 
-0000f220: 726f 7773 2069 7320 636f 6d70 7574 6564  rows is computed
-0000f230: 2061 7320 666f 6c6c 6f77 3a0a 2020 2020   as follow:.    
-0000f240: 2020 636f 6e73 7420 496e 6465 7820 6c31    const Index l1
-0000f250: 203d 2064 6566 6175 6c74 4c31 4361 6368   = defaultL1Cach
-0000f260: 6553 697a 653b 202f 2f20 696e 2042 7974  eSize; // in Byt
-0000f270: 6573 2c20 544f 444f 2c20 6c31 2073 686f  es, TODO, l1 sho
-0000f280: 756c 6420 6265 2070 6173 7365 6420 746f  uld be passed to
-0000f290: 2074 6869 7320 6675 6e63 7469 6f6e 2e0a   this function..
-0000f2a0: 2020 2020 2020 2f2f 2054 6865 206d 6178        // The max
-0000f2b0: 2831 2c20 2e2e 2e29 2068 6572 6520 6973  (1, ...) here is
-0000f2c0: 206e 6565 6465 6420 6265 6361 7573 6520   needed because 
-0000f2d0: 7765 206d 6179 2062 6520 7573 696e 6720  we may be using 
-0000f2e0: 626c 6f63 6b69 6e67 2070 6172 616d 7320  blocking params 
-0000f2f0: 6c61 7267 6572 2074 6861 6e20 7768 6174  larger than what
-0000f300: 206f 7572 206b 6e6f 776e 206c 3120 6361   our known l1 ca
-0000f310: 6368 6520 7369 7a65 0a20 2020 2020 202f  che size.      /
-0000f320: 2f20 7375 6767 6573 7473 2077 6520 7368  / suggests we sh
-0000f330: 6f75 6c64 2062 6520 7573 696e 673a 2065  ould be using: e
-0000f340: 6974 6865 7220 6265 6361 7573 6520 6f75  ither because ou
-0000f350: 7220 6b6e 6f77 6e20 6c31 2063 6163 6865  r known l1 cache
-0000f360: 2073 697a 6520 6973 2069 6e61 6363 7572   size is inaccur
-0000f370: 6174 6520 2865 2e67 2e20 6f6e 2041 6e64  ate (e.g. on And
-0000f380: 726f 6964 2c20 7765 2063 616e 206f 6e6c  roid, we can onl
-0000f390: 7920 6775 6573 7329 2c0a 2020 2020 2020  y guess),.      
-0000f3a0: 2f2f 206f 7220 6265 6361 7573 6520 7765  // or because we
-0000f3b0: 2061 7265 2074 6573 7469 6e67 2073 7065   are testing spe
-0000f3c0: 6369 6669 6320 626c 6f63 6b69 6e67 2073  cific blocking s
-0000f3d0: 697a 6573 2e0a 2020 2020 2020 636f 6e73  izes..      cons
-0000f3e0: 7420 496e 6465 7820 6163 7475 616c 5f70  t Index actual_p
-0000f3f0: 616e 656c 5f72 6f77 7320 3d20 2833 2a4c  anel_rows = (3*L
-0000f400: 6873 5072 6f67 7265 7373 2920 2a20 7374  hsProgress) * st
-0000f410: 643a 3a6d 6178 3c49 6e64 6578 3e28 312c  d::max<Index>(1,
-0000f420: 2820 286c 3120 2d20 7369 7a65 6f66 2852  ( (l1 - sizeof(R
-0000f430: 6573 5363 616c 6172 292a 6d72 2a6e 7220  esScalar)*mr*nr 
-0000f440: 2d20 6465 7074 682a 6e72 2a73 697a 656f  - depth*nr*sizeo
-0000f450: 6628 5268 7353 6361 6c61 7229 2920 2f20  f(RhsScalar)) / 
-0000f460: 2864 6570 7468 202a 2073 697a 656f 6628  (depth * sizeof(
-0000f470: 4c68 7353 6361 6c61 7229 202a 2033 2a4c  LhsScalar) * 3*L
-0000f480: 6873 5072 6f67 7265 7373 2920 2929 3b0a  hsProgress) ));.
-0000f490: 2020 2020 2020 666f 7228 496e 6465 7820        for(Index 
-0000f4a0: 6931 3d30 3b20 6931 3c70 6565 6c65 645f  i1=0; i1<peeled_
-0000f4b0: 6d63 333b 2069 312b 3d61 6374 7561 6c5f  mc3; i1+=actual_
-0000f4c0: 7061 6e65 6c5f 726f 7773 290a 2020 2020  panel_rows).    
-0000f4d0: 2020 7b0a 2020 2020 2020 2020 636f 6e73    {.        cons
-0000f4e0: 7420 496e 6465 7820 6163 7475 616c 5f70  t Index actual_p
-0000f4f0: 616e 656c 5f65 6e64 203d 2028 7374 643a  anel_end = (std:
-0000f500: 3a6d 696e 2928 6931 2b61 6374 7561 6c5f  :min)(i1+actual_
-0000f510: 7061 6e65 6c5f 726f 7773 2c20 7065 656c  panel_rows, peel
-0000f520: 6564 5f6d 6333 293b 0a20 2020 2020 2020  ed_mc3);.       
-0000f530: 2066 6f72 2849 6e64 6578 206a 323d 303b   for(Index j2=0;
-0000f540: 206a 323c 7061 636b 6574 5f63 6f6c 7334   j2<packet_cols4
-0000f550: 3b20 6a32 2b3d 6e72 290a 2020 2020 2020  ; j2+=nr).      
-0000f560: 2020 7b0a 2020 2020 2020 2020 2020 666f    {.          fo
-0000f570: 7228 496e 6465 7820 693d 6931 3b20 693c  r(Index i=i1; i<
-0000f580: 6163 7475 616c 5f70 616e 656c 5f65 6e64  actual_panel_end
-0000f590: 3b20 692b 3d33 2a4c 6873 5072 6f67 7265  ; i+=3*LhsProgre
-0000f5a0: 7373 290a 2020 2020 2020 2020 2020 7b0a  ss).          {.
-0000f5b0: 2020 2020 2020 2020 2020 0a20 2020 2020            .     
-0000f5c0: 2020 2020 202f 2f20 5765 2073 656c 6563       // We selec
-0000f5d0: 7465 6420 6120 332a 5472 6169 7473 3a3a  ted a 3*Traits::
-0000f5e0: 4c68 7350 726f 6772 6573 7320 7820 6e72  LhsProgress x nr
-0000f5f0: 206d 6963 726f 2062 6c6f 636b 206f 6620   micro block of 
-0000f600: 7265 7320 7768 6963 6820 6973 2065 6e74  res which is ent
-0000f610: 6972 656c 790a 2020 2020 2020 2020 2020  irely.          
-0000f620: 2f2f 2073 746f 7265 6420 696e 746f 2033  // stored into 3
-0000f630: 2078 206e 7220 7265 6769 7374 6572 732e   x nr registers.
-0000f640: 0a20 2020 2020 2020 2020 200a 2020 2020  .          .    
-0000f650: 2020 2020 2020 636f 6e73 7420 4c68 7353        const LhsS
-0000f660: 6361 6c61 722a 2062 6c41 203d 2026 626c  calar* blA = &bl
-0000f670: 6f63 6b41 5b69 2a73 7472 6964 6541 2b6f  ockA[i*strideA+o
-0000f680: 6666 7365 7441 2a28 332a 4c68 7350 726f  ffsetA*(3*LhsPro
-0000f690: 6772 6573 7329 5d3b 0a20 2020 2020 2020  gress)];.       
-0000f6a0: 2020 2070 7265 6665 7463 6828 2662 6c41     prefetch(&blA
-0000f6b0: 5b30 5d29 3b0a 0a20 2020 2020 2020 2020  [0]);..         
-0000f6c0: 202f 2f20 6765 7473 2072 6573 2062 6c6f   // gets res blo
-0000f6d0: 636b 2061 7320 7265 6769 7374 6572 0a20  ck as register. 
-0000f6e0: 2020 2020 2020 2020 2041 6363 5061 636b           AccPack
-0000f6f0: 6574 2043 302c 2043 312c 2043 322c 2020  et C0, C1, C2,  
-0000f700: 4333 2c0a 2020 2020 2020 2020 2020 2020  C3,.            
-0000f710: 2020 2020 2020 2020 4334 2c20 4335 2c20          C4, C5, 
-0000f720: 4336 2c20 2043 372c 0a20 2020 2020 2020  C6,  C7,.       
-0000f730: 2020 2020 2020 2020 2020 2020 2043 382c               C8,
-0000f740: 2043 392c 2043 3130 2c20 4331 313b 0a20   C9, C10, C11;. 
-0000f750: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-0000f760: 696e 6974 4163 6328 4330 293b 2020 7472  initAcc(C0);  tr
-0000f770: 6169 7473 2e69 6e69 7441 6363 2843 3129  aits.initAcc(C1)
-0000f780: 3b20 2074 7261 6974 732e 696e 6974 4163  ;  traits.initAc
-0000f790: 6328 4332 293b 2020 7472 6169 7473 2e69  c(C2);  traits.i
-0000f7a0: 6e69 7441 6363 2843 3329 3b0a 2020 2020  nitAcc(C3);.    
-0000f7b0: 2020 2020 2020 7472 6169 7473 2e69 6e69        traits.ini
-0000f7c0: 7441 6363 2843 3429 3b20 2074 7261 6974  tAcc(C4);  trait
-0000f7d0: 732e 696e 6974 4163 6328 4335 293b 2020  s.initAcc(C5);  
-0000f7e0: 7472 6169 7473 2e69 6e69 7441 6363 2843  traits.initAcc(C
-0000f7f0: 3629 3b20 2074 7261 6974 732e 696e 6974  6);  traits.init
-0000f800: 4163 6328 4337 293b 0a20 2020 2020 2020  Acc(C7);.       
-0000f810: 2020 2074 7261 6974 732e 696e 6974 4163     traits.initAc
-0000f820: 6328 4338 293b 2020 7472 6169 7473 2e69  c(C8);  traits.i
-0000f830: 6e69 7441 6363 2843 3929 3b20 2074 7261  nitAcc(C9);  tra
-0000f840: 6974 732e 696e 6974 4163 6328 4331 3029  its.initAcc(C10)
-0000f850: 3b20 7472 6169 7473 2e69 6e69 7441 6363  ; traits.initAcc
-0000f860: 2843 3131 293b 0a0a 2020 2020 2020 2020  (C11);..        
-0000f870: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
-0000f880: 3020 3d20 7265 732e 6765 744c 696e 6561  0 = res.getLinea
-0000f890: 724d 6170 7065 7228 692c 206a 3220 2b20  rMapper(i, j2 + 
-0000f8a0: 3029 3b0a 2020 2020 2020 2020 2020 4c69  0);.          Li
-0000f8b0: 6e65 6172 4d61 7070 6572 2072 3120 3d20  nearMapper r1 = 
-0000f8c0: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
-0000f8d0: 7065 7228 692c 206a 3220 2b20 3129 3b0a  per(i, j2 + 1);.
-0000f8e0: 2020 2020 2020 2020 2020 4c69 6e65 6172            Linear
-0000f8f0: 4d61 7070 6572 2072 3220 3d20 7265 732e  Mapper r2 = res.
-0000f900: 6765 744c 696e 6561 724d 6170 7065 7228  getLinearMapper(
-0000f910: 692c 206a 3220 2b20 3229 3b0a 2020 2020  i, j2 + 2);.    
-0000f920: 2020 2020 2020 4c69 6e65 6172 4d61 7070        LinearMapp
-0000f930: 6572 2072 3320 3d20 7265 732e 6765 744c  er r3 = res.getL
-0000f940: 696e 6561 724d 6170 7065 7228 692c 206a  inearMapper(i, j
-0000f950: 3220 2b20 3329 3b0a 0a20 2020 2020 2020  2 + 3);..       
-0000f960: 2020 2072 302e 7072 6566 6574 6368 2830     r0.prefetch(0
-0000f970: 293b 0a20 2020 2020 2020 2020 2072 312e  );.          r1.
-0000f980: 7072 6566 6574 6368 2830 293b 0a20 2020  prefetch(0);.   
-0000f990: 2020 2020 2020 2072 322e 7072 6566 6574         r2.prefet
-0000f9a0: 6368 2830 293b 0a20 2020 2020 2020 2020  ch(0);.         
-0000f9b0: 2072 332e 7072 6566 6574 6368 2830 293b   r3.prefetch(0);
-0000f9c0: 0a0a 2020 2020 2020 2020 2020 2f2f 2070  ..          // p
-0000f9d0: 6572 666f 726d 7320 2269 6e6e 6572 2220  erforms "inner" 
-0000f9e0: 7072 6f64 7563 7473 0a20 2020 2020 2020  products.       
-0000f9f0: 2020 2063 6f6e 7374 2052 6873 5363 616c     const RhsScal
-0000fa00: 6172 2a20 626c 4220 3d20 2662 6c6f 636b  ar* blB = &block
-0000fa10: 425b 6a32 2a73 7472 6964 6542 2b6f 6666  B[j2*strideB+off
-0000fa20: 7365 7442 2a6e 725d 3b0a 2020 2020 2020  setB*nr];.      
-0000fa30: 2020 2020 7072 6566 6574 6368 2826 626c      prefetch(&bl
-0000fa40: 425b 305d 293b 0a20 2020 2020 2020 2020  B[0]);.         
-0000fa50: 204c 6873 5061 636b 6574 2041 302c 2041   LhsPacket A0, A
-0000fa60: 313b 0a0a 2020 2020 2020 2020 2020 666f  1;..          fo
-0000fa70: 7228 496e 6465 7820 6b3d 303b 206b 3c70  r(Index k=0; k<p
-0000fa80: 6565 6c65 645f 6b63 3b20 6b2b 3d70 6b29  eeled_kc; k+=pk)
-0000fa90: 0a20 2020 2020 2020 2020 207b 0a20 2020  .          {.   
-0000faa0: 2020 2020 2020 2020 2045 4947 454e 5f41           EIGEN_A
-0000fab0: 534d 5f43 4f4d 4d45 4e54 2822 6265 6769  SM_COMMENT("begi
-0000fac0: 6e20 6765 6270 206d 6963 726f 206b 6572  n gebp micro ker
-0000fad0: 6e65 6c20 3370 5834 2229 3b0a 2020 2020  nel 3pX4");.    
-0000fae0: 2020 2020 2020 2020 2f2f 2031 3520 7265          // 15 re
-0000faf0: 6769 7374 6572 7320 6172 6520 7461 6b65  gisters are take
-0000fb00: 6e20 2831 3220 666f 7220 6163 632c 2032  n (12 for acc, 2
-0000fb10: 2066 6f72 206c 6873 292e 0a20 2020 2020   for lhs)..     
-0000fb20: 2020 2020 2020 2052 6873 5061 6e65 6c31         RhsPanel1
-0000fb30: 3520 7268 735f 7061 6e65 6c3b 0a20 2020  5 rhs_panel;.   
-0000fb40: 2020 2020 2020 2020 2052 6873 5061 636b           RhsPack
-0000fb50: 6574 2054 303b 0a20 2020 2020 2020 2020  et T0;.         
-0000fb60: 2020 204c 6873 5061 636b 6574 2041 323b     LhsPacket A2;
-0000fb70: 0a20 2020 2020 2020 2020 2020 2023 6966  .            #if
-0000fb80: 2045 4947 454e 5f43 4f4d 505f 474e 5543   EIGEN_COMP_GNUC
-0000fb90: 5f53 5452 4943 5420 2626 2045 4947 454e  _STRICT && EIGEN
-0000fba0: 5f41 5243 485f 4152 4d36 3420 2626 2064  _ARCH_ARM64 && d
-0000fbb0: 6566 696e 6564 2845 4947 454e 5f56 4543  efined(EIGEN_VEC
-0000fbc0: 544f 5249 5a45 5f4e 454f 4e29 2026 2620  TORIZE_NEON) && 
-0000fbd0: 2128 4549 4745 4e5f 474e 5543 5f41 545f  !(EIGEN_GNUC_AT_
-0000fbe0: 4c45 4153 5428 392c 3029 290a 2020 2020  LEAST(9,0)).    
-0000fbf0: 2020 2020 2020 2020 2f2f 2073 6565 2068          // see h
-0000fc00: 7474 703a 2f2f 6569 6765 6e2e 7475 7866  ttp://eigen.tuxf
-0000fc10: 616d 696c 792e 6f72 672f 627a 2f73 686f  amily.org/bz/sho
-0000fc20: 775f 6275 672e 6367 693f 6964 3d31 3633  w_bug.cgi?id=163
-0000fc30: 330a 2020 2020 2020 2020 2020 2020 2f2f  3.            //
-0000fc40: 2077 6974 686f 7574 2074 6869 7320 776f   without this wo
-0000fc50: 726b 6172 6f75 6e64 2041 302c 2041 312c  rkaround A0, A1,
-0000fc60: 2061 6e64 2041 3220 6172 6520 6c6f 6164   and A2 are load
-0000fc70: 6564 2069 6e20 7468 6520 7361 6d65 2072  ed in the same r
-0000fc80: 6567 6973 7465 722c 0a20 2020 2020 2020  egister,.       
-0000fc90: 2020 2020 202f 2f20 7768 6963 6820 6973       // which is
-0000fca0: 206e 6f74 2067 6f6f 6420 666f 7220 7069   not good for pi
-0000fcb0: 7065 6c69 6e69 6e67 0a20 2020 2020 2020  pelining.       
-0000fcc0: 2020 2020 2023 6465 6669 6e65 2045 4947       #define EIG
-0000fcd0: 454e 5f47 4542 505f 3350 5834 5f52 4547  EN_GEBP_3PX4_REG
-0000fce0: 4953 5445 525f 414c 4c4f 435f 574f 524b  ISTER_ALLOC_WORK
-0000fcf0: 4152 4f55 4e44 205f 5f61 736d 5f5f 2020  AROUND __asm__  
-0000fd00: 2822 2220 3a20 222b 772c 6d22 2028 4130  ("" : "+w,m" (A0
-0000fd10: 292c 2022 2b77 2c6d 2220 2841 3129 2c20  ), "+w,m" (A1), 
-0000fd20: 222b 772c 6d22 2028 4132 2929 3b0a 2020  "+w,m" (A2));.  
-0000fd30: 2020 2020 2020 2020 2020 2365 6c73 650a            #else.
-0000fd40: 2020 2020 2020 2020 2020 2020 2364 6566              #def
-0000fd50: 696e 6520 4549 4745 4e5f 4745 4250 5f33  ine EIGEN_GEBP_3
-0000fd60: 5058 345f 5245 4749 5354 4552 5f41 4c4c  PX4_REGISTER_ALL
-0000fd70: 4f43 5f57 4f52 4b41 524f 554e 440a 2020  OC_WORKAROUND.  
-0000fd80: 2020 2020 2020 2020 2020 2365 6e64 6966            #endif
-0000fd90: 0a23 6465 6669 6e65 2045 4947 454e 5f47  .#define EIGEN_G
-0000fda0: 4542 505f 4f4e 4553 5445 5028 4b29 2020  EBP_ONESTEP(K)  
-0000fdb0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fdc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fdd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fde0: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
-0000fdf0: 2064 6f20 7b20 2020 2020 2020 2020 2020   do {           
-0000fe00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fe10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fe20: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000fe30: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
-0000fe40: 2020 2020 2020 2045 4947 454e 5f41 534d         EIGEN_ASM
-0000fe50: 5f43 4f4d 4d45 4e54 2822 6265 6769 6e20  _COMMENT("begin 
-0000fe60: 7374 6570 206f 6620 6765 6270 206d 6963  step of gebp mic
-0000fe70: 726f 206b 6572 6e65 6c20 3370 5834 2229  ro kernel 3pX4")
-0000fe80: 3b20 2020 2020 2020 2020 205c 0a20 2020  ;          \.   
-0000fe90: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
-0000fea0: 5f41 534d 5f43 4f4d 4d45 4e54 2822 4e6f  _ASM_COMMENT("No
-0000feb0: 7465 3a20 7468 6573 6520 6173 6d20 636f  te: these asm co
-0000fec0: 6d6d 656e 7473 2077 6f72 6b20 6172 6f75  mments work arou
-0000fed0: 6e64 2062 7567 2039 3335 2122 293b 205c  nd bug 935!"); \
-0000fee0: 0a20 2020 2020 2020 2020 2020 2020 2069  .              i
-0000fef0: 6e74 6572 6e61 6c3a 3a70 7265 6665 7463  nternal::prefetc
-0000ff00: 6828 626c 4120 2b20 2833 202a 204b 202b  h(blA + (3 * K +
-0000ff10: 2031 3629 202a 204c 6873 5072 6f67 7265   16) * LhsProgre
-0000ff20: 7373 293b 2020 2020 2020 2020 2020 2020  ss);            
-0000ff30: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
-0000ff40: 2020 2069 6620 2845 4947 454e 5f41 5243     if (EIGEN_ARC
-0000ff50: 485f 4152 4d20 7c7c 2045 4947 454e 5f41  H_ARM || EIGEN_A
-0000ff60: 5243 485f 4d49 5053 2920 7b20 2020 2020  RCH_MIPS) {     
-0000ff70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0000ff80: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
-0000ff90: 2020 2020 2020 2020 2069 6e74 6572 6e61           interna
-0000ffa0: 6c3a 3a70 7265 6665 7463 6828 626c 4220  l::prefetch(blB 
-0000ffb0: 2b20 2834 202a 204b 202b 2031 3629 202a  + (4 * K + 16) *
-0000ffc0: 2052 6873 5072 6f67 7265 7373 293b 2020   RhsProgress);  
-0000ffd0: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
-0000ffe0: 2020 2020 2020 2020 2020 207d 202f 2a20             } /* 
-0000fff0: 4275 6720 3935 3320 2a2f 2020 2020 2020  Bug 953 */      
-00010000: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010010: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010020: 2020 2020 2020 2020 2020 2020 2020 205c                 \
-00010030: 0a20 2020 2020 2020 2020 2020 2020 2074  .              t
-00010040: 7261 6974 732e 6c6f 6164 4c68 7328 2662  raits.loadLhs(&b
-00010050: 6c41 5b28 3020 2b20 3320 2a20 4b29 202a  lA[(0 + 3 * K) *
-00010060: 204c 6873 5072 6f67 7265 7373 5d2c 2041   LhsProgress], A
-00010070: 3029 3b20 2020 2020 2020 2020 2020 2020  0);             
-00010080: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
-00010090: 2020 2074 7261 6974 732e 6c6f 6164 4c68     traits.loadLh
-000100a0: 7328 2662 6c41 5b28 3120 2b20 3320 2a20  s(&blA[(1 + 3 * 
-000100b0: 4b29 202a 204c 6873 5072 6f67 7265 7373  K) * LhsProgress
-000100c0: 5d2c 2041 3129 3b20 2020 2020 2020 2020  ], A1);         
-000100d0: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
-000100e0: 2020 2020 2020 2074 7261 6974 732e 6c6f         traits.lo
-000100f0: 6164 4c68 7328 2662 6c41 5b28 3220 2b20  adLhs(&blA[(2 + 
-00010100: 3320 2a20 4b29 202a 204c 6873 5072 6f67  3 * K) * LhsProg
-00010110: 7265 7373 5d2c 2041 3229 3b20 2020 2020  ress], A2);     
-00010120: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
-00010130: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
-00010140: 5f47 4542 505f 3350 5834 5f52 4547 4953  _GEBP_3PX4_REGIS
-00010150: 5445 525f 414c 4c4f 435f 574f 524b 4152  TER_ALLOC_WORKAR
-00010160: 4f55 4e44 205c 0a20 2020 2020 2020 2020  OUND \.         
-00010170: 2020 2020 2074 7261 6974 732e 6c6f 6164       traits.load
-00010180: 5268 7328 626c 4220 2b20 2830 2b34 2a4b  Rhs(blB + (0+4*K
-00010190: 2920 2a20 5472 6169 7473 3a3a 5268 7350  ) * Traits::RhsP
-000101a0: 726f 6772 6573 732c 2072 6873 5f70 616e  rogress, rhs_pan
-000101b0: 656c 293b 2020 2020 205c 0a20 2020 2020  el);     \.     
-000101c0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-000101d0: 6d61 6464 2841 302c 2072 6873 5f70 616e  madd(A0, rhs_pan
-000101e0: 656c 2c20 4330 2c20 5430 2c20 6669 783c  el, C0, T0, fix<
-000101f0: 303e 293b 2020 2020 2020 2020 2020 2020  0>);            
-00010200: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
-00010210: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-00010220: 6974 732e 6d61 6464 2841 312c 2072 6873  its.madd(A1, rhs
-00010230: 5f70 616e 656c 2c20 4334 2c20 5430 2c20  _panel, C4, T0, 
-00010240: 6669 783c 303e 293b 2020 2020 2020 2020  fix<0>);        
-00010250: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010260: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00010270: 2074 7261 6974 732e 6d61 6464 2841 322c   traits.madd(A2,
-00010280: 2072 6873 5f70 616e 656c 2c20 4338 2c20   rhs_panel, C8, 
-00010290: 5430 2c20 6669 783c 303e 293b 2020 2020  T0, fix<0>);    
-000102a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000102b0: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-000102c0: 2020 2020 2074 7261 6974 732e 7570 6461       traits.upda
-000102d0: 7465 5268 7328 626c 4220 2b20 2831 2b34  teRhs(blB + (1+4
-000102e0: 2a4b 2920 2a20 5472 6169 7473 3a3a 5268  *K) * Traits::Rh
-000102f0: 7350 726f 6772 6573 732c 2072 6873 5f70  sProgress, rhs_p
-00010300: 616e 656c 293b 2020 205c 0a20 2020 2020  anel);   \.     
-00010310: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-00010320: 6d61 6464 2841 302c 2072 6873 5f70 616e  madd(A0, rhs_pan
-00010330: 656c 2c20 4331 2c20 5430 2c20 6669 783c  el, C1, T0, fix<
-00010340: 313e 293b 2020 2020 2020 2020 2020 2020  1>);            
-00010350: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
-00010360: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-00010370: 6974 732e 6d61 6464 2841 312c 2072 6873  its.madd(A1, rhs
-00010380: 5f70 616e 656c 2c20 4335 2c20 5430 2c20  _panel, C5, T0, 
-00010390: 6669 783c 313e 293b 2020 2020 2020 2020  fix<1>);        
-000103a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000103b0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-000103c0: 2074 7261 6974 732e 6d61 6464 2841 322c   traits.madd(A2,
-000103d0: 2072 6873 5f70 616e 656c 2c20 4339 2c20   rhs_panel, C9, 
-000103e0: 5430 2c20 6669 783c 313e 293b 2020 2020  T0, fix<1>);    
-000103f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010400: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-00010410: 2020 2020 2074 7261 6974 732e 7570 6461       traits.upda
-00010420: 7465 5268 7328 626c 4220 2b20 2832 2b34  teRhs(blB + (2+4
-00010430: 2a4b 2920 2a20 5472 6169 7473 3a3a 5268  *K) * Traits::Rh
-00010440: 7350 726f 6772 6573 732c 2072 6873 5f70  sProgress, rhs_p
-00010450: 616e 656c 293b 2020 205c 0a20 2020 2020  anel);   \.     
-00010460: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-00010470: 6d61 6464 2841 302c 2072 6873 5f70 616e  madd(A0, rhs_pan
-00010480: 656c 2c20 4332 2c20 5430 2c20 6669 783c  el, C2, T0, fix<
-00010490: 323e 293b 2020 2020 2020 2020 2020 2020  2>);            
-000104a0: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
-000104b0: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-000104c0: 6974 732e 6d61 6464 2841 312c 2072 6873  its.madd(A1, rhs
-000104d0: 5f70 616e 656c 2c20 4336 2c20 5430 2c20  _panel, C6, T0, 
-000104e0: 6669 783c 323e 293b 2020 2020 2020 2020  fix<2>);        
-000104f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010500: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00010510: 2074 7261 6974 732e 6d61 6464 2841 322c   traits.madd(A2,
-00010520: 2072 6873 5f70 616e 656c 2c20 4331 302c   rhs_panel, C10,
-00010530: 2054 302c 2066 6978 3c32 3e29 3b20 2020   T0, fix<2>);   
-00010540: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010550: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-00010560: 2020 2020 2074 7261 6974 732e 7570 6461       traits.upda
-00010570: 7465 5268 7328 626c 4220 2b20 2833 2b34  teRhs(blB + (3+4
-00010580: 2a4b 2920 2a20 5472 6169 7473 3a3a 5268  *K) * Traits::Rh
-00010590: 7350 726f 6772 6573 732c 2072 6873 5f70  sProgress, rhs_p
-000105a0: 616e 656c 293b 2020 205c 0a20 2020 2020  anel);   \.     
-000105b0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-000105c0: 6d61 6464 2841 302c 2072 6873 5f70 616e  madd(A0, rhs_pan
-000105d0: 656c 2c20 4333 2c20 5430 2c20 6669 783c  el, C3, T0, fix<
-000105e0: 333e 293b 2020 2020 2020 2020 2020 2020  3>);            
-000105f0: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
-00010600: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-00010610: 6974 732e 6d61 6464 2841 312c 2072 6873  its.madd(A1, rhs
-00010620: 5f70 616e 656c 2c20 4337 2c20 5430 2c20  _panel, C7, T0, 
-00010630: 6669 783c 333e 293b 2020 2020 2020 2020  fix<3>);        
-00010640: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00010650: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00010660: 2074 7261 6974 732e 6d61 6464 2841 322c   traits.madd(A2,
-00010670: 2072 6873 5f70 616e 656c 2c20 4331 312c   rhs_panel, C11,
-00010680: 2054 302c 2066 6978 3c33 3e29 3b20 2020   T0, fix<3>);   
-00010690: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000106a0: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-000106b0: 2020 2020 2045 4947 454e 5f41 534d 5f43       EIGEN_ASM_C
-000106c0: 4f4d 4d45 4e54 2822 656e 6420 7374 6570  OMMENT("end step
-000106d0: 206f 6620 6765 6270 206d 6963 726f 206b   of gebp micro k
-000106e0: 6572 6e65 6c20 3370 5834 2229 3b20 2020  ernel 3pX4");   
-000106f0: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
-00010700: 2020 2020 2020 207d 2077 6869 6c65 2028         } while (
-00010710: 6661 6c73 6529 0a0a 2020 2020 2020 2020  false)..        
-00010720: 2020 2020 696e 7465 726e 616c 3a3a 7072      internal::pr
-00010730: 6566 6574 6368 2862 6c42 293b 0a20 2020  efetch(blB);.   
-00010740: 2020 2020 2020 2020 2045 4947 454e 5f47           EIGEN_G
-00010750: 4542 505f 4f4e 4553 5445 5028 3029 3b0a  EBP_ONESTEP(0);.
-00010760: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
-00010770: 4e5f 4745 4250 5f4f 4e45 5354 4550 2831  N_GEBP_ONESTEP(1
-00010780: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
-00010790: 4947 454e 5f47 4542 505f 4f4e 4553 5445  IGEN_GEBP_ONESTE
-000107a0: 5028 3229 3b0a 2020 2020 2020 2020 2020  P(2);.          
-000107b0: 2020 4549 4745 4e5f 4745 4250 5f4f 4e45    EIGEN_GEBP_ONE
-000107c0: 5354 4550 2833 293b 0a20 2020 2020 2020  STEP(3);.       
-000107d0: 2020 2020 2045 4947 454e 5f47 4542 505f       EIGEN_GEBP_
-000107e0: 4f4e 4553 5445 5028 3429 3b0a 2020 2020  ONESTEP(4);.    
-000107f0: 2020 2020 2020 2020 4549 4745 4e5f 4745          EIGEN_GE
-00010800: 4250 5f4f 4e45 5354 4550 2835 293b 0a20  BP_ONESTEP(5);. 
-00010810: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
-00010820: 5f47 4542 505f 4f4e 4553 5445 5028 3629  _GEBP_ONESTEP(6)
-00010830: 3b0a 2020 2020 2020 2020 2020 2020 4549  ;.            EI
-00010840: 4745 4e5f 4745 4250 5f4f 4e45 5354 4550  GEN_GEBP_ONESTEP
-00010850: 2837 293b 0a0a 2020 2020 2020 2020 2020  (7);..          
-00010860: 2020 626c 4220 2b3d 2070 6b2a 342a 5268    blB += pk*4*Rh
-00010870: 7350 726f 6772 6573 733b 0a20 2020 2020  sProgress;.     
-00010880: 2020 2020 2020 2062 6c41 202b 3d20 706b         blA += pk
-00010890: 2a33 2a54 7261 6974 733a 3a4c 6873 5072  *3*Traits::LhsPr
-000108a0: 6f67 7265 7373 3b0a 0a20 2020 2020 2020  ogress;..       
-000108b0: 2020 2020 2045 4947 454e 5f41 534d 5f43       EIGEN_ASM_C
-000108c0: 4f4d 4d45 4e54 2822 656e 6420 6765 6270  OMMENT("end gebp
-000108d0: 206d 6963 726f 206b 6572 6e65 6c20 3370   micro kernel 3p
-000108e0: 5834 2229 3b0a 2020 2020 2020 2020 2020  X4");.          
-000108f0: 7d0a 2020 2020 2020 2020 2020 2f2f 2070  }.          // p
-00010900: 726f 6365 7373 2072 656d 6169 6e69 6e67  rocess remaining
-00010910: 2070 6565 6c65 6420 6c6f 6f70 0a20 2020   peeled loop.   
-00010920: 2020 2020 2020 2066 6f72 2849 6e64 6578         for(Index
-00010930: 206b 3d70 6565 6c65 645f 6b63 3b20 6b3c   k=peeled_kc; k<
-00010940: 6465 7074 683b 206b 2b2b 290a 2020 2020  depth; k++).    
-00010950: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
-00010960: 2020 2020 5268 7350 616e 656c 3135 2072      RhsPanel15 r
-00010970: 6873 5f70 616e 656c 3b0a 2020 2020 2020  hs_panel;.      
-00010980: 2020 2020 2020 5268 7350 6163 6b65 7420        RhsPacket 
-00010990: 5430 3b0a 2020 2020 2020 2020 2020 2020  T0;.            
-000109a0: 4c68 7350 6163 6b65 7420 4132 3b0a 2020  LhsPacket A2;.  
-000109b0: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
-000109c0: 4745 4250 5f4f 4e45 5354 4550 2830 293b  GEBP_ONESTEP(0);
-000109d0: 0a20 2020 2020 2020 2020 2020 2062 6c42  .            blB
-000109e0: 202b 3d20 342a 5268 7350 726f 6772 6573   += 4*RhsProgres
-000109f0: 733b 0a20 2020 2020 2020 2020 2020 2062  s;.            b
-00010a00: 6c41 202b 3d20 332a 5472 6169 7473 3a3a  lA += 3*Traits::
-00010a10: 4c68 7350 726f 6772 6573 733b 0a20 2020  LhsProgress;.   
-00010a20: 2020 2020 2020 207d 0a0a 2375 6e64 6566         }..#undef
-00010a30: 2045 4947 454e 5f47 4542 505f 4f4e 4553   EIGEN_GEBP_ONES
-00010a40: 5445 500a 0a20 2020 2020 2020 2020 2052  TEP..          R
-00010a50: 6573 5061 636b 6574 2052 302c 2052 312c  esPacket R0, R1,
-00010a60: 2052 323b 0a20 2020 2020 2020 2020 2052   R2;.          R
-00010a70: 6573 5061 636b 6574 2061 6c70 6861 7620  esPacket alphav 
-00010a80: 3d20 7073 6574 313c 5265 7350 6163 6b65  = pset1<ResPacke
-00010a90: 743e 2861 6c70 6861 293b 0a0a 2020 2020  t>(alpha);..    
-00010aa0: 2020 2020 2020 5230 203d 2072 302e 7465        R0 = r0.te
-00010ab0: 6d70 6c61 7465 206c 6f61 6450 6163 6b65  mplate loadPacke
-00010ac0: 743c 5265 7350 6163 6b65 743e 2830 202a  t<ResPacket>(0 *
-00010ad0: 2054 7261 6974 733a 3a52 6573 5061 636b   Traits::ResPack
-00010ae0: 6574 5369 7a65 293b 0a20 2020 2020 2020  etSize);.       
-00010af0: 2020 2052 3120 3d20 7230 2e74 656d 706c     R1 = r0.templ
-00010b00: 6174 6520 6c6f 6164 5061 636b 6574 3c52  ate loadPacket<R
-00010b10: 6573 5061 636b 6574 3e28 3120 2a20 5472  esPacket>(1 * Tr
-00010b20: 6169 7473 3a3a 5265 7350 6163 6b65 7453  aits::ResPacketS
-00010b30: 697a 6529 3b0a 2020 2020 2020 2020 2020  ize);.          
-00010b40: 5232 203d 2072 302e 7465 6d70 6c61 7465  R2 = r0.template
-00010b50: 206c 6f61 6450 6163 6b65 743c 5265 7350   loadPacket<ResP
-00010b60: 6163 6b65 743e 2832 202a 2054 7261 6974  acket>(2 * Trait
-00010b70: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
-00010b80: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
-00010b90: 6974 732e 6163 6328 4330 2c20 616c 7068  its.acc(C0, alph
-00010ba0: 6176 2c20 5230 293b 0a20 2020 2020 2020  av, R0);.       
-00010bb0: 2020 2074 7261 6974 732e 6163 6328 4334     traits.acc(C4
-00010bc0: 2c20 616c 7068 6176 2c20 5231 293b 0a20  , alphav, R1);. 
-00010bd0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-00010be0: 6163 6328 4338 2c20 616c 7068 6176 2c20  acc(C8, alphav, 
-00010bf0: 5232 293b 0a20 2020 2020 2020 2020 2072  R2);.          r
-00010c00: 302e 7374 6f72 6550 6163 6b65 7428 3020  0.storePacket(0 
-00010c10: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
-00010c20: 6b65 7453 697a 652c 2052 3029 3b0a 2020  ketSize, R0);.  
-00010c30: 2020 2020 2020 2020 7230 2e73 746f 7265          r0.store
-00010c40: 5061 636b 6574 2831 202a 2054 7261 6974  Packet(1 * Trait
-00010c50: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
-00010c60: 2c20 5231 293b 0a20 2020 2020 2020 2020  , R1);.         
-00010c70: 2072 302e 7374 6f72 6550 6163 6b65 7428   r0.storePacket(
-00010c80: 3220 2a20 5472 6169 7473 3a3a 5265 7350  2 * Traits::ResP
-00010c90: 6163 6b65 7453 697a 652c 2052 3229 3b0a  acketSize, R2);.
-00010ca0: 0a20 2020 2020 2020 2020 2052 3020 3d20  .          R0 = 
-00010cb0: 7231 2e74 656d 706c 6174 6520 6c6f 6164  r1.template load
-00010cc0: 5061 636b 6574 3c52 6573 5061 636b 6574  Packet<ResPacket
-00010cd0: 3e28 3020 2a20 5472 6169 7473 3a3a 5265  >(0 * Traits::Re
-00010ce0: 7350 6163 6b65 7453 697a 6529 3b0a 2020  sPacketSize);.  
-00010cf0: 2020 2020 2020 2020 5231 203d 2072 312e          R1 = r1.
-00010d00: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
-00010d10: 6b65 743c 5265 7350 6163 6b65 743e 2831  ket<ResPacket>(1
-00010d20: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
-00010d30: 636b 6574 5369 7a65 293b 0a20 2020 2020  cketSize);.     
-00010d40: 2020 2020 2052 3220 3d20 7231 2e74 656d       R2 = r1.tem
-00010d50: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
-00010d60: 3c52 6573 5061 636b 6574 3e28 3220 2a20  <ResPacket>(2 * 
-00010d70: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
-00010d80: 7453 697a 6529 3b0a 2020 2020 2020 2020  tSize);.        
-00010d90: 2020 7472 6169 7473 2e61 6363 2843 312c    traits.acc(C1,
-00010da0: 2061 6c70 6861 762c 2052 3029 3b0a 2020   alphav, R0);.  
-00010db0: 2020 2020 2020 2020 7472 6169 7473 2e61          traits.a
-00010dc0: 6363 2843 352c 2061 6c70 6861 762c 2052  cc(C5, alphav, R
-00010dd0: 3129 3b0a 2020 2020 2020 2020 2020 7472  1);.          tr
-00010de0: 6169 7473 2e61 6363 2843 392c 2061 6c70  aits.acc(C9, alp
-00010df0: 6861 762c 2052 3229 3b0a 2020 2020 2020  hav, R2);.      
-00010e00: 2020 2020 7231 2e73 746f 7265 5061 636b      r1.storePack
-00010e10: 6574 2830 202a 2054 7261 6974 733a 3a52  et(0 * Traits::R
-00010e20: 6573 5061 636b 6574 5369 7a65 2c20 5230  esPacketSize, R0
-00010e30: 293b 0a20 2020 2020 2020 2020 2072 312e  );.          r1.
-00010e40: 7374 6f72 6550 6163 6b65 7428 3120 2a20  storePacket(1 * 
-00010e50: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
-00010e60: 7453 697a 652c 2052 3129 3b0a 2020 2020  tSize, R1);.    
-00010e70: 2020 2020 2020 7231 2e73 746f 7265 5061        r1.storePa
-00010e80: 636b 6574 2832 202a 2054 7261 6974 733a  cket(2 * Traits:
-00010e90: 3a52 6573 5061 636b 6574 5369 7a65 2c20  :ResPacketSize, 
-00010ea0: 5232 293b 0a0a 2020 2020 2020 2020 2020  R2);..          
-00010eb0: 5230 203d 2072 322e 7465 6d70 6c61 7465  R0 = r2.template
-00010ec0: 206c 6f61 6450 6163 6b65 743c 5265 7350   loadPacket<ResP
-00010ed0: 6163 6b65 743e 2830 202a 2054 7261 6974  acket>(0 * Trait
-00010ee0: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
-00010ef0: 293b 0a20 2020 2020 2020 2020 2052 3120  );.          R1 
-00010f00: 3d20 7232 2e74 656d 706c 6174 6520 6c6f  = r2.template lo
-00010f10: 6164 5061 636b 6574 3c52 6573 5061 636b  adPacket<ResPack
-00010f20: 6574 3e28 3120 2a20 5472 6169 7473 3a3a  et>(1 * Traits::
-00010f30: 5265 7350 6163 6b65 7453 697a 6529 3b0a  ResPacketSize);.
-00010f40: 2020 2020 2020 2020 2020 5232 203d 2072            R2 = r
-00010f50: 322e 7465 6d70 6c61 7465 206c 6f61 6450  2.template loadP
-00010f60: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
-00010f70: 2832 202a 2054 7261 6974 733a 3a52 6573  (2 * Traits::Res
-00010f80: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
-00010f90: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
-00010fa0: 6328 4332 2c20 616c 7068 6176 2c20 5230  c(C2, alphav, R0
-00010fb0: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
-00010fc0: 6974 732e 6163 6328 4336 2c20 616c 7068  its.acc(C6, alph
-00010fd0: 6176 2c20 5231 293b 0a20 2020 2020 2020  av, R1);.       
-00010fe0: 2020 2074 7261 6974 732e 6163 6328 4331     traits.acc(C1
-00010ff0: 302c 2061 6c70 6861 762c 2052 3229 3b0a  0, alphav, R2);.
-00011000: 2020 2020 2020 2020 2020 7232 2e73 746f            r2.sto
-00011010: 7265 5061 636b 6574 2830 202a 2054 7261  rePacket(0 * Tra
-00011020: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
-00011030: 7a65 2c20 5230 293b 0a20 2020 2020 2020  ze, R0);.       
-00011040: 2020 2072 322e 7374 6f72 6550 6163 6b65     r2.storePacke
-00011050: 7428 3120 2a20 5472 6169 7473 3a3a 5265  t(1 * Traits::Re
-00011060: 7350 6163 6b65 7453 697a 652c 2052 3129  sPacketSize, R1)
-00011070: 3b0a 2020 2020 2020 2020 2020 7232 2e73  ;.          r2.s
-00011080: 746f 7265 5061 636b 6574 2832 202a 2054  torePacket(2 * T
-00011090: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
-000110a0: 5369 7a65 2c20 5232 293b 0a0a 2020 2020  Size, R2);..    
-000110b0: 2020 2020 2020 5230 203d 2072 332e 7465        R0 = r3.te
-000110c0: 6d70 6c61 7465 206c 6f61 6450 6163 6b65  mplate loadPacke
-000110d0: 743c 5265 7350 6163 6b65 743e 2830 202a  t<ResPacket>(0 *
-000110e0: 2054 7261 6974 733a 3a52 6573 5061 636b   Traits::ResPack
-000110f0: 6574 5369 7a65 293b 0a20 2020 2020 2020  etSize);.       
-00011100: 2020 2052 3120 3d20 7233 2e74 656d 706c     R1 = r3.templ
-00011110: 6174 6520 6c6f 6164 5061 636b 6574 3c52  ate loadPacket<R
-00011120: 6573 5061 636b 6574 3e28 3120 2a20 5472  esPacket>(1 * Tr
-00011130: 6169 7473 3a3a 5265 7350 6163 6b65 7453  aits::ResPacketS
-00011140: 697a 6529 3b0a 2020 2020 2020 2020 2020  ize);.          
-00011150: 5232 203d 2072 332e 7465 6d70 6c61 7465  R2 = r3.template
-00011160: 206c 6f61 6450 6163 6b65 743c 5265 7350   loadPacket<ResP
-00011170: 6163 6b65 743e 2832 202a 2054 7261 6974  acket>(2 * Trait
-00011180: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
-00011190: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
-000111a0: 6974 732e 6163 6328 4333 2c20 616c 7068  its.acc(C3, alph
-000111b0: 6176 2c20 5230 293b 0a20 2020 2020 2020  av, R0);.       
-000111c0: 2020 2074 7261 6974 732e 6163 6328 4337     traits.acc(C7
-000111d0: 2c20 616c 7068 6176 2c20 5231 293b 0a20  , alphav, R1);. 
-000111e0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-000111f0: 6163 6328 4331 312c 2061 6c70 6861 762c  acc(C11, alphav,
-00011200: 2052 3229 3b0a 2020 2020 2020 2020 2020   R2);.          
-00011210: 7233 2e73 746f 7265 5061 636b 6574 2830  r3.storePacket(0
-00011220: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
-00011230: 636b 6574 5369 7a65 2c20 5230 293b 0a20  cketSize, R0);. 
-00011240: 2020 2020 2020 2020 2072 332e 7374 6f72           r3.stor
-00011250: 6550 6163 6b65 7428 3120 2a20 5472 6169  ePacket(1 * Trai
-00011260: 7473 3a3a 5265 7350 6163 6b65 7453 697a  ts::ResPacketSiz
-00011270: 652c 2052 3129 3b0a 2020 2020 2020 2020  e, R1);.        
-00011280: 2020 7233 2e73 746f 7265 5061 636b 6574    r3.storePacket
-00011290: 2832 202a 2054 7261 6974 733a 3a52 6573  (2 * Traits::Res
-000112a0: 5061 636b 6574 5369 7a65 2c20 5232 293b  PacketSize, R2);
-000112b0: 2020 2020 2020 2020 2020 0a20 2020 2020            .     
-000112c0: 2020 2020 207d 0a20 2020 2020 2020 207d       }.        }
-000112d0: 0a0a 2020 2020 2020 2020 2f2f 2044 6561  ..        // Dea
-000112e0: 6c20 7769 7468 2072 656d 6169 6e69 6e67  l with remaining
-000112f0: 2063 6f6c 756d 6e73 206f 6620 7468 6520   columns of the 
-00011300: 7268 730a 2020 2020 2020 2020 666f 7228  rhs.        for(
-00011310: 496e 6465 7820 6a32 3d70 6163 6b65 745f  Index j2=packet_
-00011320: 636f 6c73 343b 206a 323c 636f 6c73 3b20  cols4; j2<cols; 
-00011330: 6a32 2b2b 290a 2020 2020 2020 2020 7b0a  j2++).        {.
-00011340: 2020 2020 2020 2020 2020 666f 7228 496e            for(In
-00011350: 6465 7820 693d 6931 3b20 693c 6163 7475  dex i=i1; i<actu
-00011360: 616c 5f70 616e 656c 5f65 6e64 3b20 692b  al_panel_end; i+
-00011370: 3d33 2a4c 6873 5072 6f67 7265 7373 290a  =3*LhsProgress).
-00011380: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
-00011390: 2020 2020 2020 2f2f 204f 6e65 2063 6f6c        // One col
-000113a0: 756d 6e20 6174 2061 2074 696d 650a 2020  umn at a time.  
-000113b0: 2020 2020 2020 2020 636f 6e73 7420 4c68          const Lh
-000113c0: 7353 6361 6c61 722a 2062 6c41 203d 2026  sScalar* blA = &
-000113d0: 626c 6f63 6b41 5b69 2a73 7472 6964 6541  blockA[i*strideA
-000113e0: 2b6f 6666 7365 7441 2a28 332a 5472 6169  +offsetA*(3*Trai
-000113f0: 7473 3a3a 4c68 7350 726f 6772 6573 7329  ts::LhsProgress)
-00011400: 5d3b 0a20 2020 2020 2020 2020 2070 7265  ];.          pre
-00011410: 6665 7463 6828 2662 6c41 5b30 5d29 3b0a  fetch(&blA[0]);.
-00011420: 0a20 2020 2020 2020 2020 202f 2f20 6765  .          // ge
-00011430: 7473 2072 6573 2062 6c6f 636b 2061 7320  ts res block as 
-00011440: 7265 6769 7374 6572 0a20 2020 2020 2020  register.       
-00011450: 2020 2041 6363 5061 636b 6574 2043 302c     AccPacket C0,
-00011460: 2043 342c 2043 383b 0a20 2020 2020 2020   C4, C8;.       
-00011470: 2020 2074 7261 6974 732e 696e 6974 4163     traits.initAc
-00011480: 6328 4330 293b 0a20 2020 2020 2020 2020  c(C0);.         
-00011490: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
-000114a0: 4334 293b 0a20 2020 2020 2020 2020 2074  C4);.          t
-000114b0: 7261 6974 732e 696e 6974 4163 6328 4338  raits.initAcc(C8
-000114c0: 293b 0a0a 2020 2020 2020 2020 2020 4c69  );..          Li
-000114d0: 6e65 6172 4d61 7070 6572 2072 3020 3d20  nearMapper r0 = 
-000114e0: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
-000114f0: 7065 7228 692c 206a 3229 3b0a 2020 2020  per(i, j2);.    
-00011500: 2020 2020 2020 7230 2e70 7265 6665 7463        r0.prefetc
-00011510: 6828 3029 3b0a 0a20 2020 2020 2020 2020  h(0);..         
-00011520: 202f 2f20 7065 7266 6f72 6d73 2022 696e   // performs "in
-00011530: 6e65 7222 2070 726f 6475 6374 730a 2020  ner" products.  
-00011540: 2020 2020 2020 2020 636f 6e73 7420 5268          const Rh
-00011550: 7353 6361 6c61 722a 2062 6c42 203d 2026  sScalar* blB = &
-00011560: 626c 6f63 6b42 5b6a 322a 7374 7269 6465  blockB[j2*stride
-00011570: 422b 6f66 6673 6574 425d 3b0a 2020 2020  B+offsetB];.    
-00011580: 2020 2020 2020 4c68 7350 6163 6b65 7420        LhsPacket 
-00011590: 4130 2c20 4131 2c20 4132 3b0a 2020 2020  A0, A1, A2;.    
-000115a0: 2020 2020 2020 0a20 2020 2020 2020 2020        .         
-000115b0: 2066 6f72 2849 6e64 6578 206b 3d30 3b20   for(Index k=0; 
-000115c0: 6b3c 7065 656c 6564 5f6b 633b 206b 2b3d  k<peeled_kc; k+=
-000115d0: 706b 290a 2020 2020 2020 2020 2020 7b0a  pk).          {.
-000115e0: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
-000115f0: 4e5f 4153 4d5f 434f 4d4d 454e 5428 2262  N_ASM_COMMENT("b
-00011600: 6567 696e 2067 6562 7020 6d69 6372 6f20  egin gebp micro 
-00011610: 6b65 726e 656c 2033 7058 3122 293b 0a20  kernel 3pX1");. 
-00011620: 2020 2020 2020 2020 2020 2052 6873 5061             RhsPa
-00011630: 636b 6574 2042 5f30 3b0a 2364 6566 696e  cket B_0;.#defin
-00011640: 6520 4549 4745 4e5f 4745 4247 505f 4f4e  e EIGEN_GEBGP_ON
-00011650: 4553 5445 5028 4b29 2020 2020 2020 2020  ESTEP(K)        
-00011660: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011670: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011680: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
-00011690: 2020 2020 2020 2020 2020 646f 207b 2020            do {  
-000116a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000116b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000116c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000116d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000116e0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-000116f0: 4549 4745 4e5f 4153 4d5f 434f 4d4d 454e  EIGEN_ASM_COMMEN
-00011700: 5428 2262 6567 696e 2073 7465 7020 6f66  T("begin step of
-00011710: 2067 6562 7020 6d69 6372 6f20 6b65 726e   gebp micro kern
-00011720: 656c 2033 7058 3122 293b 2020 2020 2020  el 3pX1");      
-00011730: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
-00011740: 2020 2020 4549 4745 4e5f 4153 4d5f 434f      EIGEN_ASM_CO
-00011750: 4d4d 454e 5428 224e 6f74 653a 2074 6865  MMENT("Note: the
-00011760: 7365 2061 736d 2063 6f6d 6d65 6e74 7320  se asm comments 
-00011770: 776f 726b 2061 726f 756e 6420 6275 6720  work around bug 
-00011780: 3933 3521 2229 3b20 5c0a 2020 2020 2020  935!"); \.      
-00011790: 2020 2020 2020 2020 7472 6169 7473 2e6c          traits.l
-000117a0: 6f61 644c 6873 2826 626c 415b 2830 202b  oadLhs(&blA[(0 +
-000117b0: 2033 202a 204b 2920 2a20 4c68 7350 726f   3 * K) * LhsPro
-000117c0: 6772 6573 735d 2c20 4130 293b 2020 2020  gress], A0);    
-000117d0: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
-000117e0: 2020 2020 2020 2020 2020 2020 7472 6169              trai
-000117f0: 7473 2e6c 6f61 644c 6873 2826 626c 415b  ts.loadLhs(&blA[
-00011800: 2831 202b 2033 202a 204b 2920 2a20 4c68  (1 + 3 * K) * Lh
-00011810: 7350 726f 6772 6573 735d 2c20 4131 293b  sProgress], A1);
-00011820: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011830: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-00011840: 7472 6169 7473 2e6c 6f61 644c 6873 2826  traits.loadLhs(&
-00011850: 626c 415b 2832 202b 2033 202a 204b 2920  blA[(2 + 3 * K) 
-00011860: 2a20 4c68 7350 726f 6772 6573 735d 2c20  * LhsProgress], 
-00011870: 4132 293b 2020 2020 2020 2020 2020 2020  A2);            
-00011880: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
-00011890: 2020 2020 7472 6169 7473 2e6c 6f61 6452      traits.loadR
-000118a0: 6873 2826 626c 425b 2830 202b 204b 2920  hs(&blB[(0 + K) 
-000118b0: 2a20 5268 7350 726f 6772 6573 735d 2c20  * RhsProgress], 
-000118c0: 425f 3029 3b20 2020 2020 2020 2020 2020  B_0);           
-000118d0: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
-000118e0: 2020 2020 2020 2020 7472 6169 7473 2e6d          traits.m
-000118f0: 6164 6428 4130 2c20 425f 302c 2043 302c  add(A0, B_0, C0,
-00011900: 2042 5f30 2c20 6669 783c 303e 293b 2020   B_0, fix<0>);  
-00011910: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011920: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
-00011930: 2020 2020 2020 2020 2020 2020 7472 6169              trai
-00011940: 7473 2e6d 6164 6428 4131 2c20 425f 302c  ts.madd(A1, B_0,
-00011950: 2043 342c 2042 5f30 2c20 6669 783c 303e   C4, B_0, fix<0>
-00011960: 293b 2020 2020 2020 2020 2020 2020 2020  );              
-00011970: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00011980: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
-00011990: 7472 6169 7473 2e6d 6164 6428 4132 2c20  traits.madd(A2, 
-000119a0: 425f 302c 2043 382c 2042 5f30 2c20 6669  B_0, C8, B_0, fi
-000119b0: 783c 303e 293b 2020 2020 2020 2020 2020  x<0>);          
-000119c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-000119d0: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
-000119e0: 2020 2020 4549 4745 4e5f 4153 4d5f 434f      EIGEN_ASM_CO
-000119f0: 4d4d 454e 5428 2265 6e64 2073 7465 7020  MMENT("end step 
-00011a00: 6f66 2067 6562 7020 6d69 6372 6f20 6b65  of gebp micro ke
-00011a10: 726e 656c 2033 7058 3122 293b 2020 2020  rnel 3pX1");    
-00011a20: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
-00011a30: 2020 2020 2020 7d20 7768 696c 6520 2866        } while (f
-00011a40: 616c 7365 290a 0a20 2020 2020 2020 2020  alse)..         
-00011a50: 2020 2045 4947 454e 5f47 4542 4750 5f4f     EIGEN_GEBGP_O
-00011a60: 4e45 5354 4550 2830 293b 0a20 2020 2020  NESTEP(0);.     
-00011a70: 2020 2020 2020 2045 4947 454e 5f47 4542         EIGEN_GEB
-00011a80: 4750 5f4f 4e45 5354 4550 2831 293b 0a20  GP_ONESTEP(1);. 
-00011a90: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
-00011aa0: 5f47 4542 4750 5f4f 4e45 5354 4550 2832  _GEBGP_ONESTEP(2
-00011ab0: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
-00011ac0: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
-00011ad0: 4550 2833 293b 0a20 2020 2020 2020 2020  EP(3);.         
-00011ae0: 2020 2045 4947 454e 5f47 4542 4750 5f4f     EIGEN_GEBGP_O
-00011af0: 4e45 5354 4550 2834 293b 0a20 2020 2020  NESTEP(4);.     
-00011b00: 2020 2020 2020 2045 4947 454e 5f47 4542         EIGEN_GEB
-00011b10: 4750 5f4f 4e45 5354 4550 2835 293b 0a20  GP_ONESTEP(5);. 
-00011b20: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
-00011b30: 5f47 4542 4750 5f4f 4e45 5354 4550 2836  _GEBGP_ONESTEP(6
-00011b40: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
-00011b50: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
-00011b60: 4550 2837 293b 0a0a 2020 2020 2020 2020  EP(7);..        
-00011b70: 2020 2020 626c 4220 2b3d 2070 6b2a 5268      blB += pk*Rh
-00011b80: 7350 726f 6772 6573 733b 0a20 2020 2020  sProgress;.     
-00011b90: 2020 2020 2020 2062 6c41 202b 3d20 706b         blA += pk
-00011ba0: 2a33 2a54 7261 6974 733a 3a4c 6873 5072  *3*Traits::LhsPr
-00011bb0: 6f67 7265 7373 3b0a 0a20 2020 2020 2020  ogress;..       
-00011bc0: 2020 2020 2045 4947 454e 5f41 534d 5f43       EIGEN_ASM_C
-00011bd0: 4f4d 4d45 4e54 2822 656e 6420 6765 6270  OMMENT("end gebp
-00011be0: 206d 6963 726f 206b 6572 6e65 6c20 3370   micro kernel 3p
-00011bf0: 5831 2229 3b0a 2020 2020 2020 2020 2020  X1");.          
-00011c00: 7d0a 0a20 2020 2020 2020 2020 202f 2f20  }..          // 
-00011c10: 7072 6f63 6573 7320 7265 6d61 696e 696e  process remainin
-00011c20: 6720 7065 656c 6564 206c 6f6f 700a 2020  g peeled loop.  
-00011c30: 2020 2020 2020 2020 666f 7228 496e 6465          for(Inde
-00011c40: 7820 6b3d 7065 656c 6564 5f6b 633b 206b  x k=peeled_kc; k
-00011c50: 3c64 6570 7468 3b20 6b2b 2b29 0a20 2020  <depth; k++).   
-00011c60: 2020 2020 2020 207b 0a20 2020 2020 2020         {.       
-00011c70: 2020 2020 2052 6873 5061 636b 6574 2042       RhsPacket B
-00011c80: 5f30 3b0a 2020 2020 2020 2020 2020 2020  _0;.            
-00011c90: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
-00011ca0: 5445 5028 3029 3b0a 2020 2020 2020 2020  TEP(0);.        
-00011cb0: 2020 2020 626c 4220 2b3d 2052 6873 5072      blB += RhsPr
-00011cc0: 6f67 7265 7373 3b0a 2020 2020 2020 2020  ogress;.        
-00011cd0: 2020 2020 626c 4120 2b3d 2033 2a54 7261      blA += 3*Tra
-00011ce0: 6974 733a 3a4c 6873 5072 6f67 7265 7373  its::LhsProgress
-00011cf0: 3b0a 2020 2020 2020 2020 2020 7d0a 2375  ;.          }.#u
-00011d00: 6e64 6566 2045 4947 454e 5f47 4542 4750  ndef EIGEN_GEBGP
-00011d10: 5f4f 4e45 5354 4550 0a20 2020 2020 2020  _ONESTEP.       
-00011d20: 2020 2052 6573 5061 636b 6574 2052 302c     ResPacket R0,
-00011d30: 2052 312c 2052 323b 0a20 2020 2020 2020   R1, R2;.       
-00011d40: 2020 2052 6573 5061 636b 6574 2061 6c70     ResPacket alp
-00011d50: 6861 7620 3d20 7073 6574 313c 5265 7350  hav = pset1<ResP
-00011d60: 6163 6b65 743e 2861 6c70 6861 293b 0a0a  acket>(alpha);..
-00011d70: 2020 2020 2020 2020 2020 5230 203d 2072            R0 = r
-00011d80: 302e 7465 6d70 6c61 7465 206c 6f61 6450  0.template loadP
-00011d90: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
-00011da0: 2830 202a 2054 7261 6974 733a 3a52 6573  (0 * Traits::Res
-00011db0: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
-00011dc0: 2020 2020 2020 2052 3120 3d20 7230 2e74         R1 = r0.t
-00011dd0: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
-00011de0: 6574 3c52 6573 5061 636b 6574 3e28 3120  et<ResPacket>(1 
-00011df0: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
-00011e00: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
-00011e10: 2020 2020 5232 203d 2072 302e 7465 6d70      R2 = r0.temp
-00011e20: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
-00011e30: 5265 7350 6163 6b65 743e 2832 202a 2054  ResPacket>(2 * T
-00011e40: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
-00011e50: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
-00011e60: 2074 7261 6974 732e 6163 6328 4330 2c20   traits.acc(C0, 
-00011e70: 616c 7068 6176 2c20 5230 293b 0a20 2020  alphav, R0);.   
-00011e80: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
-00011e90: 6328 4334 2c20 616c 7068 6176 2c20 5231  c(C4, alphav, R1
-00011ea0: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
-00011eb0: 6974 732e 6163 6328 4338 2c20 616c 7068  its.acc(C8, alph
-00011ec0: 6176 2c20 5232 293b 0a20 2020 2020 2020  av, R2);.       
-00011ed0: 2020 2072 302e 7374 6f72 6550 6163 6b65     r0.storePacke
-00011ee0: 7428 3020 2a20 5472 6169 7473 3a3a 5265  t(0 * Traits::Re
-00011ef0: 7350 6163 6b65 7453 697a 652c 2052 3029  sPacketSize, R0)
-00011f00: 3b0a 2020 2020 2020 2020 2020 7230 2e73  ;.          r0.s
-00011f10: 746f 7265 5061 636b 6574 2831 202a 2054  torePacket(1 * T
-00011f20: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
-00011f30: 5369 7a65 2c20 5231 293b 0a20 2020 2020  Size, R1);.     
-00011f40: 2020 2020 2072 302e 7374 6f72 6550 6163       r0.storePac
-00011f50: 6b65 7428 3220 2a20 5472 6169 7473 3a3a  ket(2 * Traits::
-00011f60: 5265 7350 6163 6b65 7453 697a 652c 2052  ResPacketSize, R
-00011f70: 3229 3b20 2020 2020 2020 2020 200a 2020  2);          .  
-00011f80: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
-00011f90: 2020 7d0a 2020 2020 2020 7d0a 2020 2020    }.      }.    
-00011fa0: 7d0a 0a20 2020 202f 2f2d 2d2d 2d2d 2d2d  }..    //-------
-00011fb0: 2d2d 2d20 5072 6f63 6573 7320 3220 2a20  --- Process 2 * 
-00011fc0: 4c68 7350 726f 6772 6573 7320 726f 7773  LhsProgress rows
-00011fd0: 2061 7420 6f6e 6365 202d 2d2d 2d2d 2d2d   at once -------
-00011fe0: 2d2d 2d0a 2020 2020 6966 286d 723e 3d32  ---.    if(mr>=2
-00011ff0: 2a54 7261 6974 733a 3a4c 6873 5072 6f67  *Traits::LhsProg
-00012000: 7265 7373 290a 2020 2020 7b0a 2020 2020  ress).    {.    
-00012010: 2020 636f 6e73 7420 496e 6465 7820 6c31    const Index l1
-00012020: 203d 2064 6566 6175 6c74 4c31 4361 6368   = defaultL1Cach
-00012030: 6553 697a 653b 202f 2f20 696e 2042 7974  eSize; // in Byt
-00012040: 6573 2c20 544f 444f 2c20 6c31 2073 686f  es, TODO, l1 sho
-00012050: 756c 6420 6265 2070 6173 7365 6420 746f  uld be passed to
-00012060: 2074 6869 7320 6675 6e63 7469 6f6e 2e0a   this function..
-00012070: 2020 2020 2020 2f2f 2054 6865 206d 6178        // The max
-00012080: 2831 2c20 2e2e 2e29 2068 6572 6520 6973  (1, ...) here is
-00012090: 206e 6565 6465 6420 6265 6361 7573 6520   needed because 
-000120a0: 7765 206d 6179 2062 6520 7573 696e 6720  we may be using 
-000120b0: 626c 6f63 6b69 6e67 2070 6172 616d 7320  blocking params 
-000120c0: 6c61 7267 6572 2074 6861 6e20 7768 6174  larger than what
-000120d0: 206f 7572 206b 6e6f 776e 206c 3120 6361   our known l1 ca
-000120e0: 6368 6520 7369 7a65 0a20 2020 2020 202f  che size.      /
-000120f0: 2f20 7375 6767 6573 7473 2077 6520 7368  / suggests we sh
-00012100: 6f75 6c64 2062 6520 7573 696e 673a 2065  ould be using: e
-00012110: 6974 6865 7220 6265 6361 7573 6520 6f75  ither because ou
-00012120: 7220 6b6e 6f77 6e20 6c31 2063 6163 6865  r known l1 cache
-00012130: 2073 697a 6520 6973 2069 6e61 6363 7572   size is inaccur
-00012140: 6174 6520 2865 2e67 2e20 6f6e 2041 6e64  ate (e.g. on And
-00012150: 726f 6964 2c20 7765 2063 616e 206f 6e6c  roid, we can onl
-00012160: 7920 6775 6573 7329 2c0a 2020 2020 2020  y guess),.      
-00012170: 2f2f 206f 7220 6265 6361 7573 6520 7765  // or because we
-00012180: 2061 7265 2074 6573 7469 6e67 2073 7065   are testing spe
-00012190: 6369 6669 6320 626c 6f63 6b69 6e67 2073  cific blocking s
-000121a0: 697a 6573 2e0a 2020 2020 2020 496e 6465  izes..      Inde
-000121b0: 7820 6163 7475 616c 5f70 616e 656c 5f72  x actual_panel_r
-000121c0: 6f77 7320 3d20 2832 2a4c 6873 5072 6f67  ows = (2*LhsProg
-000121d0: 7265 7373 2920 2a20 7374 643a 3a6d 6178  ress) * std::max
-000121e0: 3c49 6e64 6578 3e28 312c 2820 286c 3120  <Index>(1,( (l1 
-000121f0: 2d20 7369 7a65 6f66 2852 6573 5363 616c  - sizeof(ResScal
-00012200: 6172 292a 6d72 2a6e 7220 2d20 6465 7074  ar)*mr*nr - dept
-00012210: 682a 6e72 2a73 697a 656f 6628 5268 7353  h*nr*sizeof(RhsS
-00012220: 6361 6c61 7229 2920 2f20 2864 6570 7468  calar)) / (depth
-00012230: 202a 2073 697a 656f 6628 4c68 7353 6361   * sizeof(LhsSca
-00012240: 6c61 7229 202a 2032 2a4c 6873 5072 6f67  lar) * 2*LhsProg
-00012250: 7265 7373 2920 2929 3b0a 0a20 2020 2020  ress) ));..     
-00012260: 2066 6f72 2849 6e64 6578 2069 313d 7065   for(Index i1=pe
-00012270: 656c 6564 5f6d 6333 3b20 6931 3c70 6565  eled_mc3; i1<pee
-00012280: 6c65 645f 6d63 323b 2069 312b 3d61 6374  led_mc2; i1+=act
-00012290: 7561 6c5f 7061 6e65 6c5f 726f 7773 290a  ual_panel_rows).
-000122a0: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
-000122b0: 496e 6465 7820 6163 7475 616c 5f70 616e  Index actual_pan
-000122c0: 656c 5f65 6e64 203d 2028 7374 643a 3a6d  el_end = (std::m
-000122d0: 696e 2928 6931 2b61 6374 7561 6c5f 7061  in)(i1+actual_pa
-000122e0: 6e65 6c5f 726f 7773 2c20 7065 656c 6564  nel_rows, peeled
-000122f0: 5f6d 6332 293b 0a20 2020 2020 2020 2066  _mc2);.        f
-00012300: 6f72 2849 6e64 6578 206a 323d 303b 206a  or(Index j2=0; j
-00012310: 323c 7061 636b 6574 5f63 6f6c 7334 3b20  2<packet_cols4; 
-00012320: 6a32 2b3d 6e72 290a 2020 2020 2020 2020  j2+=nr).        
-00012330: 7b0a 2020 2020 2020 2020 2020 666f 7228  {.          for(
-00012340: 496e 6465 7820 693d 6931 3b20 693c 6163  Index i=i1; i<ac
-00012350: 7475 616c 5f70 616e 656c 5f65 6e64 3b20  tual_panel_end; 
-00012360: 692b 3d32 2a4c 6873 5072 6f67 7265 7373  i+=2*LhsProgress
-00012370: 290a 2020 2020 2020 2020 2020 7b0a 2020  ).          {.  
-00012380: 2020 2020 2020 2020 0a20 2020 2020 2020          .       
-00012390: 2020 202f 2f20 5765 2073 656c 6563 7465     // We selecte
-000123a0: 6420 6120 322a 5472 6169 7473 3a3a 4c68  d a 2*Traits::Lh
-000123b0: 7350 726f 6772 6573 7320 7820 6e72 206d  sProgress x nr m
-000123c0: 6963 726f 2062 6c6f 636b 206f 6620 7265  icro block of re
-000123d0: 7320 7768 6963 6820 6973 2065 6e74 6972  s which is entir
-000123e0: 656c 790a 2020 2020 2020 2020 2020 2f2f  ely.          //
-000123f0: 2073 746f 7265 6420 696e 746f 2032 2078   stored into 2 x
-00012400: 206e 7220 7265 6769 7374 6572 732e 0a20   nr registers.. 
-00012410: 2020 2020 2020 2020 200a 2020 2020 2020           .      
-00012420: 2020 2020 636f 6e73 7420 4c68 7353 6361      const LhsSca
-00012430: 6c61 722a 2062 6c41 203d 2026 626c 6f63  lar* blA = &bloc
-00012440: 6b41 5b69 2a73 7472 6964 6541 2b6f 6666  kA[i*strideA+off
-00012450: 7365 7441 2a28 322a 5472 6169 7473 3a3a  setA*(2*Traits::
-00012460: 4c68 7350 726f 6772 6573 7329 5d3b 0a20  LhsProgress)];. 
-00012470: 2020 2020 2020 2020 2070 7265 6665 7463           prefetc
-00012480: 6828 2662 6c41 5b30 5d29 3b0a 0a20 2020  h(&blA[0]);..   
-00012490: 2020 2020 2020 202f 2f20 6765 7473 2072         // gets r
-000124a0: 6573 2062 6c6f 636b 2061 7320 7265 6769  es block as regi
-000124b0: 7374 6572 0a20 2020 2020 2020 2020 2041  ster.          A
-000124c0: 6363 5061 636b 6574 2043 302c 2043 312c  ccPacket C0, C1,
-000124d0: 2043 322c 2043 332c 0a20 2020 2020 2020   C2, C3,.       
-000124e0: 2020 2020 2020 2020 2020 2020 2043 342c               C4,
-000124f0: 2043 352c 2043 362c 2043 373b 0a20 2020   C5, C6, C7;.   
-00012500: 2020 2020 2020 2074 7261 6974 732e 696e         traits.in
-00012510: 6974 4163 6328 4330 293b 2074 7261 6974  itAcc(C0); trait
-00012520: 732e 696e 6974 4163 6328 4331 293b 2074  s.initAcc(C1); t
-00012530: 7261 6974 732e 696e 6974 4163 6328 4332  raits.initAcc(C2
-00012540: 293b 2074 7261 6974 732e 696e 6974 4163  ); traits.initAc
-00012550: 6328 4333 293b 0a20 2020 2020 2020 2020  c(C3);.         
-00012560: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
-00012570: 4334 293b 2074 7261 6974 732e 696e 6974  C4); traits.init
-00012580: 4163 6328 4335 293b 2074 7261 6974 732e  Acc(C5); traits.
-00012590: 696e 6974 4163 6328 4336 293b 2074 7261  initAcc(C6); tra
-000125a0: 6974 732e 696e 6974 4163 6328 4337 293b  its.initAcc(C7);
-000125b0: 0a0a 2020 2020 2020 2020 2020 4c69 6e65  ..          Line
-000125c0: 6172 4d61 7070 6572 2072 3020 3d20 7265  arMapper r0 = re
-000125d0: 732e 6765 744c 696e 6561 724d 6170 7065  s.getLinearMappe
-000125e0: 7228 692c 206a 3220 2b20 3029 3b0a 2020  r(i, j2 + 0);.  
-000125f0: 2020 2020 2020 2020 4c69 6e65 6172 4d61          LinearMa
-00012600: 7070 6572 2072 3120 3d20 7265 732e 6765  pper r1 = res.ge
-00012610: 744c 696e 6561 724d 6170 7065 7228 692c  tLinearMapper(i,
-00012620: 206a 3220 2b20 3129 3b0a 2020 2020 2020   j2 + 1);.      
-00012630: 2020 2020 4c69 6e65 6172 4d61 7070 6572      LinearMapper
-00012640: 2072 3220 3d20 7265 732e 6765 744c 696e   r2 = res.getLin
-00012650: 6561 724d 6170 7065 7228 692c 206a 3220  earMapper(i, j2 
-00012660: 2b20 3229 3b0a 2020 2020 2020 2020 2020  + 2);.          
-00012670: 4c69 6e65 6172 4d61 7070 6572 2072 3320  LinearMapper r3 
-00012680: 3d20 7265 732e 6765 744c 696e 6561 724d  = res.getLinearM
-00012690: 6170 7065 7228 692c 206a 3220 2b20 3329  apper(i, j2 + 3)
-000126a0: 3b0a 0a20 2020 2020 2020 2020 2072 302e  ;..          r0.
-000126b0: 7072 6566 6574 6368 2870 7265 6665 7463  prefetch(prefetc
-000126c0: 685f 7265 735f 6f66 6673 6574 293b 0a20  h_res_offset);. 
-000126d0: 2020 2020 2020 2020 2072 312e 7072 6566           r1.pref
-000126e0: 6574 6368 2870 7265 6665 7463 685f 7265  etch(prefetch_re
-000126f0: 735f 6f66 6673 6574 293b 0a20 2020 2020  s_offset);.     
-00012700: 2020 2020 2072 322e 7072 6566 6574 6368       r2.prefetch
-00012710: 2870 7265 6665 7463 685f 7265 735f 6f66  (prefetch_res_of
-00012720: 6673 6574 293b 0a20 2020 2020 2020 2020  fset);.         
-00012730: 2072 332e 7072 6566 6574 6368 2870 7265   r3.prefetch(pre
-00012740: 6665 7463 685f 7265 735f 6f66 6673 6574  fetch_res_offset
-00012750: 293b 0a0a 2020 2020 2020 2020 2020 2f2f  );..          //
-00012760: 2070 6572 666f 726d 7320 2269 6e6e 6572   performs "inner
-00012770: 2220 7072 6f64 7563 7473 0a20 2020 2020  " products.     
-00012780: 2020 2020 2063 6f6e 7374 2052 6873 5363       const RhsSc
-00012790: 616c 6172 2a20 626c 4220 3d20 2662 6c6f  alar* blB = &blo
-000127a0: 636b 425b 6a32 2a73 7472 6964 6542 2b6f  ckB[j2*strideB+o
-000127b0: 6666 7365 7442 2a6e 725d 3b0a 2020 2020  ffsetB*nr];.    
-000127c0: 2020 2020 2020 7072 6566 6574 6368 2826        prefetch(&
-000127d0: 626c 425b 305d 293b 0a20 2020 2020 2020  blB[0]);.       
-000127e0: 2020 204c 6873 5061 636b 6574 2041 302c     LhsPacket A0,
-000127f0: 2041 313b 0a0a 2020 2020 2020 2020 2020   A1;..          
-00012800: 666f 7228 496e 6465 7820 6b3d 303b 206b  for(Index k=0; k
-00012810: 3c70 6565 6c65 645f 6b63 3b20 6b2b 3d70  <peeled_kc; k+=p
-00012820: 6b29 0a20 2020 2020 2020 2020 207b 0a20  k).          {. 
-00012830: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
-00012840: 5f41 534d 5f43 4f4d 4d45 4e54 2822 6265  _ASM_COMMENT("be
-00012850: 6769 6e20 6765 6270 206d 6963 726f 206b  gin gebp micro k
-00012860: 6572 6e65 6c20 3270 5834 2229 3b0a 2020  ernel 2pX4");.  
-00012870: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
-00012880: 6b65 7478 3420 7268 735f 7061 6e65 6c3b  ketx4 rhs_panel;
-00012890: 0a20 2020 2020 2020 2020 2020 2052 6873  .            Rhs
-000128a0: 5061 636b 6574 2054 303b 0a0a 2020 2020  Packet T0;..    
-000128b0: 2020 2020 2020 2f2f 204e 4f54 453a 2074        // NOTE: t
-000128c0: 6865 2062 6567 696e 2f65 6e64 2061 736d  he begin/end asm
-000128d0: 2063 6f6d 6d65 6e74 7320 6265 6c6f 7720   comments below 
-000128e0: 776f 726b 2061 726f 756e 6420 6275 6720  work around bug 
-000128f0: 3933 3521 0a20 2020 2020 2020 2020 202f  935!.          /
-00012900: 2f20 6275 7420 7468 6579 2061 7265 206e  / but they are n
-00012910: 6f74 2065 6e6f 7567 6820 666f 7220 6763  ot enough for gc
-00012920: 633e 3d36 2077 6974 686f 7574 2046 4d41  c>=6 without FMA
-00012930: 2028 6275 6720 3136 3337 290a 2020 2020   (bug 1637).    
-00012940: 2020 2020 2020 2369 6620 4549 4745 4e5f        #if EIGEN_
-00012950: 474e 5543 5f41 545f 4c45 4153 5428 362c  GNUC_AT_LEAST(6,
-00012960: 3029 2026 2620 6465 6669 6e65 6428 4549  0) && defined(EI
-00012970: 4745 4e5f 5645 4354 4f52 495a 455f 5353  GEN_VECTORIZE_SS
-00012980: 4529 0a20 2020 2020 2020 2020 2020 2023  E).            #
-00012990: 6465 6669 6e65 2045 4947 454e 5f47 4542  define EIGEN_GEB
-000129a0: 505f 3250 5834 5f53 5049 4c4c 494e 475f  P_2PX4_SPILLING_
-000129b0: 574f 524b 4152 4f55 4e44 205f 5f61 736d  WORKAROUND __asm
-000129c0: 5f5f 2020 2822 2220 3a20 5b61 305d 2022  __  ("" : [a0] "
-000129d0: 2b78 2c6d 2220 2841 3029 2c5b 6131 5d20  +x,m" (A0),[a1] 
-000129e0: 222b 782c 6d22 2028 4131 2929 3b0a 2020  "+x,m" (A1));.  
-000129f0: 2020 2020 2020 2020 2365 6c73 650a 2020          #else.  
-00012a00: 2020 2020 2020 2020 2020 2364 6566 696e            #defin
-00012a10: 6520 4549 4745 4e5f 4745 4250 5f32 5058  e EIGEN_GEBP_2PX
-00012a20: 345f 5350 494c 4c49 4e47 5f57 4f52 4b41  4_SPILLING_WORKA
-00012a30: 524f 554e 440a 2020 2020 2020 2020 2020  ROUND.          
-00012a40: 2365 6e64 6966 0a23 6465 6669 6e65 2045  #endif.#define E
-00012a50: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
-00012a60: 4550 284b 2920 2020 2020 2020 2020 2020  EP(K)           
-00012a70: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012a80: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012a90: 205c 0a20 2020 2020 2020 2020 2020 2064   \.            d
-00012aa0: 6f20 7b20 2020 2020 2020 2020 2020 2020  o {             
-00012ab0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012ac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012ad0: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
-00012ae0: 2020 2020 2020 2020 2020 2020 2045 4947               EIG
-00012af0: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
-00012b00: 6265 6769 6e20 7374 6570 206f 6620 6765  begin step of ge
-00012b10: 6270 206d 6963 726f 206b 6572 6e65 6c20  bp micro kernel 
-00012b20: 3270 5834 2229 3b20 205c 0a20 2020 2020  2pX4");  \.     
-00012b30: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-00012b40: 6c6f 6164 4c68 7328 2662 6c41 5b28 3020  loadLhs(&blA[(0 
-00012b50: 2b20 3220 2a20 4b29 202a 204c 6873 5072  + 2 * K) * LhsPr
-00012b60: 6f67 7265 7373 5d2c 2041 3029 3b20 2020  ogress], A0);   
-00012b70: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-00012b80: 2020 2020 2074 7261 6974 732e 6c6f 6164       traits.load
-00012b90: 4c68 7328 2662 6c41 5b28 3120 2b20 3220  Lhs(&blA[(1 + 2 
-00012ba0: 2a20 4b29 202a 204c 6873 5072 6f67 7265  * K) * LhsProgre
-00012bb0: 7373 5d2c 2041 3129 3b20 2020 2020 2020  ss], A1);       
-00012bc0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00012bd0: 2074 7261 6974 732e 6c6f 6164 5268 7328   traits.loadRhs(
-00012be0: 2662 6c42 5b28 3020 2b20 3420 2a20 4b29  &blB[(0 + 4 * K)
-00012bf0: 202a 2052 6873 5072 6f67 7265 7373 5d2c   * RhsProgress],
-00012c00: 2072 6873 5f70 616e 656c 293b 205c 0a20   rhs_panel); \. 
-00012c10: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-00012c20: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
-00012c30: 5f70 616e 656c 2c20 4330 2c20 5430 2c20  _panel, C0, T0, 
-00012c40: 6669 783c 303e 293b 2020 2020 2020 2020  fix<0>);        
-00012c50: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
-00012c60: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-00012c70: 6d61 6464 2841 312c 2072 6873 5f70 616e  madd(A1, rhs_pan
-00012c80: 656c 2c20 4334 2c20 5430 2c20 6669 783c  el, C4, T0, fix<
-00012c90: 303e 293b 2020 2020 2020 2020 2020 2020  0>);            
-00012ca0: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-00012cb0: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
-00012cc0: 2841 302c 2072 6873 5f70 616e 656c 2c20  (A0, rhs_panel, 
-00012cd0: 4331 2c20 5430 2c20 6669 783c 313e 293b  C1, T0, fix<1>);
-00012ce0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012cf0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00012d00: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
-00012d10: 2072 6873 5f70 616e 656c 2c20 4335 2c20   rhs_panel, C5, 
-00012d20: 5430 2c20 6669 783c 313e 293b 2020 2020  T0, fix<1>);    
-00012d30: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
-00012d40: 2020 2020 2020 2020 2020 2020 2074 7261               tra
-00012d50: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
-00012d60: 5f70 616e 656c 2c20 4332 2c20 5430 2c20  _panel, C2, T0, 
-00012d70: 6669 783c 323e 293b 2020 2020 2020 2020  fix<2>);        
-00012d80: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
-00012d90: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
-00012da0: 6d61 6464 2841 312c 2072 6873 5f70 616e  madd(A1, rhs_pan
-00012db0: 656c 2c20 4336 2c20 5430 2c20 6669 783c  el, C6, T0, fix<
-00012dc0: 323e 293b 2020 2020 2020 2020 2020 2020  2>);            
-00012dd0: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
-00012de0: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
-00012df0: 2841 302c 2072 6873 5f70 616e 656c 2c20  (A0, rhs_panel, 
-00012e00: 4333 2c20 5430 2c20 6669 783c 333e 293b  C3, T0, fix<3>);
-00012e10: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012e20: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
-00012e30: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
-00012e40: 2072 6873 5f70 616e 656c 2c20 4337 2c20   rhs_panel, C7, 
-00012e50: 5430 2c20 6669 783c 333e 293b 2020 2020  T0, fix<3>);    
-00012e60: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
-00012e70: 2020 2020 2020 2020 2020 2020 2045 4947               EIG
-00012e80: 454e 5f47 4542 505f 3250 5834 5f53 5049  EN_GEBP_2PX4_SPI
-00012e90: 4c4c 494e 475f 574f 524b 4152 4f55 4e44  LLING_WORKAROUND
-00012ea0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00012eb0: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
-00012ec0: 2020 2020 2020 2020 2045 4947 454e 5f41           EIGEN_A
-00012ed0: 534d 5f43 4f4d 4d45 4e54 2822 656e 6420  SM_COMMENT("end 
-00012ee0: 7374 6570 206f 6620 6765 6270 206d 6963  step of gebp mic
-00012ef0: 726f 206b 6572 6e65 6c20 3270 5834 2229  ro kernel 2pX4")
-00012f00: 3b20 2020 205c 0a20 2020 2020 2020 2020  ;    \.         
-00012f10: 2020 207d 2077 6869 6c65 2028 6661 6c73     } while (fals
-00012f20: 6529 0a0a 2020 2020 2020 2020 2020 2020  e)..            
-00012f30: 696e 7465 726e 616c 3a3a 7072 6566 6574  internal::prefet
-00012f40: 6368 2862 6c42 2b28 3438 2b30 2929 3b0a  ch(blB+(48+0));.
-00012f50: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
-00012f60: 4e5f 4745 4247 505f 4f4e 4553 5445 5028  N_GEBGP_ONESTEP(
-00012f70: 3029 3b0a 2020 2020 2020 2020 2020 2020  0);.            
-00012f80: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
-00012f90: 5445 5028 3129 3b0a 2020 2020 2020 2020  TEP(1);.        
-00012fa0: 2020 2020 4549 4745 4e5f 4745 4247 505f      EIGEN_GEBGP_
-00012fb0: 4f4e 4553 5445 5028 3229 3b0a 2020 2020  ONESTEP(2);.    
-00012fc0: 2020 2020 2020 2020 4549 4745 4e5f 4745          EIGEN_GE
-00012fd0: 4247 505f 4f4e 4553 5445 5028 3329 3b0a  BGP_ONESTEP(3);.
-00012fe0: 2020 2020 2020 2020 2020 2020 696e 7465              inte
-00012ff0: 726e 616c 3a3a 7072 6566 6574 6368 2862  rnal::prefetch(b
-00013000: 6c42 2b28 3438 2b31 3629 293b 0a20 2020  lB+(48+16));.   
-00013010: 2020 2020 2020 2020 2045 4947 454e 5f47           EIGEN_G
-00013020: 4542 4750 5f4f 4e45 5354 4550 2834 293b  EBGP_ONESTEP(4);
-00013030: 0a20 2020 2020 2020 2020 2020 2045 4947  .            EIG
-00013040: 454e 5f47 4542 4750 5f4f 4e45 5354 4550  EN_GEBGP_ONESTEP
-00013050: 2835 293b 0a20 2020 2020 2020 2020 2020  (5);.           
-00013060: 2045 4947 454e 5f47 4542 4750 5f4f 4e45   EIGEN_GEBGP_ONE
-00013070: 5354 4550 2836 293b 0a20 2020 2020 2020  STEP(6);.       
-00013080: 2020 2020 2045 4947 454e 5f47 4542 4750       EIGEN_GEBGP
-00013090: 5f4f 4e45 5354 4550 2837 293b 0a0a 2020  _ONESTEP(7);..  
-000130a0: 2020 2020 2020 2020 2020 626c 4220 2b3d            blB +=
-000130b0: 2070 6b2a 342a 5268 7350 726f 6772 6573   pk*4*RhsProgres
-000130c0: 733b 0a20 2020 2020 2020 2020 2020 2062  s;.            b
-000130d0: 6c41 202b 3d20 706b 2a28 322a 5472 6169  lA += pk*(2*Trai
-000130e0: 7473 3a3a 4c68 7350 726f 6772 6573 7329  ts::LhsProgress)
-000130f0: 3b0a 0a20 2020 2020 2020 2020 2020 2045  ;..            E
-00013100: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
-00013110: 2822 656e 6420 6765 6270 206d 6963 726f  ("end gebp micro
-00013120: 206b 6572 6e65 6c20 3270 5834 2229 3b0a   kernel 2pX4");.
-00013130: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
-00013140: 2020 2020 2020 2f2f 2070 726f 6365 7373        // process
-00013150: 2072 656d 6169 6e69 6e67 2070 6565 6c65   remaining peele
-00013160: 6420 6c6f 6f70 0a20 2020 2020 2020 2020  d loop.         
-00013170: 2066 6f72 2849 6e64 6578 206b 3d70 6565   for(Index k=pee
-00013180: 6c65 645f 6b63 3b20 6b3c 6465 7074 683b  led_kc; k<depth;
-00013190: 206b 2b2b 290a 2020 2020 2020 2020 2020   k++).          
-000131a0: 7b0a 2020 2020 2020 2020 2020 2020 5268  {.            Rh
-000131b0: 7350 6163 6b65 7478 3420 7268 735f 7061  sPacketx4 rhs_pa
-000131c0: 6e65 6c3b 0a20 2020 2020 2020 2020 2020  nel;.           
-000131d0: 2052 6873 5061 636b 6574 2054 303b 0a20   RhsPacket T0;. 
-000131e0: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
-000131f0: 5f47 4542 4750 5f4f 4e45 5354 4550 2830  _GEBGP_ONESTEP(0
-00013200: 293b 0a20 2020 2020 2020 2020 2020 2062  );.            b
-00013210: 6c42 202b 3d20 342a 5268 7350 726f 6772  lB += 4*RhsProgr
-00013220: 6573 733b 0a20 2020 2020 2020 2020 2020  ess;.           
-00013230: 2062 6c41 202b 3d20 322a 5472 6169 7473   blA += 2*Traits
-00013240: 3a3a 4c68 7350 726f 6772 6573 733b 0a20  ::LhsProgress;. 
-00013250: 2020 2020 2020 2020 207d 0a23 756e 6465           }.#unde
-00013260: 6620 4549 4745 4e5f 4745 4247 505f 4f4e  f EIGEN_GEBGP_ON
-00013270: 4553 5445 500a 0a20 2020 2020 2020 2020  ESTEP..         
-00013280: 2052 6573 5061 636b 6574 2052 302c 2052   ResPacket R0, R
-00013290: 312c 2052 322c 2052 333b 0a20 2020 2020  1, R2, R3;.     
-000132a0: 2020 2020 2052 6573 5061 636b 6574 2061       ResPacket a
-000132b0: 6c70 6861 7620 3d20 7073 6574 313c 5265  lphav = pset1<Re
-000132c0: 7350 6163 6b65 743e 2861 6c70 6861 293b  sPacket>(alpha);
-000132d0: 0a0a 2020 2020 2020 2020 2020 5230 203d  ..          R0 =
-000132e0: 2072 302e 7465 6d70 6c61 7465 206c 6f61   r0.template loa
-000132f0: 6450 6163 6b65 743c 5265 7350 6163 6b65  dPacket<ResPacke
-00013300: 743e 2830 202a 2054 7261 6974 733a 3a52  t>(0 * Traits::R
-00013310: 6573 5061 636b 6574 5369 7a65 293b 0a20  esPacketSize);. 
-00013320: 2020 2020 2020 2020 2052 3120 3d20 7230           R1 = r0
-00013330: 2e74 656d 706c 6174 6520 6c6f 6164 5061  .template loadPa
-00013340: 636b 6574 3c52 6573 5061 636b 6574 3e28  cket<ResPacket>(
-00013350: 3120 2a20 5472 6169 7473 3a3a 5265 7350  1 * Traits::ResP
-00013360: 6163 6b65 7453 697a 6529 3b0a 2020 2020  acketSize);.    
-00013370: 2020 2020 2020 5232 203d 2072 312e 7465        R2 = r1.te
-00013380: 6d70 6c61 7465 206c 6f61 6450 6163 6b65  mplate loadPacke
-00013390: 743c 5265 7350 6163 6b65 743e 2830 202a  t<ResPacket>(0 *
-000133a0: 2054 7261 6974 733a 3a52 6573 5061 636b   Traits::ResPack
-000133b0: 6574 5369 7a65 293b 0a20 2020 2020 2020  etSize);.       
-000133c0: 2020 2052 3320 3d20 7231 2e74 656d 706c     R3 = r1.templ
-000133d0: 6174 6520 6c6f 6164 5061 636b 6574 3c52  ate loadPacket<R
-000133e0: 6573 5061 636b 6574 3e28 3120 2a20 5472  esPacket>(1 * Tr
-000133f0: 6169 7473 3a3a 5265 7350 6163 6b65 7453  aits::ResPacketS
-00013400: 697a 6529 3b0a 2020 2020 2020 2020 2020  ize);.          
-00013410: 7472 6169 7473 2e61 6363 2843 302c 2061  traits.acc(C0, a
-00013420: 6c70 6861 762c 2052 3029 3b0a 2020 2020  lphav, R0);.    
-00013430: 2020 2020 2020 7472 6169 7473 2e61 6363        traits.acc
-00013440: 2843 342c 2061 6c70 6861 762c 2052 3129  (C4, alphav, R1)
-00013450: 3b0a 2020 2020 2020 2020 2020 7472 6169  ;.          trai
-00013460: 7473 2e61 6363 2843 312c 2061 6c70 6861  ts.acc(C1, alpha
-00013470: 762c 2052 3229 3b0a 2020 2020 2020 2020  v, R2);.        
-00013480: 2020 7472 6169 7473 2e61 6363 2843 352c    traits.acc(C5,
-00013490: 2061 6c70 6861 762c 2052 3329 3b0a 2020   alphav, R3);.  
-000134a0: 2020 2020 2020 2020 7230 2e73 746f 7265          r0.store
-000134b0: 5061 636b 6574 2830 202a 2054 7261 6974  Packet(0 * Trait
-000134c0: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
-000134d0: 2c20 5230 293b 0a20 2020 2020 2020 2020  , R0);.         
-000134e0: 2072 302e 7374 6f72 6550 6163 6b65 7428   r0.storePacket(
-000134f0: 3120 2a20 5472 6169 7473 3a3a 5265 7350  1 * Traits::ResP
-00013500: 6163 6b65 7453 697a 652c 2052 3129 3b0a  acketSize, R1);.
-00013510: 2020 2020 2020 2020 2020 7231 2e73 746f            r1.sto
-00013520: 7265 5061 636b 6574 2830 202a 2054 7261  rePacket(0 * Tra
-00013530: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
-00013540: 7a65 2c20 5232 293b 0a20 2020 2020 2020  ze, R2);.       
-00013550: 2020 2072 312e 7374 6f72 6550 6163 6b65     r1.storePacke
-00013560: 7428 3120 2a20 5472 6169 7473 3a3a 5265  t(1 * Traits::Re
-00013570: 7350 6163 6b65 7453 697a 652c 2052 3329  sPacketSize, R3)
-00013580: 3b0a 0a20 2020 2020 2020 2020 2052 3020  ;..          R0 
-00013590: 3d20 7232 2e74 656d 706c 6174 6520 6c6f  = r2.template lo
-000135a0: 6164 5061 636b 6574 3c52 6573 5061 636b  adPacket<ResPack
-000135b0: 6574 3e28 3020 2a20 5472 6169 7473 3a3a  et>(0 * Traits::
-000135c0: 5265 7350 6163 6b65 7453 697a 6529 3b0a  ResPacketSize);.
-000135d0: 2020 2020 2020 2020 2020 5231 203d 2072            R1 = r
-000135e0: 322e 7465 6d70 6c61 7465 206c 6f61 6450  2.template loadP
-000135f0: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
-00013600: 2831 202a 2054 7261 6974 733a 3a52 6573  (1 * Traits::Res
-00013610: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
-00013620: 2020 2020 2020 2052 3220 3d20 7233 2e74         R2 = r3.t
-00013630: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
-00013640: 6574 3c52 6573 5061 636b 6574 3e28 3020  et<ResPacket>(0 
-00013650: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
-00013660: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
-00013670: 2020 2020 5233 203d 2072 332e 7465 6d70      R3 = r3.temp
-00013680: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
-00013690: 5265 7350 6163 6b65 743e 2831 202a 2054  ResPacket>(1 * T
-000136a0: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
-000136b0: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
-000136c0: 2074 7261 6974 732e 6163 6328 4332 2c20   traits.acc(C2, 
-000136d0: 2061 6c70 6861 762c 2052 3029 3b0a 2020   alphav, R0);.  
-000136e0: 2020 2020 2020 2020 7472 6169 7473 2e61          traits.a
-000136f0: 6363 2843 362c 2020 616c 7068 6176 2c20  cc(C6,  alphav, 
-00013700: 5231 293b 0a20 2020 2020 2020 2020 2074  R1);.          t
-00013710: 7261 6974 732e 6163 6328 4333 2c20 2061  raits.acc(C3,  a
-00013720: 6c70 6861 762c 2052 3229 3b0a 2020 2020  lphav, R2);.    
-00013730: 2020 2020 2020 7472 6169 7473 2e61 6363        traits.acc
-00013740: 2843 372c 2020 616c 7068 6176 2c20 5233  (C7,  alphav, R3
-00013750: 293b 0a20 2020 2020 2020 2020 2072 322e  );.          r2.
-00013760: 7374 6f72 6550 6163 6b65 7428 3020 2a20  storePacket(0 * 
-00013770: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
-00013780: 7453 697a 652c 2052 3029 3b0a 2020 2020  tSize, R0);.    
-00013790: 2020 2020 2020 7232 2e73 746f 7265 5061        r2.storePa
-000137a0: 636b 6574 2831 202a 2054 7261 6974 733a  cket(1 * Traits:
-000137b0: 3a52 6573 5061 636b 6574 5369 7a65 2c20  :ResPacketSize, 
-000137c0: 5231 293b 0a20 2020 2020 2020 2020 2072  R1);.          r
-000137d0: 332e 7374 6f72 6550 6163 6b65 7428 3020  3.storePacket(0 
-000137e0: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
-000137f0: 6b65 7453 697a 652c 2052 3229 3b0a 2020  ketSize, R2);.  
-00013800: 2020 2020 2020 2020 7233 2e73 746f 7265          r3.store
-00013810: 5061 636b 6574 2831 202a 2054 7261 6974  Packet(1 * Trait
-00013820: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
-00013830: 2c20 5233 293b 0a20 2020 2020 2020 2020  , R3);.         
-00013840: 207d 0a20 2020 2020 2020 207d 0a20 2020   }.        }.   
-00013850: 2020 200a 2020 2020 2020 2020 2f2f 2044     .        // D
-00013860: 6561 6c20 7769 7468 2072 656d 6169 6e69  eal with remaini
-00013870: 6e67 2063 6f6c 756d 6e73 206f 6620 7468  ng columns of th
-00013880: 6520 7268 730a 2020 2020 2020 2020 666f  e rhs.        fo
-00013890: 7228 496e 6465 7820 6a32 3d70 6163 6b65  r(Index j2=packe
-000138a0: 745f 636f 6c73 343b 206a 323c 636f 6c73  t_cols4; j2<cols
-000138b0: 3b20 6a32 2b2b 290a 2020 2020 2020 2020  ; j2++).        
-000138c0: 7b0a 2020 2020 2020 2020 2020 666f 7228  {.          for(
-000138d0: 496e 6465 7820 693d 6931 3b20 693c 6163  Index i=i1; i<ac
-000138e0: 7475 616c 5f70 616e 656c 5f65 6e64 3b20  tual_panel_end; 
-000138f0: 692b 3d32 2a4c 6873 5072 6f67 7265 7373  i+=2*LhsProgress
-00013900: 290a 2020 2020 2020 2020 2020 7b0a 2020  ).          {.  
-00013910: 2020 2020 2020 2020 2f2f 204f 6e65 2063          // One c
-00013920: 6f6c 756d 6e20 6174 2061 2074 696d 650a  olumn at a time.
-00013930: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
-00013940: 4c68 7353 6361 6c61 722a 2062 6c41 203d  LhsScalar* blA =
-00013950: 2026 626c 6f63 6b41 5b69 2a73 7472 6964   &blockA[i*strid
-00013960: 6541 2b6f 6666 7365 7441 2a28 322a 5472  eA+offsetA*(2*Tr
-00013970: 6169 7473 3a3a 4c68 7350 726f 6772 6573  aits::LhsProgres
-00013980: 7329 5d3b 0a20 2020 2020 2020 2020 2070  s)];.          p
-00013990: 7265 6665 7463 6828 2662 6c41 5b30 5d29  refetch(&blA[0])
-000139a0: 3b0a 0a20 2020 2020 2020 2020 202f 2f20  ;..          // 
-000139b0: 6765 7473 2072 6573 2062 6c6f 636b 2061  gets res block a
-000139c0: 7320 7265 6769 7374 6572 0a20 2020 2020  s register.     
-000139d0: 2020 2020 2041 6363 5061 636b 6574 2043       AccPacket C
-000139e0: 302c 2043 343b 0a20 2020 2020 2020 2020  0, C4;.         
-000139f0: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
-00013a00: 4330 293b 0a20 2020 2020 2020 2020 2074  C0);.          t
-00013a10: 7261 6974 732e 696e 6974 4163 6328 4334  raits.initAcc(C4
-00013a20: 293b 0a0a 2020 2020 2020 2020 2020 4c69  );..          Li
-00013a30: 6e65 6172 4d61 7070 6572 2072 3020 3d20  nearMapper r0 = 
-00013a40: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
-00013a50: 7065 7228 692c 206a 3229 3b0a 2020 2020  per(i, j2);.    
-00013a60: 2020 2020 2020 7230 2e70 7265 6665 7463        r0.prefetc
-00013a70: 6828 7072 6566 6574 6368 5f72 6573 5f6f  h(prefetch_res_o
-00013a80: 6666 7365 7429 3b0a 0a20 2020 2020 2020  ffset);..       
-00013a90: 2020 202f 2f20 7065 7266 6f72 6d73 2022     // performs "
-00013aa0: 696e 6e65 7222 2070 726f 6475 6374 730a  inner" products.
-00013ab0: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
-00013ac0: 5268 7353 6361 6c61 722a 2062 6c42 203d  RhsScalar* blB =
-00013ad0: 2026 626c 6f63 6b42 5b6a 322a 7374 7269   &blockB[j2*stri
-00013ae0: 6465 422b 6f66 6673 6574 425d 3b0a 2020  deB+offsetB];.  
-00013af0: 2020 2020 2020 2020 4c68 7350 6163 6b65          LhsPacke
-00013b00: 7420 4130 2c20 4131 3b0a 0a20 2020 2020  t A0, A1;..     
-00013b10: 2020 2020 2066 6f72 2849 6e64 6578 206b       for(Index k
-00013b20: 3d30 3b20 6b3c 7065 656c 6564 5f6b 633b  =0; k<peeled_kc;
-00013b30: 206b 2b3d 706b 290a 2020 2020 2020 2020   k+=pk).        
-00013b40: 2020 7b0a 2020 2020 2020 2020 2020 2020    {.            
-00013b50: 4549 4745 4e5f 4153 4d5f 434f 4d4d 454e  EIGEN_ASM_COMMEN
-00013b60: 5428 2262 6567 696e 2067 6562 7020 6d69  T("begin gebp mi
-00013b70: 6372 6f20 6b65 726e 656c 2032 7058 3122  cro kernel 2pX1"
-00013b80: 293b 0a20 2020 2020 2020 2020 2020 2052  );.            R
-00013b90: 6873 5061 636b 6574 2042 5f30 2c20 4231  hsPacket B_0, B1
-00013ba0: 3b0a 2020 2020 2020 2020 0a23 6465 6669  ;.        .#defi
-00013bb0: 6e65 2045 4947 454e 5f47 4542 4750 5f4f  ne EIGEN_GEBGP_O
-00013bc0: 4e45 5354 4550 284b 2920 5c0a 2020 2020  NESTEP(K) \.    
-00013bd0: 2020 2020 2020 2020 646f 207b 2020 2020          do {    
-00013be0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013bf0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013c00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013c10: 2020 2020 2020 2020 2020 2020 2020 5c0a                \.
-00013c20: 2020 2020 2020 2020 2020 2020 2020 4549                EI
-00013c30: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
-00013c40: 2262 6567 696e 2073 7465 7020 6f66 2067  "begin step of g
-00013c50: 6562 7020 6d69 6372 6f20 6b65 726e 656c  ebp micro kernel
-00013c60: 2032 7058 3122 293b 2020 2020 2020 2020   2pX1");        
-00013c70: 2020 5c0a 2020 2020 2020 2020 2020 2020    \.            
-00013c80: 2020 4549 4745 4e5f 4153 4d5f 434f 4d4d    EIGEN_ASM_COMM
-00013c90: 454e 5428 224e 6f74 653a 2074 6865 7365  ENT("Note: these
-00013ca0: 2061 736d 2063 6f6d 6d65 6e74 7320 776f   asm comments wo
-00013cb0: 726b 2061 726f 756e 6420 6275 6720 3933  rk around bug 93
-00013cc0: 3521 2229 3b20 5c0a 2020 2020 2020 2020  5!"); \.        
-00013cd0: 2020 2020 2020 7472 6169 7473 2e6c 6f61        traits.loa
-00013ce0: 644c 6873 2826 626c 415b 2830 2b32 2a4b  dLhs(&blA[(0+2*K
-00013cf0: 292a 4c68 7350 726f 6772 6573 735d 2c20  )*LhsProgress], 
-00013d00: 4130 293b 2020 2020 2020 2020 2020 2020  A0);            
-00013d10: 2020 2020 2020 2020 2020 5c0a 2020 2020            \.    
-00013d20: 2020 2020 2020 2020 2020 7472 6169 7473            traits
-00013d30: 2e6c 6f61 644c 6873 2826 626c 415b 2831  .loadLhs(&blA[(1
-00013d40: 2b32 2a4b 292a 4c68 7350 726f 6772 6573  +2*K)*LhsProgres
-00013d50: 735d 2c20 4131 293b 2020 2020 2020 2020  s], A1);        
-00013d60: 2020 2020 2020 2020 2020 2020 2020 5c0a                \.
-00013d70: 2020 2020 2020 2020 2020 2020 2020 7472                tr
-00013d80: 6169 7473 2e6c 6f61 6452 6873 2826 626c  aits.loadRhs(&bl
-00013d90: 425b 2830 2b4b 292a 5268 7350 726f 6772  B[(0+K)*RhsProgr
-00013da0: 6573 735d 2c20 425f 3029 3b20 2020 2020  ess], B_0);     
-00013db0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013dc0: 2020 5c0a 2020 2020 2020 2020 2020 2020    \.            
-00013dd0: 2020 7472 6169 7473 2e6d 6164 6428 4130    traits.madd(A0
-00013de0: 2c20 425f 302c 2043 302c 2042 312c 2066  , B_0, C0, B1, f
-00013df0: 6978 3c30 3e29 3b20 2020 2020 2020 2020  ix<0>);         
-00013e00: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013e10: 2020 2020 2020 5c0a 2020 2020 2020 2020        \.        
-00013e20: 2020 2020 2020 7472 6169 7473 2e6d 6164        traits.mad
-00013e30: 6428 4131 2c20 425f 302c 2043 342c 2042  d(A1, B_0, C4, B
-00013e40: 5f30 2c20 6669 783c 303e 293b 2020 2020  _0, fix<0>);    
-00013e50: 2020 2020 2020 2020 2020 2020 2020 2020                  
-00013e60: 2020 2020 2020 2020 2020 5c0a 2020 2020            \.    
-00013e70: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
-00013e80: 4153 4d5f 434f 4d4d 454e 5428 2265 6e64  ASM_COMMENT("end
-00013e90: 2073 7465 7020 6f66 2067 6562 7020 6d69   step of gebp mi
-00013ea0: 6372 6f20 6b65 726e 656c 2032 7058 3122  cro kernel 2pX1"
-00013eb0: 293b 2020 2020 2020 2020 2020 2020 5c0a  );            \.
-00013ec0: 2020 2020 2020 2020 2020 2020 7d20 7768              } wh
-00013ed0: 696c 6528 6661 6c73 6529 0a20 2020 2020  ile(false).     
-00013ee0: 2020 200a 2020 2020 2020 2020 2020 2020     .            
-00013ef0: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
-00013f00: 5445 5028 3029 3b0a 2020 2020 2020 2020  TEP(0);.        
-00013f10: 2020 2020 4549 4745 4e5f 4745 4247 505f      EIGEN_GEBGP_
-00013f20: 4f4e 4553 5445 5028 3129 3b0a 2020 2020  ONESTEP(1);.    
-00013f30: 2020 2020 2020 2020 4549 4745 4e5f 4745          EIGEN_GE
-00013f40: 4247 505f 4f4e 4553 5445 5028 3229 3b0a  BGP_ONESTEP(2);.
-00013f50: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
-00013f60: 4e5f 4745 4247 505f 4f4e 4553 5445 5028  N_GEBGP_ONESTEP(
-00013f70: 3329 3b0a 2020 2020 2020 2020 2020 2020  3);.            
-00013f80: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
-00013f90: 5445 5028 3429 3b0a 2020 2020 2020 2020  TEP(4);.        
-00013fa0: 2020 2020 4549 4745 4e5f 4745 4247 505f      EIGEN_GEBGP_
-00013fb0: 4f4e 4553 5445 5028 3529 3b0a 2020 2020  ONESTEP(5);.    
-00013fc0: 2020 2020 2020 2020 4549 4745 4e5f 4745          EIGEN_GE
-00013fd0: 4247 505f 4f4e 4553 5445 5028 3629 3b0a  BGP_ONESTEP(6);.
-00013fe0: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
-00013ff0: 4e5f 4745 4247 505f 4f4e 4553 5445 5028  N_GEBGP_ONESTEP(
-00014000: 3729 3b0a 0a20 2020 2020 2020 2020 2020  7);..           
-00014010: 2062 6c42 202b 3d20 706b 2a52 6873 5072   blB += pk*RhsPr
-00014020: 6f67 7265 7373 3b0a 2020 2020 2020 2020  ogress;.        
-00014030: 2020 2020 626c 4120 2b3d 2070 6b2a 322a      blA += pk*2*
-00014040: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
-00014050: 6573 733b 0a0a 2020 2020 2020 2020 2020  ess;..          
-00014060: 2020 4549 4745 4e5f 4153 4d5f 434f 4d4d    EIGEN_ASM_COMM
-00014070: 454e 5428 2265 6e64 2067 6562 7020 6d69  ENT("end gebp mi
-00014080: 6372 6f20 6b65 726e 656c 2032 7058 3122  cro kernel 2pX1"
-00014090: 293b 0a20 2020 2020 2020 2020 207d 0a0a  );.          }..
-000140a0: 2020 2020 2020 2020 2020 2f2f 2070 726f            // pro
-000140b0: 6365 7373 2072 656d 6169 6e69 6e67 2070  cess remaining p
-000140c0: 6565 6c65 6420 6c6f 6f70 0a20 2020 2020  eeled loop.     
-000140d0: 2020 2020 2066 6f72 2849 6e64 6578 206b       for(Index k
-000140e0: 3d70 6565 6c65 645f 6b63 3b20 6b3c 6465  =peeled_kc; k<de
-000140f0: 7074 683b 206b 2b2b 290a 2020 2020 2020  pth; k++).      
-00014100: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
-00014110: 2020 5268 7350 6163 6b65 7420 425f 302c    RhsPacket B_0,
-00014120: 2042 313b 0a20 2020 2020 2020 2020 2020   B1;.           
-00014130: 2045 4947 454e 5f47 4542 4750 5f4f 4e45   EIGEN_GEBGP_ONE
-00014140: 5354 4550 2830 293b 0a20 2020 2020 2020  STEP(0);.       
-00014150: 2020 2020 2062 6c42 202b 3d20 5268 7350       blB += RhsP
-00014160: 726f 6772 6573 733b 0a20 2020 2020 2020  rogress;.       
-00014170: 2020 2020 2062 6c41 202b 3d20 322a 5472       blA += 2*Tr
-00014180: 6169 7473 3a3a 4c68 7350 726f 6772 6573  aits::LhsProgres
-00014190: 733b 0a20 2020 2020 2020 2020 207d 0a23  s;.          }.#
-000141a0: 756e 6465 6620 4549 4745 4e5f 4745 4247  undef EIGEN_GEBG
-000141b0: 505f 4f4e 4553 5445 500a 2020 2020 2020  P_ONESTEP.      
-000141c0: 2020 2020 5265 7350 6163 6b65 7420 5230      ResPacket R0
-000141d0: 2c20 5231 3b0a 2020 2020 2020 2020 2020  , R1;.          
-000141e0: 5265 7350 6163 6b65 7420 616c 7068 6176  ResPacket alphav
-000141f0: 203d 2070 7365 7431 3c52 6573 5061 636b   = pset1<ResPack
-00014200: 6574 3e28 616c 7068 6129 3b0a 0a20 2020  et>(alpha);..   
-00014210: 2020 2020 2020 2052 3020 3d20 7230 2e74         R0 = r0.t
-00014220: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
-00014230: 6574 3c52 6573 5061 636b 6574 3e28 3020  et<ResPacket>(0 
-00014240: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
-00014250: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
-00014260: 2020 2020 5231 203d 2072 302e 7465 6d70      R1 = r0.temp
-00014270: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
-00014280: 5265 7350 6163 6b65 743e 2831 202a 2054  ResPacket>(1 * T
-00014290: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
-000142a0: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
-000142b0: 2074 7261 6974 732e 6163 6328 4330 2c20   traits.acc(C0, 
-000142c0: 616c 7068 6176 2c20 5230 293b 0a20 2020  alphav, R0);.   
-000142d0: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
-000142e0: 6328 4334 2c20 616c 7068 6176 2c20 5231  c(C4, alphav, R1
-000142f0: 293b 0a20 2020 2020 2020 2020 2072 302e  );.          r0.
-00014300: 7374 6f72 6550 6163 6b65 7428 3020 2a20  storePacket(0 * 
-00014310: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
-00014320: 7453 697a 652c 2052 3029 3b0a 2020 2020  tSize, R0);.    
-00014330: 2020 2020 2020 7230 2e73 746f 7265 5061        r0.storePa
-00014340: 636b 6574 2831 202a 2054 7261 6974 733a  cket(1 * Traits:
-00014350: 3a52 6573 5061 636b 6574 5369 7a65 2c20  :ResPacketSize, 
-00014360: 5231 293b 0a20 2020 2020 2020 2020 207d  R1);.          }
-00014370: 0a20 2020 2020 2020 207d 0a20 2020 2020  .        }.     
-00014380: 207d 0a20 2020 207d 0a20 2020 202f 2f2d   }.    }.    //-
-00014390: 2d2d 2d2d 2d2d 2d2d 2d20 5072 6f63 6573  --------- Proces
-000143a0: 7320 3120 2a20 4c68 7350 726f 6772 6573  s 1 * LhsProgres
-000143b0: 7320 726f 7773 2061 7420 6f6e 6365 202d  s rows at once -
-000143c0: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020 6966  ---------.    if
-000143d0: 286d 723e 3d31 2a54 7261 6974 733a 3a4c  (mr>=1*Traits::L
-000143e0: 6873 5072 6f67 7265 7373 290a 2020 2020  hsProgress).    
-000143f0: 7b0a 2020 2020 2020 6c68 735f 7072 6f63  {.      lhs_proc
-00014400: 6573 735f 6f6e 655f 7061 636b 6574 3c6e  ess_one_packet<n
-00014410: 722c 204c 6873 5072 6f67 7265 7373 2c20  r, LhsProgress, 
-00014420: 5268 7350 726f 6772 6573 732c 204c 6873  RhsProgress, Lhs
-00014430: 5363 616c 6172 2c20 5268 7353 6361 6c61  Scalar, RhsScala
-00014440: 722c 2052 6573 5363 616c 6172 2c20 4163  r, ResScalar, Ac
-00014450: 6350 6163 6b65 742c 204c 6873 5061 636b  cPacket, LhsPack
-00014460: 6574 2c20 5268 7350 6163 6b65 742c 2052  et, RhsPacket, R
-00014470: 6573 5061 636b 6574 2c20 5472 6169 7473  esPacket, Traits
-00014480: 2c20 4c69 6e65 6172 4d61 7070 6572 2c20  , LinearMapper, 
-00014490: 4461 7461 4d61 7070 6572 3e20 703b 0a20  DataMapper> p;. 
-000144a0: 2020 2020 2070 2872 6573 2c20 626c 6f63       p(res, bloc
-000144b0: 6b41 2c20 626c 6f63 6b42 2c20 616c 7068  kA, blockB, alph
-000144c0: 612c 2070 6565 6c65 645f 6d63 322c 2070  a, peeled_mc2, p
-000144d0: 6565 6c65 645f 6d63 312c 2073 7472 6964  eeled_mc1, strid
-000144e0: 6541 2c20 7374 7269 6465 422c 206f 6666  eA, strideB, off
-000144f0: 7365 7441 2c20 6f66 6673 6574 422c 2070  setA, offsetB, p
-00014500: 7265 6665 7463 685f 7265 735f 6f66 6673  refetch_res_offs
-00014510: 6574 2c20 7065 656c 6564 5f6b 632c 2070  et, peeled_kc, p
-00014520: 6b2c 2063 6f6c 732c 2064 6570 7468 2c20  k, cols, depth, 
-00014530: 7061 636b 6574 5f63 6f6c 7334 293b 0a20  packet_cols4);. 
-00014540: 2020 207d 0a20 2020 202f 2f2d 2d2d 2d2d     }.    //-----
-00014550: 2d2d 2d2d 2d20 5072 6f63 6573 7320 4c68  ----- Process Lh
-00014560: 7350 726f 6772 6573 7348 616c 6620 726f  sProgressHalf ro
-00014570: 7773 2061 7420 6f6e 6365 202d 2d2d 2d2d  ws at once -----
-00014580: 2d2d 2d2d 2d0a 2020 2020 6966 2828 4c68  -----.    if((Lh
-00014590: 7350 726f 6772 6573 7348 616c 6620 3c20  sProgressHalf < 
-000145a0: 4c68 7350 726f 6772 6573 7329 2026 2620  LhsProgress) && 
-000145b0: 6d72 3e3d 4c68 7350 726f 6772 6573 7348  mr>=LhsProgressH
-000145c0: 616c 6629 0a20 2020 207b 0a20 2020 2020  alf).    {.     
-000145d0: 206c 6873 5f70 726f 6365 7373 5f66 7261   lhs_process_fra
-000145e0: 6374 696f 6e5f 6f66 5f70 6163 6b65 743c  ction_of_packet<
-000145f0: 6e72 2c20 4c68 7350 726f 6772 6573 7348  nr, LhsProgressH
-00014600: 616c 662c 2052 6873 5072 6f67 7265 7373  alf, RhsProgress
-00014610: 4861 6c66 2c20 4c68 7353 6361 6c61 722c  Half, LhsScalar,
-00014620: 2052 6873 5363 616c 6172 2c20 5265 7353   RhsScalar, ResS
-00014630: 6361 6c61 722c 2041 6363 5061 636b 6574  calar, AccPacket
-00014640: 4861 6c66 2c20 4c68 7350 6163 6b65 7448  Half, LhsPacketH
-00014650: 616c 662c 2052 6873 5061 636b 6574 4861  alf, RhsPacketHa
-00014660: 6c66 2c20 5265 7350 6163 6b65 7448 616c  lf, ResPacketHal
-00014670: 662c 2048 616c 6654 7261 6974 732c 204c  f, HalfTraits, L
-00014680: 696e 6561 724d 6170 7065 722c 2044 6174  inearMapper, Dat
-00014690: 614d 6170 7065 723e 2070 3b0a 2020 2020  aMapper> p;.    
-000146a0: 2020 7028 7265 732c 2062 6c6f 636b 412c    p(res, blockA,
-000146b0: 2062 6c6f 636b 422c 2061 6c70 6861 2c20   blockB, alpha, 
-000146c0: 7065 656c 6564 5f6d 6331 2c20 7065 656c  peeled_mc1, peel
-000146d0: 6564 5f6d 635f 6861 6c66 2c20 7374 7269  ed_mc_half, stri
-000146e0: 6465 412c 2073 7472 6964 6542 2c20 6f66  deA, strideB, of
-000146f0: 6673 6574 412c 206f 6666 7365 7442 2c20  fsetA, offsetB, 
-00014700: 7072 6566 6574 6368 5f72 6573 5f6f 6666  prefetch_res_off
-00014710: 7365 742c 2070 6565 6c65 645f 6b63 2c20  set, peeled_kc, 
-00014720: 706b 2c20 636f 6c73 2c20 6465 7074 682c  pk, cols, depth,
-00014730: 2070 6163 6b65 745f 636f 6c73 3429 3b0a   packet_cols4);.
-00014740: 2020 2020 7d0a 2020 2020 2f2f 2d2d 2d2d      }.    //----
-00014750: 2d2d 2d2d 2d2d 2050 726f 6365 7373 204c  ------ Process L
-00014760: 6873 5072 6f67 7265 7373 5175 6172 7465  hsProgressQuarte
-00014770: 7220 726f 7773 2061 7420 6f6e 6365 202d  r rows at once -
-00014780: 2d2d 2d2d 2d2d 2d2d 2d0a 2020 2020 6966  ---------.    if
-00014790: 2828 4c68 7350 726f 6772 6573 7351 7561  ((LhsProgressQua
-000147a0: 7274 6572 203c 204c 6873 5072 6f67 7265  rter < LhsProgre
-000147b0: 7373 4861 6c66 2920 2626 206d 723e 3d4c  ssHalf) && mr>=L
-000147c0: 6873 5072 6f67 7265 7373 5175 6172 7465  hsProgressQuarte
-000147d0: 7229 0a20 2020 207b 0a20 2020 2020 206c  r).    {.      l
-000147e0: 6873 5f70 726f 6365 7373 5f66 7261 6374  hs_process_fract
-000147f0: 696f 6e5f 6f66 5f70 6163 6b65 743c 6e72  ion_of_packet<nr
-00014800: 2c20 4c68 7350 726f 6772 6573 7351 7561  , LhsProgressQua
-00014810: 7274 6572 2c20 5268 7350 726f 6772 6573  rter, RhsProgres
-00014820: 7351 7561 7274 6572 2c20 4c68 7353 6361  sQuarter, LhsSca
-00014830: 6c61 722c 2052 6873 5363 616c 6172 2c20  lar, RhsScalar, 
-00014840: 5265 7353 6361 6c61 722c 2041 6363 5061  ResScalar, AccPa
-00014850: 636b 6574 5175 6172 7465 722c 204c 6873  cketQuarter, Lhs
-00014860: 5061 636b 6574 5175 6172 7465 722c 2052  PacketQuarter, R
-00014870: 6873 5061 636b 6574 5175 6172 7465 722c  hsPacketQuarter,
-00014880: 2052 6573 5061 636b 6574 5175 6172 7465   ResPacketQuarte
-00014890: 722c 2051 7561 7274 6572 5472 6169 7473  r, QuarterTraits
-000148a0: 2c20 4c69 6e65 6172 4d61 7070 6572 2c20  , LinearMapper, 
-000148b0: 4461 7461 4d61 7070 6572 3e20 703b 0a20  DataMapper> p;. 
-000148c0: 2020 2020 2070 2872 6573 2c20 626c 6f63       p(res, bloc
-000148d0: 6b41 2c20 626c 6f63 6b42 2c20 616c 7068  kA, blockB, alph
-000148e0: 612c 2070 6565 6c65 645f 6d63 5f68 616c  a, peeled_mc_hal
-000148f0: 662c 2070 6565 6c65 645f 6d63 5f71 7561  f, peeled_mc_qua
-00014900: 7274 6572 2c20 7374 7269 6465 412c 2073  rter, strideA, s
-00014910: 7472 6964 6542 2c20 6f66 6673 6574 412c  trideB, offsetA,
-00014920: 206f 6666 7365 7442 2c20 7072 6566 6574   offsetB, prefet
-00014930: 6368 5f72 6573 5f6f 6666 7365 742c 2070  ch_res_offset, p
-00014940: 6565 6c65 645f 6b63 2c20 706b 2c20 636f  eeled_kc, pk, co
-00014950: 6c73 2c20 6465 7074 682c 2070 6163 6b65  ls, depth, packe
-00014960: 745f 636f 6c73 3429 3b0a 2020 2020 7d0a  t_cols4);.    }.
-00014970: 2020 2020 2f2f 2d2d 2d2d 2d2d 2d2d 2d2d      //----------
-00014980: 2050 726f 6365 7373 2072 656d 6169 6e69   Process remaini
-00014990: 6e67 2072 6f77 732c 2031 2061 7420 6f6e  ng rows, 1 at on
-000149a0: 6365 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020  ce ----------.  
-000149b0: 2020 6966 2870 6565 6c65 645f 6d63 5f71    if(peeled_mc_q
-000149c0: 7561 7274 6572 3c72 6f77 7329 0a20 2020  uarter<rows).   
-000149d0: 207b 0a20 2020 2020 202f 2f20 6c6f 6f70   {.      // loop
-000149e0: 206f 6e20 6561 6368 2070 616e 656c 206f   on each panel o
-000149f0: 6620 7468 6520 7268 730a 2020 2020 2020  f the rhs.      
-00014a00: 666f 7228 496e 6465 7820 6a32 3d30 3b20  for(Index j2=0; 
-00014a10: 6a32 3c70 6163 6b65 745f 636f 6c73 343b  j2<packet_cols4;
-00014a20: 206a 322b 3d6e 7229 0a20 2020 2020 207b   j2+=nr).      {
-00014a30: 0a20 2020 2020 2020 202f 2f20 6c6f 6f70  .        // loop
-00014a40: 206f 6e20 6561 6368 2072 6f77 206f 6620   on each row of 
-00014a50: 7468 6520 6c68 7320 2831 2a4c 6873 5072  the lhs (1*LhsPr
-00014a60: 6f67 7265 7373 2078 2064 6570 7468 290a  ogress x depth).
-00014a70: 2020 2020 2020 2020 666f 7228 496e 6465          for(Inde
-00014a80: 7820 693d 7065 656c 6564 5f6d 635f 7175  x i=peeled_mc_qu
-00014a90: 6172 7465 723b 2069 3c72 6f77 733b 2069  arter; i<rows; i
-00014aa0: 2b3d 3129 0a20 2020 2020 2020 207b 0a20  +=1).        {. 
-00014ab0: 2020 2020 2020 2020 2063 6f6e 7374 204c           const L
-00014ac0: 6873 5363 616c 6172 2a20 626c 4120 3d20  hsScalar* blA = 
-00014ad0: 2662 6c6f 636b 415b 692a 7374 7269 6465  &blockA[i*stride
-00014ae0: 412b 6f66 6673 6574 415d 3b0a 2020 2020  A+offsetA];.    
-00014af0: 2020 2020 2020 7072 6566 6574 6368 2826        prefetch(&
-00014b00: 626c 415b 305d 293b 0a20 2020 2020 2020  blA[0]);.       
-00014b10: 2020 2063 6f6e 7374 2052 6873 5363 616c     const RhsScal
-00014b20: 6172 2a20 626c 4220 3d20 2662 6c6f 636b  ar* blB = &block
-00014b30: 425b 6a32 2a73 7472 6964 6542 2b6f 6666  B[j2*strideB+off
-00014b40: 7365 7442 2a6e 725d 3b0a 0a20 2020 2020  setB*nr];..     
-00014b50: 2020 2020 202f 2f20 4966 204c 6873 5072       // If LhsPr
-00014b60: 6f67 7265 7373 2069 7320 3820 6f72 2031  ogress is 8 or 1
-00014b70: 362c 2069 7420 6173 7375 6d65 7320 7468  6, it assumes th
-00014b80: 6174 2074 6865 7265 2069 7320 610a 2020  at there is a.  
-00014b90: 2020 2020 2020 2020 2f2f 2068 616c 6620          // half 
-00014ba0: 6f72 2071 7561 7274 6572 2070 6163 6b65  or quarter packe
-00014bb0: 742c 2072 6573 7065 6374 6976 656c 792c  t, respectively,
-00014bc0: 206f 6620 7468 6520 7361 6d65 2073 697a   of the same siz
-00014bd0: 6520 6173 0a20 2020 2020 2020 2020 202f  e as.          /
-00014be0: 2f20 6e72 2028 7768 6963 6820 6973 2063  / nr (which is c
-00014bf0: 7572 7265 6e74 6c79 2034 2920 666f 7220  urrently 4) for 
-00014c00: 7468 6520 7265 7475 726e 2074 7970 652e  the return type.
-00014c10: 0a20 2020 2020 2020 2020 2063 6f6e 7374  .          const
-00014c20: 2069 6e74 2053 5265 7350 6163 6b65 7448   int SResPacketH
-00014c30: 616c 6653 697a 6520 3d20 756e 7061 636b  alfSize = unpack
-00014c40: 6574 5f74 7261 6974 733c 7479 7065 6e61  et_traits<typena
-00014c50: 6d65 2075 6e70 6163 6b65 745f 7472 6169  me unpacket_trai
-00014c60: 7473 3c53 5265 7350 6163 6b65 743e 3a3a  ts<SResPacket>::
-00014c70: 6861 6c66 3e3a 3a73 697a 653b 0a20 2020  half>::size;.   
-00014c80: 2020 2020 2020 2063 6f6e 7374 2069 6e74         const int
-00014c90: 2053 5265 7350 6163 6b65 7451 7561 7274   SResPacketQuart
-00014ca0: 6572 5369 7a65 203d 2075 6e70 6163 6b65  erSize = unpacke
-00014cb0: 745f 7472 6169 7473 3c74 7970 656e 616d  t_traits<typenam
-00014cc0: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
-00014cd0: 733c 7479 7065 6e61 6d65 2075 6e70 6163  s<typename unpac
-00014ce0: 6b65 745f 7472 6169 7473 3c53 5265 7350  ket_traits<SResP
-00014cf0: 6163 6b65 743e 3a3a 6861 6c66 3e3a 3a68  acket>::half>::h
-00014d00: 616c 663e 3a3a 7369 7a65 3b0a 2020 2020  alf>::size;.    
-00014d10: 2020 2020 2020 6966 2028 2853 7761 7070        if ((Swapp
-00014d20: 6564 5472 6169 7473 3a3a 4c68 7350 726f  edTraits::LhsPro
-00014d30: 6772 6573 7320 2520 3429 203d 3d20 3020  gress % 4) == 0 
-00014d40: 2626 0a20 2020 2020 2020 2020 2020 2020  &&.             
-00014d50: 2028 5377 6170 7065 6454 7261 6974 733a   (SwappedTraits:
-00014d60: 3a4c 6873 5072 6f67 7265 7373 3c3d 3136  :LhsProgress<=16
-00014d70: 2920 2626 0a20 2020 2020 2020 2020 2020  ) &&.           
-00014d80: 2020 2028 5377 6170 7065 6454 7261 6974     (SwappedTrait
-00014d90: 733a 3a4c 6873 5072 6f67 7265 7373 213d  s::LhsProgress!=
-00014da0: 3820 207c 7c20 5352 6573 5061 636b 6574  8  || SResPacket
-00014db0: 4861 6c66 5369 7a65 3d3d 6e72 2920 2626  HalfSize==nr) &&
-00014dc0: 0a20 2020 2020 2020 2020 2020 2020 2028  .              (
-00014dd0: 5377 6170 7065 6454 7261 6974 733a 3a4c  SwappedTraits::L
-00014de0: 6873 5072 6f67 7265 7373 213d 3136 207c  hsProgress!=16 |
-00014df0: 7c20 5352 6573 5061 636b 6574 5175 6172  | SResPacketQuar
-00014e00: 7465 7253 697a 653d 3d6e 7229 290a 2020  terSize==nr)).  
-00014e10: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
-00014e20: 2020 2020 2020 5341 6363 5061 636b 6574        SAccPacket
-00014e30: 2043 302c 2043 312c 2043 322c 2043 333b   C0, C1, C2, C3;
-00014e40: 0a20 2020 2020 2020 2020 2020 2073 7472  .            str
-00014e50: 6169 7473 2e69 6e69 7441 6363 2843 3029  aits.initAcc(C0)
-00014e60: 3b0a 2020 2020 2020 2020 2020 2020 7374  ;.            st
-00014e70: 7261 6974 732e 696e 6974 4163 6328 4331  raits.initAcc(C1
-00014e80: 293b 0a20 2020 2020 2020 2020 2020 2073  );.            s
-00014e90: 7472 6169 7473 2e69 6e69 7441 6363 2843  traits.initAcc(C
-00014ea0: 3229 3b0a 2020 2020 2020 2020 2020 2020  2);.            
-00014eb0: 7374 7261 6974 732e 696e 6974 4163 6328  straits.initAcc(
-00014ec0: 4333 293b 0a0a 2020 2020 2020 2020 2020  C3);..          
-00014ed0: 2020 636f 6e73 7420 496e 6465 7820 7370    const Index sp
-00014ee0: 6b20 2020 3d20 2873 7464 3a3a 6d61 7829  k   = (std::max)
-00014ef0: 2831 2c53 7761 7070 6564 5472 6169 7473  (1,SwappedTraits
-00014f00: 3a3a 4c68 7350 726f 6772 6573 732f 3429  ::LhsProgress/4)
-00014f10: 3b0a 2020 2020 2020 2020 2020 2020 636f  ;.            co
-00014f20: 6e73 7420 496e 6465 7820 656e 646b 2020  nst Index endk  
-00014f30: 3d20 2864 6570 7468 2f73 706b 292a 7370  = (depth/spk)*sp
-00014f40: 6b3b 0a20 2020 2020 2020 2020 2020 2063  k;.            c
-00014f50: 6f6e 7374 2049 6e64 6578 2065 6e64 6b34  onst Index endk4
-00014f60: 203d 2028 6465 7074 682f 2873 706b 2a34   = (depth/(spk*4
-00014f70: 2929 2a28 7370 6b2a 3429 3b0a 0a20 2020  ))*(spk*4);..   
-00014f80: 2020 2020 2020 2020 2049 6e64 6578 206b           Index k
-00014f90: 3d30 3b0a 2020 2020 2020 2020 2020 2020  =0;.            
-00014fa0: 666f 7228 3b20 6b3c 656e 646b 343b 206b  for(; k<endk4; k
-00014fb0: 2b3d 342a 7370 6b29 0a20 2020 2020 2020  +=4*spk).       
-00014fc0: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
-00014fd0: 2020 2020 2053 4c68 7350 6163 6b65 7420       SLhsPacket 
-00014fe0: 4130 2c41 313b 0a20 2020 2020 2020 2020  A0,A1;.         
-00014ff0: 2020 2020 2053 5268 7350 6163 6b65 7420       SRhsPacket 
-00015000: 425f 302c 425f 313b 0a0a 2020 2020 2020  B_0,B_1;..      
-00015010: 2020 2020 2020 2020 7374 7261 6974 732e          straits.
-00015020: 6c6f 6164 4c68 7355 6e61 6c69 676e 6564  loadLhsUnaligned
-00015030: 2862 6c42 2b30 2a53 7761 7070 6564 5472  (blB+0*SwappedTr
-00015040: 6169 7473 3a3a 4c68 7350 726f 6772 6573  aits::LhsProgres
-00015050: 732c 2041 3029 3b0a 2020 2020 2020 2020  s, A0);.        
-00015060: 2020 2020 2020 7374 7261 6974 732e 6c6f        straits.lo
-00015070: 6164 4c68 7355 6e61 6c69 676e 6564 2862  adLhsUnaligned(b
-00015080: 6c42 2b31 2a53 7761 7070 6564 5472 6169  lB+1*SwappedTrai
-00015090: 7473 3a3a 4c68 7350 726f 6772 6573 732c  ts::LhsProgress,
-000150a0: 2041 3129 3b0a 0a20 2020 2020 2020 2020   A1);..         
-000150b0: 2020 2020 2073 7472 6169 7473 2e6c 6f61       straits.loa
-000150c0: 6452 6873 5175 6164 2862 6c41 2b30 2a73  dRhsQuad(blA+0*s
-000150d0: 706b 2c20 425f 3029 3b0a 2020 2020 2020  pk, B_0);.      
-000150e0: 2020 2020 2020 2020 7374 7261 6974 732e          straits.
-000150f0: 6c6f 6164 5268 7351 7561 6428 626c 412b  loadRhsQuad(blA+
-00015100: 312a 7370 6b2c 2042 5f31 293b 0a20 2020  1*spk, B_1);.   
-00015110: 2020 2020 2020 2020 2020 2073 7472 6169             strai
-00015120: 7473 2e6d 6164 6428 4130 2c42 5f30 2c43  ts.madd(A0,B_0,C
-00015130: 302c 425f 302c 2066 6978 3c30 3e29 3b0a  0,B_0, fix<0>);.
-00015140: 2020 2020 2020 2020 2020 2020 2020 7374                st
-00015150: 7261 6974 732e 6d61 6464 2841 312c 425f  raits.madd(A1,B_
-00015160: 312c 4331 2c42 5f31 2c20 6669 783c 303e  1,C1,B_1, fix<0>
-00015170: 293b 0a0a 2020 2020 2020 2020 2020 2020  );..            
-00015180: 2020 7374 7261 6974 732e 6c6f 6164 4c68    straits.loadLh
-00015190: 7355 6e61 6c69 676e 6564 2862 6c42 2b32  sUnaligned(blB+2
-000151a0: 2a53 7761 7070 6564 5472 6169 7473 3a3a  *SwappedTraits::
-000151b0: 4c68 7350 726f 6772 6573 732c 2041 3029  LhsProgress, A0)
-000151c0: 3b0a 2020 2020 2020 2020 2020 2020 2020  ;.              
-000151d0: 7374 7261 6974 732e 6c6f 6164 4c68 7355  straits.loadLhsU
-000151e0: 6e61 6c69 676e 6564 2862 6c42 2b33 2a53  naligned(blB+3*S
-000151f0: 7761 7070 6564 5472 6169 7473 3a3a 4c68  wappedTraits::Lh
-00015200: 7350 726f 6772 6573 732c 2041 3129 3b0a  sProgress, A1);.
-00015210: 2020 2020 2020 2020 2020 2020 2020 7374                st
-00015220: 7261 6974 732e 6c6f 6164 5268 7351 7561  raits.loadRhsQua
-00015230: 6428 626c 412b 322a 7370 6b2c 2042 5f30  d(blA+2*spk, B_0
-00015240: 293b 0a20 2020 2020 2020 2020 2020 2020  );.             
-00015250: 2073 7472 6169 7473 2e6c 6f61 6452 6873   straits.loadRhs
-00015260: 5175 6164 2862 6c41 2b33 2a73 706b 2c20  Quad(blA+3*spk, 
-00015270: 425f 3129 3b0a 2020 2020 2020 2020 2020  B_1);.          
-00015280: 2020 2020 7374 7261 6974 732e 6d61 6464      straits.madd
-00015290: 2841 302c 425f 302c 4332 2c42 5f30 2c20  (A0,B_0,C2,B_0, 
-000152a0: 6669 783c 303e 293b 0a20 2020 2020 2020  fix<0>);.       
-000152b0: 2020 2020 2020 2073 7472 6169 7473 2e6d         straits.m
-000152c0: 6164 6428 4131 2c42 5f31 2c43 332c 425f  add(A1,B_1,C3,B_
-000152d0: 312c 2066 6978 3c30 3e29 3b0a 0a20 2020  1, fix<0>);..   
-000152e0: 2020 2020 2020 2020 2020 2062 6c42 202b             blB +
-000152f0: 3d20 342a 5377 6170 7065 6454 7261 6974  = 4*SwappedTrait
-00015300: 733a 3a4c 6873 5072 6f67 7265 7373 3b0a  s::LhsProgress;.
-00015310: 2020 2020 2020 2020 2020 2020 2020 626c                bl
-00015320: 4120 2b3d 2034 2a73 706b 3b0a 2020 2020  A += 4*spk;.    
-00015330: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
-00015340: 2020 2020 2020 4330 203d 2070 6164 6428        C0 = padd(
-00015350: 7061 6464 2843 302c 4331 292c 7061 6464  padd(C0,C1),padd
-00015360: 2843 322c 4333 2929 3b0a 2020 2020 2020  (C2,C3));.      
-00015370: 2020 2020 2020 666f 7228 3b20 6b3c 656e        for(; k<en
-00015380: 646b 3b20 6b2b 3d73 706b 290a 2020 2020  dk; k+=spk).    
-00015390: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
-000153a0: 2020 2020 2020 2020 534c 6873 5061 636b          SLhsPack
-000153b0: 6574 2041 303b 0a20 2020 2020 2020 2020  et A0;.         
-000153c0: 2020 2020 2053 5268 7350 6163 6b65 7420       SRhsPacket 
-000153d0: 425f 303b 0a0a 2020 2020 2020 2020 2020  B_0;..          
-000153e0: 2020 2020 7374 7261 6974 732e 6c6f 6164      straits.load
-000153f0: 4c68 7355 6e61 6c69 676e 6564 2862 6c42  LhsUnaligned(blB
-00015400: 2c20 4130 293b 0a20 2020 2020 2020 2020  , A0);.         
-00015410: 2020 2020 2073 7472 6169 7473 2e6c 6f61       straits.loa
-00015420: 6452 6873 5175 6164 2862 6c41 2c20 425f  dRhsQuad(blA, B_
-00015430: 3029 3b0a 2020 2020 2020 2020 2020 2020  0);.            
-00015440: 2020 7374 7261 6974 732e 6d61 6464 2841    straits.madd(A
-00015450: 302c 425f 302c 4330 2c42 5f30 2c20 6669  0,B_0,C0,B_0, fi
-00015460: 783c 303e 293b 0a0a 2020 2020 2020 2020  x<0>);..        
-00015470: 2020 2020 2020 626c 4220 2b3d 2053 7761        blB += Swa
-00015480: 7070 6564 5472 6169 7473 3a3a 4c68 7350  ppedTraits::LhsP
-00015490: 726f 6772 6573 733b 0a20 2020 2020 2020  rogress;.       
-000154a0: 2020 2020 2020 2062 6c41 202b 3d20 7370         blA += sp
-000154b0: 6b3b 0a20 2020 2020 2020 2020 2020 207d  k;.            }
-000154c0: 0a20 2020 2020 2020 2020 2020 2069 6628  .            if(
-000154d0: 5377 6170 7065 6454 7261 6974 733a 3a4c  SwappedTraits::L
-000154e0: 6873 5072 6f67 7265 7373 3d3d 3829 0a20  hsProgress==8). 
-000154f0: 2020 2020 2020 2020 2020 207b 0a20 2020             {.   
-00015500: 2020 2020 2020 2020 2020 202f 2f20 5370             // Sp
-00015510: 6563 6961 6c20 6361 7365 2077 6865 7265  ecial case where
-00015520: 2077 6520 6861 7665 2074 6f20 6669 7273   we have to firs
-00015530: 7420 7265 6475 6365 2074 6865 2061 6363  t reduce the acc
-00015540: 756d 756c 6174 696f 6e20 7265 6769 7374  umulation regist
-00015550: 6572 2043 300a 2020 2020 2020 2020 2020  er C0.          
-00015560: 2020 2020 7479 7065 6465 6620 7479 7065      typedef type
-00015570: 6e61 6d65 2063 6f6e 6469 7469 6f6e 616c  name conditional
-00015580: 3c53 7761 7070 6564 5472 6169 7473 3a3a  <SwappedTraits::
-00015590: 4c68 7350 726f 6772 6573 733e 3d38 2c74  LhsProgress>=8,t
-000155a0: 7970 656e 616d 6520 756e 7061 636b 6574  ypename unpacket
-000155b0: 5f74 7261 6974 733c 5352 6573 5061 636b  _traits<SResPack
-000155c0: 6574 3e3a 3a68 616c 662c 5352 6573 5061  et>::half,SResPa
-000155d0: 636b 6574 3e3a 3a74 7970 6520 5352 6573  cket>::type SRes
-000155e0: 5061 636b 6574 4861 6c66 3b0a 2020 2020  PacketHalf;.    
-000155f0: 2020 2020 2020 2020 2020 7479 7065 6465            typede
-00015600: 6620 7479 7065 6e61 6d65 2063 6f6e 6469  f typename condi
-00015610: 7469 6f6e 616c 3c53 7761 7070 6564 5472  tional<SwappedTr
-00015620: 6169 7473 3a3a 4c68 7350 726f 6772 6573  aits::LhsProgres
-00015630: 733e 3d38 2c74 7970 656e 616d 6520 756e  s>=8,typename un
-00015640: 7061 636b 6574 5f74 7261 6974 733c 534c  packet_traits<SL
-00015650: 6873 5061 636b 6574 3e3a 3a68 616c 662c  hsPacket>::half,
-00015660: 534c 6873 5061 636b 6574 3e3a 3a74 7970  SLhsPacket>::typ
-00015670: 6520 534c 6873 5061 636b 6574 4861 6c66  e SLhsPacketHalf
-00015680: 3b0a 2020 2020 2020 2020 2020 2020 2020  ;.              
-00015690: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
-000156a0: 2063 6f6e 6469 7469 6f6e 616c 3c53 7761   conditional<Swa
-000156b0: 7070 6564 5472 6169 7473 3a3a 4c68 7350  ppedTraits::LhsP
-000156c0: 726f 6772 6573 733e 3d38 2c74 7970 656e  rogress>=8,typen
-000156d0: 616d 6520 756e 7061 636b 6574 5f74 7261  ame unpacket_tra
-000156e0: 6974 733c 5352 6873 5061 636b 6574 3e3a  its<SRhsPacket>:
-000156f0: 3a68 616c 662c 5352 6873 5061 636b 6574  :half,SRhsPacket
-00015700: 3e3a 3a74 7970 6520 5352 6873 5061 636b  >::type SRhsPack
-00015710: 6574 4861 6c66 3b0a 2020 2020 2020 2020  etHalf;.        
-00015720: 2020 2020 2020 7479 7065 6465 6620 7479        typedef ty
-00015730: 7065 6e61 6d65 2063 6f6e 6469 7469 6f6e  pename condition
-00015740: 616c 3c53 7761 7070 6564 5472 6169 7473  al<SwappedTraits
-00015750: 3a3a 4c68 7350 726f 6772 6573 733e 3d38  ::LhsProgress>=8
-00015760: 2c74 7970 656e 616d 6520 756e 7061 636b  ,typename unpack
-00015770: 6574 5f74 7261 6974 733c 5341 6363 5061  et_traits<SAccPa
-00015780: 636b 6574 3e3a 3a68 616c 662c 5341 6363  cket>::half,SAcc
-00015790: 5061 636b 6574 3e3a 3a74 7970 6520 5341  Packet>::type SA
-000157a0: 6363 5061 636b 6574 4861 6c66 3b0a 0a20  ccPacketHalf;.. 
-000157b0: 2020 2020 2020 2020 2020 2020 2053 5265               SRe
-000157c0: 7350 6163 6b65 7448 616c 6620 5220 3d20  sPacketHalf R = 
-000157d0: 7265 732e 7465 6d70 6c61 7465 2067 6174  res.template gat
-000157e0: 6865 7250 6163 6b65 743c 5352 6573 5061  herPacket<SResPa
-000157f0: 636b 6574 4861 6c66 3e28 692c 206a 3229  cketHalf>(i, j2)
-00015800: 3b0a 2020 2020 2020 2020 2020 2020 2020  ;.              
-00015810: 5352 6573 5061 636b 6574 4861 6c66 2061  SResPacketHalf a
-00015820: 6c70 6861 7620 3d20 7073 6574 313c 5352  lphav = pset1<SR
-00015830: 6573 5061 636b 6574 4861 6c66 3e28 616c  esPacketHalf>(al
-00015840: 7068 6129 3b0a 0a20 2020 2020 2020 2020  pha);..         
-00015850: 2020 2020 2069 6628 6465 7074 682d 656e       if(depth-en
-00015860: 646b 3e30 290a 2020 2020 2020 2020 2020  dk>0).          
-00015870: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
-00015880: 2020 2020 2020 2f2f 2057 6520 6861 7665        // We have
-00015890: 2074 6f20 6861 6e64 6c65 2074 6865 206c   to handle the l
-000158a0: 6173 7420 726f 7720 6f66 2074 6865 2072  ast row of the r
-000158b0: 6873 2077 6869 6368 2063 6f72 7265 7370  hs which corresp
-000158c0: 6f6e 6473 2074 6f20 6120 6861 6c66 2d70  onds to a half-p
-000158d0: 6163 6b65 740a 2020 2020 2020 2020 2020  acket.          
-000158e0: 2020 2020 2020 534c 6873 5061 636b 6574        SLhsPacket
-000158f0: 4861 6c66 2061 303b 0a20 2020 2020 2020  Half a0;.       
-00015900: 2020 2020 2020 2020 2053 5268 7350 6163           SRhsPac
-00015910: 6b65 7448 616c 6620 6230 3b0a 2020 2020  ketHalf b0;.    
-00015920: 2020 2020 2020 2020 2020 2020 7374 7261              stra
-00015930: 6974 732e 6c6f 6164 4c68 7355 6e61 6c69  its.loadLhsUnali
-00015940: 676e 6564 2862 6c42 2c20 6130 293b 0a20  gned(blB, a0);. 
-00015950: 2020 2020 2020 2020 2020 2020 2020 2073                 s
-00015960: 7472 6169 7473 2e6c 6f61 6452 6873 2862  traits.loadRhs(b
-00015970: 6c41 2c20 6230 293b 0a20 2020 2020 2020  lA, b0);.       
-00015980: 2020 2020 2020 2020 2053 4163 6350 6163           SAccPac
-00015990: 6b65 7448 616c 6620 6330 203d 2070 7265  ketHalf c0 = pre
-000159a0: 6475 785f 6861 6c66 5f64 6f77 746f 3428  dux_half_dowto4(
-000159b0: 4330 293b 0a20 2020 2020 2020 2020 2020  C0);.           
-000159c0: 2020 2020 2073 7472 6169 7473 2e6d 6164       straits.mad
-000159d0: 6428 6130 2c62 302c 6330 2c62 302c 2066  d(a0,b0,c0,b0, f
-000159e0: 6978 3c30 3e29 3b0a 2020 2020 2020 2020  ix<0>);.        
-000159f0: 2020 2020 2020 2020 7374 7261 6974 732e          straits.
-00015a00: 6163 6328 6330 2c20 616c 7068 6176 2c20  acc(c0, alphav, 
-00015a10: 5229 3b0a 2020 2020 2020 2020 2020 2020  R);.            
-00015a20: 2020 7d0a 2020 2020 2020 2020 2020 2020    }.            
-00015a30: 2020 656c 7365 0a20 2020 2020 2020 2020    else.         
-00015a40: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
-00015a50: 2020 2020 2020 2073 7472 6169 7473 2e61         straits.a
-00015a60: 6363 2870 7265 6475 785f 6861 6c66 5f64  cc(predux_half_d
-00015a70: 6f77 746f 3428 4330 292c 2061 6c70 6861  owto4(C0), alpha
-00015a80: 762c 2052 293b 0a20 2020 2020 2020 2020  v, R);.         
-00015a90: 2020 2020 207d 0a20 2020 2020 2020 2020       }.         
-00015aa0: 2020 2020 2072 6573 2e73 6361 7474 6572       res.scatter
-00015ab0: 5061 636b 6574 2869 2c20 6a32 2c20 5229  Packet(i, j2, R)
-00015ac0: 3b0a 2020 2020 2020 2020 2020 2020 7d0a  ;.            }.
-00015ad0: 2020 2020 2020 2020 2020 2020 656c 7365              else
-00015ae0: 2069 6620 2853 7761 7070 6564 5472 6169   if (SwappedTrai
-00015af0: 7473 3a3a 4c68 7350 726f 6772 6573 733d  ts::LhsProgress=
-00015b00: 3d31 3629 0a20 2020 2020 2020 2020 2020  =16).           
-00015b10: 207b 0a20 2020 2020 2020 2020 2020 2020   {.             
-00015b20: 202f 2f20 5370 6563 6961 6c20 6361 7365   // Special case
-00015b30: 2077 6865 7265 2077 6520 6861 7665 2074   where we have t
-00015b40: 6f20 6669 7273 7420 7265 6475 6365 2074  o first reduce t
-00015b50: 6865 0a20 2020 2020 2020 2020 2020 2020  he.             
-00015b60: 202f 2f20 6163 6375 6d75 6c61 7469 6f6e   // accumulation
-00015b70: 2072 6567 6973 7465 7220 4330 2e20 5765   register C0. We
-00015b80: 2073 7065 6369 616c 697a 6520 7468 6520   specialize the 
-00015b90: 626c 6f63 6b20 696e 0a20 2020 2020 2020  block in.       
-00015ba0: 2020 2020 2020 202f 2f20 7465 6d70 6c61         // templa
-00015bb0: 7465 2066 6f72 6d2c 2073 6f20 7468 6174  te form, so that
-00015bc0: 204c 6873 5072 6f67 7265 7373 203c 2031   LhsProgress < 1
-00015bd0: 3620 7061 7468 7320 646f 6e27 740a 2020  6 paths don't.  
-00015be0: 2020 2020 2020 2020 2020 2020 2f2f 2066              // f
-00015bf0: 6169 6c20 746f 2063 6f6d 7069 6c65 0a20  ail to compile. 
-00015c00: 2020 2020 2020 2020 2020 2020 206c 6173               las
-00015c10: 745f 726f 775f 7072 6f63 6573 735f 3136  t_row_process_16
-00015c20: 5f70 6163 6b65 7473 3c4c 6873 5363 616c  _packets<LhsScal
-00015c30: 6172 2c20 5268 7353 6361 6c61 722c 2049  ar, RhsScalar, I
-00015c40: 6e64 6578 2c20 4461 7461 4d61 7070 6572  ndex, DataMapper
-00015c50: 2c20 6d72 2c20 6e72 2c20 436f 6e6a 7567  , mr, nr, Conjug
-00015c60: 6174 654c 6873 2c20 436f 6e6a 7567 6174  ateLhs, Conjugat
-00015c70: 6552 6873 3e20 703b 0a09 2020 2020 2020  eRhs> p;..      
-00015c80: 2020 2020 2020 7028 7265 732c 2073 7472        p(res, str
-00015c90: 6169 7473 2c20 626c 412c 2062 6c42 2c20  aits, blA, blB, 
-00015ca0: 6465 7074 682c 2065 6e64 6b2c 2069 2c20  depth, endk, i, 
-00015cb0: 6a32 2c61 6c70 6861 2c20 4330 293b 0a20  j2,alpha, C0);. 
-00015cc0: 2020 2020 2020 2020 2020 207d 0a20 2020             }.   
-00015cd0: 2020 2020 2020 2020 2065 6c73 650a 2020           else.  
-00015ce0: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
-00015cf0: 2020 2020 2020 2020 2020 5352 6573 5061            SResPa
-00015d00: 636b 6574 2052 203d 2072 6573 2e74 656d  cket R = res.tem
-00015d10: 706c 6174 6520 6761 7468 6572 5061 636b  plate gatherPack
-00015d20: 6574 3c53 5265 7350 6163 6b65 743e 2869  et<SResPacket>(i
-00015d30: 2c20 6a32 293b 0a20 2020 2020 2020 2020  , j2);.         
-00015d40: 2020 2020 2053 5265 7350 6163 6b65 7420       SResPacket 
-00015d50: 616c 7068 6176 203d 2070 7365 7431 3c53  alphav = pset1<S
-00015d60: 5265 7350 6163 6b65 743e 2861 6c70 6861  ResPacket>(alpha
-00015d70: 293b 0a20 2020 2020 2020 2020 2020 2020  );.             
-00015d80: 2073 7472 6169 7473 2e61 6363 2843 302c   straits.acc(C0,
-00015d90: 2061 6c70 6861 762c 2052 293b 0a20 2020   alphav, R);.   
-00015da0: 2020 2020 2020 2020 2020 2072 6573 2e73             res.s
-00015db0: 6361 7474 6572 5061 636b 6574 2869 2c20  catterPacket(i, 
-00015dc0: 6a32 2c20 5229 3b0a 2020 2020 2020 2020  j2, R);.        
-00015dd0: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
-00015de0: 7d0a 2020 2020 2020 2020 2020 656c 7365  }.          else
-00015df0: 202f 2f20 7363 616c 6172 2070 6174 680a   // scalar path.
-00015e00: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
-00015e10: 2020 2020 2020 2020 2f2f 2067 6574 2061          // get a
-00015e20: 2031 2078 2034 2072 6573 2062 6c6f 636b   1 x 4 res block
-00015e30: 2061 7320 7265 6769 7374 6572 730a 2020   as registers.  
-00015e40: 2020 2020 2020 2020 2020 5265 7353 6361            ResSca
-00015e50: 6c61 7220 4330 2830 292c 2043 3128 3029  lar C0(0), C1(0)
-00015e60: 2c20 4332 2830 292c 2043 3328 3029 3b0a  , C2(0), C3(0);.
-00015e70: 0a20 2020 2020 2020 2020 2020 2066 6f72  .            for
-00015e80: 2849 6e64 6578 206b 3d30 3b20 6b3c 6465  (Index k=0; k<de
-00015e90: 7074 683b 206b 2b2b 290a 2020 2020 2020  pth; k++).      
-00015ea0: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
-00015eb0: 2020 2020 2020 4c68 7353 6361 6c61 7220        LhsScalar 
-00015ec0: 4130 3b0a 2020 2020 2020 2020 2020 2020  A0;.            
-00015ed0: 2020 5268 7353 6361 6c61 7220 425f 302c    RhsScalar B_0,
-00015ee0: 2042 5f31 3b0a 0a20 2020 2020 2020 2020   B_1;..         
-00015ef0: 2020 2020 2041 3020 3d20 626c 415b 6b5d       A0 = blA[k]
-00015f00: 3b0a 0a20 2020 2020 2020 2020 2020 2020  ;..             
-00015f10: 2042 5f30 203d 2062 6c42 5b30 5d3b 0a20   B_0 = blB[0];. 
-00015f20: 2020 2020 2020 2020 2020 2020 2042 5f31               B_1
-00015f30: 203d 2062 6c42 5b31 5d3b 0a20 2020 2020   = blB[1];.     
-00015f40: 2020 2020 2020 2020 2043 4a4d 4144 4428           CJMADD(
-00015f50: 636a 2c41 302c 425f 302c 4330 2c20 2042  cj,A0,B_0,C0,  B
-00015f60: 5f30 293b 0a20 2020 2020 2020 2020 2020  _0);.           
-00015f70: 2020 2043 4a4d 4144 4428 636a 2c41 302c     CJMADD(cj,A0,
-00015f80: 425f 312c 4331 2c20 2042 5f31 293b 0a20  B_1,C1,  B_1);. 
-00015f90: 2020 2020 2020 2020 2020 2020 200a 2020               .  
-00015fa0: 2020 2020 2020 2020 2020 2020 425f 3020              B_0 
-00015fb0: 3d20 626c 425b 325d 3b0a 2020 2020 2020  = blB[2];.      
-00015fc0: 2020 2020 2020 2020 425f 3120 3d20 626c          B_1 = bl
-00015fd0: 425b 335d 3b0a 2020 2020 2020 2020 2020  B[3];.          
-00015fe0: 2020 2020 434a 4d41 4444 2863 6a2c 4130      CJMADD(cj,A0
-00015ff0: 2c42 5f30 2c43 322c 2020 425f 3029 3b0a  ,B_0,C2,  B_0);.
-00016000: 2020 2020 2020 2020 2020 2020 2020 434a                CJ
-00016010: 4d41 4444 2863 6a2c 4130 2c42 5f31 2c43  MADD(cj,A0,B_1,C
-00016020: 332c 2020 425f 3129 3b0a 2020 2020 2020  3,  B_1);.      
-00016030: 2020 2020 2020 2020 0a20 2020 2020 2020          .       
-00016040: 2020 2020 2020 2062 6c42 202b 3d20 343b         blB += 4;
-00016050: 0a20 2020 2020 2020 2020 2020 207d 0a20  .            }. 
-00016060: 2020 2020 2020 2020 2020 2072 6573 2869             res(i
-00016070: 2c20 6a32 202b 2030 2920 2b3d 2061 6c70  , j2 + 0) += alp
-00016080: 6861 202a 2043 303b 0a20 2020 2020 2020  ha * C0;.       
-00016090: 2020 2020 2072 6573 2869 2c20 6a32 202b       res(i, j2 +
-000160a0: 2031 2920 2b3d 2061 6c70 6861 202a 2043   1) += alpha * C
-000160b0: 313b 0a20 2020 2020 2020 2020 2020 2072  1;.            r
-000160c0: 6573 2869 2c20 6a32 202b 2032 2920 2b3d  es(i, j2 + 2) +=
-000160d0: 2061 6c70 6861 202a 2043 323b 0a20 2020   alpha * C2;.   
-000160e0: 2020 2020 2020 2020 2072 6573 2869 2c20           res(i, 
-000160f0: 6a32 202b 2033 2920 2b3d 2061 6c70 6861  j2 + 3) += alpha
-00016100: 202a 2043 333b 0a20 2020 2020 2020 2020   * C3;.         
-00016110: 207d 0a20 2020 2020 2020 207d 0a20 2020   }.        }.   
-00016120: 2020 207d 0a20 2020 2020 202f 2f20 7265     }.      // re
-00016130: 6d61 696e 696e 6720 636f 6c75 6d6e 730a  maining columns.
-00016140: 2020 2020 2020 666f 7228 496e 6465 7820        for(Index 
-00016150: 6a32 3d70 6163 6b65 745f 636f 6c73 343b  j2=packet_cols4;
-00016160: 206a 323c 636f 6c73 3b20 6a32 2b2b 290a   j2<cols; j2++).
-00016170: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
-00016180: 2f2f 206c 6f6f 7020 6f6e 2065 6163 6820  // loop on each 
-00016190: 726f 7720 6f66 2074 6865 206c 6873 2028  row of the lhs (
-000161a0: 312a 4c68 7350 726f 6772 6573 7320 7820  1*LhsProgress x 
-000161b0: 6465 7074 6829 0a20 2020 2020 2020 2066  depth).        f
-000161c0: 6f72 2849 6e64 6578 2069 3d70 6565 6c65  or(Index i=peele
-000161d0: 645f 6d63 5f71 7561 7274 6572 3b20 693c  d_mc_quarter; i<
-000161e0: 726f 7773 3b20 692b 3d31 290a 2020 2020  rows; i+=1).    
-000161f0: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
-00016200: 636f 6e73 7420 4c68 7353 6361 6c61 722a  const LhsScalar*
-00016210: 2062 6c41 203d 2026 626c 6f63 6b41 5b69   blA = &blockA[i
-00016220: 2a73 7472 6964 6541 2b6f 6666 7365 7441  *strideA+offsetA
-00016230: 5d3b 0a20 2020 2020 2020 2020 2070 7265  ];.          pre
-00016240: 6665 7463 6828 2662 6c41 5b30 5d29 3b0a  fetch(&blA[0]);.
-00016250: 2020 2020 2020 2020 2020 2f2f 2067 6574            // get
-00016260: 7320 6120 3120 7820 3120 7265 7320 626c  s a 1 x 1 res bl
-00016270: 6f63 6b20 6173 2072 6567 6973 7465 7273  ock as registers
-00016280: 0a20 2020 2020 2020 2020 2052 6573 5363  .          ResSc
-00016290: 616c 6172 2043 3028 3029 3b0a 2020 2020  alar C0(0);.    
-000162a0: 2020 2020 2020 636f 6e73 7420 5268 7353        const RhsS
-000162b0: 6361 6c61 722a 2062 6c42 203d 2026 626c  calar* blB = &bl
-000162c0: 6f63 6b42 5b6a 322a 7374 7269 6465 422b  ockB[j2*strideB+
-000162d0: 6f66 6673 6574 425d 3b0a 2020 2020 2020  offsetB];.      
-000162e0: 2020 2020 666f 7228 496e 6465 7820 6b3d      for(Index k=
-000162f0: 303b 206b 3c64 6570 7468 3b20 6b2b 2b29  0; k<depth; k++)
-00016300: 0a20 2020 2020 2020 2020 207b 0a20 2020  .          {.   
-00016310: 2020 2020 2020 2020 204c 6873 5363 616c           LhsScal
-00016320: 6172 2041 3020 3d20 626c 415b 6b5d 3b0a  ar A0 = blA[k];.
-00016330: 2020 2020 2020 2020 2020 2020 5268 7353              RhsS
-00016340: 6361 6c61 7220 425f 3020 3d20 626c 425b  calar B_0 = blB[
-00016350: 6b5d 3b0a 2020 2020 2020 2020 2020 2020  k];.            
-00016360: 434a 4d41 4444 2863 6a2c 2041 302c 2042  CJMADD(cj, A0, B
-00016370: 5f30 2c20 4330 2c20 425f 3029 3b0a 2020  _0, C0, B_0);.  
-00016380: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
-00016390: 2020 2020 7265 7328 692c 206a 3229 202b      res(i, j2) +
-000163a0: 3d20 616c 7068 6120 2a20 4330 3b0a 2020  = alpha * C0;.  
-000163b0: 2020 2020 2020 7d0a 2020 2020 2020 7d0a        }.      }.
-000163c0: 2020 2020 7d0a 2020 7d0a 0a0a 2375 6e64      }.  }...#und
-000163d0: 6566 2043 4a4d 4144 440a 0a2f 2f20 7061  ef CJMADD..// pa
-000163e0: 636b 2061 2062 6c6f 636b 206f 6620 7468  ck a block of th
-000163f0: 6520 6c68 730a 2f2f 2054 6865 2074 7261  e lhs.// The tra
-00016400: 7665 7273 616c 2069 7320 6173 2066 6f6c  versal is as fol
-00016410: 6c6f 7720 286d 723d 3d34 293a 0a2f 2f20  low (mr==4):.// 
-00016420: 2020 3020 2034 2020 3820 3132 202e 2e2e    0  4  8 12 ...
-00016430: 0a2f 2f20 2020 3120 2035 2020 3920 3133  .//   1  5  9 13
-00016440: 202e 2e2e 0a2f 2f20 2020 3220 2036 2031   ....//   2  6 1
-00016450: 3020 3134 202e 2e2e 0a2f 2f20 2020 3320  0 14 ....//   3 
-00016460: 2037 2031 3120 3135 202e 2e2e 0a2f 2f0a   7 11 15 ....//.
-00016470: 2f2f 2020 3136 2032 3020 3234 2032 3820  //  16 20 24 28 
-00016480: 2e2e 2e0a 2f2f 2020 3137 2032 3120 3235  ....//  17 21 25
-00016490: 2032 3920 2e2e 2e0a 2f2f 2020 3138 2032   29 ....//  18 2
-000164a0: 3220 3236 2033 3020 2e2e 2e0a 2f2f 2020  2 26 30 ....//  
-000164b0: 3139 2032 3320 3237 2033 3120 2e2e 2e0a  19 23 27 31 ....
-000164c0: 2f2f 0a2f 2f20 2033 3220 3333 2033 3420  //.//  32 33 34 
-000164d0: 3335 202e 2e2e 0a2f 2f20 2033 3620 3336  35 ....//  36 36
-000164e0: 2033 3820 3339 202e 2e2e 0a74 656d 706c   38 39 ....templ
-000164f0: 6174 653c 7479 7065 6e61 6d65 2053 6361  ate<typename Sca
-00016500: 6c61 722c 2074 7970 656e 616d 6520 496e  lar, typename In
-00016510: 6465 782c 2074 7970 656e 616d 6520 4461  dex, typename Da
-00016520: 7461 4d61 7070 6572 2c20 696e 7420 5061  taMapper, int Pa
-00016530: 636b 312c 2069 6e74 2050 6163 6b32 2c20  ck1, int Pack2, 
-00016540: 7479 7065 6e61 6d65 2050 6163 6b65 742c  typename Packet,
-00016550: 2062 6f6f 6c20 436f 6e6a 7567 6174 652c   bool Conjugate,
-00016560: 2062 6f6f 6c20 5061 6e65 6c4d 6f64 653e   bool PanelMode>
-00016570: 0a73 7472 7563 7420 6765 6d6d 5f70 6163  .struct gemm_pac
-00016580: 6b5f 6c68 733c 5363 616c 6172 2c20 496e  k_lhs<Scalar, In
-00016590: 6465 782c 2044 6174 614d 6170 7065 722c  dex, DataMapper,
-000165a0: 2050 6163 6b31 2c20 5061 636b 322c 2050   Pack1, Pack2, P
-000165b0: 6163 6b65 742c 2043 6f6c 4d61 6a6f 722c  acket, ColMajor,
-000165c0: 2043 6f6e 6a75 6761 7465 2c20 5061 6e65   Conjugate, Pane
-000165d0: 6c4d 6f64 653e 0a7b 0a20 2074 7970 6564  lMode>.{.  typed
-000165e0: 6566 2074 7970 656e 616d 6520 4461 7461  ef typename Data
-000165f0: 4d61 7070 6572 3a3a 4c69 6e65 6172 4d61  Mapper::LinearMa
-00016600: 7070 6572 204c 696e 6561 724d 6170 7065  pper LinearMappe
-00016610: 723b 0a20 2045 4947 454e 5f44 4f4e 545f  r;.  EIGEN_DONT_
-00016620: 494e 4c49 4e45 2076 6f69 6420 6f70 6572  INLINE void oper
-00016630: 6174 6f72 2829 2853 6361 6c61 722a 2062  ator()(Scalar* b
-00016640: 6c6f 636b 412c 2063 6f6e 7374 2044 6174  lockA, const Dat
-00016650: 614d 6170 7065 7226 206c 6873 2c20 496e  aMapper& lhs, In
-00016660: 6465 7820 6465 7074 682c 2049 6e64 6578  dex depth, Index
-00016670: 2072 6f77 732c 2049 6e64 6578 2073 7472   rows, Index str
-00016680: 6964 653d 302c 2049 6e64 6578 206f 6666  ide=0, Index off
-00016690: 7365 743d 3029 3b0a 7d3b 0a0a 7465 6d70  set=0);.};..temp
-000166a0: 6c61 7465 3c74 7970 656e 616d 6520 5363  late<typename Sc
-000166b0: 616c 6172 2c20 7479 7065 6e61 6d65 2049  alar, typename I
-000166c0: 6e64 6578 2c20 7479 7065 6e61 6d65 2044  ndex, typename D
-000166d0: 6174 614d 6170 7065 722c 2069 6e74 2050  ataMapper, int P
-000166e0: 6163 6b31 2c20 696e 7420 5061 636b 322c  ack1, int Pack2,
-000166f0: 2074 7970 656e 616d 6520 5061 636b 6574   typename Packet
-00016700: 2c20 626f 6f6c 2043 6f6e 6a75 6761 7465  , bool Conjugate
-00016710: 2c20 626f 6f6c 2050 616e 656c 4d6f 6465  , bool PanelMode
-00016720: 3e0a 4549 4745 4e5f 444f 4e54 5f49 4e4c  >.EIGEN_DONT_INL
-00016730: 494e 4520 766f 6964 2067 656d 6d5f 7061  INE void gemm_pa
-00016740: 636b 5f6c 6873 3c53 6361 6c61 722c 2049  ck_lhs<Scalar, I
-00016750: 6e64 6578 2c20 4461 7461 4d61 7070 6572  ndex, DataMapper
-00016760: 2c20 5061 636b 312c 2050 6163 6b32 2c20  , Pack1, Pack2, 
-00016770: 5061 636b 6574 2c20 436f 6c4d 616a 6f72  Packet, ColMajor
-00016780: 2c20 436f 6e6a 7567 6174 652c 2050 616e  , Conjugate, Pan
-00016790: 656c 4d6f 6465 3e0a 2020 3a3a 6f70 6572  elMode>.  ::oper
-000167a0: 6174 6f72 2829 2853 6361 6c61 722a 2062  ator()(Scalar* b
-000167b0: 6c6f 636b 412c 2063 6f6e 7374 2044 6174  lockA, const Dat
-000167c0: 614d 6170 7065 7226 206c 6873 2c20 496e  aMapper& lhs, In
-000167d0: 6465 7820 6465 7074 682c 2049 6e64 6578  dex depth, Index
-000167e0: 2072 6f77 732c 2049 6e64 6578 2073 7472   rows, Index str
-000167f0: 6964 652c 2049 6e64 6578 206f 6666 7365  ide, Index offse
-00016800: 7429 0a7b 0a20 2074 7970 6564 6566 2074  t).{.  typedef t
-00016810: 7970 656e 616d 6520 756e 7061 636b 6574  ypename unpacket
-00016820: 5f74 7261 6974 733c 5061 636b 6574 3e3a  _traits<Packet>:
-00016830: 3a68 616c 6620 4861 6c66 5061 636b 6574  :half HalfPacket
-00016840: 3b0a 2020 7479 7065 6465 6620 7479 7065  ;.  typedef type
-00016850: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
-00016860: 6169 7473 3c74 7970 656e 616d 6520 756e  aits<typename un
-00016870: 7061 636b 6574 5f74 7261 6974 733c 5061  packet_traits<Pa
-00016880: 636b 6574 3e3a 3a68 616c 663e 3a3a 6861  cket>::half>::ha
-00016890: 6c66 2051 7561 7274 6572 5061 636b 6574  lf QuarterPacket
-000168a0: 3b0a 2020 656e 756d 207b 2050 6163 6b65  ;.  enum { Packe
-000168b0: 7453 697a 6520 3d20 756e 7061 636b 6574  tSize = unpacket
-000168c0: 5f74 7261 6974 733c 5061 636b 6574 3e3a  _traits<Packet>:
-000168d0: 3a73 697a 652c 0a20 2020 2020 2020 2020  :size,.         
-000168e0: 4861 6c66 5061 636b 6574 5369 7a65 203d  HalfPacketSize =
-000168f0: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
-00016900: 3c48 616c 6650 6163 6b65 743e 3a3a 7369  <HalfPacket>::si
-00016910: 7a65 2c0a 2020 2020 2020 2020 2051 7561  ze,.         Qua
-00016920: 7274 6572 5061 636b 6574 5369 7a65 203d  rterPacketSize =
-00016930: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
-00016940: 3c51 7561 7274 6572 5061 636b 6574 3e3a  <QuarterPacket>:
-00016950: 3a73 697a 652c 0a20 2020 2020 2020 2020  :size,.         
-00016960: 4861 7348 616c 6620 3d20 2869 6e74 2948  HasHalf = (int)H
-00016970: 616c 6650 6163 6b65 7453 697a 6520 3c20  alfPacketSize < 
-00016980: 2869 6e74 2950 6163 6b65 7453 697a 652c  (int)PacketSize,
-00016990: 0a20 2020 2020 2020 2020 4861 7351 7561  .         HasQua
-000169a0: 7274 6572 203d 2028 696e 7429 5175 6172  rter = (int)Quar
-000169b0: 7465 7250 6163 6b65 7453 697a 6520 3c20  terPacketSize < 
-000169c0: 2869 6e74 2948 616c 6650 6163 6b65 7453  (int)HalfPacketS
-000169d0: 697a 657d 3b0a 0a20 2045 4947 454e 5f41  ize};..  EIGEN_A
-000169e0: 534d 5f43 4f4d 4d45 4e54 2822 4549 4745  SM_COMMENT("EIGE
-000169f0: 4e20 5052 4f44 5543 5420 5041 434b 204c  N PRODUCT PACK L
-00016a00: 4853 2229 3b0a 2020 4549 4745 4e5f 554e  HS");.  EIGEN_UN
-00016a10: 5553 4544 5f56 4152 4941 424c 4528 7374  USED_VARIABLE(st
-00016a20: 7269 6465 293b 0a20 2045 4947 454e 5f55  ride);.  EIGEN_U
-00016a30: 4e55 5345 445f 5641 5249 4142 4c45 286f  NUSED_VARIABLE(o
-00016a40: 6666 7365 7429 3b0a 2020 6569 6765 6e5f  ffset);.  eigen_
-00016a50: 6173 7365 7274 2828 2821 5061 6e65 6c4d  assert(((!PanelM
-00016a60: 6f64 6529 2026 2620 7374 7269 6465 3d3d  ode) && stride==
-00016a70: 3020 2626 206f 6666 7365 743d 3d30 2920  0 && offset==0) 
-00016a80: 7c7c 2028 5061 6e65 6c4d 6f64 6520 2626  || (PanelMode &&
-00016a90: 2073 7472 6964 653e 3d64 6570 7468 2026   stride>=depth &
-00016aa0: 2620 6f66 6673 6574 3c3d 7374 7269 6465  & offset<=stride
-00016ab0: 2929 3b0a 2020 6569 6765 6e5f 6173 7365  ));.  eigen_asse
-00016ac0: 7274 2820 2828 5061 636b 3125 5061 636b  rt( ((Pack1%Pack
-00016ad0: 6574 5369 7a65 293d 3d30 2026 2620 5061  etSize)==0 && Pa
-00016ae0: 636b 313c 3d34 2a50 6163 6b65 7453 697a  ck1<=4*PacketSiz
-00016af0: 6529 207c 7c20 2850 6163 6b31 3c3d 3429  e) || (Pack1<=4)
-00016b00: 2029 3b0a 2020 636f 6e6a 5f69 663c 4e75   );.  conj_if<Nu
-00016b10: 6d54 7261 6974 733c 5363 616c 6172 3e3a  mTraits<Scalar>:
-00016b20: 3a49 7343 6f6d 706c 6578 2026 2620 436f  :IsComplex && Co
-00016b30: 6e6a 7567 6174 653e 2063 6a3b 0a20 2049  njugate> cj;.  I
-00016b40: 6e64 6578 2063 6f75 6e74 203d 2030 3b0a  ndex count = 0;.
-00016b50: 0a20 2063 6f6e 7374 2049 6e64 6578 2070  .  const Index p
-00016b60: 6565 6c65 645f 6d63 3320 3d20 5061 636b  eeled_mc3 = Pack
-00016b70: 313e 3d33 2a50 6163 6b65 7453 697a 6520  1>=3*PacketSize 
-00016b80: 3f20 2872 6f77 732f 2833 2a50 6163 6b65  ? (rows/(3*Packe
-00016b90: 7453 697a 6529 292a 2833 2a50 6163 6b65  tSize))*(3*Packe
-00016ba0: 7453 697a 6529 203a 2030 3b0a 2020 636f  tSize) : 0;.  co
-00016bb0: 6e73 7420 496e 6465 7820 7065 656c 6564  nst Index peeled
-00016bc0: 5f6d 6332 203d 2050 6163 6b31 3e3d 322a  _mc2 = Pack1>=2*
-00016bd0: 5061 636b 6574 5369 7a65 203f 2070 6565  PacketSize ? pee
-00016be0: 6c65 645f 6d63 332b 2828 726f 7773 2d70  led_mc3+((rows-p
-00016bf0: 6565 6c65 645f 6d63 3329 2f28 322a 5061  eeled_mc3)/(2*Pa
-00016c00: 636b 6574 5369 7a65 2929 2a28 322a 5061  cketSize))*(2*Pa
-00016c10: 636b 6574 5369 7a65 2920 3a20 303b 0a20  cketSize) : 0;. 
-00016c20: 2063 6f6e 7374 2049 6e64 6578 2070 6565   const Index pee
-00016c30: 6c65 645f 6d63 3120 3d20 5061 636b 313e  led_mc1 = Pack1>
-00016c40: 3d31 2a50 6163 6b65 7453 697a 6520 3f20  =1*PacketSize ? 
-00016c50: 7065 656c 6564 5f6d 6332 2b28 2872 6f77  peeled_mc2+((row
-00016c60: 732d 7065 656c 6564 5f6d 6332 292f 2831  s-peeled_mc2)/(1
-00016c70: 2a50 6163 6b65 7453 697a 6529 292a 2831  *PacketSize))*(1
-00016c80: 2a50 6163 6b65 7453 697a 6529 203a 2030  *PacketSize) : 0
-00016c90: 3b0a 2020 636f 6e73 7420 496e 6465 7820  ;.  const Index 
-00016ca0: 7065 656c 6564 5f6d 635f 6861 6c66 203d  peeled_mc_half =
-00016cb0: 2050 6163 6b31 3e3d 4861 6c66 5061 636b   Pack1>=HalfPack
-00016cc0: 6574 5369 7a65 203f 2070 6565 6c65 645f  etSize ? peeled_
-00016cd0: 6d63 312b 2828 726f 7773 2d70 6565 6c65  mc1+((rows-peele
-00016ce0: 645f 6d63 3129 2f28 4861 6c66 5061 636b  d_mc1)/(HalfPack
-00016cf0: 6574 5369 7a65 2929 2a28 4861 6c66 5061  etSize))*(HalfPa
-00016d00: 636b 6574 5369 7a65 2920 3a20 303b 0a20  cketSize) : 0;. 
-00016d10: 2063 6f6e 7374 2049 6e64 6578 2070 6565   const Index pee
-00016d20: 6c65 645f 6d63 5f71 7561 7274 6572 203d  led_mc_quarter =
-00016d30: 2050 6163 6b31 3e3d 5175 6172 7465 7250   Pack1>=QuarterP
-00016d40: 6163 6b65 7453 697a 6520 3f20 2872 6f77  acketSize ? (row
-00016d50: 732f 2851 7561 7274 6572 5061 636b 6574  s/(QuarterPacket
-00016d60: 5369 7a65 2929 2a28 5175 6172 7465 7250  Size))*(QuarterP
-00016d70: 6163 6b65 7453 697a 6529 203a 2030 3b0a  acketSize) : 0;.
-00016d80: 2020 636f 6e73 7420 496e 6465 7820 6c61    const Index la
-00016d90: 7374 5f6c 6873 5f70 726f 6772 6573 7320  st_lhs_progress 
-00016da0: 3d20 726f 7773 203e 2070 6565 6c65 645f  = rows > peeled_
-00016db0: 6d63 5f71 7561 7274 6572 203f 2028 726f  mc_quarter ? (ro
-00016dc0: 7773 202d 2070 6565 6c65 645f 6d63 5f71  ws - peeled_mc_q
-00016dd0: 7561 7274 6572 2920 2620 7e31 203a 2030  uarter) & ~1 : 0
-00016de0: 3b0a 2020 636f 6e73 7420 496e 6465 7820  ;.  const Index 
-00016df0: 7065 656c 6564 5f6d 6330 203d 2050 6163  peeled_mc0 = Pac
-00016e00: 6b32 3e3d 5061 636b 6574 5369 7a65 203f  k2>=PacketSize ?
-00016e10: 2070 6565 6c65 645f 6d63 5f71 7561 7274   peeled_mc_quart
-00016e20: 6572 0a20 2020 2020 2020 2020 2020 2020  er.             
-00016e30: 2020 2020 2020 2020 2020 2020 3a20 5061              : Pa
-00016e40: 636b 323e 3120 2626 206c 6173 745f 6c68  ck2>1 && last_lh
-00016e50: 735f 7072 6f67 7265 7373 203f 2028 726f  s_progress ? (ro
-00016e60: 7773 2f6c 6173 745f 6c68 735f 7072 6f67  ws/last_lhs_prog
-00016e70: 7265 7373 292a 6c61 7374 5f6c 6873 5f70  ress)*last_lhs_p
-00016e80: 726f 6772 6573 7320 3a20 303b 0a0a 2020  rogress : 0;..  
-00016e90: 496e 6465 7820 693d 303b 0a0a 2020 2f2f  Index i=0;..  //
-00016ea0: 2050 6163 6b20 3320 7061 636b 6574 730a   Pack 3 packets.
-00016eb0: 2020 6966 2850 6163 6b31 3e3d 332a 5061    if(Pack1>=3*Pa
-00016ec0: 636b 6574 5369 7a65 290a 2020 7b0a 2020  cketSize).  {.  
-00016ed0: 2020 666f 7228 3b20 693c 7065 656c 6564    for(; i<peeled
-00016ee0: 5f6d 6333 3b20 692b 3d33 2a50 6163 6b65  _mc3; i+=3*Packe
-00016ef0: 7453 697a 6529 0a20 2020 207b 0a20 2020  tSize).    {.   
-00016f00: 2020 2069 6628 5061 6e65 6c4d 6f64 6529     if(PanelMode)
-00016f10: 2063 6f75 6e74 202b 3d20 2833 2a50 6163   count += (3*Pac
-00016f20: 6b65 7453 697a 6529 202a 206f 6666 7365  ketSize) * offse
-00016f30: 743b 0a0a 2020 2020 2020 666f 7228 496e  t;..      for(In
-00016f40: 6465 7820 6b3d 303b 206b 3c64 6570 7468  dex k=0; k<depth
-00016f50: 3b20 6b2b 2b29 0a20 2020 2020 207b 0a20  ; k++).      {. 
-00016f60: 2020 2020 2020 2050 6163 6b65 7420 412c         Packet A,
-00016f70: 2042 2c20 433b 0a20 2020 2020 2020 2041   B, C;.        A
-00016f80: 203d 206c 6873 2e74 656d 706c 6174 6520   = lhs.template 
-00016f90: 6c6f 6164 5061 636b 6574 3c50 6163 6b65  loadPacket<Packe
-00016fa0: 743e 2869 2b30 2a50 6163 6b65 7453 697a  t>(i+0*PacketSiz
-00016fb0: 652c 206b 293b 0a20 2020 2020 2020 2042  e, k);.        B
-00016fc0: 203d 206c 6873 2e74 656d 706c 6174 6520   = lhs.template 
-00016fd0: 6c6f 6164 5061 636b 6574 3c50 6163 6b65  loadPacket<Packe
-00016fe0: 743e 2869 2b31 2a50 6163 6b65 7453 697a  t>(i+1*PacketSiz
-00016ff0: 652c 206b 293b 0a20 2020 2020 2020 2043  e, k);.        C
-00017000: 203d 206c 6873 2e74 656d 706c 6174 6520   = lhs.template 
-00017010: 6c6f 6164 5061 636b 6574 3c50 6163 6b65  loadPacket<Packe
-00017020: 743e 2869 2b32 2a50 6163 6b65 7453 697a  t>(i+2*PacketSiz
-00017030: 652c 206b 293b 0a20 2020 2020 2020 2070  e, k);.        p
-00017040: 7374 6f72 6528 626c 6f63 6b41 2b63 6f75  store(blockA+cou
-00017050: 6e74 2c20 636a 2e70 636f 6e6a 2841 2929  nt, cj.pconj(A))
-00017060: 3b20 636f 756e 742b 3d50 6163 6b65 7453  ; count+=PacketS
-00017070: 697a 653b 0a20 2020 2020 2020 2070 7374  ize;.        pst
-00017080: 6f72 6528 626c 6f63 6b41 2b63 6f75 6e74  ore(blockA+count
-00017090: 2c20 636a 2e70 636f 6e6a 2842 2929 3b20  , cj.pconj(B)); 
-000170a0: 636f 756e 742b 3d50 6163 6b65 7453 697a  count+=PacketSiz
-000170b0: 653b 0a20 2020 2020 2020 2070 7374 6f72  e;.        pstor
-000170c0: 6528 626c 6f63 6b41 2b63 6f75 6e74 2c20  e(blockA+count, 
-000170d0: 636a 2e70 636f 6e6a 2843 2929 3b20 636f  cj.pconj(C)); co
-000170e0: 756e 742b 3d50 6163 6b65 7453 697a 653b  unt+=PacketSize;
-000170f0: 0a20 2020 2020 207d 0a20 2020 2020 2069  .      }.      i
-00017100: 6628 5061 6e65 6c4d 6f64 6529 2063 6f75  f(PanelMode) cou
-00017110: 6e74 202b 3d20 2833 2a50 6163 6b65 7453  nt += (3*PacketS
-00017120: 697a 6529 202a 2028 7374 7269 6465 2d6f  ize) * (stride-o
-00017130: 6666 7365 742d 6465 7074 6829 3b0a 2020  ffset-depth);.  
-00017140: 2020 7d0a 2020 7d0a 2020 2f2f 2050 6163    }.  }.  // Pac
-00017150: 6b20 3220 7061 636b 6574 730a 2020 6966  k 2 packets.  if
-00017160: 2850 6163 6b31 3e3d 322a 5061 636b 6574  (Pack1>=2*Packet
-00017170: 5369 7a65 290a 2020 7b0a 2020 2020 666f  Size).  {.    fo
-00017180: 7228 3b20 693c 7065 656c 6564 5f6d 6332  r(; i<peeled_mc2
-00017190: 3b20 692b 3d32 2a50 6163 6b65 7453 697a  ; i+=2*PacketSiz
-000171a0: 6529 0a20 2020 207b 0a20 2020 2020 2069  e).    {.      i
-000171b0: 6628 5061 6e65 6c4d 6f64 6529 2063 6f75  f(PanelMode) cou
-000171c0: 6e74 202b 3d20 2832 2a50 6163 6b65 7453  nt += (2*PacketS
-000171d0: 697a 6529 202a 206f 6666 7365 743b 0a0a  ize) * offset;..
-000171e0: 2020 2020 2020 666f 7228 496e 6465 7820        for(Index 
-000171f0: 6b3d 303b 206b 3c64 6570 7468 3b20 6b2b  k=0; k<depth; k+
-00017200: 2b29 0a20 2020 2020 207b 0a20 2020 2020  +).      {.     
-00017210: 2020 2050 6163 6b65 7420 412c 2042 3b0a     Packet A, B;.
-00017220: 2020 2020 2020 2020 4120 3d20 6c68 732e          A = lhs.
-00017230: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
-00017240: 6b65 743c 5061 636b 6574 3e28 692b 302a  ket<Packet>(i+0*
-00017250: 5061 636b 6574 5369 7a65 2c20 6b29 3b0a  PacketSize, k);.
-00017260: 2020 2020 2020 2020 4220 3d20 6c68 732e          B = lhs.
-00017270: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
-00017280: 6b65 743c 5061 636b 6574 3e28 692b 312a  ket<Packet>(i+1*
-00017290: 5061 636b 6574 5369 7a65 2c20 6b29 3b0a  PacketSize, k);.
-000172a0: 2020 2020 2020 2020 7073 746f 7265 2862          pstore(b
-000172b0: 6c6f 636b 412b 636f 756e 742c 2063 6a2e  lockA+count, cj.
-000172c0: 7063 6f6e 6a28 4129 293b 2063 6f75 6e74  pconj(A)); count
-000172d0: 2b3d 5061 636b 6574 5369 7a65 3b0a 2020  +=PacketSize;.  
-000172e0: 2020 2020 2020 7073 746f 7265 2862 6c6f        pstore(blo
-000172f0: 636b 412b 636f 756e 742c 2063 6a2e 7063  ckA+count, cj.pc
-00017300: 6f6e 6a28 4229 293b 2063 6f75 6e74 2b3d  onj(B)); count+=
-00017310: 5061 636b 6574 5369 7a65 3b0a 2020 2020  PacketSize;.    
-00017320: 2020 7d0a 2020 2020 2020 6966 2850 616e    }.      if(Pan
-00017330: 656c 4d6f 6465 2920 636f 756e 7420 2b3d  elMode) count +=
-00017340: 2028 322a 5061 636b 6574 5369 7a65 2920   (2*PacketSize) 
-00017350: 2a20 2873 7472 6964 652d 6f66 6673 6574  * (stride-offset
-00017360: 2d64 6570 7468 293b 0a20 2020 207d 0a20  -depth);.    }. 
-00017370: 207d 0a20 202f 2f20 5061 636b 2031 2070   }.  // Pack 1 p
-00017380: 6163 6b65 7473 0a20 2069 6628 5061 636b  ackets.  if(Pack
-00017390: 313e 3d31 2a50 6163 6b65 7453 697a 6529  1>=1*PacketSize)
-000173a0: 0a20 207b 0a20 2020 2066 6f72 283b 2069  .  {.    for(; i
-000173b0: 3c70 6565 6c65 645f 6d63 313b 2069 2b3d  <peeled_mc1; i+=
-000173c0: 312a 5061 636b 6574 5369 7a65 290a 2020  1*PacketSize).  
-000173d0: 2020 7b0a 2020 2020 2020 6966 2850 616e    {.      if(Pan
-000173e0: 656c 4d6f 6465 2920 636f 756e 7420 2b3d  elMode) count +=
-000173f0: 2028 312a 5061 636b 6574 5369 7a65 2920   (1*PacketSize) 
-00017400: 2a20 6f66 6673 6574 3b0a 0a20 2020 2020  * offset;..     
-00017410: 2066 6f72 2849 6e64 6578 206b 3d30 3b20   for(Index k=0; 
-00017420: 6b3c 6465 7074 683b 206b 2b2b 290a 2020  k<depth; k++).  
-00017430: 2020 2020 7b0a 2020 2020 2020 2020 5061      {.        Pa
-00017440: 636b 6574 2041 3b0a 2020 2020 2020 2020  cket A;.        
-00017450: 4120 3d20 6c68 732e 7465 6d70 6c61 7465  A = lhs.template
-00017460: 206c 6f61 6450 6163 6b65 743c 5061 636b   loadPacket<Pack
-00017470: 6574 3e28 692b 302a 5061 636b 6574 5369  et>(i+0*PacketSi
-00017480: 7a65 2c20 6b29 3b0a 2020 2020 2020 2020  ze, k);.        
-00017490: 7073 746f 7265 2862 6c6f 636b 412b 636f  pstore(blockA+co
-000174a0: 756e 742c 2063 6a2e 7063 6f6e 6a28 4129  unt, cj.pconj(A)
-000174b0: 293b 0a20 2020 2020 2020 2063 6f75 6e74  );.        count
-000174c0: 2b3d 5061 636b 6574 5369 7a65 3b0a 2020  +=PacketSize;.  
-000174d0: 2020 2020 7d0a 2020 2020 2020 6966 2850      }.      if(P
-000174e0: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
-000174f0: 2b3d 2028 312a 5061 636b 6574 5369 7a65  += (1*PacketSize
-00017500: 2920 2a20 2873 7472 6964 652d 6f66 6673  ) * (stride-offs
-00017510: 6574 2d64 6570 7468 293b 0a20 2020 207d  et-depth);.    }
-00017520: 0a20 207d 0a20 202f 2f20 5061 636b 2068  .  }.  // Pack h
-00017530: 616c 6620 7061 636b 6574 730a 2020 6966  alf packets.  if
-00017540: 2848 6173 4861 6c66 2026 2620 5061 636b  (HasHalf && Pack
-00017550: 313e 3d48 616c 6650 6163 6b65 7453 697a  1>=HalfPacketSiz
-00017560: 6529 0a20 207b 0a20 2020 2066 6f72 283b  e).  {.    for(;
-00017570: 2069 3c70 6565 6c65 645f 6d63 5f68 616c   i<peeled_mc_hal
-00017580: 663b 2069 2b3d 4861 6c66 5061 636b 6574  f; i+=HalfPacket
-00017590: 5369 7a65 290a 2020 2020 7b0a 2020 2020  Size).    {.    
-000175a0: 2020 6966 2850 616e 656c 4d6f 6465 2920    if(PanelMode) 
-000175b0: 636f 756e 7420 2b3d 2028 4861 6c66 5061  count += (HalfPa
-000175c0: 636b 6574 5369 7a65 2920 2a20 6f66 6673  cketSize) * offs
-000175d0: 6574 3b0a 0a20 2020 2020 2066 6f72 2849  et;..      for(I
-000175e0: 6e64 6578 206b 3d30 3b20 6b3c 6465 7074  ndex k=0; k<dept
-000175f0: 683b 206b 2b2b 290a 2020 2020 2020 7b0a  h; k++).      {.
-00017600: 2020 2020 2020 2020 4861 6c66 5061 636b          HalfPack
-00017610: 6574 2041 3b0a 2020 2020 2020 2020 4120  et A;.        A 
-00017620: 3d20 6c68 732e 7465 6d70 6c61 7465 206c  = lhs.template l
-00017630: 6f61 6450 6163 6b65 743c 4861 6c66 5061  oadPacket<HalfPa
-00017640: 636b 6574 3e28 692b 302a 2848 616c 6650  cket>(i+0*(HalfP
-00017650: 6163 6b65 7453 697a 6529 2c20 6b29 3b0a  acketSize), k);.
-00017660: 2020 2020 2020 2020 7073 746f 7265 7528          pstoreu(
-00017670: 626c 6f63 6b41 2b63 6f75 6e74 2c20 636a  blockA+count, cj
-00017680: 2e70 636f 6e6a 2841 2929 3b0a 2020 2020  .pconj(A));.    
-00017690: 2020 2020 636f 756e 742b 3d48 616c 6650      count+=HalfP
-000176a0: 6163 6b65 7453 697a 653b 0a20 2020 2020  acketSize;.     
-000176b0: 207d 0a20 2020 2020 2069 6628 5061 6e65   }.      if(Pane
-000176c0: 6c4d 6f64 6529 2063 6f75 6e74 202b 3d20  lMode) count += 
-000176d0: 2848 616c 6650 6163 6b65 7453 697a 6529  (HalfPacketSize)
-000176e0: 202a 2028 7374 7269 6465 2d6f 6666 7365   * (stride-offse
-000176f0: 742d 6465 7074 6829 3b0a 2020 2020 7d0a  t-depth);.    }.
-00017700: 2020 7d0a 2020 2f2f 2050 6163 6b20 7175    }.  // Pack qu
-00017710: 6172 7465 7220 7061 636b 6574 730a 2020  arter packets.  
-00017720: 6966 2848 6173 5175 6172 7465 7220 2626  if(HasQuarter &&
-00017730: 2050 6163 6b31 3e3d 5175 6172 7465 7250   Pack1>=QuarterP
-00017740: 6163 6b65 7453 697a 6529 0a20 207b 0a20  acketSize).  {. 
-00017750: 2020 2066 6f72 283b 2069 3c70 6565 6c65     for(; i<peele
-00017760: 645f 6d63 5f71 7561 7274 6572 3b20 692b  d_mc_quarter; i+
-00017770: 3d51 7561 7274 6572 5061 636b 6574 5369  =QuarterPacketSi
-00017780: 7a65 290a 2020 2020 7b0a 2020 2020 2020  ze).    {.      
-00017790: 6966 2850 616e 656c 4d6f 6465 2920 636f  if(PanelMode) co
-000177a0: 756e 7420 2b3d 2028 5175 6172 7465 7250  unt += (QuarterP
-000177b0: 6163 6b65 7453 697a 6529 202a 206f 6666  acketSize) * off
-000177c0: 7365 743b 0a0a 2020 2020 2020 666f 7228  set;..      for(
-000177d0: 496e 6465 7820 6b3d 303b 206b 3c64 6570  Index k=0; k<dep
-000177e0: 7468 3b20 6b2b 2b29 0a20 2020 2020 207b  th; k++).      {
-000177f0: 0a20 2020 2020 2020 2051 7561 7274 6572  .        Quarter
-00017800: 5061 636b 6574 2041 3b0a 2020 2020 2020  Packet A;.      
-00017810: 2020 4120 3d20 6c68 732e 7465 6d70 6c61    A = lhs.templa
-00017820: 7465 206c 6f61 6450 6163 6b65 743c 5175  te loadPacket<Qu
-00017830: 6172 7465 7250 6163 6b65 743e 2869 2b30  arterPacket>(i+0
-00017840: 2a28 5175 6172 7465 7250 6163 6b65 7453  *(QuarterPacketS
-00017850: 697a 6529 2c20 6b29 3b0a 2020 2020 2020  ize), k);.      
-00017860: 2020 7073 746f 7265 7528 626c 6f63 6b41    pstoreu(blockA
-00017870: 2b63 6f75 6e74 2c20 636a 2e70 636f 6e6a  +count, cj.pconj
-00017880: 2841 2929 3b0a 2020 2020 2020 2020 636f  (A));.        co
-00017890: 756e 742b 3d51 7561 7274 6572 5061 636b  unt+=QuarterPack
-000178a0: 6574 5369 7a65 3b0a 2020 2020 2020 7d0a  etSize;.      }.
-000178b0: 2020 2020 2020 6966 2850 616e 656c 4d6f        if(PanelMo
-000178c0: 6465 2920 636f 756e 7420 2b3d 2028 5175  de) count += (Qu
-000178d0: 6172 7465 7250 6163 6b65 7453 697a 6529  arterPacketSize)
-000178e0: 202a 2028 7374 7269 6465 2d6f 6666 7365   * (stride-offse
-000178f0: 742d 6465 7074 6829 3b0a 2020 2020 7d0a  t-depth);.    }.
-00017900: 2020 7d0a 2020 2f2f 2050 6163 6b32 206d    }.  // Pack2 m
-00017910: 6179 2062 6520 2a73 6d61 6c6c 6572 2a20  ay be *smaller* 
-00017920: 7468 616e 2050 6163 6b65 7453 697a 65e2  than PacketSize.
-00017930: 8094 7468 6174 2068 6170 7065 6e73 2066  ..that happens f
-00017940: 6f72 0a20 202f 2f20 7072 6f64 7563 7473  or.  // products
-00017950: 206c 696b 6520 7265 616c 202a 2063 6f6d   like real * com
-00017960: 706c 6578 2c20 7768 6572 6520 7765 2068  plex, where we h
-00017970: 6176 6520 746f 2067 6f20 6861 6c66 2074  ave to go half t
-00017980: 6865 0a20 202f 2f20 7072 6f67 7265 7373  he.  // progress
-00017990: 206f 6e20 7468 6520 6c68 7320 696e 206f   on the lhs in o
-000179a0: 7264 6572 2074 6f20 6475 706c 6963 6174  rder to duplicat
-000179b0: 6520 7468 6f73 6520 6f70 6572 616e 6473  e those operands
-000179c0: 2074 6f0a 2020 2f2f 2061 6464 7265 7373   to.  // address
-000179d0: 2062 6f74 6820 7265 616c 2026 2069 6d61   both real & ima
-000179e0: 6769 6e61 7279 2070 6172 7473 206f 6e20  ginary parts on 
-000179f0: 7468 6520 7268 732e 2054 6869 7320 706f  the rhs. This po
-00017a00: 7274 696f 6e20 7769 6c6c 0a20 202f 2f20  rtion will.  // 
-00017a10: 7061 636b 2074 686f 7365 2068 616c 6620  pack those half 
-00017a20: 6f6e 6573 2075 6e74 696c 2074 6865 7920  ones until they 
-00017a30: 6d61 7463 6820 7468 6520 6e75 6d62 6572  match the number
-00017a40: 2065 7870 6563 7465 6420 6f6e 2074 6865   expected on the
-00017a50: 0a20 202f 2f20 6c61 7374 2070 6565 6c69  .  // last peeli
-00017a60: 6e67 206c 6f6f 7020 6174 2074 6869 7320  ng loop at this 
-00017a70: 706f 696e 7420 2866 6f72 2074 6865 2072  point (for the r
-00017a80: 6873 292e 0a20 2069 6628 5061 636b 323c  hs)..  if(Pack2<
-00017a90: 5061 636b 6574 5369 7a65 2026 2620 5061  PacketSize && Pa
-00017aa0: 636b 323e 3129 0a20 207b 0a20 2020 2066  ck2>1).  {.    f
-00017ab0: 6f72 283b 2069 3c70 6565 6c65 645f 6d63  or(; i<peeled_mc
-00017ac0: 303b 2069 2b3d 6c61 7374 5f6c 6873 5f70  0; i+=last_lhs_p
-00017ad0: 726f 6772 6573 7329 0a20 2020 207b 0a20  rogress).    {. 
-00017ae0: 2020 2020 2069 6628 5061 6e65 6c4d 6f64       if(PanelMod
-00017af0: 6529 2063 6f75 6e74 202b 3d20 6c61 7374  e) count += last
-00017b00: 5f6c 6873 5f70 726f 6772 6573 7320 2a20  _lhs_progress * 
-00017b10: 6f66 6673 6574 3b0a 0a20 2020 2020 2066  offset;..      f
-00017b20: 6f72 2849 6e64 6578 206b 3d30 3b20 6b3c  or(Index k=0; k<
-00017b30: 6465 7074 683b 206b 2b2b 290a 2020 2020  depth; k++).    
-00017b40: 2020 2020 666f 7228 496e 6465 7820 773d      for(Index w=
-00017b50: 303b 2077 3c6c 6173 745f 6c68 735f 7072  0; w<last_lhs_pr
-00017b60: 6f67 7265 7373 3b20 772b 2b29 0a20 2020  ogress; w++).   
-00017b70: 2020 2020 2020 2062 6c6f 636b 415b 636f         blockA[co
-00017b80: 756e 742b 2b5d 203d 2063 6a28 6c68 7328  unt++] = cj(lhs(
-00017b90: 692b 772c 206b 2929 3b0a 0a20 2020 2020  i+w, k));..     
-00017ba0: 2069 6628 5061 6e65 6c4d 6f64 6529 2063   if(PanelMode) c
-00017bb0: 6f75 6e74 202b 3d20 6c61 7374 5f6c 6873  ount += last_lhs
-00017bc0: 5f70 726f 6772 6573 7320 2a20 2873 7472  _progress * (str
-00017bd0: 6964 652d 6f66 6673 6574 2d64 6570 7468  ide-offset-depth
-00017be0: 293b 0a20 2020 207d 0a20 207d 0a20 202f  );.    }.  }.  /
-00017bf0: 2f20 5061 636b 2073 6361 6c61 7273 0a20  / Pack scalars. 
-00017c00: 2066 6f72 283b 2069 3c72 6f77 733b 2069   for(; i<rows; i
-00017c10: 2b2b 290a 2020 7b0a 2020 2020 6966 2850  ++).  {.    if(P
-00017c20: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
-00017c30: 2b3d 206f 6666 7365 743b 0a20 2020 2066  += offset;.    f
-00017c40: 6f72 2849 6e64 6578 206b 3d30 3b20 6b3c  or(Index k=0; k<
-00017c50: 6465 7074 683b 206b 2b2b 290a 2020 2020  depth; k++).    
-00017c60: 2020 626c 6f63 6b41 5b63 6f75 6e74 2b2b    blockA[count++
-00017c70: 5d20 3d20 636a 286c 6873 2869 2c20 6b29  ] = cj(lhs(i, k)
-00017c80: 293b 0a20 2020 2069 6628 5061 6e65 6c4d  );.    if(PanelM
-00017c90: 6f64 6529 2063 6f75 6e74 202b 3d20 2873  ode) count += (s
-00017ca0: 7472 6964 652d 6f66 6673 6574 2d64 6570  tride-offset-dep
-00017cb0: 7468 293b 0a20 207d 0a7d 0a0a 7465 6d70  th);.  }.}..temp
-00017cc0: 6c61 7465 3c74 7970 656e 616d 6520 5363  late<typename Sc
-00017cd0: 616c 6172 2c20 7479 7065 6e61 6d65 2049  alar, typename I
-00017ce0: 6e64 6578 2c20 7479 7065 6e61 6d65 2044  ndex, typename D
-00017cf0: 6174 614d 6170 7065 722c 2069 6e74 2050  ataMapper, int P
-00017d00: 6163 6b31 2c20 696e 7420 5061 636b 322c  ack1, int Pack2,
-00017d10: 2074 7970 656e 616d 6520 5061 636b 6574   typename Packet
-00017d20: 2c20 626f 6f6c 2043 6f6e 6a75 6761 7465  , bool Conjugate
-00017d30: 2c20 626f 6f6c 2050 616e 656c 4d6f 6465  , bool PanelMode
-00017d40: 3e0a 7374 7275 6374 2067 656d 6d5f 7061  >.struct gemm_pa
-00017d50: 636b 5f6c 6873 3c53 6361 6c61 722c 2049  ck_lhs<Scalar, I
-00017d60: 6e64 6578 2c20 4461 7461 4d61 7070 6572  ndex, DataMapper
-00017d70: 2c20 5061 636b 312c 2050 6163 6b32 2c20  , Pack1, Pack2, 
-00017d80: 5061 636b 6574 2c20 526f 774d 616a 6f72  Packet, RowMajor
-00017d90: 2c20 436f 6e6a 7567 6174 652c 2050 616e  , Conjugate, Pan
-00017da0: 656c 4d6f 6465 3e0a 7b0a 2020 7479 7065  elMode>.{.  type
-00017db0: 6465 6620 7479 7065 6e61 6d65 2044 6174  def typename Dat
-00017dc0: 614d 6170 7065 723a 3a4c 696e 6561 724d  aMapper::LinearM
-00017dd0: 6170 7065 7220 4c69 6e65 6172 4d61 7070  apper LinearMapp
-00017de0: 6572 3b0a 2020 4549 4745 4e5f 444f 4e54  er;.  EIGEN_DONT
-00017df0: 5f49 4e4c 494e 4520 766f 6964 206f 7065  _INLINE void ope
-00017e00: 7261 746f 7228 2928 5363 616c 6172 2a20  rator()(Scalar* 
-00017e10: 626c 6f63 6b41 2c20 636f 6e73 7420 4461  blockA, const Da
-00017e20: 7461 4d61 7070 6572 2620 6c68 732c 2049  taMapper& lhs, I
-00017e30: 6e64 6578 2064 6570 7468 2c20 496e 6465  ndex depth, Inde
-00017e40: 7820 726f 7773 2c20 496e 6465 7820 7374  x rows, Index st
-00017e50: 7269 6465 3d30 2c20 496e 6465 7820 6f66  ride=0, Index of
-00017e60: 6673 6574 3d30 293b 0a7d 3b0a 0a74 656d  fset=0);.};..tem
-00017e70: 706c 6174 653c 7479 7065 6e61 6d65 2053  plate<typename S
-00017e80: 6361 6c61 722c 2074 7970 656e 616d 6520  calar, typename 
-00017e90: 496e 6465 782c 2074 7970 656e 616d 6520  Index, typename 
-00017ea0: 4461 7461 4d61 7070 6572 2c20 696e 7420  DataMapper, int 
-00017eb0: 5061 636b 312c 2069 6e74 2050 6163 6b32  Pack1, int Pack2
-00017ec0: 2c20 7479 7065 6e61 6d65 2050 6163 6b65  , typename Packe
-00017ed0: 742c 2062 6f6f 6c20 436f 6e6a 7567 6174  t, bool Conjugat
-00017ee0: 652c 2062 6f6f 6c20 5061 6e65 6c4d 6f64  e, bool PanelMod
-00017ef0: 653e 0a45 4947 454e 5f44 4f4e 545f 494e  e>.EIGEN_DONT_IN
-00017f00: 4c49 4e45 2076 6f69 6420 6765 6d6d 5f70  LINE void gemm_p
-00017f10: 6163 6b5f 6c68 733c 5363 616c 6172 2c20  ack_lhs<Scalar, 
-00017f20: 496e 6465 782c 2044 6174 614d 6170 7065  Index, DataMappe
-00017f30: 722c 2050 6163 6b31 2c20 5061 636b 322c  r, Pack1, Pack2,
-00017f40: 2050 6163 6b65 742c 2052 6f77 4d61 6a6f   Packet, RowMajo
-00017f50: 722c 2043 6f6e 6a75 6761 7465 2c20 5061  r, Conjugate, Pa
-00017f60: 6e65 6c4d 6f64 653e 0a20 203a 3a6f 7065  nelMode>.  ::ope
-00017f70: 7261 746f 7228 2928 5363 616c 6172 2a20  rator()(Scalar* 
-00017f80: 626c 6f63 6b41 2c20 636f 6e73 7420 4461  blockA, const Da
-00017f90: 7461 4d61 7070 6572 2620 6c68 732c 2049  taMapper& lhs, I
-00017fa0: 6e64 6578 2064 6570 7468 2c20 496e 6465  ndex depth, Inde
-00017fb0: 7820 726f 7773 2c20 496e 6465 7820 7374  x rows, Index st
-00017fc0: 7269 6465 2c20 496e 6465 7820 6f66 6673  ride, Index offs
-00017fd0: 6574 290a 7b0a 2020 7479 7065 6465 6620  et).{.  typedef 
-00017fe0: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
-00017ff0: 745f 7472 6169 7473 3c50 6163 6b65 743e  t_traits<Packet>
-00018000: 3a3a 6861 6c66 2048 616c 6650 6163 6b65  ::half HalfPacke
-00018010: 743b 0a20 2074 7970 6564 6566 2074 7970  t;.  typedef typ
-00018020: 656e 616d 6520 756e 7061 636b 6574 5f74  ename unpacket_t
-00018030: 7261 6974 733c 7479 7065 6e61 6d65 2075  raits<typename u
-00018040: 6e70 6163 6b65 745f 7472 6169 7473 3c50  npacket_traits<P
-00018050: 6163 6b65 743e 3a3a 6861 6c66 3e3a 3a68  acket>::half>::h
-00018060: 616c 6620 5175 6172 7465 7250 6163 6b65  alf QuarterPacke
-00018070: 743b 0a20 2065 6e75 6d20 7b20 5061 636b  t;.  enum { Pack
-00018080: 6574 5369 7a65 203d 2075 6e70 6163 6b65  etSize = unpacke
-00018090: 745f 7472 6169 7473 3c50 6163 6b65 743e  t_traits<Packet>
-000180a0: 3a3a 7369 7a65 2c0a 2020 2020 2020 2020  ::size,.        
-000180b0: 2048 616c 6650 6163 6b65 7453 697a 6520   HalfPacketSize 
-000180c0: 3d20 756e 7061 636b 6574 5f74 7261 6974  = unpacket_trait
-000180d0: 733c 4861 6c66 5061 636b 6574 3e3a 3a73  s<HalfPacket>::s
-000180e0: 697a 652c 0a20 2020 2020 2020 2020 5175  ize,.         Qu
-000180f0: 6172 7465 7250 6163 6b65 7453 697a 6520  arterPacketSize 
-00018100: 3d20 756e 7061 636b 6574 5f74 7261 6974  = unpacket_trait
-00018110: 733c 5175 6172 7465 7250 6163 6b65 743e  s<QuarterPacket>
-00018120: 3a3a 7369 7a65 2c0a 2020 2020 2020 2020  ::size,.        
-00018130: 2048 6173 4861 6c66 203d 2028 696e 7429   HasHalf = (int)
-00018140: 4861 6c66 5061 636b 6574 5369 7a65 203c  HalfPacketSize <
-00018150: 2028 696e 7429 5061 636b 6574 5369 7a65   (int)PacketSize
-00018160: 2c0a 2020 2020 2020 2020 2048 6173 5175  ,.         HasQu
-00018170: 6172 7465 7220 3d20 2869 6e74 2951 7561  arter = (int)Qua
-00018180: 7274 6572 5061 636b 6574 5369 7a65 203c  rterPacketSize <
-00018190: 2028 696e 7429 4861 6c66 5061 636b 6574   (int)HalfPacket
-000181a0: 5369 7a65 7d3b 0a0a 2020 4549 4745 4e5f  Size};..  EIGEN_
-000181b0: 4153 4d5f 434f 4d4d 454e 5428 2245 4947  ASM_COMMENT("EIG
-000181c0: 454e 2050 524f 4455 4354 2050 4143 4b20  EN PRODUCT PACK 
-000181d0: 4c48 5322 293b 0a20 2045 4947 454e 5f55  LHS");.  EIGEN_U
-000181e0: 4e55 5345 445f 5641 5249 4142 4c45 2873  NUSED_VARIABLE(s
-000181f0: 7472 6964 6529 3b0a 2020 4549 4745 4e5f  tride);.  EIGEN_
-00018200: 554e 5553 4544 5f56 4152 4941 424c 4528  UNUSED_VARIABLE(
-00018210: 6f66 6673 6574 293b 0a20 2065 6967 656e  offset);.  eigen
-00018220: 5f61 7373 6572 7428 2828 2150 616e 656c  _assert(((!Panel
-00018230: 4d6f 6465 2920 2626 2073 7472 6964 653d  Mode) && stride=
-00018240: 3d30 2026 2620 6f66 6673 6574 3d3d 3029  =0 && offset==0)
-00018250: 207c 7c20 2850 616e 656c 4d6f 6465 2026   || (PanelMode &
-00018260: 2620 7374 7269 6465 3e3d 6465 7074 6820  & stride>=depth 
-00018270: 2626 206f 6666 7365 743c 3d73 7472 6964  && offset<=strid
-00018280: 6529 293b 0a20 2063 6f6e 6a5f 6966 3c4e  e));.  conj_if<N
-00018290: 756d 5472 6169 7473 3c53 6361 6c61 723e  umTraits<Scalar>
-000182a0: 3a3a 4973 436f 6d70 6c65 7820 2626 2043  ::IsComplex && C
-000182b0: 6f6e 6a75 6761 7465 3e20 636a 3b0a 2020  onjugate> cj;.  
-000182c0: 496e 6465 7820 636f 756e 7420 3d20 303b  Index count = 0;
-000182d0: 0a20 2062 6f6f 6c20 676f 6e65 5f68 616c  .  bool gone_hal
-000182e0: 6620 3d20 6661 6c73 652c 2067 6f6e 655f  f = false, gone_
-000182f0: 7175 6172 7465 7220 3d20 6661 6c73 652c  quarter = false,
-00018300: 2067 6f6e 655f 6c61 7374 203d 2066 616c   gone_last = fal
-00018310: 7365 3b0a 0a20 2049 6e64 6578 2069 203d  se;..  Index i =
-00018320: 2030 3b0a 2020 696e 7420 7061 636b 203d   0;.  int pack =
-00018330: 2050 6163 6b31 3b0a 2020 696e 7420 7073   Pack1;.  int ps
-00018340: 697a 6520 3d20 5061 636b 6574 5369 7a65  ize = PacketSize
-00018350: 3b0a 2020 7768 696c 6528 7061 636b 3e30  ;.  while(pack>0
-00018360: 290a 2020 7b0a 2020 2020 496e 6465 7820  ).  {.    Index 
-00018370: 7265 6d61 696e 696e 675f 726f 7773 203d  remaining_rows =
-00018380: 2072 6f77 732d 693b 0a20 2020 2049 6e64   rows-i;.    Ind
-00018390: 6578 2070 6565 6c65 645f 6d63 203d 2067  ex peeled_mc = g
-000183a0: 6f6e 655f 6c61 7374 203f 2050 6163 6b32  one_last ? Pack2
-000183b0: 3e31 203f 2028 726f 7773 2f70 6163 6b29  >1 ? (rows/pack)
-000183c0: 2a70 6163 6b20 3a20 3020 3a20 692b 2872  *pack : 0 : i+(r
-000183d0: 656d 6169 6e69 6e67 5f72 6f77 732f 7061  emaining_rows/pa
-000183e0: 636b 292a 7061 636b 3b0a 2020 2020 496e  ck)*pack;.    In
-000183f0: 6465 7820 7374 6172 7469 6e67 5f70 6f73  dex starting_pos
-00018400: 203d 2069 3b0a 2020 2020 666f 7228 3b20   = i;.    for(; 
-00018410: 693c 7065 656c 6564 5f6d 633b 2069 2b3d  i<peeled_mc; i+=
-00018420: 7061 636b 290a 2020 2020 7b0a 2020 2020  pack).    {.    
-00018430: 2020 6966 2850 616e 656c 4d6f 6465 2920    if(PanelMode) 
-00018440: 636f 756e 7420 2b3d 2070 6163 6b20 2a20  count += pack * 
-00018450: 6f66 6673 6574 3b0a 0a20 2020 2020 2049  offset;..      I
-00018460: 6e64 6578 206b 3d30 3b0a 2020 2020 2020  ndex k=0;.      
-00018470: 6966 2870 6163 6b3e 3d70 7369 7a65 2026  if(pack>=psize &
-00018480: 2620 7073 697a 6520 3e3d 2051 7561 7274  & psize >= Quart
-00018490: 6572 5061 636b 6574 5369 7a65 290a 2020  erPacketSize).  
-000184a0: 2020 2020 7b0a 2020 2020 2020 2020 636f      {.        co
-000184b0: 6e73 7420 496e 6465 7820 7065 656c 6564  nst Index peeled
-000184c0: 5f6b 203d 2028 6465 7074 682f 7073 697a  _k = (depth/psiz
-000184d0: 6529 2a70 7369 7a65 3b0a 2020 2020 2020  e)*psize;.      
-000184e0: 2020 666f 7228 3b20 6b3c 7065 656c 6564    for(; k<peeled
-000184f0: 5f6b 3b20 6b2b 3d70 7369 7a65 290a 2020  _k; k+=psize).  
-00018500: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
-00018510: 2020 666f 7220 2849 6e64 6578 206d 203d    for (Index m =
-00018520: 2030 3b20 6d20 3c20 7061 636b 3b20 6d20   0; m < pack; m 
-00018530: 2b3d 2070 7369 7a65 290a 2020 2020 2020  += psize).      
-00018540: 2020 2020 7b0a 2020 2020 2020 2020 2020      {.          
-00018550: 2020 6966 2028 7073 697a 6520 3d3d 2050    if (psize == P
-00018560: 6163 6b65 7453 697a 6529 207b 0a20 2020  acketSize) {.   
-00018570: 2020 2020 2020 2020 2020 2050 6163 6b65             Packe
-00018580: 7442 6c6f 636b 3c50 6163 6b65 743e 206b  tBlock<Packet> k
-00018590: 6572 6e65 6c3b 0a20 2020 2020 2020 2020  ernel;.         
-000185a0: 2020 2020 2066 6f72 2028 696e 7420 7020       for (int p 
-000185b0: 3d20 303b 2070 203c 2070 7369 7a65 3b20  = 0; p < psize; 
-000185c0: 2b2b 7029 206b 6572 6e65 6c2e 7061 636b  ++p) kernel.pack
-000185d0: 6574 5b70 5d20 3d20 6c68 732e 7465 6d70  et[p] = lhs.temp
-000185e0: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
-000185f0: 5061 636b 6574 3e28 692b 702b 6d2c 206b  Packet>(i+p+m, k
-00018600: 293b 0a20 2020 2020 2020 2020 2020 2020  );.             
-00018610: 2070 7472 616e 7370 6f73 6528 6b65 726e   ptranspose(kern
-00018620: 656c 293b 0a20 2020 2020 2020 2020 2020  el);.           
-00018630: 2020 2066 6f72 2028 696e 7420 7020 3d20     for (int p = 
-00018640: 303b 2070 203c 2070 7369 7a65 3b20 2b2b  0; p < psize; ++
-00018650: 7029 2070 7374 6f72 6528 626c 6f63 6b41  p) pstore(blockA
-00018660: 2b63 6f75 6e74 2b6d 2b28 7061 636b 292a  +count+m+(pack)*
-00018670: 702c 2063 6a2e 7063 6f6e 6a28 6b65 726e  p, cj.pconj(kern
-00018680: 656c 2e70 6163 6b65 745b 705d 2929 3b0a  el.packet[p]));.
-00018690: 2020 2020 2020 2020 2020 2020 7d20 656c              } el
-000186a0: 7365 2069 6620 2848 6173 4861 6c66 2026  se if (HasHalf &
-000186b0: 2620 7073 697a 6520 3d3d 2048 616c 6650  & psize == HalfP
-000186c0: 6163 6b65 7453 697a 6529 207b 0a20 2020  acketSize) {.   
-000186d0: 2020 2020 2020 2020 2020 2067 6f6e 655f             gone_
-000186e0: 6861 6c66 203d 2074 7275 653b 0a20 2020  half = true;.   
-000186f0: 2020 2020 2020 2020 2020 2050 6163 6b65             Packe
-00018700: 7442 6c6f 636b 3c48 616c 6650 6163 6b65  tBlock<HalfPacke
-00018710: 743e 206b 6572 6e65 6c5f 6861 6c66 3b0a  t> kernel_half;.
-00018720: 2020 2020 2020 2020 2020 2020 2020 666f                fo
-00018730: 7220 2869 6e74 2070 203d 2030 3b20 7020  r (int p = 0; p 
-00018740: 3c20 7073 697a 653b 202b 2b70 2920 6b65  < psize; ++p) ke
-00018750: 726e 656c 5f68 616c 662e 7061 636b 6574  rnel_half.packet
-00018760: 5b70 5d20 3d20 6c68 732e 7465 6d70 6c61  [p] = lhs.templa
-00018770: 7465 206c 6f61 6450 6163 6b65 743c 4861  te loadPacket<Ha
-00018780: 6c66 5061 636b 6574 3e28 692b 702b 6d2c  lfPacket>(i+p+m,
-00018790: 206b 293b 0a20 2020 2020 2020 2020 2020   k);.           
-000187a0: 2020 2070 7472 616e 7370 6f73 6528 6b65     ptranspose(ke
-000187b0: 726e 656c 5f68 616c 6629 3b0a 2020 2020  rnel_half);.    
-000187c0: 2020 2020 2020 2020 2020 666f 7220 2869            for (i
-000187d0: 6e74 2070 203d 2030 3b20 7020 3c20 7073  nt p = 0; p < ps
-000187e0: 697a 653b 202b 2b70 2920 7073 746f 7265  ize; ++p) pstore
-000187f0: 2862 6c6f 636b 412b 636f 756e 742b 6d2b  (blockA+count+m+
-00018800: 2870 6163 6b29 2a70 2c20 636a 2e70 636f  (pack)*p, cj.pco
-00018810: 6e6a 286b 6572 6e65 6c5f 6861 6c66 2e70  nj(kernel_half.p
-00018820: 6163 6b65 745b 705d 2929 3b0a 2020 2020  acket[p]));.    
-00018830: 2020 2020 2020 2020 7d20 656c 7365 2069          } else i
-00018840: 6620 2848 6173 5175 6172 7465 7220 2626  f (HasQuarter &&
-00018850: 2070 7369 7a65 203d 3d20 5175 6172 7465   psize == Quarte
-00018860: 7250 6163 6b65 7453 697a 6529 207b 0a20  rPacketSize) {. 
-00018870: 2020 2020 2020 2020 2020 2020 2067 6f6e               gon
-00018880: 655f 7175 6172 7465 7220 3d20 7472 7565  e_quarter = true
-00018890: 3b0a 2020 2020 2020 2020 2020 2020 2020  ;.              
-000188a0: 5061 636b 6574 426c 6f63 6b3c 5175 6172  PacketBlock<Quar
-000188b0: 7465 7250 6163 6b65 743e 206b 6572 6e65  terPacket> kerne
-000188c0: 6c5f 7175 6172 7465 723b 0a20 2020 2020  l_quarter;.     
-000188d0: 2020 2020 2020 2020 2066 6f72 2028 696e           for (in
-000188e0: 7420 7020 3d20 303b 2070 203c 2070 7369  t p = 0; p < psi
-000188f0: 7a65 3b20 2b2b 7029 206b 6572 6e65 6c5f  ze; ++p) kernel_
-00018900: 7175 6172 7465 722e 7061 636b 6574 5b70  quarter.packet[p
-00018910: 5d20 3d20 6c68 732e 7465 6d70 6c61 7465  ] = lhs.template
-00018920: 206c 6f61 6450 6163 6b65 743c 5175 6172   loadPacket<Quar
-00018930: 7465 7250 6163 6b65 743e 2869 2b70 2b6d  terPacket>(i+p+m
-00018940: 2c20 6b29 3b0a 2020 2020 2020 2020 2020  , k);.          
-00018950: 2020 2020 7074 7261 6e73 706f 7365 286b      ptranspose(k
-00018960: 6572 6e65 6c5f 7175 6172 7465 7229 3b0a  ernel_quarter);.
-00018970: 2020 2020 2020 2020 2020 2020 2020 666f                fo
-00018980: 7220 2869 6e74 2070 203d 2030 3b20 7020  r (int p = 0; p 
-00018990: 3c20 7073 697a 653b 202b 2b70 2920 7073  < psize; ++p) ps
-000189a0: 746f 7265 2862 6c6f 636b 412b 636f 756e  tore(blockA+coun
-000189b0: 742b 6d2b 2870 6163 6b29 2a70 2c20 636a  t+m+(pack)*p, cj
-000189c0: 2e70 636f 6e6a 286b 6572 6e65 6c5f 7175  .pconj(kernel_qu
-000189d0: 6172 7465 722e 7061 636b 6574 5b70 5d29  arter.packet[p])
-000189e0: 293b 0a09 2020 2020 7d0a 2020 2020 2020  );..    }.      
-000189f0: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
-00018a00: 636f 756e 7420 2b3d 2070 7369 7a65 2a70  count += psize*p
-00018a10: 6163 6b3b 0a20 2020 2020 2020 207d 0a20  ack;.        }. 
-00018a20: 2020 2020 207d 0a0a 2020 2020 2020 666f       }..      fo
-00018a30: 7228 3b20 6b3c 6465 7074 683b 206b 2b2b  r(; k<depth; k++
-00018a40: 290a 2020 2020 2020 7b0a 2020 2020 2020  ).      {.      
-00018a50: 2020 496e 6465 7820 773d 303b 0a20 2020    Index w=0;.   
-00018a60: 2020 2020 2066 6f72 283b 2077 3c70 6163       for(; w<pac
-00018a70: 6b2d 333b 2077 2b3d 3429 0a20 2020 2020  k-3; w+=4).     
-00018a80: 2020 207b 0a20 2020 2020 2020 2020 2053     {.          S
-00018a90: 6361 6c61 7220 6128 636a 286c 6873 2869  calar a(cj(lhs(i
-00018aa0: 2b77 2b30 2c20 6b29 2929 2c0a 2020 2020  +w+0, k))),.    
-00018ab0: 2020 2020 2020 2020 2020 2020 2062 2863               b(c
-00018ac0: 6a28 6c68 7328 692b 772b 312c 206b 2929  j(lhs(i+w+1, k))
-00018ad0: 292c 0a20 2020 2020 2020 2020 2020 2020  ),.             
-00018ae0: 2020 2020 6328 636a 286c 6873 2869 2b77      c(cj(lhs(i+w
-00018af0: 2b32 2c20 6b29 2929 2c0a 2020 2020 2020  +2, k))),.      
-00018b00: 2020 2020 2020 2020 2020 2064 2863 6a28             d(cj(
-00018b10: 6c68 7328 692b 772b 332c 206b 2929 293b  lhs(i+w+3, k)));
-00018b20: 0a20 2020 2020 2020 2020 2062 6c6f 636b  .          block
-00018b30: 415b 636f 756e 742b 2b5d 203d 2061 3b0a  A[count++] = a;.
-00018b40: 2020 2020 2020 2020 2020 626c 6f63 6b41            blockA
-00018b50: 5b63 6f75 6e74 2b2b 5d20 3d20 623b 0a20  [count++] = b;. 
-00018b60: 2020 2020 2020 2020 2062 6c6f 636b 415b           blockA[
-00018b70: 636f 756e 742b 2b5d 203d 2063 3b0a 2020  count++] = c;.  
-00018b80: 2020 2020 2020 2020 626c 6f63 6b41 5b63          blockA[c
-00018b90: 6f75 6e74 2b2b 5d20 3d20 643b 0a20 2020  ount++] = d;.   
-00018ba0: 2020 2020 207d 0a20 2020 2020 2020 2069       }.        i
-00018bb0: 6628 7061 636b 2534 290a 2020 2020 2020  f(pack%4).      
-00018bc0: 2020 2020 666f 7228 3b77 3c70 6163 6b3b      for(;w<pack;
-00018bd0: 2b2b 7729 0a20 2020 2020 2020 2020 2020  ++w).           
-00018be0: 2062 6c6f 636b 415b 636f 756e 742b 2b5d   blockA[count++]
-00018bf0: 203d 2063 6a28 6c68 7328 692b 772c 206b   = cj(lhs(i+w, k
-00018c00: 2929 3b0a 2020 2020 2020 7d0a 0a20 2020  ));.      }..   
-00018c10: 2020 2069 6628 5061 6e65 6c4d 6f64 6529     if(PanelMode)
-00018c20: 2063 6f75 6e74 202b 3d20 7061 636b 202a   count += pack *
-00018c30: 2028 7374 7269 6465 2d6f 6666 7365 742d   (stride-offset-
-00018c40: 6465 7074 6829 3b0a 2020 2020 7d0a 0a20  depth);.    }.. 
-00018c50: 2020 2070 6163 6b20 2d3d 2070 7369 7a65     pack -= psize
-00018c60: 3b0a 2020 2020 496e 6465 7820 6c65 6674  ;.    Index left
-00018c70: 203d 2072 6f77 7320 2d20 693b 0a20 2020   = rows - i;.   
-00018c80: 2069 6620 2870 6163 6b20 3c3d 2030 2920   if (pack <= 0) 
-00018c90: 7b0a 2020 2020 2020 6966 2028 2167 6f6e  {.      if (!gon
-00018ca0: 655f 6c61 7374 2026 260a 2020 2020 2020  e_last &&.      
-00018cb0: 2020 2020 2873 7461 7274 696e 675f 706f      (starting_po
-00018cc0: 7320 3d3d 2069 207c 7c20 6c65 6674 203e  s == i || left >
-00018cd0: 3d20 7073 697a 652f 3220 7c7c 206c 6566  = psize/2 || lef
-00018ce0: 7420 3e3d 2070 7369 7a65 2f34 2920 2626  t >= psize/4) &&
-00018cf0: 0a20 2020 2020 2020 2020 2028 2870 7369  .          ((psi
-00018d00: 7a65 2f32 203d 3d20 4861 6c66 5061 636b  ze/2 == HalfPack
-00018d10: 6574 5369 7a65 2026 2620 4861 7348 616c  etSize && HasHal
-00018d20: 6620 2626 2021 676f 6e65 5f68 616c 6629  f && !gone_half)
-00018d30: 207c 7c0a 2020 2020 2020 2020 2020 2028   ||.           (
-00018d40: 7073 697a 652f 3220 3d3d 2051 7561 7274  psize/2 == Quart
-00018d50: 6572 5061 636b 6574 5369 7a65 2026 2620  erPacketSize && 
-00018d60: 4861 7351 7561 7274 6572 2026 2620 2167  HasQuarter && !g
-00018d70: 6f6e 655f 7175 6172 7465 7229 2929 207b  one_quarter))) {
-00018d80: 0a20 2020 2020 2020 2070 7369 7a65 202f  .        psize /
-00018d90: 3d20 323b 0a20 2020 2020 2020 2070 6163  = 2;.        pac
-00018da0: 6b20 3d20 7073 697a 653b 0a20 2020 2020  k = psize;.     
-00018db0: 2020 2063 6f6e 7469 6e75 653b 0a20 2020     continue;.   
-00018dc0: 2020 207d 0a20 2020 2020 202f 2f20 5061     }.      // Pa
-00018dd0: 636b 3220 6d61 7920 6265 202a 736d 616c  ck2 may be *smal
-00018de0: 6c65 722a 2074 6861 6e20 5061 636b 6574  ler* than Packet
-00018df0: 5369 7a65 e280 9474 6861 7420 6861 7070  Size...that happ
-00018e00: 656e 7320 666f 720a 2020 2020 2020 2f2f  ens for.      //
-00018e10: 2070 726f 6475 6374 7320 6c69 6b65 2072   products like r
-00018e20: 6561 6c20 2a20 636f 6d70 6c65 782c 2077  eal * complex, w
-00018e30: 6865 7265 2077 6520 6861 7665 2074 6f20  here we have to 
-00018e40: 676f 2068 616c 6620 7468 650a 2020 2020  go half the.    
-00018e50: 2020 2f2f 2070 726f 6772 6573 7320 6f6e    // progress on
-00018e60: 2074 6865 206c 6873 2069 6e20 6f72 6465   the lhs in orde
-00018e70: 7220 746f 2064 7570 6c69 6361 7465 2074  r to duplicate t
-00018e80: 686f 7365 206f 7065 7261 6e64 7320 746f  hose operands to
-00018e90: 0a20 2020 2020 202f 2f20 6164 6472 6573  .      // addres
-00018ea0: 7320 626f 7468 2072 6561 6c20 2620 696d  s both real & im
-00018eb0: 6167 696e 6172 7920 7061 7274 7320 6f6e  aginary parts on
-00018ec0: 2074 6865 2072 6873 2e20 5468 6973 2070   the rhs. This p
-00018ed0: 6f72 7469 6f6e 2077 696c 6c0a 2020 2020  ortion will.    
-00018ee0: 2020 2f2f 2070 6163 6b20 7468 6f73 6520    // pack those 
-00018ef0: 6861 6c66 206f 6e65 7320 756e 7469 6c20  half ones until 
-00018f00: 7468 6579 206d 6174 6368 2074 6865 206e  they match the n
-00018f10: 756d 6265 7220 6578 7065 6374 6564 206f  umber expected o
-00018f20: 6e20 7468 650a 2020 2020 2020 2f2f 206c  n the.      // l
-00018f30: 6173 7420 7065 656c 696e 6720 6c6f 6f70  ast peeling loop
-00018f40: 2061 7420 7468 6973 2070 6f69 6e74 2028   at this point (
-00018f50: 666f 7220 7468 6520 7268 7329 2e0a 2020  for the rhs)..  
-00018f60: 2020 2020 6966 2028 5061 636b 3220 3c20      if (Pack2 < 
-00018f70: 5061 636b 6574 5369 7a65 2026 2620 2167  PacketSize && !g
-00018f80: 6f6e 655f 6c61 7374 2920 7b0a 2020 2020  one_last) {.    
-00018f90: 2020 2020 676f 6e65 5f6c 6173 7420 3d20      gone_last = 
-00018fa0: 7472 7565 3b0a 2020 2020 2020 2020 7073  true;.        ps
-00018fb0: 697a 6520 3d20 7061 636b 203d 206c 6566  ize = pack = lef
-00018fc0: 7420 2620 7e31 3b0a 2020 2020 2020 7d0a  t & ~1;.      }.
-00018fd0: 2020 2020 7d0a 2020 7d0a 0a20 2066 6f72      }.  }..  for
-00018fe0: 283b 2069 3c72 6f77 733b 2069 2b2b 290a  (; i<rows; i++).
-00018ff0: 2020 7b0a 2020 2020 6966 2850 616e 656c    {.    if(Panel
-00019000: 4d6f 6465 2920 636f 756e 7420 2b3d 206f  Mode) count += o
-00019010: 6666 7365 743b 0a20 2020 2066 6f72 2849  ffset;.    for(I
-00019020: 6e64 6578 206b 3d30 3b20 6b3c 6465 7074  ndex k=0; k<dept
-00019030: 683b 206b 2b2b 290a 2020 2020 2020 626c  h; k++).      bl
-00019040: 6f63 6b41 5b63 6f75 6e74 2b2b 5d20 3d20  ockA[count++] = 
-00019050: 636a 286c 6873 2869 2c20 6b29 293b 0a20  cj(lhs(i, k));. 
-00019060: 2020 2069 6628 5061 6e65 6c4d 6f64 6529     if(PanelMode)
-00019070: 2063 6f75 6e74 202b 3d20 2873 7472 6964   count += (strid
-00019080: 652d 6f66 6673 6574 2d64 6570 7468 293b  e-offset-depth);
-00019090: 0a20 207d 0a7d 0a0a 2f2f 2063 6f70 7920  .  }.}..// copy 
-000190a0: 6120 636f 6d70 6c65 7465 2070 616e 656c  a complete panel
-000190b0: 206f 6620 7468 6520 7268 730a 2f2f 2074   of the rhs.// t
-000190c0: 6869 7320 7665 7273 696f 6e20 6973 206f  his version is o
-000190d0: 7074 696d 697a 6564 2066 6f72 2063 6f6c  ptimized for col
-000190e0: 756d 6e20 6d61 6a6f 7220 6d61 7472 6963  umn major matric
-000190f0: 6573 0a2f 2f20 5468 6520 7472 6176 6572  es.// The traver
-00019100: 7361 6c20 6f72 6465 7220 6973 2061 7320  sal order is as 
-00019110: 666f 6c6c 6f77 3a20 286e 723d 3d34 293a  follow: (nr==4):
-00019120: 0a2f 2f20 2030 2020 3120 2032 2020 3320  .//  0  1  2  3 
-00019130: 2020 3132 2031 3320 3134 2031 3520 2020    12 13 14 15   
-00019140: 3234 2032 370a 2f2f 2020 3420 2035 2020  24 27.//  4  5  
-00019150: 3620 2037 2020 2031 3620 3137 2031 3820  6  7   16 17 18 
-00019160: 3139 2020 2032 3520 3238 0a2f 2f20 2038  19   25 28.//  8
-00019170: 2020 3920 3130 2031 3120 2020 3230 2032    9 10 11   20 2
-00019180: 3120 3232 2032 3320 2020 3236 2032 390a  1 22 23   26 29.
-00019190: 2f2f 2020 2e20 202e 2020 2e20 202e 2020  //  .  .  .  .  
-000191a0: 2020 2e20 202e 2020 2e20 202e 2020 2020    .  .  .  .    
-000191b0: 2e20 202e 0a74 656d 706c 6174 653c 7479  .  ..template<ty
-000191c0: 7065 6e61 6d65 2053 6361 6c61 722c 2074  pename Scalar, t
-000191d0: 7970 656e 616d 6520 496e 6465 782c 2074  ypename Index, t
-000191e0: 7970 656e 616d 6520 4461 7461 4d61 7070  ypename DataMapp
-000191f0: 6572 2c20 696e 7420 6e72 2c20 626f 6f6c  er, int nr, bool
-00019200: 2043 6f6e 6a75 6761 7465 2c20 626f 6f6c   Conjugate, bool
-00019210: 2050 616e 656c 4d6f 6465 3e0a 7374 7275   PanelMode>.stru
-00019220: 6374 2067 656d 6d5f 7061 636b 5f72 6873  ct gemm_pack_rhs
-00019230: 3c53 6361 6c61 722c 2049 6e64 6578 2c20  <Scalar, Index, 
-00019240: 4461 7461 4d61 7070 6572 2c20 6e72 2c20  DataMapper, nr, 
-00019250: 436f 6c4d 616a 6f72 2c20 436f 6e6a 7567  ColMajor, Conjug
-00019260: 6174 652c 2050 616e 656c 4d6f 6465 3e0a  ate, PanelMode>.
-00019270: 7b0a 2020 7479 7065 6465 6620 7479 7065  {.  typedef type
-00019280: 6e61 6d65 2070 6163 6b65 745f 7472 6169  name packet_trai
-00019290: 7473 3c53 6361 6c61 723e 3a3a 7479 7065  ts<Scalar>::type
-000192a0: 2050 6163 6b65 743b 0a20 2074 7970 6564   Packet;.  typed
-000192b0: 6566 2074 7970 656e 616d 6520 4461 7461  ef typename Data
-000192c0: 4d61 7070 6572 3a3a 4c69 6e65 6172 4d61  Mapper::LinearMa
-000192d0: 7070 6572 204c 696e 6561 724d 6170 7065  pper LinearMappe
-000192e0: 723b 0a20 2065 6e75 6d20 7b20 5061 636b  r;.  enum { Pack
-000192f0: 6574 5369 7a65 203d 2070 6163 6b65 745f  etSize = packet_
-00019300: 7472 6169 7473 3c53 6361 6c61 723e 3a3a  traits<Scalar>::
-00019310: 7369 7a65 207d 3b0a 2020 4549 4745 4e5f  size };.  EIGEN_
-00019320: 444f 4e54 5f49 4e4c 494e 4520 766f 6964  DONT_INLINE void
-00019330: 206f 7065 7261 746f 7228 2928 5363 616c   operator()(Scal
-00019340: 6172 2a20 626c 6f63 6b42 2c20 636f 6e73  ar* blockB, cons
-00019350: 7420 4461 7461 4d61 7070 6572 2620 7268  t DataMapper& rh
-00019360: 732c 2049 6e64 6578 2064 6570 7468 2c20  s, Index depth, 
-00019370: 496e 6465 7820 636f 6c73 2c20 496e 6465  Index cols, Inde
-00019380: 7820 7374 7269 6465 3d30 2c20 496e 6465  x stride=0, Inde
-00019390: 7820 6f66 6673 6574 3d30 293b 0a7d 3b0a  x offset=0);.};.
-000193a0: 0a74 656d 706c 6174 653c 7479 7065 6e61  .template<typena
-000193b0: 6d65 2053 6361 6c61 722c 2074 7970 656e  me Scalar, typen
-000193c0: 616d 6520 496e 6465 782c 2074 7970 656e  ame Index, typen
-000193d0: 616d 6520 4461 7461 4d61 7070 6572 2c20  ame DataMapper, 
-000193e0: 696e 7420 6e72 2c20 626f 6f6c 2043 6f6e  int nr, bool Con
-000193f0: 6a75 6761 7465 2c20 626f 6f6c 2050 616e  jugate, bool Pan
-00019400: 656c 4d6f 6465 3e0a 4549 4745 4e5f 444f  elMode>.EIGEN_DO
-00019410: 4e54 5f49 4e4c 494e 4520 766f 6964 2067  NT_INLINE void g
-00019420: 656d 6d5f 7061 636b 5f72 6873 3c53 6361  emm_pack_rhs<Sca
-00019430: 6c61 722c 2049 6e64 6578 2c20 4461 7461  lar, Index, Data
-00019440: 4d61 7070 6572 2c20 6e72 2c20 436f 6c4d  Mapper, nr, ColM
-00019450: 616a 6f72 2c20 436f 6e6a 7567 6174 652c  ajor, Conjugate,
-00019460: 2050 616e 656c 4d6f 6465 3e0a 2020 3a3a   PanelMode>.  ::
-00019470: 6f70 6572 6174 6f72 2829 2853 6361 6c61  operator()(Scala
-00019480: 722a 2062 6c6f 636b 422c 2063 6f6e 7374  r* blockB, const
-00019490: 2044 6174 614d 6170 7065 7226 2072 6873   DataMapper& rhs
-000194a0: 2c20 496e 6465 7820 6465 7074 682c 2049  , Index depth, I
-000194b0: 6e64 6578 2063 6f6c 732c 2049 6e64 6578  ndex cols, Index
-000194c0: 2073 7472 6964 652c 2049 6e64 6578 206f   stride, Index o
-000194d0: 6666 7365 7429 0a7b 0a20 2045 4947 454e  ffset).{.  EIGEN
-000194e0: 5f41 534d 5f43 4f4d 4d45 4e54 2822 4549  _ASM_COMMENT("EI
-000194f0: 4745 4e20 5052 4f44 5543 5420 5041 434b  GEN PRODUCT PACK
-00019500: 2052 4853 2043 4f4c 4d41 4a4f 5222 293b   RHS COLMAJOR");
-00019510: 0a20 2045 4947 454e 5f55 4e55 5345 445f  .  EIGEN_UNUSED_
-00019520: 5641 5249 4142 4c45 2873 7472 6964 6529  VARIABLE(stride)
-00019530: 3b0a 2020 4549 4745 4e5f 554e 5553 4544  ;.  EIGEN_UNUSED
-00019540: 5f56 4152 4941 424c 4528 6f66 6673 6574  _VARIABLE(offset
-00019550: 293b 0a20 2065 6967 656e 5f61 7373 6572  );.  eigen_asser
-00019560: 7428 2828 2150 616e 656c 4d6f 6465 2920  t(((!PanelMode) 
-00019570: 2626 2073 7472 6964 653d 3d30 2026 2620  && stride==0 && 
-00019580: 6f66 6673 6574 3d3d 3029 207c 7c20 2850  offset==0) || (P
-00019590: 616e 656c 4d6f 6465 2026 2620 7374 7269  anelMode && stri
-000195a0: 6465 3e3d 6465 7074 6820 2626 206f 6666  de>=depth && off
-000195b0: 7365 743c 3d73 7472 6964 6529 293b 0a20  set<=stride));. 
-000195c0: 2063 6f6e 6a5f 6966 3c4e 756d 5472 6169   conj_if<NumTrai
-000195d0: 7473 3c53 6361 6c61 723e 3a3a 4973 436f  ts<Scalar>::IsCo
-000195e0: 6d70 6c65 7820 2626 2043 6f6e 6a75 6761  mplex && Conjuga
-000195f0: 7465 3e20 636a 3b0a 2020 496e 6465 7820  te> cj;.  Index 
-00019600: 7061 636b 6574 5f63 6f6c 7338 203d 206e  packet_cols8 = n
-00019610: 723e 3d38 203f 2028 636f 6c73 2f38 2920  r>=8 ? (cols/8) 
-00019620: 2a20 3820 3a20 303b 0a20 2049 6e64 6578  * 8 : 0;.  Index
-00019630: 2070 6163 6b65 745f 636f 6c73 3420 3d20   packet_cols4 = 
-00019640: 6e72 3e3d 3420 3f20 2863 6f6c 732f 3429  nr>=4 ? (cols/4)
-00019650: 202a 2034 203a 2030 3b0a 2020 496e 6465   * 4 : 0;.  Inde
-00019660: 7820 636f 756e 7420 3d20 303b 0a20 2063  x count = 0;.  c
-00019670: 6f6e 7374 2049 6e64 6578 2070 6565 6c65  onst Index peele
-00019680: 645f 6b20 3d20 2864 6570 7468 2f50 6163  d_k = (depth/Pac
-00019690: 6b65 7453 697a 6529 2a50 6163 6b65 7453  ketSize)*PacketS
-000196a0: 697a 653b 0a2f 2f20 2020 6966 286e 723e  ize;.//   if(nr>
-000196b0: 3d38 290a 2f2f 2020 207b 0a2f 2f20 2020  =8).//   {.//   
-000196c0: 2020 666f 7228 496e 6465 7820 6a32 3d30    for(Index j2=0
-000196d0: 3b20 6a32 3c70 6163 6b65 745f 636f 6c73  ; j2<packet_cols
-000196e0: 383b 206a 322b 3d38 290a 2f2f 2020 2020  8; j2+=8).//    
-000196f0: 207b 0a2f 2f20 2020 2020 2020 2f2f 2073   {.//       // s
-00019700: 6b69 7020 7768 6174 2077 6520 6861 7665  kip what we have
-00019710: 2062 6566 6f72 650a 2f2f 2020 2020 2020   before.//      
-00019720: 2069 6628 5061 6e65 6c4d 6f64 6529 2063   if(PanelMode) c
-00019730: 6f75 6e74 202b 3d20 3820 2a20 6f66 6673  ount += 8 * offs
-00019740: 6574 3b0a 2f2f 2020 2020 2020 2063 6f6e  et;.//       con
-00019750: 7374 2053 6361 6c61 722a 2062 3020 3d20  st Scalar* b0 = 
-00019760: 2672 6873 5b28 6a32 2b30 292a 7268 7353  &rhs[(j2+0)*rhsS
-00019770: 7472 6964 655d 3b0a 2f2f 2020 2020 2020  tride];.//      
-00019780: 2063 6f6e 7374 2053 6361 6c61 722a 2062   const Scalar* b
-00019790: 3120 3d20 2672 6873 5b28 6a32 2b31 292a  1 = &rhs[(j2+1)*
-000197a0: 7268 7353 7472 6964 655d 3b0a 2f2f 2020  rhsStride];.//  
-000197b0: 2020 2020 2063 6f6e 7374 2053 6361 6c61       const Scala
-000197c0: 722a 2062 3220 3d20 2672 6873 5b28 6a32  r* b2 = &rhs[(j2
-000197d0: 2b32 292a 7268 7353 7472 6964 655d 3b0a  +2)*rhsStride];.
-000197e0: 2f2f 2020 2020 2020 2063 6f6e 7374 2053  //       const S
-000197f0: 6361 6c61 722a 2062 3320 3d20 2672 6873  calar* b3 = &rhs
-00019800: 5b28 6a32 2b33 292a 7268 7353 7472 6964  [(j2+3)*rhsStrid
-00019810: 655d 3b0a 2f2f 2020 2020 2020 2063 6f6e  e];.//       con
-00019820: 7374 2053 6361 6c61 722a 2062 3420 3d20  st Scalar* b4 = 
-00019830: 2672 6873 5b28 6a32 2b34 292a 7268 7353  &rhs[(j2+4)*rhsS
-00019840: 7472 6964 655d 3b0a 2f2f 2020 2020 2020  tride];.//      
-00019850: 2063 6f6e 7374 2053 6361 6c61 722a 2062   const Scalar* b
-00019860: 3520 3d20 2672 6873 5b28 6a32 2b35 292a  5 = &rhs[(j2+5)*
-00019870: 7268 7353 7472 6964 655d 3b0a 2f2f 2020  rhsStride];.//  
-00019880: 2020 2020 2063 6f6e 7374 2053 6361 6c61       const Scala
-00019890: 722a 2062 3620 3d20 2672 6873 5b28 6a32  r* b6 = &rhs[(j2
-000198a0: 2b36 292a 7268 7353 7472 6964 655d 3b0a  +6)*rhsStride];.
-000198b0: 2f2f 2020 2020 2020 2063 6f6e 7374 2053  //       const S
-000198c0: 6361 6c61 722a 2062 3720 3d20 2672 6873  calar* b7 = &rhs
-000198d0: 5b28 6a32 2b37 292a 7268 7353 7472 6964  [(j2+7)*rhsStrid
-000198e0: 655d 3b0a 2f2f 2020 2020 2020 2049 6e64  e];.//       Ind
-000198f0: 6578 206b 3d30 3b0a 2f2f 2020 2020 2020  ex k=0;.//      
-00019900: 2069 6628 5061 636b 6574 5369 7a65 3d3d   if(PacketSize==
-00019910: 3829 202f 2f20 544f 444f 2065 6e61 626c  8) // TODO enabl
-00019920: 6520 7665 6374 6f72 697a 6564 2074 7261  e vectorized tra
-00019930: 6e73 706f 7369 7469 6f6e 2066 6f72 2050  nsposition for P
-00019940: 6163 6b65 7453 697a 653d 3d34 0a2f 2f20  acketSize==4.// 
-00019950: 2020 2020 2020 7b0a 2f2f 2020 2020 2020        {.//      
-00019960: 2020 2066 6f72 283b 206b 3c70 6565 6c65     for(; k<peele
-00019970: 645f 6b3b 206b 2b3d 5061 636b 6574 5369  d_k; k+=PacketSi
-00019980: 7a65 2920 7b0a 2f2f 2020 2020 2020 2020  ze) {.//        
-00019990: 2020 2050 6163 6b65 7442 6c6f 636b 3c50     PacketBlock<P
-000199a0: 6163 6b65 743e 206b 6572 6e65 6c3b 0a2f  acket> kernel;./
-000199b0: 2f20 2020 2020 2020 2020 2020 666f 7220  /           for 
-000199c0: 2869 6e74 2070 203d 2030 3b20 7020 3c20  (int p = 0; p < 
-000199d0: 5061 636b 6574 5369 7a65 3b20 2b2b 7029  PacketSize; ++p)
-000199e0: 207b 0a2f 2f20 2020 2020 2020 2020 2020   {.//           
-000199f0: 2020 6b65 726e 656c 2e70 6163 6b65 745b    kernel.packet[
-00019a00: 705d 203d 2070 6c6f 6164 753c 5061 636b  p] = ploadu<Pack
-00019a10: 6574 3e28 2672 6873 5b28 6a32 2b70 292a  et>(&rhs[(j2+p)*
-00019a20: 7268 7353 7472 6964 652b 6b5d 293b 0a2f  rhsStride+k]);./
-00019a30: 2f20 2020 2020 2020 2020 2020 7d0a 2f2f  /           }.//
-00019a40: 2020 2020 2020 2020 2020 2070 7472 616e             ptran
-00019a50: 7370 6f73 6528 6b65 726e 656c 293b 0a2f  spose(kernel);./
-00019a60: 2f20 2020 2020 2020 2020 2020 666f 7220  /           for 
-00019a70: 2869 6e74 2070 203d 2030 3b20 7020 3c20  (int p = 0; p < 
-00019a80: 5061 636b 6574 5369 7a65 3b20 2b2b 7029  PacketSize; ++p)
-00019a90: 207b 0a2f 2f20 2020 2020 2020 2020 2020   {.//           
-00019aa0: 2020 7073 746f 7265 7528 626c 6f63 6b42    pstoreu(blockB
-00019ab0: 2b63 6f75 6e74 2c20 636a 2e70 636f 6e6a  +count, cj.pconj
-00019ac0: 286b 6572 6e65 6c2e 7061 636b 6574 5b70  (kernel.packet[p
-00019ad0: 5d29 293b 0a2f 2f20 2020 2020 2020 2020  ]));.//         
-00019ae0: 2020 2020 636f 756e 742b 3d50 6163 6b65      count+=Packe
-00019af0: 7453 697a 653b 0a2f 2f20 2020 2020 2020  tSize;.//       
-00019b00: 2020 2020 7d0a 2f2f 2020 2020 2020 2020      }.//        
-00019b10: 207d 0a2f 2f20 2020 2020 2020 7d0a 2f2f   }.//       }.//
-00019b20: 2020 2020 2020 2066 6f72 283b 206b 3c64         for(; k<d
-00019b30: 6570 7468 3b20 6b2b 2b29 0a2f 2f20 2020  epth; k++).//   
-00019b40: 2020 2020 7b0a 2f2f 2020 2020 2020 2020      {.//        
-00019b50: 2062 6c6f 636b 425b 636f 756e 742b 305d   blockB[count+0]
-00019b60: 203d 2063 6a28 6230 5b6b 5d29 3b0a 2f2f   = cj(b0[k]);.//
-00019b70: 2020 2020 2020 2020 2062 6c6f 636b 425b           blockB[
-00019b80: 636f 756e 742b 315d 203d 2063 6a28 6231  count+1] = cj(b1
-00019b90: 5b6b 5d29 3b0a 2f2f 2020 2020 2020 2020  [k]);.//        
-00019ba0: 2062 6c6f 636b 425b 636f 756e 742b 325d   blockB[count+2]
-00019bb0: 203d 2063 6a28 6232 5b6b 5d29 3b0a 2f2f   = cj(b2[k]);.//
-00019bc0: 2020 2020 2020 2020 2062 6c6f 636b 425b           blockB[
-00019bd0: 636f 756e 742b 335d 203d 2063 6a28 6233  count+3] = cj(b3
-00019be0: 5b6b 5d29 3b0a 2f2f 2020 2020 2020 2020  [k]);.//        
-00019bf0: 2062 6c6f 636b 425b 636f 756e 742b 345d   blockB[count+4]
-00019c00: 203d 2063 6a28 6234 5b6b 5d29 3b0a 2f2f   = cj(b4[k]);.//
-00019c10: 2020 2020 2020 2020 2062 6c6f 636b 425b           blockB[
-00019c20: 636f 756e 742b 355d 203d 2063 6a28 6235  count+5] = cj(b5
-00019c30: 5b6b 5d29 3b0a 2f2f 2020 2020 2020 2020  [k]);.//        
-00019c40: 2062 6c6f 636b 425b 636f 756e 742b 365d   blockB[count+6]
-00019c50: 203d 2063 6a28 6236 5b6b 5d29 3b0a 2f2f   = cj(b6[k]);.//
-00019c60: 2020 2020 2020 2020 2062 6c6f 636b 425b           blockB[
-00019c70: 636f 756e 742b 375d 203d 2063 6a28 6237  count+7] = cj(b7
-00019c80: 5b6b 5d29 3b0a 2f2f 2020 2020 2020 2020  [k]);.//        
-00019c90: 2063 6f75 6e74 202b 3d20 383b 0a2f 2f20   count += 8;.// 
-00019ca0: 2020 2020 2020 7d0a 2f2f 2020 2020 2020        }.//      
-00019cb0: 202f 2f20 736b 6970 2077 6861 7420 7765   // skip what we
-00019cc0: 2068 6176 6520 6166 7465 720a 2f2f 2020   have after.//  
-00019cd0: 2020 2020 2069 6628 5061 6e65 6c4d 6f64       if(PanelMod
-00019ce0: 6529 2063 6f75 6e74 202b 3d20 3820 2a20  e) count += 8 * 
-00019cf0: 2873 7472 6964 652d 6f66 6673 6574 2d64  (stride-offset-d
-00019d00: 6570 7468 293b 0a2f 2f20 2020 2020 7d0a  epth);.//     }.
-00019d10: 2f2f 2020 207d 0a0a 2020 6966 286e 723e  //   }..  if(nr>
-00019d20: 3d34 290a 2020 7b0a 2020 2020 666f 7228  =4).  {.    for(
-00019d30: 496e 6465 7820 6a32 3d70 6163 6b65 745f  Index j2=packet_
-00019d40: 636f 6c73 383b 206a 323c 7061 636b 6574  cols8; j2<packet
-00019d50: 5f63 6f6c 7334 3b20 6a32 2b3d 3429 0a20  _cols4; j2+=4). 
-00019d60: 2020 207b 0a20 2020 2020 202f 2f20 736b     {.      // sk
-00019d70: 6970 2077 6861 7420 7765 2068 6176 6520  ip what we have 
-00019d80: 6265 666f 7265 0a20 2020 2020 2069 6628  before.      if(
-00019d90: 5061 6e65 6c4d 6f64 6529 2063 6f75 6e74  PanelMode) count
-00019da0: 202b 3d20 3420 2a20 6f66 6673 6574 3b0a   += 4 * offset;.
-00019db0: 2020 2020 2020 636f 6e73 7420 4c69 6e65        const Line
-00019dc0: 6172 4d61 7070 6572 2064 6d30 203d 2072  arMapper dm0 = r
-00019dd0: 6873 2e67 6574 4c69 6e65 6172 4d61 7070  hs.getLinearMapp
-00019de0: 6572 2830 2c20 6a32 202b 2030 293b 0a20  er(0, j2 + 0);. 
-00019df0: 2020 2020 2063 6f6e 7374 204c 696e 6561       const Linea
-00019e00: 724d 6170 7065 7220 646d 3120 3d20 7268  rMapper dm1 = rh
-00019e10: 732e 6765 744c 696e 6561 724d 6170 7065  s.getLinearMappe
-00019e20: 7228 302c 206a 3220 2b20 3129 3b0a 2020  r(0, j2 + 1);.  
-00019e30: 2020 2020 636f 6e73 7420 4c69 6e65 6172      const Linear
-00019e40: 4d61 7070 6572 2064 6d32 203d 2072 6873  Mapper dm2 = rhs
-00019e50: 2e67 6574 4c69 6e65 6172 4d61 7070 6572  .getLinearMapper
-00019e60: 2830 2c20 6a32 202b 2032 293b 0a20 2020  (0, j2 + 2);.   
-00019e70: 2020 2063 6f6e 7374 204c 696e 6561 724d     const LinearM
-00019e80: 6170 7065 7220 646d 3320 3d20 7268 732e  apper dm3 = rhs.
-00019e90: 6765 744c 696e 6561 724d 6170 7065 7228  getLinearMapper(
-00019ea0: 302c 206a 3220 2b20 3329 3b0a 0a20 2020  0, j2 + 3);..   
-00019eb0: 2020 2049 6e64 6578 206b 3d30 3b0a 2020     Index k=0;.  
-00019ec0: 2020 2020 6966 2828 5061 636b 6574 5369      if((PacketSi
-00019ed0: 7a65 2534 293d 3d30 2920 2f2f 2054 4f44  ze%4)==0) // TOD
-00019ee0: 4f20 656e 6162 6c65 2076 6563 746f 7269  O enable vectori
-00019ef0: 7a65 6420 7472 616e 7370 6f73 6974 696f  zed transpositio
-00019f00: 6e20 666f 7220 5061 636b 6574 5369 7a65  n for PacketSize
-00019f10: 3d3d 3220 3f3f 0a20 2020 2020 207b 0a20  ==2 ??.      {. 
-00019f20: 2020 2020 2020 2066 6f72 283b 206b 3c70         for(; k<p
-00019f30: 6565 6c65 645f 6b3b 206b 2b3d 5061 636b  eeled_k; k+=Pack
-00019f40: 6574 5369 7a65 2920 7b0a 2020 2020 2020  etSize) {.      
-00019f50: 2020 2020 5061 636b 6574 426c 6f63 6b3c      PacketBlock<
-00019f60: 5061 636b 6574 2c28 5061 636b 6574 5369  Packet,(PacketSi
-00019f70: 7a65 2534 293d 3d30 3f34 3a50 6163 6b65  ze%4)==0?4:Packe
-00019f80: 7453 697a 653e 206b 6572 6e65 6c3b 0a20  tSize> kernel;. 
-00019f90: 2020 2020 2020 2020 206b 6572 6e65 6c2e           kernel.
-00019fa0: 7061 636b 6574 5b30 2020 2020 2020 2020  packet[0        
-00019fb0: 2020 205d 203d 2064 6d30 2e74 656d 706c     ] = dm0.templ
-00019fc0: 6174 6520 6c6f 6164 5061 636b 6574 3c50  ate loadPacket<P
-00019fd0: 6163 6b65 743e 286b 293b 0a20 2020 2020  acket>(k);.     
-00019fe0: 2020 2020 206b 6572 6e65 6c2e 7061 636b       kernel.pack
-00019ff0: 6574 5b31 2550 6163 6b65 7453 697a 655d  et[1%PacketSize]
-0001a000: 203d 2064 6d31 2e74 656d 706c 6174 6520   = dm1.template 
-0001a010: 6c6f 6164 5061 636b 6574 3c50 6163 6b65  loadPacket<Packe
-0001a020: 743e 286b 293b 0a20 2020 2020 2020 2020  t>(k);.         
-0001a030: 206b 6572 6e65 6c2e 7061 636b 6574 5b32   kernel.packet[2
-0001a040: 2550 6163 6b65 7453 697a 655d 203d 2064  %PacketSize] = d
-0001a050: 6d32 2e74 656d 706c 6174 6520 6c6f 6164  m2.template load
-0001a060: 5061 636b 6574 3c50 6163 6b65 743e 286b  Packet<Packet>(k
-0001a070: 293b 0a20 2020 2020 2020 2020 206b 6572  );.          ker
-0001a080: 6e65 6c2e 7061 636b 6574 5b33 2550 6163  nel.packet[3%Pac
-0001a090: 6b65 7453 697a 655d 203d 2064 6d33 2e74  ketSize] = dm3.t
-0001a0a0: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
-0001a0b0: 6574 3c50 6163 6b65 743e 286b 293b 0a20  et<Packet>(k);. 
-0001a0c0: 2020 2020 2020 2020 2070 7472 616e 7370           ptransp
-0001a0d0: 6f73 6528 6b65 726e 656c 293b 0a20 2020  ose(kernel);.   
-0001a0e0: 2020 2020 2020 2070 7374 6f72 6575 2862         pstoreu(b
-0001a0f0: 6c6f 636b 422b 636f 756e 742b 302a 5061  lockB+count+0*Pa
-0001a100: 636b 6574 5369 7a65 2c20 636a 2e70 636f  cketSize, cj.pco
-0001a110: 6e6a 286b 6572 6e65 6c2e 7061 636b 6574  nj(kernel.packet
-0001a120: 5b30 5d29 293b 0a20 2020 2020 2020 2020  [0]));.         
-0001a130: 2070 7374 6f72 6575 2862 6c6f 636b 422b   pstoreu(blockB+
-0001a140: 636f 756e 742b 312a 5061 636b 6574 5369  count+1*PacketSi
-0001a150: 7a65 2c20 636a 2e70 636f 6e6a 286b 6572  ze, cj.pconj(ker
-0001a160: 6e65 6c2e 7061 636b 6574 5b31 2550 6163  nel.packet[1%Pac
-0001a170: 6b65 7453 697a 655d 2929 3b0a 2020 2020  ketSize]));.    
-0001a180: 2020 2020 2020 7073 746f 7265 7528 626c        pstoreu(bl
-0001a190: 6f63 6b42 2b63 6f75 6e74 2b32 2a50 6163  ockB+count+2*Pac
-0001a1a0: 6b65 7453 697a 652c 2063 6a2e 7063 6f6e  ketSize, cj.pcon
-0001a1b0: 6a28 6b65 726e 656c 2e70 6163 6b65 745b  j(kernel.packet[
-0001a1c0: 3225 5061 636b 6574 5369 7a65 5d29 293b  2%PacketSize]));
-0001a1d0: 0a20 2020 2020 2020 2020 2070 7374 6f72  .          pstor
-0001a1e0: 6575 2862 6c6f 636b 422b 636f 756e 742b  eu(blockB+count+
-0001a1f0: 332a 5061 636b 6574 5369 7a65 2c20 636a  3*PacketSize, cj
-0001a200: 2e70 636f 6e6a 286b 6572 6e65 6c2e 7061  .pconj(kernel.pa
-0001a210: 636b 6574 5b33 2550 6163 6b65 7453 697a  cket[3%PacketSiz
-0001a220: 655d 2929 3b0a 2020 2020 2020 2020 2020  e]));.          
-0001a230: 636f 756e 742b 3d34 2a50 6163 6b65 7453  count+=4*PacketS
-0001a240: 697a 653b 0a20 2020 2020 2020 207d 0a20  ize;.        }. 
-0001a250: 2020 2020 207d 0a20 2020 2020 2066 6f72       }.      for
-0001a260: 283b 206b 3c64 6570 7468 3b20 6b2b 2b29  (; k<depth; k++)
-0001a270: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
-0001a280: 2062 6c6f 636b 425b 636f 756e 742b 305d   blockB[count+0]
-0001a290: 203d 2063 6a28 646d 3028 6b29 293b 0a20   = cj(dm0(k));. 
-0001a2a0: 2020 2020 2020 2062 6c6f 636b 425b 636f         blockB[co
-0001a2b0: 756e 742b 315d 203d 2063 6a28 646d 3128  unt+1] = cj(dm1(
-0001a2c0: 6b29 293b 0a20 2020 2020 2020 2062 6c6f  k));.        blo
-0001a2d0: 636b 425b 636f 756e 742b 325d 203d 2063  ckB[count+2] = c
-0001a2e0: 6a28 646d 3228 6b29 293b 0a20 2020 2020  j(dm2(k));.     
-0001a2f0: 2020 2062 6c6f 636b 425b 636f 756e 742b     blockB[count+
-0001a300: 335d 203d 2063 6a28 646d 3328 6b29 293b  3] = cj(dm3(k));
-0001a310: 0a20 2020 2020 2020 2063 6f75 6e74 202b  .        count +
-0001a320: 3d20 343b 0a20 2020 2020 207d 0a20 2020  = 4;.      }.   
-0001a330: 2020 202f 2f20 736b 6970 2077 6861 7420     // skip what 
-0001a340: 7765 2068 6176 6520 6166 7465 720a 2020  we have after.  
-0001a350: 2020 2020 6966 2850 616e 656c 4d6f 6465      if(PanelMode
-0001a360: 2920 636f 756e 7420 2b3d 2034 202a 2028  ) count += 4 * (
-0001a370: 7374 7269 6465 2d6f 6666 7365 742d 6465  stride-offset-de
-0001a380: 7074 6829 3b0a 2020 2020 7d0a 2020 7d0a  pth);.    }.  }.
-0001a390: 0a20 202f 2f20 636f 7079 2074 6865 2072  .  // copy the r
-0001a3a0: 656d 6169 6e69 6e67 2063 6f6c 756d 6e73  emaining columns
-0001a3b0: 206f 6e65 2061 7420 6120 7469 6d65 2028   one at a time (
-0001a3c0: 6e72 3d3d 3129 0a20 2066 6f72 2849 6e64  nr==1).  for(Ind
-0001a3d0: 6578 206a 323d 7061 636b 6574 5f63 6f6c  ex j2=packet_col
-0001a3e0: 7334 3b20 6a32 3c63 6f6c 733b 202b 2b6a  s4; j2<cols; ++j
-0001a3f0: 3229 0a20 207b 0a20 2020 2069 6628 5061  2).  {.    if(Pa
-0001a400: 6e65 6c4d 6f64 6529 2063 6f75 6e74 202b  nelMode) count +
-0001a410: 3d20 6f66 6673 6574 3b0a 2020 2020 636f  = offset;.    co
-0001a420: 6e73 7420 4c69 6e65 6172 4d61 7070 6572  nst LinearMapper
-0001a430: 2064 6d30 203d 2072 6873 2e67 6574 4c69   dm0 = rhs.getLi
-0001a440: 6e65 6172 4d61 7070 6572 2830 2c20 6a32  nearMapper(0, j2
-0001a450: 293b 0a20 2020 2066 6f72 2849 6e64 6578  );.    for(Index
-0001a460: 206b 3d30 3b20 6b3c 6465 7074 683b 206b   k=0; k<depth; k
-0001a470: 2b2b 290a 2020 2020 7b0a 2020 2020 2020  ++).    {.      
-0001a480: 626c 6f63 6b42 5b63 6f75 6e74 5d20 3d20  blockB[count] = 
-0001a490: 636a 2864 6d30 286b 2929 3b0a 2020 2020  cj(dm0(k));.    
-0001a4a0: 2020 636f 756e 7420 2b3d 2031 3b0a 2020    count += 1;.  
-0001a4b0: 2020 7d0a 2020 2020 6966 2850 616e 656c    }.    if(Panel
-0001a4c0: 4d6f 6465 2920 636f 756e 7420 2b3d 2028  Mode) count += (
-0001a4d0: 7374 7269 6465 2d6f 6666 7365 742d 6465  stride-offset-de
-0001a4e0: 7074 6829 3b0a 2020 7d0a 7d0a 0a2f 2f20  pth);.  }.}..// 
-0001a4f0: 7468 6973 2076 6572 7369 6f6e 2069 7320  this version is 
-0001a500: 6f70 7469 6d69 7a65 6420 666f 7220 726f  optimized for ro
-0001a510: 7720 6d61 6a6f 7220 6d61 7472 6963 6573  w major matrices
-0001a520: 0a74 656d 706c 6174 653c 7479 7065 6e61  .template<typena
-0001a530: 6d65 2053 6361 6c61 722c 2074 7970 656e  me Scalar, typen
-0001a540: 616d 6520 496e 6465 782c 2074 7970 656e  ame Index, typen
-0001a550: 616d 6520 4461 7461 4d61 7070 6572 2c20  ame DataMapper, 
-0001a560: 696e 7420 6e72 2c20 626f 6f6c 2043 6f6e  int nr, bool Con
-0001a570: 6a75 6761 7465 2c20 626f 6f6c 2050 616e  jugate, bool Pan
-0001a580: 656c 4d6f 6465 3e0a 7374 7275 6374 2067  elMode>.struct g
-0001a590: 656d 6d5f 7061 636b 5f72 6873 3c53 6361  emm_pack_rhs<Sca
-0001a5a0: 6c61 722c 2049 6e64 6578 2c20 4461 7461  lar, Index, Data
-0001a5b0: 4d61 7070 6572 2c20 6e72 2c20 526f 774d  Mapper, nr, RowM
-0001a5c0: 616a 6f72 2c20 436f 6e6a 7567 6174 652c  ajor, Conjugate,
-0001a5d0: 2050 616e 656c 4d6f 6465 3e0a 7b0a 2020   PanelMode>.{.  
-0001a5e0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
-0001a5f0: 2070 6163 6b65 745f 7472 6169 7473 3c53   packet_traits<S
-0001a600: 6361 6c61 723e 3a3a 7479 7065 2050 6163  calar>::type Pac
-0001a610: 6b65 743b 0a20 2074 7970 6564 6566 2074  ket;.  typedef t
-0001a620: 7970 656e 616d 6520 4461 7461 4d61 7070  ypename DataMapp
-0001a630: 6572 3a3a 4c69 6e65 6172 4d61 7070 6572  er::LinearMapper
-0001a640: 204c 696e 6561 724d 6170 7065 723b 0a20   LinearMapper;. 
-0001a650: 2065 6e75 6d20 7b20 5061 636b 6574 5369   enum { PacketSi
-0001a660: 7a65 203d 2070 6163 6b65 745f 7472 6169  ze = packet_trai
-0001a670: 7473 3c53 6361 6c61 723e 3a3a 7369 7a65  ts<Scalar>::size
-0001a680: 207d 3b0a 2020 4549 4745 4e5f 444f 4e54   };.  EIGEN_DONT
-0001a690: 5f49 4e4c 494e 4520 766f 6964 206f 7065  _INLINE void ope
-0001a6a0: 7261 746f 7228 2928 5363 616c 6172 2a20  rator()(Scalar* 
-0001a6b0: 626c 6f63 6b42 2c20 636f 6e73 7420 4461  blockB, const Da
-0001a6c0: 7461 4d61 7070 6572 2620 7268 732c 2049  taMapper& rhs, I
-0001a6d0: 6e64 6578 2064 6570 7468 2c20 496e 6465  ndex depth, Inde
-0001a6e0: 7820 636f 6c73 2c20 496e 6465 7820 7374  x cols, Index st
-0001a6f0: 7269 6465 3d30 2c20 496e 6465 7820 6f66  ride=0, Index of
-0001a700: 6673 6574 3d30 293b 0a7d 3b0a 0a74 656d  fset=0);.};..tem
-0001a710: 706c 6174 653c 7479 7065 6e61 6d65 2053  plate<typename S
-0001a720: 6361 6c61 722c 2074 7970 656e 616d 6520  calar, typename 
-0001a730: 496e 6465 782c 2074 7970 656e 616d 6520  Index, typename 
-0001a740: 4461 7461 4d61 7070 6572 2c20 696e 7420  DataMapper, int 
-0001a750: 6e72 2c20 626f 6f6c 2043 6f6e 6a75 6761  nr, bool Conjuga
-0001a760: 7465 2c20 626f 6f6c 2050 616e 656c 4d6f  te, bool PanelMo
-0001a770: 6465 3e0a 4549 4745 4e5f 444f 4e54 5f49  de>.EIGEN_DONT_I
-0001a780: 4e4c 494e 4520 766f 6964 2067 656d 6d5f  NLINE void gemm_
-0001a790: 7061 636b 5f72 6873 3c53 6361 6c61 722c  pack_rhs<Scalar,
-0001a7a0: 2049 6e64 6578 2c20 4461 7461 4d61 7070   Index, DataMapp
-0001a7b0: 6572 2c20 6e72 2c20 526f 774d 616a 6f72  er, nr, RowMajor
-0001a7c0: 2c20 436f 6e6a 7567 6174 652c 2050 616e  , Conjugate, Pan
-0001a7d0: 656c 4d6f 6465 3e0a 2020 3a3a 6f70 6572  elMode>.  ::oper
-0001a7e0: 6174 6f72 2829 2853 6361 6c61 722a 2062  ator()(Scalar* b
-0001a7f0: 6c6f 636b 422c 2063 6f6e 7374 2044 6174  lockB, const Dat
-0001a800: 614d 6170 7065 7226 2072 6873 2c20 496e  aMapper& rhs, In
-0001a810: 6465 7820 6465 7074 682c 2049 6e64 6578  dex depth, Index
-0001a820: 2063 6f6c 732c 2049 6e64 6578 2073 7472   cols, Index str
-0001a830: 6964 652c 2049 6e64 6578 206f 6666 7365  ide, Index offse
-0001a840: 7429 0a7b 0a20 2045 4947 454e 5f41 534d  t).{.  EIGEN_ASM
-0001a850: 5f43 4f4d 4d45 4e54 2822 4549 4745 4e20  _COMMENT("EIGEN 
-0001a860: 5052 4f44 5543 5420 5041 434b 2052 4853  PRODUCT PACK RHS
-0001a870: 2052 4f57 4d41 4a4f 5222 293b 0a20 2045   ROWMAJOR");.  E
-0001a880: 4947 454e 5f55 4e55 5345 445f 5641 5249  IGEN_UNUSED_VARI
-0001a890: 4142 4c45 2873 7472 6964 6529 3b0a 2020  ABLE(stride);.  
-0001a8a0: 4549 4745 4e5f 554e 5553 4544 5f56 4152  EIGEN_UNUSED_VAR
-0001a8b0: 4941 424c 4528 6f66 6673 6574 293b 0a20  IABLE(offset);. 
-0001a8c0: 2065 6967 656e 5f61 7373 6572 7428 2828   eigen_assert(((
-0001a8d0: 2150 616e 656c 4d6f 6465 2920 2626 2073  !PanelMode) && s
-0001a8e0: 7472 6964 653d 3d30 2026 2620 6f66 6673  tride==0 && offs
-0001a8f0: 6574 3d3d 3029 207c 7c20 2850 616e 656c  et==0) || (Panel
-0001a900: 4d6f 6465 2026 2620 7374 7269 6465 3e3d  Mode && stride>=
-0001a910: 6465 7074 6820 2626 206f 6666 7365 743c  depth && offset<
-0001a920: 3d73 7472 6964 6529 293b 0a20 2063 6f6e  =stride));.  con
-0001a930: 6a5f 6966 3c4e 756d 5472 6169 7473 3c53  j_if<NumTraits<S
-0001a940: 6361 6c61 723e 3a3a 4973 436f 6d70 6c65  calar>::IsComple
-0001a950: 7820 2626 2043 6f6e 6a75 6761 7465 3e20  x && Conjugate> 
-0001a960: 636a 3b0a 2020 496e 6465 7820 7061 636b  cj;.  Index pack
-0001a970: 6574 5f63 6f6c 7338 203d 206e 723e 3d38  et_cols8 = nr>=8
-0001a980: 203f 2028 636f 6c73 2f38 2920 2a20 3820   ? (cols/8) * 8 
-0001a990: 3a20 303b 0a20 2049 6e64 6578 2070 6163  : 0;.  Index pac
-0001a9a0: 6b65 745f 636f 6c73 3420 3d20 6e72 3e3d  ket_cols4 = nr>=
-0001a9b0: 3420 3f20 2863 6f6c 732f 3429 202a 2034  4 ? (cols/4) * 4
-0001a9c0: 203a 2030 3b0a 2020 496e 6465 7820 636f   : 0;.  Index co
-0001a9d0: 756e 7420 3d20 303b 0a0a 2f2f 2020 2069  unt = 0;..//   i
-0001a9e0: 6628 6e72 3e3d 3829 0a2f 2f20 2020 7b0a  f(nr>=8).//   {.
-0001a9f0: 2f2f 2020 2020 2066 6f72 2849 6e64 6578  //     for(Index
-0001aa00: 206a 323d 303b 206a 323c 7061 636b 6574   j2=0; j2<packet
-0001aa10: 5f63 6f6c 7338 3b20 6a32 2b3d 3829 0a2f  _cols8; j2+=8)./
-0001aa20: 2f20 2020 2020 7b0a 2f2f 2020 2020 2020  /     {.//      
-0001aa30: 202f 2f20 736b 6970 2077 6861 7420 7765   // skip what we
-0001aa40: 2068 6176 6520 6265 666f 7265 0a2f 2f20   have before.// 
-0001aa50: 2020 2020 2020 6966 2850 616e 656c 4d6f        if(PanelMo
-0001aa60: 6465 2920 636f 756e 7420 2b3d 2038 202a  de) count += 8 *
-0001aa70: 206f 6666 7365 743b 0a2f 2f20 2020 2020   offset;.//     
-0001aa80: 2020 666f 7228 496e 6465 7820 6b3d 303b    for(Index k=0;
-0001aa90: 206b 3c64 6570 7468 3b20 6b2b 2b29 0a2f   k<depth; k++)./
-0001aaa0: 2f20 2020 2020 2020 7b0a 2f2f 2020 2020  /       {.//    
-0001aab0: 2020 2020 2069 6620 2850 6163 6b65 7453       if (PacketS
-0001aac0: 697a 653d 3d38 2920 7b0a 2f2f 2020 2020  ize==8) {.//    
-0001aad0: 2020 2020 2020 2050 6163 6b65 7420 4120         Packet A 
-0001aae0: 3d20 706c 6f61 6475 3c50 6163 6b65 743e  = ploadu<Packet>
-0001aaf0: 2826 7268 735b 6b2a 7268 7353 7472 6964  (&rhs[k*rhsStrid
-0001ab00: 6520 2b20 6a32 5d29 3b0a 2f2f 2020 2020  e + j2]);.//    
-0001ab10: 2020 2020 2020 2070 7374 6f72 6575 2862         pstoreu(b
-0001ab20: 6c6f 636b 422b 636f 756e 742c 2063 6a2e  lockB+count, cj.
-0001ab30: 7063 6f6e 6a28 4129 293b 0a2f 2f20 2020  pconj(A));.//   
-0001ab40: 2020 2020 2020 7d20 656c 7365 2069 6620        } else if 
-0001ab50: 2850 6163 6b65 7453 697a 653d 3d34 2920  (PacketSize==4) 
-0001ab60: 7b0a 2f2f 2020 2020 2020 2020 2020 2050  {.//           P
-0001ab70: 6163 6b65 7420 4120 3d20 706c 6f61 6475  acket A = ploadu
-0001ab80: 3c50 6163 6b65 743e 2826 7268 735b 6b2a  <Packet>(&rhs[k*
-0001ab90: 7268 7353 7472 6964 6520 2b20 6a32 5d29  rhsStride + j2])
-0001aba0: 3b0a 2f2f 2020 2020 2020 2020 2020 2050  ;.//           P
-0001abb0: 6163 6b65 7420 4220 3d20 706c 6f61 6475  acket B = ploadu
-0001abc0: 3c50 6163 6b65 743e 2826 7268 735b 6b2a  <Packet>(&rhs[k*
-0001abd0: 7268 7353 7472 6964 6520 2b20 6a32 202b  rhsStride + j2 +
-0001abe0: 2050 6163 6b65 7453 697a 655d 293b 0a2f   PacketSize]);./
-0001abf0: 2f20 2020 2020 2020 2020 2020 7073 746f  /           psto
-0001ac00: 7265 7528 626c 6f63 6b42 2b63 6f75 6e74  reu(blockB+count
-0001ac10: 2c20 636a 2e70 636f 6e6a 2841 2929 3b0a  , cj.pconj(A));.
-0001ac20: 2f2f 2020 2020 2020 2020 2020 2070 7374  //           pst
-0001ac30: 6f72 6575 2862 6c6f 636b 422b 636f 756e  oreu(blockB+coun
-0001ac40: 742b 5061 636b 6574 5369 7a65 2c20 636a  t+PacketSize, cj
-0001ac50: 2e70 636f 6e6a 2842 2929 3b0a 2f2f 2020  .pconj(B));.//  
-0001ac60: 2020 2020 2020 207d 2065 6c73 6520 7b0a         } else {.
-0001ac70: 2f2f 2020 2020 2020 2020 2020 2063 6f6e  //           con
-0001ac80: 7374 2053 6361 6c61 722a 2062 3020 3d20  st Scalar* b0 = 
-0001ac90: 2672 6873 5b6b 2a72 6873 5374 7269 6465  &rhs[k*rhsStride
-0001aca0: 202b 206a 325d 3b0a 2f2f 2020 2020 2020   + j2];.//      
-0001acb0: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
-0001acc0: 742b 305d 203d 2063 6a28 6230 5b30 5d29  t+0] = cj(b0[0])
-0001acd0: 3b0a 2f2f 2020 2020 2020 2020 2020 2062  ;.//           b
-0001ace0: 6c6f 636b 425b 636f 756e 742b 315d 203d  lockB[count+1] =
-0001acf0: 2063 6a28 6230 5b31 5d29 3b0a 2f2f 2020   cj(b0[1]);.//  
-0001ad00: 2020 2020 2020 2020 2062 6c6f 636b 425b           blockB[
-0001ad10: 636f 756e 742b 325d 203d 2063 6a28 6230  count+2] = cj(b0
-0001ad20: 5b32 5d29 3b0a 2f2f 2020 2020 2020 2020  [2]);.//        
-0001ad30: 2020 2062 6c6f 636b 425b 636f 756e 742b     blockB[count+
-0001ad40: 335d 203d 2063 6a28 6230 5b33 5d29 3b0a  3] = cj(b0[3]);.
-0001ad50: 2f2f 2020 2020 2020 2020 2020 2062 6c6f  //           blo
-0001ad60: 636b 425b 636f 756e 742b 345d 203d 2063  ckB[count+4] = c
-0001ad70: 6a28 6230 5b34 5d29 3b0a 2f2f 2020 2020  j(b0[4]);.//    
-0001ad80: 2020 2020 2020 2062 6c6f 636b 425b 636f         blockB[co
-0001ad90: 756e 742b 355d 203d 2063 6a28 6230 5b35  unt+5] = cj(b0[5
-0001ada0: 5d29 3b0a 2f2f 2020 2020 2020 2020 2020  ]);.//          
-0001adb0: 2062 6c6f 636b 425b 636f 756e 742b 365d   blockB[count+6]
-0001adc0: 203d 2063 6a28 6230 5b36 5d29 3b0a 2f2f   = cj(b0[6]);.//
-0001add0: 2020 2020 2020 2020 2020 2062 6c6f 636b             block
-0001ade0: 425b 636f 756e 742b 375d 203d 2063 6a28  B[count+7] = cj(
-0001adf0: 6230 5b37 5d29 3b0a 2f2f 2020 2020 2020  b0[7]);.//      
-0001ae00: 2020 207d 0a2f 2f20 2020 2020 2020 2020     }.//         
-0001ae10: 636f 756e 7420 2b3d 2038 3b0a 2f2f 2020  count += 8;.//  
-0001ae20: 2020 2020 207d 0a2f 2f20 2020 2020 2020       }.//       
-0001ae30: 2f2f 2073 6b69 7020 7768 6174 2077 6520  // skip what we 
-0001ae40: 6861 7665 2061 6674 6572 0a2f 2f20 2020  have after.//   
-0001ae50: 2020 2020 6966 2850 616e 656c 4d6f 6465      if(PanelMode
-0001ae60: 2920 636f 756e 7420 2b3d 2038 202a 2028  ) count += 8 * (
-0001ae70: 7374 7269 6465 2d6f 6666 7365 742d 6465  stride-offset-de
-0001ae80: 7074 6829 3b0a 2f2f 2020 2020 207d 0a2f  pth);.//     }./
-0001ae90: 2f20 2020 7d0a 2020 6966 286e 723e 3d34  /   }.  if(nr>=4
-0001aea0: 290a 2020 7b0a 2020 2020 666f 7228 496e  ).  {.    for(In
-0001aeb0: 6465 7820 6a32 3d70 6163 6b65 745f 636f  dex j2=packet_co
-0001aec0: 6c73 383b 206a 323c 7061 636b 6574 5f63  ls8; j2<packet_c
-0001aed0: 6f6c 7334 3b20 6a32 2b3d 3429 0a20 2020  ols4; j2+=4).   
-0001aee0: 207b 0a20 2020 2020 202f 2f20 736b 6970   {.      // skip
-0001aef0: 2077 6861 7420 7765 2068 6176 6520 6265   what we have be
-0001af00: 666f 7265 0a20 2020 2020 2069 6628 5061  fore.      if(Pa
-0001af10: 6e65 6c4d 6f64 6529 2063 6f75 6e74 202b  nelMode) count +
-0001af20: 3d20 3420 2a20 6f66 6673 6574 3b0a 2020  = 4 * offset;.  
-0001af30: 2020 2020 666f 7228 496e 6465 7820 6b3d      for(Index k=
-0001af40: 303b 206b 3c64 6570 7468 3b20 6b2b 2b29  0; k<depth; k++)
-0001af50: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
-0001af60: 2069 6620 2850 6163 6b65 7453 697a 653d   if (PacketSize=
-0001af70: 3d34 2920 7b0a 2020 2020 2020 2020 2020  =4) {.          
-0001af80: 5061 636b 6574 2041 203d 2072 6873 2e74  Packet A = rhs.t
-0001af90: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
-0001afa0: 6574 3c50 6163 6b65 743e 286b 2c20 6a32  et<Packet>(k, j2
-0001afb0: 293b 0a20 2020 2020 2020 2020 2070 7374  );.          pst
-0001afc0: 6f72 6575 2862 6c6f 636b 422b 636f 756e  oreu(blockB+coun
-0001afd0: 742c 2063 6a2e 7063 6f6e 6a28 4129 293b  t, cj.pconj(A));
-0001afe0: 0a20 2020 2020 2020 2020 2063 6f75 6e74  .          count
-0001aff0: 202b 3d20 5061 636b 6574 5369 7a65 3b0a   += PacketSize;.
-0001b000: 2020 2020 2020 2020 7d20 656c 7365 207b          } else {
-0001b010: 0a20 2020 2020 2020 2020 2063 6f6e 7374  .          const
-0001b020: 204c 696e 6561 724d 6170 7065 7220 646d   LinearMapper dm
-0001b030: 3020 3d20 7268 732e 6765 744c 696e 6561  0 = rhs.getLinea
-0001b040: 724d 6170 7065 7228 6b2c 206a 3229 3b0a  rMapper(k, j2);.
-0001b050: 2020 2020 2020 2020 2020 626c 6f63 6b42            blockB
-0001b060: 5b63 6f75 6e74 2b30 5d20 3d20 636a 2864  [count+0] = cj(d
-0001b070: 6d30 2830 2929 3b0a 2020 2020 2020 2020  m0(0));.        
-0001b080: 2020 626c 6f63 6b42 5b63 6f75 6e74 2b31    blockB[count+1
-0001b090: 5d20 3d20 636a 2864 6d30 2831 2929 3b0a  ] = cj(dm0(1));.
-0001b0a0: 2020 2020 2020 2020 2020 626c 6f63 6b42            blockB
-0001b0b0: 5b63 6f75 6e74 2b32 5d20 3d20 636a 2864  [count+2] = cj(d
-0001b0c0: 6d30 2832 2929 3b0a 2020 2020 2020 2020  m0(2));.        
-0001b0d0: 2020 626c 6f63 6b42 5b63 6f75 6e74 2b33    blockB[count+3
-0001b0e0: 5d20 3d20 636a 2864 6d30 2833 2929 3b0a  ] = cj(dm0(3));.
-0001b0f0: 2020 2020 2020 2020 2020 636f 756e 7420            count 
-0001b100: 2b3d 2034 3b0a 2020 2020 2020 2020 7d0a  += 4;.        }.
-0001b110: 2020 2020 2020 7d0a 2020 2020 2020 2f2f        }.      //
-0001b120: 2073 6b69 7020 7768 6174 2077 6520 6861   skip what we ha
-0001b130: 7665 2061 6674 6572 0a20 2020 2020 2069  ve after.      i
-0001b140: 6628 5061 6e65 6c4d 6f64 6529 2063 6f75  f(PanelMode) cou
-0001b150: 6e74 202b 3d20 3420 2a20 2873 7472 6964  nt += 4 * (strid
-0001b160: 652d 6f66 6673 6574 2d64 6570 7468 293b  e-offset-depth);
-0001b170: 0a20 2020 207d 0a20 207d 0a20 202f 2f20  .    }.  }.  // 
-0001b180: 636f 7079 2074 6865 2072 656d 6169 6e69  copy the remaini
-0001b190: 6e67 2063 6f6c 756d 6e73 206f 6e65 2061  ng columns one a
-0001b1a0: 7420 6120 7469 6d65 2028 6e72 3d3d 3129  t a time (nr==1)
-0001b1b0: 0a20 2066 6f72 2849 6e64 6578 206a 323d  .  for(Index j2=
-0001b1c0: 7061 636b 6574 5f63 6f6c 7334 3b20 6a32  packet_cols4; j2
-0001b1d0: 3c63 6f6c 733b 202b 2b6a 3229 0a20 207b  <cols; ++j2).  {
-0001b1e0: 0a20 2020 2069 6628 5061 6e65 6c4d 6f64  .    if(PanelMod
-0001b1f0: 6529 2063 6f75 6e74 202b 3d20 6f66 6673  e) count += offs
-0001b200: 6574 3b0a 2020 2020 666f 7228 496e 6465  et;.    for(Inde
-0001b210: 7820 6b3d 303b 206b 3c64 6570 7468 3b20  x k=0; k<depth; 
-0001b220: 6b2b 2b29 0a20 2020 207b 0a20 2020 2020  k++).    {.     
-0001b230: 2062 6c6f 636b 425b 636f 756e 745d 203d   blockB[count] =
-0001b240: 2063 6a28 7268 7328 6b2c 206a 3229 293b   cj(rhs(k, j2));
-0001b250: 0a20 2020 2020 2063 6f75 6e74 202b 3d20  .      count += 
-0001b260: 313b 0a20 2020 207d 0a20 2020 2069 6628  1;.    }.    if(
-0001b270: 5061 6e65 6c4d 6f64 6529 2063 6f75 6e74  PanelMode) count
-0001b280: 202b 3d20 7374 7269 6465 2d6f 6666 7365   += stride-offse
-0001b290: 742d 6465 7074 683b 0a20 207d 0a7d 0a0a  t-depth;.  }.}..
-0001b2a0: 7d20 2f2f 2065 6e64 206e 616d 6573 7061  } // end namespa
-0001b2b0: 6365 2069 6e74 6572 6e61 6c0a 0a2f 2a2a  ce internal../**
-0001b2c0: 205c 7265 7475 726e 7320 7468 6520 6375   \returns the cu
-0001b2d0: 7272 656e 746c 7920 7365 7420 6c65 7665  rrently set leve
-0001b2e0: 6c20 3120 6370 7520 6361 6368 6520 7369  l 1 cpu cache si
-0001b2f0: 7a65 2028 696e 2062 7974 6573 2920 7573  ze (in bytes) us
-0001b300: 6564 2074 6f20 6573 7469 6d61 7465 2074  ed to estimate t
-0001b310: 6865 2069 6465 616c 2062 6c6f 636b 696e  he ideal blockin
-0001b320: 6720 7369 7a65 2070 6172 616d 6574 6572  g size parameter
-0001b330: 732e 0a20 202a 205c 7361 2073 6574 4370  s..  * \sa setCp
-0001b340: 7543 6163 6865 5369 7a65 202a 2f0a 696e  uCacheSize */.in
-0001b350: 6c69 6e65 2073 7464 3a3a 7074 7264 6966  line std::ptrdif
-0001b360: 665f 7420 6c31 4361 6368 6553 697a 6528  f_t l1CacheSize(
-0001b370: 290a 7b0a 2020 7374 643a 3a70 7472 6469  ).{.  std::ptrdi
-0001b380: 6666 5f74 206c 312c 206c 322c 206c 333b  ff_t l1, l2, l3;
-0001b390: 0a20 2069 6e74 6572 6e61 6c3a 3a6d 616e  .  internal::man
-0001b3a0: 6167 655f 6361 6368 696e 675f 7369 7a65  age_caching_size
-0001b3b0: 7328 4765 7441 6374 696f 6e2c 2026 6c31  s(GetAction, &l1
-0001b3c0: 2c20 266c 322c 2026 6c33 293b 0a20 2072  , &l2, &l3);.  r
-0001b3d0: 6574 7572 6e20 6c31 3b0a 7d0a 0a2f 2a2a  eturn l1;.}../**
-0001b3e0: 205c 7265 7475 726e 7320 7468 6520 6375   \returns the cu
-0001b3f0: 7272 656e 746c 7920 7365 7420 6c65 7665  rrently set leve
-0001b400: 6c20 3220 6370 7520 6361 6368 6520 7369  l 2 cpu cache si
-0001b410: 7a65 2028 696e 2062 7974 6573 2920 7573  ze (in bytes) us
-0001b420: 6564 2074 6f20 6573 7469 6d61 7465 2074  ed to estimate t
-0001b430: 6865 2069 6465 616c 2062 6c6f 636b 696e  he ideal blockin
-0001b440: 6720 7369 7a65 2070 6172 616d 6574 6572  g size parameter
-0001b450: 732e 0a20 202a 205c 7361 2073 6574 4370  s..  * \sa setCp
-0001b460: 7543 6163 6865 5369 7a65 202a 2f0a 696e  uCacheSize */.in
-0001b470: 6c69 6e65 2073 7464 3a3a 7074 7264 6966  line std::ptrdif
-0001b480: 665f 7420 6c32 4361 6368 6553 697a 6528  f_t l2CacheSize(
-0001b490: 290a 7b0a 2020 7374 643a 3a70 7472 6469  ).{.  std::ptrdi
-0001b4a0: 6666 5f74 206c 312c 206c 322c 206c 333b  ff_t l1, l2, l3;
-0001b4b0: 0a20 2069 6e74 6572 6e61 6c3a 3a6d 616e  .  internal::man
-0001b4c0: 6167 655f 6361 6368 696e 675f 7369 7a65  age_caching_size
-0001b4d0: 7328 4765 7441 6374 696f 6e2c 2026 6c31  s(GetAction, &l1
-0001b4e0: 2c20 266c 322c 2026 6c33 293b 0a20 2072  , &l2, &l3);.  r
-0001b4f0: 6574 7572 6e20 6c32 3b0a 7d0a 0a2f 2a2a  eturn l2;.}../**
-0001b500: 205c 7265 7475 726e 7320 7468 6520 6375   \returns the cu
-0001b510: 7272 656e 746c 7920 7365 7420 6c65 7665  rrently set leve
-0001b520: 6c20 3320 6370 7520 6361 6368 6520 7369  l 3 cpu cache si
-0001b530: 7a65 2028 696e 2062 7974 6573 2920 7573  ze (in bytes) us
-0001b540: 6564 2074 6f20 6573 7469 6d61 7465 2074  ed to estimate t
-0001b550: 6865 2069 6465 616c 2062 6c6f 636b 696e  he ideal blockin
-0001b560: 6720 7369 7a65 2070 6172 616d 6574 655c  g size paramete\
-0001b570: 0a72 732e 2020 2020 2020 2020 2020 2020  .rs.            
-0001b580: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b590: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b5a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b5b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b5c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b5d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
-0001b5e0: 2020 2020 0a2a 205c 7361 2073 6574 4370      .* \sa setCp
-0001b5f0: 7543 6163 6865 5369 7a65 202a 2f0a 696e  uCacheSize */.in
-0001b600: 6c69 6e65 2073 7464 3a3a 7074 7264 6966  line std::ptrdif
-0001b610: 665f 7420 6c33 4361 6368 6553 697a 6528  f_t l3CacheSize(
-0001b620: 290a 7b0a 2020 7374 643a 3a70 7472 6469  ).{.  std::ptrdi
-0001b630: 6666 5f74 206c 312c 206c 322c 206c 333b  ff_t l1, l2, l3;
-0001b640: 0a20 2069 6e74 6572 6e61 6c3a 3a6d 616e  .  internal::man
-0001b650: 6167 655f 6361 6368 696e 675f 7369 7a65  age_caching_size
-0001b660: 7328 4765 7441 6374 696f 6e2c 2026 6c31  s(GetAction, &l1
-0001b670: 2c20 266c 322c 2026 6c33 293b 0a20 2072  , &l2, &l3);.  r
-0001b680: 6574 7572 6e20 6c33 3b0a 7d0a 0a2f 2a2a  eturn l3;.}../**
-0001b690: 2053 6574 2074 6865 2063 7075 204c 3120   Set the cpu L1 
-0001b6a0: 616e 6420 4c32 2063 6163 6865 2073 697a  and L2 cache siz
-0001b6b0: 6573 2028 696e 2062 7974 6573 292e 0a20  es (in bytes).. 
-0001b6c0: 202a 2054 6865 7365 2076 616c 7565 7320   * These values 
-0001b6d0: 6172 6520 7573 6520 746f 2061 646a 7573  are use to adjus
-0001b6e0: 7420 7468 6520 7369 7a65 206f 6620 7468  t the size of th
-0001b6f0: 6520 626c 6f63 6b73 0a20 202a 2066 6f72  e blocks.  * for
-0001b700: 2074 6865 2061 6c67 6f72 6974 686d 7320   the algorithms 
-0001b710: 776f 726b 696e 6720 7065 7220 626c 6f63  working per bloc
-0001b720: 6b73 2e0a 2020 2a0a 2020 2a20 5c73 6120  ks..  *.  * \sa 
-0001b730: 636f 6d70 7574 6550 726f 6475 6374 426c  computeProductBl
-0001b740: 6f63 6b69 6e67 5369 7a65 7320 2a2f 0a69  ockingSizes */.i
-0001b750: 6e6c 696e 6520 766f 6964 2073 6574 4370  nline void setCp
-0001b760: 7543 6163 6865 5369 7a65 7328 7374 643a  uCacheSizes(std:
-0001b770: 3a70 7472 6469 6666 5f74 206c 312c 2073  :ptrdiff_t l1, s
-0001b780: 7464 3a3a 7074 7264 6966 665f 7420 6c32  td::ptrdiff_t l2
-0001b790: 2c20 7374 643a 3a70 7472 6469 6666 5f74  , std::ptrdiff_t
-0001b7a0: 206c 3329 0a7b 0a20 2069 6e74 6572 6e61   l3).{.  interna
-0001b7b0: 6c3a 3a6d 616e 6167 655f 6361 6368 696e  l::manage_cachin
-0001b7c0: 675f 7369 7a65 7328 5365 7441 6374 696f  g_sizes(SetActio
-0001b7d0: 6e2c 2026 6c31 2c20 266c 322c 2026 6c33  n, &l1, &l2, &l3
-0001b7e0: 293b 0a7d 0a0a 7d20 2f2f 2065 6e64 206e  );.}..} // end n
-0001b7f0: 616d 6573 7061 6365 2045 6967 656e 0a0a  amespace Eigen..
-0001b800: 2365 6e64 6966 202f 2f20 4549 4745 4e5f  #endif // EIGEN_
-0001b810: 4745 4e45 5241 4c5f 424c 4f43 4b5f 5041  GENERAL_BLOCK_PA
-0001b820: 4e45 4c5f 480a                           NEL_H.
+00004170: 2020 7479 7065 6e61 6d65 2075 6e70 6163    typename unpac
+00004180: 6b65 745f 7472 6169 7473 3c74 7970 656e  ket_traits<typen
+00004190: 616d 6520 7061 636b 6574 5f74 7261 6974  ame packet_trait
+000041a0: 733c 5363 616c 6172 3e3a 3a68 616c 663e  s<Scalar>::half>
+000041b0: 3a3a 6861 6c66 3e3a 3a74 7970 6520 5c0a  ::half>::type \.
+000041c0: 2020 7072 6566 6978 2023 2320 5363 616c    prefix ## Scal
+000041d0: 6172 5061 636b 6574 0a0a 2364 6566 696e  arPacket..#defin
+000041e0: 6520 5041 434b 4554 5f44 4543 4c5f 434f  e PACKET_DECL_CO
+000041f0: 4e44 5f53 4341 4c41 5228 7061 636b 6574  ND_SCALAR(packet
+00004200: 5f73 697a 6529 2020 2020 2020 2020 2020  _size)          
+00004210: 2020 2020 2020 2020 2020 2020 205c 0a20               \. 
+00004220: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
+00004230: 6520 7061 636b 6574 5f63 6f6e 6469 7469  e packet_conditi
+00004240: 6f6e 616c 3c70 6163 6b65 745f 7369 7a65  onal<packet_size
+00004250: 2c20 2020 2020 2020 2020 2020 2020 2020  ,               
+00004260: 2020 5c0a 2020 2020 2020 2020 2020 2020    \.            
+00004270: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004280: 2020 2020 2020 2020 2020 7479 7065 6e61            typena
+00004290: 6d65 2070 6163 6b65 745f 7472 6169 7473  me packet_traits
+000042a0: 3c53 6361 6c61 723e 3a3a 7479 7065 2c20  <Scalar>::type, 
+000042b0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+000042c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000042d0: 2020 2020 2020 2020 7479 7065 6e61 6d65          typename
+000042e0: 2070 6163 6b65 745f 7472 6169 7473 3c53   packet_traits<S
+000042f0: 6361 6c61 723e 3a3a 6861 6c66 2c20 5c0a  calar>::half, \.
+00004300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004310: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00004320: 2020 2020 2020 7479 7065 6e61 6d65 2075        typename u
+00004330: 6e70 6163 6b65 745f 7472 6169 7473 3c74  npacket_traits<t
+00004340: 7970 656e 616d 6520 7061 636b 6574 5f74  ypename packet_t
+00004350: 7261 6974 733c 5363 616c 6172 3e3a 3a68  raits<Scalar>::h
+00004360: 616c 663e 3a3a 6861 6c66 3e3a 3a74 7970  alf>::half>::typ
+00004370: 6520 5c0a 2020 5363 616c 6172 5061 636b  e \.  ScalarPack
+00004380: 6574 0a0a 2f2a 2056 6563 746f 7269 7a61  et../* Vectoriza
+00004390: 7469 6f6e 206c 6f67 6963 0a20 2a20 2072  tion logic. *  r
+000043a0: 6561 6c2a 7265 616c 3a20 756e 7061 636b  eal*real: unpack
+000043b0: 2072 6873 2074 6f20 636f 6e73 7461 6e74   rhs to constant
+000043c0: 2070 6163 6b65 7473 2c20 2e2e 2e0a 202a   packets, .... *
+000043d0: 200a 202a 2020 6364 2a63 6420 3a20 756e   . *  cd*cd : un
+000043e0: 7061 636b 2072 6873 2074 6f20 2862 5f72  pack rhs to (b_r
+000043f0: 2c62 5f72 292c 2028 625f 692c 625f 6929  ,b_r), (b_i,b_i)
+00004400: 2c20 6d75 6c20 746f 2067 6574 2028 615f  , mul to get (a_
+00004410: 7220 625f 722c 615f 6920 625f 7229 2028  r b_r,a_i b_r) (
+00004420: 615f 7220 625f 692c 615f 6920 625f 6929  a_r b_i,a_i b_i)
+00004430: 2c0a 202a 2020 2020 2020 2020 2020 7374  ,. *          st
+00004440: 6f72 696e 6720 6561 6368 2072 6573 2070  oring each res p
+00004450: 6163 6b65 7420 696e 746f 2074 776f 2070  acket into two p
+00004460: 6163 6b65 7473 2028 3278 3229 2c0a 202a  ackets (2x2),. *
+00004470: 2020 2020 2020 2020 2020 6174 2074 6865            at the
+00004480: 2065 6e64 2063 6f6d 6269 6e65 2074 6865   end combine the
+00004490: 6d3a 2073 7761 7020 7468 6520 7365 636f  m: swap the seco
+000044a0: 6e64 2061 6e64 2061 6464 7375 6220 7468  nd and addsub th
+000044b0: 656d 200a 202a 2020 6366 2a63 6620 3a20  em . *  cf*cf : 
+000044c0: 7361 6d65 2062 7574 2077 6974 6820 3278  same but with 2x
+000044d0: 3420 626c 6f63 6b73 0a20 2a20 2063 706c  4 blocks. *  cpl
+000044e0: 782a 7265 616c 203a 2075 6e70 6163 6b20  x*real : unpack 
+000044f0: 7268 7320 746f 2063 6f6e 7374 616e 7420  rhs to constant 
+00004500: 7061 636b 6574 732c 202e 2e2e 0a20 2a20  packets, .... * 
+00004510: 2072 6561 6c2a 6370 6c78 203a 206c 6f61   real*cplx : loa
+00004520: 6420 6c68 7320 6173 2028 6130 2c61 302c  d lhs as (a0,a0,
+00004530: 6131 2c61 3129 2c20 616e 6420 6d75 6c20  a1,a1), and mul 
+00004540: 6173 2075 7375 616c 0a20 2a2f 0a74 656d  as usual. */.tem
+00004550: 706c 6174 653c 7479 7065 6e61 6d65 205f  plate<typename _
+00004560: 4c68 7353 6361 6c61 722c 2074 7970 656e  LhsScalar, typen
+00004570: 616d 6520 5f52 6873 5363 616c 6172 2c20  ame _RhsScalar, 
+00004580: 626f 6f6c 205f 436f 6e6a 4c68 732c 2062  bool _ConjLhs, b
+00004590: 6f6f 6c20 5f43 6f6e 6a52 6873 2c20 696e  ool _ConjRhs, in
+000045a0: 7420 4172 6368 2c20 696e 7420 5f50 6163  t Arch, int _Pac
+000045b0: 6b65 7453 697a 653e 0a63 6c61 7373 2067  ketSize>.class g
+000045c0: 6562 705f 7472 6169 7473 0a7b 0a70 7562  ebp_traits.{.pub
+000045d0: 6c69 633a 0a20 2074 7970 6564 6566 205f  lic:.  typedef _
+000045e0: 4c68 7353 6361 6c61 7220 4c68 7353 6361  LhsScalar LhsSca
+000045f0: 6c61 723b 0a20 2074 7970 6564 6566 205f  lar;.  typedef _
+00004600: 5268 7353 6361 6c61 7220 5268 7353 6361  RhsScalar RhsSca
+00004610: 6c61 723b 0a20 2074 7970 6564 6566 2074  lar;.  typedef t
+00004620: 7970 656e 616d 6520 5363 616c 6172 4269  ypename ScalarBi
+00004630: 6e61 7279 4f70 5472 6169 7473 3c4c 6873  naryOpTraits<Lhs
+00004640: 5363 616c 6172 2c20 5268 7353 6361 6c61  Scalar, RhsScala
+00004650: 723e 3a3a 5265 7475 726e 5479 7065 2052  r>::ReturnType R
+00004660: 6573 5363 616c 6172 3b0a 0a20 2050 4143  esScalar;..  PAC
+00004670: 4b45 545f 4445 434c 5f43 4f4e 445f 5052  KET_DECL_COND_PR
+00004680: 4546 4958 285f 2c20 4c68 732c 205f 5061  EFIX(_, Lhs, _Pa
+00004690: 636b 6574 5369 7a65 293b 0a20 2050 4143  cketSize);.  PAC
+000046a0: 4b45 545f 4445 434c 5f43 4f4e 445f 5052  KET_DECL_COND_PR
+000046b0: 4546 4958 285f 2c20 5268 732c 205f 5061  EFIX(_, Rhs, _Pa
+000046c0: 636b 6574 5369 7a65 293b 0a20 2050 4143  cketSize);.  PAC
+000046d0: 4b45 545f 4445 434c 5f43 4f4e 445f 5052  KET_DECL_COND_PR
+000046e0: 4546 4958 285f 2c20 5265 732c 205f 5061  EFIX(_, Res, _Pa
+000046f0: 636b 6574 5369 7a65 293b 0a0a 2020 656e  cketSize);..  en
+00004700: 756d 207b 0a20 2020 2043 6f6e 6a4c 6873  um {.    ConjLhs
+00004710: 203d 205f 436f 6e6a 4c68 732c 0a20 2020   = _ConjLhs,.   
+00004720: 2043 6f6e 6a52 6873 203d 205f 436f 6e6a   ConjRhs = _Conj
+00004730: 5268 732c 0a20 2020 2056 6563 746f 7269  Rhs,.    Vectori
+00004740: 7a61 626c 6520 3d20 756e 7061 636b 6574  zable = unpacket
+00004750: 5f74 7261 6974 733c 5f4c 6873 5061 636b  _traits<_LhsPack
+00004760: 6574 3e3a 3a76 6563 746f 7269 7a61 626c  et>::vectorizabl
+00004770: 6520 2626 2075 6e70 6163 6b65 745f 7472  e && unpacket_tr
+00004780: 6169 7473 3c5f 5268 7350 6163 6b65 743e  aits<_RhsPacket>
+00004790: 3a3a 7665 6374 6f72 697a 6162 6c65 2c0a  ::vectorizable,.
+000047a0: 2020 2020 4c68 7350 6163 6b65 7453 697a      LhsPacketSiz
+000047b0: 6520 3d20 5665 6374 6f72 697a 6162 6c65  e = Vectorizable
+000047c0: 203f 2075 6e70 6163 6b65 745f 7472 6169   ? unpacket_trai
+000047d0: 7473 3c5f 4c68 7350 6163 6b65 743e 3a3a  ts<_LhsPacket>::
+000047e0: 7369 7a65 203a 2031 2c0a 2020 2020 5268  size : 1,.    Rh
+000047f0: 7350 6163 6b65 7453 697a 6520 3d20 5665  sPacketSize = Ve
+00004800: 6374 6f72 697a 6162 6c65 203f 2075 6e70  ctorizable ? unp
+00004810: 6163 6b65 745f 7472 6169 7473 3c5f 5268  acket_traits<_Rh
+00004820: 7350 6163 6b65 743e 3a3a 7369 7a65 203a  sPacket>::size :
+00004830: 2031 2c0a 2020 2020 5265 7350 6163 6b65   1,.    ResPacke
+00004840: 7453 697a 6520 3d20 5665 6374 6f72 697a  tSize = Vectoriz
+00004850: 6162 6c65 203f 2075 6e70 6163 6b65 745f  able ? unpacket_
+00004860: 7472 6169 7473 3c5f 5265 7350 6163 6b65  traits<_ResPacke
+00004870: 743e 3a3a 7369 7a65 203a 2031 2c0a 2020  t>::size : 1,.  
+00004880: 2020 0a20 2020 204e 756d 6265 724f 6652    .    NumberOfR
+00004890: 6567 6973 7465 7273 203d 2045 4947 454e  egisters = EIGEN
+000048a0: 5f41 5243 485f 4445 4641 554c 545f 4e55  _ARCH_DEFAULT_NU
+000048b0: 4d42 4552 5f4f 465f 5245 4749 5354 4552  MBER_OF_REGISTER
+000048c0: 532c 0a0a 2020 2020 2f2f 2072 6567 6973  S,..    // regis
+000048d0: 7465 7220 626c 6f63 6b20 7369 7a65 2061  ter block size a
+000048e0: 6c6f 6e67 2074 6865 204e 2064 6972 6563  long the N direc
+000048f0: 7469 6f6e 206d 7573 7420 6265 2031 206f  tion must be 1 o
+00004900: 7220 340a 2020 2020 6e72 203d 2034 2c0a  r 4.    nr = 4,.
+00004910: 0a20 2020 202f 2f20 7265 6769 7374 6572  .    // register
+00004920: 2062 6c6f 636b 2073 697a 6520 616c 6f6e   block size alon
+00004930: 6720 7468 6520 4d20 6469 7265 6374 696f  g the M directio
+00004940: 6e20 2863 7572 7265 6e74 6c79 2c20 7468  n (currently, th
+00004950: 6973 206f 6e65 2063 616e 6e6f 7420 6265  is one cannot be
+00004960: 206d 6f64 6966 6965 6429 0a20 2020 2064   modified).    d
+00004970: 6566 6175 6c74 5f6d 7220 3d20 2845 4947  efault_mr = (EIG
+00004980: 454e 5f50 4c41 494e 5f45 4e55 4d5f 4d49  EN_PLAIN_ENUM_MI
+00004990: 4e28 3136 2c4e 756d 6265 724f 6652 6567  N(16,NumberOfReg
+000049a0: 6973 7465 7273 292f 322f 6e72 292a 4c68  isters)/2/nr)*Lh
+000049b0: 7350 6163 6b65 7453 697a 652c 0a23 6966  sPacketSize,.#if
+000049c0: 2064 6566 696e 6564 2845 4947 454e 5f48   defined(EIGEN_H
+000049d0: 4153 5f53 494e 474c 455f 494e 5354 5255  AS_SINGLE_INSTRU
+000049e0: 4354 494f 4e5f 4d41 4444 2920 2626 2021  CTION_MADD) && !
+000049f0: 6465 6669 6e65 6428 4549 4745 4e5f 5645  defined(EIGEN_VE
+00004a00: 4354 4f52 495a 455f 414c 5449 5645 4329  CTORIZE_ALTIVEC)
+00004a10: 2026 2620 2164 6566 696e 6564 2845 4947   && !defined(EIG
+00004a20: 454e 5f56 4543 544f 5249 5a45 5f56 5358  EN_VECTORIZE_VSX
+00004a30: 2920 5c0a 2020 2020 2626 2028 2821 4549  ) \.    && ((!EI
+00004a40: 4745 4e5f 434f 4d50 5f4d 5356 4329 207c  GEN_COMP_MSVC) |
+00004a50: 7c20 2845 4947 454e 5f43 4f4d 505f 4d53  | (EIGEN_COMP_MS
+00004a60: 5643 3e3d 3139 3134 2929 0a20 2020 202f  VC>=1914)).    /
+00004a70: 2f20 7765 2061 7373 756d 6520 3136 2072  / we assume 16 r
+00004a80: 6567 6973 7465 7273 206f 7220 6d6f 7265  egisters or more
+00004a90: 0a20 2020 202f 2f20 5365 6520 6275 6720  .    // See bug 
+00004aa0: 3939 322c 2069 6620 7468 6520 7363 616c  992, if the scal
+00004ab0: 6172 2074 7970 6520 6973 206e 6f74 2076  ar type is not v
+00004ac0: 6563 746f 7269 7a61 626c 6520 6275 7420  ectorizable but 
+00004ad0: 7468 6174 2045 4947 454e 5f48 4153 5f53  that EIGEN_HAS_S
+00004ae0: 494e 474c 455f 494e 5354 5255 4354 494f  INGLE_INSTRUCTIO
+00004af0: 4e5f 4d41 4444 2069 7320 6465 6669 6e65  N_MADD is define
+00004b00: 642c 0a20 2020 202f 2f20 7468 656e 2075  d,.    // then u
+00004b10: 7369 6e67 2033 2a4c 6873 5061 636b 6574  sing 3*LhsPacket
+00004b20: 5369 7a65 2074 7269 6767 6572 7320 6e6f  Size triggers no
+00004b30: 6e2d 696d 706c 656d 656e 7465 6420 7061  n-implemented pa
+00004b40: 7468 7320 696e 2073 7972 6b2e 0a20 2020  ths in syrk..   
+00004b50: 202f 2f20 4275 6720 3135 3135 3a20 4d53   // Bug 1515: MS
+00004b60: 5643 2070 7269 6f72 2074 6f20 7631 392e  VC prior to v19.
+00004b70: 3134 2079 6965 6c64 7320 746f 2072 6567  14 yields to reg
+00004b80: 6973 7465 7220 7370 696c 6c69 6e67 2e0a  ister spilling..
+00004b90: 2020 2020 6d72 203d 2056 6563 746f 7269      mr = Vectori
+00004ba0: 7a61 626c 6520 3f20 332a 4c68 7350 6163  zable ? 3*LhsPac
+00004bb0: 6b65 7453 697a 6520 3a20 6465 6661 756c  ketSize : defaul
+00004bc0: 745f 6d72 2c0a 2365 6c73 650a 2020 2020  t_mr,.#else.    
+00004bd0: 6d72 203d 2064 6566 6175 6c74 5f6d 722c  mr = default_mr,
+00004be0: 0a23 656e 6469 660a 2020 2020 0a20 2020  .#endif.    .   
+00004bf0: 204c 6873 5072 6f67 7265 7373 203d 204c   LhsProgress = L
+00004c00: 6873 5061 636b 6574 5369 7a65 2c0a 2020  hsPacketSize,.  
+00004c10: 2020 5268 7350 726f 6772 6573 7320 3d20    RhsProgress = 
+00004c20: 310a 2020 7d3b 0a0a 0a20 2074 7970 6564  1.  };...  typed
+00004c30: 6566 2074 7970 656e 616d 6520 636f 6e64  ef typename cond
+00004c40: 6974 696f 6e61 6c3c 5665 6374 6f72 697a  itional<Vectoriz
+00004c50: 6162 6c65 2c5f 4c68 7350 6163 6b65 742c  able,_LhsPacket,
+00004c60: 4c68 7353 6361 6c61 723e 3a3a 7479 7065  LhsScalar>::type
+00004c70: 204c 6873 5061 636b 6574 3b0a 2020 7479   LhsPacket;.  ty
+00004c80: 7065 6465 6620 7479 7065 6e61 6d65 2063  pedef typename c
+00004c90: 6f6e 6469 7469 6f6e 616c 3c56 6563 746f  onditional<Vecto
+00004ca0: 7269 7a61 626c 652c 5f52 6873 5061 636b  rizable,_RhsPack
+00004cb0: 6574 2c52 6873 5363 616c 6172 3e3a 3a74  et,RhsScalar>::t
+00004cc0: 7970 6520 5268 7350 6163 6b65 743b 0a20  ype RhsPacket;. 
+00004cd0: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
+00004ce0: 6520 636f 6e64 6974 696f 6e61 6c3c 5665  e conditional<Ve
+00004cf0: 6374 6f72 697a 6162 6c65 2c5f 5265 7350  ctorizable,_ResP
+00004d00: 6163 6b65 742c 5265 7353 6361 6c61 723e  acket,ResScalar>
+00004d10: 3a3a 7479 7065 2052 6573 5061 636b 6574  ::type ResPacket
+00004d20: 3b0a 2020 7479 7065 6465 6620 4c68 7350  ;.  typedef LhsP
+00004d30: 6163 6b65 7420 4c68 7350 6163 6b65 7434  acket LhsPacket4
+00004d40: 5061 636b 696e 673b 0a0a 2020 7479 7065  Packing;..  type
+00004d50: 6465 6620 5175 6164 5061 636b 6574 3c52  def QuadPacket<R
+00004d60: 6873 5061 636b 6574 3e20 5268 7350 6163  hsPacket> RhsPac
+00004d70: 6b65 7478 343b 0a20 2074 7970 6564 6566  ketx4;.  typedef
+00004d80: 2052 6573 5061 636b 6574 2041 6363 5061   ResPacket AccPa
+00004d90: 636b 6574 3b0a 2020 0a20 2045 4947 454e  cket;.  .  EIGEN
+00004da0: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
+00004db0: 6f69 6420 696e 6974 4163 6328 4163 6350  oid initAcc(AccP
+00004dc0: 6163 6b65 7426 2070 290a 2020 7b0a 2020  acket& p).  {.  
+00004dd0: 2020 7020 3d20 7073 6574 313c 5265 7350    p = pset1<ResP
+00004de0: 6163 6b65 743e 2852 6573 5363 616c 6172  acket>(ResScalar
+00004df0: 2830 2929 3b0a 2020 7d0a 0a20 2074 656d  (0));.  }..  tem
+00004e00: 706c 6174 653c 7479 7065 6e61 6d65 2052  plate<typename R
+00004e10: 6873 5061 636b 6574 5479 7065 3e0a 2020  hsPacketType>.  
+00004e20: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00004e30: 494e 4520 766f 6964 206c 6f61 6452 6873  INE void loadRhs
+00004e40: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
+00004e50: 2a20 622c 2052 6873 5061 636b 6574 5479  * b, RhsPacketTy
+00004e60: 7065 2620 6465 7374 2920 636f 6e73 740a  pe& dest) const.
+00004e70: 2020 7b0a 2020 2020 6465 7374 203d 2070    {.    dest = p
+00004e80: 7365 7431 3c52 6873 5061 636b 6574 5479  set1<RhsPacketTy
+00004e90: 7065 3e28 2a62 293b 0a20 207d 0a0a 2020  pe>(*b);.  }..  
+00004ea0: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00004eb0: 494e 4520 766f 6964 206c 6f61 6452 6873  INE void loadRhs
+00004ec0: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
+00004ed0: 2a20 622c 2052 6873 5061 636b 6574 7834  * b, RhsPacketx4
+00004ee0: 2620 6465 7374 2920 636f 6e73 740a 2020  & dest) const.  
+00004ef0: 7b0a 2020 2020 7062 726f 6164 6361 7374  {.    pbroadcast
+00004f00: 3428 622c 2064 6573 742e 425f 302c 2064  4(b, dest.B_0, d
+00004f10: 6573 742e 4231 2c20 6465 7374 2e42 322c  est.B1, dest.B2,
+00004f20: 2064 6573 742e 4233 293b 0a20 207d 0a0a   dest.B3);.  }..
+00004f30: 2020 7465 6d70 6c61 7465 3c74 7970 656e    template<typen
+00004f40: 616d 6520 5268 7350 6163 6b65 7454 7970  ame RhsPacketTyp
+00004f50: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
+00004f60: 475f 494e 4c49 4e45 2076 6f69 6420 7570  G_INLINE void up
+00004f70: 6461 7465 5268 7328 636f 6e73 7420 5268  dateRhs(const Rh
+00004f80: 7353 6361 6c61 722a 2062 2c20 5268 7350  sScalar* b, RhsP
+00004f90: 6163 6b65 7454 7970 6526 2064 6573 7429  acketType& dest)
+00004fa0: 2063 6f6e 7374 0a20 207b 0a20 2020 206c   const.  {.    l
+00004fb0: 6f61 6452 6873 2862 2c20 6465 7374 293b  oadRhs(b, dest);
+00004fc0: 0a20 207d 0a0a 2020 4549 4745 4e5f 5354  .  }..  EIGEN_ST
+00004fd0: 524f 4e47 5f49 4e4c 494e 4520 766f 6964  RONG_INLINE void
+00004fe0: 2075 7064 6174 6552 6873 2863 6f6e 7374   updateRhs(const
+00004ff0: 2052 6873 5363 616c 6172 2a2c 2052 6873   RhsScalar*, Rhs
+00005000: 5061 636b 6574 7834 2629 2063 6f6e 7374  Packetx4&) const
+00005010: 0a20 207b 0a20 207d 0a0a 2020 4549 4745  .  {.  }..  EIGE
+00005020: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
+00005030: 766f 6964 206c 6f61 6452 6873 5175 6164  void loadRhsQuad
+00005040: 2863 6f6e 7374 2052 6873 5363 616c 6172  (const RhsScalar
+00005050: 2a20 622c 2052 6873 5061 636b 6574 2620  * b, RhsPacket& 
+00005060: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
+00005070: 2020 2020 6465 7374 203d 2070 6c6f 6164      dest = pload
+00005080: 7175 6164 3c52 6873 5061 636b 6574 3e28  quad<RhsPacket>(
+00005090: 6229 3b0a 2020 7d0a 0a20 2074 656d 706c  b);.  }..  templ
+000050a0: 6174 653c 7479 7065 6e61 6d65 204c 6873  ate<typename Lhs
+000050b0: 5061 636b 6574 5479 7065 3e0a 2020 4549  PacketType>.  EI
+000050c0: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
+000050d0: 4520 766f 6964 206c 6f61 644c 6873 2863  E void loadLhs(c
+000050e0: 6f6e 7374 204c 6873 5363 616c 6172 2a20  onst LhsScalar* 
+000050f0: 612c 204c 6873 5061 636b 6574 5479 7065  a, LhsPacketType
+00005100: 2620 6465 7374 2920 636f 6e73 740a 2020  & dest) const.  
+00005110: 7b0a 2020 2020 6465 7374 203d 2070 6c6f  {.    dest = plo
+00005120: 6164 3c4c 6873 5061 636b 6574 5479 7065  ad<LhsPacketType
+00005130: 3e28 6129 3b0a 2020 7d0a 0a20 2074 656d  >(a);.  }..  tem
+00005140: 706c 6174 653c 7479 7065 6e61 6d65 204c  plate<typename L
+00005150: 6873 5061 636b 6574 5479 7065 3e0a 2020  hsPacketType>.  
+00005160: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00005170: 494e 4520 766f 6964 206c 6f61 644c 6873  INE void loadLhs
+00005180: 556e 616c 6967 6e65 6428 636f 6e73 7420  Unaligned(const 
+00005190: 4c68 7353 6361 6c61 722a 2061 2c20 4c68  LhsScalar* a, Lh
+000051a0: 7350 6163 6b65 7454 7970 6526 2064 6573  sPacketType& des
+000051b0: 7429 2063 6f6e 7374 0a20 207b 0a20 2020  t) const.  {.   
+000051c0: 2064 6573 7420 3d20 706c 6f61 6475 3c4c   dest = ploadu<L
+000051d0: 6873 5061 636b 6574 5479 7065 3e28 6129  hsPacketType>(a)
+000051e0: 3b0a 2020 7d0a 0a20 2074 656d 706c 6174  ;.  }..  templat
+000051f0: 653c 7479 7065 6e61 6d65 204c 6873 5061  e<typename LhsPa
+00005200: 636b 6574 5479 7065 2c20 7479 7065 6e61  cketType, typena
+00005210: 6d65 2052 6873 5061 636b 6574 5479 7065  me RhsPacketType
+00005220: 2c20 7479 7065 6e61 6d65 2041 6363 5061  , typename AccPa
+00005230: 636b 6574 5479 7065 2c20 7479 7065 6e61  cketType, typena
+00005240: 6d65 204c 616e 6549 6454 7970 653e 0a20  me LaneIdType>. 
+00005250: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
+00005260: 4c49 4e45 2076 6f69 6420 6d61 6464 2863  LINE void madd(c
+00005270: 6f6e 7374 204c 6873 5061 636b 6574 5479  onst LhsPacketTy
+00005280: 7065 2620 612c 2063 6f6e 7374 2052 6873  pe& a, const Rhs
+00005290: 5061 636b 6574 5479 7065 2620 622c 2041  PacketType& b, A
+000052a0: 6363 5061 636b 6574 5479 7065 2620 632c  ccPacketType& c,
+000052b0: 2052 6873 5061 636b 6574 5479 7065 2620   RhsPacketType& 
+000052c0: 746d 702c 2063 6f6e 7374 204c 616e 6549  tmp, const LaneI
+000052d0: 6454 7970 6526 2920 636f 6e73 740a 2020  dType&) const.  
+000052e0: 7b0a 2020 2020 636f 6e6a 5f68 656c 7065  {.    conj_helpe
+000052f0: 723c 4c68 7350 6163 6b65 7454 7970 652c  r<LhsPacketType,
+00005300: 5268 7350 6163 6b65 7454 7970 652c 436f  RhsPacketType,Co
+00005310: 6e6a 4c68 732c 436f 6e6a 5268 733e 2063  njLhs,ConjRhs> c
+00005320: 6a3b 0a20 2020 202f 2f20 4974 2077 6f75  j;.    // It wou
+00005330: 6c64 2062 6520 6120 6c6f 7420 636c 6561  ld be a lot clea
+00005340: 6e65 7220 746f 2063 616c 6c20 706d 6164  ner to call pmad
+00005350: 6420 616c 6c20 7468 6520 7469 6d65 2e20  d all the time. 
+00005360: 556e 666f 7274 756e 6174 656c 7920 6966  Unfortunately if
+00005370: 2077 650a 2020 2020 2f2f 206c 6574 2067   we.    // let g
+00005380: 6363 2061 6c6c 6f63 6174 6520 7468 6520  cc allocate the 
+00005390: 7265 6769 7374 6572 2069 6e20 7768 6963  register in whic
+000053a0: 6820 746f 2073 746f 7265 2074 6865 2072  h to store the r
+000053b0: 6573 756c 7420 6f66 2074 6865 2070 6d75  esult of the pmu
+000053c0: 6c0a 2020 2020 2f2f 2028 696e 2074 6865  l.    // (in the
+000053d0: 2063 6173 6520 7768 6572 6520 7468 6572   case where ther
+000053e0: 6520 6973 206e 6f20 464d 4129 2067 6363  e is no FMA) gcc
+000053f0: 2066 6169 6c73 2074 6f20 6669 6775 7265   fails to figure
+00005400: 206f 7574 2068 6f77 2074 6f20 6176 6f69   out how to avoi
+00005410: 640a 2020 2020 2f2f 2073 7069 6c6c 696e  d.    // spillin
+00005420: 6720 7265 6769 7374 6572 2e0a 2369 6664  g register..#ifd
+00005430: 6566 2045 4947 454e 5f48 4153 5f53 494e  ef EIGEN_HAS_SIN
+00005440: 474c 455f 494e 5354 5255 4354 494f 4e5f  GLE_INSTRUCTION_
+00005450: 4d41 4444 0a20 2020 2045 4947 454e 5f55  MADD.    EIGEN_U
+00005460: 4e55 5345 445f 5641 5249 4142 4c45 2874  NUSED_VARIABLE(t
+00005470: 6d70 293b 0a20 2020 2063 203d 2063 6a2e  mp);.    c = cj.
+00005480: 706d 6164 6428 612c 622c 6329 3b0a 2365  pmadd(a,b,c);.#e
+00005490: 6c73 650a 2020 2020 746d 7020 3d20 623b  lse.    tmp = b;
+000054a0: 2074 6d70 203d 2063 6a2e 706d 756c 2861   tmp = cj.pmul(a
+000054b0: 2c74 6d70 293b 2063 203d 2070 6164 6428  ,tmp); c = padd(
+000054c0: 632c 746d 7029 3b0a 2365 6e64 6966 0a20  c,tmp);.#endif. 
+000054d0: 207d 0a0a 2020 7465 6d70 6c61 7465 3c74   }..  template<t
+000054e0: 7970 656e 616d 6520 4c68 7350 6163 6b65  ypename LhsPacke
+000054f0: 7454 7970 652c 2074 7970 656e 616d 6520  tType, typename 
+00005500: 4163 6350 6163 6b65 7454 7970 652c 2074  AccPacketType, t
+00005510: 7970 656e 616d 6520 4c61 6e65 4964 5479  ypename LaneIdTy
+00005520: 7065 3e0a 2020 4549 4745 4e5f 5354 524f  pe>.  EIGEN_STRO
+00005530: 4e47 5f49 4e4c 494e 4520 766f 6964 206d  NG_INLINE void m
+00005540: 6164 6428 636f 6e73 7420 4c68 7350 6163  add(const LhsPac
+00005550: 6b65 7454 7970 6526 2061 2c20 636f 6e73  ketType& a, cons
+00005560: 7420 5268 7350 6163 6b65 7478 3426 2062  t RhsPacketx4& b
+00005570: 2c20 4163 6350 6163 6b65 7454 7970 6526  , AccPacketType&
+00005580: 2063 2c20 5268 7350 6163 6b65 7426 2074   c, RhsPacket& t
+00005590: 6d70 2c20 636f 6e73 7420 4c61 6e65 4964  mp, const LaneId
+000055a0: 5479 7065 2620 6c61 6e65 2920 636f 6e73  Type& lane) cons
+000055b0: 740a 2020 7b0a 2020 2020 6d61 6464 2861  t.  {.    madd(a
+000055c0: 2c20 622e 6765 7428 6c61 6e65 292c 2063  , b.get(lane), c
+000055d0: 2c20 746d 702c 206c 616e 6529 3b0a 2020  , tmp, lane);.  
+000055e0: 7d0a 0a20 2045 4947 454e 5f53 5452 4f4e  }..  EIGEN_STRON
+000055f0: 475f 494e 4c49 4e45 2076 6f69 6420 6163  G_INLINE void ac
+00005600: 6328 636f 6e73 7420 4163 6350 6163 6b65  c(const AccPacke
+00005610: 7426 2063 2c20 636f 6e73 7420 5265 7350  t& c, const ResP
+00005620: 6163 6b65 7426 2061 6c70 6861 2c20 5265  acket& alpha, Re
+00005630: 7350 6163 6b65 7426 2072 2920 636f 6e73  sPacket& r) cons
+00005640: 740a 2020 7b0a 2020 2020 7220 3d20 706d  t.  {.    r = pm
+00005650: 6164 6428 632c 616c 7068 612c 7229 3b0a  add(c,alpha,r);.
+00005660: 2020 7d0a 2020 0a20 2074 656d 706c 6174    }.  .  templat
+00005670: 653c 7479 7065 6e61 6d65 2052 6573 5061  e<typename ResPa
+00005680: 636b 6574 4861 6c66 3e0a 2020 4549 4745  cketHalf>.  EIGE
+00005690: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
+000056a0: 766f 6964 2061 6363 2863 6f6e 7374 2052  void acc(const R
+000056b0: 6573 5061 636b 6574 4861 6c66 2620 632c  esPacketHalf& c,
+000056c0: 2063 6f6e 7374 2052 6573 5061 636b 6574   const ResPacket
+000056d0: 4861 6c66 2620 616c 7068 612c 2052 6573  Half& alpha, Res
+000056e0: 5061 636b 6574 4861 6c66 2620 7229 2063  PacketHalf& r) c
+000056f0: 6f6e 7374 0a20 207b 0a20 2020 2072 203d  onst.  {.    r =
+00005700: 2070 6d61 6464 2863 2c61 6c70 6861 2c72   pmadd(c,alpha,r
+00005710: 293b 0a20 207d 0a0a 7d3b 0a0a 7465 6d70  );.  }..};..temp
+00005720: 6c61 7465 3c74 7970 656e 616d 6520 5265  late<typename Re
+00005730: 616c 5363 616c 6172 2c20 626f 6f6c 205f  alScalar, bool _
+00005740: 436f 6e6a 4c68 732c 2069 6e74 2041 7263  ConjLhs, int Arc
+00005750: 682c 2069 6e74 205f 5061 636b 6574 5369  h, int _PacketSi
+00005760: 7a65 3e0a 636c 6173 7320 6765 6270 5f74  ze>.class gebp_t
+00005770: 7261 6974 733c 7374 643a 3a63 6f6d 706c  raits<std::compl
+00005780: 6578 3c52 6561 6c53 6361 6c61 723e 2c20  ex<RealScalar>, 
+00005790: 5265 616c 5363 616c 6172 2c20 5f43 6f6e  RealScalar, _Con
+000057a0: 6a4c 6873 2c20 6661 6c73 652c 2041 7263  jLhs, false, Arc
+000057b0: 682c 205f 5061 636b 6574 5369 7a65 3e0a  h, _PacketSize>.
+000057c0: 7b0a 7075 626c 6963 3a0a 2020 7479 7065  {.public:.  type
+000057d0: 6465 6620 7374 643a 3a63 6f6d 706c 6578  def std::complex
+000057e0: 3c52 6561 6c53 6361 6c61 723e 204c 6873  <RealScalar> Lhs
+000057f0: 5363 616c 6172 3b0a 2020 7479 7065 6465  Scalar;.  typede
+00005800: 6620 5265 616c 5363 616c 6172 2052 6873  f RealScalar Rhs
+00005810: 5363 616c 6172 3b0a 2020 7479 7065 6465  Scalar;.  typede
+00005820: 6620 7479 7065 6e61 6d65 2053 6361 6c61  f typename Scala
+00005830: 7242 696e 6172 794f 7054 7261 6974 733c  rBinaryOpTraits<
+00005840: 4c68 7353 6361 6c61 722c 2052 6873 5363  LhsScalar, RhsSc
+00005850: 616c 6172 3e3a 3a52 6574 7572 6e54 7970  alar>::ReturnTyp
+00005860: 6520 5265 7353 6361 6c61 723b 0a0a 2020  e ResScalar;..  
+00005870: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
+00005880: 5f50 5245 4649 5828 5f2c 204c 6873 2c20  _PREFIX(_, Lhs, 
+00005890: 5f50 6163 6b65 7453 697a 6529 3b0a 2020  _PacketSize);.  
+000058a0: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
+000058b0: 5f50 5245 4649 5828 5f2c 2052 6873 2c20  _PREFIX(_, Rhs, 
+000058c0: 5f50 6163 6b65 7453 697a 6529 3b0a 2020  _PacketSize);.  
+000058d0: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
+000058e0: 5f50 5245 4649 5828 5f2c 2052 6573 2c20  _PREFIX(_, Res, 
+000058f0: 5f50 6163 6b65 7453 697a 6529 3b0a 0a20  _PacketSize);.. 
+00005900: 2065 6e75 6d20 7b0a 2020 2020 436f 6e6a   enum {.    Conj
+00005910: 4c68 7320 3d20 5f43 6f6e 6a4c 6873 2c0a  Lhs = _ConjLhs,.
+00005920: 2020 2020 436f 6e6a 5268 7320 3d20 6661      ConjRhs = fa
+00005930: 6c73 652c 0a20 2020 2056 6563 746f 7269  lse,.    Vectori
+00005940: 7a61 626c 6520 3d20 756e 7061 636b 6574  zable = unpacket
+00005950: 5f74 7261 6974 733c 5f4c 6873 5061 636b  _traits<_LhsPack
+00005960: 6574 3e3a 3a76 6563 746f 7269 7a61 626c  et>::vectorizabl
+00005970: 6520 2626 2075 6e70 6163 6b65 745f 7472  e && unpacket_tr
+00005980: 6169 7473 3c5f 5268 7350 6163 6b65 743e  aits<_RhsPacket>
+00005990: 3a3a 7665 6374 6f72 697a 6162 6c65 2c0a  ::vectorizable,.
+000059a0: 2020 2020 4c68 7350 6163 6b65 7453 697a      LhsPacketSiz
+000059b0: 6520 3d20 5665 6374 6f72 697a 6162 6c65  e = Vectorizable
+000059c0: 203f 2075 6e70 6163 6b65 745f 7472 6169   ? unpacket_trai
+000059d0: 7473 3c5f 4c68 7350 6163 6b65 743e 3a3a  ts<_LhsPacket>::
+000059e0: 7369 7a65 203a 2031 2c0a 2020 2020 5268  size : 1,.    Rh
+000059f0: 7350 6163 6b65 7453 697a 6520 3d20 5665  sPacketSize = Ve
+00005a00: 6374 6f72 697a 6162 6c65 203f 2075 6e70  ctorizable ? unp
+00005a10: 6163 6b65 745f 7472 6169 7473 3c5f 5268  acket_traits<_Rh
+00005a20: 7350 6163 6b65 743e 3a3a 7369 7a65 203a  sPacket>::size :
+00005a30: 2031 2c0a 2020 2020 5265 7350 6163 6b65   1,.    ResPacke
+00005a40: 7453 697a 6520 3d20 5665 6374 6f72 697a  tSize = Vectoriz
+00005a50: 6162 6c65 203f 2075 6e70 6163 6b65 745f  able ? unpacket_
+00005a60: 7472 6169 7473 3c5f 5265 7350 6163 6b65  traits<_ResPacke
+00005a70: 743e 3a3a 7369 7a65 203a 2031 2c0a 2020  t>::size : 1,.  
+00005a80: 2020 0a20 2020 204e 756d 6265 724f 6652    .    NumberOfR
+00005a90: 6567 6973 7465 7273 203d 2045 4947 454e  egisters = EIGEN
+00005aa0: 5f41 5243 485f 4445 4641 554c 545f 4e55  _ARCH_DEFAULT_NU
+00005ab0: 4d42 4552 5f4f 465f 5245 4749 5354 4552  MBER_OF_REGISTER
+00005ac0: 532c 0a20 2020 206e 7220 3d20 342c 0a23  S,.    nr = 4,.#
+00005ad0: 6966 2064 6566 696e 6564 2845 4947 454e  if defined(EIGEN
+00005ae0: 5f48 4153 5f53 494e 474c 455f 494e 5354  _HAS_SINGLE_INST
+00005af0: 5255 4354 494f 4e5f 4d41 4444 2920 2626  RUCTION_MADD) &&
+00005b00: 2021 6465 6669 6e65 6428 4549 4745 4e5f   !defined(EIGEN_
+00005b10: 5645 4354 4f52 495a 455f 414c 5449 5645  VECTORIZE_ALTIVE
+00005b20: 4329 2026 2620 2164 6566 696e 6564 2845  C) && !defined(E
+00005b30: 4947 454e 5f56 4543 544f 5249 5a45 5f56  IGEN_VECTORIZE_V
+00005b40: 5358 290a 2020 2020 2f2f 2077 6520 6173  SX).    // we as
+00005b50: 7375 6d65 2031 3620 7265 6769 7374 6572  sume 16 register
+00005b60: 730a 2020 2020 6d72 203d 2033 2a4c 6873  s.    mr = 3*Lhs
+00005b70: 5061 636b 6574 5369 7a65 2c0a 2365 6c73  PacketSize,.#els
+00005b80: 650a 2020 2020 6d72 203d 2028 4549 4745  e.    mr = (EIGE
+00005b90: 4e5f 504c 4149 4e5f 454e 554d 5f4d 494e  N_PLAIN_ENUM_MIN
+00005ba0: 2831 362c 4e75 6d62 6572 4f66 5265 6769  (16,NumberOfRegi
+00005bb0: 7374 6572 7329 2f32 2f6e 7229 2a4c 6873  sters)/2/nr)*Lhs
+00005bc0: 5061 636b 6574 5369 7a65 2c0a 2365 6e64  PacketSize,.#end
+00005bd0: 6966 0a0a 2020 2020 4c68 7350 726f 6772  if..    LhsProgr
+00005be0: 6573 7320 3d20 4c68 7350 6163 6b65 7453  ess = LhsPacketS
+00005bf0: 697a 652c 0a20 2020 2052 6873 5072 6f67  ize,.    RhsProg
+00005c00: 7265 7373 203d 2031 0a20 207d 3b0a 0a20  ress = 1.  };.. 
+00005c10: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
+00005c20: 6520 636f 6e64 6974 696f 6e61 6c3c 5665  e conditional<Ve
+00005c30: 6374 6f72 697a 6162 6c65 2c5f 4c68 7350  ctorizable,_LhsP
+00005c40: 6163 6b65 742c 4c68 7353 6361 6c61 723e  acket,LhsScalar>
+00005c50: 3a3a 7479 7065 204c 6873 5061 636b 6574  ::type LhsPacket
+00005c60: 3b0a 2020 7479 7065 6465 6620 7479 7065  ;.  typedef type
+00005c70: 6e61 6d65 2063 6f6e 6469 7469 6f6e 616c  name conditional
+00005c80: 3c56 6563 746f 7269 7a61 626c 652c 5f52  <Vectorizable,_R
+00005c90: 6873 5061 636b 6574 2c52 6873 5363 616c  hsPacket,RhsScal
+00005ca0: 6172 3e3a 3a74 7970 6520 5268 7350 6163  ar>::type RhsPac
+00005cb0: 6b65 743b 0a20 2074 7970 6564 6566 2074  ket;.  typedef t
+00005cc0: 7970 656e 616d 6520 636f 6e64 6974 696f  ypename conditio
+00005cd0: 6e61 6c3c 5665 6374 6f72 697a 6162 6c65  nal<Vectorizable
+00005ce0: 2c5f 5265 7350 6163 6b65 742c 5265 7353  ,_ResPacket,ResS
+00005cf0: 6361 6c61 723e 3a3a 7479 7065 2052 6573  calar>::type Res
+00005d00: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
+00005d10: 6620 4c68 7350 6163 6b65 7420 4c68 7350  f LhsPacket LhsP
+00005d20: 6163 6b65 7434 5061 636b 696e 673b 0a0a  acket4Packing;..
+00005d30: 2020 7479 7065 6465 6620 5175 6164 5061    typedef QuadPa
+00005d40: 636b 6574 3c52 6873 5061 636b 6574 3e20  cket<RhsPacket> 
+00005d50: 5268 7350 6163 6b65 7478 343b 0a0a 2020  RhsPacketx4;..  
+00005d60: 7479 7065 6465 6620 5265 7350 6163 6b65  typedef ResPacke
+00005d70: 7420 4163 6350 6163 6b65 743b 0a0a 2020  t AccPacket;..  
+00005d80: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00005d90: 494e 4520 766f 6964 2069 6e69 7441 6363  INE void initAcc
+00005da0: 2841 6363 5061 636b 6574 2620 7029 0a20  (AccPacket& p). 
+00005db0: 207b 0a20 2020 2070 203d 2070 7365 7431   {.    p = pset1
+00005dc0: 3c52 6573 5061 636b 6574 3e28 5265 7353  <ResPacket>(ResS
+00005dd0: 6361 6c61 7228 3029 293b 0a20 207d 0a0a  calar(0));.  }..
+00005de0: 2020 7465 6d70 6c61 7465 3c74 7970 656e    template<typen
+00005df0: 616d 6520 5268 7350 6163 6b65 7454 7970  ame RhsPacketTyp
+00005e00: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
+00005e10: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
+00005e20: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
+00005e30: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
+00005e40: 6b65 7454 7970 6526 2064 6573 7429 2063  ketType& dest) c
+00005e50: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
+00005e60: 7420 3d20 7073 6574 313c 5268 7350 6163  t = pset1<RhsPac
+00005e70: 6b65 7454 7970 653e 282a 6229 3b0a 2020  ketType>(*b);.  
+00005e80: 7d0a 0a20 2045 4947 454e 5f53 5452 4f4e  }..  EIGEN_STRON
+00005e90: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
+00005ea0: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
+00005eb0: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
+00005ec0: 6b65 7478 3426 2064 6573 7429 2063 6f6e  ketx4& dest) con
+00005ed0: 7374 0a20 207b 0a20 2020 2070 6272 6f61  st.  {.    pbroa
+00005ee0: 6463 6173 7434 2862 2c20 6465 7374 2e42  dcast4(b, dest.B
+00005ef0: 5f30 2c20 6465 7374 2e42 312c 2064 6573  _0, dest.B1, des
+00005f00: 742e 4232 2c20 6465 7374 2e42 3329 3b0a  t.B2, dest.B3);.
+00005f10: 2020 7d0a 0a20 2074 656d 706c 6174 653c    }..  template<
+00005f20: 7479 7065 6e61 6d65 2052 6873 5061 636b  typename RhsPack
+00005f30: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
+00005f40: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+00005f50: 6964 2075 7064 6174 6552 6873 2863 6f6e  id updateRhs(con
+00005f60: 7374 2052 6873 5363 616c 6172 2a20 622c  st RhsScalar* b,
+00005f70: 2052 6873 5061 636b 6574 5479 7065 2620   RhsPacketType& 
+00005f80: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
+00005f90: 2020 2020 6c6f 6164 5268 7328 622c 2064      loadRhs(b, d
+00005fa0: 6573 7429 3b0a 2020 7d0a 0a20 2045 4947  est);.  }..  EIG
+00005fb0: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
+00005fc0: 2076 6f69 6420 7570 6461 7465 5268 7328   void updateRhs(
+00005fd0: 636f 6e73 7420 5268 7353 6361 6c61 722a  const RhsScalar*
+00005fe0: 2c20 5268 7350 6163 6b65 7478 3426 2920  , RhsPacketx4&) 
+00005ff0: 636f 6e73 740a 2020 7b7d 0a20 200a 2020  const.  {}.  .  
+00006000: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00006010: 494e 4520 766f 6964 206c 6f61 6452 6873  INE void loadRhs
+00006020: 5175 6164 2863 6f6e 7374 2052 6873 5363  Quad(const RhsSc
+00006030: 616c 6172 2a20 622c 2052 6873 5061 636b  alar* b, RhsPack
+00006040: 6574 2620 6465 7374 2920 636f 6e73 740a  et& dest) const.
+00006050: 2020 7b0a 2020 2020 6c6f 6164 5268 7351    {.    loadRhsQ
+00006060: 7561 645f 696d 706c 2862 2c64 6573 742c  uad_impl(b,dest,
+00006070: 2074 7970 656e 616d 6520 636f 6e64 6974   typename condit
+00006080: 696f 6e61 6c3c 5268 7350 6163 6b65 7453  ional<RhsPacketS
+00006090: 697a 653d 3d31 362c 7472 7565 5f74 7970  ize==16,true_typ
+000060a0: 652c 6661 6c73 655f 7479 7065 3e3a 3a74  e,false_type>::t
+000060b0: 7970 6528 2929 3b0a 2020 7d0a 0a20 2045  ype());.  }..  E
+000060c0: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
+000060d0: 4e45 2076 6f69 6420 6c6f 6164 5268 7351  NE void loadRhsQ
+000060e0: 7561 645f 696d 706c 2863 6f6e 7374 2052  uad_impl(const R
+000060f0: 6873 5363 616c 6172 2a20 622c 2052 6873  hsScalar* b, Rhs
+00006100: 5061 636b 6574 2620 6465 7374 2c20 636f  Packet& dest, co
+00006110: 6e73 7420 7472 7565 5f74 7970 6526 2920  nst true_type&) 
+00006120: 636f 6e73 740a 2020 7b0a 2020 2020 2f2f  const.  {.    //
+00006130: 2046 4958 4d45 2077 6520 6361 6e20 646f   FIXME we can do
+00006140: 2062 6574 7465 7221 0a20 2020 202f 2f20   better!.    // 
+00006150: 7768 6174 2077 6520 7761 6e74 2068 6572  what we want her
+00006160: 6520 6973 2061 2070 6c6f 6164 6865 6967  e is a ploadheig
+00006170: 6874 0a20 2020 2052 6873 5363 616c 6172  ht.    RhsScalar
+00006180: 2074 6d70 5b34 5d20 3d20 7b62 5b30 5d2c   tmp[4] = {b[0],
+00006190: 625b 305d 2c62 5b31 5d2c 625b 315d 7d3b  b[0],b[1],b[1]};
+000061a0: 0a20 2020 2064 6573 7420 3d20 706c 6f61  .    dest = ploa
+000061b0: 6471 7561 643c 5268 7350 6163 6b65 743e  dquad<RhsPacket>
+000061c0: 2874 6d70 293b 0a20 207d 0a0a 2020 4549  (tmp);.  }..  EI
+000061d0: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
+000061e0: 4520 766f 6964 206c 6f61 6452 6873 5175  E void loadRhsQu
+000061f0: 6164 5f69 6d70 6c28 636f 6e73 7420 5268  ad_impl(const Rh
+00006200: 7353 6361 6c61 722a 2062 2c20 5268 7350  sScalar* b, RhsP
+00006210: 6163 6b65 7426 2064 6573 742c 2063 6f6e  acket& dest, con
+00006220: 7374 2066 616c 7365 5f74 7970 6526 2920  st false_type&) 
+00006230: 636f 6e73 740a 2020 7b0a 2020 2020 6569  const.  {.    ei
+00006240: 6765 6e5f 696e 7465 726e 616c 5f61 7373  gen_internal_ass
+00006250: 6572 7428 5268 7350 6163 6b65 7453 697a  ert(RhsPacketSiz
+00006260: 653c 3d38 293b 0a20 2020 2064 6573 7420  e<=8);.    dest 
+00006270: 3d20 7073 6574 313c 5268 7350 6163 6b65  = pset1<RhsPacke
+00006280: 743e 282a 6229 3b0a 2020 7d0a 0a20 2045  t>(*b);.  }..  E
+00006290: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
+000062a0: 4e45 2076 6f69 6420 6c6f 6164 4c68 7328  NE void loadLhs(
+000062b0: 636f 6e73 7420 4c68 7353 6361 6c61 722a  const LhsScalar*
+000062c0: 2061 2c20 4c68 7350 6163 6b65 7426 2064   a, LhsPacket& d
+000062d0: 6573 7429 2063 6f6e 7374 0a20 207b 0a20  est) const.  {. 
+000062e0: 2020 2064 6573 7420 3d20 706c 6f61 643c     dest = pload<
+000062f0: 4c68 7350 6163 6b65 743e 2861 293b 0a20  LhsPacket>(a);. 
+00006300: 207d 0a0a 2020 7465 6d70 6c61 7465 3c74   }..  template<t
+00006310: 7970 656e 616d 6520 4c68 7350 6163 6b65  ypename LhsPacke
+00006320: 7454 7970 653e 0a20 2045 4947 454e 5f53  tType>.  EIGEN_S
+00006330: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
+00006340: 6420 6c6f 6164 4c68 7355 6e61 6c69 676e  d loadLhsUnalign
+00006350: 6564 2863 6f6e 7374 204c 6873 5363 616c  ed(const LhsScal
+00006360: 6172 2a20 612c 204c 6873 5061 636b 6574  ar* a, LhsPacket
+00006370: 5479 7065 2620 6465 7374 2920 636f 6e73  Type& dest) cons
+00006380: 740a 2020 7b0a 2020 2020 6465 7374 203d  t.  {.    dest =
+00006390: 2070 6c6f 6164 753c 4c68 7350 6163 6b65   ploadu<LhsPacke
+000063a0: 7454 7970 653e 2861 293b 0a20 207d 0a0a  tType>(a);.  }..
+000063b0: 2020 7465 6d70 6c61 7465 203c 7479 7065    template <type
+000063c0: 6e61 6d65 204c 6873 5061 636b 6574 5479  name LhsPacketTy
+000063d0: 7065 2c20 7479 7065 6e61 6d65 2052 6873  pe, typename Rhs
+000063e0: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
+000063f0: 6e61 6d65 2041 6363 5061 636b 6574 5479  name AccPacketTy
+00006400: 7065 2c20 7479 7065 6e61 6d65 204c 616e  pe, typename Lan
+00006410: 6549 6454 7970 653e 0a20 2045 4947 454e  eIdType>.  EIGEN
+00006420: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
+00006430: 6f69 6420 6d61 6464 2863 6f6e 7374 204c  oid madd(const L
+00006440: 6873 5061 636b 6574 5479 7065 2620 612c  hsPacketType& a,
+00006450: 2063 6f6e 7374 2052 6873 5061 636b 6574   const RhsPacket
+00006460: 5479 7065 2620 622c 2041 6363 5061 636b  Type& b, AccPack
+00006470: 6574 5479 7065 2620 632c 2052 6873 5061  etType& c, RhsPa
+00006480: 636b 6574 5479 7065 2620 746d 702c 2063  cketType& tmp, c
+00006490: 6f6e 7374 204c 616e 6549 6454 7970 6526  onst LaneIdType&
+000064a0: 2920 636f 6e73 740a 2020 7b0a 2020 2020  ) const.  {.    
+000064b0: 6d61 6464 5f69 6d70 6c28 612c 2062 2c20  madd_impl(a, b, 
+000064c0: 632c 2074 6d70 2c20 7479 7065 6e61 6d65  c, tmp, typename
+000064d0: 2063 6f6e 6469 7469 6f6e 616c 3c56 6563   conditional<Vec
+000064e0: 746f 7269 7a61 626c 652c 7472 7565 5f74  torizable,true_t
+000064f0: 7970 652c 6661 6c73 655f 7479 7065 3e3a  ype,false_type>:
+00006500: 3a74 7970 6528 2929 3b0a 2020 7d0a 0a20  :type());.  }.. 
+00006510: 2074 656d 706c 6174 6520 3c74 7970 656e   template <typen
+00006520: 616d 6520 4c68 7350 6163 6b65 7454 7970  ame LhsPacketTyp
+00006530: 652c 2074 7970 656e 616d 6520 5268 7350  e, typename RhsP
+00006540: 6163 6b65 7454 7970 652c 2074 7970 656e  acketType, typen
+00006550: 616d 6520 4163 6350 6163 6b65 7454 7970  ame AccPacketTyp
+00006560: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
+00006570: 475f 494e 4c49 4e45 2076 6f69 6420 6d61  G_INLINE void ma
+00006580: 6464 5f69 6d70 6c28 636f 6e73 7420 4c68  dd_impl(const Lh
+00006590: 7350 6163 6b65 7454 7970 6526 2061 2c20  sPacketType& a, 
+000065a0: 636f 6e73 7420 5268 7350 6163 6b65 7454  const RhsPacketT
+000065b0: 7970 6526 2062 2c20 4163 6350 6163 6b65  ype& b, AccPacke
+000065c0: 7454 7970 6526 2063 2c20 5268 7350 6163  tType& c, RhsPac
+000065d0: 6b65 7454 7970 6526 2074 6d70 2c20 636f  ketType& tmp, co
+000065e0: 6e73 7420 7472 7565 5f74 7970 6526 2920  nst true_type&) 
+000065f0: 636f 6e73 740a 2020 7b0a 2369 6664 6566  const.  {.#ifdef
+00006600: 2045 4947 454e 5f48 4153 5f53 494e 474c   EIGEN_HAS_SINGL
+00006610: 455f 494e 5354 5255 4354 494f 4e5f 4d41  E_INSTRUCTION_MA
+00006620: 4444 0a20 2020 2045 4947 454e 5f55 4e55  DD.    EIGEN_UNU
+00006630: 5345 445f 5641 5249 4142 4c45 2874 6d70  SED_VARIABLE(tmp
+00006640: 293b 0a20 2020 2063 2e76 203d 2070 6d61  );.    c.v = pma
+00006650: 6464 2861 2e76 2c62 2c63 2e76 293b 0a23  dd(a.v,b,c.v);.#
+00006660: 656c 7365 0a20 2020 2074 6d70 203d 2062  else.    tmp = b
+00006670: 3b20 746d 7020 3d20 706d 756c 2861 2e76  ; tmp = pmul(a.v
+00006680: 2c74 6d70 293b 2063 2e76 203d 2070 6164  ,tmp); c.v = pad
+00006690: 6428 632e 762c 746d 7029 3b0a 2365 6e64  d(c.v,tmp);.#end
+000066a0: 6966 0a20 207d 0a0a 2020 4549 4745 4e5f  if.  }..  EIGEN_
+000066b0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+000066c0: 6964 206d 6164 645f 696d 706c 2863 6f6e  id madd_impl(con
+000066d0: 7374 204c 6873 5363 616c 6172 2620 612c  st LhsScalar& a,
+000066e0: 2063 6f6e 7374 2052 6873 5363 616c 6172   const RhsScalar
+000066f0: 2620 622c 2052 6573 5363 616c 6172 2620  & b, ResScalar& 
+00006700: 632c 2052 6873 5363 616c 6172 2620 2f2a  c, RhsScalar& /*
+00006710: 746d 702a 2f2c 2063 6f6e 7374 2066 616c  tmp*/, const fal
+00006720: 7365 5f74 7970 6526 2920 636f 6e73 740a  se_type&) const.
+00006730: 2020 7b0a 2020 2020 6320 2b3d 2061 202a    {.    c += a *
+00006740: 2062 3b0a 2020 7d0a 0a20 2074 656d 706c   b;.  }..  templ
+00006750: 6174 653c 7479 7065 6e61 6d65 204c 6873  ate<typename Lhs
+00006760: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
+00006770: 6e61 6d65 2041 6363 5061 636b 6574 5479  name AccPacketTy
+00006780: 7065 2c20 7479 7065 6e61 6d65 204c 616e  pe, typename Lan
+00006790: 6549 6454 7970 653e 0a20 2045 4947 454e  eIdType>.  EIGEN
+000067a0: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
+000067b0: 6f69 6420 6d61 6464 2863 6f6e 7374 204c  oid madd(const L
+000067c0: 6873 5061 636b 6574 5479 7065 2620 612c  hsPacketType& a,
+000067d0: 2063 6f6e 7374 2052 6873 5061 636b 6574   const RhsPacket
+000067e0: 7834 2620 622c 2041 6363 5061 636b 6574  x4& b, AccPacket
+000067f0: 5479 7065 2620 632c 2052 6873 5061 636b  Type& c, RhsPack
+00006800: 6574 2620 746d 702c 2063 6f6e 7374 204c  et& tmp, const L
+00006810: 616e 6549 6454 7970 6526 206c 616e 6529  aneIdType& lane)
+00006820: 2063 6f6e 7374 0a20 207b 0a20 2020 206d   const.  {.    m
+00006830: 6164 6428 612c 2062 2e67 6574 286c 616e  add(a, b.get(lan
+00006840: 6529 2c20 632c 2074 6d70 2c20 6c61 6e65  e), c, tmp, lane
+00006850: 293b 0a20 207d 0a0a 2020 7465 6d70 6c61  );.  }..  templa
+00006860: 7465 203c 7479 7065 6e61 6d65 2052 6573  te <typename Res
+00006870: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
+00006880: 6e61 6d65 2041 6363 5061 636b 6574 5479  name AccPacketTy
+00006890: 7065 3e0a 2020 4549 4745 4e5f 5354 524f  pe>.  EIGEN_STRO
+000068a0: 4e47 5f49 4e4c 494e 4520 766f 6964 2061  NG_INLINE void a
+000068b0: 6363 2863 6f6e 7374 2041 6363 5061 636b  cc(const AccPack
+000068c0: 6574 5479 7065 2620 632c 2063 6f6e 7374  etType& c, const
+000068d0: 2052 6573 5061 636b 6574 5479 7065 2620   ResPacketType& 
+000068e0: 616c 7068 612c 2052 6573 5061 636b 6574  alpha, ResPacket
+000068f0: 5479 7065 2620 7229 2063 6f6e 7374 0a20  Type& r) const. 
+00006900: 207b 0a20 2020 2063 6f6e 6a5f 6865 6c70   {.    conj_help
+00006910: 6572 3c52 6573 5061 636b 6574 5479 7065  er<ResPacketType
+00006920: 2c52 6573 5061 636b 6574 5479 7065 2c43  ,ResPacketType,C
+00006930: 6f6e 6a4c 6873 2c66 616c 7365 3e20 636a  onjLhs,false> cj
+00006940: 3b0a 2020 2020 7220 3d20 636a 2e70 6d61  ;.    r = cj.pma
+00006950: 6464 2863 2c61 6c70 6861 2c72 293b 0a20  dd(c,alpha,r);. 
+00006960: 207d 0a0a 7072 6f74 6563 7465 643a 0a7d   }..protected:.}
+00006970: 3b0a 0a74 656d 706c 6174 653c 7479 7065  ;..template<type
+00006980: 6e61 6d65 2050 6163 6b65 743e 0a73 7472  name Packet>.str
+00006990: 7563 7420 446f 7562 6c65 5061 636b 6574  uct DoublePacket
+000069a0: 0a7b 0a20 2050 6163 6b65 7420 6669 7273  .{.  Packet firs
+000069b0: 743b 0a20 2050 6163 6b65 7420 7365 636f  t;.  Packet seco
+000069c0: 6e64 3b0a 7d3b 0a0a 7465 6d70 6c61 7465  nd;.};..template
+000069d0: 3c74 7970 656e 616d 6520 5061 636b 6574  <typename Packet
+000069e0: 3e0a 446f 7562 6c65 5061 636b 6574 3c50  >.DoublePacket<P
+000069f0: 6163 6b65 743e 2070 6164 6428 636f 6e73  acket> padd(cons
+00006a00: 7420 446f 7562 6c65 5061 636b 6574 3c50  t DoublePacket<P
+00006a10: 6163 6b65 743e 2026 612c 2063 6f6e 7374  acket> &a, const
+00006a20: 2044 6f75 626c 6550 6163 6b65 743c 5061   DoublePacket<Pa
+00006a30: 636b 6574 3e20 2662 290a 7b0a 2020 446f  cket> &b).{.  Do
+00006a40: 7562 6c65 5061 636b 6574 3c50 6163 6b65  ublePacket<Packe
+00006a50: 743e 2072 6573 3b0a 2020 7265 732e 6669  t> res;.  res.fi
+00006a60: 7273 7420 203d 2070 6164 6428 612e 6669  rst  = padd(a.fi
+00006a70: 7273 742c 2062 2e66 6972 7374 293b 0a20  rst, b.first);. 
+00006a80: 2072 6573 2e73 6563 6f6e 6420 3d20 7061   res.second = pa
+00006a90: 6464 2861 2e73 6563 6f6e 642c 622e 7365  dd(a.second,b.se
+00006aa0: 636f 6e64 293b 0a20 2072 6574 7572 6e20  cond);.  return 
+00006ab0: 7265 733b 0a7d 0a0a 2f2f 206e 6f74 6520  res;.}..// note 
+00006ac0: 7468 6174 2066 6f72 2044 6f75 626c 6550  that for DoubleP
+00006ad0: 6163 6b65 743c 5265 616c 5061 636b 6574  acket<RealPacket
+00006ae0: 3e20 7468 6520 2234 2220 696e 2022 646f  > the "4" in "do
+00006af0: 776e 746f 3422 0a2f 2f20 636f 7272 6573  wnto4".// corres
+00006b00: 706f 6e64 7320 746f 2074 6865 206e 756d  ponds to the num
+00006b10: 6265 7220 6f66 2063 6f6d 706c 6578 6573  ber of complexes
+00006b20: 2c20 736f 2069 7420 6d65 616e 7320 2238  , so it means "8
+00006b30: 220a 2f2f 2069 7420 7465 726d 7320 6f66  ".// it terms of
+00006b40: 2072 6561 6c20 636f 6566 6669 6369 656e   real coefficien
+00006b50: 7473 2e0a 0a74 656d 706c 6174 653c 7479  ts...template<ty
+00006b60: 7065 6e61 6d65 2050 6163 6b65 743e 0a63  pename Packet>.c
+00006b70: 6f6e 7374 2044 6f75 626c 6550 6163 6b65  onst DoublePacke
+00006b80: 743c 5061 636b 6574 3e26 0a70 7265 6475  t<Packet>&.predu
+00006b90: 785f 6861 6c66 5f64 6f77 746f 3428 636f  x_half_dowto4(co
+00006ba0: 6e73 7420 446f 7562 6c65 5061 636b 6574  nst DoublePacket
+00006bb0: 3c50 6163 6b65 743e 2026 612c 0a20 2020  <Packet> &a,.   
+00006bc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006bd0: 7479 7065 6e61 6d65 2065 6e61 626c 655f  typename enable_
+00006be0: 6966 3c75 6e70 6163 6b65 745f 7472 6169  if<unpacket_trai
+00006bf0: 7473 3c50 6163 6b65 743e 3a3a 7369 7a65  ts<Packet>::size
+00006c00: 3c3d 383e 3a3a 7479 7065 2a20 3d20 3029  <=8>::type* = 0)
+00006c10: 0a7b 0a20 2072 6574 7572 6e20 613b 0a7d  .{.  return a;.}
+00006c20: 0a0a 7465 6d70 6c61 7465 3c74 7970 656e  ..template<typen
+00006c30: 616d 6520 5061 636b 6574 3e0a 446f 7562  ame Packet>.Doub
+00006c40: 6c65 5061 636b 6574 3c74 7970 656e 616d  lePacket<typenam
+00006c50: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
+00006c60: 733c 5061 636b 6574 3e3a 3a68 616c 663e  s<Packet>::half>
+00006c70: 0a70 7265 6475 785f 6861 6c66 5f64 6f77  .predux_half_dow
+00006c80: 746f 3428 636f 6e73 7420 446f 7562 6c65  to4(const Double
+00006c90: 5061 636b 6574 3c50 6163 6b65 743e 2026  Packet<Packet> &
+00006ca0: 612c 0a20 2020 2020 2020 2020 2020 2020  a,.             
+00006cb0: 2020 2020 2020 7479 7065 6e61 6d65 2065        typename e
+00006cc0: 6e61 626c 655f 6966 3c75 6e70 6163 6b65  nable_if<unpacke
+00006cd0: 745f 7472 6169 7473 3c50 6163 6b65 743e  t_traits<Packet>
+00006ce0: 3a3a 7369 7a65 3d3d 3136 3e3a 3a74 7970  ::size==16>::typ
+00006cf0: 652a 203d 2030 290a 7b0a 2020 2f2f 2079  e* = 0).{.  // y
+00006d00: 6573 2c20 7468 6174 2773 2070 7265 7474  es, that's prett
+00006d10: 7920 6861 636b 6973 6820 3a28 0a20 2044  y hackish :(.  D
+00006d20: 6f75 626c 6550 6163 6b65 743c 7479 7065  oublePacket<type
+00006d30: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
+00006d40: 6169 7473 3c50 6163 6b65 743e 3a3a 6861  aits<Packet>::ha
+00006d50: 6c66 3e20 7265 733b 0a20 2074 7970 6564  lf> res;.  typed
+00006d60: 6566 2073 7464 3a3a 636f 6d70 6c65 783c  ef std::complex<
+00006d70: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
+00006d80: 745f 7472 6169 7473 3c50 6163 6b65 743e  t_traits<Packet>
+00006d90: 3a3a 7479 7065 3e20 4370 6c78 3b0a 2020  ::type> Cplx;.  
+00006da0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
+00006db0: 2070 6163 6b65 745f 7472 6169 7473 3c43   packet_traits<C
+00006dc0: 706c 783e 3a3a 7479 7065 2043 706c 7850  plx>::type CplxP
+00006dd0: 6163 6b65 743b 0a20 2072 6573 2e66 6972  acket;.  res.fir
+00006de0: 7374 2020 3d20 7072 6564 7578 5f68 616c  st  = predux_hal
+00006df0: 665f 646f 7774 6f34 2843 706c 7850 6163  f_dowto4(CplxPac
+00006e00: 6b65 7428 612e 6669 7273 7429 292e 763b  ket(a.first)).v;
+00006e10: 0a20 2072 6573 2e73 6563 6f6e 6420 3d20  .  res.second = 
+00006e20: 7072 6564 7578 5f68 616c 665f 646f 7774  predux_half_dowt
+00006e30: 6f34 2843 706c 7850 6163 6b65 7428 612e  o4(CplxPacket(a.
+00006e40: 7365 636f 6e64 2929 2e76 3b0a 2020 7265  second)).v;.  re
+00006e50: 7475 726e 2072 6573 3b0a 7d0a 0a2f 2f20  turn res;.}..// 
+00006e60: 7361 6d65 2068 6572 652c 2022 7175 6164  same here, "quad
+00006e70: 2220 6163 7475 616c 6c79 206d 6561 6e73  " actually means
+00006e80: 2022 3822 2069 6e20 7465 726d 7320 6f66   "8" in terms of
+00006e90: 2072 6561 6c20 636f 6566 6669 6369 656e   real coefficien
+00006ea0: 7473 0a74 656d 706c 6174 653c 7479 7065  ts.template<type
+00006eb0: 6e61 6d65 2053 6361 6c61 722c 2074 7970  name Scalar, typ
+00006ec0: 656e 616d 6520 5265 616c 5061 636b 6574  ename RealPacket
+00006ed0: 3e0a 766f 6964 206c 6f61 6451 7561 6454  >.void loadQuadT
+00006ee0: 6f44 6f75 626c 6550 6163 6b65 7428 636f  oDoublePacket(co
+00006ef0: 6e73 7420 5363 616c 6172 2a20 622c 2044  nst Scalar* b, D
+00006f00: 6f75 626c 6550 6163 6b65 743c 5265 616c  oublePacket<Real
+00006f10: 5061 636b 6574 3e26 2064 6573 742c 0a20  Packet>& dest,. 
+00006f20: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00006f30: 2020 2020 2020 2020 2020 2074 7970 656e             typen
+00006f40: 616d 6520 656e 6162 6c65 5f69 663c 756e  ame enable_if<un
+00006f50: 7061 636b 6574 5f74 7261 6974 733c 5265  packet_traits<Re
+00006f60: 616c 5061 636b 6574 3e3a 3a73 697a 653c  alPacket>::size<
+00006f70: 3d38 3e3a 3a74 7970 652a 203d 2030 290a  =8>::type* = 0).
+00006f80: 7b0a 2020 6465 7374 2e66 6972 7374 2020  {.  dest.first  
+00006f90: 3d20 7073 6574 313c 5265 616c 5061 636b  = pset1<RealPack
+00006fa0: 6574 3e28 6e75 6d65 7874 3a3a 7265 616c  et>(numext::real
+00006fb0: 282a 6229 293b 0a20 2064 6573 742e 7365  (*b));.  dest.se
+00006fc0: 636f 6e64 203d 2070 7365 7431 3c52 6561  cond = pset1<Rea
+00006fd0: 6c50 6163 6b65 743e 286e 756d 6578 743a  lPacket>(numext:
+00006fe0: 3a69 6d61 6728 2a62 2929 3b0a 7d0a 0a74  :imag(*b));.}..t
+00006ff0: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
+00007000: 2053 6361 6c61 722c 2074 7970 656e 616d   Scalar, typenam
+00007010: 6520 5265 616c 5061 636b 6574 3e0a 766f  e RealPacket>.vo
+00007020: 6964 206c 6f61 6451 7561 6454 6f44 6f75  id loadQuadToDou
+00007030: 626c 6550 6163 6b65 7428 636f 6e73 7420  blePacket(const 
+00007040: 5363 616c 6172 2a20 622c 2044 6f75 626c  Scalar* b, Doubl
+00007050: 6550 6163 6b65 743c 5265 616c 5061 636b  ePacket<RealPack
+00007060: 6574 3e26 2064 6573 742c 0a20 2020 2020  et>& dest,.     
+00007070: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00007080: 2020 2020 2020 2074 7970 656e 616d 6520         typename 
+00007090: 656e 6162 6c65 5f69 663c 756e 7061 636b  enable_if<unpack
+000070a0: 6574 5f74 7261 6974 733c 5265 616c 5061  et_traits<RealPa
+000070b0: 636b 6574 3e3a 3a73 697a 653d 3d31 363e  cket>::size==16>
+000070c0: 3a3a 7479 7065 2a20 3d20 3029 0a7b 0a20  ::type* = 0).{. 
+000070d0: 202f 2f20 7965 732c 2074 6861 7427 7320   // yes, that's 
+000070e0: 7072 6574 7479 2068 6163 6b69 7368 2074  pretty hackish t
+000070f0: 6f6f 203a 280a 2020 7479 7065 6465 6620  oo :(.  typedef 
+00007100: 7479 7065 6e61 6d65 204e 756d 5472 6169  typename NumTrai
+00007110: 7473 3c53 6361 6c61 723e 3a3a 5265 616c  ts<Scalar>::Real
+00007120: 2052 6561 6c53 6361 6c61 723b 0a20 2052   RealScalar;.  R
+00007130: 6561 6c53 6361 6c61 7220 725b 345d 203d  ealScalar r[4] =
+00007140: 207b 6e75 6d65 7874 3a3a 7265 616c 2862   {numext::real(b
+00007150: 5b30 5d29 2c20 6e75 6d65 7874 3a3a 7265  [0]), numext::re
+00007160: 616c 2862 5b30 5d29 2c20 6e75 6d65 7874  al(b[0]), numext
+00007170: 3a3a 7265 616c 2862 5b31 5d29 2c20 6e75  ::real(b[1]), nu
+00007180: 6d65 7874 3a3a 7265 616c 2862 5b31 5d29  mext::real(b[1])
+00007190: 7d3b 0a20 2052 6561 6c53 6361 6c61 7220  };.  RealScalar 
+000071a0: 695b 345d 203d 207b 6e75 6d65 7874 3a3a  i[4] = {numext::
+000071b0: 696d 6167 2862 5b30 5d29 2c20 6e75 6d65  imag(b[0]), nume
+000071c0: 7874 3a3a 696d 6167 2862 5b30 5d29 2c20  xt::imag(b[0]), 
+000071d0: 6e75 6d65 7874 3a3a 696d 6167 2862 5b31  numext::imag(b[1
+000071e0: 5d29 2c20 6e75 6d65 7874 3a3a 696d 6167  ]), numext::imag
+000071f0: 2862 5b31 5d29 7d3b 0a20 2064 6573 742e  (b[1])};.  dest.
+00007200: 6669 7273 7420 203d 2070 6c6f 6164 7175  first  = ploadqu
+00007210: 6164 3c52 6561 6c50 6163 6b65 743e 2872  ad<RealPacket>(r
+00007220: 293b 0a20 2064 6573 742e 7365 636f 6e64  );.  dest.second
+00007230: 203d 2070 6c6f 6164 7175 6164 3c52 6561   = ploadquad<Rea
+00007240: 6c50 6163 6b65 743e 2869 293b 0a7d 0a0a  lPacket>(i);.}..
+00007250: 0a74 656d 706c 6174 653c 7479 7065 6e61  .template<typena
+00007260: 6d65 2050 6163 6b65 743e 2073 7472 7563  me Packet> struc
+00007270: 7420 756e 7061 636b 6574 5f74 7261 6974  t unpacket_trait
+00007280: 733c 446f 7562 6c65 5061 636b 6574 3c50  s<DoublePacket<P
+00007290: 6163 6b65 743e 203e 207b 0a20 2074 7970  acket> > {.  typ
+000072a0: 6564 6566 2044 6f75 626c 6550 6163 6b65  edef DoublePacke
+000072b0: 743c 7479 7065 6e61 6d65 2075 6e70 6163  t<typename unpac
+000072c0: 6b65 745f 7472 6169 7473 3c50 6163 6b65  ket_traits<Packe
+000072d0: 743e 3a3a 6861 6c66 3e20 6861 6c66 3b0a  t>::half> half;.
+000072e0: 7d3b 0a2f 2f20 7465 6d70 6c61 7465 3c74  };.// template<t
+000072f0: 7970 656e 616d 6520 5061 636b 6574 3e0a  ypename Packet>.
+00007300: 2f2f 2044 6f75 626c 6550 6163 6b65 743c  // DoublePacket<
+00007310: 5061 636b 6574 3e20 706d 6164 6428 636f  Packet> pmadd(co
+00007320: 6e73 7420 446f 7562 6c65 5061 636b 6574  nst DoublePacket
+00007330: 3c50 6163 6b65 743e 2026 612c 2063 6f6e  <Packet> &a, con
+00007340: 7374 2044 6f75 626c 6550 6163 6b65 743c  st DoublePacket<
+00007350: 5061 636b 6574 3e20 2662 290a 2f2f 207b  Packet> &b).// {
+00007360: 0a2f 2f20 2020 446f 7562 6c65 5061 636b  .//   DoublePack
+00007370: 6574 3c50 6163 6b65 743e 2072 6573 3b0a  et<Packet> res;.
+00007380: 2f2f 2020 2072 6573 2e66 6972 7374 2020  //   res.first  
+00007390: 3d20 7061 6464 2861 2e66 6972 7374 2c20  = padd(a.first, 
+000073a0: 622e 6669 7273 7429 3b0a 2f2f 2020 2072  b.first);.//   r
+000073b0: 6573 2e73 6563 6f6e 6420 3d20 7061 6464  es.second = padd
+000073c0: 2861 2e73 6563 6f6e 642c 622e 7365 636f  (a.second,b.seco
+000073d0: 6e64 293b 0a2f 2f20 2020 7265 7475 726e  nd);.//   return
+000073e0: 2072 6573 3b0a 2f2f 207d 0a0a 7465 6d70   res;.// }..temp
+000073f0: 6c61 7465 3c74 7970 656e 616d 6520 5265  late<typename Re
+00007400: 616c 5363 616c 6172 2c20 626f 6f6c 205f  alScalar, bool _
+00007410: 436f 6e6a 4c68 732c 2062 6f6f 6c20 5f43  ConjLhs, bool _C
+00007420: 6f6e 6a52 6873 2c20 696e 7420 4172 6368  onjRhs, int Arch
+00007430: 2c20 696e 7420 5f50 6163 6b65 7453 697a  , int _PacketSiz
+00007440: 653e 0a63 6c61 7373 2067 6562 705f 7472  e>.class gebp_tr
+00007450: 6169 7473 3c73 7464 3a3a 636f 6d70 6c65  aits<std::comple
+00007460: 783c 5265 616c 5363 616c 6172 3e2c 2073  x<RealScalar>, s
+00007470: 7464 3a3a 636f 6d70 6c65 783c 5265 616c  td::complex<Real
+00007480: 5363 616c 6172 3e2c 205f 436f 6e6a 4c68  Scalar>, _ConjLh
+00007490: 732c 205f 436f 6e6a 5268 732c 2041 7263  s, _ConjRhs, Arc
+000074a0: 682c 205f 5061 636b 6574 5369 7a65 203e  h, _PacketSize >
+000074b0: 0a7b 0a70 7562 6c69 633a 0a20 2074 7970  .{.public:.  typ
+000074c0: 6564 6566 2073 7464 3a3a 636f 6d70 6c65  edef std::comple
+000074d0: 783c 5265 616c 5363 616c 6172 3e20 2053  x<RealScalar>  S
+000074e0: 6361 6c61 723b 0a20 2074 7970 6564 6566  calar;.  typedef
+000074f0: 2073 7464 3a3a 636f 6d70 6c65 783c 5265   std::complex<Re
+00007500: 616c 5363 616c 6172 3e20 204c 6873 5363  alScalar>  LhsSc
+00007510: 616c 6172 3b0a 2020 7479 7065 6465 6620  alar;.  typedef 
+00007520: 7374 643a 3a63 6f6d 706c 6578 3c52 6561  std::complex<Rea
+00007530: 6c53 6361 6c61 723e 2020 5268 7353 6361  lScalar>  RhsSca
+00007540: 6c61 723b 0a20 2074 7970 6564 6566 2073  lar;.  typedef s
+00007550: 7464 3a3a 636f 6d70 6c65 783c 5265 616c  td::complex<Real
+00007560: 5363 616c 6172 3e20 2052 6573 5363 616c  Scalar>  ResScal
+00007570: 6172 3b0a 2020 0a20 2050 4143 4b45 545f  ar;.  .  PACKET_
+00007580: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
+00007590: 285f 2c20 4c68 732c 205f 5061 636b 6574  (_, Lhs, _Packet
+000075a0: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
+000075b0: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
+000075c0: 285f 2c20 5268 732c 205f 5061 636b 6574  (_, Rhs, _Packet
+000075d0: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
+000075e0: 4445 434c 5f43 4f4e 445f 5052 4546 4958  DECL_COND_PREFIX
+000075f0: 285f 2c20 5265 732c 205f 5061 636b 6574  (_, Res, _Packet
+00007600: 5369 7a65 293b 0a20 2050 4143 4b45 545f  Size);.  PACKET_
+00007610: 4445 434c 5f43 4f4e 4428 5265 616c 2c20  DECL_COND(Real, 
+00007620: 5f50 6163 6b65 7453 697a 6529 3b0a 2020  _PacketSize);.  
+00007630: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
+00007640: 5f53 4341 4c41 5228 5f50 6163 6b65 7453  _SCALAR(_PacketS
+00007650: 697a 6529 3b0a 0a20 2065 6e75 6d20 7b0a  ize);..  enum {.
+00007660: 2020 2020 436f 6e6a 4c68 7320 3d20 5f43      ConjLhs = _C
+00007670: 6f6e 6a4c 6873 2c0a 2020 2020 436f 6e6a  onjLhs,.    Conj
+00007680: 5268 7320 3d20 5f43 6f6e 6a52 6873 2c0a  Rhs = _ConjRhs,.
+00007690: 2020 2020 5665 6374 6f72 697a 6162 6c65      Vectorizable
+000076a0: 203d 2075 6e70 6163 6b65 745f 7472 6169   = unpacket_trai
+000076b0: 7473 3c52 6561 6c50 6163 6b65 743e 3a3a  ts<RealPacket>::
+000076c0: 7665 6374 6f72 697a 6162 6c65 0a20 2020  vectorizable.   
+000076d0: 2020 2020 2020 2020 2020 2020 2026 2620               && 
+000076e0: 756e 7061 636b 6574 5f74 7261 6974 733c  unpacket_traits<
+000076f0: 5363 616c 6172 5061 636b 6574 3e3a 3a76  ScalarPacket>::v
+00007700: 6563 746f 7269 7a61 626c 652c 0a20 2020  ectorizable,.   
+00007710: 2052 6573 5061 636b 6574 5369 7a65 2020   ResPacketSize  
+00007720: 203d 2056 6563 746f 7269 7a61 626c 6520   = Vectorizable 
+00007730: 3f20 756e 7061 636b 6574 5f74 7261 6974  ? unpacket_trait
+00007740: 733c 5f52 6573 5061 636b 6574 3e3a 3a73  s<_ResPacket>::s
+00007750: 697a 6520 3a20 312c 0a20 2020 204c 6873  ize : 1,.    Lhs
+00007760: 5061 636b 6574 5369 7a65 203d 2056 6563  PacketSize = Vec
+00007770: 746f 7269 7a61 626c 6520 3f20 756e 7061  torizable ? unpa
+00007780: 636b 6574 5f74 7261 6974 733c 5f4c 6873  cket_traits<_Lhs
+00007790: 5061 636b 6574 3e3a 3a73 697a 6520 3a20  Packet>::size : 
+000077a0: 312c 0a20 2020 2052 6873 5061 636b 6574  1,.    RhsPacket
+000077b0: 5369 7a65 203d 2056 6563 746f 7269 7a61  Size = Vectoriza
+000077c0: 626c 6520 3f20 756e 7061 636b 6574 5f74  ble ? unpacket_t
+000077d0: 7261 6974 733c 5268 7353 6361 6c61 723e  raits<RhsScalar>
+000077e0: 3a3a 7369 7a65 203a 2031 2c0a 2020 2020  ::size : 1,.    
+000077f0: 5265 616c 5061 636b 6574 5369 7a65 2020  RealPacketSize  
+00007800: 3d20 5665 6374 6f72 697a 6162 6c65 203f  = Vectorizable ?
+00007810: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
+00007820: 3c52 6561 6c50 6163 6b65 743e 3a3a 7369  <RealPacket>::si
+00007830: 7a65 203a 2031 2c0a 0a20 2020 202f 2f20  ze : 1,..    // 
+00007840: 4649 584d 453a 2073 686f 756c 6420 6465  FIXME: should de
+00007850: 7065 6e64 206f 6e20 4e75 6d62 6572 4f66  pend on NumberOf
+00007860: 5265 6769 7374 6572 730a 2020 2020 6e72  Registers.    nr
+00007870: 203d 2034 2c0a 2020 2020 6d72 203d 2052   = 4,.    mr = R
+00007880: 6573 5061 636b 6574 5369 7a65 2c0a 0a20  esPacketSize,.. 
+00007890: 2020 204c 6873 5072 6f67 7265 7373 203d     LhsProgress =
+000078a0: 2052 6573 5061 636b 6574 5369 7a65 2c0a   ResPacketSize,.
+000078b0: 2020 2020 5268 7350 726f 6772 6573 7320      RhsProgress 
+000078c0: 3d20 310a 2020 7d3b 0a20 200a 2020 7479  = 1.  };.  .  ty
+000078d0: 7065 6465 6620 446f 7562 6c65 5061 636b  pedef DoublePack
+000078e0: 6574 3c52 6561 6c50 6163 6b65 743e 2020  et<RealPacket>  
+000078f0: 2020 2020 2020 2020 2020 2020 2020 2044                 D
+00007900: 6f75 626c 6550 6163 6b65 7454 7970 653b  oublePacketType;
+00007910: 0a0a 2020 7479 7065 6465 6620 7479 7065  ..  typedef type
+00007920: 6e61 6d65 2063 6f6e 6469 7469 6f6e 616c  name conditional
+00007930: 3c56 6563 746f 7269 7a61 626c 652c 5363  <Vectorizable,Sc
+00007940: 616c 6172 5061 636b 6574 2c53 6361 6c61  alarPacket,Scala
+00007950: 723e 3a3a 7479 7065 204c 6873 5061 636b  r>::type LhsPack
+00007960: 6574 3450 6163 6b69 6e67 3b0a 2020 7479  et4Packing;.  ty
+00007970: 7065 6465 6620 7479 7065 6e61 6d65 2063  pedef typename c
+00007980: 6f6e 6469 7469 6f6e 616c 3c56 6563 746f  onditional<Vecto
+00007990: 7269 7a61 626c 652c 5265 616c 5061 636b  rizable,RealPack
+000079a0: 6574 2c20 2053 6361 6c61 723e 3a3a 7479  et,  Scalar>::ty
+000079b0: 7065 204c 6873 5061 636b 6574 3b0a 2020  pe LhsPacket;.  
+000079c0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
+000079d0: 2063 6f6e 6469 7469 6f6e 616c 3c56 6563   conditional<Vec
+000079e0: 746f 7269 7a61 626c 652c 446f 7562 6c65  torizable,Double
+000079f0: 5061 636b 6574 5479 7065 2c53 6361 6c61  PacketType,Scala
+00007a00: 723e 3a3a 7479 7065 2052 6873 5061 636b  r>::type RhsPack
+00007a10: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
+00007a20: 7065 6e61 6d65 2063 6f6e 6469 7469 6f6e  pename condition
+00007a30: 616c 3c56 6563 746f 7269 7a61 626c 652c  al<Vectorizable,
+00007a40: 5363 616c 6172 5061 636b 6574 2c53 6361  ScalarPacket,Sca
+00007a50: 6c61 723e 3a3a 7479 7065 2052 6573 5061  lar>::type ResPa
+00007a60: 636b 6574 3b0a 2020 7479 7065 6465 6620  cket;.  typedef 
+00007a70: 7479 7065 6e61 6d65 2063 6f6e 6469 7469  typename conditi
+00007a80: 6f6e 616c 3c56 6563 746f 7269 7a61 626c  onal<Vectorizabl
+00007a90: 652c 446f 7562 6c65 5061 636b 6574 5479  e,DoublePacketTy
+00007aa0: 7065 2c53 6361 6c61 723e 3a3a 7479 7065  pe,Scalar>::type
+00007ab0: 2041 6363 5061 636b 6574 3b0a 0a20 202f   AccPacket;..  /
+00007ac0: 2f20 7468 6973 2061 6374 7561 6c79 2068  / this actualy h
+00007ad0: 6f6c 6473 2038 2070 6163 6b65 7473 210a  olds 8 packets!.
+00007ae0: 2020 7479 7065 6465 6620 5175 6164 5061    typedef QuadPa
+00007af0: 636b 6574 3c52 6873 5061 636b 6574 3e20  cket<RhsPacket> 
+00007b00: 5268 7350 6163 6b65 7478 343b 0a20 200a  RhsPacketx4;.  .
+00007b10: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
+00007b20: 4e4c 494e 4520 766f 6964 2069 6e69 7441  NLINE void initA
+00007b30: 6363 2853 6361 6c61 7226 2070 2920 7b20  cc(Scalar& p) { 
+00007b40: 7020 3d20 5363 616c 6172 2830 293b 207d  p = Scalar(0); }
+00007b50: 0a0a 2020 4549 4745 4e5f 5354 524f 4e47  ..  EIGEN_STRONG
+00007b60: 5f49 4e4c 494e 4520 766f 6964 2069 6e69  _INLINE void ini
+00007b70: 7441 6363 2844 6f75 626c 6550 6163 6b65  tAcc(DoublePacke
+00007b80: 7454 7970 6526 2070 290a 2020 7b0a 2020  tType& p).  {.  
+00007b90: 2020 702e 6669 7273 7420 2020 3d20 7073    p.first   = ps
+00007ba0: 6574 313c 5265 616c 5061 636b 6574 3e28  et1<RealPacket>(
+00007bb0: 5265 616c 5363 616c 6172 2830 2929 3b0a  RealScalar(0));.
+00007bc0: 2020 2020 702e 7365 636f 6e64 2020 3d20      p.second  = 
+00007bd0: 7073 6574 313c 5265 616c 5061 636b 6574  pset1<RealPacket
+00007be0: 3e28 5265 616c 5363 616c 6172 2830 2929  >(RealScalar(0))
+00007bf0: 3b0a 2020 7d0a 0a20 202f 2f20 5363 616c  ;.  }..  // Scal
+00007c00: 6172 2070 6174 680a 2020 4549 4745 4e5f  ar path.  EIGEN_
+00007c10: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+00007c20: 6964 206c 6f61 6452 6873 2863 6f6e 7374  id loadRhs(const
+00007c30: 2052 6873 5363 616c 6172 2a20 622c 2053   RhsScalar* b, S
+00007c40: 6361 6c61 7250 6163 6b65 7426 2064 6573  calarPacket& des
+00007c50: 7429 2063 6f6e 7374 0a20 207b 0a20 2020  t) const.  {.   
+00007c60: 2064 6573 7420 3d20 7073 6574 313c 5363   dest = pset1<Sc
+00007c70: 616c 6172 5061 636b 6574 3e28 2a62 293b  alarPacket>(*b);
+00007c80: 0a20 207d 0a0a 2020 2f2f 2056 6563 746f  .  }..  // Vecto
+00007c90: 7269 7a65 6420 7061 7468 0a20 2074 656d  rized path.  tem
+00007ca0: 706c 6174 653c 7479 7065 6e61 6d65 2052  plate<typename R
+00007cb0: 6561 6c50 6163 6b65 7454 7970 653e 0a20  ealPacketType>. 
+00007cc0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
+00007cd0: 4c49 4e45 2076 6f69 6420 6c6f 6164 5268  LINE void loadRh
+00007ce0: 7328 636f 6e73 7420 5268 7353 6361 6c61  s(const RhsScala
+00007cf0: 722a 2062 2c20 446f 7562 6c65 5061 636b  r* b, DoublePack
+00007d00: 6574 3c52 6561 6c50 6163 6b65 7454 7970  et<RealPacketTyp
+00007d10: 653e 2620 6465 7374 2920 636f 6e73 740a  e>& dest) const.
+00007d20: 2020 7b0a 2020 2020 6465 7374 2e66 6972    {.    dest.fir
+00007d30: 7374 2020 3d20 7073 6574 313c 5265 616c  st  = pset1<Real
+00007d40: 5061 636b 6574 5479 7065 3e28 6e75 6d65  PacketType>(nume
+00007d50: 7874 3a3a 7265 616c 282a 6229 293b 0a20  xt::real(*b));. 
+00007d60: 2020 2064 6573 742e 7365 636f 6e64 203d     dest.second =
+00007d70: 2070 7365 7431 3c52 6561 6c50 6163 6b65   pset1<RealPacke
+00007d80: 7454 7970 653e 286e 756d 6578 743a 3a69  tType>(numext::i
+00007d90: 6d61 6728 2a62 2929 3b0a 2020 7d0a 0a20  mag(*b));.  }.. 
+00007da0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
+00007db0: 4c49 4e45 2076 6f69 6420 6c6f 6164 5268  LINE void loadRh
+00007dc0: 7328 636f 6e73 7420 5268 7353 6361 6c61  s(const RhsScala
+00007dd0: 722a 2062 2c20 5268 7350 6163 6b65 7478  r* b, RhsPacketx
+00007de0: 3426 2064 6573 7429 2063 6f6e 7374 0a20  4& dest) const. 
+00007df0: 207b 0a20 2020 206c 6f61 6452 6873 2862   {.    loadRhs(b
+00007e00: 2c20 6465 7374 2e42 5f30 293b 0a20 2020  , dest.B_0);.   
+00007e10: 206c 6f61 6452 6873 2862 202b 2031 2c20   loadRhs(b + 1, 
+00007e20: 6465 7374 2e42 3129 3b0a 2020 2020 6c6f  dest.B1);.    lo
+00007e30: 6164 5268 7328 6220 2b20 322c 2064 6573  adRhs(b + 2, des
+00007e40: 742e 4232 293b 0a20 2020 206c 6f61 6452  t.B2);.    loadR
+00007e50: 6873 2862 202b 2033 2c20 6465 7374 2e42  hs(b + 3, dest.B
+00007e60: 3329 3b0a 2020 7d0a 0a20 202f 2f20 5363  3);.  }..  // Sc
+00007e70: 616c 6172 2070 6174 680a 2020 4549 4745  alar path.  EIGE
+00007e80: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
+00007e90: 766f 6964 2075 7064 6174 6552 6873 2863  void updateRhs(c
+00007ea0: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
+00007eb0: 622c 2053 6361 6c61 7250 6163 6b65 7426  b, ScalarPacket&
+00007ec0: 2064 6573 7429 2063 6f6e 7374 0a20 207b   dest) const.  {
+00007ed0: 0a20 2020 206c 6f61 6452 6873 2862 2c20  .    loadRhs(b, 
+00007ee0: 6465 7374 293b 0a20 207d 0a0a 2020 2f2f  dest);.  }..  //
+00007ef0: 2056 6563 746f 7269 7a65 6420 7061 7468   Vectorized path
+00007f00: 0a20 2074 656d 706c 6174 653c 7479 7065  .  template<type
+00007f10: 6e61 6d65 2052 6561 6c50 6163 6b65 7454  name RealPacketT
+00007f20: 7970 653e 0a20 2045 4947 454e 5f53 5452  ype>.  EIGEN_STR
+00007f30: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
+00007f40: 7570 6461 7465 5268 7328 636f 6e73 7420  updateRhs(const 
+00007f50: 5268 7353 6361 6c61 722a 2062 2c20 446f  RhsScalar* b, Do
+00007f60: 7562 6c65 5061 636b 6574 3c52 6561 6c50  ublePacket<RealP
+00007f70: 6163 6b65 7454 7970 653e 2620 6465 7374  acketType>& dest
+00007f80: 2920 636f 6e73 740a 2020 7b0a 2020 2020  ) const.  {.    
+00007f90: 6c6f 6164 5268 7328 622c 2064 6573 7429  loadRhs(b, dest)
+00007fa0: 3b0a 2020 7d0a 0a20 2045 4947 454e 5f53  ;.  }..  EIGEN_S
+00007fb0: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
+00007fc0: 6420 7570 6461 7465 5268 7328 636f 6e73  d updateRhs(cons
+00007fd0: 7420 5268 7353 6361 6c61 722a 2c20 5268  t RhsScalar*, Rh
+00007fe0: 7350 6163 6b65 7478 3426 2920 636f 6e73  sPacketx4&) cons
+00007ff0: 7420 7b7d 0a20 200a 2020 4549 4745 4e5f  t {}.  .  EIGEN_
+00008000: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+00008010: 6964 206c 6f61 6452 6873 5175 6164 2863  id loadRhsQuad(c
+00008020: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
+00008030: 622c 2052 6573 5061 636b 6574 2620 6465  b, ResPacket& de
+00008040: 7374 2920 636f 6e73 740a 2020 7b0a 2020  st) const.  {.  
+00008050: 2020 6c6f 6164 5268 7328 622c 6465 7374    loadRhs(b,dest
+00008060: 293b 0a20 207d 0a20 2045 4947 454e 5f53  );.  }.  EIGEN_S
+00008070: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
+00008080: 6420 6c6f 6164 5268 7351 7561 6428 636f  d loadRhsQuad(co
+00008090: 6e73 7420 5268 7353 6361 6c61 722a 2062  nst RhsScalar* b
+000080a0: 2c20 446f 7562 6c65 5061 636b 6574 5479  , DoublePacketTy
+000080b0: 7065 2620 6465 7374 2920 636f 6e73 740a  pe& dest) const.
+000080c0: 2020 7b0a 2020 2020 6c6f 6164 5175 6164    {.    loadQuad
+000080d0: 546f 446f 7562 6c65 5061 636b 6574 2862  ToDoublePacket(b
+000080e0: 2c64 6573 7429 3b0a 2020 7d0a 0a20 202f  ,dest);.  }..  /
+000080f0: 2f20 6e6f 7468 696e 6720 7370 6563 6961  / nothing specia
+00008100: 6c20 6865 7265 0a20 2045 4947 454e 5f53  l here.  EIGEN_S
+00008110: 5452 4f4e 475f 494e 4c49 4e45 2076 6f69  TRONG_INLINE voi
+00008120: 6420 6c6f 6164 4c68 7328 636f 6e73 7420  d loadLhs(const 
+00008130: 4c68 7353 6361 6c61 722a 2061 2c20 4c68  LhsScalar* a, Lh
+00008140: 7350 6163 6b65 7426 2064 6573 7429 2063  sPacket& dest) c
+00008150: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
+00008160: 7420 3d20 706c 6f61 643c 4c68 7350 6163  t = pload<LhsPac
+00008170: 6b65 743e 2828 636f 6e73 7420 7479 7065  ket>((const type
+00008180: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
+00008190: 6169 7473 3c4c 6873 5061 636b 6574 3e3a  aits<LhsPacket>:
+000081a0: 3a74 7970 652a 2928 6129 293b 0a20 207d  :type*)(a));.  }
+000081b0: 0a0a 2020 7465 6d70 6c61 7465 3c74 7970  ..  template<typ
+000081c0: 656e 616d 6520 4c68 7350 6163 6b65 7454  ename LhsPacketT
+000081d0: 7970 653e 0a20 2045 4947 454e 5f53 5452  ype>.  EIGEN_STR
+000081e0: 4f4e 475f 494e 4c49 4e45 2076 6f69 6420  ONG_INLINE void 
+000081f0: 6c6f 6164 4c68 7355 6e61 6c69 676e 6564  loadLhsUnaligned
+00008200: 2863 6f6e 7374 204c 6873 5363 616c 6172  (const LhsScalar
+00008210: 2a20 612c 204c 6873 5061 636b 6574 5479  * a, LhsPacketTy
+00008220: 7065 2620 6465 7374 2920 636f 6e73 740a  pe& dest) const.
+00008230: 2020 7b0a 2020 2020 6465 7374 203d 2070    {.    dest = p
+00008240: 6c6f 6164 753c 4c68 7350 6163 6b65 7454  loadu<LhsPacketT
+00008250: 7970 653e 2828 636f 6e73 7420 7479 7065  ype>((const type
+00008260: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
+00008270: 6169 7473 3c4c 6873 5061 636b 6574 5479  aits<LhsPacketTy
+00008280: 7065 3e3a 3a74 7970 652a 2928 6129 293b  pe>::type*)(a));
+00008290: 0a20 207d 0a0a 2020 7465 6d70 6c61 7465  .  }..  template
+000082a0: 3c74 7970 656e 616d 6520 4c68 7350 6163  <typename LhsPac
+000082b0: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
+000082c0: 6520 5268 7350 6163 6b65 7454 7970 652c  e RhsPacketType,
+000082d0: 2074 7970 656e 616d 6520 5265 7350 6163   typename ResPac
+000082e0: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
+000082f0: 6520 546d 7054 7970 652c 2074 7970 656e  e TmpType, typen
+00008300: 616d 6520 4c61 6e65 4964 5479 7065 3e0a  ame LaneIdType>.
+00008310: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
+00008320: 4e4c 494e 450a 2020 7479 7065 6e61 6d65  NLINE.  typename
+00008330: 2065 6e61 626c 655f 6966 3c21 6973 5f73   enable_if<!is_s
+00008340: 616d 653c 5268 7350 6163 6b65 7454 7970  ame<RhsPacketTyp
+00008350: 652c 5268 7350 6163 6b65 7478 343e 3a3a  e,RhsPacketx4>::
+00008360: 7661 6c75 653e 3a3a 7479 7065 0a20 206d  value>::type.  m
+00008370: 6164 6428 636f 6e73 7420 4c68 7350 6163  add(const LhsPac
+00008380: 6b65 7454 7970 6526 2061 2c20 636f 6e73  ketType& a, cons
+00008390: 7420 5268 7350 6163 6b65 7454 7970 6526  t RhsPacketType&
+000083a0: 2062 2c20 446f 7562 6c65 5061 636b 6574   b, DoublePacket
+000083b0: 3c52 6573 5061 636b 6574 5479 7065 3e26  <ResPacketType>&
+000083c0: 2063 2c20 546d 7054 7970 6526 202f 2a74   c, TmpType& /*t
+000083d0: 6d70 2a2f 2c20 636f 6e73 7420 4c61 6e65  mp*/, const Lane
+000083e0: 4964 5479 7065 2629 2063 6f6e 7374 0a20  IdType&) const. 
+000083f0: 207b 0a20 2020 2063 2e66 6972 7374 2020   {.    c.first  
+00008400: 203d 2070 6164 6428 706d 756c 2861 2c62   = padd(pmul(a,b
+00008410: 2e66 6972 7374 292c 2063 2e66 6972 7374  .first), c.first
+00008420: 293b 0a20 2020 2063 2e73 6563 6f6e 6420  );.    c.second 
+00008430: 203d 2070 6164 6428 706d 756c 2861 2c62   = padd(pmul(a,b
+00008440: 2e73 6563 6f6e 6429 2c63 2e73 6563 6f6e  .second),c.secon
+00008450: 6429 3b0a 2020 7d0a 0a20 2074 656d 706c  d);.  }..  templ
+00008460: 6174 653c 7479 7065 6e61 6d65 204c 616e  ate<typename Lan
+00008470: 6549 6454 7970 653e 0a20 2045 4947 454e  eIdType>.  EIGEN
+00008480: 5f53 5452 4f4e 475f 494e 4c49 4e45 2076  _STRONG_INLINE v
+00008490: 6f69 6420 6d61 6464 2863 6f6e 7374 204c  oid madd(const L
+000084a0: 6873 5061 636b 6574 2620 612c 2063 6f6e  hsPacket& a, con
+000084b0: 7374 2052 6873 5061 636b 6574 2620 622c  st RhsPacket& b,
+000084c0: 2052 6573 5061 636b 6574 2620 632c 2052   ResPacket& c, R
+000084d0: 6873 5061 636b 6574 2620 2f2a 746d 702a  hsPacket& /*tmp*
+000084e0: 2f2c 2063 6f6e 7374 204c 616e 6549 6454  /, const LaneIdT
+000084f0: 7970 6526 2920 636f 6e73 740a 2020 7b0a  ype&) const.  {.
+00008500: 2020 2020 6320 3d20 636a 2e70 6d61 6464      c = cj.pmadd
+00008510: 2861 2c62 2c63 293b 0a20 207d 0a0a 2020  (a,b,c);.  }..  
+00008520: 7465 6d70 6c61 7465 3c74 7970 656e 616d  template<typenam
+00008530: 6520 4c68 7350 6163 6b65 7454 7970 652c  e LhsPacketType,
+00008540: 2074 7970 656e 616d 6520 4163 6350 6163   typename AccPac
+00008550: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
+00008560: 6520 4c61 6e65 4964 5479 7065 3e0a 2020  e LaneIdType>.  
+00008570: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00008580: 494e 4520 766f 6964 206d 6164 6428 636f  INE void madd(co
+00008590: 6e73 7420 4c68 7350 6163 6b65 7454 7970  nst LhsPacketTyp
+000085a0: 6526 2061 2c20 636f 6e73 7420 5268 7350  e& a, const RhsP
+000085b0: 6163 6b65 7478 3426 2062 2c20 4163 6350  acketx4& b, AccP
+000085c0: 6163 6b65 7454 7970 6526 2063 2c20 5268  acketType& c, Rh
+000085d0: 7350 6163 6b65 7426 2074 6d70 2c20 636f  sPacket& tmp, co
+000085e0: 6e73 7420 4c61 6e65 4964 5479 7065 2620  nst LaneIdType& 
+000085f0: 6c61 6e65 2920 636f 6e73 740a 2020 7b0a  lane) const.  {.
+00008600: 2020 2020 6d61 6464 2861 2c20 622e 6765      madd(a, b.ge
+00008610: 7428 6c61 6e65 292c 2063 2c20 746d 702c  t(lane), c, tmp,
+00008620: 206c 616e 6529 3b0a 2020 7d0a 2020 0a20   lane);.  }.  . 
+00008630: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
+00008640: 4c49 4e45 2076 6f69 6420 6163 6328 636f  LINE void acc(co
+00008650: 6e73 7420 5363 616c 6172 2620 632c 2063  nst Scalar& c, c
+00008660: 6f6e 7374 2053 6361 6c61 7226 2061 6c70  onst Scalar& alp
+00008670: 6861 2c20 5363 616c 6172 2620 7229 2063  ha, Scalar& r) c
+00008680: 6f6e 7374 207b 2072 202b 3d20 616c 7068  onst { r += alph
+00008690: 6120 2a20 633b 207d 0a20 200a 2020 7465  a * c; }.  .  te
+000086a0: 6d70 6c61 7465 3c74 7970 656e 616d 6520  mplate<typename 
+000086b0: 5265 616c 5061 636b 6574 5479 7065 2c20  RealPacketType, 
+000086c0: 7479 7065 6e61 6d65 2052 6573 5061 636b  typename ResPack
+000086d0: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
+000086e0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+000086f0: 6964 2061 6363 2863 6f6e 7374 2044 6f75  id acc(const Dou
+00008700: 626c 6550 6163 6b65 743c 5265 616c 5061  blePacket<RealPa
+00008710: 636b 6574 5479 7065 3e26 2063 2c20 636f  cketType>& c, co
+00008720: 6e73 7420 5265 7350 6163 6b65 7454 7970  nst ResPacketTyp
+00008730: 6526 2061 6c70 6861 2c20 5265 7350 6163  e& alpha, ResPac
+00008740: 6b65 7454 7970 6526 2072 2920 636f 6e73  ketType& r) cons
+00008750: 740a 2020 7b0a 2020 2020 2f2f 2061 7373  t.  {.    // ass
+00008760: 656d 626c 6520 630a 2020 2020 5265 7350  emble c.    ResP
+00008770: 6163 6b65 7454 7970 6520 746d 703b 0a20  acketType tmp;. 
+00008780: 2020 2069 6628 2821 436f 6e6a 4c68 7329     if((!ConjLhs)
+00008790: 2626 2821 436f 6e6a 5268 7329 290a 2020  &&(!ConjRhs)).  
+000087a0: 2020 7b0a 2020 2020 2020 746d 7020 3d20    {.      tmp = 
+000087b0: 7063 706c 7866 6c69 7028 7063 6f6e 6a28  pcplxflip(pconj(
+000087c0: 5265 7350 6163 6b65 7454 7970 6528 632e  ResPacketType(c.
+000087d0: 7365 636f 6e64 2929 293b 0a20 2020 2020  second)));.     
+000087e0: 2074 6d70 203d 2070 6164 6428 5265 7350   tmp = padd(ResP
+000087f0: 6163 6b65 7454 7970 6528 632e 6669 7273  acketType(c.firs
+00008800: 7429 2c74 6d70 293b 0a20 2020 207d 0a20  t),tmp);.    }. 
+00008810: 2020 2065 6c73 6520 6966 2828 2143 6f6e     else if((!Con
+00008820: 6a4c 6873 2926 2628 436f 6e6a 5268 7329  jLhs)&&(ConjRhs)
+00008830: 290a 2020 2020 7b0a 2020 2020 2020 746d  ).    {.      tm
+00008840: 7020 3d20 7063 6f6e 6a28 7063 706c 7866  p = pconj(pcplxf
+00008850: 6c69 7028 5265 7350 6163 6b65 7454 7970  lip(ResPacketTyp
+00008860: 6528 632e 7365 636f 6e64 2929 293b 0a20  e(c.second)));. 
+00008870: 2020 2020 2074 6d70 203d 2070 6164 6428       tmp = padd(
+00008880: 5265 7350 6163 6b65 7454 7970 6528 632e  ResPacketType(c.
+00008890: 6669 7273 7429 2c74 6d70 293b 0a20 2020  first),tmp);.   
+000088a0: 207d 0a20 2020 2065 6c73 6520 6966 2828   }.    else if((
+000088b0: 436f 6e6a 4c68 7329 2626 2821 436f 6e6a  ConjLhs)&&(!Conj
+000088c0: 5268 7329 290a 2020 2020 7b0a 2020 2020  Rhs)).    {.    
+000088d0: 2020 746d 7020 3d20 7063 706c 7866 6c69    tmp = pcplxfli
+000088e0: 7028 5265 7350 6163 6b65 7454 7970 6528  p(ResPacketType(
+000088f0: 632e 7365 636f 6e64 2929 3b0a 2020 2020  c.second));.    
+00008900: 2020 746d 7020 3d20 7061 6464 2870 636f    tmp = padd(pco
+00008910: 6e6a 2852 6573 5061 636b 6574 5479 7065  nj(ResPacketType
+00008920: 2863 2e66 6972 7374 2929 2c74 6d70 293b  (c.first)),tmp);
+00008930: 0a20 2020 207d 0a20 2020 2065 6c73 6520  .    }.    else 
+00008940: 6966 2828 436f 6e6a 4c68 7329 2626 2843  if((ConjLhs)&&(C
+00008950: 6f6e 6a52 6873 2929 0a20 2020 207b 0a20  onjRhs)).    {. 
+00008960: 2020 2020 2074 6d70 203d 2070 6370 6c78       tmp = pcplx
+00008970: 666c 6970 2852 6573 5061 636b 6574 5479  flip(ResPacketTy
+00008980: 7065 2863 2e73 6563 6f6e 6429 293b 0a20  pe(c.second));. 
+00008990: 2020 2020 2074 6d70 203d 2070 7375 6228       tmp = psub(
+000089a0: 7063 6f6e 6a28 5265 7350 6163 6b65 7454  pconj(ResPacketT
+000089b0: 7970 6528 632e 6669 7273 7429 292c 746d  ype(c.first)),tm
+000089c0: 7029 3b0a 2020 2020 7d0a 2020 2020 0a20  p);.    }.    . 
+000089d0: 2020 2072 203d 2070 6d61 6464 2874 6d70     r = pmadd(tmp
+000089e0: 2c61 6c70 6861 2c72 293b 0a20 207d 0a0a  ,alpha,r);.  }..
+000089f0: 7072 6f74 6563 7465 643a 0a20 2063 6f6e  protected:.  con
+00008a00: 6a5f 6865 6c70 6572 3c4c 6873 5363 616c  j_helper<LhsScal
+00008a10: 6172 2c52 6873 5363 616c 6172 2c43 6f6e  ar,RhsScalar,Con
+00008a20: 6a4c 6873 2c43 6f6e 6a52 6873 3e20 636a  jLhs,ConjRhs> cj
+00008a30: 3b0a 7d3b 0a0a 7465 6d70 6c61 7465 3c74  ;.};..template<t
+00008a40: 7970 656e 616d 6520 5265 616c 5363 616c  ypename RealScal
+00008a50: 6172 2c20 626f 6f6c 205f 436f 6e6a 5268  ar, bool _ConjRh
+00008a60: 732c 2069 6e74 2041 7263 682c 2069 6e74  s, int Arch, int
+00008a70: 205f 5061 636b 6574 5369 7a65 3e0a 636c   _PacketSize>.cl
+00008a80: 6173 7320 6765 6270 5f74 7261 6974 733c  ass gebp_traits<
+00008a90: 5265 616c 5363 616c 6172 2c20 7374 643a  RealScalar, std:
+00008aa0: 3a63 6f6d 706c 6578 3c52 6561 6c53 6361  :complex<RealSca
+00008ab0: 6c61 723e 2c20 6661 6c73 652c 205f 436f  lar>, false, _Co
+00008ac0: 6e6a 5268 732c 2041 7263 682c 205f 5061  njRhs, Arch, _Pa
+00008ad0: 636b 6574 5369 7a65 203e 0a7b 0a70 7562  cketSize >.{.pub
+00008ae0: 6c69 633a 0a20 2074 7970 6564 6566 2073  lic:.  typedef s
+00008af0: 7464 3a3a 636f 6d70 6c65 783c 5265 616c  td::complex<Real
+00008b00: 5363 616c 6172 3e20 2053 6361 6c61 723b  Scalar>  Scalar;
+00008b10: 0a20 2074 7970 6564 6566 2052 6561 6c53  .  typedef RealS
+00008b20: 6361 6c61 7220 204c 6873 5363 616c 6172  calar  LhsScalar
+00008b30: 3b0a 2020 7479 7065 6465 6620 5363 616c  ;.  typedef Scal
+00008b40: 6172 2020 2020 2020 5268 7353 6361 6c61  ar      RhsScala
+00008b50: 723b 0a20 2074 7970 6564 6566 2053 6361  r;.  typedef Sca
+00008b60: 6c61 7220 2020 2020 2052 6573 5363 616c  lar      ResScal
+00008b70: 6172 3b0a 0a20 2050 4143 4b45 545f 4445  ar;..  PACKET_DE
+00008b80: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
+00008b90: 2c20 4c68 732c 205f 5061 636b 6574 5369  , Lhs, _PacketSi
+00008ba0: 7a65 293b 0a20 2050 4143 4b45 545f 4445  ze);.  PACKET_DE
+00008bb0: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
+00008bc0: 2c20 5268 732c 205f 5061 636b 6574 5369  , Rhs, _PacketSi
+00008bd0: 7a65 293b 0a20 2050 4143 4b45 545f 4445  ze);.  PACKET_DE
+00008be0: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
+00008bf0: 2c20 5265 732c 205f 5061 636b 6574 5369  , Res, _PacketSi
+00008c00: 7a65 293b 0a20 2050 4143 4b45 545f 4445  ze);.  PACKET_DE
+00008c10: 434c 5f43 4f4e 445f 5052 4546 4958 285f  CL_COND_PREFIX(_
+00008c20: 2c20 5265 616c 2c20 5f50 6163 6b65 7453  , Real, _PacketS
+00008c30: 697a 6529 3b0a 2020 5041 434b 4554 5f44  ize);.  PACKET_D
+00008c40: 4543 4c5f 434f 4e44 5f53 4341 4c41 525f  ECL_COND_SCALAR_
+00008c50: 5052 4546 4958 285f 2c20 5f50 6163 6b65  PREFIX(_, _Packe
+00008c60: 7453 697a 6529 3b0a 0a23 756e 6465 6620  tSize);..#undef 
+00008c70: 5041 434b 4554 5f44 4543 4c5f 434f 4e44  PACKET_DECL_COND
+00008c80: 5f53 4341 4c41 525f 5052 4546 4958 0a23  _SCALAR_PREFIX.#
+00008c90: 756e 6465 6620 5041 434b 4554 5f44 4543  undef PACKET_DEC
+00008ca0: 4c5f 434f 4e44 5f50 5245 4649 580a 2375  L_COND_PREFIX.#u
+00008cb0: 6e64 6566 2050 4143 4b45 545f 4445 434c  ndef PACKET_DECL
+00008cc0: 5f43 4f4e 445f 5343 414c 4152 0a23 756e  _COND_SCALAR.#un
+00008cd0: 6465 6620 5041 434b 4554 5f44 4543 4c5f  def PACKET_DECL_
+00008ce0: 434f 4e44 0a0a 2020 656e 756d 207b 0a20  COND..  enum {. 
+00008cf0: 2020 2043 6f6e 6a4c 6873 203d 2066 616c     ConjLhs = fal
+00008d00: 7365 2c0a 2020 2020 436f 6e6a 5268 7320  se,.    ConjRhs 
+00008d10: 3d20 5f43 6f6e 6a52 6873 2c0a 2020 2020  = _ConjRhs,.    
+00008d20: 5665 6374 6f72 697a 6162 6c65 203d 2075  Vectorizable = u
+00008d30: 6e70 6163 6b65 745f 7472 6169 7473 3c5f  npacket_traits<_
+00008d40: 5265 616c 5061 636b 6574 3e3a 3a76 6563  RealPacket>::vec
+00008d50: 746f 7269 7a61 626c 650a 2020 2020 2020  torizable.      
+00008d60: 2020 2020 2020 2020 2020 2626 2075 6e70            && unp
+00008d70: 6163 6b65 745f 7472 6169 7473 3c5f 5363  acket_traits<_Sc
+00008d80: 616c 6172 5061 636b 6574 3e3a 3a76 6563  alarPacket>::vec
+00008d90: 746f 7269 7a61 626c 652c 0a20 2020 204c  torizable,.    L
+00008da0: 6873 5061 636b 6574 5369 7a65 203d 2056  hsPacketSize = V
+00008db0: 6563 746f 7269 7a61 626c 6520 3f20 756e  ectorizable ? un
+00008dc0: 7061 636b 6574 5f74 7261 6974 733c 5f4c  packet_traits<_L
+00008dd0: 6873 5061 636b 6574 3e3a 3a73 697a 6520  hsPacket>::size 
+00008de0: 3a20 312c 0a20 2020 2052 6873 5061 636b  : 1,.    RhsPack
+00008df0: 6574 5369 7a65 203d 2056 6563 746f 7269  etSize = Vectori
+00008e00: 7a61 626c 6520 3f20 756e 7061 636b 6574  zable ? unpacket
+00008e10: 5f74 7261 6974 733c 5f52 6873 5061 636b  _traits<_RhsPack
+00008e20: 6574 3e3a 3a73 697a 6520 3a20 312c 0a20  et>::size : 1,. 
+00008e30: 2020 2052 6573 5061 636b 6574 5369 7a65     ResPacketSize
+00008e40: 203d 2056 6563 746f 7269 7a61 626c 6520   = Vectorizable 
+00008e50: 3f20 756e 7061 636b 6574 5f74 7261 6974  ? unpacket_trait
+00008e60: 733c 5f52 6573 5061 636b 6574 3e3a 3a73  s<_ResPacket>::s
+00008e70: 697a 6520 3a20 312c 0a20 2020 200a 2020  ize : 1,.    .  
+00008e80: 2020 4e75 6d62 6572 4f66 5265 6769 7374    NumberOfRegist
+00008e90: 6572 7320 3d20 4549 4745 4e5f 4152 4348  ers = EIGEN_ARCH
+00008ea0: 5f44 4546 4155 4c54 5f4e 554d 4245 525f  _DEFAULT_NUMBER_
+00008eb0: 4f46 5f52 4547 4953 5445 5253 2c0a 2020  OF_REGISTERS,.  
+00008ec0: 2020 2f2f 2046 4958 4d45 3a20 7368 6f75    // FIXME: shou
+00008ed0: 6c64 2064 6570 656e 6420 6f6e 204e 756d  ld depend on Num
+00008ee0: 6265 724f 6652 6567 6973 7465 7273 0a20  berOfRegisters. 
+00008ef0: 2020 206e 7220 3d20 342c 0a20 2020 206d     nr = 4,.    m
+00008f00: 7220 3d20 2845 4947 454e 5f50 4c41 494e  r = (EIGEN_PLAIN
+00008f10: 5f45 4e55 4d5f 4d49 4e28 3136 2c4e 756d  _ENUM_MIN(16,Num
+00008f20: 6265 724f 6652 6567 6973 7465 7273 292f  berOfRegisters)/
+00008f30: 322f 6e72 292a 5265 7350 6163 6b65 7453  2/nr)*ResPacketS
+00008f40: 697a 652c 0a0a 2020 2020 4c68 7350 726f  ize,..    LhsPro
+00008f50: 6772 6573 7320 3d20 5265 7350 6163 6b65  gress = ResPacke
+00008f60: 7453 697a 652c 0a20 2020 2052 6873 5072  tSize,.    RhsPr
+00008f70: 6f67 7265 7373 203d 2031 0a20 207d 3b0a  ogress = 1.  };.
+00008f80: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
+00008f90: 616d 6520 636f 6e64 6974 696f 6e61 6c3c  ame conditional<
+00008fa0: 5665 6374 6f72 697a 6162 6c65 2c5f 4c68  Vectorizable,_Lh
+00008fb0: 7350 6163 6b65 742c 4c68 7353 6361 6c61  sPacket,LhsScala
+00008fc0: 723e 3a3a 7479 7065 204c 6873 5061 636b  r>::type LhsPack
+00008fd0: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
+00008fe0: 7065 6e61 6d65 2063 6f6e 6469 7469 6f6e  pename condition
+00008ff0: 616c 3c56 6563 746f 7269 7a61 626c 652c  al<Vectorizable,
+00009000: 5f52 6873 5061 636b 6574 2c52 6873 5363  _RhsPacket,RhsSc
+00009010: 616c 6172 3e3a 3a74 7970 6520 5268 7350  alar>::type RhsP
+00009020: 6163 6b65 743b 0a20 2074 7970 6564 6566  acket;.  typedef
+00009030: 2074 7970 656e 616d 6520 636f 6e64 6974   typename condit
+00009040: 696f 6e61 6c3c 5665 6374 6f72 697a 6162  ional<Vectorizab
+00009050: 6c65 2c5f 5265 7350 6163 6b65 742c 5265  le,_ResPacket,Re
+00009060: 7353 6361 6c61 723e 3a3a 7479 7065 2052  sScalar>::type R
+00009070: 6573 5061 636b 6574 3b0a 2020 7479 7065  esPacket;.  type
+00009080: 6465 6620 4c68 7350 6163 6b65 7420 4c68  def LhsPacket Lh
+00009090: 7350 6163 6b65 7434 5061 636b 696e 673b  sPacket4Packing;
+000090a0: 0a20 2074 7970 6564 6566 2051 7561 6450  .  typedef QuadP
+000090b0: 6163 6b65 743c 5268 7350 6163 6b65 743e  acket<RhsPacket>
+000090c0: 2052 6873 5061 636b 6574 7834 3b0a 2020   RhsPacketx4;.  
+000090d0: 7479 7065 6465 6620 5265 7350 6163 6b65  typedef ResPacke
+000090e0: 7420 4163 6350 6163 6b65 743b 0a0a 2020  t AccPacket;..  
+000090f0: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00009100: 494e 4520 766f 6964 2069 6e69 7441 6363  INE void initAcc
+00009110: 2841 6363 5061 636b 6574 2620 7029 0a20  (AccPacket& p). 
+00009120: 207b 0a20 2020 2070 203d 2070 7365 7431   {.    p = pset1
+00009130: 3c52 6573 5061 636b 6574 3e28 5265 7353  <ResPacket>(ResS
+00009140: 6361 6c61 7228 3029 293b 0a20 207d 0a0a  calar(0));.  }..
+00009150: 2020 7465 6d70 6c61 7465 3c74 7970 656e    template<typen
+00009160: 616d 6520 5268 7350 6163 6b65 7454 7970  ame RhsPacketTyp
+00009170: 653e 0a20 2045 4947 454e 5f53 5452 4f4e  e>.  EIGEN_STRON
+00009180: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
+00009190: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
+000091a0: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
+000091b0: 6b65 7454 7970 6526 2064 6573 7429 2063  ketType& dest) c
+000091c0: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
+000091d0: 7420 3d20 7073 6574 313c 5268 7350 6163  t = pset1<RhsPac
+000091e0: 6b65 7454 7970 653e 282a 6229 3b0a 2020  ketType>(*b);.  
+000091f0: 7d0a 0a20 2045 4947 454e 5f53 5452 4f4e  }..  EIGEN_STRON
+00009200: 475f 494e 4c49 4e45 2076 6f69 6420 6c6f  G_INLINE void lo
+00009210: 6164 5268 7328 636f 6e73 7420 5268 7353  adRhs(const RhsS
+00009220: 6361 6c61 722a 2062 2c20 5268 7350 6163  calar* b, RhsPac
+00009230: 6b65 7478 3426 2064 6573 7429 2063 6f6e  ketx4& dest) con
+00009240: 7374 0a20 207b 0a20 2020 2070 6272 6f61  st.  {.    pbroa
+00009250: 6463 6173 7434 2862 2c20 6465 7374 2e42  dcast4(b, dest.B
+00009260: 5f30 2c20 6465 7374 2e42 312c 2064 6573  _0, dest.B1, des
+00009270: 742e 4232 2c20 6465 7374 2e42 3329 3b0a  t.B2, dest.B3);.
+00009280: 2020 7d0a 0a20 2074 656d 706c 6174 653c    }..  template<
+00009290: 7479 7065 6e61 6d65 2052 6873 5061 636b  typename RhsPack
+000092a0: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
+000092b0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+000092c0: 6964 2075 7064 6174 6552 6873 2863 6f6e  id updateRhs(con
+000092d0: 7374 2052 6873 5363 616c 6172 2a20 622c  st RhsScalar* b,
+000092e0: 2052 6873 5061 636b 6574 5479 7065 2620   RhsPacketType& 
+000092f0: 6465 7374 2920 636f 6e73 740a 2020 7b0a  dest) const.  {.
+00009300: 2020 2020 6c6f 6164 5268 7328 622c 2064      loadRhs(b, d
+00009310: 6573 7429 3b0a 2020 7d0a 0a20 2045 4947  est);.  }..  EIG
+00009320: 454e 5f53 5452 4f4e 475f 494e 4c49 4e45  EN_STRONG_INLINE
+00009330: 2076 6f69 6420 7570 6461 7465 5268 7328   void updateRhs(
+00009340: 636f 6e73 7420 5268 7353 6361 6c61 722a  const RhsScalar*
+00009350: 2c20 5268 7350 6163 6b65 7478 3426 2920  , RhsPacketx4&) 
+00009360: 636f 6e73 740a 2020 7b7d 0a0a 2020 4549  const.  {}..  EI
+00009370: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
+00009380: 4520 766f 6964 206c 6f61 644c 6873 2863  E void loadLhs(c
+00009390: 6f6e 7374 204c 6873 5363 616c 6172 2a20  onst LhsScalar* 
+000093a0: 612c 204c 6873 5061 636b 6574 2620 6465  a, LhsPacket& de
+000093b0: 7374 2920 636f 6e73 740a 2020 7b0a 2020  st) const.  {.  
+000093c0: 2020 6465 7374 203d 2070 6c6f 6164 6475    dest = ploaddu
+000093d0: 703c 4c68 7350 6163 6b65 743e 2861 293b  p<LhsPacket>(a);
+000093e0: 0a20 207d 0a20 200a 2020 4549 4745 4e5f  .  }.  .  EIGEN_
+000093f0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+00009400: 6964 206c 6f61 6452 6873 5175 6164 2863  id loadRhsQuad(c
+00009410: 6f6e 7374 2052 6873 5363 616c 6172 2a20  onst RhsScalar* 
+00009420: 622c 2052 6873 5061 636b 6574 2620 6465  b, RhsPacket& de
+00009430: 7374 2920 636f 6e73 740a 2020 7b0a 2020  st) const.  {.  
+00009440: 2020 6465 7374 203d 2070 6c6f 6164 7175    dest = ploadqu
+00009450: 6164 3c52 6873 5061 636b 6574 3e28 6229  ad<RhsPacket>(b)
+00009460: 3b0a 2020 7d0a 0a20 2074 656d 706c 6174  ;.  }..  templat
+00009470: 653c 7479 7065 6e61 6d65 204c 6873 5061  e<typename LhsPa
+00009480: 636b 6574 5479 7065 3e0a 2020 4549 4745  cketType>.  EIGE
+00009490: 4e5f 5354 524f 4e47 5f49 4e4c 494e 4520  N_STRONG_INLINE 
+000094a0: 766f 6964 206c 6f61 644c 6873 556e 616c  void loadLhsUnal
+000094b0: 6967 6e65 6428 636f 6e73 7420 4c68 7353  igned(const LhsS
+000094c0: 6361 6c61 722a 2061 2c20 4c68 7350 6163  calar* a, LhsPac
+000094d0: 6b65 7454 7970 6526 2064 6573 7429 2063  ketType& dest) c
+000094e0: 6f6e 7374 0a20 207b 0a20 2020 2064 6573  onst.  {.    des
+000094f0: 7420 3d20 706c 6f61 6464 7570 3c4c 6873  t = ploaddup<Lhs
+00009500: 5061 636b 6574 5479 7065 3e28 6129 3b0a  PacketType>(a);.
+00009510: 2020 7d0a 0a20 2074 656d 706c 6174 6520    }..  template 
+00009520: 3c74 7970 656e 616d 6520 4c68 7350 6163  <typename LhsPac
+00009530: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
+00009540: 6520 5268 7350 6163 6b65 7454 7970 652c  e RhsPacketType,
+00009550: 2074 7970 656e 616d 6520 4163 6350 6163   typename AccPac
+00009560: 6b65 7454 7970 652c 2074 7970 656e 616d  ketType, typenam
+00009570: 6520 4c61 6e65 4964 5479 7065 3e0a 2020  e LaneIdType>.  
+00009580: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+00009590: 494e 4520 766f 6964 206d 6164 6428 636f  INE void madd(co
+000095a0: 6e73 7420 4c68 7350 6163 6b65 7454 7970  nst LhsPacketTyp
+000095b0: 6526 2061 2c20 636f 6e73 7420 5268 7350  e& a, const RhsP
+000095c0: 6163 6b65 7454 7970 6526 2062 2c20 4163  acketType& b, Ac
+000095d0: 6350 6163 6b65 7454 7970 6526 2063 2c20  cPacketType& c, 
+000095e0: 5268 7350 6163 6b65 7454 7970 6526 2074  RhsPacketType& t
+000095f0: 6d70 2c20 636f 6e73 7420 4c61 6e65 4964  mp, const LaneId
+00009600: 5479 7065 2629 2063 6f6e 7374 0a20 207b  Type&) const.  {
+00009610: 0a20 2020 206d 6164 645f 696d 706c 2861  .    madd_impl(a
+00009620: 2c20 622c 2063 2c20 746d 702c 2074 7970  , b, c, tmp, typ
+00009630: 656e 616d 6520 636f 6e64 6974 696f 6e61  ename conditiona
+00009640: 6c3c 5665 6374 6f72 697a 6162 6c65 2c74  l<Vectorizable,t
+00009650: 7275 655f 7479 7065 2c66 616c 7365 5f74  rue_type,false_t
+00009660: 7970 653e 3a3a 7479 7065 2829 293b 0a20  ype>::type());. 
+00009670: 207d 0a0a 2020 7465 6d70 6c61 7465 203c   }..  template <
+00009680: 7479 7065 6e61 6d65 204c 6873 5061 636b  typename LhsPack
+00009690: 6574 5479 7065 2c20 7479 7065 6e61 6d65  etType, typename
+000096a0: 2052 6873 5061 636b 6574 5479 7065 2c20   RhsPacketType, 
+000096b0: 7479 7065 6e61 6d65 2041 6363 5061 636b  typename AccPack
+000096c0: 6574 5479 7065 3e0a 2020 4549 4745 4e5f  etType>.  EIGEN_
+000096d0: 5354 524f 4e47 5f49 4e4c 494e 4520 766f  STRONG_INLINE vo
+000096e0: 6964 206d 6164 645f 696d 706c 2863 6f6e  id madd_impl(con
+000096f0: 7374 204c 6873 5061 636b 6574 5479 7065  st LhsPacketType
+00009700: 2620 612c 2063 6f6e 7374 2052 6873 5061  & a, const RhsPa
+00009710: 636b 6574 5479 7065 2620 622c 2041 6363  cketType& b, Acc
+00009720: 5061 636b 6574 5479 7065 2620 632c 2052  PacketType& c, R
+00009730: 6873 5061 636b 6574 5479 7065 2620 746d  hsPacketType& tm
+00009740: 702c 2063 6f6e 7374 2074 7275 655f 7479  p, const true_ty
+00009750: 7065 2629 2063 6f6e 7374 0a20 207b 0a23  pe&) const.  {.#
+00009760: 6966 6465 6620 4549 4745 4e5f 4841 535f  ifdef EIGEN_HAS_
+00009770: 5349 4e47 4c45 5f49 4e53 5452 5543 5449  SINGLE_INSTRUCTI
+00009780: 4f4e 5f4d 4144 440a 2020 2020 4549 4745  ON_MADD.    EIGE
+00009790: 4e5f 554e 5553 4544 5f56 4152 4941 424c  N_UNUSED_VARIABL
+000097a0: 4528 746d 7029 3b0a 2020 2020 632e 7620  E(tmp);.    c.v 
+000097b0: 3d20 706d 6164 6428 612c 622e 762c 632e  = pmadd(a,b.v,c.
+000097c0: 7629 3b0a 2365 6c73 650a 2020 2020 746d  v);.#else.    tm
+000097d0: 7020 3d20 623b 2074 6d70 2e76 203d 2070  p = b; tmp.v = p
+000097e0: 6d75 6c28 612c 746d 702e 7629 3b20 6320  mul(a,tmp.v); c 
+000097f0: 3d20 7061 6464 2863 2c74 6d70 293b 0a23  = padd(c,tmp);.#
+00009800: 656e 6469 660a 2020 2020 0a20 207d 0a0a  endif.    .  }..
+00009810: 2020 4549 4745 4e5f 5354 524f 4e47 5f49    EIGEN_STRONG_I
+00009820: 4e4c 494e 4520 766f 6964 206d 6164 645f  NLINE void madd_
+00009830: 696d 706c 2863 6f6e 7374 204c 6873 5363  impl(const LhsSc
+00009840: 616c 6172 2620 612c 2063 6f6e 7374 2052  alar& a, const R
+00009850: 6873 5363 616c 6172 2620 622c 2052 6573  hsScalar& b, Res
+00009860: 5363 616c 6172 2620 632c 2052 6873 5363  Scalar& c, RhsSc
+00009870: 616c 6172 2620 2f2a 746d 702a 2f2c 2063  alar& /*tmp*/, c
+00009880: 6f6e 7374 2066 616c 7365 5f74 7970 6526  onst false_type&
+00009890: 2920 636f 6e73 740a 2020 7b0a 2020 2020  ) const.  {.    
+000098a0: 6320 2b3d 2061 202a 2062 3b0a 2020 7d0a  c += a * b;.  }.
+000098b0: 0a20 2074 656d 706c 6174 653c 7479 7065  .  template<type
+000098c0: 6e61 6d65 204c 6873 5061 636b 6574 5479  name LhsPacketTy
+000098d0: 7065 2c20 7479 7065 6e61 6d65 2041 6363  pe, typename Acc
+000098e0: 5061 636b 6574 5479 7065 2c20 7479 7065  PacketType, type
+000098f0: 6e61 6d65 204c 616e 6549 6454 7970 653e  name LaneIdType>
+00009900: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
+00009910: 494e 4c49 4e45 2076 6f69 6420 6d61 6464  INLINE void madd
+00009920: 2863 6f6e 7374 204c 6873 5061 636b 6574  (const LhsPacket
+00009930: 5479 7065 2620 612c 2063 6f6e 7374 2052  Type& a, const R
+00009940: 6873 5061 636b 6574 7834 2620 622c 2041  hsPacketx4& b, A
+00009950: 6363 5061 636b 6574 5479 7065 2620 632c  ccPacketType& c,
+00009960: 2052 6873 5061 636b 6574 2620 746d 702c   RhsPacket& tmp,
+00009970: 2063 6f6e 7374 204c 616e 6549 6454 7970   const LaneIdTyp
+00009980: 6526 206c 616e 6529 2063 6f6e 7374 0a20  e& lane) const. 
+00009990: 207b 0a20 2020 206d 6164 6428 612c 2062   {.    madd(a, b
+000099a0: 2e67 6574 286c 616e 6529 2c20 632c 2074  .get(lane), c, t
+000099b0: 6d70 2c20 6c61 6e65 293b 0a20 207d 0a0a  mp, lane);.  }..
+000099c0: 2020 7465 6d70 6c61 7465 203c 7479 7065    template <type
+000099d0: 6e61 6d65 2052 6573 5061 636b 6574 5479  name ResPacketTy
+000099e0: 7065 2c20 7479 7065 6e61 6d65 2041 6363  pe, typename Acc
+000099f0: 5061 636b 6574 5479 7065 3e0a 2020 4549  PacketType>.  EI
+00009a00: 4745 4e5f 5354 524f 4e47 5f49 4e4c 494e  GEN_STRONG_INLIN
+00009a10: 4520 766f 6964 2061 6363 2863 6f6e 7374  E void acc(const
+00009a20: 2041 6363 5061 636b 6574 5479 7065 2620   AccPacketType& 
+00009a30: 632c 2063 6f6e 7374 2052 6573 5061 636b  c, const ResPack
+00009a40: 6574 5479 7065 2620 616c 7068 612c 2052  etType& alpha, R
+00009a50: 6573 5061 636b 6574 5479 7065 2620 7229  esPacketType& r)
+00009a60: 2063 6f6e 7374 0a20 207b 0a20 2020 2063   const.  {.    c
+00009a70: 6f6e 6a5f 6865 6c70 6572 3c52 6573 5061  onj_helper<ResPa
+00009a80: 636b 6574 5479 7065 2c52 6573 5061 636b  cketType,ResPack
+00009a90: 6574 5479 7065 2c66 616c 7365 2c43 6f6e  etType,false,Con
+00009aa0: 6a52 6873 3e20 636a 3b0a 2020 2020 7220  jRhs> cj;.    r 
+00009ab0: 3d20 636a 2e70 6d61 6464 2861 6c70 6861  = cj.pmadd(alpha
+00009ac0: 2c63 2c72 293b 0a20 207d 0a0a 7072 6f74  ,c,r);.  }..prot
+00009ad0: 6563 7465 643a 0a0a 7d3b 0a0a 2f2a 206f  ected:..};../* o
+00009ae0: 7074 696d 697a 6564 2047 656e 6572 616c  ptimized General
+00009af0: 2070 6163 6b65 6420 426c 6f63 6b20 2a20   packed Block * 
+00009b00: 7061 636b 6564 2050 616e 656c 2070 726f  packed Panel pro
+00009b10: 6475 6374 206b 6572 6e65 6c0a 202a 0a20  duct kernel. *. 
+00009b20: 2a20 4d69 7869 6e67 2074 7970 6520 6c6f  * Mixing type lo
+00009b30: 6769 633a 2043 202b 3d20 4120 2a20 420a  gic: C += A * B.
+00009b40: 202a 2020 7c20 2041 2020 7c20 2042 2020   *  |  A  |  B  
+00009b50: 7c20 636f 6d6d 656e 7473 0a20 2a20 207c  | comments. *  |
+00009b60: 7265 616c 207c 6370 6c78 207c 206e 6f20  real |cplx | no 
+00009b70: 7665 6374 6f72 697a 6174 696f 6e20 7965  vectorization ye
+00009b80: 742c 2077 6f75 6c64 2072 6571 7569 7265  t, would require
+00009b90: 2074 6f20 7061 636b 2041 2077 6974 6820   to pack A with 
+00009ba0: 6475 706c 6963 6174 696f 6e0a 202a 2020  duplication. *  
+00009bb0: 7c63 706c 7820 7c72 6561 6c20 7c20 6561  |cplx |real | ea
+00009bc0: 7379 2076 6563 746f 7269 7a61 7469 6f6e  sy vectorization
+00009bd0: 0a20 2a2f 0a74 656d 706c 6174 653c 7479  . */.template<ty
+00009be0: 7065 6e61 6d65 204c 6873 5363 616c 6172  pename LhsScalar
+00009bf0: 2c20 7479 7065 6e61 6d65 2052 6873 5363  , typename RhsSc
+00009c00: 616c 6172 2c20 7479 7065 6e61 6d65 2049  alar, typename I
+00009c10: 6e64 6578 2c20 7479 7065 6e61 6d65 2044  ndex, typename D
+00009c20: 6174 614d 6170 7065 722c 2069 6e74 206d  ataMapper, int m
+00009c30: 722c 2069 6e74 206e 722c 2062 6f6f 6c20  r, int nr, bool 
+00009c40: 436f 6e6a 7567 6174 654c 6873 2c20 626f  ConjugateLhs, bo
+00009c50: 6f6c 2043 6f6e 6a75 6761 7465 5268 733e  ol ConjugateRhs>
+00009c60: 0a73 7472 7563 7420 6765 6270 5f6b 6572  .struct gebp_ker
+00009c70: 6e65 6c0a 7b0a 2020 7479 7065 6465 6620  nel.{.  typedef 
+00009c80: 6765 6270 5f74 7261 6974 733c 4c68 7353  gebp_traits<LhsS
+00009c90: 6361 6c61 722c 5268 7353 6361 6c61 722c  calar,RhsScalar,
+00009ca0: 436f 6e6a 7567 6174 654c 6873 2c43 6f6e  ConjugateLhs,Con
+00009cb0: 6a75 6761 7465 5268 732c 4172 6368 6974  jugateRhs,Archit
+00009cc0: 6563 7475 7265 3a3a 5461 7267 6574 3e20  ecture::Target> 
+00009cd0: 5472 6169 7473 3b0a 2020 7479 7065 6465  Traits;.  typede
+00009ce0: 6620 6765 6270 5f74 7261 6974 733c 4c68  f gebp_traits<Lh
+00009cf0: 7353 6361 6c61 722c 5268 7353 6361 6c61  sScalar,RhsScala
+00009d00: 722c 436f 6e6a 7567 6174 654c 6873 2c43  r,ConjugateLhs,C
+00009d10: 6f6e 6a75 6761 7465 5268 732c 4172 6368  onjugateRhs,Arch
+00009d20: 6974 6563 7475 7265 3a3a 5461 7267 6574  itecture::Target
+00009d30: 2c47 4542 5050 6163 6b65 7448 616c 663e  ,GEBPPacketHalf>
+00009d40: 2048 616c 6654 7261 6974 733b 0a20 2074   HalfTraits;.  t
+00009d50: 7970 6564 6566 2067 6562 705f 7472 6169  ypedef gebp_trai
+00009d60: 7473 3c4c 6873 5363 616c 6172 2c52 6873  ts<LhsScalar,Rhs
+00009d70: 5363 616c 6172 2c43 6f6e 6a75 6761 7465  Scalar,Conjugate
+00009d80: 4c68 732c 436f 6e6a 7567 6174 6552 6873  Lhs,ConjugateRhs
+00009d90: 2c41 7263 6869 7465 6374 7572 653a 3a54  ,Architecture::T
+00009da0: 6172 6765 742c 4745 4250 5061 636b 6574  arget,GEBPPacket
+00009db0: 5175 6172 7465 723e 2051 7561 7274 6572  Quarter> Quarter
+00009dc0: 5472 6169 7473 3b0a 2020 0a20 2074 7970  Traits;.  .  typ
+00009dd0: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009de0: 6169 7473 3a3a 5265 7353 6361 6c61 7220  aits::ResScalar 
+00009df0: 5265 7353 6361 6c61 723b 0a20 2074 7970  ResScalar;.  typ
+00009e00: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009e10: 6169 7473 3a3a 4c68 7350 6163 6b65 7420  aits::LhsPacket 
+00009e20: 4c68 7350 6163 6b65 743b 0a20 2074 7970  LhsPacket;.  typ
+00009e30: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009e40: 6169 7473 3a3a 5268 7350 6163 6b65 7420  aits::RhsPacket 
+00009e50: 5268 7350 6163 6b65 743b 0a20 2074 7970  RhsPacket;.  typ
+00009e60: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009e70: 6169 7473 3a3a 5265 7350 6163 6b65 7420  aits::ResPacket 
+00009e80: 5265 7350 6163 6b65 743b 0a20 2074 7970  ResPacket;.  typ
+00009e90: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009ea0: 6169 7473 3a3a 4163 6350 6163 6b65 7420  aits::AccPacket 
+00009eb0: 4163 6350 6163 6b65 743b 0a20 2074 7970  AccPacket;.  typ
+00009ec0: 6564 6566 2074 7970 656e 616d 6520 5472  edef typename Tr
+00009ed0: 6169 7473 3a3a 5268 7350 6163 6b65 7478  aits::RhsPacketx
+00009ee0: 3420 5268 7350 6163 6b65 7478 343b 0a0a  4 RhsPacketx4;..
+00009ef0: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
+00009f00: 6d65 2052 6873 5061 6e65 6c48 656c 7065  me RhsPanelHelpe
+00009f10: 723c 5268 7350 6163 6b65 742c 2052 6873  r<RhsPacket, Rhs
+00009f20: 5061 636b 6574 7834 2c20 3135 3e3a 3a74  Packetx4, 15>::t
+00009f30: 7970 6520 5268 7350 616e 656c 3135 3b0a  ype RhsPanel15;.
+00009f40: 0a20 2074 7970 6564 6566 2067 6562 705f  .  typedef gebp_
+00009f50: 7472 6169 7473 3c52 6873 5363 616c 6172  traits<RhsScalar
+00009f60: 2c4c 6873 5363 616c 6172 2c43 6f6e 6a75  ,LhsScalar,Conju
+00009f70: 6761 7465 5268 732c 436f 6e6a 7567 6174  gateRhs,Conjugat
+00009f80: 654c 6873 2c41 7263 6869 7465 6374 7572  eLhs,Architectur
+00009f90: 653a 3a54 6172 6765 743e 2053 7761 7070  e::Target> Swapp
+00009fa0: 6564 5472 6169 7473 3b0a 0a20 2074 7970  edTraits;..  typ
+00009fb0: 6564 6566 2074 7970 656e 616d 6520 5377  edef typename Sw
+00009fc0: 6170 7065 6454 7261 6974 733a 3a52 6573  appedTraits::Res
+00009fd0: 5363 616c 6172 2053 5265 7353 6361 6c61  Scalar SResScala
+00009fe0: 723b 0a20 2074 7970 6564 6566 2074 7970  r;.  typedef typ
+00009ff0: 656e 616d 6520 5377 6170 7065 6454 7261  ename SwappedTra
+0000a000: 6974 733a 3a4c 6873 5061 636b 6574 2053  its::LhsPacket S
+0000a010: 4c68 7350 6163 6b65 743b 0a20 2074 7970  LhsPacket;.  typ
+0000a020: 6564 6566 2074 7970 656e 616d 6520 5377  edef typename Sw
+0000a030: 6170 7065 6454 7261 6974 733a 3a52 6873  appedTraits::Rhs
+0000a040: 5061 636b 6574 2053 5268 7350 6163 6b65  Packet SRhsPacke
+0000a050: 743b 0a20 2074 7970 6564 6566 2074 7970  t;.  typedef typ
+0000a060: 656e 616d 6520 5377 6170 7065 6454 7261  ename SwappedTra
+0000a070: 6974 733a 3a52 6573 5061 636b 6574 2053  its::ResPacket S
+0000a080: 5265 7350 6163 6b65 743b 0a20 2074 7970  ResPacket;.  typ
+0000a090: 6564 6566 2074 7970 656e 616d 6520 5377  edef typename Sw
+0000a0a0: 6170 7065 6454 7261 6974 733a 3a41 6363  appedTraits::Acc
+0000a0b0: 5061 636b 6574 2053 4163 6350 6163 6b65  Packet SAccPacke
+0000a0c0: 743b 0a0a 2020 7479 7065 6465 6620 7479  t;..  typedef ty
+0000a0d0: 7065 6e61 6d65 2048 616c 6654 7261 6974  pename HalfTrait
+0000a0e0: 733a 3a4c 6873 5061 636b 6574 204c 6873  s::LhsPacket Lhs
+0000a0f0: 5061 636b 6574 4861 6c66 3b0a 2020 7479  PacketHalf;.  ty
+0000a100: 7065 6465 6620 7479 7065 6e61 6d65 2048  pedef typename H
+0000a110: 616c 6654 7261 6974 733a 3a52 6873 5061  alfTraits::RhsPa
+0000a120: 636b 6574 2052 6873 5061 636b 6574 4861  cket RhsPacketHa
+0000a130: 6c66 3b0a 2020 7479 7065 6465 6620 7479  lf;.  typedef ty
+0000a140: 7065 6e61 6d65 2048 616c 6654 7261 6974  pename HalfTrait
+0000a150: 733a 3a52 6573 5061 636b 6574 2052 6573  s::ResPacket Res
+0000a160: 5061 636b 6574 4861 6c66 3b0a 2020 7479  PacketHalf;.  ty
+0000a170: 7065 6465 6620 7479 7065 6e61 6d65 2048  pedef typename H
+0000a180: 616c 6654 7261 6974 733a 3a41 6363 5061  alfTraits::AccPa
+0000a190: 636b 6574 2041 6363 5061 636b 6574 4861  cket AccPacketHa
+0000a1a0: 6c66 3b0a 0a20 2074 7970 6564 6566 2074  lf;..  typedef t
+0000a1b0: 7970 656e 616d 6520 5175 6172 7465 7254  ypename QuarterT
+0000a1c0: 7261 6974 733a 3a4c 6873 5061 636b 6574  raits::LhsPacket
+0000a1d0: 204c 6873 5061 636b 6574 5175 6172 7465   LhsPacketQuarte
+0000a1e0: 723b 0a20 2074 7970 6564 6566 2074 7970  r;.  typedef typ
+0000a1f0: 656e 616d 6520 5175 6172 7465 7254 7261  ename QuarterTra
+0000a200: 6974 733a 3a52 6873 5061 636b 6574 2052  its::RhsPacket R
+0000a210: 6873 5061 636b 6574 5175 6172 7465 723b  hsPacketQuarter;
+0000a220: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
+0000a230: 616d 6520 5175 6172 7465 7254 7261 6974  ame QuarterTrait
+0000a240: 733a 3a52 6573 5061 636b 6574 2052 6573  s::ResPacket Res
+0000a250: 5061 636b 6574 5175 6172 7465 723b 0a20  PacketQuarter;. 
+0000a260: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
+0000a270: 6520 5175 6172 7465 7254 7261 6974 733a  e QuarterTraits:
+0000a280: 3a41 6363 5061 636b 6574 2041 6363 5061  :AccPacket AccPa
+0000a290: 636b 6574 5175 6172 7465 723b 0a0a 2020  cketQuarter;..  
+0000a2a0: 7479 7065 6465 6620 7479 7065 6e61 6d65  typedef typename
+0000a2b0: 2044 6174 614d 6170 7065 723a 3a4c 696e   DataMapper::Lin
+0000a2c0: 6561 724d 6170 7065 7220 4c69 6e65 6172  earMapper Linear
+0000a2d0: 4d61 7070 6572 3b0a 0a20 2065 6e75 6d20  Mapper;..  enum 
+0000a2e0: 7b0a 2020 2020 5665 6374 6f72 697a 6162  {.    Vectorizab
+0000a2f0: 6c65 2020 3d20 5472 6169 7473 3a3a 5665  le  = Traits::Ve
+0000a300: 6374 6f72 697a 6162 6c65 2c0a 2020 2020  ctorizable,.    
+0000a310: 4c68 7350 726f 6772 6573 7320 2020 3d20  LhsProgress   = 
+0000a320: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
+0000a330: 6573 732c 0a20 2020 204c 6873 5072 6f67  ess,.    LhsProg
+0000a340: 7265 7373 4861 6c66 2020 2020 2020 3d20  ressHalf      = 
+0000a350: 4861 6c66 5472 6169 7473 3a3a 4c68 7350  HalfTraits::LhsP
+0000a360: 726f 6772 6573 732c 0a20 2020 204c 6873  rogress,.    Lhs
+0000a370: 5072 6f67 7265 7373 5175 6172 7465 7220  ProgressQuarter 
+0000a380: 2020 3d20 5175 6172 7465 7254 7261 6974    = QuarterTrait
+0000a390: 733a 3a4c 6873 5072 6f67 7265 7373 2c0a  s::LhsProgress,.
+0000a3a0: 2020 2020 5268 7350 726f 6772 6573 7320      RhsProgress 
+0000a3b0: 2020 3d20 5472 6169 7473 3a3a 5268 7350    = Traits::RhsP
+0000a3c0: 726f 6772 6573 732c 0a20 2020 2052 6873  rogress,.    Rhs
+0000a3d0: 5072 6f67 7265 7373 4861 6c66 2020 2020  ProgressHalf    
+0000a3e0: 2020 3d20 4861 6c66 5472 6169 7473 3a3a    = HalfTraits::
+0000a3f0: 5268 7350 726f 6772 6573 732c 0a20 2020  RhsProgress,.   
+0000a400: 2052 6873 5072 6f67 7265 7373 5175 6172   RhsProgressQuar
+0000a410: 7465 7220 2020 3d20 5175 6172 7465 7254  ter   = QuarterT
+0000a420: 7261 6974 733a 3a52 6873 5072 6f67 7265  raits::RhsProgre
+0000a430: 7373 2c0a 2020 2020 5265 7350 6163 6b65  ss,.    ResPacke
+0000a440: 7453 697a 6520 3d20 5472 6169 7473 3a3a  tSize = Traits::
+0000a450: 5265 7350 6163 6b65 7453 697a 650a 2020  ResPacketSize.  
+0000a460: 7d3b 0a0a 2020 4549 4745 4e5f 444f 4e54  };..  EIGEN_DONT
+0000a470: 5f49 4e4c 494e 450a 2020 766f 6964 206f  _INLINE.  void o
+0000a480: 7065 7261 746f 7228 2928 636f 6e73 7420  perator()(const 
+0000a490: 4461 7461 4d61 7070 6572 2620 7265 732c  DataMapper& res,
+0000a4a0: 2063 6f6e 7374 204c 6873 5363 616c 6172   const LhsScalar
+0000a4b0: 2a20 626c 6f63 6b41 2c20 636f 6e73 7420  * blockA, const 
+0000a4c0: 5268 7353 6361 6c61 722a 2062 6c6f 636b  RhsScalar* block
+0000a4d0: 422c 0a20 2020 2020 2020 2020 2020 2020  B,.             
+0000a4e0: 2020 2020 2049 6e64 6578 2072 6f77 732c       Index rows,
+0000a4f0: 2049 6e64 6578 2064 6570 7468 2c20 496e   Index depth, In
+0000a500: 6465 7820 636f 6c73 2c20 5265 7353 6361  dex cols, ResSca
+0000a510: 6c61 7220 616c 7068 612c 0a20 2020 2020  lar alpha,.     
+0000a520: 2020 2020 2020 2020 2020 2020 2049 6e64               Ind
+0000a530: 6578 2073 7472 6964 6541 3d2d 312c 2049  ex strideA=-1, I
+0000a540: 6e64 6578 2073 7472 6964 6542 3d2d 312c  ndex strideB=-1,
+0000a550: 2049 6e64 6578 206f 6666 7365 7441 3d30   Index offsetA=0
+0000a560: 2c20 496e 6465 7820 6f66 6673 6574 423d  , Index offsetB=
+0000a570: 3029 3b0a 7d3b 0a0a 7465 6d70 6c61 7465  0);.};..template
+0000a580: 3c74 7970 656e 616d 6520 4c68 7353 6361  <typename LhsSca
+0000a590: 6c61 722c 2074 7970 656e 616d 6520 5268  lar, typename Rh
+0000a5a0: 7353 6361 6c61 722c 2074 7970 656e 616d  sScalar, typenam
+0000a5b0: 6520 496e 6465 782c 2074 7970 656e 616d  e Index, typenam
+0000a5c0: 6520 4461 7461 4d61 7070 6572 2c20 696e  e DataMapper, in
+0000a5d0: 7420 6d72 2c20 696e 7420 6e72 2c20 626f  t mr, int nr, bo
+0000a5e0: 6f6c 2043 6f6e 6a75 6761 7465 4c68 732c  ol ConjugateLhs,
+0000a5f0: 2062 6f6f 6c20 436f 6e6a 7567 6174 6552   bool ConjugateR
+0000a600: 6873 2c0a 696e 7420 5377 6170 7065 644c  hs,.int SwappedL
+0000a610: 6873 5072 6f67 7265 7373 203d 2067 6562  hsProgress = geb
+0000a620: 705f 7472 6169 7473 3c52 6873 5363 616c  p_traits<RhsScal
+0000a630: 6172 2c4c 6873 5363 616c 6172 2c43 6f6e  ar,LhsScalar,Con
+0000a640: 6a75 6761 7465 5268 732c 436f 6e6a 7567  jugateRhs,Conjug
+0000a650: 6174 654c 6873 2c41 7263 6869 7465 6374  ateLhs,Architect
+0000a660: 7572 653a 3a54 6172 6765 743e 3a3a 4c68  ure::Target>::Lh
+0000a670: 7350 726f 6772 6573 733e 0a73 7472 7563  sProgress>.struc
+0000a680: 7420 6c61 7374 5f72 6f77 5f70 726f 6365  t last_row_proce
+0000a690: 7373 5f31 365f 7061 636b 6574 730a 7b0a  ss_16_packets.{.
+0000a6a0: 2020 7479 7065 6465 6620 6765 6270 5f74    typedef gebp_t
+0000a6b0: 7261 6974 733c 4c68 7353 6361 6c61 722c  raits<LhsScalar,
+0000a6c0: 5268 7353 6361 6c61 722c 436f 6e6a 7567  RhsScalar,Conjug
+0000a6d0: 6174 654c 6873 2c43 6f6e 6a75 6761 7465  ateLhs,Conjugate
+0000a6e0: 5268 732c 4172 6368 6974 6563 7475 7265  Rhs,Architecture
+0000a6f0: 3a3a 5461 7267 6574 3e20 5472 6169 7473  ::Target> Traits
+0000a700: 3b0a 2020 7479 7065 6465 6620 6765 6270  ;.  typedef gebp
+0000a710: 5f74 7261 6974 733c 5268 7353 6361 6c61  _traits<RhsScala
+0000a720: 722c 4c68 7353 6361 6c61 722c 436f 6e6a  r,LhsScalar,Conj
+0000a730: 7567 6174 6552 6873 2c43 6f6e 6a75 6761  ugateRhs,Conjuga
+0000a740: 7465 4c68 732c 4172 6368 6974 6563 7475  teLhs,Architectu
+0000a750: 7265 3a3a 5461 7267 6574 3e20 5377 6170  re::Target> Swap
+0000a760: 7065 6454 7261 6974 733b 0a0a 2020 7479  pedTraits;..  ty
+0000a770: 7065 6465 6620 7479 7065 6e61 6d65 2054  pedef typename T
+0000a780: 7261 6974 733a 3a52 6573 5363 616c 6172  raits::ResScalar
+0000a790: 2052 6573 5363 616c 6172 3b0a 2020 7479   ResScalar;.  ty
+0000a7a0: 7065 6465 6620 7479 7065 6e61 6d65 2053  pedef typename S
+0000a7b0: 7761 7070 6564 5472 6169 7473 3a3a 4c68  wappedTraits::Lh
+0000a7c0: 7350 6163 6b65 7420 534c 6873 5061 636b  sPacket SLhsPack
+0000a7d0: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
+0000a7e0: 7065 6e61 6d65 2053 7761 7070 6564 5472  pename SwappedTr
+0000a7f0: 6169 7473 3a3a 5268 7350 6163 6b65 7420  aits::RhsPacket 
+0000a800: 5352 6873 5061 636b 6574 3b0a 2020 7479  SRhsPacket;.  ty
+0000a810: 7065 6465 6620 7479 7065 6e61 6d65 2053  pedef typename S
+0000a820: 7761 7070 6564 5472 6169 7473 3a3a 5265  wappedTraits::Re
+0000a830: 7350 6163 6b65 7420 5352 6573 5061 636b  sPacket SResPack
+0000a840: 6574 3b0a 2020 7479 7065 6465 6620 7479  et;.  typedef ty
+0000a850: 7065 6e61 6d65 2053 7761 7070 6564 5472  pename SwappedTr
+0000a860: 6169 7473 3a3a 4163 6350 6163 6b65 7420  aits::AccPacket 
+0000a870: 5341 6363 5061 636b 6574 3b0a 0a20 2045  SAccPacket;..  E
+0000a880: 4947 454e 5f53 5452 4f4e 475f 494e 4c49  IGEN_STRONG_INLI
+0000a890: 4e45 2076 6f69 6420 6f70 6572 6174 6f72  NE void operator
+0000a8a0: 2829 2863 6f6e 7374 2044 6174 614d 6170  ()(const DataMap
+0000a8b0: 7065 7226 2072 6573 2c20 5377 6170 7065  per& res, Swappe
+0000a8c0: 6454 7261 6974 7320 2673 7472 6169 7473  dTraits &straits
+0000a8d0: 2c20 636f 6e73 7420 4c68 7353 6361 6c61  , const LhsScala
+0000a8e0: 722a 2062 6c41 2c0a 2020 2020 2020 2020  r* blA,.        
+0000a8f0: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
+0000a900: 5268 7353 6361 6c61 722a 2062 6c42 2c20  RhsScalar* blB, 
+0000a910: 496e 6465 7820 6465 7074 682c 2063 6f6e  Index depth, con
+0000a920: 7374 2049 6e64 6578 2065 6e64 6b2c 2049  st Index endk, I
+0000a930: 6e64 6578 2069 2c20 496e 6465 7820 6a32  ndex i, Index j2
+0000a940: 2c0a 2020 2020 2020 2020 2020 2020 2020  ,.              
+0000a950: 2020 2020 5265 7353 6361 6c61 7220 616c      ResScalar al
+0000a960: 7068 612c 2053 4163 6350 6163 6b65 7420  pha, SAccPacket 
+0000a970: 2643 3029 0a20 2020 207b 0a20 2020 2020  &C0).    {.     
+0000a980: 2045 4947 454e 5f55 4e55 5345 445f 5641   EIGEN_UNUSED_VA
+0000a990: 5249 4142 4c45 2872 6573 293b 0a20 2020  RIABLE(res);.   
+0000a9a0: 2020 2045 4947 454e 5f55 4e55 5345 445f     EIGEN_UNUSED_
+0000a9b0: 5641 5249 4142 4c45 2873 7472 6169 7473  VARIABLE(straits
+0000a9c0: 293b 0a20 2020 2020 2045 4947 454e 5f55  );.      EIGEN_U
+0000a9d0: 4e55 5345 445f 5641 5249 4142 4c45 2862  NUSED_VARIABLE(b
+0000a9e0: 6c41 293b 0a20 2020 2020 2045 4947 454e  lA);.      EIGEN
+0000a9f0: 5f55 4e55 5345 445f 5641 5249 4142 4c45  _UNUSED_VARIABLE
+0000aa00: 2862 6c42 293b 0a20 2020 2020 2045 4947  (blB);.      EIG
+0000aa10: 454e 5f55 4e55 5345 445f 5641 5249 4142  EN_UNUSED_VARIAB
+0000aa20: 4c45 2864 6570 7468 293b 0a20 2020 2020  LE(depth);.     
+0000aa30: 2045 4947 454e 5f55 4e55 5345 445f 5641   EIGEN_UNUSED_VA
+0000aa40: 5249 4142 4c45 2865 6e64 6b29 3b0a 2020  RIABLE(endk);.  
+0000aa50: 2020 2020 4549 4745 4e5f 554e 5553 4544      EIGEN_UNUSED
+0000aa60: 5f56 4152 4941 424c 4528 6929 3b0a 2020  _VARIABLE(i);.  
+0000aa70: 2020 2020 4549 4745 4e5f 554e 5553 4544      EIGEN_UNUSED
+0000aa80: 5f56 4152 4941 424c 4528 6a32 293b 0a20  _VARIABLE(j2);. 
+0000aa90: 2020 2020 2045 4947 454e 5f55 4e55 5345       EIGEN_UNUSE
+0000aaa0: 445f 5641 5249 4142 4c45 2861 6c70 6861  D_VARIABLE(alpha
+0000aab0: 293b 0a20 2020 2020 2045 4947 454e 5f55  );.      EIGEN_U
+0000aac0: 4e55 5345 445f 5641 5249 4142 4c45 2843  NUSED_VARIABLE(C
+0000aad0: 3029 3b0a 2020 2020 7d0a 7d3b 0a0a 0a74  0);.    }.};...t
+0000aae0: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
+0000aaf0: 204c 6873 5363 616c 6172 2c20 7479 7065   LhsScalar, type
+0000ab00: 6e61 6d65 2052 6873 5363 616c 6172 2c20  name RhsScalar, 
+0000ab10: 7479 7065 6e61 6d65 2049 6e64 6578 2c20  typename Index, 
+0000ab20: 7479 7065 6e61 6d65 2044 6174 614d 6170  typename DataMap
+0000ab30: 7065 722c 2069 6e74 206d 722c 2069 6e74  per, int mr, int
+0000ab40: 206e 722c 2062 6f6f 6c20 436f 6e6a 7567   nr, bool Conjug
+0000ab50: 6174 654c 6873 2c20 626f 6f6c 2043 6f6e  ateLhs, bool Con
+0000ab60: 6a75 6761 7465 5268 733e 0a73 7472 7563  jugateRhs>.struc
+0000ab70: 7420 6c61 7374 5f72 6f77 5f70 726f 6365  t last_row_proce
+0000ab80: 7373 5f31 365f 7061 636b 6574 733c 4c68  ss_16_packets<Lh
+0000ab90: 7353 6361 6c61 722c 2052 6873 5363 616c  sScalar, RhsScal
+0000aba0: 6172 2c20 496e 6465 782c 2044 6174 614d  ar, Index, DataM
+0000abb0: 6170 7065 722c 2020 6d72 2c20 206e 722c  apper,  mr,  nr,
+0000abc0: 2043 6f6e 6a75 6761 7465 4c68 732c 2020   ConjugateLhs,  
+0000abd0: 436f 6e6a 7567 6174 6552 6873 2c20 3136  ConjugateRhs, 16
+0000abe0: 3e20 7b0a 2020 7479 7065 6465 6620 6765  > {.  typedef ge
+0000abf0: 6270 5f74 7261 6974 733c 4c68 7353 6361  bp_traits<LhsSca
+0000ac00: 6c61 722c 5268 7353 6361 6c61 722c 436f  lar,RhsScalar,Co
+0000ac10: 6e6a 7567 6174 654c 6873 2c43 6f6e 6a75  njugateLhs,Conju
+0000ac20: 6761 7465 5268 732c 4172 6368 6974 6563  gateRhs,Architec
+0000ac30: 7475 7265 3a3a 5461 7267 6574 3e20 5472  ture::Target> Tr
+0000ac40: 6169 7473 3b0a 2020 7479 7065 6465 6620  aits;.  typedef 
+0000ac50: 6765 6270 5f74 7261 6974 733c 5268 7353  gebp_traits<RhsS
+0000ac60: 6361 6c61 722c 4c68 7353 6361 6c61 722c  calar,LhsScalar,
+0000ac70: 436f 6e6a 7567 6174 6552 6873 2c43 6f6e  ConjugateRhs,Con
+0000ac80: 6a75 6761 7465 4c68 732c 4172 6368 6974  jugateLhs,Archit
+0000ac90: 6563 7475 7265 3a3a 5461 7267 6574 3e20  ecture::Target> 
+0000aca0: 5377 6170 7065 6454 7261 6974 733b 0a0a  SwappedTraits;..
+0000acb0: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
+0000acc0: 6d65 2054 7261 6974 733a 3a52 6573 5363  me Traits::ResSc
+0000acd0: 616c 6172 2052 6573 5363 616c 6172 3b0a  alar ResScalar;.
+0000ace0: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
+0000acf0: 6d65 2053 7761 7070 6564 5472 6169 7473  me SwappedTraits
+0000ad00: 3a3a 4c68 7350 6163 6b65 7420 534c 6873  ::LhsPacket SLhs
+0000ad10: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
+0000ad20: 6620 7479 7065 6e61 6d65 2053 7761 7070  f typename Swapp
+0000ad30: 6564 5472 6169 7473 3a3a 5268 7350 6163  edTraits::RhsPac
+0000ad40: 6b65 7420 5352 6873 5061 636b 6574 3b0a  ket SRhsPacket;.
+0000ad50: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
+0000ad60: 6d65 2053 7761 7070 6564 5472 6169 7473  me SwappedTraits
+0000ad70: 3a3a 5265 7350 6163 6b65 7420 5352 6573  ::ResPacket SRes
+0000ad80: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
+0000ad90: 6620 7479 7065 6e61 6d65 2053 7761 7070  f typename Swapp
+0000ada0: 6564 5472 6169 7473 3a3a 4163 6350 6163  edTraits::AccPac
+0000adb0: 6b65 7420 5341 6363 5061 636b 6574 3b0a  ket SAccPacket;.
+0000adc0: 0a20 2045 4947 454e 5f53 5452 4f4e 475f  .  EIGEN_STRONG_
+0000add0: 494e 4c49 4e45 2076 6f69 6420 6f70 6572  INLINE void oper
+0000ade0: 6174 6f72 2829 2863 6f6e 7374 2044 6174  ator()(const Dat
+0000adf0: 614d 6170 7065 7226 2072 6573 2c20 5377  aMapper& res, Sw
+0000ae00: 6170 7065 6454 7261 6974 7320 2673 7472  appedTraits &str
+0000ae10: 6169 7473 2c20 636f 6e73 7420 4c68 7353  aits, const LhsS
+0000ae20: 6361 6c61 722a 2062 6c41 2c0a 2020 2020  calar* blA,.    
+0000ae30: 2020 2020 2020 2020 2020 2020 2020 636f                co
+0000ae40: 6e73 7420 5268 7353 6361 6c61 722a 2062  nst RhsScalar* b
+0000ae50: 6c42 2c20 496e 6465 7820 6465 7074 682c  lB, Index depth,
+0000ae60: 2063 6f6e 7374 2049 6e64 6578 2065 6e64   const Index end
+0000ae70: 6b2c 2049 6e64 6578 2069 2c20 496e 6465  k, Index i, Inde
+0000ae80: 7820 6a32 2c0a 2020 2020 2020 2020 2020  x j2,.          
+0000ae90: 2020 2020 2020 2020 5265 7353 6361 6c61          ResScala
+0000aea0: 7220 616c 7068 612c 2053 4163 6350 6163  r alpha, SAccPac
+0000aeb0: 6b65 7420 2643 3029 0a20 207b 0a20 2020  ket &C0).  {.   
+0000aec0: 2074 7970 6564 6566 2074 7970 656e 616d   typedef typenam
+0000aed0: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
+0000aee0: 733c 7479 7065 6e61 6d65 2075 6e70 6163  s<typename unpac
+0000aef0: 6b65 745f 7472 6169 7473 3c53 5265 7350  ket_traits<SResP
+0000af00: 6163 6b65 743e 3a3a 6861 6c66 3e3a 3a68  acket>::half>::h
+0000af10: 616c 6620 5352 6573 5061 636b 6574 5175  alf SResPacketQu
+0000af20: 6172 7465 723b 0a20 2020 2074 7970 6564  arter;.    typed
+0000af30: 6566 2074 7970 656e 616d 6520 756e 7061  ef typename unpa
+0000af40: 636b 6574 5f74 7261 6974 733c 7479 7065  cket_traits<type
+0000af50: 6e61 6d65 2075 6e70 6163 6b65 745f 7472  name unpacket_tr
+0000af60: 6169 7473 3c53 4c68 7350 6163 6b65 743e  aits<SLhsPacket>
+0000af70: 3a3a 6861 6c66 3e3a 3a68 616c 6620 534c  ::half>::half SL
+0000af80: 6873 5061 636b 6574 5175 6172 7465 723b  hsPacketQuarter;
+0000af90: 0a20 2020 2074 7970 6564 6566 2074 7970  .    typedef typ
+0000afa0: 656e 616d 6520 756e 7061 636b 6574 5f74  ename unpacket_t
+0000afb0: 7261 6974 733c 7479 7065 6e61 6d65 2075  raits<typename u
+0000afc0: 6e70 6163 6b65 745f 7472 6169 7473 3c53  npacket_traits<S
+0000afd0: 5268 7350 6163 6b65 743e 3a3a 6861 6c66  RhsPacket>::half
+0000afe0: 3e3a 3a68 616c 6620 5352 6873 5061 636b  >::half SRhsPack
+0000aff0: 6574 5175 6172 7465 723b 0a20 2020 2074  etQuarter;.    t
+0000b000: 7970 6564 6566 2074 7970 656e 616d 6520  ypedef typename 
+0000b010: 756e 7061 636b 6574 5f74 7261 6974 733c  unpacket_traits<
+0000b020: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
+0000b030: 745f 7472 6169 7473 3c53 4163 6350 6163  t_traits<SAccPac
+0000b040: 6b65 743e 3a3a 6861 6c66 3e3a 3a68 616c  ket>::half>::hal
+0000b050: 6620 5341 6363 5061 636b 6574 5175 6172  f SAccPacketQuar
+0000b060: 7465 723b 0a0a 2020 2020 5352 6573 5061  ter;..    SResPa
+0000b070: 636b 6574 5175 6172 7465 7220 5220 3d20  cketQuarter R = 
+0000b080: 7265 732e 7465 6d70 6c61 7465 2067 6174  res.template gat
+0000b090: 6865 7250 6163 6b65 743c 5352 6573 5061  herPacket<SResPa
+0000b0a0: 636b 6574 5175 6172 7465 723e 2869 2c20  cketQuarter>(i, 
+0000b0b0: 6a32 293b 0a20 2020 2053 5265 7350 6163  j2);.    SResPac
+0000b0c0: 6b65 7451 7561 7274 6572 2061 6c70 6861  ketQuarter alpha
+0000b0d0: 7620 3d20 7073 6574 313c 5352 6573 5061  v = pset1<SResPa
+0000b0e0: 636b 6574 5175 6172 7465 723e 2861 6c70  cketQuarter>(alp
+0000b0f0: 6861 293b 0a0a 2020 2020 6966 2028 6465  ha);..    if (de
+0000b100: 7074 6820 2d20 656e 646b 203e 2030 290a  pth - endk > 0).
+0000b110: 2020 2020 2020 7b0a 092f 2f20 5765 2068        {..// We h
+0000b120: 6176 6520 746f 2068 616e 646c 6520 7468  ave to handle th
+0000b130: 6520 6c61 7374 2072 6f77 2873 2920 6f66  e last row(s) of
+0000b140: 2074 6865 2072 6873 2c20 7768 6963 680a   the rhs, which.
+0000b150: 092f 2f20 636f 7272 6573 706f 6e64 2074  .// correspond t
+0000b160: 6f20 6120 6861 6c66 2d70 6163 6b65 740a  o a half-packet.
+0000b170: 0953 4163 6350 6163 6b65 7451 7561 7274  .SAccPacketQuart
+0000b180: 6572 2063 3020 3d20 7072 6564 7578 5f68  er c0 = predux_h
+0000b190: 616c 665f 646f 7774 6f34 2870 7265 6475  alf_dowto4(predu
+0000b1a0: 785f 6861 6c66 5f64 6f77 746f 3428 4330  x_half_dowto4(C0
+0000b1b0: 2929 3b0a 0a09 666f 7220 2849 6e64 6578  ));...for (Index
+0000b1c0: 206b 6b20 3d20 656e 646b 3b20 6b6b 203c   kk = endk; kk <
+0000b1d0: 2064 6570 7468 3b20 6b6b 2b2b 290a 0920   depth; kk++).. 
+0000b1e0: 207b 0a09 2020 2020 534c 6873 5061 636b   {..    SLhsPack
+0000b1f0: 6574 5175 6172 7465 7220 6130 3b0a 0920  etQuarter a0;.. 
+0000b200: 2020 2053 5268 7350 6163 6b65 7451 7561     SRhsPacketQua
+0000b210: 7274 6572 2062 303b 0a09 2020 2020 7374  rter b0;..    st
+0000b220: 7261 6974 732e 6c6f 6164 4c68 7355 6e61  raits.loadLhsUna
+0000b230: 6c69 676e 6564 2862 6c42 2c20 6130 293b  ligned(blB, a0);
+0000b240: 0a09 2020 2020 7374 7261 6974 732e 6c6f  ..    straits.lo
+0000b250: 6164 5268 7328 626c 412c 2062 3029 3b0a  adRhs(blA, b0);.
+0000b260: 0920 2020 2073 7472 6169 7473 2e6d 6164  .    straits.mad
+0000b270: 6428 6130 2c62 302c 6330 2c62 302c 2066  d(a0,b0,c0,b0, f
+0000b280: 6978 3c30 3e29 3b0a 0920 2020 2062 6c42  ix<0>);..    blB
+0000b290: 202b 3d20 5377 6170 7065 6454 7261 6974   += SwappedTrait
+0000b2a0: 733a 3a4c 6873 5072 6f67 7265 7373 2f34  s::LhsProgress/4
+0000b2b0: 3b0a 0920 2020 2062 6c41 202b 3d20 313b  ;..    blA += 1;
+0000b2c0: 0a09 2020 7d0a 0973 7472 6169 7473 2e61  ..  }..straits.a
+0000b2d0: 6363 2863 302c 2061 6c70 6861 762c 2052  cc(c0, alphav, R
+0000b2e0: 293b 0a20 2020 2020 207d 0a20 2020 2065  );.      }.    e
+0000b2f0: 6c73 650a 2020 2020 2020 7b0a 0973 7472  lse.      {..str
+0000b300: 6169 7473 2e61 6363 2870 7265 6475 785f  aits.acc(predux_
+0000b310: 6861 6c66 5f64 6f77 746f 3428 7072 6564  half_dowto4(pred
+0000b320: 7578 5f68 616c 665f 646f 7774 6f34 2843  ux_half_dowto4(C
+0000b330: 3029 292c 2061 6c70 6861 762c 2052 293b  0)), alphav, R);
+0000b340: 0a20 2020 2020 207d 0a20 2020 2072 6573  .      }.    res
+0000b350: 2e73 6361 7474 6572 5061 636b 6574 2869  .scatterPacket(i
+0000b360: 2c20 6a32 2c20 5229 3b0a 2020 7d0a 7d3b  , j2, R);.  }.};
+0000b370: 0a0a 7465 6d70 6c61 7465 3c69 6e74 206e  ..template<int n
+0000b380: 722c 2049 6e64 6578 204c 6873 5072 6f67  r, Index LhsProg
+0000b390: 7265 7373 2c20 496e 6465 7820 5268 7350  ress, Index RhsP
+0000b3a0: 726f 6772 6573 732c 2074 7970 656e 616d  rogress, typenam
+0000b3b0: 6520 4c68 7353 6361 6c61 722c 2074 7970  e LhsScalar, typ
+0000b3c0: 656e 616d 6520 5268 7353 6361 6c61 722c  ename RhsScalar,
+0000b3d0: 2074 7970 656e 616d 6520 5265 7353 6361   typename ResSca
+0000b3e0: 6c61 722c 2074 7970 656e 616d 6520 4163  lar, typename Ac
+0000b3f0: 6350 6163 6b65 742c 2074 7970 656e 616d  cPacket, typenam
+0000b400: 6520 4c68 7350 6163 6b65 742c 2074 7970  e LhsPacket, typ
+0000b410: 656e 616d 6520 5268 7350 6163 6b65 742c  ename RhsPacket,
+0000b420: 2074 7970 656e 616d 6520 5265 7350 6163   typename ResPac
+0000b430: 6b65 742c 2074 7970 656e 616d 6520 4745  ket, typename GE
+0000b440: 4250 5472 6169 7473 2c20 7479 7065 6e61  BPTraits, typena
+0000b450: 6d65 204c 696e 6561 724d 6170 7065 722c  me LinearMapper,
+0000b460: 2074 7970 656e 616d 6520 4461 7461 4d61   typename DataMa
+0000b470: 7070 6572 3e0a 7374 7275 6374 206c 6873  pper>.struct lhs
+0000b480: 5f70 726f 6365 7373 5f6f 6e65 5f70 6163  _process_one_pac
+0000b490: 6b65 740a 7b0a 2020 7479 7065 6465 6620  ket.{.  typedef 
+0000b4a0: 7479 7065 6e61 6d65 2047 4542 5054 7261  typename GEBPTra
+0000b4b0: 6974 733a 3a52 6873 5061 636b 6574 7834  its::RhsPacketx4
+0000b4c0: 2052 6873 5061 636b 6574 7834 3b0a 0a20   RhsPacketx4;.. 
+0000b4d0: 2045 4947 454e 5f53 5452 4f4e 475f 494e   EIGEN_STRONG_IN
+0000b4e0: 4c49 4e45 2076 6f69 6420 7065 656c 6564  LINE void peeled
+0000b4f0: 5f6b 635f 6f6e 6573 7465 7028 496e 6465  _kc_onestep(Inde
+0000b500: 7820 4b2c 2063 6f6e 7374 204c 6873 5363  x K, const LhsSc
+0000b510: 616c 6172 2a20 626c 412c 2063 6f6e 7374  alar* blA, const
+0000b520: 2052 6873 5363 616c 6172 2a20 626c 422c   RhsScalar* blB,
+0000b530: 2047 4542 5054 7261 6974 7320 7472 6169   GEBPTraits trai
+0000b540: 7473 2c20 4c68 7350 6163 6b65 7420 2a41  ts, LhsPacket *A
+0000b550: 302c 2052 6873 5061 636b 6574 7834 202a  0, RhsPacketx4 *
+0000b560: 7268 735f 7061 6e65 6c2c 2052 6873 5061  rhs_panel, RhsPa
+0000b570: 636b 6574 202a 5430 2c20 4163 6350 6163  cket *T0, AccPac
+0000b580: 6b65 7420 2a43 302c 2041 6363 5061 636b  ket *C0, AccPack
+0000b590: 6574 202a 4331 2c20 4163 6350 6163 6b65  et *C1, AccPacke
+0000b5a0: 7420 2a43 322c 2041 6363 5061 636b 6574  t *C2, AccPacket
+0000b5b0: 202a 4333 290a 2020 7b0a 2020 2020 4549   *C3).  {.    EI
+0000b5c0: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
+0000b5d0: 2262 6567 696e 2073 7465 7020 6f66 2067  "begin step of g
+0000b5e0: 6562 7020 6d69 6372 6f20 6b65 726e 656c  ebp micro kernel
+0000b5f0: 2031 5834 2229 3b0a 2020 2020 4549 4745   1X4");.    EIGE
+0000b600: 4e5f 4153 4d5f 434f 4d4d 454e 5428 224e  N_ASM_COMMENT("N
+0000b610: 6f74 653a 2074 6865 7365 2061 736d 2063  ote: these asm c
+0000b620: 6f6d 6d65 6e74 7320 776f 726b 2061 726f  omments work aro
+0000b630: 756e 6420 6275 6720 3933 3521 2229 3b0a  und bug 935!");.
+0000b640: 2020 2020 7472 6169 7473 2e6c 6f61 644c      traits.loadL
+0000b650: 6873 2826 626c 415b 2830 2b31 2a4b 292a  hs(&blA[(0+1*K)*
+0000b660: 4c68 7350 726f 6772 6573 735d 2c20 2a41  LhsProgress], *A
+0000b670: 3029 3b0a 2020 2020 7472 6169 7473 2e6c  0);.    traits.l
+0000b680: 6f61 6452 6873 2826 626c 425b 2830 2b34  oadRhs(&blB[(0+4
+0000b690: 2a4b 292a 5268 7350 726f 6772 6573 735d  *K)*RhsProgress]
+0000b6a0: 2c20 2a72 6873 5f70 616e 656c 293b 0a20  , *rhs_panel);. 
+0000b6b0: 2020 2074 7261 6974 732e 6d61 6464 282a     traits.madd(*
+0000b6c0: 4130 2c20 2a72 6873 5f70 616e 656c 2c20  A0, *rhs_panel, 
+0000b6d0: 2a43 302c 202a 5430 2c20 6669 783c 303e  *C0, *T0, fix<0>
+0000b6e0: 293b 0a20 2020 2074 7261 6974 732e 6d61  );.    traits.ma
+0000b6f0: 6464 282a 4130 2c20 2a72 6873 5f70 616e  dd(*A0, *rhs_pan
+0000b700: 656c 2c20 2a43 312c 202a 5430 2c20 6669  el, *C1, *T0, fi
+0000b710: 783c 313e 293b 0a20 2020 2074 7261 6974  x<1>);.    trait
+0000b720: 732e 6d61 6464 282a 4130 2c20 2a72 6873  s.madd(*A0, *rhs
+0000b730: 5f70 616e 656c 2c20 2a43 322c 202a 5430  _panel, *C2, *T0
+0000b740: 2c20 6669 783c 323e 293b 0a20 2020 2074  , fix<2>);.    t
+0000b750: 7261 6974 732e 6d61 6464 282a 4130 2c20  raits.madd(*A0, 
+0000b760: 2a72 6873 5f70 616e 656c 2c20 2a43 332c  *rhs_panel, *C3,
+0000b770: 202a 5430 2c20 6669 783c 333e 293b 0a20   *T0, fix<3>);. 
+0000b780: 2020 2023 6966 2045 4947 454e 5f47 4e55     #if EIGEN_GNU
+0000b790: 435f 4154 5f4c 4541 5354 2836 2c30 2920  C_AT_LEAST(6,0) 
+0000b7a0: 2626 2064 6566 696e 6564 2845 4947 454e  && defined(EIGEN
+0000b7b0: 5f56 4543 544f 5249 5a45 5f53 5345 290a  _VECTORIZE_SSE).
+0000b7c0: 2020 2020 5f5f 6173 6d5f 5f20 2028 2222      __asm__  (""
+0000b7d0: 203a 2022 2b78 2c6d 2220 282a 4130 2929   : "+x,m" (*A0))
+0000b7e0: 3b0a 2020 2020 2365 6e64 6966 0a20 2020  ;.    #endif.   
+0000b7f0: 2045 4947 454e 5f41 534d 5f43 4f4d 4d45   EIGEN_ASM_COMME
+0000b800: 4e54 2822 656e 6420 7374 6570 206f 6620  NT("end step of 
+0000b810: 6765 6270 206d 6963 726f 206b 6572 6e65  gebp micro kerne
+0000b820: 6c20 3158 3422 293b 0a20 207d 0a0a 2020  l 1X4");.  }..  
+0000b830: 4549 4745 4e5f 5354 524f 4e47 5f49 4e4c  EIGEN_STRONG_INL
+0000b840: 494e 4520 766f 6964 206f 7065 7261 746f  INE void operato
+0000b850: 7228 2928 0a20 2020 2063 6f6e 7374 2044  r()(.    const D
+0000b860: 6174 614d 6170 7065 7226 2072 6573 2c20  ataMapper& res, 
+0000b870: 636f 6e73 7420 4c68 7353 6361 6c61 722a  const LhsScalar*
+0000b880: 2062 6c6f 636b 412c 2063 6f6e 7374 2052   blockA, const R
+0000b890: 6873 5363 616c 6172 2a20 626c 6f63 6b42  hsScalar* blockB
+0000b8a0: 2c20 5265 7353 6361 6c61 7220 616c 7068  , ResScalar alph
+0000b8b0: 612c 0a20 2020 2049 6e64 6578 2070 6565  a,.    Index pee
+0000b8c0: 6c53 7461 7274 2c20 496e 6465 7820 7065  lStart, Index pe
+0000b8d0: 656c 456e 642c 2049 6e64 6578 2073 7472  elEnd, Index str
+0000b8e0: 6964 6541 2c20 496e 6465 7820 7374 7269  ideA, Index stri
+0000b8f0: 6465 422c 2049 6e64 6578 206f 6666 7365  deB, Index offse
+0000b900: 7441 2c20 496e 6465 7820 6f66 6673 6574  tA, Index offset
+0000b910: 422c 0a20 2020 2069 6e74 2070 7265 6665  B,.    int prefe
+0000b920: 7463 685f 7265 735f 6f66 6673 6574 2c20  tch_res_offset, 
+0000b930: 496e 6465 7820 7065 656c 6564 5f6b 632c  Index peeled_kc,
+0000b940: 2049 6e64 6578 2070 6b2c 2049 6e64 6578   Index pk, Index
+0000b950: 2063 6f6c 732c 2049 6e64 6578 2064 6570   cols, Index dep
+0000b960: 7468 2c20 496e 6465 7820 7061 636b 6574  th, Index packet
+0000b970: 5f63 6f6c 7334 290a 2020 7b0a 2020 2020  _cols4).  {.    
+0000b980: 4745 4250 5472 6169 7473 2074 7261 6974  GEBPTraits trait
+0000b990: 733b 0a0a 2020 2020 2f2f 206c 6f6f 7073  s;..    // loops
+0000b9a0: 206f 6e20 6561 6368 206c 6172 6765 7374   on each largest
+0000b9b0: 206d 6963 726f 2068 6f72 697a 6f6e 7461   micro horizonta
+0000b9c0: 6c20 7061 6e65 6c20 6f66 206c 6873 0a20  l panel of lhs. 
+0000b9d0: 2020 202f 2f20 284c 6873 5072 6f67 7265     // (LhsProgre
+0000b9e0: 7373 2078 2064 6570 7468 290a 2020 2020  ss x depth).    
+0000b9f0: 666f 7228 496e 6465 7820 693d 7065 656c  for(Index i=peel
+0000ba00: 5374 6172 743b 2069 3c70 6565 6c45 6e64  Start; i<peelEnd
+0000ba10: 3b20 692b 3d4c 6873 5072 6f67 7265 7373  ; i+=LhsProgress
+0000ba20: 290a 2020 2020 7b0a 2020 2020 2020 2f2f  ).    {.      //
+0000ba30: 206c 6f6f 7073 206f 6e20 6561 6368 206c   loops on each l
+0000ba40: 6172 6765 7374 206d 6963 726f 2076 6572  argest micro ver
+0000ba50: 7469 6361 6c20 7061 6e65 6c20 6f66 2072  tical panel of r
+0000ba60: 6873 2028 6465 7074 6820 2a20 6e72 290a  hs (depth * nr).
+0000ba70: 2020 2020 2020 666f 7228 496e 6465 7820        for(Index 
+0000ba80: 6a32 3d30 3b20 6a32 3c70 6163 6b65 745f  j2=0; j2<packet_
+0000ba90: 636f 6c73 343b 206a 322b 3d6e 7229 0a20  cols4; j2+=nr). 
+0000baa0: 2020 2020 207b 0a20 2020 2020 2020 202f       {.        /
+0000bab0: 2f20 5765 2073 656c 6563 7420 6120 4c68  / We select a Lh
+0000bac0: 7350 726f 6772 6573 7320 7820 6e72 206d  sProgress x nr m
+0000bad0: 6963 726f 2062 6c6f 636b 206f 6620 7265  icro block of re
+0000bae0: 730a 2020 2020 2020 2020 2f2f 2077 6869  s.        // whi
+0000baf0: 6368 2069 7320 656e 7469 7265 6c79 2073  ch is entirely s
+0000bb00: 746f 7265 6420 696e 746f 2031 2078 206e  tored into 1 x n
+0000bb10: 7220 7265 6769 7374 6572 732e 0a0a 2020  r registers...  
+0000bb20: 2020 2020 2020 636f 6e73 7420 4c68 7353        const LhsS
+0000bb30: 6361 6c61 722a 2062 6c41 203d 2026 626c  calar* blA = &bl
+0000bb40: 6f63 6b41 5b69 2a73 7472 6964 6541 2b6f  ockA[i*strideA+o
+0000bb50: 6666 7365 7441 2a28 4c68 7350 726f 6772  ffsetA*(LhsProgr
+0000bb60: 6573 7329 5d3b 0a20 2020 2020 2020 2070  ess)];.        p
+0000bb70: 7265 6665 7463 6828 2662 6c41 5b30 5d29  refetch(&blA[0])
+0000bb80: 3b0a 0a20 2020 2020 2020 202f 2f20 6765  ;..        // ge
+0000bb90: 7473 2072 6573 2062 6c6f 636b 2061 7320  ts res block as 
+0000bba0: 7265 6769 7374 6572 0a20 2020 2020 2020  register.       
+0000bbb0: 2041 6363 5061 636b 6574 2043 302c 2043   AccPacket C0, C
+0000bbc0: 312c 2043 322c 2043 333b 0a20 2020 2020  1, C2, C3;.     
+0000bbd0: 2020 2074 7261 6974 732e 696e 6974 4163     traits.initAc
+0000bbe0: 6328 4330 293b 0a20 2020 2020 2020 2074  c(C0);.        t
+0000bbf0: 7261 6974 732e 696e 6974 4163 6328 4331  raits.initAcc(C1
+0000bc00: 293b 0a20 2020 2020 2020 2074 7261 6974  );.        trait
+0000bc10: 732e 696e 6974 4163 6328 4332 293b 0a20  s.initAcc(C2);. 
+0000bc20: 2020 2020 2020 2074 7261 6974 732e 696e         traits.in
+0000bc30: 6974 4163 6328 4333 293b 0a20 2020 2020  itAcc(C3);.     
+0000bc40: 2020 202f 2f20 546f 2069 6d70 726f 7665     // To improve
+0000bc50: 2069 6e73 7472 7563 7469 6f6e 2070 6970   instruction pip
+0000bc60: 656c 696e 696e 672c 206c 6574 2773 2064  elining, let's d
+0000bc70: 6f75 626c 6520 7468 6520 6163 6375 6d75  ouble the accumu
+0000bc80: 6c61 7469 6f6e 2072 6567 6973 7465 7273  lation registers
+0000bc90: 3a0a 2020 2020 2020 2020 2f2f 2020 6576  :.        //  ev
+0000bca0: 656e 206b 2077 696c 6c20 6163 6375 6d75  en k will accumu
+0000bcb0: 6c61 7465 2069 6e20 432a 2c20 7768 696c  late in C*, whil
+0000bcc0: 6520 6f64 6420 6b20 7769 6c6c 2061 6363  e odd k will acc
+0000bcd0: 756d 756c 6174 6520 696e 2044 2a2e 0a20  umulate in D*.. 
+0000bce0: 2020 2020 2020 202f 2f20 5468 6973 2074         // This t
+0000bcf0: 7269 636b 2069 7320 6372 7574 6961 6c20  rick is crutial 
+0000bd00: 746f 2067 6574 2067 6f6f 6420 7065 7266  to get good perf
+0000bd10: 6f72 6d61 6e63 6520 7769 7468 2046 4d41  ormance with FMA
+0000bd20: 2c20 6f74 6865 7277 6973 6520 6974 2069  , otherwise it i
+0000bd30: 7320 0a20 2020 2020 2020 202f 2f20 6163  s .        // ac
+0000bd40: 7475 616c 6c79 2066 6173 7465 7220 746f  tually faster to
+0000bd50: 2070 6572 666f 726d 2073 6570 6172 6174   perform separat
+0000bd60: 6564 204d 554c 2b41 4444 2062 6563 6175  ed MUL+ADD becau
+0000bd70: 7365 206f 6620 6120 6e61 7475 7261 6c6c  se of a naturall
+0000bd80: 790a 2020 2020 2020 2020 2f2f 2062 6574  y.        // bet
+0000bd90: 7465 7220 696e 7374 7275 6374 696f 6e2d  ter instruction-
+0000bda0: 6c65 7665 6c20 7061 7261 6c6c 656c 6973  level parallelis
+0000bdb0: 6d2e 0a20 2020 2020 2020 2041 6363 5061  m..        AccPa
+0000bdc0: 636b 6574 2044 302c 2044 312c 2044 322c  cket D0, D1, D2,
+0000bdd0: 2044 333b 0a20 2020 2020 2020 2074 7261   D3;.        tra
+0000bde0: 6974 732e 696e 6974 4163 6328 4430 293b  its.initAcc(D0);
+0000bdf0: 0a20 2020 2020 2020 2074 7261 6974 732e  .        traits.
+0000be00: 696e 6974 4163 6328 4431 293b 0a20 2020  initAcc(D1);.   
+0000be10: 2020 2020 2074 7261 6974 732e 696e 6974       traits.init
+0000be20: 4163 6328 4432 293b 0a20 2020 2020 2020  Acc(D2);.       
+0000be30: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
+0000be40: 4433 293b 0a0a 2020 2020 2020 2020 4c69  D3);..        Li
+0000be50: 6e65 6172 4d61 7070 6572 2072 3020 3d20  nearMapper r0 = 
+0000be60: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
+0000be70: 7065 7228 692c 206a 3220 2b20 3029 3b0a  per(i, j2 + 0);.
+0000be80: 2020 2020 2020 2020 4c69 6e65 6172 4d61          LinearMa
+0000be90: 7070 6572 2072 3120 3d20 7265 732e 6765  pper r1 = res.ge
+0000bea0: 744c 696e 6561 724d 6170 7065 7228 692c  tLinearMapper(i,
+0000beb0: 206a 3220 2b20 3129 3b0a 2020 2020 2020   j2 + 1);.      
+0000bec0: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
+0000bed0: 3220 3d20 7265 732e 6765 744c 696e 6561  2 = res.getLinea
+0000bee0: 724d 6170 7065 7228 692c 206a 3220 2b20  rMapper(i, j2 + 
+0000bef0: 3229 3b0a 2020 2020 2020 2020 4c69 6e65  2);.        Line
+0000bf00: 6172 4d61 7070 6572 2072 3320 3d20 7265  arMapper r3 = re
+0000bf10: 732e 6765 744c 696e 6561 724d 6170 7065  s.getLinearMappe
+0000bf20: 7228 692c 206a 3220 2b20 3329 3b0a 0a20  r(i, j2 + 3);.. 
+0000bf30: 2020 2020 2020 2072 302e 7072 6566 6574         r0.prefet
+0000bf40: 6368 2870 7265 6665 7463 685f 7265 735f  ch(prefetch_res_
+0000bf50: 6f66 6673 6574 293b 0a20 2020 2020 2020  offset);.       
+0000bf60: 2072 312e 7072 6566 6574 6368 2870 7265   r1.prefetch(pre
+0000bf70: 6665 7463 685f 7265 735f 6f66 6673 6574  fetch_res_offset
+0000bf80: 293b 0a20 2020 2020 2020 2072 322e 7072  );.        r2.pr
+0000bf90: 6566 6574 6368 2870 7265 6665 7463 685f  efetch(prefetch_
+0000bfa0: 7265 735f 6f66 6673 6574 293b 0a20 2020  res_offset);.   
+0000bfb0: 2020 2020 2072 332e 7072 6566 6574 6368       r3.prefetch
+0000bfc0: 2870 7265 6665 7463 685f 7265 735f 6f66  (prefetch_res_of
+0000bfd0: 6673 6574 293b 0a0a 2020 2020 2020 2020  fset);..        
+0000bfe0: 2f2f 2070 6572 666f 726d 7320 2269 6e6e  // performs "inn
+0000bff0: 6572 2220 7072 6f64 7563 7473 0a20 2020  er" products.   
+0000c000: 2020 2020 2063 6f6e 7374 2052 6873 5363       const RhsSc
+0000c010: 616c 6172 2a20 626c 4220 3d20 2662 6c6f  alar* blB = &blo
+0000c020: 636b 425b 6a32 2a73 7472 6964 6542 2b6f  ckB[j2*strideB+o
+0000c030: 6666 7365 7442 2a6e 725d 3b0a 2020 2020  ffsetB*nr];.    
+0000c040: 2020 2020 7072 6566 6574 6368 2826 626c      prefetch(&bl
+0000c050: 425b 305d 293b 0a20 2020 2020 2020 204c  B[0]);.        L
+0000c060: 6873 5061 636b 6574 2041 302c 2041 313b  hsPacket A0, A1;
+0000c070: 0a0a 2020 2020 2020 2020 666f 7228 496e  ..        for(In
+0000c080: 6465 7820 6b3d 303b 206b 3c70 6565 6c65  dex k=0; k<peele
+0000c090: 645f 6b63 3b20 6b2b 3d70 6b29 0a20 2020  d_kc; k+=pk).   
+0000c0a0: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
+0000c0b0: 2045 4947 454e 5f41 534d 5f43 4f4d 4d45   EIGEN_ASM_COMME
+0000c0c0: 4e54 2822 6265 6769 6e20 6765 6270 206d  NT("begin gebp m
+0000c0d0: 6963 726f 206b 6572 6e65 6c20 312f 6861  icro kernel 1/ha
+0000c0e0: 6c66 2f71 7561 7274 6572 5834 2229 3b0a  lf/quarterX4");.
+0000c0f0: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
+0000c100: 6b65 7478 3420 7268 735f 7061 6e65 6c3b  ketx4 rhs_panel;
+0000c110: 0a20 2020 2020 2020 2020 2052 6873 5061  .          RhsPa
+0000c120: 636b 6574 2054 303b 0a0a 2020 2020 2020  cket T0;..      
+0000c130: 2020 2020 696e 7465 726e 616c 3a3a 7072      internal::pr
+0000c140: 6566 6574 6368 2862 6c42 2b28 3438 2b30  efetch(blB+(48+0
+0000c150: 2929 3b0a 2020 2020 2020 2020 2020 7065  ));.          pe
+0000c160: 656c 6564 5f6b 635f 6f6e 6573 7465 7028  eled_kc_onestep(
+0000c170: 302c 2062 6c41 2c20 626c 422c 2074 7261  0, blA, blB, tra
+0000c180: 6974 732c 2026 4130 2c20 2672 6873 5f70  its, &A0, &rhs_p
+0000c190: 616e 656c 2c20 2654 302c 2026 4330 2c20  anel, &T0, &C0, 
+0000c1a0: 2643 312c 2026 4332 2c20 2643 3329 3b0a  &C1, &C2, &C3);.
+0000c1b0: 2020 2020 2020 2020 2020 7065 656c 6564            peeled
+0000c1c0: 5f6b 635f 6f6e 6573 7465 7028 312c 2062  _kc_onestep(1, b
+0000c1d0: 6c41 2c20 626c 422c 2074 7261 6974 732c  lA, blB, traits,
+0000c1e0: 2026 4131 2c20 2672 6873 5f70 616e 656c   &A1, &rhs_panel
+0000c1f0: 2c20 2654 302c 2026 4430 2c20 2644 312c  , &T0, &D0, &D1,
+0000c200: 2026 4432 2c20 2644 3329 3b0a 2020 2020   &D2, &D3);.    
+0000c210: 2020 2020 2020 7065 656c 6564 5f6b 635f        peeled_kc_
+0000c220: 6f6e 6573 7465 7028 322c 2062 6c41 2c20  onestep(2, blA, 
+0000c230: 626c 422c 2074 7261 6974 732c 2026 4130  blB, traits, &A0
+0000c240: 2c20 2672 6873 5f70 616e 656c 2c20 2654  , &rhs_panel, &T
+0000c250: 302c 2026 4330 2c20 2643 312c 2026 4332  0, &C0, &C1, &C2
+0000c260: 2c20 2643 3329 3b0a 2020 2020 2020 2020  , &C3);.        
+0000c270: 2020 7065 656c 6564 5f6b 635f 6f6e 6573    peeled_kc_ones
+0000c280: 7465 7028 332c 2062 6c41 2c20 626c 422c  tep(3, blA, blB,
+0000c290: 2074 7261 6974 732c 2026 4131 2c20 2672   traits, &A1, &r
+0000c2a0: 6873 5f70 616e 656c 2c20 2654 302c 2026  hs_panel, &T0, &
+0000c2b0: 4430 2c20 2644 312c 2026 4432 2c20 2644  D0, &D1, &D2, &D
+0000c2c0: 3329 3b0a 2020 2020 2020 2020 2020 696e  3);.          in
+0000c2d0: 7465 726e 616c 3a3a 7072 6566 6574 6368  ternal::prefetch
+0000c2e0: 2862 6c42 2b28 3438 2b31 3629 293b 0a20  (blB+(48+16));. 
+0000c2f0: 2020 2020 2020 2020 2070 6565 6c65 645f           peeled_
+0000c300: 6b63 5f6f 6e65 7374 6570 2834 2c20 626c  kc_onestep(4, bl
+0000c310: 412c 2062 6c42 2c20 7472 6169 7473 2c20  A, blB, traits, 
+0000c320: 2641 302c 2026 7268 735f 7061 6e65 6c2c  &A0, &rhs_panel,
+0000c330: 2026 5430 2c20 2643 302c 2026 4331 2c20   &T0, &C0, &C1, 
+0000c340: 2643 322c 2026 4333 293b 0a20 2020 2020  &C2, &C3);.     
+0000c350: 2020 2020 2070 6565 6c65 645f 6b63 5f6f       peeled_kc_o
+0000c360: 6e65 7374 6570 2835 2c20 626c 412c 2062  nestep(5, blA, b
+0000c370: 6c42 2c20 7472 6169 7473 2c20 2641 312c  lB, traits, &A1,
+0000c380: 2026 7268 735f 7061 6e65 6c2c 2026 5430   &rhs_panel, &T0
+0000c390: 2c20 2644 302c 2026 4431 2c20 2644 322c  , &D0, &D1, &D2,
+0000c3a0: 2026 4433 293b 0a20 2020 2020 2020 2020   &D3);.         
+0000c3b0: 2070 6565 6c65 645f 6b63 5f6f 6e65 7374   peeled_kc_onest
+0000c3c0: 6570 2836 2c20 626c 412c 2062 6c42 2c20  ep(6, blA, blB, 
+0000c3d0: 7472 6169 7473 2c20 2641 302c 2026 7268  traits, &A0, &rh
+0000c3e0: 735f 7061 6e65 6c2c 2026 5430 2c20 2643  s_panel, &T0, &C
+0000c3f0: 302c 2026 4331 2c20 2643 322c 2026 4333  0, &C1, &C2, &C3
+0000c400: 293b 0a20 2020 2020 2020 2020 2070 6565  );.          pee
+0000c410: 6c65 645f 6b63 5f6f 6e65 7374 6570 2837  led_kc_onestep(7
+0000c420: 2c20 626c 412c 2062 6c42 2c20 7472 6169  , blA, blB, trai
+0000c430: 7473 2c20 2641 312c 2026 7268 735f 7061  ts, &A1, &rhs_pa
+0000c440: 6e65 6c2c 2026 5430 2c20 2644 302c 2026  nel, &T0, &D0, &
+0000c450: 4431 2c20 2644 322c 2026 4433 293b 0a0a  D1, &D2, &D3);..
+0000c460: 2020 2020 2020 2020 2020 626c 4220 2b3d            blB +=
+0000c470: 2070 6b2a 342a 5268 7350 726f 6772 6573   pk*4*RhsProgres
+0000c480: 733b 0a20 2020 2020 2020 2020 2062 6c41  s;.          blA
+0000c490: 202b 3d20 706b 2a4c 6873 5072 6f67 7265   += pk*LhsProgre
+0000c4a0: 7373 3b0a 0a20 2020 2020 2020 2020 2045  ss;..          E
+0000c4b0: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
+0000c4c0: 2822 656e 6420 6765 6270 206d 6963 726f  ("end gebp micro
+0000c4d0: 206b 6572 6e65 6c20 312f 6861 6c66 2f71   kernel 1/half/q
+0000c4e0: 7561 7274 6572 5834 2229 3b0a 2020 2020  uarterX4");.    
+0000c4f0: 2020 2020 7d0a 2020 2020 2020 2020 4330      }.        C0
+0000c500: 203d 2070 6164 6428 4330 2c44 3029 3b0a   = padd(C0,D0);.
+0000c510: 2020 2020 2020 2020 4331 203d 2070 6164          C1 = pad
+0000c520: 6428 4331 2c44 3129 3b0a 2020 2020 2020  d(C1,D1);.      
+0000c530: 2020 4332 203d 2070 6164 6428 4332 2c44    C2 = padd(C2,D
+0000c540: 3229 3b0a 2020 2020 2020 2020 4333 203d  2);.        C3 =
+0000c550: 2070 6164 6428 4333 2c44 3329 3b0a 0a20   padd(C3,D3);.. 
+0000c560: 2020 2020 2020 202f 2f20 7072 6f63 6573         // proces
+0000c570: 7320 7265 6d61 696e 696e 6720 7065 656c  s remaining peel
+0000c580: 6564 206c 6f6f 700a 2020 2020 2020 2020  ed loop.        
+0000c590: 666f 7228 496e 6465 7820 6b3d 7065 656c  for(Index k=peel
+0000c5a0: 6564 5f6b 633b 206b 3c64 6570 7468 3b20  ed_kc; k<depth; 
+0000c5b0: 6b2b 2b29 0a20 2020 2020 2020 207b 0a20  k++).        {. 
+0000c5c0: 2020 2020 2020 2020 2052 6873 5061 636b           RhsPack
+0000c5d0: 6574 7834 2072 6873 5f70 616e 656c 3b0a  etx4 rhs_panel;.
+0000c5e0: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
+0000c5f0: 6b65 7420 5430 3b0a 2020 2020 2020 2020  ket T0;.        
+0000c600: 2020 7065 656c 6564 5f6b 635f 6f6e 6573    peeled_kc_ones
+0000c610: 7465 7028 302c 2062 6c41 2c20 626c 422c  tep(0, blA, blB,
+0000c620: 2074 7261 6974 732c 2026 4130 2c20 2672   traits, &A0, &r
+0000c630: 6873 5f70 616e 656c 2c20 2654 302c 2026  hs_panel, &T0, &
+0000c640: 4330 2c20 2643 312c 2026 4332 2c20 2643  C0, &C1, &C2, &C
+0000c650: 3329 3b0a 2020 2020 2020 2020 2020 626c  3);.          bl
+0000c660: 4220 2b3d 2034 2a52 6873 5072 6f67 7265  B += 4*RhsProgre
+0000c670: 7373 3b0a 2020 2020 2020 2020 2020 626c  ss;.          bl
+0000c680: 4120 2b3d 204c 6873 5072 6f67 7265 7373  A += LhsProgress
+0000c690: 3b0a 2020 2020 2020 2020 7d0a 0a20 2020  ;.        }..   
+0000c6a0: 2020 2020 2052 6573 5061 636b 6574 2052       ResPacket R
+0000c6b0: 302c 2052 313b 0a20 2020 2020 2020 2052  0, R1;.        R
+0000c6c0: 6573 5061 636b 6574 2061 6c70 6861 7620  esPacket alphav 
+0000c6d0: 3d20 7073 6574 313c 5265 7350 6163 6b65  = pset1<ResPacke
+0000c6e0: 743e 2861 6c70 6861 293b 0a0a 2020 2020  t>(alpha);..    
+0000c6f0: 2020 2020 5230 203d 2072 302e 7465 6d70      R0 = r0.temp
+0000c700: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
+0000c710: 5265 7350 6163 6b65 743e 2830 293b 0a20  ResPacket>(0);. 
+0000c720: 2020 2020 2020 2052 3120 3d20 7231 2e74         R1 = r1.t
+0000c730: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+0000c740: 6574 3c52 6573 5061 636b 6574 3e28 3029  et<ResPacket>(0)
+0000c750: 3b0a 2020 2020 2020 2020 7472 6169 7473  ;.        traits
+0000c760: 2e61 6363 2843 302c 2061 6c70 6861 762c  .acc(C0, alphav,
+0000c770: 2052 3029 3b0a 2020 2020 2020 2020 7472   R0);.        tr
+0000c780: 6169 7473 2e61 6363 2843 312c 2020 616c  aits.acc(C1,  al
+0000c790: 7068 6176 2c20 5231 293b 0a20 2020 2020  phav, R1);.     
+0000c7a0: 2020 2072 302e 7374 6f72 6550 6163 6b65     r0.storePacke
+0000c7b0: 7428 302c 2052 3029 3b0a 2020 2020 2020  t(0, R0);.      
+0000c7c0: 2020 7231 2e73 746f 7265 5061 636b 6574    r1.storePacket
+0000c7d0: 2830 2c20 5231 293b 0a0a 2020 2020 2020  (0, R1);..      
+0000c7e0: 2020 5230 203d 2072 322e 7465 6d70 6c61    R0 = r2.templa
+0000c7f0: 7465 206c 6f61 6450 6163 6b65 743c 5265  te loadPacket<Re
+0000c800: 7350 6163 6b65 743e 2830 293b 0a20 2020  sPacket>(0);.   
+0000c810: 2020 2020 2052 3120 3d20 7233 2e74 656d       R1 = r3.tem
+0000c820: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
+0000c830: 3c52 6573 5061 636b 6574 3e28 3029 3b0a  <ResPacket>(0);.
+0000c840: 2020 2020 2020 2020 7472 6169 7473 2e61          traits.a
+0000c850: 6363 2843 322c 2020 616c 7068 6176 2c20  cc(C2,  alphav, 
+0000c860: 5230 293b 0a20 2020 2020 2020 2074 7261  R0);.        tra
+0000c870: 6974 732e 6163 6328 4333 2c20 2061 6c70  its.acc(C3,  alp
+0000c880: 6861 762c 2052 3129 3b0a 2020 2020 2020  hav, R1);.      
+0000c890: 2020 7232 2e73 746f 7265 5061 636b 6574    r2.storePacket
+0000c8a0: 2830 2c20 5230 293b 0a20 2020 2020 2020  (0, R0);.       
+0000c8b0: 2072 332e 7374 6f72 6550 6163 6b65 7428   r3.storePacket(
+0000c8c0: 302c 2052 3129 3b0a 2020 2020 2020 7d0a  0, R1);.      }.
+0000c8d0: 0a20 2020 2020 202f 2f20 4465 616c 2077  .      // Deal w
+0000c8e0: 6974 6820 7265 6d61 696e 696e 6720 636f  ith remaining co
+0000c8f0: 6c75 6d6e 7320 6f66 2074 6865 2072 6873  lumns of the rhs
+0000c900: 0a20 2020 2020 2066 6f72 2849 6e64 6578  .      for(Index
+0000c910: 206a 323d 7061 636b 6574 5f63 6f6c 7334   j2=packet_cols4
+0000c920: 3b20 6a32 3c63 6f6c 733b 206a 322b 2b29  ; j2<cols; j2++)
+0000c930: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
+0000c940: 202f 2f20 4f6e 6520 636f 6c75 6d6e 2061   // One column a
+0000c950: 7420 6120 7469 6d65 0a20 2020 2020 2020  t a time.       
+0000c960: 2063 6f6e 7374 204c 6873 5363 616c 6172   const LhsScalar
+0000c970: 2a20 626c 4120 3d20 2662 6c6f 636b 415b  * blA = &blockA[
+0000c980: 692a 7374 7269 6465 412b 6f66 6673 6574  i*strideA+offset
+0000c990: 412a 284c 6873 5072 6f67 7265 7373 295d  A*(LhsProgress)]
+0000c9a0: 3b0a 2020 2020 2020 2020 7072 6566 6574  ;.        prefet
+0000c9b0: 6368 2826 626c 415b 305d 293b 0a0a 2020  ch(&blA[0]);..  
+0000c9c0: 2020 2020 2020 2f2f 2067 6574 7320 7265        // gets re
+0000c9d0: 7320 626c 6f63 6b20 6173 2072 6567 6973  s block as regis
+0000c9e0: 7465 720a 2020 2020 2020 2020 4163 6350  ter.        AccP
+0000c9f0: 6163 6b65 7420 4330 3b0a 2020 2020 2020  acket C0;.      
+0000ca00: 2020 7472 6169 7473 2e69 6e69 7441 6363    traits.initAcc
+0000ca10: 2843 3029 3b0a 0a20 2020 2020 2020 204c  (C0);..        L
+0000ca20: 696e 6561 724d 6170 7065 7220 7230 203d  inearMapper r0 =
+0000ca30: 2072 6573 2e67 6574 4c69 6e65 6172 4d61   res.getLinearMa
+0000ca40: 7070 6572 2869 2c20 6a32 293b 0a0a 2020  pper(i, j2);..  
+0000ca50: 2020 2020 2020 2f2f 2070 6572 666f 726d        // perform
+0000ca60: 7320 2269 6e6e 6572 2220 7072 6f64 7563  s "inner" produc
+0000ca70: 7473 0a20 2020 2020 2020 2063 6f6e 7374  ts.        const
+0000ca80: 2052 6873 5363 616c 6172 2a20 626c 4220   RhsScalar* blB 
+0000ca90: 3d20 2662 6c6f 636b 425b 6a32 2a73 7472  = &blockB[j2*str
+0000caa0: 6964 6542 2b6f 6666 7365 7442 5d3b 0a20  ideB+offsetB];. 
+0000cab0: 2020 2020 2020 204c 6873 5061 636b 6574         LhsPacket
+0000cac0: 2041 303b 0a0a 2020 2020 2020 2020 666f   A0;..        fo
+0000cad0: 7228 496e 6465 7820 6b3d 2030 3b20 6b3c  r(Index k= 0; k<
+0000cae0: 7065 656c 6564 5f6b 633b 206b 2b3d 706b  peeled_kc; k+=pk
+0000caf0: 290a 2020 2020 2020 2020 7b0a 2020 2020  ).        {.    
+0000cb00: 2020 2020 2020 4549 4745 4e5f 4153 4d5f        EIGEN_ASM_
+0000cb10: 434f 4d4d 454e 5428 2262 6567 696e 2067  COMMENT("begin g
+0000cb20: 6562 7020 6d69 6372 6f20 6b65 726e 656c  ebp micro kernel
+0000cb30: 2031 2f68 616c 662f 7175 6172 7465 7258   1/half/quarterX
+0000cb40: 3122 293b 0a20 2020 2020 2020 2020 2052  1");.          R
+0000cb50: 6873 5061 636b 6574 2042 5f30 3b0a 0a23  hsPacket B_0;..#
+0000cb60: 6465 6669 6e65 2045 4947 454e 5f47 4542  define EIGEN_GEB
+0000cb70: 4750 5f4f 4e45 5354 4550 284b 2920 2020  GP_ONESTEP(K)   
+0000cb80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cb90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cba0: 2020 2020 2020 205c 0a09 2020 2020 2020         \..      
+0000cbb0: 646f 207b 2020 2020 2020 2020 2020 2020  do {            
+0000cbc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cbd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000cbe0: 2020 2020 2020 2020 2020 5c0a 0909 4549            \...EI
+0000cbf0: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
+0000cc00: 2262 6567 696e 2073 7465 7020 6f66 2067  "begin step of g
+0000cc10: 6562 7020 6d69 6372 6f20 6b65 726e 656c  ebp micro kernel
+0000cc20: 2031 2f68 616c 662f 7175 6172 7465 7258   1/half/quarterX
+0000cc30: 3122 293b 205c 0a09 0945 4947 454e 5f41  1"); \...EIGEN_A
+0000cc40: 534d 5f43 4f4d 4d45 4e54 2822 4e6f 7465  SM_COMMENT("Note
+0000cc50: 3a20 7468 6573 6520 6173 6d20 636f 6d6d  : these asm comm
+0000cc60: 656e 7473 2077 6f72 6b20 6172 6f75 6e64  ents work around
+0000cc70: 2062 7567 2039 3335 2122 293b 205c 0a20   bug 935!"); \. 
+0000cc80: 2020 202f 2a20 4649 584d 453a 2077 6879     /* FIXME: why
+0000cc90: 2075 6e61 6c69 676e 6564 3f3f 3f3f 202a   unaligned???? *
+0000cca0: 2f20 5c0a 0909 7472 6169 7473 2e6c 6f61  / \...traits.loa
+0000ccb0: 644c 6873 556e 616c 6967 6e65 6428 2662  dLhsUnaligned(&b
+0000ccc0: 6c41 5b28 302b 312a 4b29 2a4c 6873 5072  lA[(0+1*K)*LhsPr
+0000ccd0: 6f67 7265 7373 5d2c 2041 3029 3b20 5c0a  ogress], A0); \.
+0000cce0: 0909 7472 6169 7473 2e6c 6f61 6452 6873  ..traits.loadRhs
+0000ccf0: 2826 626c 425b 2830 2b4b 292a 5268 7350  (&blB[(0+K)*RhsP
+0000cd00: 726f 6772 6573 735d 2c20 425f 3029 3b09  rogress], B_0);.
+0000cd10: 095c 0a09 0974 7261 6974 732e 6d61 6464  .\...traits.madd
+0000cd20: 2841 302c 2042 5f30 2c20 4330 2c20 425f  (A0, B_0, C0, B_
+0000cd30: 302c 2066 6978 3c30 3e29 3b09 0909 095c  0, fix<0>);....\
+0000cd40: 0a09 0945 4947 454e 5f41 534d 5f43 4f4d  ...EIGEN_ASM_COM
+0000cd50: 4d45 4e54 2822 656e 6420 7374 6570 206f  MENT("end step o
+0000cd60: 6620 6765 6270 206d 6963 726f 206b 6572  f gebp micro ker
+0000cd70: 6e65 6c20 312f 6861 6c66 2f71 7561 7274  nel 1/half/quart
+0000cd80: 6572 5831 2229 3b20 5c0a 0920 2020 2020  erX1"); \..     
+0000cd90: 207d 2077 6869 6c65 2866 616c 7365 293b   } while(false);
+0000cda0: 0a0a 2020 2020 2020 2020 2020 4549 4745  ..          EIGE
+0000cdb0: 4e5f 4745 4247 505f 4f4e 4553 5445 5028  N_GEBGP_ONESTEP(
+0000cdc0: 3029 3b0a 2020 2020 2020 2020 2020 4549  0);.          EI
+0000cdd0: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+0000cde0: 5028 3129 3b0a 2020 2020 2020 2020 2020  P(1);.          
+0000cdf0: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
+0000ce00: 5445 5028 3229 3b0a 2020 2020 2020 2020  TEP(2);.        
+0000ce10: 2020 4549 4745 4e5f 4745 4247 505f 4f4e    EIGEN_GEBGP_ON
+0000ce20: 4553 5445 5028 3329 3b0a 2020 2020 2020  ESTEP(3);.      
+0000ce30: 2020 2020 4549 4745 4e5f 4745 4247 505f      EIGEN_GEBGP_
+0000ce40: 4f4e 4553 5445 5028 3429 3b0a 2020 2020  ONESTEP(4);.    
+0000ce50: 2020 2020 2020 4549 4745 4e5f 4745 4247        EIGEN_GEBG
+0000ce60: 505f 4f4e 4553 5445 5028 3529 3b0a 2020  P_ONESTEP(5);.  
+0000ce70: 2020 2020 2020 2020 4549 4745 4e5f 4745          EIGEN_GE
+0000ce80: 4247 505f 4f4e 4553 5445 5028 3629 3b0a  BGP_ONESTEP(6);.
+0000ce90: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
+0000cea0: 4745 4247 505f 4f4e 4553 5445 5028 3729  GEBGP_ONESTEP(7)
+0000ceb0: 3b0a 0a20 2020 2020 2020 2020 2062 6c42  ;..          blB
+0000cec0: 202b 3d20 706b 2a52 6873 5072 6f67 7265   += pk*RhsProgre
+0000ced0: 7373 3b0a 2020 2020 2020 2020 2020 626c  ss;.          bl
+0000cee0: 4120 2b3d 2070 6b2a 4c68 7350 726f 6772  A += pk*LhsProgr
+0000cef0: 6573 733b 0a0a 2020 2020 2020 2020 2020  ess;..          
+0000cf00: 4549 4745 4e5f 4153 4d5f 434f 4d4d 454e  EIGEN_ASM_COMMEN
+0000cf10: 5428 2265 6e64 2067 6562 7020 6d69 6372  T("end gebp micr
+0000cf20: 6f20 6b65 726e 656c 2031 2f68 616c 662f  o kernel 1/half/
+0000cf30: 7175 6172 7465 7258 3122 293b 0a20 2020  quarterX1");.   
+0000cf40: 2020 2020 207d 0a0a 2020 2020 2020 2020       }..        
+0000cf50: 2f2f 2070 726f 6365 7373 2072 656d 6169  // process remai
+0000cf60: 6e69 6e67 2070 6565 6c65 6420 6c6f 6f70  ning peeled loop
+0000cf70: 0a20 2020 2020 2020 2066 6f72 2849 6e64  .        for(Ind
+0000cf80: 6578 206b 3d70 6565 6c65 645f 6b63 3b20  ex k=peeled_kc; 
+0000cf90: 6b3c 6465 7074 683b 206b 2b2b 290a 2020  k<depth; k++).  
+0000cfa0: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+0000cfb0: 2020 5268 7350 6163 6b65 7420 425f 303b    RhsPacket B_0;
+0000cfc0: 0a20 2020 2020 2020 2020 2045 4947 454e  .          EIGEN
+0000cfd0: 5f47 4542 4750 5f4f 4e45 5354 4550 2830  _GEBGP_ONESTEP(0
+0000cfe0: 293b 0a20 2020 2020 2020 2020 2062 6c42  );.          blB
+0000cff0: 202b 3d20 5268 7350 726f 6772 6573 733b   += RhsProgress;
+0000d000: 0a20 2020 2020 2020 2020 2062 6c41 202b  .          blA +
+0000d010: 3d20 4c68 7350 726f 6772 6573 733b 0a20  = LhsProgress;. 
+0000d020: 2020 2020 2020 207d 0a23 756e 6465 6620         }.#undef 
+0000d030: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
+0000d040: 5445 500a 2020 2020 2020 2020 5265 7350  TEP.        ResP
+0000d050: 6163 6b65 7420 5230 3b0a 2020 2020 2020  acket R0;.      
+0000d060: 2020 5265 7350 6163 6b65 7420 616c 7068    ResPacket alph
+0000d070: 6176 203d 2070 7365 7431 3c52 6573 5061  av = pset1<ResPa
+0000d080: 636b 6574 3e28 616c 7068 6129 3b0a 2020  cket>(alpha);.  
+0000d090: 2020 2020 2020 5230 203d 2072 302e 7465        R0 = r0.te
+0000d0a0: 6d70 6c61 7465 206c 6f61 6450 6163 6b65  mplate loadPacke
+0000d0b0: 743c 5265 7350 6163 6b65 743e 2830 293b  t<ResPacket>(0);
+0000d0c0: 0a20 2020 2020 2020 2074 7261 6974 732e  .        traits.
+0000d0d0: 6163 6328 4330 2c20 616c 7068 6176 2c20  acc(C0, alphav, 
+0000d0e0: 5230 293b 0a20 2020 2020 2020 2072 302e  R0);.        r0.
+0000d0f0: 7374 6f72 6550 6163 6b65 7428 302c 2052  storePacket(0, R
+0000d100: 3029 3b0a 2020 2020 2020 7d0a 2020 2020  0);.      }.    
+0000d110: 7d0a 2020 7d0a 7d3b 0a0a 7465 6d70 6c61  }.  }.};..templa
+0000d120: 7465 3c69 6e74 206e 722c 2049 6e64 6578  te<int nr, Index
+0000d130: 204c 6873 5072 6f67 7265 7373 2c20 496e   LhsProgress, In
+0000d140: 6465 7820 5268 7350 726f 6772 6573 732c  dex RhsProgress,
+0000d150: 2074 7970 656e 616d 6520 4c68 7353 6361   typename LhsSca
+0000d160: 6c61 722c 2074 7970 656e 616d 6520 5268  lar, typename Rh
+0000d170: 7353 6361 6c61 722c 2074 7970 656e 616d  sScalar, typenam
+0000d180: 6520 5265 7353 6361 6c61 722c 2074 7970  e ResScalar, typ
+0000d190: 656e 616d 6520 4163 6350 6163 6b65 742c  ename AccPacket,
+0000d1a0: 2074 7970 656e 616d 6520 4c68 7350 6163   typename LhsPac
+0000d1b0: 6b65 742c 2074 7970 656e 616d 6520 5268  ket, typename Rh
+0000d1c0: 7350 6163 6b65 742c 2074 7970 656e 616d  sPacket, typenam
+0000d1d0: 6520 5265 7350 6163 6b65 742c 2074 7970  e ResPacket, typ
+0000d1e0: 656e 616d 6520 4745 4250 5472 6169 7473  ename GEBPTraits
+0000d1f0: 2c20 7479 7065 6e61 6d65 204c 696e 6561  , typename Linea
+0000d200: 724d 6170 7065 722c 2074 7970 656e 616d  rMapper, typenam
+0000d210: 6520 4461 7461 4d61 7070 6572 3e0a 7374  e DataMapper>.st
+0000d220: 7275 6374 206c 6873 5f70 726f 6365 7373  ruct lhs_process
+0000d230: 5f66 7261 6374 696f 6e5f 6f66 5f70 6163  _fraction_of_pac
+0000d240: 6b65 7420 3a20 6c68 735f 7072 6f63 6573  ket : lhs_proces
+0000d250: 735f 6f6e 655f 7061 636b 6574 3c6e 722c  s_one_packet<nr,
+0000d260: 204c 6873 5072 6f67 7265 7373 2c20 5268   LhsProgress, Rh
+0000d270: 7350 726f 6772 6573 732c 204c 6873 5363  sProgress, LhsSc
+0000d280: 616c 6172 2c20 5268 7353 6361 6c61 722c  alar, RhsScalar,
+0000d290: 2052 6573 5363 616c 6172 2c20 4163 6350   ResScalar, AccP
+0000d2a0: 6163 6b65 742c 204c 6873 5061 636b 6574  acket, LhsPacket
+0000d2b0: 2c20 5268 7350 6163 6b65 742c 2052 6573  , RhsPacket, Res
+0000d2c0: 5061 636b 6574 2c20 4745 4250 5472 6169  Packet, GEBPTrai
+0000d2d0: 7473 2c20 4c69 6e65 6172 4d61 7070 6572  ts, LinearMapper
+0000d2e0: 2c20 4461 7461 4d61 7070 6572 3e0a 7b0a  , DataMapper>.{.
+0000d2f0: 0a45 4947 454e 5f53 5452 4f4e 475f 494e  .EIGEN_STRONG_IN
+0000d300: 4c49 4e45 2076 6f69 6420 7065 656c 6564  LINE void peeled
+0000d310: 5f6b 635f 6f6e 6573 7465 7028 496e 6465  _kc_onestep(Inde
+0000d320: 7820 4b2c 2063 6f6e 7374 204c 6873 5363  x K, const LhsSc
+0000d330: 616c 6172 2a20 626c 412c 2063 6f6e 7374  alar* blA, const
+0000d340: 2052 6873 5363 616c 6172 2a20 626c 422c   RhsScalar* blB,
+0000d350: 2047 4542 5054 7261 6974 7320 7472 6169   GEBPTraits trai
+0000d360: 7473 2c20 4c68 7350 6163 6b65 7420 2a41  ts, LhsPacket *A
+0000d370: 302c 2052 6873 5061 636b 6574 202a 425f  0, RhsPacket *B_
+0000d380: 302c 2052 6873 5061 636b 6574 202a 4231  0, RhsPacket *B1
+0000d390: 2c20 5268 7350 6163 6b65 7420 2a42 322c  , RhsPacket *B2,
+0000d3a0: 2052 6873 5061 636b 6574 202a 4233 2c20   RhsPacket *B3, 
+0000d3b0: 4163 6350 6163 6b65 7420 2a43 302c 2041  AccPacket *C0, A
+0000d3c0: 6363 5061 636b 6574 202a 4331 2c20 4163  ccPacket *C1, Ac
+0000d3d0: 6350 6163 6b65 7420 2a43 322c 2041 6363  cPacket *C2, Acc
+0000d3e0: 5061 636b 6574 202a 4333 290a 2020 7b0a  Packet *C3).  {.
+0000d3f0: 2020 2020 2020 2020 4549 4745 4e5f 4153          EIGEN_AS
+0000d400: 4d5f 434f 4d4d 454e 5428 2262 6567 696e  M_COMMENT("begin
+0000d410: 2073 7465 7020 6f66 2067 6562 7020 6d69   step of gebp mi
+0000d420: 6372 6f20 6b65 726e 656c 2031 5834 2229  cro kernel 1X4")
+0000d430: 3b0a 2020 2020 2020 2020 4549 4745 4e5f  ;.        EIGEN_
+0000d440: 4153 4d5f 434f 4d4d 454e 5428 224e 6f74  ASM_COMMENT("Not
+0000d450: 653a 2074 6865 7365 2061 736d 2063 6f6d  e: these asm com
+0000d460: 6d65 6e74 7320 776f 726b 2061 726f 756e  ments work aroun
+0000d470: 6420 6275 6720 3933 3521 2229 3b0a 2020  d bug 935!");.  
+0000d480: 2020 2020 2020 7472 6169 7473 2e6c 6f61        traits.loa
+0000d490: 644c 6873 556e 616c 6967 6e65 6428 2662  dLhsUnaligned(&b
+0000d4a0: 6c41 5b28 302b 312a 4b29 2a28 4c68 7350  lA[(0+1*K)*(LhsP
+0000d4b0: 726f 6772 6573 7329 5d2c 202a 4130 293b  rogress)], *A0);
+0000d4c0: 0a20 2020 2020 2020 2074 7261 6974 732e  .        traits.
+0000d4d0: 6272 6f61 6463 6173 7452 6873 2826 626c  broadcastRhs(&bl
+0000d4e0: 425b 2830 2b34 2a4b 292a 5268 7350 726f  B[(0+4*K)*RhsPro
+0000d4f0: 6772 6573 735d 2c20 2a42 5f30 2c20 2a42  gress], *B_0, *B
+0000d500: 312c 202a 4232 2c20 2a42 3329 3b0a 2020  1, *B2, *B3);.  
+0000d510: 2020 2020 2020 7472 6169 7473 2e6d 6164        traits.mad
+0000d520: 6428 2a41 302c 202a 425f 302c 202a 4330  d(*A0, *B_0, *C0
+0000d530: 2c20 2a42 5f30 293b 0a20 2020 2020 2020  , *B_0);.       
+0000d540: 2074 7261 6974 732e 6d61 6464 282a 4130   traits.madd(*A0
+0000d550: 2c20 2a42 312c 2020 2a43 312c 202a 4231  , *B1,  *C1, *B1
+0000d560: 293b 0a20 2020 2020 2020 2074 7261 6974  );.        trait
+0000d570: 732e 6d61 6464 282a 4130 2c20 2a42 322c  s.madd(*A0, *B2,
+0000d580: 2020 2a43 322c 202a 4232 293b 0a20 2020    *C2, *B2);.   
+0000d590: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
+0000d5a0: 282a 4130 2c20 2a42 332c 2020 2a43 332c  (*A0, *B3,  *C3,
+0000d5b0: 202a 4233 293b 0a20 2020 2020 2020 2045   *B3);.        E
+0000d5c0: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
+0000d5d0: 2822 656e 6420 7374 6570 206f 6620 6765  ("end step of ge
+0000d5e0: 6270 206d 6963 726f 206b 6572 6e65 6c20  bp micro kernel 
+0000d5f0: 3158 3422 293b 0a20 207d 0a7d 3b0a 0a74  1X4");.  }.};..t
+0000d600: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
+0000d610: 204c 6873 5363 616c 6172 2c20 7479 7065   LhsScalar, type
+0000d620: 6e61 6d65 2052 6873 5363 616c 6172 2c20  name RhsScalar, 
+0000d630: 7479 7065 6e61 6d65 2049 6e64 6578 2c20  typename Index, 
+0000d640: 7479 7065 6e61 6d65 2044 6174 614d 6170  typename DataMap
+0000d650: 7065 722c 2069 6e74 206d 722c 2069 6e74  per, int mr, int
+0000d660: 206e 722c 2062 6f6f 6c20 436f 6e6a 7567   nr, bool Conjug
+0000d670: 6174 654c 6873 2c20 626f 6f6c 2043 6f6e  ateLhs, bool Con
+0000d680: 6a75 6761 7465 5268 733e 0a45 4947 454e  jugateRhs>.EIGEN
+0000d690: 5f44 4f4e 545f 494e 4c49 4e45 0a76 6f69  _DONT_INLINE.voi
+0000d6a0: 6420 6765 6270 5f6b 6572 6e65 6c3c 4c68  d gebp_kernel<Lh
+0000d6b0: 7353 6361 6c61 722c 5268 7353 6361 6c61  sScalar,RhsScala
+0000d6c0: 722c 496e 6465 782c 4461 7461 4d61 7070  r,Index,DataMapp
+0000d6d0: 6572 2c6d 722c 6e72 2c43 6f6e 6a75 6761  er,mr,nr,Conjuga
+0000d6e0: 7465 4c68 732c 436f 6e6a 7567 6174 6552  teLhs,ConjugateR
+0000d6f0: 6873 3e0a 2020 3a3a 6f70 6572 6174 6f72  hs>.  ::operator
+0000d700: 2829 2863 6f6e 7374 2044 6174 614d 6170  ()(const DataMap
+0000d710: 7065 7226 2072 6573 2c20 636f 6e73 7420  per& res, const 
+0000d720: 4c68 7353 6361 6c61 722a 2062 6c6f 636b  LhsScalar* block
+0000d730: 412c 2063 6f6e 7374 2052 6873 5363 616c  A, const RhsScal
+0000d740: 6172 2a20 626c 6f63 6b42 2c0a 2020 2020  ar* blockB,.    
+0000d750: 2020 2020 2020 2020 2020 2049 6e64 6578             Index
+0000d760: 2072 6f77 732c 2049 6e64 6578 2064 6570   rows, Index dep
+0000d770: 7468 2c20 496e 6465 7820 636f 6c73 2c20  th, Index cols, 
+0000d780: 5265 7353 6361 6c61 7220 616c 7068 612c  ResScalar alpha,
+0000d790: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+0000d7a0: 496e 6465 7820 7374 7269 6465 412c 2049  Index strideA, I
+0000d7b0: 6e64 6578 2073 7472 6964 6542 2c20 496e  ndex strideB, In
+0000d7c0: 6465 7820 6f66 6673 6574 412c 2049 6e64  dex offsetA, Ind
+0000d7d0: 6578 206f 6666 7365 7442 290a 2020 7b0a  ex offsetB).  {.
+0000d7e0: 2020 2020 5472 6169 7473 2074 7261 6974      Traits trait
+0000d7f0: 733b 0a20 2020 2053 7761 7070 6564 5472  s;.    SwappedTr
+0000d800: 6169 7473 2073 7472 6169 7473 3b0a 2020  aits straits;.  
+0000d810: 2020 0a20 2020 2069 6628 7374 7269 6465    .    if(stride
+0000d820: 413d 3d2d 3129 2073 7472 6964 6541 203d  A==-1) strideA =
+0000d830: 2064 6570 7468 3b0a 2020 2020 6966 2873   depth;.    if(s
+0000d840: 7472 6964 6542 3d3d 2d31 2920 7374 7269  trideB==-1) stri
+0000d850: 6465 4220 3d20 6465 7074 683b 0a20 2020  deB = depth;.   
+0000d860: 2063 6f6e 6a5f 6865 6c70 6572 3c4c 6873   conj_helper<Lhs
+0000d870: 5363 616c 6172 2c52 6873 5363 616c 6172  Scalar,RhsScalar
+0000d880: 2c43 6f6e 6a75 6761 7465 4c68 732c 436f  ,ConjugateLhs,Co
+0000d890: 6e6a 7567 6174 6552 6873 3e20 636a 3b0a  njugateRhs> cj;.
+0000d8a0: 2020 2020 496e 6465 7820 7061 636b 6574      Index packet
+0000d8b0: 5f63 6f6c 7334 203d 206e 723e 3d34 203f  _cols4 = nr>=4 ?
+0000d8c0: 2028 636f 6c73 2f34 2920 2a20 3420 3a20   (cols/4) * 4 : 
+0000d8d0: 303b 0a20 2020 2063 6f6e 7374 2049 6e64  0;.    const Ind
+0000d8e0: 6578 2070 6565 6c65 645f 6d63 3320 3d20  ex peeled_mc3 = 
+0000d8f0: 6d72 3e3d 332a 5472 6169 7473 3a3a 4c68  mr>=3*Traits::Lh
+0000d900: 7350 726f 6772 6573 7320 3f20 2872 6f77  sProgress ? (row
+0000d910: 732f 2833 2a4c 6873 5072 6f67 7265 7373  s/(3*LhsProgress
+0000d920: 2929 2a28 332a 4c68 7350 726f 6772 6573  ))*(3*LhsProgres
+0000d930: 7329 203a 2030 3b0a 2020 2020 636f 6e73  s) : 0;.    cons
+0000d940: 7420 496e 6465 7820 7065 656c 6564 5f6d  t Index peeled_m
+0000d950: 6332 203d 206d 723e 3d32 2a54 7261 6974  c2 = mr>=2*Trait
+0000d960: 733a 3a4c 6873 5072 6f67 7265 7373 203f  s::LhsProgress ?
+0000d970: 2070 6565 6c65 645f 6d63 332b 2828 726f   peeled_mc3+((ro
+0000d980: 7773 2d70 6565 6c65 645f 6d63 3329 2f28  ws-peeled_mc3)/(
+0000d990: 322a 4c68 7350 726f 6772 6573 7329 292a  2*LhsProgress))*
+0000d9a0: 2832 2a4c 6873 5072 6f67 7265 7373 2920  (2*LhsProgress) 
+0000d9b0: 3a20 303b 0a20 2020 2063 6f6e 7374 2049  : 0;.    const I
+0000d9c0: 6e64 6578 2070 6565 6c65 645f 6d63 3120  ndex peeled_mc1 
+0000d9d0: 3d20 6d72 3e3d 312a 5472 6169 7473 3a3a  = mr>=1*Traits::
+0000d9e0: 4c68 7350 726f 6772 6573 7320 3f20 7065  LhsProgress ? pe
+0000d9f0: 656c 6564 5f6d 6332 2b28 2872 6f77 732d  eled_mc2+((rows-
+0000da00: 7065 656c 6564 5f6d 6332 292f 2831 2a4c  peeled_mc2)/(1*L
+0000da10: 6873 5072 6f67 7265 7373 2929 2a28 312a  hsProgress))*(1*
+0000da20: 4c68 7350 726f 6772 6573 7329 203a 2030  LhsProgress) : 0
+0000da30: 3b0a 2020 2020 636f 6e73 7420 496e 6465  ;.    const Inde
+0000da40: 7820 7065 656c 6564 5f6d 635f 6861 6c66  x peeled_mc_half
+0000da50: 203d 206d 723e 3d4c 6873 5072 6f67 7265   = mr>=LhsProgre
+0000da60: 7373 4861 6c66 203f 2070 6565 6c65 645f  ssHalf ? peeled_
+0000da70: 6d63 312b 2828 726f 7773 2d70 6565 6c65  mc1+((rows-peele
+0000da80: 645f 6d63 3129 2f28 4c68 7350 726f 6772  d_mc1)/(LhsProgr
+0000da90: 6573 7348 616c 6629 292a 284c 6873 5072  essHalf))*(LhsPr
+0000daa0: 6f67 7265 7373 4861 6c66 2920 3a20 303b  ogressHalf) : 0;
+0000dab0: 0a20 2020 2063 6f6e 7374 2049 6e64 6578  .    const Index
+0000dac0: 2070 6565 6c65 645f 6d63 5f71 7561 7274   peeled_mc_quart
+0000dad0: 6572 203d 206d 723e 3d4c 6873 5072 6f67  er = mr>=LhsProg
+0000dae0: 7265 7373 5175 6172 7465 7220 3f20 7065  ressQuarter ? pe
+0000daf0: 656c 6564 5f6d 635f 6861 6c66 2b28 2872  eled_mc_half+((r
+0000db00: 6f77 732d 7065 656c 6564 5f6d 635f 6861  ows-peeled_mc_ha
+0000db10: 6c66 292f 284c 6873 5072 6f67 7265 7373  lf)/(LhsProgress
+0000db20: 5175 6172 7465 7229 292a 284c 6873 5072  Quarter))*(LhsPr
+0000db30: 6f67 7265 7373 5175 6172 7465 7229 203a  ogressQuarter) :
+0000db40: 2030 3b0a 2020 2020 656e 756d 207b 2070   0;.    enum { p
+0000db50: 6b20 3d20 3820 7d3b 202f 2f20 4e4f 5445  k = 8 }; // NOTE
+0000db60: 2053 7563 6820 6120 6c61 7267 6520 7065   Such a large pe
+0000db70: 656c 696e 6720 6661 6374 6f72 2069 7320  eling factor is 
+0000db80: 696d 706f 7274 616e 7420 666f 7220 6c61  important for la
+0000db90: 7267 6520 6d61 7472 6963 6573 2028 7e20  rge matrices (~ 
+0000dba0: 2b35 2520 7768 656e 203e 3130 3030 206f  +5% when >1000 o
+0000dbb0: 6e20 4861 7377 656c 6c29 0a20 2020 2063  n Haswell).    c
+0000dbc0: 6f6e 7374 2049 6e64 6578 2070 6565 6c65  onst Index peele
+0000dbd0: 645f 6b63 2020 3d20 6465 7074 6820 2620  d_kc  = depth & 
+0000dbe0: 7e28 706b 2d31 293b 0a20 2020 2063 6f6e  ~(pk-1);.    con
+0000dbf0: 7374 2069 6e74 2070 7265 6665 7463 685f  st int prefetch_
+0000dc00: 7265 735f 6f66 6673 6574 203d 2033 322f  res_offset = 32/
+0000dc10: 7369 7a65 6f66 2852 6573 5363 616c 6172  sizeof(ResScalar
+0000dc20: 293b 2020 2020 0a2f 2f20 2020 2020 636f  );    .//     co
+0000dc30: 6e73 7420 496e 6465 7820 6465 7074 6832  nst Index depth2
+0000dc40: 2020 2020 203d 2064 6570 7468 2026 207e       = depth & ~
+0000dc50: 313b 0a0a 2020 2020 2f2f 2d2d 2d2d 2d2d  1;..    //------
+0000dc60: 2d2d 2d2d 2050 726f 6365 7373 2033 202a  ---- Process 3 *
+0000dc70: 204c 6873 5072 6f67 7265 7373 2072 6f77   LhsProgress row
+0000dc80: 7320 6174 206f 6e63 6520 2d2d 2d2d 2d2d  s at once ------
+0000dc90: 2d2d 2d2d 0a20 2020 202f 2f20 5468 6973  ----.    // This
+0000dca0: 2063 6f72 7265 7370 6f6e 6473 2074 6f20   corresponds to 
+0000dcb0: 332a 4c68 7350 726f 6772 6573 7320 7820  3*LhsProgress x 
+0000dcc0: 6e72 2072 6567 6973 7465 7220 626c 6f63  nr register bloc
+0000dcd0: 6b73 2e0a 2020 2020 2f2f 2055 7375 616c  ks..    // Usual
+0000dce0: 6c79 2c20 6d61 6b65 2073 656e 7365 206f  ly, make sense o
+0000dcf0: 6e6c 7920 7769 7468 2046 4d41 0a20 2020  nly with FMA.   
+0000dd00: 2069 6628 6d72 3e3d 332a 5472 6169 7473   if(mr>=3*Traits
+0000dd10: 3a3a 4c68 7350 726f 6772 6573 7329 0a20  ::LhsProgress). 
+0000dd20: 2020 207b 0a20 2020 2020 202f 2f20 4865     {.      // He
+0000dd30: 7265 2c20 7468 6520 6765 6e65 7261 6c20  re, the general 
+0000dd40: 6964 6561 2069 7320 746f 206c 6f6f 7020  idea is to loop 
+0000dd50: 6f6e 2065 6163 6820 6c61 7267 6573 7420  on each largest 
+0000dd60: 6d69 6372 6f20 686f 7269 7a6f 6e74 616c  micro horizontal
+0000dd70: 2070 616e 656c 206f 6620 7468 6520 6c68   panel of the lh
+0000dd80: 7320 2833 2a54 7261 6974 733a 3a4c 6873  s (3*Traits::Lhs
+0000dd90: 5072 6f67 7265 7373 2078 2064 6570 7468  Progress x depth
+0000dda0: 290a 2020 2020 2020 2f2f 2061 6e64 206f  ).      // and o
+0000ddb0: 6e20 6561 6368 206c 6172 6765 7374 206d  n each largest m
+0000ddc0: 6963 726f 2076 6572 7469 6361 6c20 7061  icro vertical pa
+0000ddd0: 6e65 6c20 6f66 2074 6865 2072 6873 2028  nel of the rhs (
+0000dde0: 6465 7074 6820 2a20 6e72 292e 0a20 2020  depth * nr)..   
+0000ddf0: 2020 202f 2f20 426c 6f63 6b69 6e67 2073     // Blocking s
+0000de00: 697a 6573 2c20 692e 652e 2c20 2764 6570  izes, i.e., 'dep
+0000de10: 7468 2720 6861 7320 6265 656e 2063 6f6d  th' has been com
+0000de20: 7075 7465 6420 736f 2074 6861 7420 7468  puted so that th
+0000de30: 6520 6d69 6372 6f20 686f 7269 7a6f 6e74  e micro horizont
+0000de40: 616c 2070 616e 656c 206f 6620 7468 6520  al panel of the 
+0000de50: 6c68 7320 6669 7420 696e 204c 312e 0a20  lhs fit in L1.. 
+0000de60: 2020 2020 202f 2f20 486f 7765 7665 722c       // However,
+0000de70: 2069 6620 6465 7074 6820 6973 2074 6f6f   if depth is too
+0000de80: 2073 6d61 6c6c 2c20 7765 2063 616e 2065   small, we can e
+0000de90: 7874 656e 6420 7468 6520 6e75 6d62 6572  xtend the number
+0000dea0: 206f 6620 726f 7773 206f 6620 7468 6573   of rows of thes
+0000deb0: 6520 686f 7269 7a6f 6e74 616c 2070 616e  e horizontal pan
+0000dec0: 656c 732e 0a20 2020 2020 202f 2f20 5468  els..      // Th
+0000ded0: 6973 2061 6374 7561 6c20 6e75 6d62 6572  is actual number
+0000dee0: 206f 6620 726f 7773 2069 7320 636f 6d70   of rows is comp
+0000def0: 7574 6564 2061 7320 666f 6c6c 6f77 3a0a  uted as follow:.
+0000df00: 2020 2020 2020 636f 6e73 7420 496e 6465        const Inde
+0000df10: 7820 6c31 203d 2064 6566 6175 6c74 4c31  x l1 = defaultL1
+0000df20: 4361 6368 6553 697a 653b 202f 2f20 696e  CacheSize; // in
+0000df30: 2042 7974 6573 2c20 544f 444f 2c20 6c31   Bytes, TODO, l1
+0000df40: 2073 686f 756c 6420 6265 2070 6173 7365   should be passe
+0000df50: 6420 746f 2074 6869 7320 6675 6e63 7469  d to this functi
+0000df60: 6f6e 2e0a 2020 2020 2020 2f2f 2054 6865  on..      // The
+0000df70: 206d 6178 2831 2c20 2e2e 2e29 2068 6572   max(1, ...) her
+0000df80: 6520 6973 206e 6565 6465 6420 6265 6361  e is needed beca
+0000df90: 7573 6520 7765 206d 6179 2062 6520 7573  use we may be us
+0000dfa0: 696e 6720 626c 6f63 6b69 6e67 2070 6172  ing blocking par
+0000dfb0: 616d 7320 6c61 7267 6572 2074 6861 6e20  ams larger than 
+0000dfc0: 7768 6174 206f 7572 206b 6e6f 776e 206c  what our known l
+0000dfd0: 3120 6361 6368 6520 7369 7a65 0a20 2020  1 cache size.   
+0000dfe0: 2020 202f 2f20 7375 6767 6573 7473 2077     // suggests w
+0000dff0: 6520 7368 6f75 6c64 2062 6520 7573 696e  e should be usin
+0000e000: 673a 2065 6974 6865 7220 6265 6361 7573  g: either becaus
+0000e010: 6520 6f75 7220 6b6e 6f77 6e20 6c31 2063  e our known l1 c
+0000e020: 6163 6865 2073 697a 6520 6973 2069 6e61  ache size is ina
+0000e030: 6363 7572 6174 6520 2865 2e67 2e20 6f6e  ccurate (e.g. on
+0000e040: 2041 6e64 726f 6964 2c20 7765 2063 616e   Android, we can
+0000e050: 206f 6e6c 7920 6775 6573 7329 2c0a 2020   only guess),.  
+0000e060: 2020 2020 2f2f 206f 7220 6265 6361 7573      // or becaus
+0000e070: 6520 7765 2061 7265 2074 6573 7469 6e67  e we are testing
+0000e080: 2073 7065 6369 6669 6320 626c 6f63 6b69   specific blocki
+0000e090: 6e67 2073 697a 6573 2e0a 2020 2020 2020  ng sizes..      
+0000e0a0: 636f 6e73 7420 496e 6465 7820 6163 7475  const Index actu
+0000e0b0: 616c 5f70 616e 656c 5f72 6f77 7320 3d20  al_panel_rows = 
+0000e0c0: 2833 2a4c 6873 5072 6f67 7265 7373 2920  (3*LhsProgress) 
+0000e0d0: 2a20 7374 643a 3a6d 6178 3c49 6e64 6578  * std::max<Index
+0000e0e0: 3e28 312c 2820 286c 3120 2d20 7369 7a65  >(1,( (l1 - size
+0000e0f0: 6f66 2852 6573 5363 616c 6172 292a 6d72  of(ResScalar)*mr
+0000e100: 2a6e 7220 2d20 6465 7074 682a 6e72 2a73  *nr - depth*nr*s
+0000e110: 697a 656f 6628 5268 7353 6361 6c61 7229  izeof(RhsScalar)
+0000e120: 2920 2f20 2864 6570 7468 202a 2073 697a  ) / (depth * siz
+0000e130: 656f 6628 4c68 7353 6361 6c61 7229 202a  eof(LhsScalar) *
+0000e140: 2033 2a4c 6873 5072 6f67 7265 7373 2920   3*LhsProgress) 
+0000e150: 2929 3b0a 2020 2020 2020 666f 7228 496e  ));.      for(In
+0000e160: 6465 7820 6931 3d30 3b20 6931 3c70 6565  dex i1=0; i1<pee
+0000e170: 6c65 645f 6d63 333b 2069 312b 3d61 6374  led_mc3; i1+=act
+0000e180: 7561 6c5f 7061 6e65 6c5f 726f 7773 290a  ual_panel_rows).
+0000e190: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+0000e1a0: 636f 6e73 7420 496e 6465 7820 6163 7475  const Index actu
+0000e1b0: 616c 5f70 616e 656c 5f65 6e64 203d 2028  al_panel_end = (
+0000e1c0: 7374 643a 3a6d 696e 2928 6931 2b61 6374  std::min)(i1+act
+0000e1d0: 7561 6c5f 7061 6e65 6c5f 726f 7773 2c20  ual_panel_rows, 
+0000e1e0: 7065 656c 6564 5f6d 6333 293b 0a20 2020  peeled_mc3);.   
+0000e1f0: 2020 2020 2066 6f72 2849 6e64 6578 206a       for(Index j
+0000e200: 323d 303b 206a 323c 7061 636b 6574 5f63  2=0; j2<packet_c
+0000e210: 6f6c 7334 3b20 6a32 2b3d 6e72 290a 2020  ols4; j2+=nr).  
+0000e220: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+0000e230: 2020 666f 7228 496e 6465 7820 693d 6931    for(Index i=i1
+0000e240: 3b20 693c 6163 7475 616c 5f70 616e 656c  ; i<actual_panel
+0000e250: 5f65 6e64 3b20 692b 3d33 2a4c 6873 5072  _end; i+=3*LhsPr
+0000e260: 6f67 7265 7373 290a 2020 2020 2020 2020  ogress).        
+0000e270: 2020 7b0a 2020 2020 2020 2020 2020 0a20    {.          . 
+0000e280: 2020 2020 2020 2020 202f 2f20 5765 2073           // We s
+0000e290: 656c 6563 7465 6420 6120 332a 5472 6169  elected a 3*Trai
+0000e2a0: 7473 3a3a 4c68 7350 726f 6772 6573 7320  ts::LhsProgress 
+0000e2b0: 7820 6e72 206d 6963 726f 2062 6c6f 636b  x nr micro block
+0000e2c0: 206f 6620 7265 7320 7768 6963 6820 6973   of res which is
+0000e2d0: 2065 6e74 6972 656c 790a 2020 2020 2020   entirely.      
+0000e2e0: 2020 2020 2f2f 2073 746f 7265 6420 696e      // stored in
+0000e2f0: 746f 2033 2078 206e 7220 7265 6769 7374  to 3 x nr regist
+0000e300: 6572 732e 0a20 2020 2020 2020 2020 200a  ers..          .
+0000e310: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
+0000e320: 4c68 7353 6361 6c61 722a 2062 6c41 203d  LhsScalar* blA =
+0000e330: 2026 626c 6f63 6b41 5b69 2a73 7472 6964   &blockA[i*strid
+0000e340: 6541 2b6f 6666 7365 7441 2a28 332a 4c68  eA+offsetA*(3*Lh
+0000e350: 7350 726f 6772 6573 7329 5d3b 0a20 2020  sProgress)];.   
+0000e360: 2020 2020 2020 2070 7265 6665 7463 6828         prefetch(
+0000e370: 2662 6c41 5b30 5d29 3b0a 0a20 2020 2020  &blA[0]);..     
+0000e380: 2020 2020 202f 2f20 6765 7473 2072 6573       // gets res
+0000e390: 2062 6c6f 636b 2061 7320 7265 6769 7374   block as regist
+0000e3a0: 6572 0a20 2020 2020 2020 2020 2041 6363  er.          Acc
+0000e3b0: 5061 636b 6574 2043 302c 2043 312c 2043  Packet C0, C1, C
+0000e3c0: 322c 2020 4333 2c0a 2020 2020 2020 2020  2,  C3,.        
+0000e3d0: 2020 2020 2020 2020 2020 2020 4334 2c20              C4, 
+0000e3e0: 4335 2c20 4336 2c20 2043 372c 0a20 2020  C5, C6,  C7,.   
+0000e3f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000e400: 2043 382c 2043 392c 2043 3130 2c20 4331   C8, C9, C10, C1
+0000e410: 313b 0a20 2020 2020 2020 2020 2074 7261  1;.          tra
+0000e420: 6974 732e 696e 6974 4163 6328 4330 293b  its.initAcc(C0);
+0000e430: 2020 7472 6169 7473 2e69 6e69 7441 6363    traits.initAcc
+0000e440: 2843 3129 3b20 2074 7261 6974 732e 696e  (C1);  traits.in
+0000e450: 6974 4163 6328 4332 293b 2020 7472 6169  itAcc(C2);  trai
+0000e460: 7473 2e69 6e69 7441 6363 2843 3329 3b0a  ts.initAcc(C3);.
+0000e470: 2020 2020 2020 2020 2020 7472 6169 7473            traits
+0000e480: 2e69 6e69 7441 6363 2843 3429 3b20 2074  .initAcc(C4);  t
+0000e490: 7261 6974 732e 696e 6974 4163 6328 4335  raits.initAcc(C5
+0000e4a0: 293b 2020 7472 6169 7473 2e69 6e69 7441  );  traits.initA
+0000e4b0: 6363 2843 3629 3b20 2074 7261 6974 732e  cc(C6);  traits.
+0000e4c0: 696e 6974 4163 6328 4337 293b 0a20 2020  initAcc(C7);.   
+0000e4d0: 2020 2020 2020 2074 7261 6974 732e 696e         traits.in
+0000e4e0: 6974 4163 6328 4338 293b 2020 7472 6169  itAcc(C8);  trai
+0000e4f0: 7473 2e69 6e69 7441 6363 2843 3929 3b20  ts.initAcc(C9); 
+0000e500: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
+0000e510: 4331 3029 3b20 7472 6169 7473 2e69 6e69  C10); traits.ini
+0000e520: 7441 6363 2843 3131 293b 0a0a 2020 2020  tAcc(C11);..    
+0000e530: 2020 2020 2020 4c69 6e65 6172 4d61 7070        LinearMapp
+0000e540: 6572 2072 3020 3d20 7265 732e 6765 744c  er r0 = res.getL
+0000e550: 696e 6561 724d 6170 7065 7228 692c 206a  inearMapper(i, j
+0000e560: 3220 2b20 3029 3b0a 2020 2020 2020 2020  2 + 0);.        
+0000e570: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
+0000e580: 3120 3d20 7265 732e 6765 744c 696e 6561  1 = res.getLinea
+0000e590: 724d 6170 7065 7228 692c 206a 3220 2b20  rMapper(i, j2 + 
+0000e5a0: 3129 3b0a 2020 2020 2020 2020 2020 4c69  1);.          Li
+0000e5b0: 6e65 6172 4d61 7070 6572 2072 3220 3d20  nearMapper r2 = 
+0000e5c0: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
+0000e5d0: 7065 7228 692c 206a 3220 2b20 3229 3b0a  per(i, j2 + 2);.
+0000e5e0: 2020 2020 2020 2020 2020 4c69 6e65 6172            Linear
+0000e5f0: 4d61 7070 6572 2072 3320 3d20 7265 732e  Mapper r3 = res.
+0000e600: 6765 744c 696e 6561 724d 6170 7065 7228  getLinearMapper(
+0000e610: 692c 206a 3220 2b20 3329 3b0a 0a20 2020  i, j2 + 3);..   
+0000e620: 2020 2020 2020 2072 302e 7072 6566 6574         r0.prefet
+0000e630: 6368 2830 293b 0a20 2020 2020 2020 2020  ch(0);.         
+0000e640: 2072 312e 7072 6566 6574 6368 2830 293b   r1.prefetch(0);
+0000e650: 0a20 2020 2020 2020 2020 2072 322e 7072  .          r2.pr
+0000e660: 6566 6574 6368 2830 293b 0a20 2020 2020  efetch(0);.     
+0000e670: 2020 2020 2072 332e 7072 6566 6574 6368       r3.prefetch
+0000e680: 2830 293b 0a0a 2020 2020 2020 2020 2020  (0);..          
+0000e690: 2f2f 2070 6572 666f 726d 7320 2269 6e6e  // performs "inn
+0000e6a0: 6572 2220 7072 6f64 7563 7473 0a20 2020  er" products.   
+0000e6b0: 2020 2020 2020 2063 6f6e 7374 2052 6873         const Rhs
+0000e6c0: 5363 616c 6172 2a20 626c 4220 3d20 2662  Scalar* blB = &b
+0000e6d0: 6c6f 636b 425b 6a32 2a73 7472 6964 6542  lockB[j2*strideB
+0000e6e0: 2b6f 6666 7365 7442 2a6e 725d 3b0a 2020  +offsetB*nr];.  
+0000e6f0: 2020 2020 2020 2020 7072 6566 6574 6368          prefetch
+0000e700: 2826 626c 425b 305d 293b 0a20 2020 2020  (&blB[0]);.     
+0000e710: 2020 2020 204c 6873 5061 636b 6574 2041       LhsPacket A
+0000e720: 302c 2041 313b 0a0a 2020 2020 2020 2020  0, A1;..        
+0000e730: 2020 666f 7228 496e 6465 7820 6b3d 303b    for(Index k=0;
+0000e740: 206b 3c70 6565 6c65 645f 6b63 3b20 6b2b   k<peeled_kc; k+
+0000e750: 3d70 6b29 0a20 2020 2020 2020 2020 207b  =pk).          {
+0000e760: 0a20 2020 2020 2020 2020 2020 2045 4947  .            EIG
+0000e770: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
+0000e780: 6265 6769 6e20 6765 6270 206d 6963 726f  begin gebp micro
+0000e790: 206b 6572 6e65 6c20 3370 5834 2229 3b0a   kernel 3pX4");.
+0000e7a0: 2020 2020 2020 2020 2020 2020 2f2f 2031              // 1
+0000e7b0: 3520 7265 6769 7374 6572 7320 6172 6520  5 registers are 
+0000e7c0: 7461 6b65 6e20 2831 3220 666f 7220 6163  taken (12 for ac
+0000e7d0: 632c 2032 2066 6f72 206c 6873 292e 0a20  c, 2 for lhs).. 
+0000e7e0: 2020 2020 2020 2020 2020 2052 6873 5061             RhsPa
+0000e7f0: 6e65 6c31 3520 7268 735f 7061 6e65 6c3b  nel15 rhs_panel;
+0000e800: 0a20 2020 2020 2020 2020 2020 2052 6873  .            Rhs
+0000e810: 5061 636b 6574 2054 303b 0a20 2020 2020  Packet T0;.     
+0000e820: 2020 2020 2020 204c 6873 5061 636b 6574         LhsPacket
+0000e830: 2041 323b 0a20 2020 2020 2020 2020 2020   A2;.           
+0000e840: 2023 6966 2045 4947 454e 5f43 4f4d 505f   #if EIGEN_COMP_
+0000e850: 474e 5543 5f53 5452 4943 5420 2626 2045  GNUC_STRICT && E
+0000e860: 4947 454e 5f41 5243 485f 4152 4d36 3420  IGEN_ARCH_ARM64 
+0000e870: 2626 2064 6566 696e 6564 2845 4947 454e  && defined(EIGEN
+0000e880: 5f56 4543 544f 5249 5a45 5f4e 454f 4e29  _VECTORIZE_NEON)
+0000e890: 2026 2620 2128 4549 4745 4e5f 474e 5543   && !(EIGEN_GNUC
+0000e8a0: 5f41 545f 4c45 4153 5428 392c 3029 290a  _AT_LEAST(9,0)).
+0000e8b0: 2020 2020 2020 2020 2020 2020 2f2f 2073              // s
+0000e8c0: 6565 2068 7474 703a 2f2f 6569 6765 6e2e  ee http://eigen.
+0000e8d0: 7475 7866 616d 696c 792e 6f72 672f 627a  tuxfamily.org/bz
+0000e8e0: 2f73 686f 775f 6275 672e 6367 693f 6964  /show_bug.cgi?id
+0000e8f0: 3d31 3633 330a 2020 2020 2020 2020 2020  =1633.          
+0000e900: 2020 2f2f 2077 6974 686f 7574 2074 6869    // without thi
+0000e910: 7320 776f 726b 6172 6f75 6e64 2041 302c  s workaround A0,
+0000e920: 2041 312c 2061 6e64 2041 3220 6172 6520   A1, and A2 are 
+0000e930: 6c6f 6164 6564 2069 6e20 7468 6520 7361  loaded in the sa
+0000e940: 6d65 2072 6567 6973 7465 722c 0a20 2020  me register,.   
+0000e950: 2020 2020 2020 2020 202f 2f20 7768 6963           // whic
+0000e960: 6820 6973 206e 6f74 2067 6f6f 6420 666f  h is not good fo
+0000e970: 7220 7069 7065 6c69 6e69 6e67 0a20 2020  r pipelining.   
+0000e980: 2020 2020 2020 2020 2023 6465 6669 6e65           #define
+0000e990: 2045 4947 454e 5f47 4542 505f 3350 5834   EIGEN_GEBP_3PX4
+0000e9a0: 5f52 4547 4953 5445 525f 414c 4c4f 435f  _REGISTER_ALLOC_
+0000e9b0: 574f 524b 4152 4f55 4e44 205f 5f61 736d  WORKAROUND __asm
+0000e9c0: 5f5f 2020 2822 2220 3a20 222b 772c 6d22  __  ("" : "+w,m"
+0000e9d0: 2028 4130 292c 2022 2b77 2c6d 2220 2841   (A0), "+w,m" (A
+0000e9e0: 3129 2c20 222b 772c 6d22 2028 4132 2929  1), "+w,m" (A2))
+0000e9f0: 3b0a 2020 2020 2020 2020 2020 2020 2365  ;.            #e
+0000ea00: 6c73 650a 2020 2020 2020 2020 2020 2020  lse.            
+0000ea10: 2364 6566 696e 6520 4549 4745 4e5f 4745  #define EIGEN_GE
+0000ea20: 4250 5f33 5058 345f 5245 4749 5354 4552  BP_3PX4_REGISTER
+0000ea30: 5f41 4c4c 4f43 5f57 4f52 4b41 524f 554e  _ALLOC_WORKAROUN
+0000ea40: 440a 2020 2020 2020 2020 2020 2020 2365  D.            #e
+0000ea50: 6e64 6966 0a23 6465 6669 6e65 2045 4947  ndif.#define EIG
+0000ea60: 454e 5f47 4542 505f 4f4e 4553 5445 5028  EN_GEBP_ONESTEP(
+0000ea70: 4b29 2020 2020 2020 2020 2020 2020 2020  K)              
+0000ea80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ea90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eaa0: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+0000eab0: 2020 2020 2064 6f20 7b20 2020 2020 2020       do {       
+0000eac0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ead0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eaf0: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+0000eb00: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+0000eb10: 5f41 534d 5f43 4f4d 4d45 4e54 2822 6265  _ASM_COMMENT("be
+0000eb20: 6769 6e20 7374 6570 206f 6620 6765 6270  gin step of gebp
+0000eb30: 206d 6963 726f 206b 6572 6e65 6c20 3370   micro kernel 3p
+0000eb40: 5834 2229 3b20 2020 2020 2020 2020 205c  X4");          \
+0000eb50: 0a20 2020 2020 2020 2020 2020 2020 2045  .              E
+0000eb60: 4947 454e 5f41 534d 5f43 4f4d 4d45 4e54  IGEN_ASM_COMMENT
+0000eb70: 2822 4e6f 7465 3a20 7468 6573 6520 6173  ("Note: these as
+0000eb80: 6d20 636f 6d6d 656e 7473 2077 6f72 6b20  m comments work 
+0000eb90: 6172 6f75 6e64 2062 7567 2039 3335 2122  around bug 935!"
+0000eba0: 293b 205c 0a20 2020 2020 2020 2020 2020  ); \.           
+0000ebb0: 2020 2069 6e74 6572 6e61 6c3a 3a70 7265     internal::pre
+0000ebc0: 6665 7463 6828 626c 4120 2b20 2833 202a  fetch(blA + (3 *
+0000ebd0: 204b 202b 2031 3629 202a 204c 6873 5072   K + 16) * LhsPr
+0000ebe0: 6f67 7265 7373 293b 2020 2020 2020 2020  ogress);        
+0000ebf0: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+0000ec00: 2020 2020 2020 2069 6620 2845 4947 454e         if (EIGEN
+0000ec10: 5f41 5243 485f 4152 4d20 7c7c 2045 4947  _ARCH_ARM || EIG
+0000ec20: 454e 5f41 5243 485f 4d49 5053 2920 7b20  EN_ARCH_MIPS) { 
+0000ec30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ec40: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+0000ec50: 2020 2020 2020 2020 2020 2020 2069 6e74               int
+0000ec60: 6572 6e61 6c3a 3a70 7265 6665 7463 6828  ernal::prefetch(
+0000ec70: 626c 4220 2b20 2834 202a 204b 202b 2031  blB + (4 * K + 1
+0000ec80: 3629 202a 2052 6873 5072 6f67 7265 7373  6) * RhsProgress
+0000ec90: 293b 2020 2020 2020 2020 2020 2020 205c  );             \
+0000eca0: 0a20 2020 2020 2020 2020 2020 2020 207d  .              }
+0000ecb0: 202f 2a20 4275 6720 3935 3320 2a2f 2020   /* Bug 953 */  
+0000ecc0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ecd0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ece0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ecf0: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
+0000ed00: 2020 2074 7261 6974 732e 6c6f 6164 4c68     traits.loadLh
+0000ed10: 7328 2662 6c41 5b28 3020 2b20 3320 2a20  s(&blA[(0 + 3 * 
+0000ed20: 4b29 202a 204c 6873 5072 6f67 7265 7373  K) * LhsProgress
+0000ed30: 5d2c 2041 3029 3b20 2020 2020 2020 2020  ], A0);         
+0000ed40: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+0000ed50: 2020 2020 2020 2074 7261 6974 732e 6c6f         traits.lo
+0000ed60: 6164 4c68 7328 2662 6c41 5b28 3120 2b20  adLhs(&blA[(1 + 
+0000ed70: 3320 2a20 4b29 202a 204c 6873 5072 6f67  3 * K) * LhsProg
+0000ed80: 7265 7373 5d2c 2041 3129 3b20 2020 2020  ress], A1);     
+0000ed90: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+0000eda0: 2020 2020 2020 2020 2020 2074 7261 6974             trait
+0000edb0: 732e 6c6f 6164 4c68 7328 2662 6c41 5b28  s.loadLhs(&blA[(
+0000edc0: 3220 2b20 3320 2a20 4b29 202a 204c 6873  2 + 3 * K) * Lhs
+0000edd0: 5072 6f67 7265 7373 5d2c 2041 3229 3b20  Progress], A2); 
+0000ede0: 2020 2020 2020 2020 2020 2020 2020 205c                 \
+0000edf0: 0a20 2020 2020 2020 2020 2020 2020 2045  .              E
+0000ee00: 4947 454e 5f47 4542 505f 3350 5834 5f52  IGEN_GEBP_3PX4_R
+0000ee10: 4547 4953 5445 525f 414c 4c4f 435f 574f  EGISTER_ALLOC_WO
+0000ee20: 524b 4152 4f55 4e44 205c 0a20 2020 2020  RKAROUND \.     
+0000ee30: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
+0000ee40: 6c6f 6164 5268 7328 626c 4220 2b20 2830  loadRhs(blB + (0
+0000ee50: 2b34 2a4b 2920 2a20 5472 6169 7473 3a3a  +4*K) * Traits::
+0000ee60: 5268 7350 726f 6772 6573 732c 2072 6873  RhsProgress, rhs
+0000ee70: 5f70 616e 656c 293b 2020 2020 205c 0a20  _panel);     \. 
+0000ee80: 2020 2020 2020 2020 2020 2020 2074 7261               tra
+0000ee90: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
+0000eea0: 5f70 616e 656c 2c20 4330 2c20 5430 2c20  _panel, C0, T0, 
+0000eeb0: 6669 783c 303e 293b 2020 2020 2020 2020  fix<0>);        
+0000eec0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000eed0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+0000eee0: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
+0000eef0: 2072 6873 5f70 616e 656c 2c20 4334 2c20   rhs_panel, C4, 
+0000ef00: 5430 2c20 6669 783c 303e 293b 2020 2020  T0, fix<0>);    
+0000ef10: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ef20: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
+0000ef30: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
+0000ef40: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
+0000ef50: 4338 2c20 5430 2c20 6669 783c 303e 293b  C8, T0, fix<0>);
+0000ef60: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000ef70: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
+0000ef80: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
+0000ef90: 7570 6461 7465 5268 7328 626c 4220 2b20  updateRhs(blB + 
+0000efa0: 2831 2b34 2a4b 2920 2a20 5472 6169 7473  (1+4*K) * Traits
+0000efb0: 3a3a 5268 7350 726f 6772 6573 732c 2072  ::RhsProgress, r
+0000efc0: 6873 5f70 616e 656c 293b 2020 205c 0a20  hs_panel);   \. 
+0000efd0: 2020 2020 2020 2020 2020 2020 2074 7261               tra
+0000efe0: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
+0000eff0: 5f70 616e 656c 2c20 4331 2c20 5430 2c20  _panel, C1, T0, 
+0000f000: 6669 783c 313e 293b 2020 2020 2020 2020  fix<1>);        
+0000f010: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f020: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+0000f030: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
+0000f040: 2072 6873 5f70 616e 656c 2c20 4335 2c20   rhs_panel, C5, 
+0000f050: 5430 2c20 6669 783c 313e 293b 2020 2020  T0, fix<1>);    
+0000f060: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f070: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
+0000f080: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
+0000f090: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
+0000f0a0: 4339 2c20 5430 2c20 6669 783c 313e 293b  C9, T0, fix<1>);
+0000f0b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f0c0: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
+0000f0d0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
+0000f0e0: 7570 6461 7465 5268 7328 626c 4220 2b20  updateRhs(blB + 
+0000f0f0: 2832 2b34 2a4b 2920 2a20 5472 6169 7473  (2+4*K) * Traits
+0000f100: 3a3a 5268 7350 726f 6772 6573 732c 2072  ::RhsProgress, r
+0000f110: 6873 5f70 616e 656c 293b 2020 205c 0a20  hs_panel);   \. 
+0000f120: 2020 2020 2020 2020 2020 2020 2074 7261               tra
+0000f130: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
+0000f140: 5f70 616e 656c 2c20 4332 2c20 5430 2c20  _panel, C2, T0, 
+0000f150: 6669 783c 323e 293b 2020 2020 2020 2020  fix<2>);        
+0000f160: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f170: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+0000f180: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
+0000f190: 2072 6873 5f70 616e 656c 2c20 4336 2c20   rhs_panel, C6, 
+0000f1a0: 5430 2c20 6669 783c 323e 293b 2020 2020  T0, fix<2>);    
+0000f1b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f1c0: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
+0000f1d0: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
+0000f1e0: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
+0000f1f0: 4331 302c 2054 302c 2066 6978 3c32 3e29  C10, T0, fix<2>)
+0000f200: 3b20 2020 2020 2020 2020 2020 2020 2020  ;               
+0000f210: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
+0000f220: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
+0000f230: 7570 6461 7465 5268 7328 626c 4220 2b20  updateRhs(blB + 
+0000f240: 2833 2b34 2a4b 2920 2a20 5472 6169 7473  (3+4*K) * Traits
+0000f250: 3a3a 5268 7350 726f 6772 6573 732c 2072  ::RhsProgress, r
+0000f260: 6873 5f70 616e 656c 293b 2020 205c 0a20  hs_panel);   \. 
+0000f270: 2020 2020 2020 2020 2020 2020 2074 7261               tra
+0000f280: 6974 732e 6d61 6464 2841 302c 2072 6873  its.madd(A0, rhs
+0000f290: 5f70 616e 656c 2c20 4333 2c20 5430 2c20  _panel, C3, T0, 
+0000f2a0: 6669 783c 333e 293b 2020 2020 2020 2020  fix<3>);        
+0000f2b0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f2c0: 205c 0a20 2020 2020 2020 2020 2020 2020   \.             
+0000f2d0: 2074 7261 6974 732e 6d61 6464 2841 312c   traits.madd(A1,
+0000f2e0: 2072 6873 5f70 616e 656c 2c20 4337 2c20   rhs_panel, C7, 
+0000f2f0: 5430 2c20 6669 783c 333e 293b 2020 2020  T0, fix<3>);    
+0000f300: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0000f310: 2020 2020 205c 0a20 2020 2020 2020 2020       \.         
+0000f320: 2020 2020 2074 7261 6974 732e 6d61 6464       traits.madd
+0000f330: 2841 322c 2072 6873 5f70 616e 656c 2c20  (A2, rhs_panel, 
+0000f340: 4331 312c 2054 302c 2066 6978 3c33 3e29  C11, T0, fix<3>)
+0000f350: 3b20 2020 2020 2020 2020 2020 2020 2020  ;               
+0000f360: 2020 2020 2020 2020 205c 0a20 2020 2020           \.     
+0000f370: 2020 2020 2020 2020 2045 4947 454e 5f41           EIGEN_A
+0000f380: 534d 5f43 4f4d 4d45 4e54 2822 656e 6420  SM_COMMENT("end 
+0000f390: 7374 6570 206f 6620 6765 6270 206d 6963  step of gebp mic
+0000f3a0: 726f 206b 6572 6e65 6c20 3370 5834 2229  ro kernel 3pX4")
+0000f3b0: 3b20 2020 2020 2020 2020 2020 205c 0a20  ;            \. 
+0000f3c0: 2020 2020 2020 2020 2020 207d 2077 6869             } whi
+0000f3d0: 6c65 2028 6661 6c73 6529 0a0a 2020 2020  le (false)..    
+0000f3e0: 2020 2020 2020 2020 696e 7465 726e 616c          internal
+0000f3f0: 3a3a 7072 6566 6574 6368 2862 6c42 293b  ::prefetch(blB);
+0000f400: 0a20 2020 2020 2020 2020 2020 2045 4947  .            EIG
+0000f410: 454e 5f47 4542 505f 4f4e 4553 5445 5028  EN_GEBP_ONESTEP(
+0000f420: 3029 3b0a 2020 2020 2020 2020 2020 2020  0);.            
+0000f430: 4549 4745 4e5f 4745 4250 5f4f 4e45 5354  EIGEN_GEBP_ONEST
+0000f440: 4550 2831 293b 0a20 2020 2020 2020 2020  EP(1);.         
+0000f450: 2020 2045 4947 454e 5f47 4542 505f 4f4e     EIGEN_GEBP_ON
+0000f460: 4553 5445 5028 3229 3b0a 2020 2020 2020  ESTEP(2);.      
+0000f470: 2020 2020 2020 4549 4745 4e5f 4745 4250        EIGEN_GEBP
+0000f480: 5f4f 4e45 5354 4550 2833 293b 0a20 2020  _ONESTEP(3);.   
+0000f490: 2020 2020 2020 2020 2045 4947 454e 5f47           EIGEN_G
+0000f4a0: 4542 505f 4f4e 4553 5445 5028 3429 3b0a  EBP_ONESTEP(4);.
+0000f4b0: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
+0000f4c0: 4e5f 4745 4250 5f4f 4e45 5354 4550 2835  N_GEBP_ONESTEP(5
+0000f4d0: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
+0000f4e0: 4947 454e 5f47 4542 505f 4f4e 4553 5445  IGEN_GEBP_ONESTE
+0000f4f0: 5028 3629 3b0a 2020 2020 2020 2020 2020  P(6);.          
+0000f500: 2020 4549 4745 4e5f 4745 4250 5f4f 4e45    EIGEN_GEBP_ONE
+0000f510: 5354 4550 2837 293b 0a0a 2020 2020 2020  STEP(7);..      
+0000f520: 2020 2020 2020 626c 4220 2b3d 2070 6b2a        blB += pk*
+0000f530: 342a 5268 7350 726f 6772 6573 733b 0a20  4*RhsProgress;. 
+0000f540: 2020 2020 2020 2020 2020 2062 6c41 202b             blA +
+0000f550: 3d20 706b 2a33 2a54 7261 6974 733a 3a4c  = pk*3*Traits::L
+0000f560: 6873 5072 6f67 7265 7373 3b0a 0a20 2020  hsProgress;..   
+0000f570: 2020 2020 2020 2020 2045 4947 454e 5f41           EIGEN_A
+0000f580: 534d 5f43 4f4d 4d45 4e54 2822 656e 6420  SM_COMMENT("end 
+0000f590: 6765 6270 206d 6963 726f 206b 6572 6e65  gebp micro kerne
+0000f5a0: 6c20 3370 5834 2229 3b0a 2020 2020 2020  l 3pX4");.      
+0000f5b0: 2020 2020 7d0a 2020 2020 2020 2020 2020      }.          
+0000f5c0: 2f2f 2070 726f 6365 7373 2072 656d 6169  // process remai
+0000f5d0: 6e69 6e67 2070 6565 6c65 6420 6c6f 6f70  ning peeled loop
+0000f5e0: 0a20 2020 2020 2020 2020 2066 6f72 2849  .          for(I
+0000f5f0: 6e64 6578 206b 3d70 6565 6c65 645f 6b63  ndex k=peeled_kc
+0000f600: 3b20 6b3c 6465 7074 683b 206b 2b2b 290a  ; k<depth; k++).
+0000f610: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
+0000f620: 2020 2020 2020 2020 5268 7350 616e 656c          RhsPanel
+0000f630: 3135 2072 6873 5f70 616e 656c 3b0a 2020  15 rhs_panel;.  
+0000f640: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
+0000f650: 6b65 7420 5430 3b0a 2020 2020 2020 2020  ket T0;.        
+0000f660: 2020 2020 4c68 7350 6163 6b65 7420 4132      LhsPacket A2
+0000f670: 3b0a 2020 2020 2020 2020 2020 2020 4549  ;.            EI
+0000f680: 4745 4e5f 4745 4250 5f4f 4e45 5354 4550  GEN_GEBP_ONESTEP
+0000f690: 2830 293b 0a20 2020 2020 2020 2020 2020  (0);.           
+0000f6a0: 2062 6c42 202b 3d20 342a 5268 7350 726f   blB += 4*RhsPro
+0000f6b0: 6772 6573 733b 0a20 2020 2020 2020 2020  gress;.         
+0000f6c0: 2020 2062 6c41 202b 3d20 332a 5472 6169     blA += 3*Trai
+0000f6d0: 7473 3a3a 4c68 7350 726f 6772 6573 733b  ts::LhsProgress;
+0000f6e0: 0a20 2020 2020 2020 2020 207d 0a0a 2375  .          }..#u
+0000f6f0: 6e64 6566 2045 4947 454e 5f47 4542 505f  ndef EIGEN_GEBP_
+0000f700: 4f4e 4553 5445 500a 0a20 2020 2020 2020  ONESTEP..       
+0000f710: 2020 2052 6573 5061 636b 6574 2052 302c     ResPacket R0,
+0000f720: 2052 312c 2052 323b 0a20 2020 2020 2020   R1, R2;.       
+0000f730: 2020 2052 6573 5061 636b 6574 2061 6c70     ResPacket alp
+0000f740: 6861 7620 3d20 7073 6574 313c 5265 7350  hav = pset1<ResP
+0000f750: 6163 6b65 743e 2861 6c70 6861 293b 0a0a  acket>(alpha);..
+0000f760: 2020 2020 2020 2020 2020 5230 203d 2072            R0 = r
+0000f770: 302e 7465 6d70 6c61 7465 206c 6f61 6450  0.template loadP
+0000f780: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
+0000f790: 2830 202a 2054 7261 6974 733a 3a52 6573  (0 * Traits::Res
+0000f7a0: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
+0000f7b0: 2020 2020 2020 2052 3120 3d20 7230 2e74         R1 = r0.t
+0000f7c0: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+0000f7d0: 6574 3c52 6573 5061 636b 6574 3e28 3120  et<ResPacket>(1 
+0000f7e0: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
+0000f7f0: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
+0000f800: 2020 2020 5232 203d 2072 302e 7465 6d70      R2 = r0.temp
+0000f810: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
+0000f820: 5265 7350 6163 6b65 743e 2832 202a 2054  ResPacket>(2 * T
+0000f830: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
+0000f840: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
+0000f850: 2074 7261 6974 732e 6163 6328 4330 2c20   traits.acc(C0, 
+0000f860: 616c 7068 6176 2c20 5230 293b 0a20 2020  alphav, R0);.   
+0000f870: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
+0000f880: 6328 4334 2c20 616c 7068 6176 2c20 5231  c(C4, alphav, R1
+0000f890: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
+0000f8a0: 6974 732e 6163 6328 4338 2c20 616c 7068  its.acc(C8, alph
+0000f8b0: 6176 2c20 5232 293b 0a20 2020 2020 2020  av, R2);.       
+0000f8c0: 2020 2072 302e 7374 6f72 6550 6163 6b65     r0.storePacke
+0000f8d0: 7428 3020 2a20 5472 6169 7473 3a3a 5265  t(0 * Traits::Re
+0000f8e0: 7350 6163 6b65 7453 697a 652c 2052 3029  sPacketSize, R0)
+0000f8f0: 3b0a 2020 2020 2020 2020 2020 7230 2e73  ;.          r0.s
+0000f900: 746f 7265 5061 636b 6574 2831 202a 2054  torePacket(1 * T
+0000f910: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
+0000f920: 5369 7a65 2c20 5231 293b 0a20 2020 2020  Size, R1);.     
+0000f930: 2020 2020 2072 302e 7374 6f72 6550 6163       r0.storePac
+0000f940: 6b65 7428 3220 2a20 5472 6169 7473 3a3a  ket(2 * Traits::
+0000f950: 5265 7350 6163 6b65 7453 697a 652c 2052  ResPacketSize, R
+0000f960: 3229 3b0a 0a20 2020 2020 2020 2020 2052  2);..          R
+0000f970: 3020 3d20 7231 2e74 656d 706c 6174 6520  0 = r1.template 
+0000f980: 6c6f 6164 5061 636b 6574 3c52 6573 5061  loadPacket<ResPa
+0000f990: 636b 6574 3e28 3020 2a20 5472 6169 7473  cket>(0 * Traits
+0000f9a0: 3a3a 5265 7350 6163 6b65 7453 697a 6529  ::ResPacketSize)
+0000f9b0: 3b0a 2020 2020 2020 2020 2020 5231 203d  ;.          R1 =
+0000f9c0: 2072 312e 7465 6d70 6c61 7465 206c 6f61   r1.template loa
+0000f9d0: 6450 6163 6b65 743c 5265 7350 6163 6b65  dPacket<ResPacke
+0000f9e0: 743e 2831 202a 2054 7261 6974 733a 3a52  t>(1 * Traits::R
+0000f9f0: 6573 5061 636b 6574 5369 7a65 293b 0a20  esPacketSize);. 
+0000fa00: 2020 2020 2020 2020 2052 3220 3d20 7231           R2 = r1
+0000fa10: 2e74 656d 706c 6174 6520 6c6f 6164 5061  .template loadPa
+0000fa20: 636b 6574 3c52 6573 5061 636b 6574 3e28  cket<ResPacket>(
+0000fa30: 3220 2a20 5472 6169 7473 3a3a 5265 7350  2 * Traits::ResP
+0000fa40: 6163 6b65 7453 697a 6529 3b0a 2020 2020  acketSize);.    
+0000fa50: 2020 2020 2020 7472 6169 7473 2e61 6363        traits.acc
+0000fa60: 2843 312c 2061 6c70 6861 762c 2052 3029  (C1, alphav, R0)
+0000fa70: 3b0a 2020 2020 2020 2020 2020 7472 6169  ;.          trai
+0000fa80: 7473 2e61 6363 2843 352c 2061 6c70 6861  ts.acc(C5, alpha
+0000fa90: 762c 2052 3129 3b0a 2020 2020 2020 2020  v, R1);.        
+0000faa0: 2020 7472 6169 7473 2e61 6363 2843 392c    traits.acc(C9,
+0000fab0: 2061 6c70 6861 762c 2052 3229 3b0a 2020   alphav, R2);.  
+0000fac0: 2020 2020 2020 2020 7231 2e73 746f 7265          r1.store
+0000fad0: 5061 636b 6574 2830 202a 2054 7261 6974  Packet(0 * Trait
+0000fae0: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
+0000faf0: 2c20 5230 293b 0a20 2020 2020 2020 2020  , R0);.         
+0000fb00: 2072 312e 7374 6f72 6550 6163 6b65 7428   r1.storePacket(
+0000fb10: 3120 2a20 5472 6169 7473 3a3a 5265 7350  1 * Traits::ResP
+0000fb20: 6163 6b65 7453 697a 652c 2052 3129 3b0a  acketSize, R1);.
+0000fb30: 2020 2020 2020 2020 2020 7231 2e73 746f            r1.sto
+0000fb40: 7265 5061 636b 6574 2832 202a 2054 7261  rePacket(2 * Tra
+0000fb50: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
+0000fb60: 7a65 2c20 5232 293b 0a0a 2020 2020 2020  ze, R2);..      
+0000fb70: 2020 2020 5230 203d 2072 322e 7465 6d70      R0 = r2.temp
+0000fb80: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
+0000fb90: 5265 7350 6163 6b65 743e 2830 202a 2054  ResPacket>(0 * T
+0000fba0: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
+0000fbb0: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
+0000fbc0: 2052 3120 3d20 7232 2e74 656d 706c 6174   R1 = r2.templat
+0000fbd0: 6520 6c6f 6164 5061 636b 6574 3c52 6573  e loadPacket<Res
+0000fbe0: 5061 636b 6574 3e28 3120 2a20 5472 6169  Packet>(1 * Trai
+0000fbf0: 7473 3a3a 5265 7350 6163 6b65 7453 697a  ts::ResPacketSiz
+0000fc00: 6529 3b0a 2020 2020 2020 2020 2020 5232  e);.          R2
+0000fc10: 203d 2072 322e 7465 6d70 6c61 7465 206c   = r2.template l
+0000fc20: 6f61 6450 6163 6b65 743c 5265 7350 6163  oadPacket<ResPac
+0000fc30: 6b65 743e 2832 202a 2054 7261 6974 733a  ket>(2 * Traits:
+0000fc40: 3a52 6573 5061 636b 6574 5369 7a65 293b  :ResPacketSize);
+0000fc50: 0a20 2020 2020 2020 2020 2074 7261 6974  .          trait
+0000fc60: 732e 6163 6328 4332 2c20 616c 7068 6176  s.acc(C2, alphav
+0000fc70: 2c20 5230 293b 0a20 2020 2020 2020 2020  , R0);.         
+0000fc80: 2074 7261 6974 732e 6163 6328 4336 2c20   traits.acc(C6, 
+0000fc90: 616c 7068 6176 2c20 5231 293b 0a20 2020  alphav, R1);.   
+0000fca0: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
+0000fcb0: 6328 4331 302c 2061 6c70 6861 762c 2052  c(C10, alphav, R
+0000fcc0: 3229 3b0a 2020 2020 2020 2020 2020 7232  2);.          r2
+0000fcd0: 2e73 746f 7265 5061 636b 6574 2830 202a  .storePacket(0 *
+0000fce0: 2054 7261 6974 733a 3a52 6573 5061 636b   Traits::ResPack
+0000fcf0: 6574 5369 7a65 2c20 5230 293b 0a20 2020  etSize, R0);.   
+0000fd00: 2020 2020 2020 2072 322e 7374 6f72 6550         r2.storeP
+0000fd10: 6163 6b65 7428 3120 2a20 5472 6169 7473  acket(1 * Traits
+0000fd20: 3a3a 5265 7350 6163 6b65 7453 697a 652c  ::ResPacketSize,
+0000fd30: 2052 3129 3b0a 2020 2020 2020 2020 2020   R1);.          
+0000fd40: 7232 2e73 746f 7265 5061 636b 6574 2832  r2.storePacket(2
+0000fd50: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
+0000fd60: 636b 6574 5369 7a65 2c20 5232 293b 0a0a  cketSize, R2);..
+0000fd70: 2020 2020 2020 2020 2020 5230 203d 2072            R0 = r
+0000fd80: 332e 7465 6d70 6c61 7465 206c 6f61 6450  3.template loadP
+0000fd90: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
+0000fda0: 2830 202a 2054 7261 6974 733a 3a52 6573  (0 * Traits::Res
+0000fdb0: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
+0000fdc0: 2020 2020 2020 2052 3120 3d20 7233 2e74         R1 = r3.t
+0000fdd0: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+0000fde0: 6574 3c52 6573 5061 636b 6574 3e28 3120  et<ResPacket>(1 
+0000fdf0: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
+0000fe00: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
+0000fe10: 2020 2020 5232 203d 2072 332e 7465 6d70      R2 = r3.temp
+0000fe20: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
+0000fe30: 5265 7350 6163 6b65 743e 2832 202a 2054  ResPacket>(2 * T
+0000fe40: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
+0000fe50: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
+0000fe60: 2074 7261 6974 732e 6163 6328 4333 2c20   traits.acc(C3, 
+0000fe70: 616c 7068 6176 2c20 5230 293b 0a20 2020  alphav, R0);.   
+0000fe80: 2020 2020 2020 2074 7261 6974 732e 6163         traits.ac
+0000fe90: 6328 4337 2c20 616c 7068 6176 2c20 5231  c(C7, alphav, R1
+0000fea0: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
+0000feb0: 6974 732e 6163 6328 4331 312c 2061 6c70  its.acc(C11, alp
+0000fec0: 6861 762c 2052 3229 3b0a 2020 2020 2020  hav, R2);.      
+0000fed0: 2020 2020 7233 2e73 746f 7265 5061 636b      r3.storePack
+0000fee0: 6574 2830 202a 2054 7261 6974 733a 3a52  et(0 * Traits::R
+0000fef0: 6573 5061 636b 6574 5369 7a65 2c20 5230  esPacketSize, R0
+0000ff00: 293b 0a20 2020 2020 2020 2020 2072 332e  );.          r3.
+0000ff10: 7374 6f72 6550 6163 6b65 7428 3120 2a20  storePacket(1 * 
+0000ff20: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
+0000ff30: 7453 697a 652c 2052 3129 3b0a 2020 2020  tSize, R1);.    
+0000ff40: 2020 2020 2020 7233 2e73 746f 7265 5061        r3.storePa
+0000ff50: 636b 6574 2832 202a 2054 7261 6974 733a  cket(2 * Traits:
+0000ff60: 3a52 6573 5061 636b 6574 5369 7a65 2c20  :ResPacketSize, 
+0000ff70: 5232 293b 2020 2020 2020 2020 2020 0a20  R2);          . 
+0000ff80: 2020 2020 2020 2020 207d 0a20 2020 2020           }.     
+0000ff90: 2020 207d 0a0a 2020 2020 2020 2020 2f2f     }..        //
+0000ffa0: 2044 6561 6c20 7769 7468 2072 656d 6169   Deal with remai
+0000ffb0: 6e69 6e67 2063 6f6c 756d 6e73 206f 6620  ning columns of 
+0000ffc0: 7468 6520 7268 730a 2020 2020 2020 2020  the rhs.        
+0000ffd0: 666f 7228 496e 6465 7820 6a32 3d70 6163  for(Index j2=pac
+0000ffe0: 6b65 745f 636f 6c73 343b 206a 323c 636f  ket_cols4; j2<co
+0000fff0: 6c73 3b20 6a32 2b2b 290a 2020 2020 2020  ls; j2++).      
+00010000: 2020 7b0a 2020 2020 2020 2020 2020 666f    {.          fo
+00010010: 7228 496e 6465 7820 693d 6931 3b20 693c  r(Index i=i1; i<
+00010020: 6163 7475 616c 5f70 616e 656c 5f65 6e64  actual_panel_end
+00010030: 3b20 692b 3d33 2a4c 6873 5072 6f67 7265  ; i+=3*LhsProgre
+00010040: 7373 290a 2020 2020 2020 2020 2020 7b0a  ss).          {.
+00010050: 2020 2020 2020 2020 2020 2f2f 204f 6e65            // One
+00010060: 2063 6f6c 756d 6e20 6174 2061 2074 696d   column at a tim
+00010070: 650a 2020 2020 2020 2020 2020 636f 6e73  e.          cons
+00010080: 7420 4c68 7353 6361 6c61 722a 2062 6c41  t LhsScalar* blA
+00010090: 203d 2026 626c 6f63 6b41 5b69 2a73 7472   = &blockA[i*str
+000100a0: 6964 6541 2b6f 6666 7365 7441 2a28 332a  ideA+offsetA*(3*
+000100b0: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
+000100c0: 6573 7329 5d3b 0a20 2020 2020 2020 2020  ess)];.         
+000100d0: 2070 7265 6665 7463 6828 2662 6c41 5b30   prefetch(&blA[0
+000100e0: 5d29 3b0a 0a20 2020 2020 2020 2020 202f  ]);..          /
+000100f0: 2f20 6765 7473 2072 6573 2062 6c6f 636b  / gets res block
+00010100: 2061 7320 7265 6769 7374 6572 0a20 2020   as register.   
+00010110: 2020 2020 2020 2041 6363 5061 636b 6574         AccPacket
+00010120: 2043 302c 2043 342c 2043 383b 0a20 2020   C0, C4, C8;.   
+00010130: 2020 2020 2020 2074 7261 6974 732e 696e         traits.in
+00010140: 6974 4163 6328 4330 293b 0a20 2020 2020  itAcc(C0);.     
+00010150: 2020 2020 2074 7261 6974 732e 696e 6974       traits.init
+00010160: 4163 6328 4334 293b 0a20 2020 2020 2020  Acc(C4);.       
+00010170: 2020 2074 7261 6974 732e 696e 6974 4163     traits.initAc
+00010180: 6328 4338 293b 0a0a 2020 2020 2020 2020  c(C8);..        
+00010190: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
+000101a0: 3020 3d20 7265 732e 6765 744c 696e 6561  0 = res.getLinea
+000101b0: 724d 6170 7065 7228 692c 206a 3229 3b0a  rMapper(i, j2);.
+000101c0: 2020 2020 2020 2020 2020 7230 2e70 7265            r0.pre
+000101d0: 6665 7463 6828 3029 3b0a 0a20 2020 2020  fetch(0);..     
+000101e0: 2020 2020 202f 2f20 7065 7266 6f72 6d73       // performs
+000101f0: 2022 696e 6e65 7222 2070 726f 6475 6374   "inner" product
+00010200: 730a 2020 2020 2020 2020 2020 636f 6e73  s.          cons
+00010210: 7420 5268 7353 6361 6c61 722a 2062 6c42  t RhsScalar* blB
+00010220: 203d 2026 626c 6f63 6b42 5b6a 322a 7374   = &blockB[j2*st
+00010230: 7269 6465 422b 6f66 6673 6574 425d 3b0a  rideB+offsetB];.
+00010240: 2020 2020 2020 2020 2020 4c68 7350 6163            LhsPac
+00010250: 6b65 7420 4130 2c20 4131 2c20 4132 3b0a  ket A0, A1, A2;.
+00010260: 2020 2020 2020 2020 2020 0a20 2020 2020            .     
+00010270: 2020 2020 2066 6f72 2849 6e64 6578 206b       for(Index k
+00010280: 3d30 3b20 6b3c 7065 656c 6564 5f6b 633b  =0; k<peeled_kc;
+00010290: 206b 2b3d 706b 290a 2020 2020 2020 2020   k+=pk).        
+000102a0: 2020 7b0a 2020 2020 2020 2020 2020 2020    {.            
+000102b0: 4549 4745 4e5f 4153 4d5f 434f 4d4d 454e  EIGEN_ASM_COMMEN
+000102c0: 5428 2262 6567 696e 2067 6562 7020 6d69  T("begin gebp mi
+000102d0: 6372 6f20 6b65 726e 656c 2033 7058 3122  cro kernel 3pX1"
+000102e0: 293b 0a20 2020 2020 2020 2020 2020 2052  );.            R
+000102f0: 6873 5061 636b 6574 2042 5f30 3b0a 2364  hsPacket B_0;.#d
+00010300: 6566 696e 6520 4549 4745 4e5f 4745 4247  efine EIGEN_GEBG
+00010310: 505f 4f4e 4553 5445 5028 4b29 2020 2020  P_ONESTEP(K)    
+00010320: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010330: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010340: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010350: 5c0a 2020 2020 2020 2020 2020 2020 646f  \.            do
+00010360: 207b 2020 2020 2020 2020 2020 2020 2020   {              
+00010370: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010380: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010390: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000103a0: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
+000103b0: 2020 2020 4549 4745 4e5f 4153 4d5f 434f      EIGEN_ASM_CO
+000103c0: 4d4d 454e 5428 2262 6567 696e 2073 7465  MMENT("begin ste
+000103d0: 7020 6f66 2067 6562 7020 6d69 6372 6f20  p of gebp micro 
+000103e0: 6b65 726e 656c 2033 7058 3122 293b 2020  kernel 3pX1");  
+000103f0: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
+00010400: 2020 2020 2020 2020 4549 4745 4e5f 4153          EIGEN_AS
+00010410: 4d5f 434f 4d4d 454e 5428 224e 6f74 653a  M_COMMENT("Note:
+00010420: 2074 6865 7365 2061 736d 2063 6f6d 6d65   these asm comme
+00010430: 6e74 7320 776f 726b 2061 726f 756e 6420  nts work around 
+00010440: 6275 6720 3933 3521 2229 3b20 5c0a 2020  bug 935!"); \.  
+00010450: 2020 2020 2020 2020 2020 2020 7472 6169              trai
+00010460: 7473 2e6c 6f61 644c 6873 2826 626c 415b  ts.loadLhs(&blA[
+00010470: 2830 202b 2033 202a 204b 2920 2a20 4c68  (0 + 3 * K) * Lh
+00010480: 7350 726f 6772 6573 735d 2c20 4130 293b  sProgress], A0);
+00010490: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000104a0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+000104b0: 7472 6169 7473 2e6c 6f61 644c 6873 2826  traits.loadLhs(&
+000104c0: 626c 415b 2831 202b 2033 202a 204b 2920  blA[(1 + 3 * K) 
+000104d0: 2a20 4c68 7350 726f 6772 6573 735d 2c20  * LhsProgress], 
+000104e0: 4131 293b 2020 2020 2020 2020 2020 2020  A1);            
+000104f0: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
+00010500: 2020 2020 7472 6169 7473 2e6c 6f61 644c      traits.loadL
+00010510: 6873 2826 626c 415b 2832 202b 2033 202a  hs(&blA[(2 + 3 *
+00010520: 204b 2920 2a20 4c68 7350 726f 6772 6573   K) * LhsProgres
+00010530: 735d 2c20 4132 293b 2020 2020 2020 2020  s], A2);        
+00010540: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
+00010550: 2020 2020 2020 2020 7472 6169 7473 2e6c          traits.l
+00010560: 6f61 6452 6873 2826 626c 425b 2830 202b  oadRhs(&blB[(0 +
+00010570: 204b 2920 2a20 5268 7350 726f 6772 6573   K) * RhsProgres
+00010580: 735d 2c20 425f 3029 3b20 2020 2020 2020  s], B_0);       
+00010590: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+000105a0: 2020 2020 2020 2020 2020 2020 7472 6169              trai
+000105b0: 7473 2e6d 6164 6428 4130 2c20 425f 302c  ts.madd(A0, B_0,
+000105c0: 2043 302c 2042 5f30 2c20 6669 783c 303e   C0, B_0, fix<0>
+000105d0: 293b 2020 2020 2020 2020 2020 2020 2020  );              
+000105e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000105f0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00010600: 7472 6169 7473 2e6d 6164 6428 4131 2c20  traits.madd(A1, 
+00010610: 425f 302c 2043 342c 2042 5f30 2c20 6669  B_0, C4, B_0, fi
+00010620: 783c 303e 293b 2020 2020 2020 2020 2020  x<0>);          
+00010630: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010640: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
+00010650: 2020 2020 7472 6169 7473 2e6d 6164 6428      traits.madd(
+00010660: 4132 2c20 425f 302c 2043 382c 2042 5f30  A2, B_0, C8, B_0
+00010670: 2c20 6669 783c 303e 293b 2020 2020 2020  , fix<0>);      
+00010680: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00010690: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
+000106a0: 2020 2020 2020 2020 4549 4745 4e5f 4153          EIGEN_AS
+000106b0: 4d5f 434f 4d4d 454e 5428 2265 6e64 2073  M_COMMENT("end s
+000106c0: 7465 7020 6f66 2067 6562 7020 6d69 6372  tep of gebp micr
+000106d0: 6f20 6b65 726e 656c 2033 7058 3122 293b  o kernel 3pX1");
+000106e0: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+000106f0: 2020 2020 2020 2020 2020 7d20 7768 696c            } whil
+00010700: 6520 2866 616c 7365 290a 0a20 2020 2020  e (false)..     
+00010710: 2020 2020 2020 2045 4947 454e 5f47 4542         EIGEN_GEB
+00010720: 4750 5f4f 4e45 5354 4550 2830 293b 0a20  GP_ONESTEP(0);. 
+00010730: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+00010740: 5f47 4542 4750 5f4f 4e45 5354 4550 2831  _GEBGP_ONESTEP(1
+00010750: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
+00010760: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
+00010770: 4550 2832 293b 0a20 2020 2020 2020 2020  EP(2);.         
+00010780: 2020 2045 4947 454e 5f47 4542 4750 5f4f     EIGEN_GEBGP_O
+00010790: 4e45 5354 4550 2833 293b 0a20 2020 2020  NESTEP(3);.     
+000107a0: 2020 2020 2020 2045 4947 454e 5f47 4542         EIGEN_GEB
+000107b0: 4750 5f4f 4e45 5354 4550 2834 293b 0a20  GP_ONESTEP(4);. 
+000107c0: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+000107d0: 5f47 4542 4750 5f4f 4e45 5354 4550 2835  _GEBGP_ONESTEP(5
+000107e0: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
+000107f0: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
+00010800: 4550 2836 293b 0a20 2020 2020 2020 2020  EP(6);.         
+00010810: 2020 2045 4947 454e 5f47 4542 4750 5f4f     EIGEN_GEBGP_O
+00010820: 4e45 5354 4550 2837 293b 0a0a 2020 2020  NESTEP(7);..    
+00010830: 2020 2020 2020 2020 626c 4220 2b3d 2069          blB += i
+00010840: 6e74 2870 6b29 202a 2069 6e74 2852 6873  nt(pk) * int(Rhs
+00010850: 5072 6f67 7265 7373 293b 0a20 2020 2020  Progress);.     
+00010860: 2020 2020 2020 2062 6c41 202b 3d20 696e         blA += in
+00010870: 7428 706b 2920 2a20 3320 2a20 696e 7428  t(pk) * 3 * int(
+00010880: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
+00010890: 6573 7329 3b0a 0a20 2020 2020 2020 2020  ess);..         
+000108a0: 2020 2045 4947 454e 5f41 534d 5f43 4f4d     EIGEN_ASM_COM
+000108b0: 4d45 4e54 2822 656e 6420 6765 6270 206d  MENT("end gebp m
+000108c0: 6963 726f 206b 6572 6e65 6c20 3370 5831  icro kernel 3pX1
+000108d0: 2229 3b0a 2020 2020 2020 2020 2020 7d0a  ");.          }.
+000108e0: 0a20 2020 2020 2020 2020 202f 2f20 7072  .          // pr
+000108f0: 6f63 6573 7320 7265 6d61 696e 696e 6720  ocess remaining 
+00010900: 7065 656c 6564 206c 6f6f 700a 2020 2020  peeled loop.    
+00010910: 2020 2020 2020 666f 7228 496e 6465 7820        for(Index 
+00010920: 6b3d 7065 656c 6564 5f6b 633b 206b 3c64  k=peeled_kc; k<d
+00010930: 6570 7468 3b20 6b2b 2b29 0a20 2020 2020  epth; k++).     
+00010940: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
+00010950: 2020 2052 6873 5061 636b 6574 2042 5f30     RhsPacket B_0
+00010960: 3b0a 2020 2020 2020 2020 2020 2020 4549  ;.            EI
+00010970: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+00010980: 5028 3029 3b0a 2020 2020 2020 2020 2020  P(0);.          
+00010990: 2020 626c 4220 2b3d 2052 6873 5072 6f67    blB += RhsProg
+000109a0: 7265 7373 3b0a 2020 2020 2020 2020 2020  ress;.          
+000109b0: 2020 626c 4120 2b3d 2033 2a54 7261 6974    blA += 3*Trait
+000109c0: 733a 3a4c 6873 5072 6f67 7265 7373 3b0a  s::LhsProgress;.
+000109d0: 2020 2020 2020 2020 2020 7d0a 2375 6e64            }.#und
+000109e0: 6566 2045 4947 454e 5f47 4542 4750 5f4f  ef EIGEN_GEBGP_O
+000109f0: 4e45 5354 4550 0a20 2020 2020 2020 2020  NESTEP.         
+00010a00: 2052 6573 5061 636b 6574 2052 302c 2052   ResPacket R0, R
+00010a10: 312c 2052 323b 0a20 2020 2020 2020 2020  1, R2;.         
+00010a20: 2052 6573 5061 636b 6574 2061 6c70 6861   ResPacket alpha
+00010a30: 7620 3d20 7073 6574 313c 5265 7350 6163  v = pset1<ResPac
+00010a40: 6b65 743e 2861 6c70 6861 293b 0a0a 2020  ket>(alpha);..  
+00010a50: 2020 2020 2020 2020 5230 203d 2072 302e          R0 = r0.
+00010a60: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
+00010a70: 6b65 743c 5265 7350 6163 6b65 743e 2830  ket<ResPacket>(0
+00010a80: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
+00010a90: 636b 6574 5369 7a65 293b 0a20 2020 2020  cketSize);.     
+00010aa0: 2020 2020 2052 3120 3d20 7230 2e74 656d       R1 = r0.tem
+00010ab0: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
+00010ac0: 3c52 6573 5061 636b 6574 3e28 3120 2a20  <ResPacket>(1 * 
+00010ad0: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
+00010ae0: 7453 697a 6529 3b0a 2020 2020 2020 2020  tSize);.        
+00010af0: 2020 5232 203d 2072 302e 7465 6d70 6c61    R2 = r0.templa
+00010b00: 7465 206c 6f61 6450 6163 6b65 743c 5265  te loadPacket<Re
+00010b10: 7350 6163 6b65 743e 2832 202a 2054 7261  sPacket>(2 * Tra
+00010b20: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
+00010b30: 7a65 293b 0a20 2020 2020 2020 2020 2074  ze);.          t
+00010b40: 7261 6974 732e 6163 6328 4330 2c20 616c  raits.acc(C0, al
+00010b50: 7068 6176 2c20 5230 293b 0a20 2020 2020  phav, R0);.     
+00010b60: 2020 2020 2074 7261 6974 732e 6163 6328       traits.acc(
+00010b70: 4334 2c20 616c 7068 6176 2c20 5231 293b  C4, alphav, R1);
+00010b80: 0a20 2020 2020 2020 2020 2074 7261 6974  .          trait
+00010b90: 732e 6163 6328 4338 2c20 616c 7068 6176  s.acc(C8, alphav
+00010ba0: 2c20 5232 293b 0a20 2020 2020 2020 2020  , R2);.         
+00010bb0: 2072 302e 7374 6f72 6550 6163 6b65 7428   r0.storePacket(
+00010bc0: 3020 2a20 5472 6169 7473 3a3a 5265 7350  0 * Traits::ResP
+00010bd0: 6163 6b65 7453 697a 652c 2052 3029 3b0a  acketSize, R0);.
+00010be0: 2020 2020 2020 2020 2020 7230 2e73 746f            r0.sto
+00010bf0: 7265 5061 636b 6574 2831 202a 2054 7261  rePacket(1 * Tra
+00010c00: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
+00010c10: 7a65 2c20 5231 293b 0a20 2020 2020 2020  ze, R1);.       
+00010c20: 2020 2072 302e 7374 6f72 6550 6163 6b65     r0.storePacke
+00010c30: 7428 3220 2a20 5472 6169 7473 3a3a 5265  t(2 * Traits::Re
+00010c40: 7350 6163 6b65 7453 697a 652c 2052 3229  sPacketSize, R2)
+00010c50: 3b20 2020 2020 2020 2020 200a 2020 2020  ;          .    
+00010c60: 2020 2020 2020 7d0a 2020 2020 2020 2020        }.        
+00010c70: 7d0a 2020 2020 2020 7d0a 2020 2020 7d0a  }.      }.    }.
+00010c80: 0a20 2020 202f 2f2d 2d2d 2d2d 2d2d 2d2d  .    //---------
+00010c90: 2d20 5072 6f63 6573 7320 3220 2a20 4c68  - Process 2 * Lh
+00010ca0: 7350 726f 6772 6573 7320 726f 7773 2061  sProgress rows a
+00010cb0: 7420 6f6e 6365 202d 2d2d 2d2d 2d2d 2d2d  t once ---------
+00010cc0: 2d0a 2020 2020 6966 286d 723e 3d32 2a54  -.    if(mr>=2*T
+00010cd0: 7261 6974 733a 3a4c 6873 5072 6f67 7265  raits::LhsProgre
+00010ce0: 7373 290a 2020 2020 7b0a 2020 2020 2020  ss).    {.      
+00010cf0: 636f 6e73 7420 496e 6465 7820 6c31 203d  const Index l1 =
+00010d00: 2064 6566 6175 6c74 4c31 4361 6368 6553   defaultL1CacheS
+00010d10: 697a 653b 202f 2f20 696e 2042 7974 6573  ize; // in Bytes
+00010d20: 2c20 544f 444f 2c20 6c31 2073 686f 756c  , TODO, l1 shoul
+00010d30: 6420 6265 2070 6173 7365 6420 746f 2074  d be passed to t
+00010d40: 6869 7320 6675 6e63 7469 6f6e 2e0a 2020  his function..  
+00010d50: 2020 2020 2f2f 2054 6865 206d 6178 2831      // The max(1
+00010d60: 2c20 2e2e 2e29 2068 6572 6520 6973 206e  , ...) here is n
+00010d70: 6565 6465 6420 6265 6361 7573 6520 7765  eeded because we
+00010d80: 206d 6179 2062 6520 7573 696e 6720 626c   may be using bl
+00010d90: 6f63 6b69 6e67 2070 6172 616d 7320 6c61  ocking params la
+00010da0: 7267 6572 2074 6861 6e20 7768 6174 206f  rger than what o
+00010db0: 7572 206b 6e6f 776e 206c 3120 6361 6368  ur known l1 cach
+00010dc0: 6520 7369 7a65 0a20 2020 2020 202f 2f20  e size.      // 
+00010dd0: 7375 6767 6573 7473 2077 6520 7368 6f75  suggests we shou
+00010de0: 6c64 2062 6520 7573 696e 673a 2065 6974  ld be using: eit
+00010df0: 6865 7220 6265 6361 7573 6520 6f75 7220  her because our 
+00010e00: 6b6e 6f77 6e20 6c31 2063 6163 6865 2073  known l1 cache s
+00010e10: 697a 6520 6973 2069 6e61 6363 7572 6174  ize is inaccurat
+00010e20: 6520 2865 2e67 2e20 6f6e 2041 6e64 726f  e (e.g. on Andro
+00010e30: 6964 2c20 7765 2063 616e 206f 6e6c 7920  id, we can only 
+00010e40: 6775 6573 7329 2c0a 2020 2020 2020 2f2f  guess),.      //
+00010e50: 206f 7220 6265 6361 7573 6520 7765 2061   or because we a
+00010e60: 7265 2074 6573 7469 6e67 2073 7065 6369  re testing speci
+00010e70: 6669 6320 626c 6f63 6b69 6e67 2073 697a  fic blocking siz
+00010e80: 6573 2e0a 2020 2020 2020 496e 6465 7820  es..      Index 
+00010e90: 6163 7475 616c 5f70 616e 656c 5f72 6f77  actual_panel_row
+00010ea0: 7320 3d20 2832 2a4c 6873 5072 6f67 7265  s = (2*LhsProgre
+00010eb0: 7373 2920 2a20 7374 643a 3a6d 6178 3c49  ss) * std::max<I
+00010ec0: 6e64 6578 3e28 312c 2820 286c 3120 2d20  ndex>(1,( (l1 - 
+00010ed0: 7369 7a65 6f66 2852 6573 5363 616c 6172  sizeof(ResScalar
+00010ee0: 292a 6d72 2a6e 7220 2d20 6465 7074 682a  )*mr*nr - depth*
+00010ef0: 6e72 2a73 697a 656f 6628 5268 7353 6361  nr*sizeof(RhsSca
+00010f00: 6c61 7229 2920 2f20 2864 6570 7468 202a  lar)) / (depth *
+00010f10: 2073 697a 656f 6628 4c68 7353 6361 6c61   sizeof(LhsScala
+00010f20: 7229 202a 2032 2a4c 6873 5072 6f67 7265  r) * 2*LhsProgre
+00010f30: 7373 2920 2929 3b0a 0a20 2020 2020 2066  ss) ));..      f
+00010f40: 6f72 2849 6e64 6578 2069 313d 7065 656c  or(Index i1=peel
+00010f50: 6564 5f6d 6333 3b20 6931 3c70 6565 6c65  ed_mc3; i1<peele
+00010f60: 645f 6d63 323b 2069 312b 3d61 6374 7561  d_mc2; i1+=actua
+00010f70: 6c5f 7061 6e65 6c5f 726f 7773 290a 2020  l_panel_rows).  
+00010f80: 2020 2020 7b0a 2020 2020 2020 2020 496e      {.        In
+00010f90: 6465 7820 6163 7475 616c 5f70 616e 656c  dex actual_panel
+00010fa0: 5f65 6e64 203d 2028 7374 643a 3a6d 696e  _end = (std::min
+00010fb0: 2928 6931 2b61 6374 7561 6c5f 7061 6e65  )(i1+actual_pane
+00010fc0: 6c5f 726f 7773 2c20 7065 656c 6564 5f6d  l_rows, peeled_m
+00010fd0: 6332 293b 0a20 2020 2020 2020 2066 6f72  c2);.        for
+00010fe0: 2849 6e64 6578 206a 323d 303b 206a 323c  (Index j2=0; j2<
+00010ff0: 7061 636b 6574 5f63 6f6c 7334 3b20 6a32  packet_cols4; j2
+00011000: 2b3d 6e72 290a 2020 2020 2020 2020 7b0a  +=nr).        {.
+00011010: 2020 2020 2020 2020 2020 666f 7228 496e            for(In
+00011020: 6465 7820 693d 6931 3b20 693c 6163 7475  dex i=i1; i<actu
+00011030: 616c 5f70 616e 656c 5f65 6e64 3b20 692b  al_panel_end; i+
+00011040: 3d32 2a4c 6873 5072 6f67 7265 7373 290a  =2*LhsProgress).
+00011050: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
+00011060: 2020 2020 2020 0a20 2020 2020 2020 2020        .         
+00011070: 202f 2f20 5765 2073 656c 6563 7465 6420   // We selected 
+00011080: 6120 322a 5472 6169 7473 3a3a 4c68 7350  a 2*Traits::LhsP
+00011090: 726f 6772 6573 7320 7820 6e72 206d 6963  rogress x nr mic
+000110a0: 726f 2062 6c6f 636b 206f 6620 7265 7320  ro block of res 
+000110b0: 7768 6963 6820 6973 2065 6e74 6972 656c  which is entirel
+000110c0: 790a 2020 2020 2020 2020 2020 2f2f 2073  y.          // s
+000110d0: 746f 7265 6420 696e 746f 2032 2078 206e  tored into 2 x n
+000110e0: 7220 7265 6769 7374 6572 732e 0a20 2020  r registers..   
+000110f0: 2020 2020 2020 200a 2020 2020 2020 2020         .        
+00011100: 2020 636f 6e73 7420 4c68 7353 6361 6c61    const LhsScala
+00011110: 722a 2062 6c41 203d 2026 626c 6f63 6b41  r* blA = &blockA
+00011120: 5b69 2a73 7472 6964 6541 2b6f 6666 7365  [i*strideA+offse
+00011130: 7441 2a28 322a 5472 6169 7473 3a3a 4c68  tA*(2*Traits::Lh
+00011140: 7350 726f 6772 6573 7329 5d3b 0a20 2020  sProgress)];.   
+00011150: 2020 2020 2020 2070 7265 6665 7463 6828         prefetch(
+00011160: 2662 6c41 5b30 5d29 3b0a 0a20 2020 2020  &blA[0]);..     
+00011170: 2020 2020 202f 2f20 6765 7473 2072 6573       // gets res
+00011180: 2062 6c6f 636b 2061 7320 7265 6769 7374   block as regist
+00011190: 6572 0a20 2020 2020 2020 2020 2041 6363  er.          Acc
+000111a0: 5061 636b 6574 2043 302c 2043 312c 2043  Packet C0, C1, C
+000111b0: 322c 2043 332c 0a20 2020 2020 2020 2020  2, C3,.         
+000111c0: 2020 2020 2020 2020 2020 2043 342c 2043             C4, C
+000111d0: 352c 2043 362c 2043 373b 0a20 2020 2020  5, C6, C7;.     
+000111e0: 2020 2020 2074 7261 6974 732e 696e 6974       traits.init
+000111f0: 4163 6328 4330 293b 2074 7261 6974 732e  Acc(C0); traits.
+00011200: 696e 6974 4163 6328 4331 293b 2074 7261  initAcc(C1); tra
+00011210: 6974 732e 696e 6974 4163 6328 4332 293b  its.initAcc(C2);
+00011220: 2074 7261 6974 732e 696e 6974 4163 6328   traits.initAcc(
+00011230: 4333 293b 0a20 2020 2020 2020 2020 2074  C3);.          t
+00011240: 7261 6974 732e 696e 6974 4163 6328 4334  raits.initAcc(C4
+00011250: 293b 2074 7261 6974 732e 696e 6974 4163  ); traits.initAc
+00011260: 6328 4335 293b 2074 7261 6974 732e 696e  c(C5); traits.in
+00011270: 6974 4163 6328 4336 293b 2074 7261 6974  itAcc(C6); trait
+00011280: 732e 696e 6974 4163 6328 4337 293b 0a0a  s.initAcc(C7);..
+00011290: 2020 2020 2020 2020 2020 4c69 6e65 6172            Linear
+000112a0: 4d61 7070 6572 2072 3020 3d20 7265 732e  Mapper r0 = res.
+000112b0: 6765 744c 696e 6561 724d 6170 7065 7228  getLinearMapper(
+000112c0: 692c 206a 3220 2b20 3029 3b0a 2020 2020  i, j2 + 0);.    
+000112d0: 2020 2020 2020 4c69 6e65 6172 4d61 7070        LinearMapp
+000112e0: 6572 2072 3120 3d20 7265 732e 6765 744c  er r1 = res.getL
+000112f0: 696e 6561 724d 6170 7065 7228 692c 206a  inearMapper(i, j
+00011300: 3220 2b20 3129 3b0a 2020 2020 2020 2020  2 + 1);.        
+00011310: 2020 4c69 6e65 6172 4d61 7070 6572 2072    LinearMapper r
+00011320: 3220 3d20 7265 732e 6765 744c 696e 6561  2 = res.getLinea
+00011330: 724d 6170 7065 7228 692c 206a 3220 2b20  rMapper(i, j2 + 
+00011340: 3229 3b0a 2020 2020 2020 2020 2020 4c69  2);.          Li
+00011350: 6e65 6172 4d61 7070 6572 2072 3320 3d20  nearMapper r3 = 
+00011360: 7265 732e 6765 744c 696e 6561 724d 6170  res.getLinearMap
+00011370: 7065 7228 692c 206a 3220 2b20 3329 3b0a  per(i, j2 + 3);.
+00011380: 0a20 2020 2020 2020 2020 2072 302e 7072  .          r0.pr
+00011390: 6566 6574 6368 2870 7265 6665 7463 685f  efetch(prefetch_
+000113a0: 7265 735f 6f66 6673 6574 293b 0a20 2020  res_offset);.   
+000113b0: 2020 2020 2020 2072 312e 7072 6566 6574         r1.prefet
+000113c0: 6368 2870 7265 6665 7463 685f 7265 735f  ch(prefetch_res_
+000113d0: 6f66 6673 6574 293b 0a20 2020 2020 2020  offset);.       
+000113e0: 2020 2072 322e 7072 6566 6574 6368 2870     r2.prefetch(p
+000113f0: 7265 6665 7463 685f 7265 735f 6f66 6673  refetch_res_offs
+00011400: 6574 293b 0a20 2020 2020 2020 2020 2072  et);.          r
+00011410: 332e 7072 6566 6574 6368 2870 7265 6665  3.prefetch(prefe
+00011420: 7463 685f 7265 735f 6f66 6673 6574 293b  tch_res_offset);
+00011430: 0a0a 2020 2020 2020 2020 2020 2f2f 2070  ..          // p
+00011440: 6572 666f 726d 7320 2269 6e6e 6572 2220  erforms "inner" 
+00011450: 7072 6f64 7563 7473 0a20 2020 2020 2020  products.       
+00011460: 2020 2063 6f6e 7374 2052 6873 5363 616c     const RhsScal
+00011470: 6172 2a20 626c 4220 3d20 2662 6c6f 636b  ar* blB = &block
+00011480: 425b 6a32 2a73 7472 6964 6542 2b6f 6666  B[j2*strideB+off
+00011490: 7365 7442 2a6e 725d 3b0a 2020 2020 2020  setB*nr];.      
+000114a0: 2020 2020 7072 6566 6574 6368 2826 626c      prefetch(&bl
+000114b0: 425b 305d 293b 0a20 2020 2020 2020 2020  B[0]);.         
+000114c0: 204c 6873 5061 636b 6574 2041 302c 2041   LhsPacket A0, A
+000114d0: 313b 0a0a 2020 2020 2020 2020 2020 666f  1;..          fo
+000114e0: 7228 496e 6465 7820 6b3d 303b 206b 3c70  r(Index k=0; k<p
+000114f0: 6565 6c65 645f 6b63 3b20 6b2b 3d70 6b29  eeled_kc; k+=pk)
+00011500: 0a20 2020 2020 2020 2020 207b 0a20 2020  .          {.   
+00011510: 2020 2020 2020 2020 2045 4947 454e 5f41           EIGEN_A
+00011520: 534d 5f43 4f4d 4d45 4e54 2822 6265 6769  SM_COMMENT("begi
+00011530: 6e20 6765 6270 206d 6963 726f 206b 6572  n gebp micro ker
+00011540: 6e65 6c20 3270 5834 2229 3b0a 2020 2020  nel 2pX4");.    
+00011550: 2020 2020 2020 2020 5268 7350 6163 6b65          RhsPacke
+00011560: 7478 3420 7268 735f 7061 6e65 6c3b 0a20  tx4 rhs_panel;. 
+00011570: 2020 2020 2020 2020 2020 2052 6873 5061             RhsPa
+00011580: 636b 6574 2054 303b 0a0a 2020 2020 2020  cket T0;..      
+00011590: 2020 2020 2f2f 204e 4f54 453a 2074 6865      // NOTE: the
+000115a0: 2062 6567 696e 2f65 6e64 2061 736d 2063   begin/end asm c
+000115b0: 6f6d 6d65 6e74 7320 6265 6c6f 7720 776f  omments below wo
+000115c0: 726b 2061 726f 756e 6420 6275 6720 3933  rk around bug 93
+000115d0: 3521 0a20 2020 2020 2020 2020 202f 2f20  5!.          // 
+000115e0: 6275 7420 7468 6579 2061 7265 206e 6f74  but they are not
+000115f0: 2065 6e6f 7567 6820 666f 7220 6763 633e   enough for gcc>
+00011600: 3d36 2077 6974 686f 7574 2046 4d41 2028  =6 without FMA (
+00011610: 6275 6720 3136 3337 290a 2020 2020 2020  bug 1637).      
+00011620: 2020 2020 2369 6620 4549 4745 4e5f 474e      #if EIGEN_GN
+00011630: 5543 5f41 545f 4c45 4153 5428 362c 3029  UC_AT_LEAST(6,0)
+00011640: 2026 2620 6465 6669 6e65 6428 4549 4745   && defined(EIGE
+00011650: 4e5f 5645 4354 4f52 495a 455f 5353 4529  N_VECTORIZE_SSE)
+00011660: 0a20 2020 2020 2020 2020 2020 2023 6465  .            #de
+00011670: 6669 6e65 2045 4947 454e 5f47 4542 505f  fine EIGEN_GEBP_
+00011680: 3250 5834 5f53 5049 4c4c 494e 475f 574f  2PX4_SPILLING_WO
+00011690: 524b 4152 4f55 4e44 205f 5f61 736d 5f5f  RKAROUND __asm__
+000116a0: 2020 2822 2220 3a20 5b61 305d 2022 2b78    ("" : [a0] "+x
+000116b0: 2c6d 2220 2841 3029 2c5b 6131 5d20 222b  ,m" (A0),[a1] "+
+000116c0: 782c 6d22 2028 4131 2929 3b0a 2020 2020  x,m" (A1));.    
+000116d0: 2020 2020 2020 2365 6c73 650a 2020 2020        #else.    
+000116e0: 2020 2020 2020 2020 2364 6566 696e 6520          #define 
+000116f0: 4549 4745 4e5f 4745 4250 5f32 5058 345f  EIGEN_GEBP_2PX4_
+00011700: 5350 494c 4c49 4e47 5f57 4f52 4b41 524f  SPILLING_WORKARO
+00011710: 554e 440a 2020 2020 2020 2020 2020 2365  UND.          #e
+00011720: 6e64 6966 0a23 6465 6669 6e65 2045 4947  ndif.#define EIG
+00011730: 454e 5f47 4542 4750 5f4f 4e45 5354 4550  EN_GEBGP_ONESTEP
+00011740: 284b 2920 2020 2020 2020 2020 2020 2020  (K)             
+00011750: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011760: 2020 2020 2020 2020 2020 2020 2020 205c                 \
+00011770: 0a20 2020 2020 2020 2020 2020 2064 6f20  .            do 
+00011780: 7b20 2020 2020 2020 2020 2020 2020 2020  {               
+00011790: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000117a0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000117b0: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+000117c0: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+000117d0: 5f41 534d 5f43 4f4d 4d45 4e54 2822 6265  _ASM_COMMENT("be
+000117e0: 6769 6e20 7374 6570 206f 6620 6765 6270  gin step of gebp
+000117f0: 206d 6963 726f 206b 6572 6e65 6c20 3270   micro kernel 2p
+00011800: 5834 2229 3b20 205c 0a20 2020 2020 2020  X4");  \.       
+00011810: 2020 2020 2020 2074 7261 6974 732e 6c6f         traits.lo
+00011820: 6164 4c68 7328 2662 6c41 5b28 3020 2b20  adLhs(&blA[(0 + 
+00011830: 3220 2a20 4b29 202a 204c 6873 5072 6f67  2 * K) * LhsProg
+00011840: 7265 7373 5d2c 2041 3029 3b20 2020 2020  ress], A0);     
+00011850: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
+00011860: 2020 2074 7261 6974 732e 6c6f 6164 4c68     traits.loadLh
+00011870: 7328 2662 6c41 5b28 3120 2b20 3220 2a20  s(&blA[(1 + 2 * 
+00011880: 4b29 202a 204c 6873 5072 6f67 7265 7373  K) * LhsProgress
+00011890: 5d2c 2041 3129 3b20 2020 2020 2020 205c  ], A1);        \
+000118a0: 0a20 2020 2020 2020 2020 2020 2020 2074  .              t
+000118b0: 7261 6974 732e 6c6f 6164 5268 7328 2662  raits.loadRhs(&b
+000118c0: 6c42 5b28 3020 2b20 3420 2a20 4b29 202a  lB[(0 + 4 * K) *
+000118d0: 2052 6873 5072 6f67 7265 7373 5d2c 2072   RhsProgress], r
+000118e0: 6873 5f70 616e 656c 293b 205c 0a20 2020  hs_panel); \.   
+000118f0: 2020 2020 2020 2020 2020 2074 7261 6974             trait
+00011900: 732e 6d61 6464 2841 302c 2072 6873 5f70  s.madd(A0, rhs_p
+00011910: 616e 656c 2c20 4330 2c20 5430 2c20 6669  anel, C0, T0, fi
+00011920: 783c 303e 293b 2020 2020 2020 2020 2020  x<0>);          
+00011930: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+00011940: 2020 2020 2020 2074 7261 6974 732e 6d61         traits.ma
+00011950: 6464 2841 312c 2072 6873 5f70 616e 656c  dd(A1, rhs_panel
+00011960: 2c20 4334 2c20 5430 2c20 6669 783c 303e  , C4, T0, fix<0>
+00011970: 293b 2020 2020 2020 2020 2020 2020 2020  );              
+00011980: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
+00011990: 2020 2074 7261 6974 732e 6d61 6464 2841     traits.madd(A
+000119a0: 302c 2072 6873 5f70 616e 656c 2c20 4331  0, rhs_panel, C1
+000119b0: 2c20 5430 2c20 6669 783c 313e 293b 2020  , T0, fix<1>);  
+000119c0: 2020 2020 2020 2020 2020 2020 2020 205c                 \
+000119d0: 0a20 2020 2020 2020 2020 2020 2020 2074  .              t
+000119e0: 7261 6974 732e 6d61 6464 2841 312c 2072  raits.madd(A1, r
+000119f0: 6873 5f70 616e 656c 2c20 4335 2c20 5430  hs_panel, C5, T0
+00011a00: 2c20 6669 783c 313e 293b 2020 2020 2020  , fix<1>);      
+00011a10: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+00011a20: 2020 2020 2020 2020 2020 2074 7261 6974             trait
+00011a30: 732e 6d61 6464 2841 302c 2072 6873 5f70  s.madd(A0, rhs_p
+00011a40: 616e 656c 2c20 4332 2c20 5430 2c20 6669  anel, C2, T0, fi
+00011a50: 783c 323e 293b 2020 2020 2020 2020 2020  x<2>);          
+00011a60: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+00011a70: 2020 2020 2020 2074 7261 6974 732e 6d61         traits.ma
+00011a80: 6464 2841 312c 2072 6873 5f70 616e 656c  dd(A1, rhs_panel
+00011a90: 2c20 4336 2c20 5430 2c20 6669 783c 323e  , C6, T0, fix<2>
+00011aa0: 293b 2020 2020 2020 2020 2020 2020 2020  );              
+00011ab0: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
+00011ac0: 2020 2074 7261 6974 732e 6d61 6464 2841     traits.madd(A
+00011ad0: 302c 2072 6873 5f70 616e 656c 2c20 4333  0, rhs_panel, C3
+00011ae0: 2c20 5430 2c20 6669 783c 333e 293b 2020  , T0, fix<3>);  
+00011af0: 2020 2020 2020 2020 2020 2020 2020 205c                 \
+00011b00: 0a20 2020 2020 2020 2020 2020 2020 2074  .              t
+00011b10: 7261 6974 732e 6d61 6464 2841 312c 2072  raits.madd(A1, r
+00011b20: 6873 5f70 616e 656c 2c20 4337 2c20 5430  hs_panel, C7, T0
+00011b30: 2c20 6669 783c 333e 293b 2020 2020 2020  , fix<3>);      
+00011b40: 2020 2020 2020 2020 2020 205c 0a20 2020             \.   
+00011b50: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+00011b60: 5f47 4542 505f 3250 5834 5f53 5049 4c4c  _GEBP_2PX4_SPILL
+00011b70: 494e 475f 574f 524b 4152 4f55 4e44 2020  ING_WORKAROUND  
+00011b80: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00011b90: 2020 2020 2020 205c 0a20 2020 2020 2020         \.       
+00011ba0: 2020 2020 2020 2045 4947 454e 5f41 534d         EIGEN_ASM
+00011bb0: 5f43 4f4d 4d45 4e54 2822 656e 6420 7374  _COMMENT("end st
+00011bc0: 6570 206f 6620 6765 6270 206d 6963 726f  ep of gebp micro
+00011bd0: 206b 6572 6e65 6c20 3270 5834 2229 3b20   kernel 2pX4"); 
+00011be0: 2020 205c 0a20 2020 2020 2020 2020 2020     \.           
+00011bf0: 207d 2077 6869 6c65 2028 6661 6c73 6529   } while (false)
+00011c00: 0a0a 2020 2020 2020 2020 2020 2020 696e  ..            in
+00011c10: 7465 726e 616c 3a3a 7072 6566 6574 6368  ternal::prefetch
+00011c20: 2862 6c42 2b28 3438 2b30 2929 3b0a 2020  (blB+(48+0));.  
+00011c30: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
+00011c40: 4745 4247 505f 4f4e 4553 5445 5028 3029  GEBGP_ONESTEP(0)
+00011c50: 3b0a 2020 2020 2020 2020 2020 2020 4549  ;.            EI
+00011c60: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+00011c70: 5028 3129 3b0a 2020 2020 2020 2020 2020  P(1);.          
+00011c80: 2020 4549 4745 4e5f 4745 4247 505f 4f4e    EIGEN_GEBGP_ON
+00011c90: 4553 5445 5028 3229 3b0a 2020 2020 2020  ESTEP(2);.      
+00011ca0: 2020 2020 2020 4549 4745 4e5f 4745 4247        EIGEN_GEBG
+00011cb0: 505f 4f4e 4553 5445 5028 3329 3b0a 2020  P_ONESTEP(3);.  
+00011cc0: 2020 2020 2020 2020 2020 696e 7465 726e            intern
+00011cd0: 616c 3a3a 7072 6566 6574 6368 2862 6c42  al::prefetch(blB
+00011ce0: 2b28 3438 2b31 3629 293b 0a20 2020 2020  +(48+16));.     
+00011cf0: 2020 2020 2020 2045 4947 454e 5f47 4542         EIGEN_GEB
+00011d00: 4750 5f4f 4e45 5354 4550 2834 293b 0a20  GP_ONESTEP(4);. 
+00011d10: 2020 2020 2020 2020 2020 2045 4947 454e             EIGEN
+00011d20: 5f47 4542 4750 5f4f 4e45 5354 4550 2835  _GEBGP_ONESTEP(5
+00011d30: 293b 0a20 2020 2020 2020 2020 2020 2045  );.            E
+00011d40: 4947 454e 5f47 4542 4750 5f4f 4e45 5354  IGEN_GEBGP_ONEST
+00011d50: 4550 2836 293b 0a20 2020 2020 2020 2020  EP(6);.         
+00011d60: 2020 2045 4947 454e 5f47 4542 4750 5f4f     EIGEN_GEBGP_O
+00011d70: 4e45 5354 4550 2837 293b 0a0a 2020 2020  NESTEP(7);..    
+00011d80: 2020 2020 2020 2020 626c 4220 2b3d 2070          blB += p
+00011d90: 6b2a 342a 5268 7350 726f 6772 6573 733b  k*4*RhsProgress;
+00011da0: 0a20 2020 2020 2020 2020 2020 2062 6c41  .            blA
+00011db0: 202b 3d20 706b 2a28 322a 5472 6169 7473   += pk*(2*Traits
+00011dc0: 3a3a 4c68 7350 726f 6772 6573 7329 3b0a  ::LhsProgress);.
+00011dd0: 0a20 2020 2020 2020 2020 2020 2045 4947  .            EIG
+00011de0: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
+00011df0: 656e 6420 6765 6270 206d 6963 726f 206b  end gebp micro k
+00011e00: 6572 6e65 6c20 3270 5834 2229 3b0a 2020  ernel 2pX4");.  
+00011e10: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
+00011e20: 2020 2020 2f2f 2070 726f 6365 7373 2072      // process r
+00011e30: 656d 6169 6e69 6e67 2070 6565 6c65 6420  emaining peeled 
+00011e40: 6c6f 6f70 0a20 2020 2020 2020 2020 2066  loop.          f
+00011e50: 6f72 2849 6e64 6578 206b 3d70 6565 6c65  or(Index k=peele
+00011e60: 645f 6b63 3b20 6b3c 6465 7074 683b 206b  d_kc; k<depth; k
+00011e70: 2b2b 290a 2020 2020 2020 2020 2020 7b0a  ++).          {.
+00011e80: 2020 2020 2020 2020 2020 2020 5268 7350              RhsP
+00011e90: 6163 6b65 7478 3420 7268 735f 7061 6e65  acketx4 rhs_pane
+00011ea0: 6c3b 0a20 2020 2020 2020 2020 2020 2052  l;.            R
+00011eb0: 6873 5061 636b 6574 2054 303b 0a20 2020  hsPacket T0;.   
+00011ec0: 2020 2020 2020 2020 2045 4947 454e 5f47           EIGEN_G
+00011ed0: 4542 4750 5f4f 4e45 5354 4550 2830 293b  EBGP_ONESTEP(0);
+00011ee0: 0a20 2020 2020 2020 2020 2020 2062 6c42  .            blB
+00011ef0: 202b 3d20 342a 5268 7350 726f 6772 6573   += 4*RhsProgres
+00011f00: 733b 0a20 2020 2020 2020 2020 2020 2062  s;.            b
+00011f10: 6c41 202b 3d20 322a 5472 6169 7473 3a3a  lA += 2*Traits::
+00011f20: 4c68 7350 726f 6772 6573 733b 0a20 2020  LhsProgress;.   
+00011f30: 2020 2020 2020 207d 0a23 756e 6465 6620         }.#undef 
+00011f40: 4549 4745 4e5f 4745 4247 505f 4f4e 4553  EIGEN_GEBGP_ONES
+00011f50: 5445 500a 0a20 2020 2020 2020 2020 2052  TEP..          R
+00011f60: 6573 5061 636b 6574 2052 302c 2052 312c  esPacket R0, R1,
+00011f70: 2052 322c 2052 333b 0a20 2020 2020 2020   R2, R3;.       
+00011f80: 2020 2052 6573 5061 636b 6574 2061 6c70     ResPacket alp
+00011f90: 6861 7620 3d20 7073 6574 313c 5265 7350  hav = pset1<ResP
+00011fa0: 6163 6b65 743e 2861 6c70 6861 293b 0a0a  acket>(alpha);..
+00011fb0: 2020 2020 2020 2020 2020 5230 203d 2072            R0 = r
+00011fc0: 302e 7465 6d70 6c61 7465 206c 6f61 6450  0.template loadP
+00011fd0: 6163 6b65 743c 5265 7350 6163 6b65 743e  acket<ResPacket>
+00011fe0: 2830 202a 2054 7261 6974 733a 3a52 6573  (0 * Traits::Res
+00011ff0: 5061 636b 6574 5369 7a65 293b 0a20 2020  PacketSize);.   
+00012000: 2020 2020 2020 2052 3120 3d20 7230 2e74         R1 = r0.t
+00012010: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+00012020: 6574 3c52 6573 5061 636b 6574 3e28 3120  et<ResPacket>(1 
+00012030: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
+00012040: 6b65 7453 697a 6529 3b0a 2020 2020 2020  ketSize);.      
+00012050: 2020 2020 5232 203d 2072 312e 7465 6d70      R2 = r1.temp
+00012060: 6c61 7465 206c 6f61 6450 6163 6b65 743c  late loadPacket<
+00012070: 5265 7350 6163 6b65 743e 2830 202a 2054  ResPacket>(0 * T
+00012080: 7261 6974 733a 3a52 6573 5061 636b 6574  raits::ResPacket
+00012090: 5369 7a65 293b 0a20 2020 2020 2020 2020  Size);.         
+000120a0: 2052 3320 3d20 7231 2e74 656d 706c 6174   R3 = r1.templat
+000120b0: 6520 6c6f 6164 5061 636b 6574 3c52 6573  e loadPacket<Res
+000120c0: 5061 636b 6574 3e28 3120 2a20 5472 6169  Packet>(1 * Trai
+000120d0: 7473 3a3a 5265 7350 6163 6b65 7453 697a  ts::ResPacketSiz
+000120e0: 6529 3b0a 2020 2020 2020 2020 2020 7472  e);.          tr
+000120f0: 6169 7473 2e61 6363 2843 302c 2061 6c70  aits.acc(C0, alp
+00012100: 6861 762c 2052 3029 3b0a 2020 2020 2020  hav, R0);.      
+00012110: 2020 2020 7472 6169 7473 2e61 6363 2843      traits.acc(C
+00012120: 342c 2061 6c70 6861 762c 2052 3129 3b0a  4, alphav, R1);.
+00012130: 2020 2020 2020 2020 2020 7472 6169 7473            traits
+00012140: 2e61 6363 2843 312c 2061 6c70 6861 762c  .acc(C1, alphav,
+00012150: 2052 3229 3b0a 2020 2020 2020 2020 2020   R2);.          
+00012160: 7472 6169 7473 2e61 6363 2843 352c 2061  traits.acc(C5, a
+00012170: 6c70 6861 762c 2052 3329 3b0a 2020 2020  lphav, R3);.    
+00012180: 2020 2020 2020 7230 2e73 746f 7265 5061        r0.storePa
+00012190: 636b 6574 2830 202a 2054 7261 6974 733a  cket(0 * Traits:
+000121a0: 3a52 6573 5061 636b 6574 5369 7a65 2c20  :ResPacketSize, 
+000121b0: 5230 293b 0a20 2020 2020 2020 2020 2072  R0);.          r
+000121c0: 302e 7374 6f72 6550 6163 6b65 7428 3120  0.storePacket(1 
+000121d0: 2a20 5472 6169 7473 3a3a 5265 7350 6163  * Traits::ResPac
+000121e0: 6b65 7453 697a 652c 2052 3129 3b0a 2020  ketSize, R1);.  
+000121f0: 2020 2020 2020 2020 7231 2e73 746f 7265          r1.store
+00012200: 5061 636b 6574 2830 202a 2054 7261 6974  Packet(0 * Trait
+00012210: 733a 3a52 6573 5061 636b 6574 5369 7a65  s::ResPacketSize
+00012220: 2c20 5232 293b 0a20 2020 2020 2020 2020  , R2);.         
+00012230: 2072 312e 7374 6f72 6550 6163 6b65 7428   r1.storePacket(
+00012240: 3120 2a20 5472 6169 7473 3a3a 5265 7350  1 * Traits::ResP
+00012250: 6163 6b65 7453 697a 652c 2052 3329 3b0a  acketSize, R3);.
+00012260: 0a20 2020 2020 2020 2020 2052 3020 3d20  .          R0 = 
+00012270: 7232 2e74 656d 706c 6174 6520 6c6f 6164  r2.template load
+00012280: 5061 636b 6574 3c52 6573 5061 636b 6574  Packet<ResPacket
+00012290: 3e28 3020 2a20 5472 6169 7473 3a3a 5265  >(0 * Traits::Re
+000122a0: 7350 6163 6b65 7453 697a 6529 3b0a 2020  sPacketSize);.  
+000122b0: 2020 2020 2020 2020 5231 203d 2072 322e          R1 = r2.
+000122c0: 7465 6d70 6c61 7465 206c 6f61 6450 6163  template loadPac
+000122d0: 6b65 743c 5265 7350 6163 6b65 743e 2831  ket<ResPacket>(1
+000122e0: 202a 2054 7261 6974 733a 3a52 6573 5061   * Traits::ResPa
+000122f0: 636b 6574 5369 7a65 293b 0a20 2020 2020  cketSize);.     
+00012300: 2020 2020 2052 3220 3d20 7233 2e74 656d       R2 = r3.tem
+00012310: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
+00012320: 3c52 6573 5061 636b 6574 3e28 3020 2a20  <ResPacket>(0 * 
+00012330: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
+00012340: 7453 697a 6529 3b0a 2020 2020 2020 2020  tSize);.        
+00012350: 2020 5233 203d 2072 332e 7465 6d70 6c61    R3 = r3.templa
+00012360: 7465 206c 6f61 6450 6163 6b65 743c 5265  te loadPacket<Re
+00012370: 7350 6163 6b65 743e 2831 202a 2054 7261  sPacket>(1 * Tra
+00012380: 6974 733a 3a52 6573 5061 636b 6574 5369  its::ResPacketSi
+00012390: 7a65 293b 0a20 2020 2020 2020 2020 2074  ze);.          t
+000123a0: 7261 6974 732e 6163 6328 4332 2c20 2061  raits.acc(C2,  a
+000123b0: 6c70 6861 762c 2052 3029 3b0a 2020 2020  lphav, R0);.    
+000123c0: 2020 2020 2020 7472 6169 7473 2e61 6363        traits.acc
+000123d0: 2843 362c 2020 616c 7068 6176 2c20 5231  (C6,  alphav, R1
+000123e0: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
+000123f0: 6974 732e 6163 6328 4333 2c20 2061 6c70  its.acc(C3,  alp
+00012400: 6861 762c 2052 3229 3b0a 2020 2020 2020  hav, R2);.      
+00012410: 2020 2020 7472 6169 7473 2e61 6363 2843      traits.acc(C
+00012420: 372c 2020 616c 7068 6176 2c20 5233 293b  7,  alphav, R3);
+00012430: 0a20 2020 2020 2020 2020 2072 322e 7374  .          r2.st
+00012440: 6f72 6550 6163 6b65 7428 3020 2a20 5472  orePacket(0 * Tr
+00012450: 6169 7473 3a3a 5265 7350 6163 6b65 7453  aits::ResPacketS
+00012460: 697a 652c 2052 3029 3b0a 2020 2020 2020  ize, R0);.      
+00012470: 2020 2020 7232 2e73 746f 7265 5061 636b      r2.storePack
+00012480: 6574 2831 202a 2054 7261 6974 733a 3a52  et(1 * Traits::R
+00012490: 6573 5061 636b 6574 5369 7a65 2c20 5231  esPacketSize, R1
+000124a0: 293b 0a20 2020 2020 2020 2020 2072 332e  );.          r3.
+000124b0: 7374 6f72 6550 6163 6b65 7428 3020 2a20  storePacket(0 * 
+000124c0: 5472 6169 7473 3a3a 5265 7350 6163 6b65  Traits::ResPacke
+000124d0: 7453 697a 652c 2052 3229 3b0a 2020 2020  tSize, R2);.    
+000124e0: 2020 2020 2020 7233 2e73 746f 7265 5061        r3.storePa
+000124f0: 636b 6574 2831 202a 2054 7261 6974 733a  cket(1 * Traits:
+00012500: 3a52 6573 5061 636b 6574 5369 7a65 2c20  :ResPacketSize, 
+00012510: 5233 293b 0a20 2020 2020 2020 2020 207d  R3);.          }
+00012520: 0a20 2020 2020 2020 207d 0a20 2020 2020  .        }.     
+00012530: 200a 2020 2020 2020 2020 2f2f 2044 6561   .        // Dea
+00012540: 6c20 7769 7468 2072 656d 6169 6e69 6e67  l with remaining
+00012550: 2063 6f6c 756d 6e73 206f 6620 7468 6520   columns of the 
+00012560: 7268 730a 2020 2020 2020 2020 666f 7228  rhs.        for(
+00012570: 496e 6465 7820 6a32 3d70 6163 6b65 745f  Index j2=packet_
+00012580: 636f 6c73 343b 206a 323c 636f 6c73 3b20  cols4; j2<cols; 
+00012590: 6a32 2b2b 290a 2020 2020 2020 2020 7b0a  j2++).        {.
+000125a0: 2020 2020 2020 2020 2020 666f 7228 496e            for(In
+000125b0: 6465 7820 693d 6931 3b20 693c 6163 7475  dex i=i1; i<actu
+000125c0: 616c 5f70 616e 656c 5f65 6e64 3b20 692b  al_panel_end; i+
+000125d0: 3d32 2a4c 6873 5072 6f67 7265 7373 290a  =2*LhsProgress).
+000125e0: 2020 2020 2020 2020 2020 7b0a 2020 2020            {.    
+000125f0: 2020 2020 2020 2f2f 204f 6e65 2063 6f6c        // One col
+00012600: 756d 6e20 6174 2061 2074 696d 650a 2020  umn at a time.  
+00012610: 2020 2020 2020 2020 636f 6e73 7420 4c68          const Lh
+00012620: 7353 6361 6c61 722a 2062 6c41 203d 2026  sScalar* blA = &
+00012630: 626c 6f63 6b41 5b69 2a73 7472 6964 6541  blockA[i*strideA
+00012640: 2b6f 6666 7365 7441 2a28 322a 5472 6169  +offsetA*(2*Trai
+00012650: 7473 3a3a 4c68 7350 726f 6772 6573 7329  ts::LhsProgress)
+00012660: 5d3b 0a20 2020 2020 2020 2020 2070 7265  ];.          pre
+00012670: 6665 7463 6828 2662 6c41 5b30 5d29 3b0a  fetch(&blA[0]);.
+00012680: 0a20 2020 2020 2020 2020 202f 2f20 6765  .          // ge
+00012690: 7473 2072 6573 2062 6c6f 636b 2061 7320  ts res block as 
+000126a0: 7265 6769 7374 6572 0a20 2020 2020 2020  register.       
+000126b0: 2020 2041 6363 5061 636b 6574 2043 302c     AccPacket C0,
+000126c0: 2043 343b 0a20 2020 2020 2020 2020 2074   C4;.          t
+000126d0: 7261 6974 732e 696e 6974 4163 6328 4330  raits.initAcc(C0
+000126e0: 293b 0a20 2020 2020 2020 2020 2074 7261  );.          tra
+000126f0: 6974 732e 696e 6974 4163 6328 4334 293b  its.initAcc(C4);
+00012700: 0a0a 2020 2020 2020 2020 2020 4c69 6e65  ..          Line
+00012710: 6172 4d61 7070 6572 2072 3020 3d20 7265  arMapper r0 = re
+00012720: 732e 6765 744c 696e 6561 724d 6170 7065  s.getLinearMappe
+00012730: 7228 692c 206a 3229 3b0a 2020 2020 2020  r(i, j2);.      
+00012740: 2020 2020 7230 2e70 7265 6665 7463 6828      r0.prefetch(
+00012750: 7072 6566 6574 6368 5f72 6573 5f6f 6666  prefetch_res_off
+00012760: 7365 7429 3b0a 0a20 2020 2020 2020 2020  set);..         
+00012770: 202f 2f20 7065 7266 6f72 6d73 2022 696e   // performs "in
+00012780: 6e65 7222 2070 726f 6475 6374 730a 2020  ner" products.  
+00012790: 2020 2020 2020 2020 636f 6e73 7420 5268          const Rh
+000127a0: 7353 6361 6c61 722a 2062 6c42 203d 2026  sScalar* blB = &
+000127b0: 626c 6f63 6b42 5b6a 322a 7374 7269 6465  blockB[j2*stride
+000127c0: 422b 6f66 6673 6574 425d 3b0a 2020 2020  B+offsetB];.    
+000127d0: 2020 2020 2020 4c68 7350 6163 6b65 7420        LhsPacket 
+000127e0: 4130 2c20 4131 3b0a 0a20 2020 2020 2020  A0, A1;..       
+000127f0: 2020 2066 6f72 2849 6e64 6578 206b 3d30     for(Index k=0
+00012800: 3b20 6b3c 7065 656c 6564 5f6b 633b 206b  ; k<peeled_kc; k
+00012810: 2b3d 706b 290a 2020 2020 2020 2020 2020  +=pk).          
+00012820: 7b0a 2020 2020 2020 2020 2020 2020 4549  {.            EI
+00012830: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
+00012840: 2262 6567 696e 2067 6562 7020 6d69 6372  "begin gebp micr
+00012850: 6f20 6b65 726e 656c 2032 7058 3122 293b  o kernel 2pX1");
+00012860: 0a20 2020 2020 2020 2020 2020 2052 6873  .            Rhs
+00012870: 5061 636b 6574 2042 5f30 2c20 4231 3b0a  Packet B_0, B1;.
+00012880: 2020 2020 2020 2020 0a23 6465 6669 6e65          .#define
+00012890: 2045 4947 454e 5f47 4542 4750 5f4f 4e45   EIGEN_GEBGP_ONE
+000128a0: 5354 4550 284b 2920 5c0a 2020 2020 2020  STEP(K) \.      
+000128b0: 2020 2020 2020 646f 207b 2020 2020 2020        do {      
+000128c0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000128d0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000128e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000128f0: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+00012900: 2020 2020 2020 2020 2020 2020 4549 4745              EIGE
+00012910: 4e5f 4153 4d5f 434f 4d4d 454e 5428 2262  N_ASM_COMMENT("b
+00012920: 6567 696e 2073 7465 7020 6f66 2067 6562  egin step of geb
+00012930: 7020 6d69 6372 6f20 6b65 726e 656c 2032  p micro kernel 2
+00012940: 7058 3122 293b 2020 2020 2020 2020 2020  pX1");          
+00012950: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00012960: 4549 4745 4e5f 4153 4d5f 434f 4d4d 454e  EIGEN_ASM_COMMEN
+00012970: 5428 224e 6f74 653a 2074 6865 7365 2061  T("Note: these a
+00012980: 736d 2063 6f6d 6d65 6e74 7320 776f 726b  sm comments work
+00012990: 2061 726f 756e 6420 6275 6720 3933 3521   around bug 935!
+000129a0: 2229 3b20 5c0a 2020 2020 2020 2020 2020  "); \.          
+000129b0: 2020 2020 7472 6169 7473 2e6c 6f61 644c      traits.loadL
+000129c0: 6873 2826 626c 415b 2830 2b32 2a4b 292a  hs(&blA[(0+2*K)*
+000129d0: 4c68 7350 726f 6772 6573 735d 2c20 4130  LhsProgress], A0
+000129e0: 293b 2020 2020 2020 2020 2020 2020 2020  );              
+000129f0: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
+00012a00: 2020 2020 2020 2020 7472 6169 7473 2e6c          traits.l
+00012a10: 6f61 644c 6873 2826 626c 415b 2831 2b32  oadLhs(&blA[(1+2
+00012a20: 2a4b 292a 4c68 7350 726f 6772 6573 735d  *K)*LhsProgress]
+00012a30: 2c20 4131 293b 2020 2020 2020 2020 2020  , A1);          
+00012a40: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+00012a50: 2020 2020 2020 2020 2020 2020 7472 6169              trai
+00012a60: 7473 2e6c 6f61 6452 6873 2826 626c 425b  ts.loadRhs(&blB[
+00012a70: 2830 2b4b 292a 5268 7350 726f 6772 6573  (0+K)*RhsProgres
+00012a80: 735d 2c20 425f 3029 3b20 2020 2020 2020  s], B_0);       
+00012a90: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012aa0: 5c0a 2020 2020 2020 2020 2020 2020 2020  \.              
+00012ab0: 7472 6169 7473 2e6d 6164 6428 4130 2c20  traits.madd(A0, 
+00012ac0: 425f 302c 2043 302c 2042 312c 2066 6978  B_0, C0, B1, fix
+00012ad0: 3c30 3e29 3b20 2020 2020 2020 2020 2020  <0>);           
+00012ae0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012af0: 2020 2020 5c0a 2020 2020 2020 2020 2020      \.          
+00012b00: 2020 2020 7472 6169 7473 2e6d 6164 6428      traits.madd(
+00012b10: 4131 2c20 425f 302c 2043 342c 2042 5f30  A1, B_0, C4, B_0
+00012b20: 2c20 6669 783c 303e 293b 2020 2020 2020  , fix<0>);      
+00012b30: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00012b40: 2020 2020 2020 2020 5c0a 2020 2020 2020          \.      
+00012b50: 2020 2020 2020 2020 4549 4745 4e5f 4153          EIGEN_AS
+00012b60: 4d5f 434f 4d4d 454e 5428 2265 6e64 2073  M_COMMENT("end s
+00012b70: 7465 7020 6f66 2067 6562 7020 6d69 6372  tep of gebp micr
+00012b80: 6f20 6b65 726e 656c 2032 7058 3122 293b  o kernel 2pX1");
+00012b90: 2020 2020 2020 2020 2020 2020 5c0a 2020              \.  
+00012ba0: 2020 2020 2020 2020 2020 7d20 7768 696c            } whil
+00012bb0: 6528 6661 6c73 6529 0a20 2020 2020 2020  e(false).       
+00012bc0: 200a 2020 2020 2020 2020 2020 2020 4549   .            EI
+00012bd0: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+00012be0: 5028 3029 3b0a 2020 2020 2020 2020 2020  P(0);.          
+00012bf0: 2020 4549 4745 4e5f 4745 4247 505f 4f4e    EIGEN_GEBGP_ON
+00012c00: 4553 5445 5028 3129 3b0a 2020 2020 2020  ESTEP(1);.      
+00012c10: 2020 2020 2020 4549 4745 4e5f 4745 4247        EIGEN_GEBG
+00012c20: 505f 4f4e 4553 5445 5028 3229 3b0a 2020  P_ONESTEP(2);.  
+00012c30: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
+00012c40: 4745 4247 505f 4f4e 4553 5445 5028 3329  GEBGP_ONESTEP(3)
+00012c50: 3b0a 2020 2020 2020 2020 2020 2020 4549  ;.            EI
+00012c60: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+00012c70: 5028 3429 3b0a 2020 2020 2020 2020 2020  P(4);.          
+00012c80: 2020 4549 4745 4e5f 4745 4247 505f 4f4e    EIGEN_GEBGP_ON
+00012c90: 4553 5445 5028 3529 3b0a 2020 2020 2020  ESTEP(5);.      
+00012ca0: 2020 2020 2020 4549 4745 4e5f 4745 4247        EIGEN_GEBG
+00012cb0: 505f 4f4e 4553 5445 5028 3629 3b0a 2020  P_ONESTEP(6);.  
+00012cc0: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
+00012cd0: 4745 4247 505f 4f4e 4553 5445 5028 3729  GEBGP_ONESTEP(7)
+00012ce0: 3b0a 0a20 2020 2020 2020 2020 2020 2062  ;..            b
+00012cf0: 6c42 202b 3d20 696e 7428 706b 2920 2a20  lB += int(pk) * 
+00012d00: 696e 7428 5268 7350 726f 6772 6573 7329  int(RhsProgress)
+00012d10: 3b0a 2020 2020 2020 2020 2020 2020 626c  ;.            bl
+00012d20: 4120 2b3d 2069 6e74 2870 6b29 202a 2032  A += int(pk) * 2
+00012d30: 202a 2069 6e74 2854 7261 6974 733a 3a4c   * int(Traits::L
+00012d40: 6873 5072 6f67 7265 7373 293b 0a0a 2020  hsProgress);..  
+00012d50: 2020 2020 2020 2020 2020 4549 4745 4e5f            EIGEN_
+00012d60: 4153 4d5f 434f 4d4d 454e 5428 2265 6e64  ASM_COMMENT("end
+00012d70: 2067 6562 7020 6d69 6372 6f20 6b65 726e   gebp micro kern
+00012d80: 656c 2032 7058 3122 293b 0a20 2020 2020  el 2pX1");.     
+00012d90: 2020 2020 207d 0a0a 2020 2020 2020 2020       }..        
+00012da0: 2020 2f2f 2070 726f 6365 7373 2072 656d    // process rem
+00012db0: 6169 6e69 6e67 2070 6565 6c65 6420 6c6f  aining peeled lo
+00012dc0: 6f70 0a20 2020 2020 2020 2020 2066 6f72  op.          for
+00012dd0: 2849 6e64 6578 206b 3d70 6565 6c65 645f  (Index k=peeled_
+00012de0: 6b63 3b20 6b3c 6465 7074 683b 206b 2b2b  kc; k<depth; k++
+00012df0: 290a 2020 2020 2020 2020 2020 7b0a 2020  ).          {.  
+00012e00: 2020 2020 2020 2020 2020 5268 7350 6163            RhsPac
+00012e10: 6b65 7420 425f 302c 2042 313b 0a20 2020  ket B_0, B1;.   
+00012e20: 2020 2020 2020 2020 2045 4947 454e 5f47           EIGEN_G
+00012e30: 4542 4750 5f4f 4e45 5354 4550 2830 293b  EBGP_ONESTEP(0);
+00012e40: 0a20 2020 2020 2020 2020 2020 2062 6c42  .            blB
+00012e50: 202b 3d20 5268 7350 726f 6772 6573 733b   += RhsProgress;
+00012e60: 0a20 2020 2020 2020 2020 2020 2062 6c41  .            blA
+00012e70: 202b 3d20 322a 5472 6169 7473 3a3a 4c68   += 2*Traits::Lh
+00012e80: 7350 726f 6772 6573 733b 0a20 2020 2020  sProgress;.     
+00012e90: 2020 2020 207d 0a23 756e 6465 6620 4549       }.#undef EI
+00012ea0: 4745 4e5f 4745 4247 505f 4f4e 4553 5445  GEN_GEBGP_ONESTE
+00012eb0: 500a 2020 2020 2020 2020 2020 5265 7350  P.          ResP
+00012ec0: 6163 6b65 7420 5230 2c20 5231 3b0a 2020  acket R0, R1;.  
+00012ed0: 2020 2020 2020 2020 5265 7350 6163 6b65          ResPacke
+00012ee0: 7420 616c 7068 6176 203d 2070 7365 7431  t alphav = pset1
+00012ef0: 3c52 6573 5061 636b 6574 3e28 616c 7068  <ResPacket>(alph
+00012f00: 6129 3b0a 0a20 2020 2020 2020 2020 2052  a);..          R
+00012f10: 3020 3d20 7230 2e74 656d 706c 6174 6520  0 = r0.template 
+00012f20: 6c6f 6164 5061 636b 6574 3c52 6573 5061  loadPacket<ResPa
+00012f30: 636b 6574 3e28 3020 2a20 5472 6169 7473  cket>(0 * Traits
+00012f40: 3a3a 5265 7350 6163 6b65 7453 697a 6529  ::ResPacketSize)
+00012f50: 3b0a 2020 2020 2020 2020 2020 5231 203d  ;.          R1 =
+00012f60: 2072 302e 7465 6d70 6c61 7465 206c 6f61   r0.template loa
+00012f70: 6450 6163 6b65 743c 5265 7350 6163 6b65  dPacket<ResPacke
+00012f80: 743e 2831 202a 2054 7261 6974 733a 3a52  t>(1 * Traits::R
+00012f90: 6573 5061 636b 6574 5369 7a65 293b 0a20  esPacketSize);. 
+00012fa0: 2020 2020 2020 2020 2074 7261 6974 732e           traits.
+00012fb0: 6163 6328 4330 2c20 616c 7068 6176 2c20  acc(C0, alphav, 
+00012fc0: 5230 293b 0a20 2020 2020 2020 2020 2074  R0);.          t
+00012fd0: 7261 6974 732e 6163 6328 4334 2c20 616c  raits.acc(C4, al
+00012fe0: 7068 6176 2c20 5231 293b 0a20 2020 2020  phav, R1);.     
+00012ff0: 2020 2020 2072 302e 7374 6f72 6550 6163       r0.storePac
+00013000: 6b65 7428 3020 2a20 5472 6169 7473 3a3a  ket(0 * Traits::
+00013010: 5265 7350 6163 6b65 7453 697a 652c 2052  ResPacketSize, R
+00013020: 3029 3b0a 2020 2020 2020 2020 2020 7230  0);.          r0
+00013030: 2e73 746f 7265 5061 636b 6574 2831 202a  .storePacket(1 *
+00013040: 2054 7261 6974 733a 3a52 6573 5061 636b   Traits::ResPack
+00013050: 6574 5369 7a65 2c20 5231 293b 0a20 2020  etSize, R1);.   
+00013060: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+00013070: 207d 0a20 2020 2020 207d 0a20 2020 207d   }.      }.    }
+00013080: 0a20 2020 202f 2f2d 2d2d 2d2d 2d2d 2d2d  .    //---------
+00013090: 2d20 5072 6f63 6573 7320 3120 2a20 4c68  - Process 1 * Lh
+000130a0: 7350 726f 6772 6573 7320 726f 7773 2061  sProgress rows a
+000130b0: 7420 6f6e 6365 202d 2d2d 2d2d 2d2d 2d2d  t once ---------
+000130c0: 2d0a 2020 2020 6966 286d 723e 3d31 2a54  -.    if(mr>=1*T
+000130d0: 7261 6974 733a 3a4c 6873 5072 6f67 7265  raits::LhsProgre
+000130e0: 7373 290a 2020 2020 7b0a 2020 2020 2020  ss).    {.      
+000130f0: 6c68 735f 7072 6f63 6573 735f 6f6e 655f  lhs_process_one_
+00013100: 7061 636b 6574 3c6e 722c 204c 6873 5072  packet<nr, LhsPr
+00013110: 6f67 7265 7373 2c20 5268 7350 726f 6772  ogress, RhsProgr
+00013120: 6573 732c 204c 6873 5363 616c 6172 2c20  ess, LhsScalar, 
+00013130: 5268 7353 6361 6c61 722c 2052 6573 5363  RhsScalar, ResSc
+00013140: 616c 6172 2c20 4163 6350 6163 6b65 742c  alar, AccPacket,
+00013150: 204c 6873 5061 636b 6574 2c20 5268 7350   LhsPacket, RhsP
+00013160: 6163 6b65 742c 2052 6573 5061 636b 6574  acket, ResPacket
+00013170: 2c20 5472 6169 7473 2c20 4c69 6e65 6172  , Traits, Linear
+00013180: 4d61 7070 6572 2c20 4461 7461 4d61 7070  Mapper, DataMapp
+00013190: 6572 3e20 703b 0a20 2020 2020 2070 2872  er> p;.      p(r
+000131a0: 6573 2c20 626c 6f63 6b41 2c20 626c 6f63  es, blockA, bloc
+000131b0: 6b42 2c20 616c 7068 612c 2070 6565 6c65  kB, alpha, peele
+000131c0: 645f 6d63 322c 2070 6565 6c65 645f 6d63  d_mc2, peeled_mc
+000131d0: 312c 2073 7472 6964 6541 2c20 7374 7269  1, strideA, stri
+000131e0: 6465 422c 206f 6666 7365 7441 2c20 6f66  deB, offsetA, of
+000131f0: 6673 6574 422c 2070 7265 6665 7463 685f  fsetB, prefetch_
+00013200: 7265 735f 6f66 6673 6574 2c20 7065 656c  res_offset, peel
+00013210: 6564 5f6b 632c 2070 6b2c 2063 6f6c 732c  ed_kc, pk, cols,
+00013220: 2064 6570 7468 2c20 7061 636b 6574 5f63   depth, packet_c
+00013230: 6f6c 7334 293b 0a20 2020 207d 0a20 2020  ols4);.    }.   
+00013240: 202f 2f2d 2d2d 2d2d 2d2d 2d2d 2d20 5072   //---------- Pr
+00013250: 6f63 6573 7320 4c68 7350 726f 6772 6573  ocess LhsProgres
+00013260: 7348 616c 6620 726f 7773 2061 7420 6f6e  sHalf rows at on
+00013270: 6365 202d 2d2d 2d2d 2d2d 2d2d 2d0a 2020  ce ----------.  
+00013280: 2020 6966 2828 4c68 7350 726f 6772 6573    if((LhsProgres
+00013290: 7348 616c 6620 3c20 4c68 7350 726f 6772  sHalf < LhsProgr
+000132a0: 6573 7329 2026 2620 6d72 3e3d 4c68 7350  ess) && mr>=LhsP
+000132b0: 726f 6772 6573 7348 616c 6629 0a20 2020  rogressHalf).   
+000132c0: 207b 0a20 2020 2020 206c 6873 5f70 726f   {.      lhs_pro
+000132d0: 6365 7373 5f66 7261 6374 696f 6e5f 6f66  cess_fraction_of
+000132e0: 5f70 6163 6b65 743c 6e72 2c20 4c68 7350  _packet<nr, LhsP
+000132f0: 726f 6772 6573 7348 616c 662c 2052 6873  rogressHalf, Rhs
+00013300: 5072 6f67 7265 7373 4861 6c66 2c20 4c68  ProgressHalf, Lh
+00013310: 7353 6361 6c61 722c 2052 6873 5363 616c  sScalar, RhsScal
+00013320: 6172 2c20 5265 7353 6361 6c61 722c 2041  ar, ResScalar, A
+00013330: 6363 5061 636b 6574 4861 6c66 2c20 4c68  ccPacketHalf, Lh
+00013340: 7350 6163 6b65 7448 616c 662c 2052 6873  sPacketHalf, Rhs
+00013350: 5061 636b 6574 4861 6c66 2c20 5265 7350  PacketHalf, ResP
+00013360: 6163 6b65 7448 616c 662c 2048 616c 6654  acketHalf, HalfT
+00013370: 7261 6974 732c 204c 696e 6561 724d 6170  raits, LinearMap
+00013380: 7065 722c 2044 6174 614d 6170 7065 723e  per, DataMapper>
+00013390: 2070 3b0a 2020 2020 2020 7028 7265 732c   p;.      p(res,
+000133a0: 2062 6c6f 636b 412c 2062 6c6f 636b 422c   blockA, blockB,
+000133b0: 2061 6c70 6861 2c20 7065 656c 6564 5f6d   alpha, peeled_m
+000133c0: 6331 2c20 7065 656c 6564 5f6d 635f 6861  c1, peeled_mc_ha
+000133d0: 6c66 2c20 7374 7269 6465 412c 2073 7472  lf, strideA, str
+000133e0: 6964 6542 2c20 6f66 6673 6574 412c 206f  ideB, offsetA, o
+000133f0: 6666 7365 7442 2c20 7072 6566 6574 6368  ffsetB, prefetch
+00013400: 5f72 6573 5f6f 6666 7365 742c 2070 6565  _res_offset, pee
+00013410: 6c65 645f 6b63 2c20 706b 2c20 636f 6c73  led_kc, pk, cols
+00013420: 2c20 6465 7074 682c 2070 6163 6b65 745f  , depth, packet_
+00013430: 636f 6c73 3429 3b0a 2020 2020 7d0a 2020  cols4);.    }.  
+00013440: 2020 2f2f 2d2d 2d2d 2d2d 2d2d 2d2d 2050    //---------- P
+00013450: 726f 6365 7373 204c 6873 5072 6f67 7265  rocess LhsProgre
+00013460: 7373 5175 6172 7465 7220 726f 7773 2061  ssQuarter rows a
+00013470: 7420 6f6e 6365 202d 2d2d 2d2d 2d2d 2d2d  t once ---------
+00013480: 2d0a 2020 2020 6966 2828 4c68 7350 726f  -.    if((LhsPro
+00013490: 6772 6573 7351 7561 7274 6572 203c 204c  gressQuarter < L
+000134a0: 6873 5072 6f67 7265 7373 4861 6c66 2920  hsProgressHalf) 
+000134b0: 2626 206d 723e 3d4c 6873 5072 6f67 7265  && mr>=LhsProgre
+000134c0: 7373 5175 6172 7465 7229 0a20 2020 207b  ssQuarter).    {
+000134d0: 0a20 2020 2020 206c 6873 5f70 726f 6365  .      lhs_proce
+000134e0: 7373 5f66 7261 6374 696f 6e5f 6f66 5f70  ss_fraction_of_p
+000134f0: 6163 6b65 743c 6e72 2c20 4c68 7350 726f  acket<nr, LhsPro
+00013500: 6772 6573 7351 7561 7274 6572 2c20 5268  gressQuarter, Rh
+00013510: 7350 726f 6772 6573 7351 7561 7274 6572  sProgressQuarter
+00013520: 2c20 4c68 7353 6361 6c61 722c 2052 6873  , LhsScalar, Rhs
+00013530: 5363 616c 6172 2c20 5265 7353 6361 6c61  Scalar, ResScala
+00013540: 722c 2041 6363 5061 636b 6574 5175 6172  r, AccPacketQuar
+00013550: 7465 722c 204c 6873 5061 636b 6574 5175  ter, LhsPacketQu
+00013560: 6172 7465 722c 2052 6873 5061 636b 6574  arter, RhsPacket
+00013570: 5175 6172 7465 722c 2052 6573 5061 636b  Quarter, ResPack
+00013580: 6574 5175 6172 7465 722c 2051 7561 7274  etQuarter, Quart
+00013590: 6572 5472 6169 7473 2c20 4c69 6e65 6172  erTraits, Linear
+000135a0: 4d61 7070 6572 2c20 4461 7461 4d61 7070  Mapper, DataMapp
+000135b0: 6572 3e20 703b 0a20 2020 2020 2070 2872  er> p;.      p(r
+000135c0: 6573 2c20 626c 6f63 6b41 2c20 626c 6f63  es, blockA, bloc
+000135d0: 6b42 2c20 616c 7068 612c 2070 6565 6c65  kB, alpha, peele
+000135e0: 645f 6d63 5f68 616c 662c 2070 6565 6c65  d_mc_half, peele
+000135f0: 645f 6d63 5f71 7561 7274 6572 2c20 7374  d_mc_quarter, st
+00013600: 7269 6465 412c 2073 7472 6964 6542 2c20  rideA, strideB, 
+00013610: 6f66 6673 6574 412c 206f 6666 7365 7442  offsetA, offsetB
+00013620: 2c20 7072 6566 6574 6368 5f72 6573 5f6f  , prefetch_res_o
+00013630: 6666 7365 742c 2070 6565 6c65 645f 6b63  ffset, peeled_kc
+00013640: 2c20 706b 2c20 636f 6c73 2c20 6465 7074  , pk, cols, dept
+00013650: 682c 2070 6163 6b65 745f 636f 6c73 3429  h, packet_cols4)
+00013660: 3b0a 2020 2020 7d0a 2020 2020 2f2f 2d2d  ;.    }.    //--
+00013670: 2d2d 2d2d 2d2d 2d2d 2050 726f 6365 7373  -------- Process
+00013680: 2072 656d 6169 6e69 6e67 2072 6f77 732c   remaining rows,
+00013690: 2031 2061 7420 6f6e 6365 202d 2d2d 2d2d   1 at once -----
+000136a0: 2d2d 2d2d 2d0a 2020 2020 6966 2870 6565  -----.    if(pee
+000136b0: 6c65 645f 6d63 5f71 7561 7274 6572 3c72  led_mc_quarter<r
+000136c0: 6f77 7329 0a20 2020 207b 0a20 2020 2020  ows).    {.     
+000136d0: 202f 2f20 6c6f 6f70 206f 6e20 6561 6368   // loop on each
+000136e0: 2070 616e 656c 206f 6620 7468 6520 7268   panel of the rh
+000136f0: 730a 2020 2020 2020 666f 7228 496e 6465  s.      for(Inde
+00013700: 7820 6a32 3d30 3b20 6a32 3c70 6163 6b65  x j2=0; j2<packe
+00013710: 745f 636f 6c73 343b 206a 322b 3d6e 7229  t_cols4; j2+=nr)
+00013720: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
+00013730: 202f 2f20 6c6f 6f70 206f 6e20 6561 6368   // loop on each
+00013740: 2072 6f77 206f 6620 7468 6520 6c68 7320   row of the lhs 
+00013750: 2831 2a4c 6873 5072 6f67 7265 7373 2078  (1*LhsProgress x
+00013760: 2064 6570 7468 290a 2020 2020 2020 2020   depth).        
+00013770: 666f 7228 496e 6465 7820 693d 7065 656c  for(Index i=peel
+00013780: 6564 5f6d 635f 7175 6172 7465 723b 2069  ed_mc_quarter; i
+00013790: 3c72 6f77 733b 2069 2b3d 3129 0a20 2020  <rows; i+=1).   
+000137a0: 2020 2020 207b 0a20 2020 2020 2020 2020       {.         
+000137b0: 2063 6f6e 7374 204c 6873 5363 616c 6172   const LhsScalar
+000137c0: 2a20 626c 4120 3d20 2662 6c6f 636b 415b  * blA = &blockA[
+000137d0: 692a 7374 7269 6465 412b 6f66 6673 6574  i*strideA+offset
+000137e0: 415d 3b0a 2020 2020 2020 2020 2020 7072  A];.          pr
+000137f0: 6566 6574 6368 2826 626c 415b 305d 293b  efetch(&blA[0]);
+00013800: 0a20 2020 2020 2020 2020 2063 6f6e 7374  .          const
+00013810: 2052 6873 5363 616c 6172 2a20 626c 4220   RhsScalar* blB 
+00013820: 3d20 2662 6c6f 636b 425b 6a32 2a73 7472  = &blockB[j2*str
+00013830: 6964 6542 2b6f 6666 7365 7442 2a6e 725d  ideB+offsetB*nr]
+00013840: 3b0a 0a20 2020 2020 2020 2020 202f 2f20  ;..          // 
+00013850: 4966 204c 6873 5072 6f67 7265 7373 2069  If LhsProgress i
+00013860: 7320 3820 6f72 2031 362c 2069 7420 6173  s 8 or 16, it as
+00013870: 7375 6d65 7320 7468 6174 2074 6865 7265  sumes that there
+00013880: 2069 7320 610a 2020 2020 2020 2020 2020   is a.          
+00013890: 2f2f 2068 616c 6620 6f72 2071 7561 7274  // half or quart
+000138a0: 6572 2070 6163 6b65 742c 2072 6573 7065  er packet, respe
+000138b0: 6374 6976 656c 792c 206f 6620 7468 6520  ctively, of the 
+000138c0: 7361 6d65 2073 697a 6520 6173 0a20 2020  same size as.   
+000138d0: 2020 2020 2020 202f 2f20 6e72 2028 7768         // nr (wh
+000138e0: 6963 6820 6973 2063 7572 7265 6e74 6c79  ich is currently
+000138f0: 2034 2920 666f 7220 7468 6520 7265 7475   4) for the retu
+00013900: 726e 2074 7970 652e 0a20 2020 2020 2020  rn type..       
+00013910: 2020 2063 6f6e 7374 2069 6e74 2053 5265     const int SRe
+00013920: 7350 6163 6b65 7448 616c 6653 697a 6520  sPacketHalfSize 
+00013930: 3d20 756e 7061 636b 6574 5f74 7261 6974  = unpacket_trait
+00013940: 733c 7479 7065 6e61 6d65 2075 6e70 6163  s<typename unpac
+00013950: 6b65 745f 7472 6169 7473 3c53 5265 7350  ket_traits<SResP
+00013960: 6163 6b65 743e 3a3a 6861 6c66 3e3a 3a73  acket>::half>::s
+00013970: 697a 653b 0a20 2020 2020 2020 2020 2063  ize;.          c
+00013980: 6f6e 7374 2069 6e74 2053 5265 7350 6163  onst int SResPac
+00013990: 6b65 7451 7561 7274 6572 5369 7a65 203d  ketQuarterSize =
+000139a0: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
+000139b0: 3c74 7970 656e 616d 6520 756e 7061 636b  <typename unpack
+000139c0: 6574 5f74 7261 6974 733c 7479 7065 6e61  et_traits<typena
+000139d0: 6d65 2075 6e70 6163 6b65 745f 7472 6169  me unpacket_trai
+000139e0: 7473 3c53 5265 7350 6163 6b65 743e 3a3a  ts<SResPacket>::
+000139f0: 6861 6c66 3e3a 3a68 616c 663e 3a3a 7369  half>::half>::si
+00013a00: 7a65 3b0a 2020 2020 2020 2020 2020 6966  ze;.          if
+00013a10: 2028 2853 7761 7070 6564 5472 6169 7473   ((SwappedTraits
+00013a20: 3a3a 4c68 7350 726f 6772 6573 7320 2520  ::LhsProgress % 
+00013a30: 3429 203d 3d20 3020 2626 0a20 2020 2020  4) == 0 &&.     
+00013a40: 2020 2020 2020 2020 2028 5377 6170 7065           (Swappe
+00013a50: 6454 7261 6974 733a 3a4c 6873 5072 6f67  dTraits::LhsProg
+00013a60: 7265 7373 3c3d 3136 2920 2626 0a20 2020  ress<=16) &&.   
+00013a70: 2020 2020 2020 2020 2020 2028 5377 6170             (Swap
+00013a80: 7065 6454 7261 6974 733a 3a4c 6873 5072  pedTraits::LhsPr
+00013a90: 6f67 7265 7373 213d 3820 207c 7c20 5352  ogress!=8  || SR
+00013aa0: 6573 5061 636b 6574 4861 6c66 5369 7a65  esPacketHalfSize
+00013ab0: 3d3d 6e72 2920 2626 0a20 2020 2020 2020  ==nr) &&.       
+00013ac0: 2020 2020 2020 2028 5377 6170 7065 6454         (SwappedT
+00013ad0: 7261 6974 733a 3a4c 6873 5072 6f67 7265  raits::LhsProgre
+00013ae0: 7373 213d 3136 207c 7c20 5352 6573 5061  ss!=16 || SResPa
+00013af0: 636b 6574 5175 6172 7465 7253 697a 653d  cketQuarterSize=
+00013b00: 3d6e 7229 290a 2020 2020 2020 2020 2020  =nr)).          
+00013b10: 7b0a 2020 2020 2020 2020 2020 2020 5341  {.            SA
+00013b20: 6363 5061 636b 6574 2043 302c 2043 312c  ccPacket C0, C1,
+00013b30: 2043 322c 2043 333b 0a20 2020 2020 2020   C2, C3;.       
+00013b40: 2020 2020 2073 7472 6169 7473 2e69 6e69       straits.ini
+00013b50: 7441 6363 2843 3029 3b0a 2020 2020 2020  tAcc(C0);.      
+00013b60: 2020 2020 2020 7374 7261 6974 732e 696e        straits.in
+00013b70: 6974 4163 6328 4331 293b 0a20 2020 2020  itAcc(C1);.     
+00013b80: 2020 2020 2020 2073 7472 6169 7473 2e69         straits.i
+00013b90: 6e69 7441 6363 2843 3229 3b0a 2020 2020  nitAcc(C2);.    
+00013ba0: 2020 2020 2020 2020 7374 7261 6974 732e          straits.
+00013bb0: 696e 6974 4163 6328 4333 293b 0a0a 2020  initAcc(C3);..  
+00013bc0: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
+00013bd0: 496e 6465 7820 7370 6b20 2020 3d20 2873  Index spk   = (s
+00013be0: 7464 3a3a 6d61 7829 2831 2c53 7761 7070  td::max)(1,Swapp
+00013bf0: 6564 5472 6169 7473 3a3a 4c68 7350 726f  edTraits::LhsPro
+00013c00: 6772 6573 732f 3429 3b0a 2020 2020 2020  gress/4);.      
+00013c10: 2020 2020 2020 636f 6e73 7420 496e 6465        const Inde
+00013c20: 7820 656e 646b 2020 3d20 2864 6570 7468  x endk  = (depth
+00013c30: 2f73 706b 292a 7370 6b3b 0a20 2020 2020  /spk)*spk;.     
+00013c40: 2020 2020 2020 2063 6f6e 7374 2049 6e64         const Ind
+00013c50: 6578 2065 6e64 6b34 203d 2028 6465 7074  ex endk4 = (dept
+00013c60: 682f 2873 706b 2a34 2929 2a28 7370 6b2a  h/(spk*4))*(spk*
+00013c70: 3429 3b0a 0a20 2020 2020 2020 2020 2020  4);..           
+00013c80: 2049 6e64 6578 206b 3d30 3b0a 2020 2020   Index k=0;.    
+00013c90: 2020 2020 2020 2020 666f 7228 3b20 6b3c          for(; k<
+00013ca0: 656e 646b 343b 206b 2b3d 342a 7370 6b29  endk4; k+=4*spk)
+00013cb0: 0a20 2020 2020 2020 2020 2020 207b 0a20  .            {. 
+00013cc0: 2020 2020 2020 2020 2020 2020 2053 4c68               SLh
+00013cd0: 7350 6163 6b65 7420 4130 2c41 313b 0a20  sPacket A0,A1;. 
+00013ce0: 2020 2020 2020 2020 2020 2020 2053 5268               SRh
+00013cf0: 7350 6163 6b65 7420 425f 302c 425f 313b  sPacket B_0,B_1;
+00013d00: 0a0a 2020 2020 2020 2020 2020 2020 2020  ..              
+00013d10: 7374 7261 6974 732e 6c6f 6164 4c68 7355  straits.loadLhsU
+00013d20: 6e61 6c69 676e 6564 2862 6c42 2b30 2a53  naligned(blB+0*S
+00013d30: 7761 7070 6564 5472 6169 7473 3a3a 4c68  wappedTraits::Lh
+00013d40: 7350 726f 6772 6573 732c 2041 3029 3b0a  sProgress, A0);.
+00013d50: 2020 2020 2020 2020 2020 2020 2020 7374                st
+00013d60: 7261 6974 732e 6c6f 6164 4c68 7355 6e61  raits.loadLhsUna
+00013d70: 6c69 676e 6564 2862 6c42 2b31 2a53 7761  ligned(blB+1*Swa
+00013d80: 7070 6564 5472 6169 7473 3a3a 4c68 7350  ppedTraits::LhsP
+00013d90: 726f 6772 6573 732c 2041 3129 3b0a 0a20  rogress, A1);.. 
+00013da0: 2020 2020 2020 2020 2020 2020 2073 7472               str
+00013db0: 6169 7473 2e6c 6f61 6452 6873 5175 6164  aits.loadRhsQuad
+00013dc0: 2862 6c41 2b30 2a73 706b 2c20 425f 3029  (blA+0*spk, B_0)
+00013dd0: 3b0a 2020 2020 2020 2020 2020 2020 2020  ;.              
+00013de0: 7374 7261 6974 732e 6c6f 6164 5268 7351  straits.loadRhsQ
+00013df0: 7561 6428 626c 412b 312a 7370 6b2c 2042  uad(blA+1*spk, B
+00013e00: 5f31 293b 0a20 2020 2020 2020 2020 2020  _1);.           
+00013e10: 2020 2073 7472 6169 7473 2e6d 6164 6428     straits.madd(
+00013e20: 4130 2c42 5f30 2c43 302c 425f 302c 2066  A0,B_0,C0,B_0, f
+00013e30: 6978 3c30 3e29 3b0a 2020 2020 2020 2020  ix<0>);.        
+00013e40: 2020 2020 2020 7374 7261 6974 732e 6d61        straits.ma
+00013e50: 6464 2841 312c 425f 312c 4331 2c42 5f31  dd(A1,B_1,C1,B_1
+00013e60: 2c20 6669 783c 303e 293b 0a0a 2020 2020  , fix<0>);..    
+00013e70: 2020 2020 2020 2020 2020 7374 7261 6974            strait
+00013e80: 732e 6c6f 6164 4c68 7355 6e61 6c69 676e  s.loadLhsUnalign
+00013e90: 6564 2862 6c42 2b32 2a53 7761 7070 6564  ed(blB+2*Swapped
+00013ea0: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
+00013eb0: 6573 732c 2041 3029 3b0a 2020 2020 2020  ess, A0);.      
+00013ec0: 2020 2020 2020 2020 7374 7261 6974 732e          straits.
+00013ed0: 6c6f 6164 4c68 7355 6e61 6c69 676e 6564  loadLhsUnaligned
+00013ee0: 2862 6c42 2b33 2a53 7761 7070 6564 5472  (blB+3*SwappedTr
+00013ef0: 6169 7473 3a3a 4c68 7350 726f 6772 6573  aits::LhsProgres
+00013f00: 732c 2041 3129 3b0a 2020 2020 2020 2020  s, A1);.        
+00013f10: 2020 2020 2020 7374 7261 6974 732e 6c6f        straits.lo
+00013f20: 6164 5268 7351 7561 6428 626c 412b 322a  adRhsQuad(blA+2*
+00013f30: 7370 6b2c 2042 5f30 293b 0a20 2020 2020  spk, B_0);.     
+00013f40: 2020 2020 2020 2020 2073 7472 6169 7473           straits
+00013f50: 2e6c 6f61 6452 6873 5175 6164 2862 6c41  .loadRhsQuad(blA
+00013f60: 2b33 2a73 706b 2c20 425f 3129 3b0a 2020  +3*spk, B_1);.  
+00013f70: 2020 2020 2020 2020 2020 2020 7374 7261              stra
+00013f80: 6974 732e 6d61 6464 2841 302c 425f 302c  its.madd(A0,B_0,
+00013f90: 4332 2c42 5f30 2c20 6669 783c 303e 293b  C2,B_0, fix<0>);
+00013fa0: 0a20 2020 2020 2020 2020 2020 2020 2073  .              s
+00013fb0: 7472 6169 7473 2e6d 6164 6428 4131 2c42  traits.madd(A1,B
+00013fc0: 5f31 2c43 332c 425f 312c 2066 6978 3c30  _1,C3,B_1, fix<0
+00013fd0: 3e29 3b0a 0a20 2020 2020 2020 2020 2020  >);..           
+00013fe0: 2020 2062 6c42 202b 3d20 342a 5377 6170     blB += 4*Swap
+00013ff0: 7065 6454 7261 6974 733a 3a4c 6873 5072  pedTraits::LhsPr
+00014000: 6f67 7265 7373 3b0a 2020 2020 2020 2020  ogress;.        
+00014010: 2020 2020 2020 626c 4120 2b3d 2034 2a73        blA += 4*s
+00014020: 706b 3b0a 2020 2020 2020 2020 2020 2020  pk;.            
+00014030: 7d0a 2020 2020 2020 2020 2020 2020 4330  }.            C0
+00014040: 203d 2070 6164 6428 7061 6464 2843 302c   = padd(padd(C0,
+00014050: 4331 292c 7061 6464 2843 322c 4333 2929  C1),padd(C2,C3))
+00014060: 3b0a 2020 2020 2020 2020 2020 2020 666f  ;.            fo
+00014070: 7228 3b20 6b3c 656e 646b 3b20 6b2b 3d73  r(; k<endk; k+=s
+00014080: 706b 290a 2020 2020 2020 2020 2020 2020  pk).            
+00014090: 7b0a 2020 2020 2020 2020 2020 2020 2020  {.              
+000140a0: 534c 6873 5061 636b 6574 2041 303b 0a20  SLhsPacket A0;. 
+000140b0: 2020 2020 2020 2020 2020 2020 2053 5268               SRh
+000140c0: 7350 6163 6b65 7420 425f 303b 0a0a 2020  sPacket B_0;..  
+000140d0: 2020 2020 2020 2020 2020 2020 7374 7261              stra
+000140e0: 6974 732e 6c6f 6164 4c68 7355 6e61 6c69  its.loadLhsUnali
+000140f0: 676e 6564 2862 6c42 2c20 4130 293b 0a20  gned(blB, A0);. 
+00014100: 2020 2020 2020 2020 2020 2020 2073 7472               str
+00014110: 6169 7473 2e6c 6f61 6452 6873 5175 6164  aits.loadRhsQuad
+00014120: 2862 6c41 2c20 425f 3029 3b0a 2020 2020  (blA, B_0);.    
+00014130: 2020 2020 2020 2020 2020 7374 7261 6974            strait
+00014140: 732e 6d61 6464 2841 302c 425f 302c 4330  s.madd(A0,B_0,C0
+00014150: 2c42 5f30 2c20 6669 783c 303e 293b 0a0a  ,B_0, fix<0>);..
+00014160: 2020 2020 2020 2020 2020 2020 2020 626c                bl
+00014170: 4220 2b3d 2053 7761 7070 6564 5472 6169  B += SwappedTrai
+00014180: 7473 3a3a 4c68 7350 726f 6772 6573 733b  ts::LhsProgress;
+00014190: 0a20 2020 2020 2020 2020 2020 2020 2062  .              b
+000141a0: 6c41 202b 3d20 7370 6b3b 0a20 2020 2020  lA += spk;.     
+000141b0: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+000141c0: 2020 2020 2069 6628 5377 6170 7065 6454       if(SwappedT
+000141d0: 7261 6974 733a 3a4c 6873 5072 6f67 7265  raits::LhsProgre
+000141e0: 7373 3d3d 3829 0a20 2020 2020 2020 2020  ss==8).         
+000141f0: 2020 207b 0a20 2020 2020 2020 2020 2020     {.           
+00014200: 2020 202f 2f20 5370 6563 6961 6c20 6361     // Special ca
+00014210: 7365 2077 6865 7265 2077 6520 6861 7665  se where we have
+00014220: 2074 6f20 6669 7273 7420 7265 6475 6365   to first reduce
+00014230: 2074 6865 2061 6363 756d 756c 6174 696f   the accumulatio
+00014240: 6e20 7265 6769 7374 6572 2043 300a 2020  n register C0.  
+00014250: 2020 2020 2020 2020 2020 2020 7479 7065              type
+00014260: 6465 6620 7479 7065 6e61 6d65 2063 6f6e  def typename con
+00014270: 6469 7469 6f6e 616c 3c53 7761 7070 6564  ditional<Swapped
+00014280: 5472 6169 7473 3a3a 4c68 7350 726f 6772  Traits::LhsProgr
+00014290: 6573 733e 3d38 2c74 7970 656e 616d 6520  ess>=8,typename 
+000142a0: 756e 7061 636b 6574 5f74 7261 6974 733c  unpacket_traits<
+000142b0: 5352 6573 5061 636b 6574 3e3a 3a68 616c  SResPacket>::hal
+000142c0: 662c 5352 6573 5061 636b 6574 3e3a 3a74  f,SResPacket>::t
+000142d0: 7970 6520 5352 6573 5061 636b 6574 4861  ype SResPacketHa
+000142e0: 6c66 3b0a 2020 2020 2020 2020 2020 2020  lf;.            
+000142f0: 2020 7479 7065 6465 6620 7479 7065 6e61    typedef typena
+00014300: 6d65 2063 6f6e 6469 7469 6f6e 616c 3c53  me conditional<S
+00014310: 7761 7070 6564 5472 6169 7473 3a3a 4c68  wappedTraits::Lh
+00014320: 7350 726f 6772 6573 733e 3d38 2c74 7970  sProgress>=8,typ
+00014330: 656e 616d 6520 756e 7061 636b 6574 5f74  ename unpacket_t
+00014340: 7261 6974 733c 534c 6873 5061 636b 6574  raits<SLhsPacket
+00014350: 3e3a 3a68 616c 662c 534c 6873 5061 636b  >::half,SLhsPack
+00014360: 6574 3e3a 3a74 7970 6520 534c 6873 5061  et>::type SLhsPa
+00014370: 636b 6574 4861 6c66 3b0a 2020 2020 2020  cketHalf;.      
+00014380: 2020 2020 2020 2020 7479 7065 6465 6620          typedef 
+00014390: 7479 7065 6e61 6d65 2063 6f6e 6469 7469  typename conditi
+000143a0: 6f6e 616c 3c53 7761 7070 6564 5472 6169  onal<SwappedTrai
+000143b0: 7473 3a3a 4c68 7350 726f 6772 6573 733e  ts::LhsProgress>
+000143c0: 3d38 2c74 7970 656e 616d 6520 756e 7061  =8,typename unpa
+000143d0: 636b 6574 5f74 7261 6974 733c 5352 6873  cket_traits<SRhs
+000143e0: 5061 636b 6574 3e3a 3a68 616c 662c 5352  Packet>::half,SR
+000143f0: 6873 5061 636b 6574 3e3a 3a74 7970 6520  hsPacket>::type 
+00014400: 5352 6873 5061 636b 6574 4861 6c66 3b0a  SRhsPacketHalf;.
+00014410: 2020 2020 2020 2020 2020 2020 2020 7479                ty
+00014420: 7065 6465 6620 7479 7065 6e61 6d65 2063  pedef typename c
+00014430: 6f6e 6469 7469 6f6e 616c 3c53 7761 7070  onditional<Swapp
+00014440: 6564 5472 6169 7473 3a3a 4c68 7350 726f  edTraits::LhsPro
+00014450: 6772 6573 733e 3d38 2c74 7970 656e 616d  gress>=8,typenam
+00014460: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
+00014470: 733c 5341 6363 5061 636b 6574 3e3a 3a68  s<SAccPacket>::h
+00014480: 616c 662c 5341 6363 5061 636b 6574 3e3a  alf,SAccPacket>:
+00014490: 3a74 7970 6520 5341 6363 5061 636b 6574  :type SAccPacket
+000144a0: 4861 6c66 3b0a 0a20 2020 2020 2020 2020  Half;..         
+000144b0: 2020 2020 2053 5265 7350 6163 6b65 7448       SResPacketH
+000144c0: 616c 6620 5220 3d20 7265 732e 7465 6d70  alf R = res.temp
+000144d0: 6c61 7465 2067 6174 6865 7250 6163 6b65  late gatherPacke
+000144e0: 743c 5352 6573 5061 636b 6574 4861 6c66  t<SResPacketHalf
+000144f0: 3e28 692c 206a 3229 3b0a 2020 2020 2020  >(i, j2);.      
+00014500: 2020 2020 2020 2020 5352 6573 5061 636b          SResPack
+00014510: 6574 4861 6c66 2061 6c70 6861 7620 3d20  etHalf alphav = 
+00014520: 7073 6574 313c 5352 6573 5061 636b 6574  pset1<SResPacket
+00014530: 4861 6c66 3e28 616c 7068 6129 3b0a 0a20  Half>(alpha);.. 
+00014540: 2020 2020 2020 2020 2020 2020 2069 6628               if(
+00014550: 6465 7074 682d 656e 646b 3e30 290a 2020  depth-endk>0).  
+00014560: 2020 2020 2020 2020 2020 2020 7b0a 2020              {.  
+00014570: 2020 2020 2020 2020 2020 2020 2020 2f2f                //
+00014580: 2057 6520 6861 7665 2074 6f20 6861 6e64   We have to hand
+00014590: 6c65 2074 6865 206c 6173 7420 726f 7720  le the last row 
+000145a0: 6f66 2074 6865 2072 6873 2077 6869 6368  of the rhs which
+000145b0: 2063 6f72 7265 7370 6f6e 6473 2074 6f20   corresponds to 
+000145c0: 6120 6861 6c66 2d70 6163 6b65 740a 2020  a half-packet.  
+000145d0: 2020 2020 2020 2020 2020 2020 2020 534c                SL
+000145e0: 6873 5061 636b 6574 4861 6c66 2061 303b  hsPacketHalf a0;
+000145f0: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014600: 2053 5268 7350 6163 6b65 7448 616c 6620   SRhsPacketHalf 
+00014610: 6230 3b0a 2020 2020 2020 2020 2020 2020  b0;.            
+00014620: 2020 2020 7374 7261 6974 732e 6c6f 6164      straits.load
+00014630: 4c68 7355 6e61 6c69 676e 6564 2862 6c42  LhsUnaligned(blB
+00014640: 2c20 6130 293b 0a20 2020 2020 2020 2020  , a0);.         
+00014650: 2020 2020 2020 2073 7472 6169 7473 2e6c         straits.l
+00014660: 6f61 6452 6873 2862 6c41 2c20 6230 293b  oadRhs(blA, b0);
+00014670: 0a20 2020 2020 2020 2020 2020 2020 2020  .               
+00014680: 2053 4163 6350 6163 6b65 7448 616c 6620   SAccPacketHalf 
+00014690: 6330 203d 2070 7265 6475 785f 6861 6c66  c0 = predux_half
+000146a0: 5f64 6f77 746f 3428 4330 293b 0a20 2020  _dowto4(C0);.   
+000146b0: 2020 2020 2020 2020 2020 2020 2073 7472               str
+000146c0: 6169 7473 2e6d 6164 6428 6130 2c62 302c  aits.madd(a0,b0,
+000146d0: 6330 2c62 302c 2066 6978 3c30 3e29 3b0a  c0,b0, fix<0>);.
+000146e0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+000146f0: 7374 7261 6974 732e 6163 6328 6330 2c20  straits.acc(c0, 
+00014700: 616c 7068 6176 2c20 5229 3b0a 2020 2020  alphav, R);.    
+00014710: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+00014720: 2020 2020 2020 2020 2020 656c 7365 0a20            else. 
+00014730: 2020 2020 2020 2020 2020 2020 207b 0a20               {. 
+00014740: 2020 2020 2020 2020 2020 2020 2020 2073                 s
+00014750: 7472 6169 7473 2e61 6363 2870 7265 6475  traits.acc(predu
+00014760: 785f 6861 6c66 5f64 6f77 746f 3428 4330  x_half_dowto4(C0
+00014770: 292c 2061 6c70 6861 762c 2052 293b 0a20  ), alphav, R);. 
+00014780: 2020 2020 2020 2020 2020 2020 207d 0a20               }. 
+00014790: 2020 2020 2020 2020 2020 2020 2072 6573               res
+000147a0: 2e73 6361 7474 6572 5061 636b 6574 2869  .scatterPacket(i
+000147b0: 2c20 6a32 2c20 5229 3b0a 2020 2020 2020  , j2, R);.      
+000147c0: 2020 2020 2020 7d0a 2020 2020 2020 2020        }.        
+000147d0: 2020 2020 656c 7365 2069 6620 2853 7761      else if (Swa
+000147e0: 7070 6564 5472 6169 7473 3a3a 4c68 7350  ppedTraits::LhsP
+000147f0: 726f 6772 6573 733d 3d31 3629 0a20 2020  rogress==16).   
+00014800: 2020 2020 2020 2020 207b 0a20 2020 2020           {.     
+00014810: 2020 2020 2020 2020 202f 2f20 5370 6563           // Spec
+00014820: 6961 6c20 6361 7365 2077 6865 7265 2077  ial case where w
+00014830: 6520 6861 7665 2074 6f20 6669 7273 7420  e have to first 
+00014840: 7265 6475 6365 2074 6865 0a20 2020 2020  reduce the.     
+00014850: 2020 2020 2020 2020 202f 2f20 6163 6375           // accu
+00014860: 6d75 6c61 7469 6f6e 2072 6567 6973 7465  mulation registe
+00014870: 7220 4330 2e20 5765 2073 7065 6369 616c  r C0. We special
+00014880: 697a 6520 7468 6520 626c 6f63 6b20 696e  ize the block in
+00014890: 0a20 2020 2020 2020 2020 2020 2020 202f  .              /
+000148a0: 2f20 7465 6d70 6c61 7465 2066 6f72 6d2c  / template form,
+000148b0: 2073 6f20 7468 6174 204c 6873 5072 6f67   so that LhsProg
+000148c0: 7265 7373 203c 2031 3620 7061 7468 7320  ress < 16 paths 
+000148d0: 646f 6e27 740a 2020 2020 2020 2020 2020  don't.          
+000148e0: 2020 2020 2f2f 2066 6169 6c20 746f 2063      // fail to c
+000148f0: 6f6d 7069 6c65 0a20 2020 2020 2020 2020  ompile.         
+00014900: 2020 2020 206c 6173 745f 726f 775f 7072       last_row_pr
+00014910: 6f63 6573 735f 3136 5f70 6163 6b65 7473  ocess_16_packets
+00014920: 3c4c 6873 5363 616c 6172 2c20 5268 7353  <LhsScalar, RhsS
+00014930: 6361 6c61 722c 2049 6e64 6578 2c20 4461  calar, Index, Da
+00014940: 7461 4d61 7070 6572 2c20 6d72 2c20 6e72  taMapper, mr, nr
+00014950: 2c20 436f 6e6a 7567 6174 654c 6873 2c20  , ConjugateLhs, 
+00014960: 436f 6e6a 7567 6174 6552 6873 3e20 703b  ConjugateRhs> p;
+00014970: 0a09 2020 2020 2020 2020 2020 2020 7028  ..            p(
+00014980: 7265 732c 2073 7472 6169 7473 2c20 626c  res, straits, bl
+00014990: 412c 2062 6c42 2c20 6465 7074 682c 2065  A, blB, depth, e
+000149a0: 6e64 6b2c 2069 2c20 6a32 2c61 6c70 6861  ndk, i, j2,alpha
+000149b0: 2c20 4330 293b 0a20 2020 2020 2020 2020  , C0);.         
+000149c0: 2020 207d 0a20 2020 2020 2020 2020 2020     }.           
+000149d0: 2065 6c73 650a 2020 2020 2020 2020 2020   else.          
+000149e0: 2020 7b0a 2020 2020 2020 2020 2020 2020    {.            
+000149f0: 2020 5352 6573 5061 636b 6574 2052 203d    SResPacket R =
+00014a00: 2072 6573 2e74 656d 706c 6174 6520 6761   res.template ga
+00014a10: 7468 6572 5061 636b 6574 3c53 5265 7350  therPacket<SResP
+00014a20: 6163 6b65 743e 2869 2c20 6a32 293b 0a20  acket>(i, j2);. 
+00014a30: 2020 2020 2020 2020 2020 2020 2053 5265               SRe
+00014a40: 7350 6163 6b65 7420 616c 7068 6176 203d  sPacket alphav =
+00014a50: 2070 7365 7431 3c53 5265 7350 6163 6b65   pset1<SResPacke
+00014a60: 743e 2861 6c70 6861 293b 0a20 2020 2020  t>(alpha);.     
+00014a70: 2020 2020 2020 2020 2073 7472 6169 7473           straits
+00014a80: 2e61 6363 2843 302c 2061 6c70 6861 762c  .acc(C0, alphav,
+00014a90: 2052 293b 0a20 2020 2020 2020 2020 2020   R);.           
+00014aa0: 2020 2072 6573 2e73 6361 7474 6572 5061     res.scatterPa
+00014ab0: 636b 6574 2869 2c20 6a32 2c20 5229 3b0a  cket(i, j2, R);.
+00014ac0: 2020 2020 2020 2020 2020 2020 7d0a 2020              }.  
+00014ad0: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
+00014ae0: 2020 2020 656c 7365 202f 2f20 7363 616c      else // scal
+00014af0: 6172 2070 6174 680a 2020 2020 2020 2020  ar path.        
+00014b00: 2020 7b0a 2020 2020 2020 2020 2020 2020    {.            
+00014b10: 2f2f 2067 6574 2061 2031 2078 2034 2072  // get a 1 x 4 r
+00014b20: 6573 2062 6c6f 636b 2061 7320 7265 6769  es block as regi
+00014b30: 7374 6572 730a 2020 2020 2020 2020 2020  sters.          
+00014b40: 2020 5265 7353 6361 6c61 7220 4330 2830    ResScalar C0(0
+00014b50: 292c 2043 3128 3029 2c20 4332 2830 292c  ), C1(0), C2(0),
+00014b60: 2043 3328 3029 3b0a 0a20 2020 2020 2020   C3(0);..       
+00014b70: 2020 2020 2066 6f72 2849 6e64 6578 206b       for(Index k
+00014b80: 3d30 3b20 6b3c 6465 7074 683b 206b 2b2b  =0; k<depth; k++
+00014b90: 290a 2020 2020 2020 2020 2020 2020 7b0a  ).            {.
+00014ba0: 2020 2020 2020 2020 2020 2020 2020 4c68                Lh
+00014bb0: 7353 6361 6c61 7220 4130 3b0a 2020 2020  sScalar A0;.    
+00014bc0: 2020 2020 2020 2020 2020 5268 7353 6361            RhsSca
+00014bd0: 6c61 7220 425f 302c 2042 5f31 3b0a 0a20  lar B_0, B_1;.. 
+00014be0: 2020 2020 2020 2020 2020 2020 2041 3020               A0 
+00014bf0: 3d20 626c 415b 6b5d 3b0a 0a20 2020 2020  = blA[k];..     
+00014c00: 2020 2020 2020 2020 2042 5f30 203d 2062           B_0 = b
+00014c10: 6c42 5b30 5d3b 0a20 2020 2020 2020 2020  lB[0];.         
+00014c20: 2020 2020 2042 5f31 203d 2062 6c42 5b31       B_1 = blB[1
+00014c30: 5d3b 0a20 2020 2020 2020 2020 2020 2020  ];.             
+00014c40: 2043 3020 3d20 636a 2e70 6d61 6464 2841   C0 = cj.pmadd(A
+00014c50: 302c 425f 302c 4330 293b 0a20 2020 2020  0,B_0,C0);.     
+00014c60: 2020 2020 2020 2020 2043 3120 3d20 636a           C1 = cj
+00014c70: 2e70 6d61 6464 2841 302c 425f 312c 4331  .pmadd(A0,B_1,C1
+00014c80: 293b 0a0a 2020 2020 2020 2020 2020 2020  );..            
+00014c90: 2020 425f 3020 3d20 626c 425b 325d 3b0a    B_0 = blB[2];.
+00014ca0: 2020 2020 2020 2020 2020 2020 2020 425f                B_
+00014cb0: 3120 3d20 626c 425b 335d 3b0a 2020 2020  1 = blB[3];.    
+00014cc0: 2020 2020 2020 2020 2020 4332 203d 2063            C2 = c
+00014cd0: 6a2e 706d 6164 6428 4130 2c42 5f30 2c43  j.pmadd(A0,B_0,C
+00014ce0: 3229 3b0a 2020 2020 2020 2020 2020 2020  2);.            
+00014cf0: 2020 4333 203d 2063 6a2e 706d 6164 6428    C3 = cj.pmadd(
+00014d00: 4130 2c42 5f31 2c43 3329 3b0a 0a20 2020  A0,B_1,C3);..   
+00014d10: 2020 2020 2020 2020 2020 2062 6c42 202b             blB +
+00014d20: 3d20 343b 0a20 2020 2020 2020 2020 2020  = 4;.           
+00014d30: 207d 0a20 2020 2020 2020 2020 2020 2072   }.            r
+00014d40: 6573 2869 2c20 6a32 202b 2030 2920 2b3d  es(i, j2 + 0) +=
+00014d50: 2061 6c70 6861 202a 2043 303b 0a20 2020   alpha * C0;.   
+00014d60: 2020 2020 2020 2020 2072 6573 2869 2c20           res(i, 
+00014d70: 6a32 202b 2031 2920 2b3d 2061 6c70 6861  j2 + 1) += alpha
+00014d80: 202a 2043 313b 0a20 2020 2020 2020 2020   * C1;.         
+00014d90: 2020 2072 6573 2869 2c20 6a32 202b 2032     res(i, j2 + 2
+00014da0: 2920 2b3d 2061 6c70 6861 202a 2043 323b  ) += alpha * C2;
+00014db0: 0a20 2020 2020 2020 2020 2020 2072 6573  .            res
+00014dc0: 2869 2c20 6a32 202b 2033 2920 2b3d 2061  (i, j2 + 3) += a
+00014dd0: 6c70 6861 202a 2043 333b 0a20 2020 2020  lpha * C3;.     
+00014de0: 2020 2020 207d 0a20 2020 2020 2020 207d       }.        }
+00014df0: 0a20 2020 2020 207d 0a20 2020 2020 202f  .      }.      /
+00014e00: 2f20 7265 6d61 696e 696e 6720 636f 6c75  / remaining colu
+00014e10: 6d6e 730a 2020 2020 2020 666f 7228 496e  mns.      for(In
+00014e20: 6465 7820 6a32 3d70 6163 6b65 745f 636f  dex j2=packet_co
+00014e30: 6c73 343b 206a 323c 636f 6c73 3b20 6a32  ls4; j2<cols; j2
+00014e40: 2b2b 290a 2020 2020 2020 7b0a 2020 2020  ++).      {.    
+00014e50: 2020 2020 2f2f 206c 6f6f 7020 6f6e 2065      // loop on e
+00014e60: 6163 6820 726f 7720 6f66 2074 6865 206c  ach row of the l
+00014e70: 6873 2028 312a 4c68 7350 726f 6772 6573  hs (1*LhsProgres
+00014e80: 7320 7820 6465 7074 6829 0a20 2020 2020  s x depth).     
+00014e90: 2020 2066 6f72 2849 6e64 6578 2069 3d70     for(Index i=p
+00014ea0: 6565 6c65 645f 6d63 5f71 7561 7274 6572  eeled_mc_quarter
+00014eb0: 3b20 693c 726f 7773 3b20 692b 3d31 290a  ; i<rows; i+=1).
+00014ec0: 2020 2020 2020 2020 7b0a 2020 2020 2020          {.      
+00014ed0: 2020 2020 636f 6e73 7420 4c68 7353 6361      const LhsSca
+00014ee0: 6c61 722a 2062 6c41 203d 2026 626c 6f63  lar* blA = &bloc
+00014ef0: 6b41 5b69 2a73 7472 6964 6541 2b6f 6666  kA[i*strideA+off
+00014f00: 7365 7441 5d3b 0a20 2020 2020 2020 2020  setA];.         
+00014f10: 2070 7265 6665 7463 6828 2662 6c41 5b30   prefetch(&blA[0
+00014f20: 5d29 3b0a 2020 2020 2020 2020 2020 2f2f  ]);.          //
+00014f30: 2067 6574 7320 6120 3120 7820 3120 7265   gets a 1 x 1 re
+00014f40: 7320 626c 6f63 6b20 6173 2072 6567 6973  s block as regis
+00014f50: 7465 7273 0a20 2020 2020 2020 2020 2052  ters.          R
+00014f60: 6573 5363 616c 6172 2043 3028 3029 3b0a  esScalar C0(0);.
+00014f70: 2020 2020 2020 2020 2020 636f 6e73 7420            const 
+00014f80: 5268 7353 6361 6c61 722a 2062 6c42 203d  RhsScalar* blB =
+00014f90: 2026 626c 6f63 6b42 5b6a 322a 7374 7269   &blockB[j2*stri
+00014fa0: 6465 422b 6f66 6673 6574 425d 3b0a 2020  deB+offsetB];.  
+00014fb0: 2020 2020 2020 2020 666f 7228 496e 6465          for(Inde
+00014fc0: 7820 6b3d 303b 206b 3c64 6570 7468 3b20  x k=0; k<depth; 
+00014fd0: 6b2b 2b29 0a20 2020 2020 2020 2020 207b  k++).          {
+00014fe0: 0a20 2020 2020 2020 2020 2020 204c 6873  .            Lhs
+00014ff0: 5363 616c 6172 2041 3020 3d20 626c 415b  Scalar A0 = blA[
+00015000: 6b5d 3b0a 2020 2020 2020 2020 2020 2020  k];.            
+00015010: 5268 7353 6361 6c61 7220 425f 3020 3d20  RhsScalar B_0 = 
+00015020: 626c 425b 6b5d 3b0a 2020 2020 2020 2020  blB[k];.        
+00015030: 2020 2020 4330 203d 2063 6a2e 706d 6164      C0 = cj.pmad
+00015040: 6428 4130 2c20 425f 302c 2043 3029 3b0a  d(A0, B_0, C0);.
+00015050: 2020 2020 2020 2020 2020 7d0a 2020 2020            }.    
+00015060: 2020 2020 2020 7265 7328 692c 206a 3229        res(i, j2)
+00015070: 202b 3d20 616c 7068 6120 2a20 4330 3b0a   += alpha * C0;.
+00015080: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
+00015090: 7d0a 2020 2020 7d0a 2020 7d0a 0a0a 2f2f  }.    }.  }...//
+000150a0: 2070 6163 6b20 6120 626c 6f63 6b20 6f66   pack a block of
+000150b0: 2074 6865 206c 6873 0a2f 2f20 5468 6520   the lhs.// The 
+000150c0: 7472 6176 6572 7361 6c20 6973 2061 7320  traversal is as 
+000150d0: 666f 6c6c 6f77 2028 6d72 3d3d 3429 3a0a  follow (mr==4):.
+000150e0: 2f2f 2020 2030 2020 3420 2038 2031 3220  //   0  4  8 12 
+000150f0: 2e2e 2e0a 2f2f 2020 2031 2020 3520 2039  ....//   1  5  9
+00015100: 2031 3320 2e2e 2e0a 2f2f 2020 2032 2020   13 ....//   2  
+00015110: 3620 3130 2031 3420 2e2e 2e0a 2f2f 2020  6 10 14 ....//  
+00015120: 2033 2020 3720 3131 2031 3520 2e2e 2e0a   3  7 11 15 ....
+00015130: 2f2f 0a2f 2f20 2031 3620 3230 2032 3420  //.//  16 20 24 
+00015140: 3238 202e 2e2e 0a2f 2f20 2031 3720 3231  28 ....//  17 21
+00015150: 2032 3520 3239 202e 2e2e 0a2f 2f20 2031   25 29 ....//  1
+00015160: 3820 3232 2032 3620 3330 202e 2e2e 0a2f  8 22 26 30 ..../
+00015170: 2f20 2031 3920 3233 2032 3720 3331 202e  /  19 23 27 31 .
+00015180: 2e2e 0a2f 2f0a 2f2f 2020 3332 2033 3320  ...//.//  32 33 
+00015190: 3334 2033 3520 2e2e 2e0a 2f2f 2020 3336  34 35 ....//  36
+000151a0: 2033 3620 3338 2033 3920 2e2e 2e0a 7465   36 38 39 ....te
+000151b0: 6d70 6c61 7465 3c74 7970 656e 616d 6520  mplate<typename 
+000151c0: 5363 616c 6172 2c20 7479 7065 6e61 6d65  Scalar, typename
+000151d0: 2049 6e64 6578 2c20 7479 7065 6e61 6d65   Index, typename
+000151e0: 2044 6174 614d 6170 7065 722c 2069 6e74   DataMapper, int
+000151f0: 2050 6163 6b31 2c20 696e 7420 5061 636b   Pack1, int Pack
+00015200: 322c 2074 7970 656e 616d 6520 5061 636b  2, typename Pack
+00015210: 6574 2c20 626f 6f6c 2043 6f6e 6a75 6761  et, bool Conjuga
+00015220: 7465 2c20 626f 6f6c 2050 616e 656c 4d6f  te, bool PanelMo
+00015230: 6465 3e0a 7374 7275 6374 2067 656d 6d5f  de>.struct gemm_
+00015240: 7061 636b 5f6c 6873 3c53 6361 6c61 722c  pack_lhs<Scalar,
+00015250: 2049 6e64 6578 2c20 4461 7461 4d61 7070   Index, DataMapp
+00015260: 6572 2c20 5061 636b 312c 2050 6163 6b32  er, Pack1, Pack2
+00015270: 2c20 5061 636b 6574 2c20 436f 6c4d 616a  , Packet, ColMaj
+00015280: 6f72 2c20 436f 6e6a 7567 6174 652c 2050  or, Conjugate, P
+00015290: 616e 656c 4d6f 6465 3e0a 7b0a 2020 7479  anelMode>.{.  ty
+000152a0: 7065 6465 6620 7479 7065 6e61 6d65 2044  pedef typename D
+000152b0: 6174 614d 6170 7065 723a 3a4c 696e 6561  ataMapper::Linea
+000152c0: 724d 6170 7065 7220 4c69 6e65 6172 4d61  rMapper LinearMa
+000152d0: 7070 6572 3b0a 2020 4549 4745 4e5f 444f  pper;.  EIGEN_DO
+000152e0: 4e54 5f49 4e4c 494e 4520 766f 6964 206f  NT_INLINE void o
+000152f0: 7065 7261 746f 7228 2928 5363 616c 6172  perator()(Scalar
+00015300: 2a20 626c 6f63 6b41 2c20 636f 6e73 7420  * blockA, const 
+00015310: 4461 7461 4d61 7070 6572 2620 6c68 732c  DataMapper& lhs,
+00015320: 2049 6e64 6578 2064 6570 7468 2c20 496e   Index depth, In
+00015330: 6465 7820 726f 7773 2c20 496e 6465 7820  dex rows, Index 
+00015340: 7374 7269 6465 3d30 2c20 496e 6465 7820  stride=0, Index 
+00015350: 6f66 6673 6574 3d30 293b 0a7d 3b0a 0a74  offset=0);.};..t
+00015360: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
+00015370: 2053 6361 6c61 722c 2074 7970 656e 616d   Scalar, typenam
+00015380: 6520 496e 6465 782c 2074 7970 656e 616d  e Index, typenam
+00015390: 6520 4461 7461 4d61 7070 6572 2c20 696e  e DataMapper, in
+000153a0: 7420 5061 636b 312c 2069 6e74 2050 6163  t Pack1, int Pac
+000153b0: 6b32 2c20 7479 7065 6e61 6d65 2050 6163  k2, typename Pac
+000153c0: 6b65 742c 2062 6f6f 6c20 436f 6e6a 7567  ket, bool Conjug
+000153d0: 6174 652c 2062 6f6f 6c20 5061 6e65 6c4d  ate, bool PanelM
+000153e0: 6f64 653e 0a45 4947 454e 5f44 4f4e 545f  ode>.EIGEN_DONT_
+000153f0: 494e 4c49 4e45 2076 6f69 6420 6765 6d6d  INLINE void gemm
+00015400: 5f70 6163 6b5f 6c68 733c 5363 616c 6172  _pack_lhs<Scalar
+00015410: 2c20 496e 6465 782c 2044 6174 614d 6170  , Index, DataMap
+00015420: 7065 722c 2050 6163 6b31 2c20 5061 636b  per, Pack1, Pack
+00015430: 322c 2050 6163 6b65 742c 2043 6f6c 4d61  2, Packet, ColMa
+00015440: 6a6f 722c 2043 6f6e 6a75 6761 7465 2c20  jor, Conjugate, 
+00015450: 5061 6e65 6c4d 6f64 653e 0a20 203a 3a6f  PanelMode>.  ::o
+00015460: 7065 7261 746f 7228 2928 5363 616c 6172  perator()(Scalar
+00015470: 2a20 626c 6f63 6b41 2c20 636f 6e73 7420  * blockA, const 
+00015480: 4461 7461 4d61 7070 6572 2620 6c68 732c  DataMapper& lhs,
+00015490: 2049 6e64 6578 2064 6570 7468 2c20 496e   Index depth, In
+000154a0: 6465 7820 726f 7773 2c20 496e 6465 7820  dex rows, Index 
+000154b0: 7374 7269 6465 2c20 496e 6465 7820 6f66  stride, Index of
+000154c0: 6673 6574 290a 7b0a 2020 7479 7065 6465  fset).{.  typede
+000154d0: 6620 7479 7065 6e61 6d65 2075 6e70 6163  f typename unpac
+000154e0: 6b65 745f 7472 6169 7473 3c50 6163 6b65  ket_traits<Packe
+000154f0: 743e 3a3a 6861 6c66 2048 616c 6650 6163  t>::half HalfPac
+00015500: 6b65 743b 0a20 2074 7970 6564 6566 2074  ket;.  typedef t
+00015510: 7970 656e 616d 6520 756e 7061 636b 6574  ypename unpacket
+00015520: 5f74 7261 6974 733c 7479 7065 6e61 6d65  _traits<typename
+00015530: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
+00015540: 3c50 6163 6b65 743e 3a3a 6861 6c66 3e3a  <Packet>::half>:
+00015550: 3a68 616c 6620 5175 6172 7465 7250 6163  :half QuarterPac
+00015560: 6b65 743b 0a20 2065 6e75 6d20 7b20 5061  ket;.  enum { Pa
+00015570: 636b 6574 5369 7a65 203d 2075 6e70 6163  cketSize = unpac
+00015580: 6b65 745f 7472 6169 7473 3c50 6163 6b65  ket_traits<Packe
+00015590: 743e 3a3a 7369 7a65 2c0a 2020 2020 2020  t>::size,.      
+000155a0: 2020 2048 616c 6650 6163 6b65 7453 697a     HalfPacketSiz
+000155b0: 6520 3d20 756e 7061 636b 6574 5f74 7261  e = unpacket_tra
+000155c0: 6974 733c 4861 6c66 5061 636b 6574 3e3a  its<HalfPacket>:
+000155d0: 3a73 697a 652c 0a20 2020 2020 2020 2020  :size,.         
+000155e0: 5175 6172 7465 7250 6163 6b65 7453 697a  QuarterPacketSiz
+000155f0: 6520 3d20 756e 7061 636b 6574 5f74 7261  e = unpacket_tra
+00015600: 6974 733c 5175 6172 7465 7250 6163 6b65  its<QuarterPacke
+00015610: 743e 3a3a 7369 7a65 2c0a 2020 2020 2020  t>::size,.      
+00015620: 2020 2048 6173 4861 6c66 203d 2028 696e     HasHalf = (in
+00015630: 7429 4861 6c66 5061 636b 6574 5369 7a65  t)HalfPacketSize
+00015640: 203c 2028 696e 7429 5061 636b 6574 5369   < (int)PacketSi
+00015650: 7a65 2c0a 2020 2020 2020 2020 2048 6173  ze,.         Has
+00015660: 5175 6172 7465 7220 3d20 2869 6e74 2951  Quarter = (int)Q
+00015670: 7561 7274 6572 5061 636b 6574 5369 7a65  uarterPacketSize
+00015680: 203c 2028 696e 7429 4861 6c66 5061 636b   < (int)HalfPack
+00015690: 6574 5369 7a65 7d3b 0a0a 2020 4549 4745  etSize};..  EIGE
+000156a0: 4e5f 4153 4d5f 434f 4d4d 454e 5428 2245  N_ASM_COMMENT("E
+000156b0: 4947 454e 2050 524f 4455 4354 2050 4143  IGEN PRODUCT PAC
+000156c0: 4b20 4c48 5322 293b 0a20 2045 4947 454e  K LHS");.  EIGEN
+000156d0: 5f55 4e55 5345 445f 5641 5249 4142 4c45  _UNUSED_VARIABLE
+000156e0: 2873 7472 6964 6529 3b0a 2020 4549 4745  (stride);.  EIGE
+000156f0: 4e5f 554e 5553 4544 5f56 4152 4941 424c  N_UNUSED_VARIABL
+00015700: 4528 6f66 6673 6574 293b 0a20 2065 6967  E(offset);.  eig
+00015710: 656e 5f61 7373 6572 7428 2828 2150 616e  en_assert(((!Pan
+00015720: 656c 4d6f 6465 2920 2626 2073 7472 6964  elMode) && strid
+00015730: 653d 3d30 2026 2620 6f66 6673 6574 3d3d  e==0 && offset==
+00015740: 3029 207c 7c20 2850 616e 656c 4d6f 6465  0) || (PanelMode
+00015750: 2026 2620 7374 7269 6465 3e3d 6465 7074   && stride>=dept
+00015760: 6820 2626 206f 6666 7365 743c 3d73 7472  h && offset<=str
+00015770: 6964 6529 293b 0a20 2065 6967 656e 5f61  ide));.  eigen_a
+00015780: 7373 6572 7428 2028 2850 6163 6b31 2550  ssert( ((Pack1%P
+00015790: 6163 6b65 7453 697a 6529 3d3d 3020 2626  acketSize)==0 &&
+000157a0: 2050 6163 6b31 3c3d 342a 5061 636b 6574   Pack1<=4*Packet
+000157b0: 5369 7a65 2920 7c7c 2028 5061 636b 313c  Size) || (Pack1<
+000157c0: 3d34 2920 293b 0a20 2063 6f6e 6a5f 6966  =4) );.  conj_if
+000157d0: 3c4e 756d 5472 6169 7473 3c53 6361 6c61  <NumTraits<Scala
+000157e0: 723e 3a3a 4973 436f 6d70 6c65 7820 2626  r>::IsComplex &&
+000157f0: 2043 6f6e 6a75 6761 7465 3e20 636a 3b0a   Conjugate> cj;.
+00015800: 2020 496e 6465 7820 636f 756e 7420 3d20    Index count = 
+00015810: 303b 0a0a 2020 636f 6e73 7420 496e 6465  0;..  const Inde
+00015820: 7820 7065 656c 6564 5f6d 6333 203d 2050  x peeled_mc3 = P
+00015830: 6163 6b31 3e3d 332a 5061 636b 6574 5369  ack1>=3*PacketSi
+00015840: 7a65 203f 2028 726f 7773 2f28 332a 5061  ze ? (rows/(3*Pa
+00015850: 636b 6574 5369 7a65 2929 2a28 332a 5061  cketSize))*(3*Pa
+00015860: 636b 6574 5369 7a65 2920 3a20 303b 0a20  cketSize) : 0;. 
+00015870: 2063 6f6e 7374 2049 6e64 6578 2070 6565   const Index pee
+00015880: 6c65 645f 6d63 3220 3d20 5061 636b 313e  led_mc2 = Pack1>
+00015890: 3d32 2a50 6163 6b65 7453 697a 6520 3f20  =2*PacketSize ? 
+000158a0: 7065 656c 6564 5f6d 6333 2b28 2872 6f77  peeled_mc3+((row
+000158b0: 732d 7065 656c 6564 5f6d 6333 292f 2832  s-peeled_mc3)/(2
+000158c0: 2a50 6163 6b65 7453 697a 6529 292a 2832  *PacketSize))*(2
+000158d0: 2a50 6163 6b65 7453 697a 6529 203a 2030  *PacketSize) : 0
+000158e0: 3b0a 2020 636f 6e73 7420 496e 6465 7820  ;.  const Index 
+000158f0: 7065 656c 6564 5f6d 6331 203d 2050 6163  peeled_mc1 = Pac
+00015900: 6b31 3e3d 312a 5061 636b 6574 5369 7a65  k1>=1*PacketSize
+00015910: 203f 2070 6565 6c65 645f 6d63 322b 2828   ? peeled_mc2+((
+00015920: 726f 7773 2d70 6565 6c65 645f 6d63 3229  rows-peeled_mc2)
+00015930: 2f28 312a 5061 636b 6574 5369 7a65 2929  /(1*PacketSize))
+00015940: 2a28 312a 5061 636b 6574 5369 7a65 2920  *(1*PacketSize) 
+00015950: 3a20 303b 0a20 2063 6f6e 7374 2049 6e64  : 0;.  const Ind
+00015960: 6578 2070 6565 6c65 645f 6d63 5f68 616c  ex peeled_mc_hal
+00015970: 6620 3d20 5061 636b 313e 3d48 616c 6650  f = Pack1>=HalfP
+00015980: 6163 6b65 7453 697a 6520 3f20 7065 656c  acketSize ? peel
+00015990: 6564 5f6d 6331 2b28 2872 6f77 732d 7065  ed_mc1+((rows-pe
+000159a0: 656c 6564 5f6d 6331 292f 2848 616c 6650  eled_mc1)/(HalfP
+000159b0: 6163 6b65 7453 697a 6529 292a 2848 616c  acketSize))*(Hal
+000159c0: 6650 6163 6b65 7453 697a 6529 203a 2030  fPacketSize) : 0
+000159d0: 3b0a 2020 636f 6e73 7420 496e 6465 7820  ;.  const Index 
+000159e0: 7065 656c 6564 5f6d 635f 7175 6172 7465  peeled_mc_quarte
+000159f0: 7220 3d20 5061 636b 313e 3d51 7561 7274  r = Pack1>=Quart
+00015a00: 6572 5061 636b 6574 5369 7a65 203f 2028  erPacketSize ? (
+00015a10: 726f 7773 2f28 5175 6172 7465 7250 6163  rows/(QuarterPac
+00015a20: 6b65 7453 697a 6529 292a 2851 7561 7274  ketSize))*(Quart
+00015a30: 6572 5061 636b 6574 5369 7a65 2920 3a20  erPacketSize) : 
+00015a40: 303b 0a20 2063 6f6e 7374 2049 6e64 6578  0;.  const Index
+00015a50: 206c 6173 745f 6c68 735f 7072 6f67 7265   last_lhs_progre
+00015a60: 7373 203d 2072 6f77 7320 3e20 7065 656c  ss = rows > peel
+00015a70: 6564 5f6d 635f 7175 6172 7465 7220 3f20  ed_mc_quarter ? 
+00015a80: 2872 6f77 7320 2d20 7065 656c 6564 5f6d  (rows - peeled_m
+00015a90: 635f 7175 6172 7465 7229 2026 207e 3120  c_quarter) & ~1 
+00015aa0: 3a20 303b 0a20 2063 6f6e 7374 2049 6e64  : 0;.  const Ind
+00015ab0: 6578 2070 6565 6c65 645f 6d63 3020 3d20  ex peeled_mc0 = 
+00015ac0: 5061 636b 323e 3d50 6163 6b65 7453 697a  Pack2>=PacketSiz
+00015ad0: 6520 3f20 7065 656c 6564 5f6d 635f 7175  e ? peeled_mc_qu
+00015ae0: 6172 7465 720a 2020 2020 2020 2020 2020  arter.          
+00015af0: 2020 2020 2020 2020 2020 2020 2020 203a                 :
+00015b00: 2050 6163 6b32 3e31 2026 2620 6c61 7374   Pack2>1 && last
+00015b10: 5f6c 6873 5f70 726f 6772 6573 7320 3f20  _lhs_progress ? 
+00015b20: 2872 6f77 732f 6c61 7374 5f6c 6873 5f70  (rows/last_lhs_p
+00015b30: 726f 6772 6573 7329 2a6c 6173 745f 6c68  rogress)*last_lh
+00015b40: 735f 7072 6f67 7265 7373 203a 2030 3b0a  s_progress : 0;.
+00015b50: 0a20 2049 6e64 6578 2069 3d30 3b0a 0a20  .  Index i=0;.. 
+00015b60: 202f 2f20 5061 636b 2033 2070 6163 6b65   // Pack 3 packe
+00015b70: 7473 0a20 2069 6628 5061 636b 313e 3d33  ts.  if(Pack1>=3
+00015b80: 2a50 6163 6b65 7453 697a 6529 0a20 207b  *PacketSize).  {
+00015b90: 0a20 2020 2066 6f72 283b 2069 3c70 6565  .    for(; i<pee
+00015ba0: 6c65 645f 6d63 333b 2069 2b3d 332a 5061  led_mc3; i+=3*Pa
+00015bb0: 636b 6574 5369 7a65 290a 2020 2020 7b0a  cketSize).    {.
+00015bc0: 2020 2020 2020 6966 2850 616e 656c 4d6f        if(PanelMo
+00015bd0: 6465 2920 636f 756e 7420 2b3d 2028 332a  de) count += (3*
+00015be0: 5061 636b 6574 5369 7a65 2920 2a20 6f66  PacketSize) * of
+00015bf0: 6673 6574 3b0a 0a20 2020 2020 2066 6f72  fset;..      for
+00015c00: 2849 6e64 6578 206b 3d30 3b20 6b3c 6465  (Index k=0; k<de
+00015c10: 7074 683b 206b 2b2b 290a 2020 2020 2020  pth; k++).      
+00015c20: 7b0a 2020 2020 2020 2020 5061 636b 6574  {.        Packet
+00015c30: 2041 2c20 422c 2043 3b0a 2020 2020 2020   A, B, C;.      
+00015c40: 2020 4120 3d20 6c68 732e 7465 6d70 6c61    A = lhs.templa
+00015c50: 7465 206c 6f61 6450 6163 6b65 743c 5061  te loadPacket<Pa
+00015c60: 636b 6574 3e28 692b 302a 5061 636b 6574  cket>(i+0*Packet
+00015c70: 5369 7a65 2c20 6b29 3b0a 2020 2020 2020  Size, k);.      
+00015c80: 2020 4220 3d20 6c68 732e 7465 6d70 6c61    B = lhs.templa
+00015c90: 7465 206c 6f61 6450 6163 6b65 743c 5061  te loadPacket<Pa
+00015ca0: 636b 6574 3e28 692b 312a 5061 636b 6574  cket>(i+1*Packet
+00015cb0: 5369 7a65 2c20 6b29 3b0a 2020 2020 2020  Size, k);.      
+00015cc0: 2020 4320 3d20 6c68 732e 7465 6d70 6c61    C = lhs.templa
+00015cd0: 7465 206c 6f61 6450 6163 6b65 743c 5061  te loadPacket<Pa
+00015ce0: 636b 6574 3e28 692b 322a 5061 636b 6574  cket>(i+2*Packet
+00015cf0: 5369 7a65 2c20 6b29 3b0a 2020 2020 2020  Size, k);.      
+00015d00: 2020 7073 746f 7265 2862 6c6f 636b 412b    pstore(blockA+
+00015d10: 636f 756e 742c 2063 6a2e 7063 6f6e 6a28  count, cj.pconj(
+00015d20: 4129 293b 2063 6f75 6e74 2b3d 5061 636b  A)); count+=Pack
+00015d30: 6574 5369 7a65 3b0a 2020 2020 2020 2020  etSize;.        
+00015d40: 7073 746f 7265 2862 6c6f 636b 412b 636f  pstore(blockA+co
+00015d50: 756e 742c 2063 6a2e 7063 6f6e 6a28 4229  unt, cj.pconj(B)
+00015d60: 293b 2063 6f75 6e74 2b3d 5061 636b 6574  ); count+=Packet
+00015d70: 5369 7a65 3b0a 2020 2020 2020 2020 7073  Size;.        ps
+00015d80: 746f 7265 2862 6c6f 636b 412b 636f 756e  tore(blockA+coun
+00015d90: 742c 2063 6a2e 7063 6f6e 6a28 4329 293b  t, cj.pconj(C));
+00015da0: 2063 6f75 6e74 2b3d 5061 636b 6574 5369   count+=PacketSi
+00015db0: 7a65 3b0a 2020 2020 2020 7d0a 2020 2020  ze;.      }.    
+00015dc0: 2020 6966 2850 616e 656c 4d6f 6465 2920    if(PanelMode) 
+00015dd0: 636f 756e 7420 2b3d 2028 332a 5061 636b  count += (3*Pack
+00015de0: 6574 5369 7a65 2920 2a20 2873 7472 6964  etSize) * (strid
+00015df0: 652d 6f66 6673 6574 2d64 6570 7468 293b  e-offset-depth);
+00015e00: 0a20 2020 207d 0a20 207d 0a20 202f 2f20  .    }.  }.  // 
+00015e10: 5061 636b 2032 2070 6163 6b65 7473 0a20  Pack 2 packets. 
+00015e20: 2069 6628 5061 636b 313e 3d32 2a50 6163   if(Pack1>=2*Pac
+00015e30: 6b65 7453 697a 6529 0a20 207b 0a20 2020  ketSize).  {.   
+00015e40: 2066 6f72 283b 2069 3c70 6565 6c65 645f   for(; i<peeled_
+00015e50: 6d63 323b 2069 2b3d 322a 5061 636b 6574  mc2; i+=2*Packet
+00015e60: 5369 7a65 290a 2020 2020 7b0a 2020 2020  Size).    {.    
+00015e70: 2020 6966 2850 616e 656c 4d6f 6465 2920    if(PanelMode) 
+00015e80: 636f 756e 7420 2b3d 2028 322a 5061 636b  count += (2*Pack
+00015e90: 6574 5369 7a65 2920 2a20 6f66 6673 6574  etSize) * offset
+00015ea0: 3b0a 0a20 2020 2020 2066 6f72 2849 6e64  ;..      for(Ind
+00015eb0: 6578 206b 3d30 3b20 6b3c 6465 7074 683b  ex k=0; k<depth;
+00015ec0: 206b 2b2b 290a 2020 2020 2020 7b0a 2020   k++).      {.  
+00015ed0: 2020 2020 2020 5061 636b 6574 2041 2c20        Packet A, 
+00015ee0: 423b 0a20 2020 2020 2020 2041 203d 206c  B;.        A = l
+00015ef0: 6873 2e74 656d 706c 6174 6520 6c6f 6164  hs.template load
+00015f00: 5061 636b 6574 3c50 6163 6b65 743e 2869  Packet<Packet>(i
+00015f10: 2b30 2a50 6163 6b65 7453 697a 652c 206b  +0*PacketSize, k
+00015f20: 293b 0a20 2020 2020 2020 2042 203d 206c  );.        B = l
+00015f30: 6873 2e74 656d 706c 6174 6520 6c6f 6164  hs.template load
+00015f40: 5061 636b 6574 3c50 6163 6b65 743e 2869  Packet<Packet>(i
+00015f50: 2b31 2a50 6163 6b65 7453 697a 652c 206b  +1*PacketSize, k
+00015f60: 293b 0a20 2020 2020 2020 2070 7374 6f72  );.        pstor
+00015f70: 6528 626c 6f63 6b41 2b63 6f75 6e74 2c20  e(blockA+count, 
+00015f80: 636a 2e70 636f 6e6a 2841 2929 3b20 636f  cj.pconj(A)); co
+00015f90: 756e 742b 3d50 6163 6b65 7453 697a 653b  unt+=PacketSize;
+00015fa0: 0a20 2020 2020 2020 2070 7374 6f72 6528  .        pstore(
+00015fb0: 626c 6f63 6b41 2b63 6f75 6e74 2c20 636a  blockA+count, cj
+00015fc0: 2e70 636f 6e6a 2842 2929 3b20 636f 756e  .pconj(B)); coun
+00015fd0: 742b 3d50 6163 6b65 7453 697a 653b 0a20  t+=PacketSize;. 
+00015fe0: 2020 2020 207d 0a20 2020 2020 2069 6628       }.      if(
+00015ff0: 5061 6e65 6c4d 6f64 6529 2063 6f75 6e74  PanelMode) count
+00016000: 202b 3d20 2832 2a50 6163 6b65 7453 697a   += (2*PacketSiz
+00016010: 6529 202a 2028 7374 7269 6465 2d6f 6666  e) * (stride-off
+00016020: 7365 742d 6465 7074 6829 3b0a 2020 2020  set-depth);.    
+00016030: 7d0a 2020 7d0a 2020 2f2f 2050 6163 6b20  }.  }.  // Pack 
+00016040: 3120 7061 636b 6574 730a 2020 6966 2850  1 packets.  if(P
+00016050: 6163 6b31 3e3d 312a 5061 636b 6574 5369  ack1>=1*PacketSi
+00016060: 7a65 290a 2020 7b0a 2020 2020 666f 7228  ze).  {.    for(
+00016070: 3b20 693c 7065 656c 6564 5f6d 6331 3b20  ; i<peeled_mc1; 
+00016080: 692b 3d31 2a50 6163 6b65 7453 697a 6529  i+=1*PacketSize)
+00016090: 0a20 2020 207b 0a20 2020 2020 2069 6628  .    {.      if(
+000160a0: 5061 6e65 6c4d 6f64 6529 2063 6f75 6e74  PanelMode) count
+000160b0: 202b 3d20 2831 2a50 6163 6b65 7453 697a   += (1*PacketSiz
+000160c0: 6529 202a 206f 6666 7365 743b 0a0a 2020  e) * offset;..  
+000160d0: 2020 2020 666f 7228 496e 6465 7820 6b3d      for(Index k=
+000160e0: 303b 206b 3c64 6570 7468 3b20 6b2b 2b29  0; k<depth; k++)
+000160f0: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
+00016100: 2050 6163 6b65 7420 413b 0a20 2020 2020   Packet A;.     
+00016110: 2020 2041 203d 206c 6873 2e74 656d 706c     A = lhs.templ
+00016120: 6174 6520 6c6f 6164 5061 636b 6574 3c50  ate loadPacket<P
+00016130: 6163 6b65 743e 2869 2b30 2a50 6163 6b65  acket>(i+0*Packe
+00016140: 7453 697a 652c 206b 293b 0a20 2020 2020  tSize, k);.     
+00016150: 2020 2070 7374 6f72 6528 626c 6f63 6b41     pstore(blockA
+00016160: 2b63 6f75 6e74 2c20 636a 2e70 636f 6e6a  +count, cj.pconj
+00016170: 2841 2929 3b0a 2020 2020 2020 2020 636f  (A));.        co
+00016180: 756e 742b 3d50 6163 6b65 7453 697a 653b  unt+=PacketSize;
+00016190: 0a20 2020 2020 207d 0a20 2020 2020 2069  .      }.      i
+000161a0: 6628 5061 6e65 6c4d 6f64 6529 2063 6f75  f(PanelMode) cou
+000161b0: 6e74 202b 3d20 2831 2a50 6163 6b65 7453  nt += (1*PacketS
+000161c0: 697a 6529 202a 2028 7374 7269 6465 2d6f  ize) * (stride-o
+000161d0: 6666 7365 742d 6465 7074 6829 3b0a 2020  ffset-depth);.  
+000161e0: 2020 7d0a 2020 7d0a 2020 2f2f 2050 6163    }.  }.  // Pac
+000161f0: 6b20 6861 6c66 2070 6163 6b65 7473 0a20  k half packets. 
+00016200: 2069 6628 4861 7348 616c 6620 2626 2050   if(HasHalf && P
+00016210: 6163 6b31 3e3d 4861 6c66 5061 636b 6574  ack1>=HalfPacket
+00016220: 5369 7a65 290a 2020 7b0a 2020 2020 666f  Size).  {.    fo
+00016230: 7228 3b20 693c 7065 656c 6564 5f6d 635f  r(; i<peeled_mc_
+00016240: 6861 6c66 3b20 692b 3d48 616c 6650 6163  half; i+=HalfPac
+00016250: 6b65 7453 697a 6529 0a20 2020 207b 0a20  ketSize).    {. 
+00016260: 2020 2020 2069 6628 5061 6e65 6c4d 6f64       if(PanelMod
+00016270: 6529 2063 6f75 6e74 202b 3d20 2848 616c  e) count += (Hal
+00016280: 6650 6163 6b65 7453 697a 6529 202a 206f  fPacketSize) * o
+00016290: 6666 7365 743b 0a0a 2020 2020 2020 666f  ffset;..      fo
+000162a0: 7228 496e 6465 7820 6b3d 303b 206b 3c64  r(Index k=0; k<d
+000162b0: 6570 7468 3b20 6b2b 2b29 0a20 2020 2020  epth; k++).     
+000162c0: 207b 0a20 2020 2020 2020 2048 616c 6650   {.        HalfP
+000162d0: 6163 6b65 7420 413b 0a20 2020 2020 2020  acket A;.       
+000162e0: 2041 203d 206c 6873 2e74 656d 706c 6174   A = lhs.templat
+000162f0: 6520 6c6f 6164 5061 636b 6574 3c48 616c  e loadPacket<Hal
+00016300: 6650 6163 6b65 743e 2869 2b30 2a28 4861  fPacket>(i+0*(Ha
+00016310: 6c66 5061 636b 6574 5369 7a65 292c 206b  lfPacketSize), k
+00016320: 293b 0a20 2020 2020 2020 2070 7374 6f72  );.        pstor
+00016330: 6575 2862 6c6f 636b 412b 636f 756e 742c  eu(blockA+count,
+00016340: 2063 6a2e 7063 6f6e 6a28 4129 293b 0a20   cj.pconj(A));. 
+00016350: 2020 2020 2020 2063 6f75 6e74 2b3d 4861         count+=Ha
+00016360: 6c66 5061 636b 6574 5369 7a65 3b0a 2020  lfPacketSize;.  
+00016370: 2020 2020 7d0a 2020 2020 2020 6966 2850      }.      if(P
+00016380: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
+00016390: 2b3d 2028 4861 6c66 5061 636b 6574 5369  += (HalfPacketSi
+000163a0: 7a65 2920 2a20 2873 7472 6964 652d 6f66  ze) * (stride-of
+000163b0: 6673 6574 2d64 6570 7468 293b 0a20 2020  fset-depth);.   
+000163c0: 207d 0a20 207d 0a20 202f 2f20 5061 636b   }.  }.  // Pack
+000163d0: 2071 7561 7274 6572 2070 6163 6b65 7473   quarter packets
+000163e0: 0a20 2069 6628 4861 7351 7561 7274 6572  .  if(HasQuarter
+000163f0: 2026 2620 5061 636b 313e 3d51 7561 7274   && Pack1>=Quart
+00016400: 6572 5061 636b 6574 5369 7a65 290a 2020  erPacketSize).  
+00016410: 7b0a 2020 2020 666f 7228 3b20 693c 7065  {.    for(; i<pe
+00016420: 656c 6564 5f6d 635f 7175 6172 7465 723b  eled_mc_quarter;
+00016430: 2069 2b3d 5175 6172 7465 7250 6163 6b65   i+=QuarterPacke
+00016440: 7453 697a 6529 0a20 2020 207b 0a20 2020  tSize).    {.   
+00016450: 2020 2069 6628 5061 6e65 6c4d 6f64 6529     if(PanelMode)
+00016460: 2063 6f75 6e74 202b 3d20 2851 7561 7274   count += (Quart
+00016470: 6572 5061 636b 6574 5369 7a65 2920 2a20  erPacketSize) * 
+00016480: 6f66 6673 6574 3b0a 0a20 2020 2020 2066  offset;..      f
+00016490: 6f72 2849 6e64 6578 206b 3d30 3b20 6b3c  or(Index k=0; k<
+000164a0: 6465 7074 683b 206b 2b2b 290a 2020 2020  depth; k++).    
+000164b0: 2020 7b0a 2020 2020 2020 2020 5175 6172    {.        Quar
+000164c0: 7465 7250 6163 6b65 7420 413b 0a20 2020  terPacket A;.   
+000164d0: 2020 2020 2041 203d 206c 6873 2e74 656d       A = lhs.tem
+000164e0: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
+000164f0: 3c51 7561 7274 6572 5061 636b 6574 3e28  <QuarterPacket>(
+00016500: 692b 302a 2851 7561 7274 6572 5061 636b  i+0*(QuarterPack
+00016510: 6574 5369 7a65 292c 206b 293b 0a20 2020  etSize), k);.   
+00016520: 2020 2020 2070 7374 6f72 6575 2862 6c6f       pstoreu(blo
+00016530: 636b 412b 636f 756e 742c 2063 6a2e 7063  ckA+count, cj.pc
+00016540: 6f6e 6a28 4129 293b 0a20 2020 2020 2020  onj(A));.       
+00016550: 2063 6f75 6e74 2b3d 5175 6172 7465 7250   count+=QuarterP
+00016560: 6163 6b65 7453 697a 653b 0a20 2020 2020  acketSize;.     
+00016570: 207d 0a20 2020 2020 2069 6628 5061 6e65   }.      if(Pane
+00016580: 6c4d 6f64 6529 2063 6f75 6e74 202b 3d20  lMode) count += 
+00016590: 2851 7561 7274 6572 5061 636b 6574 5369  (QuarterPacketSi
+000165a0: 7a65 2920 2a20 2873 7472 6964 652d 6f66  ze) * (stride-of
+000165b0: 6673 6574 2d64 6570 7468 293b 0a20 2020  fset-depth);.   
+000165c0: 207d 0a20 207d 0a20 202f 2f20 5061 636b   }.  }.  // Pack
+000165d0: 3220 6d61 7920 6265 202a 736d 616c 6c65  2 may be *smalle
+000165e0: 722a 2074 6861 6e20 5061 636b 6574 5369  r* than PacketSi
+000165f0: 7a65 e280 9474 6861 7420 6861 7070 656e  ze...that happen
+00016600: 7320 666f 720a 2020 2f2f 2070 726f 6475  s for.  // produ
+00016610: 6374 7320 6c69 6b65 2072 6561 6c20 2a20  cts like real * 
+00016620: 636f 6d70 6c65 782c 2077 6865 7265 2077  complex, where w
+00016630: 6520 6861 7665 2074 6f20 676f 2068 616c  e have to go hal
+00016640: 6620 7468 650a 2020 2f2f 2070 726f 6772  f the.  // progr
+00016650: 6573 7320 6f6e 2074 6865 206c 6873 2069  ess on the lhs i
+00016660: 6e20 6f72 6465 7220 746f 2064 7570 6c69  n order to dupli
+00016670: 6361 7465 2074 686f 7365 206f 7065 7261  cate those opera
+00016680: 6e64 7320 746f 0a20 202f 2f20 6164 6472  nds to.  // addr
+00016690: 6573 7320 626f 7468 2072 6561 6c20 2620  ess both real & 
+000166a0: 696d 6167 696e 6172 7920 7061 7274 7320  imaginary parts 
+000166b0: 6f6e 2074 6865 2072 6873 2e20 5468 6973  on the rhs. This
+000166c0: 2070 6f72 7469 6f6e 2077 696c 6c0a 2020   portion will.  
+000166d0: 2f2f 2070 6163 6b20 7468 6f73 6520 6861  // pack those ha
+000166e0: 6c66 206f 6e65 7320 756e 7469 6c20 7468  lf ones until th
+000166f0: 6579 206d 6174 6368 2074 6865 206e 756d  ey match the num
+00016700: 6265 7220 6578 7065 6374 6564 206f 6e20  ber expected on 
+00016710: 7468 650a 2020 2f2f 206c 6173 7420 7065  the.  // last pe
+00016720: 656c 696e 6720 6c6f 6f70 2061 7420 7468  eling loop at th
+00016730: 6973 2070 6f69 6e74 2028 666f 7220 7468  is point (for th
+00016740: 6520 7268 7329 2e0a 2020 6966 2850 6163  e rhs)..  if(Pac
+00016750: 6b32 3c50 6163 6b65 7453 697a 6520 2626  k2<PacketSize &&
+00016760: 2050 6163 6b32 3e31 290a 2020 7b0a 2020   Pack2>1).  {.  
+00016770: 2020 666f 7228 3b20 693c 7065 656c 6564    for(; i<peeled
+00016780: 5f6d 6330 3b20 692b 3d6c 6173 745f 6c68  _mc0; i+=last_lh
+00016790: 735f 7072 6f67 7265 7373 290a 2020 2020  s_progress).    
+000167a0: 7b0a 2020 2020 2020 6966 2850 616e 656c  {.      if(Panel
+000167b0: 4d6f 6465 2920 636f 756e 7420 2b3d 206c  Mode) count += l
+000167c0: 6173 745f 6c68 735f 7072 6f67 7265 7373  ast_lhs_progress
+000167d0: 202a 206f 6666 7365 743b 0a0a 2020 2020   * offset;..    
+000167e0: 2020 666f 7228 496e 6465 7820 6b3d 303b    for(Index k=0;
+000167f0: 206b 3c64 6570 7468 3b20 6b2b 2b29 0a20   k<depth; k++). 
+00016800: 2020 2020 2020 2066 6f72 2849 6e64 6578         for(Index
+00016810: 2077 3d30 3b20 773c 6c61 7374 5f6c 6873   w=0; w<last_lhs
+00016820: 5f70 726f 6772 6573 733b 2077 2b2b 290a  _progress; w++).
+00016830: 2020 2020 2020 2020 2020 626c 6f63 6b41            blockA
+00016840: 5b63 6f75 6e74 2b2b 5d20 3d20 636a 286c  [count++] = cj(l
+00016850: 6873 2869 2b77 2c20 6b29 293b 0a0a 2020  hs(i+w, k));..  
+00016860: 2020 2020 6966 2850 616e 656c 4d6f 6465      if(PanelMode
+00016870: 2920 636f 756e 7420 2b3d 206c 6173 745f  ) count += last_
+00016880: 6c68 735f 7072 6f67 7265 7373 202a 2028  lhs_progress * (
+00016890: 7374 7269 6465 2d6f 6666 7365 742d 6465  stride-offset-de
+000168a0: 7074 6829 3b0a 2020 2020 7d0a 2020 7d0a  pth);.    }.  }.
+000168b0: 2020 2f2f 2050 6163 6b20 7363 616c 6172    // Pack scalar
+000168c0: 730a 2020 666f 7228 3b20 693c 726f 7773  s.  for(; i<rows
+000168d0: 3b20 692b 2b29 0a20 207b 0a20 2020 2069  ; i++).  {.    i
+000168e0: 6628 5061 6e65 6c4d 6f64 6529 2063 6f75  f(PanelMode) cou
+000168f0: 6e74 202b 3d20 6f66 6673 6574 3b0a 2020  nt += offset;.  
+00016900: 2020 666f 7228 496e 6465 7820 6b3d 303b    for(Index k=0;
+00016910: 206b 3c64 6570 7468 3b20 6b2b 2b29 0a20   k<depth; k++). 
+00016920: 2020 2020 2062 6c6f 636b 415b 636f 756e       blockA[coun
+00016930: 742b 2b5d 203d 2063 6a28 6c68 7328 692c  t++] = cj(lhs(i,
+00016940: 206b 2929 3b0a 2020 2020 6966 2850 616e   k));.    if(Pan
+00016950: 656c 4d6f 6465 2920 636f 756e 7420 2b3d  elMode) count +=
+00016960: 2028 7374 7269 6465 2d6f 6666 7365 742d   (stride-offset-
+00016970: 6465 7074 6829 3b0a 2020 7d0a 7d0a 0a74  depth);.  }.}..t
+00016980: 656d 706c 6174 653c 7479 7065 6e61 6d65  emplate<typename
+00016990: 2053 6361 6c61 722c 2074 7970 656e 616d   Scalar, typenam
+000169a0: 6520 496e 6465 782c 2074 7970 656e 616d  e Index, typenam
+000169b0: 6520 4461 7461 4d61 7070 6572 2c20 696e  e DataMapper, in
+000169c0: 7420 5061 636b 312c 2069 6e74 2050 6163  t Pack1, int Pac
+000169d0: 6b32 2c20 7479 7065 6e61 6d65 2050 6163  k2, typename Pac
+000169e0: 6b65 742c 2062 6f6f 6c20 436f 6e6a 7567  ket, bool Conjug
+000169f0: 6174 652c 2062 6f6f 6c20 5061 6e65 6c4d  ate, bool PanelM
+00016a00: 6f64 653e 0a73 7472 7563 7420 6765 6d6d  ode>.struct gemm
+00016a10: 5f70 6163 6b5f 6c68 733c 5363 616c 6172  _pack_lhs<Scalar
+00016a20: 2c20 496e 6465 782c 2044 6174 614d 6170  , Index, DataMap
+00016a30: 7065 722c 2050 6163 6b31 2c20 5061 636b  per, Pack1, Pack
+00016a40: 322c 2050 6163 6b65 742c 2052 6f77 4d61  2, Packet, RowMa
+00016a50: 6a6f 722c 2043 6f6e 6a75 6761 7465 2c20  jor, Conjugate, 
+00016a60: 5061 6e65 6c4d 6f64 653e 0a7b 0a20 2074  PanelMode>.{.  t
+00016a70: 7970 6564 6566 2074 7970 656e 616d 6520  ypedef typename 
+00016a80: 4461 7461 4d61 7070 6572 3a3a 4c69 6e65  DataMapper::Line
+00016a90: 6172 4d61 7070 6572 204c 696e 6561 724d  arMapper LinearM
+00016aa0: 6170 7065 723b 0a20 2045 4947 454e 5f44  apper;.  EIGEN_D
+00016ab0: 4f4e 545f 494e 4c49 4e45 2076 6f69 6420  ONT_INLINE void 
+00016ac0: 6f70 6572 6174 6f72 2829 2853 6361 6c61  operator()(Scala
+00016ad0: 722a 2062 6c6f 636b 412c 2063 6f6e 7374  r* blockA, const
+00016ae0: 2044 6174 614d 6170 7065 7226 206c 6873   DataMapper& lhs
+00016af0: 2c20 496e 6465 7820 6465 7074 682c 2049  , Index depth, I
+00016b00: 6e64 6578 2072 6f77 732c 2049 6e64 6578  ndex rows, Index
+00016b10: 2073 7472 6964 653d 302c 2049 6e64 6578   stride=0, Index
+00016b20: 206f 6666 7365 743d 3029 3b0a 7d3b 0a0a   offset=0);.};..
+00016b30: 7465 6d70 6c61 7465 3c74 7970 656e 616d  template<typenam
+00016b40: 6520 5363 616c 6172 2c20 7479 7065 6e61  e Scalar, typena
+00016b50: 6d65 2049 6e64 6578 2c20 7479 7065 6e61  me Index, typena
+00016b60: 6d65 2044 6174 614d 6170 7065 722c 2069  me DataMapper, i
+00016b70: 6e74 2050 6163 6b31 2c20 696e 7420 5061  nt Pack1, int Pa
+00016b80: 636b 322c 2074 7970 656e 616d 6520 5061  ck2, typename Pa
+00016b90: 636b 6574 2c20 626f 6f6c 2043 6f6e 6a75  cket, bool Conju
+00016ba0: 6761 7465 2c20 626f 6f6c 2050 616e 656c  gate, bool Panel
+00016bb0: 4d6f 6465 3e0a 4549 4745 4e5f 444f 4e54  Mode>.EIGEN_DONT
+00016bc0: 5f49 4e4c 494e 4520 766f 6964 2067 656d  _INLINE void gem
+00016bd0: 6d5f 7061 636b 5f6c 6873 3c53 6361 6c61  m_pack_lhs<Scala
+00016be0: 722c 2049 6e64 6578 2c20 4461 7461 4d61  r, Index, DataMa
+00016bf0: 7070 6572 2c20 5061 636b 312c 2050 6163  pper, Pack1, Pac
+00016c00: 6b32 2c20 5061 636b 6574 2c20 526f 774d  k2, Packet, RowM
+00016c10: 616a 6f72 2c20 436f 6e6a 7567 6174 652c  ajor, Conjugate,
+00016c20: 2050 616e 656c 4d6f 6465 3e0a 2020 3a3a   PanelMode>.  ::
+00016c30: 6f70 6572 6174 6f72 2829 2853 6361 6c61  operator()(Scala
+00016c40: 722a 2062 6c6f 636b 412c 2063 6f6e 7374  r* blockA, const
+00016c50: 2044 6174 614d 6170 7065 7226 206c 6873   DataMapper& lhs
+00016c60: 2c20 496e 6465 7820 6465 7074 682c 2049  , Index depth, I
+00016c70: 6e64 6578 2072 6f77 732c 2049 6e64 6578  ndex rows, Index
+00016c80: 2073 7472 6964 652c 2049 6e64 6578 206f   stride, Index o
+00016c90: 6666 7365 7429 0a7b 0a20 2074 7970 6564  ffset).{.  typed
+00016ca0: 6566 2074 7970 656e 616d 6520 756e 7061  ef typename unpa
+00016cb0: 636b 6574 5f74 7261 6974 733c 5061 636b  cket_traits<Pack
+00016cc0: 6574 3e3a 3a68 616c 6620 4861 6c66 5061  et>::half HalfPa
+00016cd0: 636b 6574 3b0a 2020 7479 7065 6465 6620  cket;.  typedef 
+00016ce0: 7479 7065 6e61 6d65 2075 6e70 6163 6b65  typename unpacke
+00016cf0: 745f 7472 6169 7473 3c74 7970 656e 616d  t_traits<typenam
+00016d00: 6520 756e 7061 636b 6574 5f74 7261 6974  e unpacket_trait
+00016d10: 733c 5061 636b 6574 3e3a 3a68 616c 663e  s<Packet>::half>
+00016d20: 3a3a 6861 6c66 2051 7561 7274 6572 5061  ::half QuarterPa
+00016d30: 636b 6574 3b0a 2020 656e 756d 207b 2050  cket;.  enum { P
+00016d40: 6163 6b65 7453 697a 6520 3d20 756e 7061  acketSize = unpa
+00016d50: 636b 6574 5f74 7261 6974 733c 5061 636b  cket_traits<Pack
+00016d60: 6574 3e3a 3a73 697a 652c 0a20 2020 2020  et>::size,.     
+00016d70: 2020 2020 4861 6c66 5061 636b 6574 5369      HalfPacketSi
+00016d80: 7a65 203d 2075 6e70 6163 6b65 745f 7472  ze = unpacket_tr
+00016d90: 6169 7473 3c48 616c 6650 6163 6b65 743e  aits<HalfPacket>
+00016da0: 3a3a 7369 7a65 2c0a 2020 2020 2020 2020  ::size,.        
+00016db0: 2051 7561 7274 6572 5061 636b 6574 5369   QuarterPacketSi
+00016dc0: 7a65 203d 2075 6e70 6163 6b65 745f 7472  ze = unpacket_tr
+00016dd0: 6169 7473 3c51 7561 7274 6572 5061 636b  aits<QuarterPack
+00016de0: 6574 3e3a 3a73 697a 652c 0a20 2020 2020  et>::size,.     
+00016df0: 2020 2020 4861 7348 616c 6620 3d20 2869      HasHalf = (i
+00016e00: 6e74 2948 616c 6650 6163 6b65 7453 697a  nt)HalfPacketSiz
+00016e10: 6520 3c20 2869 6e74 2950 6163 6b65 7453  e < (int)PacketS
+00016e20: 697a 652c 0a20 2020 2020 2020 2020 4861  ize,.         Ha
+00016e30: 7351 7561 7274 6572 203d 2028 696e 7429  sQuarter = (int)
+00016e40: 5175 6172 7465 7250 6163 6b65 7453 697a  QuarterPacketSiz
+00016e50: 6520 3c20 2869 6e74 2948 616c 6650 6163  e < (int)HalfPac
+00016e60: 6b65 7453 697a 657d 3b0a 0a20 2045 4947  ketSize};..  EIG
+00016e70: 454e 5f41 534d 5f43 4f4d 4d45 4e54 2822  EN_ASM_COMMENT("
+00016e80: 4549 4745 4e20 5052 4f44 5543 5420 5041  EIGEN PRODUCT PA
+00016e90: 434b 204c 4853 2229 3b0a 2020 4549 4745  CK LHS");.  EIGE
+00016ea0: 4e5f 554e 5553 4544 5f56 4152 4941 424c  N_UNUSED_VARIABL
+00016eb0: 4528 7374 7269 6465 293b 0a20 2045 4947  E(stride);.  EIG
+00016ec0: 454e 5f55 4e55 5345 445f 5641 5249 4142  EN_UNUSED_VARIAB
+00016ed0: 4c45 286f 6666 7365 7429 3b0a 2020 6569  LE(offset);.  ei
+00016ee0: 6765 6e5f 6173 7365 7274 2828 2821 5061  gen_assert(((!Pa
+00016ef0: 6e65 6c4d 6f64 6529 2026 2620 7374 7269  nelMode) && stri
+00016f00: 6465 3d3d 3020 2626 206f 6666 7365 743d  de==0 && offset=
+00016f10: 3d30 2920 7c7c 2028 5061 6e65 6c4d 6f64  =0) || (PanelMod
+00016f20: 6520 2626 2073 7472 6964 653e 3d64 6570  e && stride>=dep
+00016f30: 7468 2026 2620 6f66 6673 6574 3c3d 7374  th && offset<=st
+00016f40: 7269 6465 2929 3b0a 2020 636f 6e6a 5f69  ride));.  conj_i
+00016f50: 663c 4e75 6d54 7261 6974 733c 5363 616c  f<NumTraits<Scal
+00016f60: 6172 3e3a 3a49 7343 6f6d 706c 6578 2026  ar>::IsComplex &
+00016f70: 2620 436f 6e6a 7567 6174 653e 2063 6a3b  & Conjugate> cj;
+00016f80: 0a20 2049 6e64 6578 2063 6f75 6e74 203d  .  Index count =
+00016f90: 2030 3b0a 2020 626f 6f6c 2067 6f6e 655f   0;.  bool gone_
+00016fa0: 6861 6c66 203d 2066 616c 7365 2c20 676f  half = false, go
+00016fb0: 6e65 5f71 7561 7274 6572 203d 2066 616c  ne_quarter = fal
+00016fc0: 7365 2c20 676f 6e65 5f6c 6173 7420 3d20  se, gone_last = 
+00016fd0: 6661 6c73 653b 0a0a 2020 496e 6465 7820  false;..  Index 
+00016fe0: 6920 3d20 303b 0a20 2069 6e74 2070 6163  i = 0;.  int pac
+00016ff0: 6b20 3d20 5061 636b 313b 0a20 2069 6e74  k = Pack1;.  int
+00017000: 2070 7369 7a65 203d 2050 6163 6b65 7453   psize = PacketS
+00017010: 697a 653b 0a20 2077 6869 6c65 2870 6163  ize;.  while(pac
+00017020: 6b3e 3029 0a20 207b 0a20 2020 2049 6e64  k>0).  {.    Ind
+00017030: 6578 2072 656d 6169 6e69 6e67 5f72 6f77  ex remaining_row
+00017040: 7320 3d20 726f 7773 2d69 3b0a 2020 2020  s = rows-i;.    
+00017050: 496e 6465 7820 7065 656c 6564 5f6d 6320  Index peeled_mc 
+00017060: 3d20 676f 6e65 5f6c 6173 7420 3f20 5061  = gone_last ? Pa
+00017070: 636b 323e 3120 3f20 2872 6f77 732f 7061  ck2>1 ? (rows/pa
+00017080: 636b 292a 7061 636b 203a 2030 203a 2069  ck)*pack : 0 : i
+00017090: 2b28 7265 6d61 696e 696e 675f 726f 7773  +(remaining_rows
+000170a0: 2f70 6163 6b29 2a70 6163 6b3b 0a20 2020  /pack)*pack;.   
+000170b0: 2049 6e64 6578 2073 7461 7274 696e 675f   Index starting_
+000170c0: 706f 7320 3d20 693b 0a20 2020 2066 6f72  pos = i;.    for
+000170d0: 283b 2069 3c70 6565 6c65 645f 6d63 3b20  (; i<peeled_mc; 
+000170e0: 692b 3d70 6163 6b29 0a20 2020 207b 0a20  i+=pack).    {. 
+000170f0: 2020 2020 2069 6628 5061 6e65 6c4d 6f64       if(PanelMod
+00017100: 6529 2063 6f75 6e74 202b 3d20 7061 636b  e) count += pack
+00017110: 202a 206f 6666 7365 743b 0a0a 2020 2020   * offset;..    
+00017120: 2020 496e 6465 7820 6b3d 303b 0a20 2020    Index k=0;.   
+00017130: 2020 2069 6628 7061 636b 3e3d 7073 697a     if(pack>=psiz
+00017140: 6520 2626 2070 7369 7a65 203e 3d20 5175  e && psize >= Qu
+00017150: 6172 7465 7250 6163 6b65 7453 697a 6529  arterPacketSize)
+00017160: 0a20 2020 2020 207b 0a20 2020 2020 2020  .      {.       
+00017170: 2063 6f6e 7374 2049 6e64 6578 2070 6565   const Index pee
+00017180: 6c65 645f 6b20 3d20 2864 6570 7468 2f70  led_k = (depth/p
+00017190: 7369 7a65 292a 7073 697a 653b 0a20 2020  size)*psize;.   
+000171a0: 2020 2020 2066 6f72 283b 206b 3c70 6565       for(; k<pee
+000171b0: 6c65 645f 6b3b 206b 2b3d 7073 697a 6529  led_k; k+=psize)
+000171c0: 0a20 2020 2020 2020 207b 0a20 2020 2020  .        {.     
+000171d0: 2020 2020 2066 6f72 2028 496e 6465 7820       for (Index 
+000171e0: 6d20 3d20 303b 206d 203c 2070 6163 6b3b  m = 0; m < pack;
+000171f0: 206d 202b 3d20 7073 697a 6529 0a20 2020   m += psize).   
+00017200: 2020 2020 2020 207b 0a20 2020 2020 2020         {.       
+00017210: 2020 2020 2069 6620 2870 7369 7a65 203d       if (psize =
+00017220: 3d20 5061 636b 6574 5369 7a65 2920 7b0a  = PacketSize) {.
+00017230: 2020 2020 2020 2020 2020 2020 2020 5061                Pa
+00017240: 636b 6574 426c 6f63 6b3c 5061 636b 6574  cketBlock<Packet
+00017250: 3e20 6b65 726e 656c 3b0a 2020 2020 2020  > kernel;.      
+00017260: 2020 2020 2020 2020 666f 7220 2869 6e74          for (int
+00017270: 2070 203d 2030 3b20 7020 3c20 7073 697a   p = 0; p < psiz
+00017280: 653b 202b 2b70 2920 6b65 726e 656c 2e70  e; ++p) kernel.p
+00017290: 6163 6b65 745b 705d 203d 206c 6873 2e74  acket[p] = lhs.t
+000172a0: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+000172b0: 6574 3c50 6163 6b65 743e 2869 2b70 2b6d  et<Packet>(i+p+m
+000172c0: 2c20 6b29 3b0a 2020 2020 2020 2020 2020  , k);.          
+000172d0: 2020 2020 7074 7261 6e73 706f 7365 286b      ptranspose(k
+000172e0: 6572 6e65 6c29 3b0a 2020 2020 2020 2020  ernel);.        
+000172f0: 2020 2020 2020 666f 7220 2869 6e74 2070        for (int p
+00017300: 203d 2030 3b20 7020 3c20 7073 697a 653b   = 0; p < psize;
+00017310: 202b 2b70 2920 7073 746f 7265 2862 6c6f   ++p) pstore(blo
+00017320: 636b 412b 636f 756e 742b 6d2b 2870 6163  ckA+count+m+(pac
+00017330: 6b29 2a70 2c20 636a 2e70 636f 6e6a 286b  k)*p, cj.pconj(k
+00017340: 6572 6e65 6c2e 7061 636b 6574 5b70 5d29  ernel.packet[p])
+00017350: 293b 0a20 2020 2020 2020 2020 2020 207d  );.            }
+00017360: 2065 6c73 6520 6966 2028 4861 7348 616c   else if (HasHal
+00017370: 6620 2626 2070 7369 7a65 203d 3d20 4861  f && psize == Ha
+00017380: 6c66 5061 636b 6574 5369 7a65 2920 7b0a  lfPacketSize) {.
+00017390: 2020 2020 2020 2020 2020 2020 2020 676f                go
+000173a0: 6e65 5f68 616c 6620 3d20 7472 7565 3b0a  ne_half = true;.
+000173b0: 2020 2020 2020 2020 2020 2020 2020 5061                Pa
+000173c0: 636b 6574 426c 6f63 6b3c 4861 6c66 5061  cketBlock<HalfPa
+000173d0: 636b 6574 3e20 6b65 726e 656c 5f68 616c  cket> kernel_hal
+000173e0: 663b 0a20 2020 2020 2020 2020 2020 2020  f;.             
+000173f0: 2066 6f72 2028 696e 7420 7020 3d20 303b   for (int p = 0;
+00017400: 2070 203c 2070 7369 7a65 3b20 2b2b 7029   p < psize; ++p)
+00017410: 206b 6572 6e65 6c5f 6861 6c66 2e70 6163   kernel_half.pac
+00017420: 6b65 745b 705d 203d 206c 6873 2e74 656d  ket[p] = lhs.tem
+00017430: 706c 6174 6520 6c6f 6164 5061 636b 6574  plate loadPacket
+00017440: 3c48 616c 6650 6163 6b65 743e 2869 2b70  <HalfPacket>(i+p
+00017450: 2b6d 2c20 6b29 3b0a 2020 2020 2020 2020  +m, k);.        
+00017460: 2020 2020 2020 7074 7261 6e73 706f 7365        ptranspose
+00017470: 286b 6572 6e65 6c5f 6861 6c66 293b 0a20  (kernel_half);. 
+00017480: 2020 2020 2020 2020 2020 2020 2066 6f72               for
+00017490: 2028 696e 7420 7020 3d20 303b 2070 203c   (int p = 0; p <
+000174a0: 2070 7369 7a65 3b20 2b2b 7029 2070 7374   psize; ++p) pst
+000174b0: 6f72 6528 626c 6f63 6b41 2b63 6f75 6e74  ore(blockA+count
+000174c0: 2b6d 2b28 7061 636b 292a 702c 2063 6a2e  +m+(pack)*p, cj.
+000174d0: 7063 6f6e 6a28 6b65 726e 656c 5f68 616c  pconj(kernel_hal
+000174e0: 662e 7061 636b 6574 5b70 5d29 293b 0a20  f.packet[p]));. 
+000174f0: 2020 2020 2020 2020 2020 207d 2065 6c73             } els
+00017500: 6520 6966 2028 4861 7351 7561 7274 6572  e if (HasQuarter
+00017510: 2026 2620 7073 697a 6520 3d3d 2051 7561   && psize == Qua
+00017520: 7274 6572 5061 636b 6574 5369 7a65 2920  rterPacketSize) 
+00017530: 7b0a 2020 2020 2020 2020 2020 2020 2020  {.              
+00017540: 676f 6e65 5f71 7561 7274 6572 203d 2074  gone_quarter = t
+00017550: 7275 653b 0a20 2020 2020 2020 2020 2020  rue;.           
+00017560: 2020 2050 6163 6b65 7442 6c6f 636b 3c51     PacketBlock<Q
+00017570: 7561 7274 6572 5061 636b 6574 3e20 6b65  uarterPacket> ke
+00017580: 726e 656c 5f71 7561 7274 6572 3b0a 2020  rnel_quarter;.  
+00017590: 2020 2020 2020 2020 2020 2020 666f 7220              for 
+000175a0: 2869 6e74 2070 203d 2030 3b20 7020 3c20  (int p = 0; p < 
+000175b0: 7073 697a 653b 202b 2b70 2920 6b65 726e  psize; ++p) kern
+000175c0: 656c 5f71 7561 7274 6572 2e70 6163 6b65  el_quarter.packe
+000175d0: 745b 705d 203d 206c 6873 2e74 656d 706c  t[p] = lhs.templ
+000175e0: 6174 6520 6c6f 6164 5061 636b 6574 3c51  ate loadPacket<Q
+000175f0: 7561 7274 6572 5061 636b 6574 3e28 692b  uarterPacket>(i+
+00017600: 702b 6d2c 206b 293b 0a20 2020 2020 2020  p+m, k);.       
+00017610: 2020 2020 2020 2070 7472 616e 7370 6f73         ptranspos
+00017620: 6528 6b65 726e 656c 5f71 7561 7274 6572  e(kernel_quarter
+00017630: 293b 0a20 2020 2020 2020 2020 2020 2020  );.             
+00017640: 2066 6f72 2028 696e 7420 7020 3d20 303b   for (int p = 0;
+00017650: 2070 203c 2070 7369 7a65 3b20 2b2b 7029   p < psize; ++p)
+00017660: 2070 7374 6f72 6528 626c 6f63 6b41 2b63   pstore(blockA+c
+00017670: 6f75 6e74 2b6d 2b28 7061 636b 292a 702c  ount+m+(pack)*p,
+00017680: 2063 6a2e 7063 6f6e 6a28 6b65 726e 656c   cj.pconj(kernel
+00017690: 5f71 7561 7274 6572 2e70 6163 6b65 745b  _quarter.packet[
+000176a0: 705d 2929 3b0a 0920 2020 207d 0a20 2020  p]));..    }.   
+000176b0: 2020 2020 2020 207d 0a20 2020 2020 2020         }.       
+000176c0: 2020 2063 6f75 6e74 202b 3d20 7073 697a     count += psiz
+000176d0: 652a 7061 636b 3b0a 2020 2020 2020 2020  e*pack;.        
+000176e0: 7d0a 2020 2020 2020 7d0a 0a20 2020 2020  }.      }..     
+000176f0: 2066 6f72 283b 206b 3c64 6570 7468 3b20   for(; k<depth; 
+00017700: 6b2b 2b29 0a20 2020 2020 207b 0a20 2020  k++).      {.   
+00017710: 2020 2020 2049 6e64 6578 2077 3d30 3b0a       Index w=0;.
+00017720: 2020 2020 2020 2020 666f 7228 3b20 773c          for(; w<
+00017730: 7061 636b 2d33 3b20 772b 3d34 290a 2020  pack-3; w+=4).  
+00017740: 2020 2020 2020 7b0a 2020 2020 2020 2020        {.        
+00017750: 2020 5363 616c 6172 2061 2863 6a28 6c68    Scalar a(cj(lh
+00017760: 7328 692b 772b 302c 206b 2929 292c 0a20  s(i+w+0, k))),. 
+00017770: 2020 2020 2020 2020 2020 2020 2020 2020                  
+00017780: 6228 636a 286c 6873 2869 2b77 2b31 2c20  b(cj(lhs(i+w+1, 
+00017790: 6b29 2929 2c0a 2020 2020 2020 2020 2020  k))),.          
+000177a0: 2020 2020 2020 2063 2863 6a28 6c68 7328         c(cj(lhs(
+000177b0: 692b 772b 322c 206b 2929 292c 0a20 2020  i+w+2, k))),.   
+000177c0: 2020 2020 2020 2020 2020 2020 2020 6428                d(
+000177d0: 636a 286c 6873 2869 2b77 2b33 2c20 6b29  cj(lhs(i+w+3, k)
+000177e0: 2929 3b0a 2020 2020 2020 2020 2020 626c  ));.          bl
+000177f0: 6f63 6b41 5b63 6f75 6e74 2b2b 5d20 3d20  ockA[count++] = 
+00017800: 613b 0a20 2020 2020 2020 2020 2062 6c6f  a;.          blo
+00017810: 636b 415b 636f 756e 742b 2b5d 203d 2062  ckA[count++] = b
+00017820: 3b0a 2020 2020 2020 2020 2020 626c 6f63  ;.          bloc
+00017830: 6b41 5b63 6f75 6e74 2b2b 5d20 3d20 633b  kA[count++] = c;
+00017840: 0a20 2020 2020 2020 2020 2062 6c6f 636b  .          block
+00017850: 415b 636f 756e 742b 2b5d 203d 2064 3b0a  A[count++] = d;.
+00017860: 2020 2020 2020 2020 7d0a 2020 2020 2020          }.      
+00017870: 2020 6966 2870 6163 6b25 3429 0a20 2020    if(pack%4).   
+00017880: 2020 2020 2020 2066 6f72 283b 773c 7061         for(;w<pa
+00017890: 636b 3b2b 2b77 290a 2020 2020 2020 2020  ck;++w).        
+000178a0: 2020 2020 626c 6f63 6b41 5b63 6f75 6e74      blockA[count
+000178b0: 2b2b 5d20 3d20 636a 286c 6873 2869 2b77  ++] = cj(lhs(i+w
+000178c0: 2c20 6b29 293b 0a20 2020 2020 207d 0a0a  , k));.      }..
+000178d0: 2020 2020 2020 6966 2850 616e 656c 4d6f        if(PanelMo
+000178e0: 6465 2920 636f 756e 7420 2b3d 2070 6163  de) count += pac
+000178f0: 6b20 2a20 2873 7472 6964 652d 6f66 6673  k * (stride-offs
+00017900: 6574 2d64 6570 7468 293b 0a20 2020 207d  et-depth);.    }
+00017910: 0a0a 2020 2020 7061 636b 202d 3d20 7073  ..    pack -= ps
+00017920: 697a 653b 0a20 2020 2049 6e64 6578 206c  ize;.    Index l
+00017930: 6566 7420 3d20 726f 7773 202d 2069 3b0a  eft = rows - i;.
+00017940: 2020 2020 6966 2028 7061 636b 203c 3d20      if (pack <= 
+00017950: 3029 207b 0a20 2020 2020 2069 6620 2821  0) {.      if (!
+00017960: 676f 6e65 5f6c 6173 7420 2626 0a20 2020  gone_last &&.   
+00017970: 2020 2020 2020 2028 7374 6172 7469 6e67         (starting
+00017980: 5f70 6f73 203d 3d20 6920 7c7c 206c 6566  _pos == i || lef
+00017990: 7420 3e3d 2070 7369 7a65 2f32 207c 7c20  t >= psize/2 || 
+000179a0: 6c65 6674 203e 3d20 7073 697a 652f 3429  left >= psize/4)
+000179b0: 2026 260a 2020 2020 2020 2020 2020 2828   &&.          ((
+000179c0: 7073 697a 652f 3220 3d3d 2048 616c 6650  psize/2 == HalfP
+000179d0: 6163 6b65 7453 697a 6520 2626 2048 6173  acketSize && Has
+000179e0: 4861 6c66 2026 2620 2167 6f6e 655f 6861  Half && !gone_ha
+000179f0: 6c66 2920 7c7c 0a20 2020 2020 2020 2020  lf) ||.         
+00017a00: 2020 2870 7369 7a65 2f32 203d 3d20 5175    (psize/2 == Qu
+00017a10: 6172 7465 7250 6163 6b65 7453 697a 6520  arterPacketSize 
+00017a20: 2626 2048 6173 5175 6172 7465 7220 2626  && HasQuarter &&
+00017a30: 2021 676f 6e65 5f71 7561 7274 6572 2929   !gone_quarter))
+00017a40: 2920 7b0a 2020 2020 2020 2020 7073 697a  ) {.        psiz
+00017a50: 6520 2f3d 2032 3b0a 2020 2020 2020 2020  e /= 2;.        
+00017a60: 7061 636b 203d 2070 7369 7a65 3b0a 2020  pack = psize;.  
+00017a70: 2020 2020 2020 636f 6e74 696e 7565 3b0a        continue;.
+00017a80: 2020 2020 2020 7d0a 2020 2020 2020 2f2f        }.      //
+00017a90: 2050 6163 6b32 206d 6179 2062 6520 2a73   Pack2 may be *s
+00017aa0: 6d61 6c6c 6572 2a20 7468 616e 2050 6163  maller* than Pac
+00017ab0: 6b65 7453 697a 65e2 8094 7468 6174 2068  ketSize...that h
+00017ac0: 6170 7065 6e73 2066 6f72 0a20 2020 2020  appens for.     
+00017ad0: 202f 2f20 7072 6f64 7563 7473 206c 696b   // products lik
+00017ae0: 6520 7265 616c 202a 2063 6f6d 706c 6578  e real * complex
+00017af0: 2c20 7768 6572 6520 7765 2068 6176 6520  , where we have 
+00017b00: 746f 2067 6f20 6861 6c66 2074 6865 0a20  to go half the. 
+00017b10: 2020 2020 202f 2f20 7072 6f67 7265 7373       // progress
+00017b20: 206f 6e20 7468 6520 6c68 7320 696e 206f   on the lhs in o
+00017b30: 7264 6572 2074 6f20 6475 706c 6963 6174  rder to duplicat
+00017b40: 6520 7468 6f73 6520 6f70 6572 616e 6473  e those operands
+00017b50: 2074 6f0a 2020 2020 2020 2f2f 2061 6464   to.      // add
+00017b60: 7265 7373 2062 6f74 6820 7265 616c 2026  ress both real &
+00017b70: 2069 6d61 6769 6e61 7279 2070 6172 7473   imaginary parts
+00017b80: 206f 6e20 7468 6520 7268 732e 2054 6869   on the rhs. Thi
+00017b90: 7320 706f 7274 696f 6e20 7769 6c6c 0a20  s portion will. 
+00017ba0: 2020 2020 202f 2f20 7061 636b 2074 686f       // pack tho
+00017bb0: 7365 2068 616c 6620 6f6e 6573 2075 6e74  se half ones unt
+00017bc0: 696c 2074 6865 7920 6d61 7463 6820 7468  il they match th
+00017bd0: 6520 6e75 6d62 6572 2065 7870 6563 7465  e number expecte
+00017be0: 6420 6f6e 2074 6865 0a20 2020 2020 202f  d on the.      /
+00017bf0: 2f20 6c61 7374 2070 6565 6c69 6e67 206c  / last peeling l
+00017c00: 6f6f 7020 6174 2074 6869 7320 706f 696e  oop at this poin
+00017c10: 7420 2866 6f72 2074 6865 2072 6873 292e  t (for the rhs).
+00017c20: 0a20 2020 2020 2069 6620 2850 6163 6b32  .      if (Pack2
+00017c30: 203c 2050 6163 6b65 7453 697a 6520 2626   < PacketSize &&
+00017c40: 2021 676f 6e65 5f6c 6173 7429 207b 0a20   !gone_last) {. 
+00017c50: 2020 2020 2020 2067 6f6e 655f 6c61 7374         gone_last
+00017c60: 203d 2074 7275 653b 0a20 2020 2020 2020   = true;.       
+00017c70: 2070 7369 7a65 203d 2070 6163 6b20 3d20   psize = pack = 
+00017c80: 6c65 6674 2026 207e 313b 0a20 2020 2020  left & ~1;.     
+00017c90: 207d 0a20 2020 207d 0a20 207d 0a0a 2020   }.    }.  }..  
+00017ca0: 666f 7228 3b20 693c 726f 7773 3b20 692b  for(; i<rows; i+
+00017cb0: 2b29 0a20 207b 0a20 2020 2069 6628 5061  +).  {.    if(Pa
+00017cc0: 6e65 6c4d 6f64 6529 2063 6f75 6e74 202b  nelMode) count +
+00017cd0: 3d20 6f66 6673 6574 3b0a 2020 2020 666f  = offset;.    fo
+00017ce0: 7228 496e 6465 7820 6b3d 303b 206b 3c64  r(Index k=0; k<d
+00017cf0: 6570 7468 3b20 6b2b 2b29 0a20 2020 2020  epth; k++).     
+00017d00: 2062 6c6f 636b 415b 636f 756e 742b 2b5d   blockA[count++]
+00017d10: 203d 2063 6a28 6c68 7328 692c 206b 2929   = cj(lhs(i, k))
+00017d20: 3b0a 2020 2020 6966 2850 616e 656c 4d6f  ;.    if(PanelMo
+00017d30: 6465 2920 636f 756e 7420 2b3d 2028 7374  de) count += (st
+00017d40: 7269 6465 2d6f 6666 7365 742d 6465 7074  ride-offset-dept
+00017d50: 6829 3b0a 2020 7d0a 7d0a 0a2f 2f20 636f  h);.  }.}..// co
+00017d60: 7079 2061 2063 6f6d 706c 6574 6520 7061  py a complete pa
+00017d70: 6e65 6c20 6f66 2074 6865 2072 6873 0a2f  nel of the rhs./
+00017d80: 2f20 7468 6973 2076 6572 7369 6f6e 2069  / this version i
+00017d90: 7320 6f70 7469 6d69 7a65 6420 666f 7220  s optimized for 
+00017da0: 636f 6c75 6d6e 206d 616a 6f72 206d 6174  column major mat
+00017db0: 7269 6365 730a 2f2f 2054 6865 2074 7261  rices.// The tra
+00017dc0: 7665 7273 616c 206f 7264 6572 2069 7320  versal order is 
+00017dd0: 6173 2066 6f6c 6c6f 773a 2028 6e72 3d3d  as follow: (nr==
+00017de0: 3429 3a0a 2f2f 2020 3020 2031 2020 3220  4):.//  0  1  2 
+00017df0: 2033 2020 2031 3220 3133 2031 3420 3135   3   12 13 14 15
+00017e00: 2020 2032 3420 3237 0a2f 2f20 2034 2020     24 27.//  4  
+00017e10: 3520 2036 2020 3720 2020 3136 2031 3720  5  6  7   16 17 
+00017e20: 3138 2031 3920 2020 3235 2032 380a 2f2f  18 19   25 28.//
+00017e30: 2020 3820 2039 2031 3020 3131 2020 2032    8  9 10 11   2
+00017e40: 3020 3231 2032 3220 3233 2020 2032 3620  0 21 22 23   26 
+00017e50: 3239 0a2f 2f20 202e 2020 2e20 202e 2020  29.//  .  .  .  
+00017e60: 2e20 2020 202e 2020 2e20 202e 2020 2e20  .    .  .  .  . 
+00017e70: 2020 202e 2020 2e0a 7465 6d70 6c61 7465     .  ..template
+00017e80: 3c74 7970 656e 616d 6520 5363 616c 6172  <typename Scalar
+00017e90: 2c20 7479 7065 6e61 6d65 2049 6e64 6578  , typename Index
+00017ea0: 2c20 7479 7065 6e61 6d65 2044 6174 614d  , typename DataM
+00017eb0: 6170 7065 722c 2069 6e74 206e 722c 2062  apper, int nr, b
+00017ec0: 6f6f 6c20 436f 6e6a 7567 6174 652c 2062  ool Conjugate, b
+00017ed0: 6f6f 6c20 5061 6e65 6c4d 6f64 653e 0a73  ool PanelMode>.s
+00017ee0: 7472 7563 7420 6765 6d6d 5f70 6163 6b5f  truct gemm_pack_
+00017ef0: 7268 733c 5363 616c 6172 2c20 496e 6465  rhs<Scalar, Inde
+00017f00: 782c 2044 6174 614d 6170 7065 722c 206e  x, DataMapper, n
+00017f10: 722c 2043 6f6c 4d61 6a6f 722c 2043 6f6e  r, ColMajor, Con
+00017f20: 6a75 6761 7465 2c20 5061 6e65 6c4d 6f64  jugate, PanelMod
+00017f30: 653e 0a7b 0a20 2074 7970 6564 6566 2074  e>.{.  typedef t
+00017f40: 7970 656e 616d 6520 7061 636b 6574 5f74  ypename packet_t
+00017f50: 7261 6974 733c 5363 616c 6172 3e3a 3a74  raits<Scalar>::t
+00017f60: 7970 6520 5061 636b 6574 3b0a 2020 7479  ype Packet;.  ty
+00017f70: 7065 6465 6620 7479 7065 6e61 6d65 2044  pedef typename D
+00017f80: 6174 614d 6170 7065 723a 3a4c 696e 6561  ataMapper::Linea
+00017f90: 724d 6170 7065 7220 4c69 6e65 6172 4d61  rMapper LinearMa
+00017fa0: 7070 6572 3b0a 2020 656e 756d 207b 2050  pper;.  enum { P
+00017fb0: 6163 6b65 7453 697a 6520 3d20 7061 636b  acketSize = pack
+00017fc0: 6574 5f74 7261 6974 733c 5363 616c 6172  et_traits<Scalar
+00017fd0: 3e3a 3a73 697a 6520 7d3b 0a20 2045 4947  >::size };.  EIG
+00017fe0: 454e 5f44 4f4e 545f 494e 4c49 4e45 2076  EN_DONT_INLINE v
+00017ff0: 6f69 6420 6f70 6572 6174 6f72 2829 2853  oid operator()(S
+00018000: 6361 6c61 722a 2062 6c6f 636b 422c 2063  calar* blockB, c
+00018010: 6f6e 7374 2044 6174 614d 6170 7065 7226  onst DataMapper&
+00018020: 2072 6873 2c20 496e 6465 7820 6465 7074   rhs, Index dept
+00018030: 682c 2049 6e64 6578 2063 6f6c 732c 2049  h, Index cols, I
+00018040: 6e64 6578 2073 7472 6964 653d 302c 2049  ndex stride=0, I
+00018050: 6e64 6578 206f 6666 7365 743d 3029 3b0a  ndex offset=0);.
+00018060: 7d3b 0a0a 7465 6d70 6c61 7465 3c74 7970  };..template<typ
+00018070: 656e 616d 6520 5363 616c 6172 2c20 7479  ename Scalar, ty
+00018080: 7065 6e61 6d65 2049 6e64 6578 2c20 7479  pename Index, ty
+00018090: 7065 6e61 6d65 2044 6174 614d 6170 7065  pename DataMappe
+000180a0: 722c 2069 6e74 206e 722c 2062 6f6f 6c20  r, int nr, bool 
+000180b0: 436f 6e6a 7567 6174 652c 2062 6f6f 6c20  Conjugate, bool 
+000180c0: 5061 6e65 6c4d 6f64 653e 0a45 4947 454e  PanelMode>.EIGEN
+000180d0: 5f44 4f4e 545f 494e 4c49 4e45 2076 6f69  _DONT_INLINE voi
+000180e0: 6420 6765 6d6d 5f70 6163 6b5f 7268 733c  d gemm_pack_rhs<
+000180f0: 5363 616c 6172 2c20 496e 6465 782c 2044  Scalar, Index, D
+00018100: 6174 614d 6170 7065 722c 206e 722c 2043  ataMapper, nr, C
+00018110: 6f6c 4d61 6a6f 722c 2043 6f6e 6a75 6761  olMajor, Conjuga
+00018120: 7465 2c20 5061 6e65 6c4d 6f64 653e 0a20  te, PanelMode>. 
+00018130: 203a 3a6f 7065 7261 746f 7228 2928 5363   ::operator()(Sc
+00018140: 616c 6172 2a20 626c 6f63 6b42 2c20 636f  alar* blockB, co
+00018150: 6e73 7420 4461 7461 4d61 7070 6572 2620  nst DataMapper& 
+00018160: 7268 732c 2049 6e64 6578 2064 6570 7468  rhs, Index depth
+00018170: 2c20 496e 6465 7820 636f 6c73 2c20 496e  , Index cols, In
+00018180: 6465 7820 7374 7269 6465 2c20 496e 6465  dex stride, Inde
+00018190: 7820 6f66 6673 6574 290a 7b0a 2020 4549  x offset).{.  EI
+000181a0: 4745 4e5f 4153 4d5f 434f 4d4d 454e 5428  GEN_ASM_COMMENT(
+000181b0: 2245 4947 454e 2050 524f 4455 4354 2050  "EIGEN PRODUCT P
+000181c0: 4143 4b20 5248 5320 434f 4c4d 414a 4f52  ACK RHS COLMAJOR
+000181d0: 2229 3b0a 2020 4549 4745 4e5f 554e 5553  ");.  EIGEN_UNUS
+000181e0: 4544 5f56 4152 4941 424c 4528 7374 7269  ED_VARIABLE(stri
+000181f0: 6465 293b 0a20 2045 4947 454e 5f55 4e55  de);.  EIGEN_UNU
+00018200: 5345 445f 5641 5249 4142 4c45 286f 6666  SED_VARIABLE(off
+00018210: 7365 7429 3b0a 2020 6569 6765 6e5f 6173  set);.  eigen_as
+00018220: 7365 7274 2828 2821 5061 6e65 6c4d 6f64  sert(((!PanelMod
+00018230: 6529 2026 2620 7374 7269 6465 3d3d 3020  e) && stride==0 
+00018240: 2626 206f 6666 7365 743d 3d30 2920 7c7c  && offset==0) ||
+00018250: 2028 5061 6e65 6c4d 6f64 6520 2626 2073   (PanelMode && s
+00018260: 7472 6964 653e 3d64 6570 7468 2026 2620  tride>=depth && 
+00018270: 6f66 6673 6574 3c3d 7374 7269 6465 2929  offset<=stride))
+00018280: 3b0a 2020 636f 6e6a 5f69 663c 4e75 6d54  ;.  conj_if<NumT
+00018290: 7261 6974 733c 5363 616c 6172 3e3a 3a49  raits<Scalar>::I
+000182a0: 7343 6f6d 706c 6578 2026 2620 436f 6e6a  sComplex && Conj
+000182b0: 7567 6174 653e 2063 6a3b 0a20 2049 6e64  ugate> cj;.  Ind
+000182c0: 6578 2070 6163 6b65 745f 636f 6c73 3820  ex packet_cols8 
+000182d0: 3d20 6e72 3e3d 3820 3f20 2863 6f6c 732f  = nr>=8 ? (cols/
+000182e0: 3829 202a 2038 203a 2030 3b0a 2020 496e  8) * 8 : 0;.  In
+000182f0: 6465 7820 7061 636b 6574 5f63 6f6c 7334  dex packet_cols4
+00018300: 203d 206e 723e 3d34 203f 2028 636f 6c73   = nr>=4 ? (cols
+00018310: 2f34 2920 2a20 3420 3a20 303b 0a20 2049  /4) * 4 : 0;.  I
+00018320: 6e64 6578 2063 6f75 6e74 203d 2030 3b0a  ndex count = 0;.
+00018330: 2020 636f 6e73 7420 496e 6465 7820 7065    const Index pe
+00018340: 656c 6564 5f6b 203d 2028 6465 7074 682f  eled_k = (depth/
+00018350: 5061 636b 6574 5369 7a65 292a 5061 636b  PacketSize)*Pack
+00018360: 6574 5369 7a65 3b0a 2f2f 2020 2069 6628  etSize;.//   if(
+00018370: 6e72 3e3d 3829 0a2f 2f20 2020 7b0a 2f2f  nr>=8).//   {.//
+00018380: 2020 2020 2066 6f72 2849 6e64 6578 206a       for(Index j
+00018390: 323d 303b 206a 323c 7061 636b 6574 5f63  2=0; j2<packet_c
+000183a0: 6f6c 7338 3b20 6a32 2b3d 3829 0a2f 2f20  ols8; j2+=8).// 
+000183b0: 2020 2020 7b0a 2f2f 2020 2020 2020 202f      {.//       /
+000183c0: 2f20 736b 6970 2077 6861 7420 7765 2068  / skip what we h
+000183d0: 6176 6520 6265 666f 7265 0a2f 2f20 2020  ave before.//   
+000183e0: 2020 2020 6966 2850 616e 656c 4d6f 6465      if(PanelMode
+000183f0: 2920 636f 756e 7420 2b3d 2038 202a 206f  ) count += 8 * o
+00018400: 6666 7365 743b 0a2f 2f20 2020 2020 2020  ffset;.//       
+00018410: 636f 6e73 7420 5363 616c 6172 2a20 6230  const Scalar* b0
+00018420: 203d 2026 7268 735b 286a 322b 3029 2a72   = &rhs[(j2+0)*r
+00018430: 6873 5374 7269 6465 5d3b 0a2f 2f20 2020  hsStride];.//   
+00018440: 2020 2020 636f 6e73 7420 5363 616c 6172      const Scalar
+00018450: 2a20 6231 203d 2026 7268 735b 286a 322b  * b1 = &rhs[(j2+
+00018460: 3129 2a72 6873 5374 7269 6465 5d3b 0a2f  1)*rhsStride];./
+00018470: 2f20 2020 2020 2020 636f 6e73 7420 5363  /       const Sc
+00018480: 616c 6172 2a20 6232 203d 2026 7268 735b  alar* b2 = &rhs[
+00018490: 286a 322b 3229 2a72 6873 5374 7269 6465  (j2+2)*rhsStride
+000184a0: 5d3b 0a2f 2f20 2020 2020 2020 636f 6e73  ];.//       cons
+000184b0: 7420 5363 616c 6172 2a20 6233 203d 2026  t Scalar* b3 = &
+000184c0: 7268 735b 286a 322b 3329 2a72 6873 5374  rhs[(j2+3)*rhsSt
+000184d0: 7269 6465 5d3b 0a2f 2f20 2020 2020 2020  ride];.//       
+000184e0: 636f 6e73 7420 5363 616c 6172 2a20 6234  const Scalar* b4
+000184f0: 203d 2026 7268 735b 286a 322b 3429 2a72   = &rhs[(j2+4)*r
+00018500: 6873 5374 7269 6465 5d3b 0a2f 2f20 2020  hsStride];.//   
+00018510: 2020 2020 636f 6e73 7420 5363 616c 6172      const Scalar
+00018520: 2a20 6235 203d 2026 7268 735b 286a 322b  * b5 = &rhs[(j2+
+00018530: 3529 2a72 6873 5374 7269 6465 5d3b 0a2f  5)*rhsStride];./
+00018540: 2f20 2020 2020 2020 636f 6e73 7420 5363  /       const Sc
+00018550: 616c 6172 2a20 6236 203d 2026 7268 735b  alar* b6 = &rhs[
+00018560: 286a 322b 3629 2a72 6873 5374 7269 6465  (j2+6)*rhsStride
+00018570: 5d3b 0a2f 2f20 2020 2020 2020 636f 6e73  ];.//       cons
+00018580: 7420 5363 616c 6172 2a20 6237 203d 2026  t Scalar* b7 = &
+00018590: 7268 735b 286a 322b 3729 2a72 6873 5374  rhs[(j2+7)*rhsSt
+000185a0: 7269 6465 5d3b 0a2f 2f20 2020 2020 2020  ride];.//       
+000185b0: 496e 6465 7820 6b3d 303b 0a2f 2f20 2020  Index k=0;.//   
+000185c0: 2020 2020 6966 2850 6163 6b65 7453 697a      if(PacketSiz
+000185d0: 653d 3d38 2920 2f2f 2054 4f44 4f20 656e  e==8) // TODO en
+000185e0: 6162 6c65 2076 6563 746f 7269 7a65 6420  able vectorized 
+000185f0: 7472 616e 7370 6f73 6974 696f 6e20 666f  transposition fo
+00018600: 7220 5061 636b 6574 5369 7a65 3d3d 340a  r PacketSize==4.
+00018610: 2f2f 2020 2020 2020 207b 0a2f 2f20 2020  //       {.//   
+00018620: 2020 2020 2020 666f 7228 3b20 6b3c 7065        for(; k<pe
+00018630: 656c 6564 5f6b 3b20 6b2b 3d50 6163 6b65  eled_k; k+=Packe
+00018640: 7453 697a 6529 207b 0a2f 2f20 2020 2020  tSize) {.//     
+00018650: 2020 2020 2020 5061 636b 6574 426c 6f63        PacketBloc
+00018660: 6b3c 5061 636b 6574 3e20 6b65 726e 656c  k<Packet> kernel
+00018670: 3b0a 2f2f 2020 2020 2020 2020 2020 2066  ;.//           f
+00018680: 6f72 2028 696e 7420 7020 3d20 303b 2070  or (int p = 0; p
+00018690: 203c 2050 6163 6b65 7453 697a 653b 202b   < PacketSize; +
+000186a0: 2b70 2920 7b0a 2f2f 2020 2020 2020 2020  +p) {.//        
+000186b0: 2020 2020 206b 6572 6e65 6c2e 7061 636b       kernel.pack
+000186c0: 6574 5b70 5d20 3d20 706c 6f61 6475 3c50  et[p] = ploadu<P
+000186d0: 6163 6b65 743e 2826 7268 735b 286a 322b  acket>(&rhs[(j2+
+000186e0: 7029 2a72 6873 5374 7269 6465 2b6b 5d29  p)*rhsStride+k])
+000186f0: 3b0a 2f2f 2020 2020 2020 2020 2020 207d  ;.//           }
+00018700: 0a2f 2f20 2020 2020 2020 2020 2020 7074  .//           pt
+00018710: 7261 6e73 706f 7365 286b 6572 6e65 6c29  ranspose(kernel)
+00018720: 3b0a 2f2f 2020 2020 2020 2020 2020 2066  ;.//           f
+00018730: 6f72 2028 696e 7420 7020 3d20 303b 2070  or (int p = 0; p
+00018740: 203c 2050 6163 6b65 7453 697a 653b 202b   < PacketSize; +
+00018750: 2b70 2920 7b0a 2f2f 2020 2020 2020 2020  +p) {.//        
+00018760: 2020 2020 2070 7374 6f72 6575 2862 6c6f       pstoreu(blo
+00018770: 636b 422b 636f 756e 742c 2063 6a2e 7063  ckB+count, cj.pc
+00018780: 6f6e 6a28 6b65 726e 656c 2e70 6163 6b65  onj(kernel.packe
+00018790: 745b 705d 2929 3b0a 2f2f 2020 2020 2020  t[p]));.//      
+000187a0: 2020 2020 2020 2063 6f75 6e74 2b3d 5061         count+=Pa
+000187b0: 636b 6574 5369 7a65 3b0a 2f2f 2020 2020  cketSize;.//    
+000187c0: 2020 2020 2020 207d 0a2f 2f20 2020 2020         }.//     
+000187d0: 2020 2020 7d0a 2f2f 2020 2020 2020 207d      }.//       }
+000187e0: 0a2f 2f20 2020 2020 2020 666f 7228 3b20  .//       for(; 
+000187f0: 6b3c 6465 7074 683b 206b 2b2b 290a 2f2f  k<depth; k++).//
+00018800: 2020 2020 2020 207b 0a2f 2f20 2020 2020         {.//     
+00018810: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
+00018820: 2b30 5d20 3d20 636a 2862 305b 6b5d 293b  +0] = cj(b0[k]);
+00018830: 0a2f 2f20 2020 2020 2020 2020 626c 6f63  .//         bloc
+00018840: 6b42 5b63 6f75 6e74 2b31 5d20 3d20 636a  kB[count+1] = cj
+00018850: 2862 315b 6b5d 293b 0a2f 2f20 2020 2020  (b1[k]);.//     
+00018860: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
+00018870: 2b32 5d20 3d20 636a 2862 325b 6b5d 293b  +2] = cj(b2[k]);
+00018880: 0a2f 2f20 2020 2020 2020 2020 626c 6f63  .//         bloc
+00018890: 6b42 5b63 6f75 6e74 2b33 5d20 3d20 636a  kB[count+3] = cj
+000188a0: 2862 335b 6b5d 293b 0a2f 2f20 2020 2020  (b3[k]);.//     
+000188b0: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
+000188c0: 2b34 5d20 3d20 636a 2862 345b 6b5d 293b  +4] = cj(b4[k]);
+000188d0: 0a2f 2f20 2020 2020 2020 2020 626c 6f63  .//         bloc
+000188e0: 6b42 5b63 6f75 6e74 2b35 5d20 3d20 636a  kB[count+5] = cj
+000188f0: 2862 355b 6b5d 293b 0a2f 2f20 2020 2020  (b5[k]);.//     
+00018900: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
+00018910: 2b36 5d20 3d20 636a 2862 365b 6b5d 293b  +6] = cj(b6[k]);
+00018920: 0a2f 2f20 2020 2020 2020 2020 626c 6f63  .//         bloc
+00018930: 6b42 5b63 6f75 6e74 2b37 5d20 3d20 636a  kB[count+7] = cj
+00018940: 2862 375b 6b5d 293b 0a2f 2f20 2020 2020  (b7[k]);.//     
+00018950: 2020 2020 636f 756e 7420 2b3d 2038 3b0a      count += 8;.
+00018960: 2f2f 2020 2020 2020 207d 0a2f 2f20 2020  //       }.//   
+00018970: 2020 2020 2f2f 2073 6b69 7020 7768 6174      // skip what
+00018980: 2077 6520 6861 7665 2061 6674 6572 0a2f   we have after./
+00018990: 2f20 2020 2020 2020 6966 2850 616e 656c  /       if(Panel
+000189a0: 4d6f 6465 2920 636f 756e 7420 2b3d 2038  Mode) count += 8
+000189b0: 202a 2028 7374 7269 6465 2d6f 6666 7365   * (stride-offse
+000189c0: 742d 6465 7074 6829 3b0a 2f2f 2020 2020  t-depth);.//    
+000189d0: 207d 0a2f 2f20 2020 7d0a 0a20 2069 6628   }.//   }..  if(
+000189e0: 6e72 3e3d 3429 0a20 207b 0a20 2020 2066  nr>=4).  {.    f
+000189f0: 6f72 2849 6e64 6578 206a 323d 7061 636b  or(Index j2=pack
+00018a00: 6574 5f63 6f6c 7338 3b20 6a32 3c70 6163  et_cols8; j2<pac
+00018a10: 6b65 745f 636f 6c73 343b 206a 322b 3d34  ket_cols4; j2+=4
+00018a20: 290a 2020 2020 7b0a 2020 2020 2020 2f2f  ).    {.      //
+00018a30: 2073 6b69 7020 7768 6174 2077 6520 6861   skip what we ha
+00018a40: 7665 2062 6566 6f72 650a 2020 2020 2020  ve before.      
+00018a50: 6966 2850 616e 656c 4d6f 6465 2920 636f  if(PanelMode) co
+00018a60: 756e 7420 2b3d 2034 202a 206f 6666 7365  unt += 4 * offse
+00018a70: 743b 0a20 2020 2020 2063 6f6e 7374 204c  t;.      const L
+00018a80: 696e 6561 724d 6170 7065 7220 646d 3020  inearMapper dm0 
+00018a90: 3d20 7268 732e 6765 744c 696e 6561 724d  = rhs.getLinearM
+00018aa0: 6170 7065 7228 302c 206a 3220 2b20 3029  apper(0, j2 + 0)
+00018ab0: 3b0a 2020 2020 2020 636f 6e73 7420 4c69  ;.      const Li
+00018ac0: 6e65 6172 4d61 7070 6572 2064 6d31 203d  nearMapper dm1 =
+00018ad0: 2072 6873 2e67 6574 4c69 6e65 6172 4d61   rhs.getLinearMa
+00018ae0: 7070 6572 2830 2c20 6a32 202b 2031 293b  pper(0, j2 + 1);
+00018af0: 0a20 2020 2020 2063 6f6e 7374 204c 696e  .      const Lin
+00018b00: 6561 724d 6170 7065 7220 646d 3220 3d20  earMapper dm2 = 
+00018b10: 7268 732e 6765 744c 696e 6561 724d 6170  rhs.getLinearMap
+00018b20: 7065 7228 302c 206a 3220 2b20 3229 3b0a  per(0, j2 + 2);.
+00018b30: 2020 2020 2020 636f 6e73 7420 4c69 6e65        const Line
+00018b40: 6172 4d61 7070 6572 2064 6d33 203d 2072  arMapper dm3 = r
+00018b50: 6873 2e67 6574 4c69 6e65 6172 4d61 7070  hs.getLinearMapp
+00018b60: 6572 2830 2c20 6a32 202b 2033 293b 0a0a  er(0, j2 + 3);..
+00018b70: 2020 2020 2020 496e 6465 7820 6b3d 303b        Index k=0;
+00018b80: 0a20 2020 2020 2069 6628 2850 6163 6b65  .      if((Packe
+00018b90: 7453 697a 6525 3429 3d3d 3029 202f 2f20  tSize%4)==0) // 
+00018ba0: 544f 444f 2065 6e61 626c 6520 7665 6374  TODO enable vect
+00018bb0: 6f72 697a 6564 2074 7261 6e73 706f 7369  orized transposi
+00018bc0: 7469 6f6e 2066 6f72 2050 6163 6b65 7453  tion for PacketS
+00018bd0: 697a 653d 3d32 203f 3f0a 2020 2020 2020  ize==2 ??.      
+00018be0: 7b0a 2020 2020 2020 2020 666f 7228 3b20  {.        for(; 
+00018bf0: 6b3c 7065 656c 6564 5f6b 3b20 6b2b 3d50  k<peeled_k; k+=P
+00018c00: 6163 6b65 7453 697a 6529 207b 0a20 2020  acketSize) {.   
+00018c10: 2020 2020 2020 2050 6163 6b65 7442 6c6f         PacketBlo
+00018c20: 636b 3c50 6163 6b65 742c 2850 6163 6b65  ck<Packet,(Packe
+00018c30: 7453 697a 6525 3429 3d3d 303f 343a 5061  tSize%4)==0?4:Pa
+00018c40: 636b 6574 5369 7a65 3e20 6b65 726e 656c  cketSize> kernel
+00018c50: 3b0a 2020 2020 2020 2020 2020 6b65 726e  ;.          kern
+00018c60: 656c 2e70 6163 6b65 745b 3020 2020 2020  el.packet[0     
+00018c70: 2020 2020 2020 5d20 3d20 646d 302e 7465        ] = dm0.te
+00018c80: 6d70 6c61 7465 206c 6f61 6450 6163 6b65  mplate loadPacke
+00018c90: 743c 5061 636b 6574 3e28 6b29 3b0a 2020  t<Packet>(k);.  
+00018ca0: 2020 2020 2020 2020 6b65 726e 656c 2e70          kernel.p
+00018cb0: 6163 6b65 745b 3125 5061 636b 6574 5369  acket[1%PacketSi
+00018cc0: 7a65 5d20 3d20 646d 312e 7465 6d70 6c61  ze] = dm1.templa
+00018cd0: 7465 206c 6f61 6450 6163 6b65 743c 5061  te loadPacket<Pa
+00018ce0: 636b 6574 3e28 6b29 3b0a 2020 2020 2020  cket>(k);.      
+00018cf0: 2020 2020 6b65 726e 656c 2e70 6163 6b65      kernel.packe
+00018d00: 745b 3225 5061 636b 6574 5369 7a65 5d20  t[2%PacketSize] 
+00018d10: 3d20 646d 322e 7465 6d70 6c61 7465 206c  = dm2.template l
+00018d20: 6f61 6450 6163 6b65 743c 5061 636b 6574  oadPacket<Packet
+00018d30: 3e28 6b29 3b0a 2020 2020 2020 2020 2020  >(k);.          
+00018d40: 6b65 726e 656c 2e70 6163 6b65 745b 3325  kernel.packet[3%
+00018d50: 5061 636b 6574 5369 7a65 5d20 3d20 646d  PacketSize] = dm
+00018d60: 332e 7465 6d70 6c61 7465 206c 6f61 6450  3.template loadP
+00018d70: 6163 6b65 743c 5061 636b 6574 3e28 6b29  acket<Packet>(k)
+00018d80: 3b0a 2020 2020 2020 2020 2020 7074 7261  ;.          ptra
+00018d90: 6e73 706f 7365 286b 6572 6e65 6c29 3b0a  nspose(kernel);.
+00018da0: 2020 2020 2020 2020 2020 7073 746f 7265            pstore
+00018db0: 7528 626c 6f63 6b42 2b63 6f75 6e74 2b30  u(blockB+count+0
+00018dc0: 2a50 6163 6b65 7453 697a 652c 2063 6a2e  *PacketSize, cj.
+00018dd0: 7063 6f6e 6a28 6b65 726e 656c 2e70 6163  pconj(kernel.pac
+00018de0: 6b65 745b 305d 2929 3b0a 2020 2020 2020  ket[0]));.      
+00018df0: 2020 2020 7073 746f 7265 7528 626c 6f63      pstoreu(bloc
+00018e00: 6b42 2b63 6f75 6e74 2b31 2a50 6163 6b65  kB+count+1*Packe
+00018e10: 7453 697a 652c 2063 6a2e 7063 6f6e 6a28  tSize, cj.pconj(
+00018e20: 6b65 726e 656c 2e70 6163 6b65 745b 3125  kernel.packet[1%
+00018e30: 5061 636b 6574 5369 7a65 5d29 293b 0a20  PacketSize]));. 
+00018e40: 2020 2020 2020 2020 2070 7374 6f72 6575           pstoreu
+00018e50: 2862 6c6f 636b 422b 636f 756e 742b 322a  (blockB+count+2*
+00018e60: 5061 636b 6574 5369 7a65 2c20 636a 2e70  PacketSize, cj.p
+00018e70: 636f 6e6a 286b 6572 6e65 6c2e 7061 636b  conj(kernel.pack
+00018e80: 6574 5b32 2550 6163 6b65 7453 697a 655d  et[2%PacketSize]
+00018e90: 2929 3b0a 2020 2020 2020 2020 2020 7073  ));.          ps
+00018ea0: 746f 7265 7528 626c 6f63 6b42 2b63 6f75  toreu(blockB+cou
+00018eb0: 6e74 2b33 2a50 6163 6b65 7453 697a 652c  nt+3*PacketSize,
+00018ec0: 2063 6a2e 7063 6f6e 6a28 6b65 726e 656c   cj.pconj(kernel
+00018ed0: 2e70 6163 6b65 745b 3325 5061 636b 6574  .packet[3%Packet
+00018ee0: 5369 7a65 5d29 293b 0a20 2020 2020 2020  Size]));.       
+00018ef0: 2020 2063 6f75 6e74 2b3d 342a 5061 636b     count+=4*Pack
+00018f00: 6574 5369 7a65 3b0a 2020 2020 2020 2020  etSize;.        
+00018f10: 7d0a 2020 2020 2020 7d0a 2020 2020 2020  }.      }.      
+00018f20: 666f 7228 3b20 6b3c 6465 7074 683b 206b  for(; k<depth; k
+00018f30: 2b2b 290a 2020 2020 2020 7b0a 2020 2020  ++).      {.    
+00018f40: 2020 2020 626c 6f63 6b42 5b63 6f75 6e74      blockB[count
+00018f50: 2b30 5d20 3d20 636a 2864 6d30 286b 2929  +0] = cj(dm0(k))
+00018f60: 3b0a 2020 2020 2020 2020 626c 6f63 6b42  ;.        blockB
+00018f70: 5b63 6f75 6e74 2b31 5d20 3d20 636a 2864  [count+1] = cj(d
+00018f80: 6d31 286b 2929 3b0a 2020 2020 2020 2020  m1(k));.        
+00018f90: 626c 6f63 6b42 5b63 6f75 6e74 2b32 5d20  blockB[count+2] 
+00018fa0: 3d20 636a 2864 6d32 286b 2929 3b0a 2020  = cj(dm2(k));.  
+00018fb0: 2020 2020 2020 626c 6f63 6b42 5b63 6f75        blockB[cou
+00018fc0: 6e74 2b33 5d20 3d20 636a 2864 6d33 286b  nt+3] = cj(dm3(k
+00018fd0: 2929 3b0a 2020 2020 2020 2020 636f 756e  ));.        coun
+00018fe0: 7420 2b3d 2034 3b0a 2020 2020 2020 7d0a  t += 4;.      }.
+00018ff0: 2020 2020 2020 2f2f 2073 6b69 7020 7768        // skip wh
+00019000: 6174 2077 6520 6861 7665 2061 6674 6572  at we have after
+00019010: 0a20 2020 2020 2069 6628 5061 6e65 6c4d  .      if(PanelM
+00019020: 6f64 6529 2063 6f75 6e74 202b 3d20 3420  ode) count += 4 
+00019030: 2a20 2873 7472 6964 652d 6f66 6673 6574  * (stride-offset
+00019040: 2d64 6570 7468 293b 0a20 2020 207d 0a20  -depth);.    }. 
+00019050: 207d 0a0a 2020 2f2f 2063 6f70 7920 7468   }..  // copy th
+00019060: 6520 7265 6d61 696e 696e 6720 636f 6c75  e remaining colu
+00019070: 6d6e 7320 6f6e 6520 6174 2061 2074 696d  mns one at a tim
+00019080: 6520 286e 723d 3d31 290a 2020 666f 7228  e (nr==1).  for(
+00019090: 496e 6465 7820 6a32 3d70 6163 6b65 745f  Index j2=packet_
+000190a0: 636f 6c73 343b 206a 323c 636f 6c73 3b20  cols4; j2<cols; 
+000190b0: 2b2b 6a32 290a 2020 7b0a 2020 2020 6966  ++j2).  {.    if
+000190c0: 2850 616e 656c 4d6f 6465 2920 636f 756e  (PanelMode) coun
+000190d0: 7420 2b3d 206f 6666 7365 743b 0a20 2020  t += offset;.   
+000190e0: 2063 6f6e 7374 204c 696e 6561 724d 6170   const LinearMap
+000190f0: 7065 7220 646d 3020 3d20 7268 732e 6765  per dm0 = rhs.ge
+00019100: 744c 696e 6561 724d 6170 7065 7228 302c  tLinearMapper(0,
+00019110: 206a 3229 3b0a 2020 2020 666f 7228 496e   j2);.    for(In
+00019120: 6465 7820 6b3d 303b 206b 3c64 6570 7468  dex k=0; k<depth
+00019130: 3b20 6b2b 2b29 0a20 2020 207b 0a20 2020  ; k++).    {.   
+00019140: 2020 2062 6c6f 636b 425b 636f 756e 745d     blockB[count]
+00019150: 203d 2063 6a28 646d 3028 6b29 293b 0a20   = cj(dm0(k));. 
+00019160: 2020 2020 2063 6f75 6e74 202b 3d20 313b       count += 1;
+00019170: 0a20 2020 207d 0a20 2020 2069 6628 5061  .    }.    if(Pa
+00019180: 6e65 6c4d 6f64 6529 2063 6f75 6e74 202b  nelMode) count +
+00019190: 3d20 2873 7472 6964 652d 6f66 6673 6574  = (stride-offset
+000191a0: 2d64 6570 7468 293b 0a20 207d 0a7d 0a0a  -depth);.  }.}..
+000191b0: 2f2f 2074 6869 7320 7665 7273 696f 6e20  // this version 
+000191c0: 6973 206f 7074 696d 697a 6564 2066 6f72  is optimized for
+000191d0: 2072 6f77 206d 616a 6f72 206d 6174 7269   row major matri
+000191e0: 6365 730a 7465 6d70 6c61 7465 3c74 7970  ces.template<typ
+000191f0: 656e 616d 6520 5363 616c 6172 2c20 7479  ename Scalar, ty
+00019200: 7065 6e61 6d65 2049 6e64 6578 2c20 7479  pename Index, ty
+00019210: 7065 6e61 6d65 2044 6174 614d 6170 7065  pename DataMappe
+00019220: 722c 2069 6e74 206e 722c 2062 6f6f 6c20  r, int nr, bool 
+00019230: 436f 6e6a 7567 6174 652c 2062 6f6f 6c20  Conjugate, bool 
+00019240: 5061 6e65 6c4d 6f64 653e 0a73 7472 7563  PanelMode>.struc
+00019250: 7420 6765 6d6d 5f70 6163 6b5f 7268 733c  t gemm_pack_rhs<
+00019260: 5363 616c 6172 2c20 496e 6465 782c 2044  Scalar, Index, D
+00019270: 6174 614d 6170 7065 722c 206e 722c 2052  ataMapper, nr, R
+00019280: 6f77 4d61 6a6f 722c 2043 6f6e 6a75 6761  owMajor, Conjuga
+00019290: 7465 2c20 5061 6e65 6c4d 6f64 653e 0a7b  te, PanelMode>.{
+000192a0: 0a20 2074 7970 6564 6566 2074 7970 656e  .  typedef typen
+000192b0: 616d 6520 7061 636b 6574 5f74 7261 6974  ame packet_trait
+000192c0: 733c 5363 616c 6172 3e3a 3a74 7970 6520  s<Scalar>::type 
+000192d0: 5061 636b 6574 3b0a 2020 7479 7065 6465  Packet;.  typede
+000192e0: 6620 7479 7065 6e61 6d65 2075 6e70 6163  f typename unpac
+000192f0: 6b65 745f 7472 6169 7473 3c50 6163 6b65  ket_traits<Packe
+00019300: 743e 3a3a 6861 6c66 2048 616c 6650 6163  t>::half HalfPac
+00019310: 6b65 743b 0a20 2074 7970 6564 6566 2074  ket;.  typedef t
+00019320: 7970 656e 616d 6520 756e 7061 636b 6574  ypename unpacket
+00019330: 5f74 7261 6974 733c 7479 7065 6e61 6d65  _traits<typename
+00019340: 2075 6e70 6163 6b65 745f 7472 6169 7473   unpacket_traits
+00019350: 3c50 6163 6b65 743e 3a3a 6861 6c66 3e3a  <Packet>::half>:
+00019360: 3a68 616c 6620 5175 6172 7465 7250 6163  :half QuarterPac
+00019370: 6b65 743b 0a20 2074 7970 6564 6566 2074  ket;.  typedef t
+00019380: 7970 656e 616d 6520 4461 7461 4d61 7070  ypename DataMapp
+00019390: 6572 3a3a 4c69 6e65 6172 4d61 7070 6572  er::LinearMapper
+000193a0: 204c 696e 6561 724d 6170 7065 723b 0a20   LinearMapper;. 
+000193b0: 2065 6e75 6d20 7b20 5061 636b 6574 5369   enum { PacketSi
+000193c0: 7a65 203d 2070 6163 6b65 745f 7472 6169  ze = packet_trai
+000193d0: 7473 3c53 6361 6c61 723e 3a3a 7369 7a65  ts<Scalar>::size
+000193e0: 2c0a 2020 2020 2020 2020 2048 616c 6650  ,.         HalfP
+000193f0: 6163 6b65 7453 697a 6520 3d20 756e 7061  acketSize = unpa
+00019400: 636b 6574 5f74 7261 6974 733c 4861 6c66  cket_traits<Half
+00019410: 5061 636b 6574 3e3a 3a73 697a 652c 0a09  Packet>::size,..
+00019420: 0920 5175 6172 7465 7250 6163 6b65 7453  . QuarterPacketS
+00019430: 697a 6520 3d20 756e 7061 636b 6574 5f74  ize = unpacket_t
+00019440: 7261 6974 733c 5175 6172 7465 7250 6163  raits<QuarterPac
+00019450: 6b65 743e 3a3a 7369 7a65 7d3b 0a20 2045  ket>::size};.  E
+00019460: 4947 454e 5f44 4f4e 545f 494e 4c49 4e45  IGEN_DONT_INLINE
+00019470: 2076 6f69 6420 6f70 6572 6174 6f72 2829   void operator()
+00019480: 2853 6361 6c61 722a 2062 6c6f 636b 422c  (Scalar* blockB,
+00019490: 2063 6f6e 7374 2044 6174 614d 6170 7065   const DataMappe
+000194a0: 7226 2072 6873 2c20 496e 6465 7820 6465  r& rhs, Index de
+000194b0: 7074 682c 2049 6e64 6578 2063 6f6c 732c  pth, Index cols,
+000194c0: 2049 6e64 6578 2073 7472 6964 653d 302c   Index stride=0,
+000194d0: 2049 6e64 6578 206f 6666 7365 743d 3029   Index offset=0)
+000194e0: 0a20 207b 0a20 2020 2045 4947 454e 5f41  .  {.    EIGEN_A
+000194f0: 534d 5f43 4f4d 4d45 4e54 2822 4549 4745  SM_COMMENT("EIGE
+00019500: 4e20 5052 4f44 5543 5420 5041 434b 2052  N PRODUCT PACK R
+00019510: 4853 2052 4f57 4d41 4a4f 5222 293b 0a20  HS ROWMAJOR");. 
+00019520: 2020 2045 4947 454e 5f55 4e55 5345 445f     EIGEN_UNUSED_
+00019530: 5641 5249 4142 4c45 2873 7472 6964 6529  VARIABLE(stride)
+00019540: 3b0a 2020 2020 4549 4745 4e5f 554e 5553  ;.    EIGEN_UNUS
+00019550: 4544 5f56 4152 4941 424c 4528 6f66 6673  ED_VARIABLE(offs
+00019560: 6574 293b 0a20 2020 2065 6967 656e 5f61  et);.    eigen_a
+00019570: 7373 6572 7428 2828 2150 616e 656c 4d6f  ssert(((!PanelMo
+00019580: 6465 2920 2626 2073 7472 6964 653d 3d30  de) && stride==0
+00019590: 2026 2620 6f66 6673 6574 3d3d 3029 207c   && offset==0) |
+000195a0: 7c20 2850 616e 656c 4d6f 6465 2026 2620  | (PanelMode && 
+000195b0: 7374 7269 6465 3e3d 6465 7074 6820 2626  stride>=depth &&
+000195c0: 206f 6666 7365 743c 3d73 7472 6964 6529   offset<=stride)
+000195d0: 293b 0a20 2020 2063 6f6e 7374 2062 6f6f  );.    const boo
+000195e0: 6c20 4861 7348 616c 6620 3d20 2869 6e74  l HasHalf = (int
+000195f0: 2948 616c 6650 6163 6b65 7453 697a 6520  )HalfPacketSize 
+00019600: 3c20 2869 6e74 2950 6163 6b65 7453 697a  < (int)PacketSiz
+00019610: 653b 0a20 2020 2063 6f6e 7374 2062 6f6f  e;.    const boo
+00019620: 6c20 4861 7351 7561 7274 6572 203d 2028  l HasQuarter = (
+00019630: 696e 7429 5175 6172 7465 7250 6163 6b65  int)QuarterPacke
+00019640: 7453 697a 6520 3c20 2869 6e74 2948 616c  tSize < (int)Hal
+00019650: 6650 6163 6b65 7453 697a 653b 0a20 2020  fPacketSize;.   
+00019660: 2063 6f6e 6a5f 6966 3c4e 756d 5472 6169   conj_if<NumTrai
+00019670: 7473 3c53 6361 6c61 723e 3a3a 4973 436f  ts<Scalar>::IsCo
+00019680: 6d70 6c65 7820 2626 2043 6f6e 6a75 6761  mplex && Conjuga
+00019690: 7465 3e20 636a 3b0a 2020 2020 496e 6465  te> cj;.    Inde
+000196a0: 7820 7061 636b 6574 5f63 6f6c 7338 203d  x packet_cols8 =
+000196b0: 206e 723e 3d38 203f 2028 636f 6c73 2f38   nr>=8 ? (cols/8
+000196c0: 2920 2a20 3820 3a20 303b 0a20 2020 2049  ) * 8 : 0;.    I
+000196d0: 6e64 6578 2070 6163 6b65 745f 636f 6c73  ndex packet_cols
+000196e0: 3420 3d20 6e72 3e3d 3420 3f20 2863 6f6c  4 = nr>=4 ? (col
+000196f0: 732f 3429 202a 2034 203a 2030 3b0a 2020  s/4) * 4 : 0;.  
+00019700: 2020 496e 6465 7820 636f 756e 7420 3d20    Index count = 
+00019710: 303b 0a0a 2020 2f2f 2020 2069 6628 6e72  0;..  //   if(nr
+00019720: 3e3d 3829 0a20 202f 2f20 2020 7b0a 2020  >=8).  //   {.  
+00019730: 2f2f 2020 2020 2066 6f72 2849 6e64 6578  //     for(Index
+00019740: 206a 323d 303b 206a 323c 7061 636b 6574   j2=0; j2<packet
+00019750: 5f63 6f6c 7338 3b20 6a32 2b3d 3829 0a20  _cols8; j2+=8). 
+00019760: 202f 2f20 2020 2020 7b0a 2020 2f2f 2020   //     {.  //  
+00019770: 2020 2020 202f 2f20 736b 6970 2077 6861       // skip wha
+00019780: 7420 7765 2068 6176 6520 6265 666f 7265  t we have before
+00019790: 0a20 202f 2f20 2020 2020 2020 6966 2850  .  //       if(P
+000197a0: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
+000197b0: 2b3d 2038 202a 206f 6666 7365 743b 0a20  += 8 * offset;. 
+000197c0: 202f 2f20 2020 2020 2020 666f 7228 496e   //       for(In
+000197d0: 6465 7820 6b3d 303b 206b 3c64 6570 7468  dex k=0; k<depth
+000197e0: 3b20 6b2b 2b29 0a20 202f 2f20 2020 2020  ; k++).  //     
+000197f0: 2020 7b0a 2020 2f2f 2020 2020 2020 2020    {.  //        
+00019800: 2069 6620 2850 6163 6b65 7453 697a 653d   if (PacketSize=
+00019810: 3d38 2920 7b0a 2020 2f2f 2020 2020 2020  =8) {.  //      
+00019820: 2020 2020 2050 6163 6b65 7420 4120 3d20       Packet A = 
+00019830: 706c 6f61 6475 3c50 6163 6b65 743e 2826  ploadu<Packet>(&
+00019840: 7268 735b 6b2a 7268 7353 7472 6964 6520  rhs[k*rhsStride 
+00019850: 2b20 6a32 5d29 3b0a 2020 2f2f 2020 2020  + j2]);.  //    
+00019860: 2020 2020 2020 2070 7374 6f72 6575 2862         pstoreu(b
+00019870: 6c6f 636b 422b 636f 756e 742c 2063 6a2e  lockB+count, cj.
+00019880: 7063 6f6e 6a28 4129 293b 0a20 202f 2f20  pconj(A));.  // 
+00019890: 2020 2020 2020 2020 7d20 656c 7365 2069          } else i
+000198a0: 6620 2850 6163 6b65 7453 697a 653d 3d34  f (PacketSize==4
+000198b0: 2920 7b0a 2020 2f2f 2020 2020 2020 2020  ) {.  //        
+000198c0: 2020 2050 6163 6b65 7420 4120 3d20 706c     Packet A = pl
+000198d0: 6f61 6475 3c50 6163 6b65 743e 2826 7268  oadu<Packet>(&rh
+000198e0: 735b 6b2a 7268 7353 7472 6964 6520 2b20  s[k*rhsStride + 
+000198f0: 6a32 5d29 3b0a 2020 2f2f 2020 2020 2020  j2]);.  //      
+00019900: 2020 2020 2050 6163 6b65 7420 4220 3d20       Packet B = 
+00019910: 706c 6f61 6475 3c50 6163 6b65 743e 2826  ploadu<Packet>(&
+00019920: 7268 735b 6b2a 7268 7353 7472 6964 6520  rhs[k*rhsStride 
+00019930: 2b20 6a32 202b 2050 6163 6b65 7453 697a  + j2 + PacketSiz
+00019940: 655d 293b 0a20 202f 2f20 2020 2020 2020  e]);.  //       
+00019950: 2020 2020 7073 746f 7265 7528 626c 6f63      pstoreu(bloc
+00019960: 6b42 2b63 6f75 6e74 2c20 636a 2e70 636f  kB+count, cj.pco
+00019970: 6e6a 2841 2929 3b0a 2020 2f2f 2020 2020  nj(A));.  //    
+00019980: 2020 2020 2020 2070 7374 6f72 6575 2862         pstoreu(b
+00019990: 6c6f 636b 422b 636f 756e 742b 5061 636b  lockB+count+Pack
+000199a0: 6574 5369 7a65 2c20 636a 2e70 636f 6e6a  etSize, cj.pconj
+000199b0: 2842 2929 3b0a 2020 2f2f 2020 2020 2020  (B));.  //      
+000199c0: 2020 207d 2065 6c73 6520 7b0a 2020 2f2f     } else {.  //
+000199d0: 2020 2020 2020 2020 2020 2063 6f6e 7374             const
+000199e0: 2053 6361 6c61 722a 2062 3020 3d20 2672   Scalar* b0 = &r
+000199f0: 6873 5b6b 2a72 6873 5374 7269 6465 202b  hs[k*rhsStride +
+00019a00: 206a 325d 3b0a 2020 2f2f 2020 2020 2020   j2];.  //      
+00019a10: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
+00019a20: 742b 305d 203d 2063 6a28 6230 5b30 5d29  t+0] = cj(b0[0])
+00019a30: 3b0a 2020 2f2f 2020 2020 2020 2020 2020  ;.  //          
+00019a40: 2062 6c6f 636b 425b 636f 756e 742b 315d   blockB[count+1]
+00019a50: 203d 2063 6a28 6230 5b31 5d29 3b0a 2020   = cj(b0[1]);.  
+00019a60: 2f2f 2020 2020 2020 2020 2020 2062 6c6f  //           blo
+00019a70: 636b 425b 636f 756e 742b 325d 203d 2063  ckB[count+2] = c
+00019a80: 6a28 6230 5b32 5d29 3b0a 2020 2f2f 2020  j(b0[2]);.  //  
+00019a90: 2020 2020 2020 2020 2062 6c6f 636b 425b           blockB[
+00019aa0: 636f 756e 742b 335d 203d 2063 6a28 6230  count+3] = cj(b0
+00019ab0: 5b33 5d29 3b0a 2020 2f2f 2020 2020 2020  [3]);.  //      
+00019ac0: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
+00019ad0: 742b 345d 203d 2063 6a28 6230 5b34 5d29  t+4] = cj(b0[4])
+00019ae0: 3b0a 2020 2f2f 2020 2020 2020 2020 2020  ;.  //          
+00019af0: 2062 6c6f 636b 425b 636f 756e 742b 355d   blockB[count+5]
+00019b00: 203d 2063 6a28 6230 5b35 5d29 3b0a 2020   = cj(b0[5]);.  
+00019b10: 2f2f 2020 2020 2020 2020 2020 2062 6c6f  //           blo
+00019b20: 636b 425b 636f 756e 742b 365d 203d 2063  ckB[count+6] = c
+00019b30: 6a28 6230 5b36 5d29 3b0a 2020 2f2f 2020  j(b0[6]);.  //  
+00019b40: 2020 2020 2020 2020 2062 6c6f 636b 425b           blockB[
+00019b50: 636f 756e 742b 375d 203d 2063 6a28 6230  count+7] = cj(b0
+00019b60: 5b37 5d29 3b0a 2020 2f2f 2020 2020 2020  [7]);.  //      
+00019b70: 2020 207d 0a20 202f 2f20 2020 2020 2020     }.  //       
+00019b80: 2020 636f 756e 7420 2b3d 2038 3b0a 2020    count += 8;.  
+00019b90: 2f2f 2020 2020 2020 207d 0a20 202f 2f20  //       }.  // 
+00019ba0: 2020 2020 2020 2f2f 2073 6b69 7020 7768        // skip wh
+00019bb0: 6174 2077 6520 6861 7665 2061 6674 6572  at we have after
+00019bc0: 0a20 202f 2f20 2020 2020 2020 6966 2850  .  //       if(P
+00019bd0: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
+00019be0: 2b3d 2038 202a 2028 7374 7269 6465 2d6f  += 8 * (stride-o
+00019bf0: 6666 7365 742d 6465 7074 6829 3b0a 2020  ffset-depth);.  
+00019c00: 2f2f 2020 2020 207d 0a20 202f 2f20 2020  //     }.  //   
+00019c10: 7d0a 2020 2020 6966 286e 723e 3d34 290a  }.    if(nr>=4).
+00019c20: 2020 2020 7b0a 2020 2020 2020 666f 7228      {.      for(
+00019c30: 496e 6465 7820 6a32 3d70 6163 6b65 745f  Index j2=packet_
+00019c40: 636f 6c73 383b 206a 323c 7061 636b 6574  cols8; j2<packet
+00019c50: 5f63 6f6c 7334 3b20 6a32 2b3d 3429 0a20  _cols4; j2+=4). 
+00019c60: 2020 2020 207b 0a20 2020 2020 2020 202f       {.        /
+00019c70: 2f20 736b 6970 2077 6861 7420 7765 2068  / skip what we h
+00019c80: 6176 6520 6265 666f 7265 0a20 2020 2020  ave before.     
+00019c90: 2020 2069 6628 5061 6e65 6c4d 6f64 6529     if(PanelMode)
+00019ca0: 2063 6f75 6e74 202b 3d20 3420 2a20 6f66   count += 4 * of
+00019cb0: 6673 6574 3b0a 2020 2020 2020 2020 666f  fset;.        fo
+00019cc0: 7228 496e 6465 7820 6b3d 303b 206b 3c64  r(Index k=0; k<d
+00019cd0: 6570 7468 3b20 6b2b 2b29 0a20 2020 2020  epth; k++).     
+00019ce0: 2020 207b 0a20 2020 2020 2020 2020 2069     {.          i
+00019cf0: 6620 2850 6163 6b65 7453 697a 653d 3d34  f (PacketSize==4
+00019d00: 2920 7b0a 2020 2020 2020 2020 2020 2020  ) {.            
+00019d10: 5061 636b 6574 2041 203d 2072 6873 2e74  Packet A = rhs.t
+00019d20: 656d 706c 6174 6520 6c6f 6164 5061 636b  emplate loadPack
+00019d30: 6574 3c50 6163 6b65 743e 286b 2c20 6a32  et<Packet>(k, j2
+00019d40: 293b 0a20 2020 2020 2020 2020 2020 2070  );.            p
+00019d50: 7374 6f72 6575 2862 6c6f 636b 422b 636f  storeu(blockB+co
+00019d60: 756e 742c 2063 6a2e 7063 6f6e 6a28 4129  unt, cj.pconj(A)
+00019d70: 293b 0a20 2020 2020 2020 2020 2020 2063  );.            c
+00019d80: 6f75 6e74 202b 3d20 5061 636b 6574 5369  ount += PacketSi
+00019d90: 7a65 3b0a 2020 2020 2020 2020 2020 7d20  ze;.          } 
+00019da0: 656c 7365 2069 6620 2848 6173 4861 6c66  else if (HasHalf
+00019db0: 2026 2620 4861 6c66 5061 636b 6574 5369   && HalfPacketSi
+00019dc0: 7a65 3d3d 3429 207b 0a20 2020 2020 2020  ze==4) {.       
+00019dd0: 2020 2020 2048 616c 6650 6163 6b65 7420       HalfPacket 
+00019de0: 4120 3d20 7268 732e 7465 6d70 6c61 7465  A = rhs.template
+00019df0: 206c 6f61 6450 6163 6b65 743c 4861 6c66   loadPacket<Half
+00019e00: 5061 636b 6574 3e28 6b2c 206a 3229 3b0a  Packet>(k, j2);.
+00019e10: 2020 2020 2020 2020 2020 2020 7073 746f              psto
+00019e20: 7265 7528 626c 6f63 6b42 2b63 6f75 6e74  reu(blockB+count
+00019e30: 2c20 636a 2e70 636f 6e6a 2841 2929 3b0a  , cj.pconj(A));.
+00019e40: 2020 2020 2020 2020 2020 2020 636f 756e              coun
+00019e50: 7420 2b3d 2048 616c 6650 6163 6b65 7453  t += HalfPacketS
+00019e60: 697a 653b 0a20 2020 2020 2020 2020 207d  ize;.          }
+00019e70: 2065 6c73 6520 6966 2028 4861 7351 7561   else if (HasQua
+00019e80: 7274 6572 2026 2620 5175 6172 7465 7250  rter && QuarterP
+00019e90: 6163 6b65 7453 697a 653d 3d34 2920 7b0a  acketSize==4) {.
+00019ea0: 2020 2020 2020 2020 2020 2020 5175 6172              Quar
+00019eb0: 7465 7250 6163 6b65 7420 4120 3d20 7268  terPacket A = rh
+00019ec0: 732e 7465 6d70 6c61 7465 206c 6f61 6450  s.template loadP
+00019ed0: 6163 6b65 743c 5175 6172 7465 7250 6163  acket<QuarterPac
+00019ee0: 6b65 743e 286b 2c20 6a32 293b 0a20 2020  ket>(k, j2);.   
+00019ef0: 2020 2020 2020 2020 2070 7374 6f72 6575           pstoreu
+00019f00: 2862 6c6f 636b 422b 636f 756e 742c 2063  (blockB+count, c
+00019f10: 6a2e 7063 6f6e 6a28 4129 293b 0a20 2020  j.pconj(A));.   
+00019f20: 2020 2020 2020 2020 2063 6f75 6e74 202b           count +
+00019f30: 3d20 5175 6172 7465 7250 6163 6b65 7453  = QuarterPacketS
+00019f40: 697a 653b 0a20 2020 2020 2020 2020 207d  ize;.          }
+00019f50: 2065 6c73 6520 7b0a 2020 2020 2020 2020   else {.        
+00019f60: 2020 2020 636f 6e73 7420 4c69 6e65 6172      const Linear
+00019f70: 4d61 7070 6572 2064 6d30 203d 2072 6873  Mapper dm0 = rhs
+00019f80: 2e67 6574 4c69 6e65 6172 4d61 7070 6572  .getLinearMapper
+00019f90: 286b 2c20 6a32 293b 0a20 2020 2020 2020  (k, j2);.       
+00019fa0: 2020 2020 2062 6c6f 636b 425b 636f 756e       blockB[coun
+00019fb0: 742b 305d 203d 2063 6a28 646d 3028 3029  t+0] = cj(dm0(0)
+00019fc0: 293b 0a20 2020 2020 2020 2020 2020 2062  );.            b
+00019fd0: 6c6f 636b 425b 636f 756e 742b 315d 203d  lockB[count+1] =
+00019fe0: 2063 6a28 646d 3028 3129 293b 0a20 2020   cj(dm0(1));.   
+00019ff0: 2020 2020 2020 2020 2062 6c6f 636b 425b           blockB[
+0001a000: 636f 756e 742b 325d 203d 2063 6a28 646d  count+2] = cj(dm
+0001a010: 3028 3229 293b 0a20 2020 2020 2020 2020  0(2));.         
+0001a020: 2020 2062 6c6f 636b 425b 636f 756e 742b     blockB[count+
+0001a030: 335d 203d 2063 6a28 646d 3028 3329 293b  3] = cj(dm0(3));
+0001a040: 0a20 2020 2020 2020 2020 2020 2063 6f75  .            cou
+0001a050: 6e74 202b 3d20 343b 0a20 2020 2020 2020  nt += 4;.       
+0001a060: 2020 207d 0a20 2020 2020 2020 207d 0a20     }.        }. 
+0001a070: 2020 2020 2020 202f 2f20 736b 6970 2077         // skip w
+0001a080: 6861 7420 7765 2068 6176 6520 6166 7465  hat we have afte
+0001a090: 720a 2020 2020 2020 2020 6966 2850 616e  r.        if(Pan
+0001a0a0: 656c 4d6f 6465 2920 636f 756e 7420 2b3d  elMode) count +=
+0001a0b0: 2034 202a 2028 7374 7269 6465 2d6f 6666   4 * (stride-off
+0001a0c0: 7365 742d 6465 7074 6829 3b0a 2020 2020  set-depth);.    
+0001a0d0: 2020 7d0a 2020 2020 7d0a 2020 2020 2f2f    }.    }.    //
+0001a0e0: 2063 6f70 7920 7468 6520 7265 6d61 696e   copy the remain
+0001a0f0: 696e 6720 636f 6c75 6d6e 7320 6f6e 6520  ing columns one 
+0001a100: 6174 2061 2074 696d 6520 286e 723d 3d31  at a time (nr==1
+0001a110: 290a 2020 2020 666f 7228 496e 6465 7820  ).    for(Index 
+0001a120: 6a32 3d70 6163 6b65 745f 636f 6c73 343b  j2=packet_cols4;
+0001a130: 206a 323c 636f 6c73 3b20 2b2b 6a32 290a   j2<cols; ++j2).
+0001a140: 2020 2020 7b0a 2020 2020 2020 6966 2850      {.      if(P
+0001a150: 616e 656c 4d6f 6465 2920 636f 756e 7420  anelMode) count 
+0001a160: 2b3d 206f 6666 7365 743b 0a20 2020 2020  += offset;.     
+0001a170: 2066 6f72 2849 6e64 6578 206b 3d30 3b20   for(Index k=0; 
+0001a180: 6b3c 6465 7074 683b 206b 2b2b 290a 2020  k<depth; k++).  
+0001a190: 2020 2020 7b0a 2020 2020 2020 2020 626c      {.        bl
+0001a1a0: 6f63 6b42 5b63 6f75 6e74 5d20 3d20 636a  ockB[count] = cj
+0001a1b0: 2872 6873 286b 2c20 6a32 2929 3b0a 2020  (rhs(k, j2));.  
+0001a1c0: 2020 2020 2020 636f 756e 7420 2b3d 2031        count += 1
+0001a1d0: 3b0a 2020 2020 2020 7d0a 2020 2020 2020  ;.      }.      
+0001a1e0: 6966 2850 616e 656c 4d6f 6465 2920 636f  if(PanelMode) co
+0001a1f0: 756e 7420 2b3d 2073 7472 6964 652d 6f66  unt += stride-of
+0001a200: 6673 6574 2d64 6570 7468 3b0a 2020 2020  fset-depth;.    
+0001a210: 7d0a 2020 7d0a 7d3b 0a0a 7d20 2f2f 2065  }.  }.};..} // e
+0001a220: 6e64 206e 616d 6573 7061 6365 2069 6e74  nd namespace int
+0001a230: 6572 6e61 6c0a 0a2f 2a2a 205c 7265 7475  ernal../** \retu
+0001a240: 726e 7320 7468 6520 6375 7272 656e 746c  rns the currentl
+0001a250: 7920 7365 7420 6c65 7665 6c20 3120 6370  y set level 1 cp
+0001a260: 7520 6361 6368 6520 7369 7a65 2028 696e  u cache size (in
+0001a270: 2062 7974 6573 2920 7573 6564 2074 6f20   bytes) used to 
+0001a280: 6573 7469 6d61 7465 2074 6865 2069 6465  estimate the ide
+0001a290: 616c 2062 6c6f 636b 696e 6720 7369 7a65  al blocking size
+0001a2a0: 2070 6172 616d 6574 6572 732e 0a20 202a   parameters..  *
+0001a2b0: 205c 7361 2073 6574 4370 7543 6163 6865   \sa setCpuCache
+0001a2c0: 5369 7a65 202a 2f0a 696e 6c69 6e65 2073  Size */.inline s
+0001a2d0: 7464 3a3a 7074 7264 6966 665f 7420 6c31  td::ptrdiff_t l1
+0001a2e0: 4361 6368 6553 697a 6528 290a 7b0a 2020  CacheSize().{.  
+0001a2f0: 7374 643a 3a70 7472 6469 6666 5f74 206c  std::ptrdiff_t l
+0001a300: 312c 206c 322c 206c 333b 0a20 2069 6e74  1, l2, l3;.  int
+0001a310: 6572 6e61 6c3a 3a6d 616e 6167 655f 6361  ernal::manage_ca
+0001a320: 6368 696e 675f 7369 7a65 7328 4765 7441  ching_sizes(GetA
+0001a330: 6374 696f 6e2c 2026 6c31 2c20 266c 322c  ction, &l1, &l2,
+0001a340: 2026 6c33 293b 0a20 2072 6574 7572 6e20   &l3);.  return 
+0001a350: 6c31 3b0a 7d0a 0a2f 2a2a 205c 7265 7475  l1;.}../** \retu
+0001a360: 726e 7320 7468 6520 6375 7272 656e 746c  rns the currentl
+0001a370: 7920 7365 7420 6c65 7665 6c20 3220 6370  y set level 2 cp
+0001a380: 7520 6361 6368 6520 7369 7a65 2028 696e  u cache size (in
+0001a390: 2062 7974 6573 2920 7573 6564 2074 6f20   bytes) used to 
+0001a3a0: 6573 7469 6d61 7465 2074 6865 2069 6465  estimate the ide
+0001a3b0: 616c 2062 6c6f 636b 696e 6720 7369 7a65  al blocking size
+0001a3c0: 2070 6172 616d 6574 6572 732e 0a20 202a   parameters..  *
+0001a3d0: 205c 7361 2073 6574 4370 7543 6163 6865   \sa setCpuCache
+0001a3e0: 5369 7a65 202a 2f0a 696e 6c69 6e65 2073  Size */.inline s
+0001a3f0: 7464 3a3a 7074 7264 6966 665f 7420 6c32  td::ptrdiff_t l2
+0001a400: 4361 6368 6553 697a 6528 290a 7b0a 2020  CacheSize().{.  
+0001a410: 7374 643a 3a70 7472 6469 6666 5f74 206c  std::ptrdiff_t l
+0001a420: 312c 206c 322c 206c 333b 0a20 2069 6e74  1, l2, l3;.  int
+0001a430: 6572 6e61 6c3a 3a6d 616e 6167 655f 6361  ernal::manage_ca
+0001a440: 6368 696e 675f 7369 7a65 7328 4765 7441  ching_sizes(GetA
+0001a450: 6374 696f 6e2c 2026 6c31 2c20 266c 322c  ction, &l1, &l2,
+0001a460: 2026 6c33 293b 0a20 2072 6574 7572 6e20   &l3);.  return 
+0001a470: 6c32 3b0a 7d0a 0a2f 2a2a 205c 7265 7475  l2;.}../** \retu
+0001a480: 726e 7320 7468 6520 6375 7272 656e 746c  rns the currentl
+0001a490: 7920 7365 7420 6c65 7665 6c20 3320 6370  y set level 3 cp
+0001a4a0: 7520 6361 6368 6520 7369 7a65 2028 696e  u cache size (in
+0001a4b0: 2062 7974 6573 2920 7573 6564 2074 6f20   bytes) used to 
+0001a4c0: 6573 7469 6d61 7465 2074 6865 2069 6465  estimate the ide
+0001a4d0: 616c 2062 6c6f 636b 696e 6720 7369 7a65  al blocking size
+0001a4e0: 2070 6172 616d 6574 655c 0a72 732e 2020   paramete\.rs.  
+0001a4f0: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a500: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a510: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a520: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a530: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a540: 2020 2020 2020 2020 2020 2020 2020 2020                  
+0001a550: 2020 2020 2020 2020 2020 2020 2020 0a2a                .*
+0001a560: 205c 7361 2073 6574 4370 7543 6163 6865   \sa setCpuCache
+0001a570: 5369 7a65 202a 2f0a 696e 6c69 6e65 2073  Size */.inline s
+0001a580: 7464 3a3a 7074 7264 6966 665f 7420 6c33  td::ptrdiff_t l3
+0001a590: 4361 6368 6553 697a 6528 290a 7b0a 2020  CacheSize().{.  
+0001a5a0: 7374 643a 3a70 7472 6469 6666 5f74 206c  std::ptrdiff_t l
+0001a5b0: 312c 206c 322c 206c 333b 0a20 2069 6e74  1, l2, l3;.  int
+0001a5c0: 6572 6e61 6c3a 3a6d 616e 6167 655f 6361  ernal::manage_ca
+0001a5d0: 6368 696e 675f 7369 7a65 7328 4765 7441  ching_sizes(GetA
+0001a5e0: 6374 696f 6e2c 2026 6c31 2c20 266c 322c  ction, &l1, &l2,
+0001a5f0: 2026 6c33 293b 0a20 2072 6574 7572 6e20   &l3);.  return 
+0001a600: 6c33 3b0a 7d0a 0a2f 2a2a 2053 6574 2074  l3;.}../** Set t
+0001a610: 6865 2063 7075 204c 3120 616e 6420 4c32  he cpu L1 and L2
+0001a620: 2063 6163 6865 2073 697a 6573 2028 696e   cache sizes (in
+0001a630: 2062 7974 6573 292e 0a20 202a 2054 6865   bytes)..  * The
+0001a640: 7365 2076 616c 7565 7320 6172 6520 7573  se values are us
+0001a650: 6520 746f 2061 646a 7573 7420 7468 6520  e to adjust the 
+0001a660: 7369 7a65 206f 6620 7468 6520 626c 6f63  size of the bloc
+0001a670: 6b73 0a20 202a 2066 6f72 2074 6865 2061  ks.  * for the a
+0001a680: 6c67 6f72 6974 686d 7320 776f 726b 696e  lgorithms workin
+0001a690: 6720 7065 7220 626c 6f63 6b73 2e0a 2020  g per blocks..  
+0001a6a0: 2a0a 2020 2a20 5c73 6120 636f 6d70 7574  *.  * \sa comput
+0001a6b0: 6550 726f 6475 6374 426c 6f63 6b69 6e67  eProductBlocking
+0001a6c0: 5369 7a65 7320 2a2f 0a69 6e6c 696e 6520  Sizes */.inline 
+0001a6d0: 766f 6964 2073 6574 4370 7543 6163 6865  void setCpuCache
+0001a6e0: 5369 7a65 7328 7374 643a 3a70 7472 6469  Sizes(std::ptrdi
+0001a6f0: 6666 5f74 206c 312c 2073 7464 3a3a 7074  ff_t l1, std::pt
+0001a700: 7264 6966 665f 7420 6c32 2c20 7374 643a  rdiff_t l2, std:
+0001a710: 3a70 7472 6469 6666 5f74 206c 3329 0a7b  :ptrdiff_t l3).{
+0001a720: 0a20 2069 6e74 6572 6e61 6c3a 3a6d 616e  .  internal::man
+0001a730: 6167 655f 6361 6368 696e 675f 7369 7a65  age_caching_size
+0001a740: 7328 5365 7441 6374 696f 6e2c 2026 6c31  s(SetAction, &l1
+0001a750: 2c20 266c 322c 2026 6c33 293b 0a7d 0a0a  , &l2, &l3);.}..
+0001a760: 7d20 2f2f 2065 6e64 206e 616d 6573 7061  } // end namespa
+0001a770: 6365 2045 6967 656e 0a0a 2365 6e64 6966  ce Eigen..#endif
+0001a780: 202f 2f20 4549 4745 4e5f 4745 4e45 5241   // EIGEN_GENERA
+0001a790: 4c5f 424c 4f43 4b5f 5041 4e45 4c5f 480a  L_BLOCK_PANEL_H.
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrix.h`

 * *Files 2% similar despite different names*

```diff
@@ -16,64 +16,66 @@
 
 template<typename _LhsScalar, typename _RhsScalar> class level3_blocking;
 
 /* Specialization for a row-major destination matrix => simple transposition of the product */
 template<
   typename Index,
   typename LhsScalar, int LhsStorageOrder, bool ConjugateLhs,
-  typename RhsScalar, int RhsStorageOrder, bool ConjugateRhs>
-struct general_matrix_matrix_product<Index,LhsScalar,LhsStorageOrder,ConjugateLhs,RhsScalar,RhsStorageOrder,ConjugateRhs,RowMajor>
+  typename RhsScalar, int RhsStorageOrder, bool ConjugateRhs,
+  int ResInnerStride>
+struct general_matrix_matrix_product<Index,LhsScalar,LhsStorageOrder,ConjugateLhs,RhsScalar,RhsStorageOrder,ConjugateRhs,RowMajor,ResInnerStride>
 {
   typedef gebp_traits<RhsScalar,LhsScalar> Traits;
 
   typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
   static EIGEN_STRONG_INLINE void run(
     Index rows, Index cols, Index depth,
     const LhsScalar* lhs, Index lhsStride,
     const RhsScalar* rhs, Index rhsStride,
-    ResScalar* res, Index resStride,
+    ResScalar* res, Index resIncr, Index resStride,
     ResScalar alpha,
     level3_blocking<RhsScalar,LhsScalar>& blocking,
     GemmParallelInfo<Index>* info = 0)
   {
     // transpose the product such that the result is column major
     general_matrix_matrix_product<Index,
       RhsScalar, RhsStorageOrder==RowMajor ? ColMajor : RowMajor, ConjugateRhs,
       LhsScalar, LhsStorageOrder==RowMajor ? ColMajor : RowMajor, ConjugateLhs,
-      ColMajor>
-    ::run(cols,rows,depth,rhs,rhsStride,lhs,lhsStride,res,resStride,alpha,blocking,info);
+      ColMajor,ResInnerStride>
+    ::run(cols,rows,depth,rhs,rhsStride,lhs,lhsStride,res,resIncr,resStride,alpha,blocking,info);
   }
 };
 
 /*  Specialization for a col-major destination matrix
  *    => Blocking algorithm following Goto's paper */
 template<
   typename Index,
   typename LhsScalar, int LhsStorageOrder, bool ConjugateLhs,
-  typename RhsScalar, int RhsStorageOrder, bool ConjugateRhs>
-struct general_matrix_matrix_product<Index,LhsScalar,LhsStorageOrder,ConjugateLhs,RhsScalar,RhsStorageOrder,ConjugateRhs,ColMajor>
+  typename RhsScalar, int RhsStorageOrder, bool ConjugateRhs,
+  int ResInnerStride>
+struct general_matrix_matrix_product<Index,LhsScalar,LhsStorageOrder,ConjugateLhs,RhsScalar,RhsStorageOrder,ConjugateRhs,ColMajor,ResInnerStride>
 {
 
 typedef gebp_traits<LhsScalar,RhsScalar> Traits;
 
 typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
 static void run(Index rows, Index cols, Index depth,
   const LhsScalar* _lhs, Index lhsStride,
   const RhsScalar* _rhs, Index rhsStride,
-  ResScalar* _res, Index resStride,
+  ResScalar* _res, Index resIncr, Index resStride,
   ResScalar alpha,
   level3_blocking<LhsScalar,RhsScalar>& blocking,
   GemmParallelInfo<Index>* info = 0)
 {
   typedef const_blas_data_mapper<LhsScalar, Index, LhsStorageOrder> LhsMapper;
   typedef const_blas_data_mapper<RhsScalar, Index, RhsStorageOrder> RhsMapper;
-  typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor> ResMapper;
-  LhsMapper lhs(_lhs,lhsStride);
-  RhsMapper rhs(_rhs,rhsStride);
-  ResMapper res(_res, resStride);
+  typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor,Unaligned,ResInnerStride> ResMapper;
+  LhsMapper lhs(_lhs, lhsStride);
+  RhsMapper rhs(_rhs, rhsStride);
+  ResMapper res(_res, resStride, resIncr);
 
   Index kc = blocking.kc();                   // cache block size along the K direction
   Index mc = (std::min)(rows,blocking.mc());  // cache block size along the M direction
   Index nc = (std::min)(cols,blocking.nc());  // cache block size along the N direction
 
   gemm_pack_lhs<LhsScalar, Index, LhsMapper, Traits::mr, Traits::LhsProgress, typename Traits::LhsPacket4Packing, LhsStorageOrder> pack_lhs;
   gemm_pack_rhs<RhsScalar, Index, RhsMapper, Traits::nr, RhsStorageOrder> pack_rhs;
@@ -224,15 +226,15 @@
   {
     if(cols==-1)
       cols = m_rhs.cols();
 
     Gemm::run(rows, cols, m_lhs.cols(),
               &m_lhs.coeffRef(row,0), m_lhs.outerStride(),
               &m_rhs.coeffRef(0,col), m_rhs.outerStride(),
-              (Scalar*)&(m_dest.coeffRef(row,col)), m_dest.outerStride(),
+              (Scalar*)&(m_dest.coeffRef(row,col)), m_dest.innerStride(), m_dest.outerStride(),
               m_actualAlpha, m_blocking, info);
   }
 
   typedef typename Gemm::Traits Traits;
 
   protected:
     const Lhs& m_lhs;
@@ -465,44 +467,45 @@
   template<typename Dest>
   static void scaleAndAddTo(Dest& dst, const Lhs& a_lhs, const Rhs& a_rhs, const Scalar& alpha)
   {
     eigen_assert(dst.rows()==a_lhs.rows() && dst.cols()==a_rhs.cols());
     if(a_lhs.cols()==0 || a_lhs.rows()==0 || a_rhs.cols()==0)
       return;
 
-    // Fallback to GEMV if either the lhs or rhs is a runtime vector
     if (dst.cols() == 1)
     {
+      // Fallback to GEMV if either the lhs or rhs is a runtime vector
       typename Dest::ColXpr dst_vec(dst.col(0));
       return internal::generic_product_impl<Lhs,typename Rhs::ConstColXpr,DenseShape,DenseShape,GemvProduct>
         ::scaleAndAddTo(dst_vec, a_lhs, a_rhs.col(0), alpha);
     }
     else if (dst.rows() == 1)
     {
+      // Fallback to GEMV if either the lhs or rhs is a runtime vector
       typename Dest::RowXpr dst_vec(dst.row(0));
       return internal::generic_product_impl<typename Lhs::ConstRowXpr,Rhs,DenseShape,DenseShape,GemvProduct>
         ::scaleAndAddTo(dst_vec, a_lhs.row(0), a_rhs, alpha);
     }
 
     typename internal::add_const_on_value_type<ActualLhsType>::type lhs = LhsBlasTraits::extract(a_lhs);
     typename internal::add_const_on_value_type<ActualRhsType>::type rhs = RhsBlasTraits::extract(a_rhs);
 
-    Scalar actualAlpha = alpha * LhsBlasTraits::extractScalarFactor(a_lhs)
-                               * RhsBlasTraits::extractScalarFactor(a_rhs);
+    Scalar actualAlpha = combine_scalar_factors(alpha, a_lhs, a_rhs);
 
     typedef internal::gemm_blocking_space<(Dest::Flags&RowMajorBit) ? RowMajor : ColMajor,LhsScalar,RhsScalar,
             Dest::MaxRowsAtCompileTime,Dest::MaxColsAtCompileTime,MaxDepthAtCompileTime> BlockingType;
 
     typedef internal::gemm_functor<
       Scalar, Index,
       internal::general_matrix_matrix_product<
         Index,
         LhsScalar, (ActualLhsTypeCleaned::Flags&RowMajorBit) ? RowMajor : ColMajor, bool(LhsBlasTraits::NeedToConjugate),
         RhsScalar, (ActualRhsTypeCleaned::Flags&RowMajorBit) ? RowMajor : ColMajor, bool(RhsBlasTraits::NeedToConjugate),
-        (Dest::Flags&RowMajorBit) ? RowMajor : ColMajor>,
+        (Dest::Flags&RowMajorBit) ? RowMajor : ColMajor,
+        Dest::InnerStrideAtCompileTime>,
       ActualLhsTypeCleaned, ActualRhsTypeCleaned, Dest, BlockingType> GemmFunctor;
 
     BlockingType blocking(dst.rows(), dst.cols(), lhs.cols(), 1, true);
     internal::parallelize_gemm<(Dest::MaxRowsAtCompileTime>32 || Dest::MaxRowsAtCompileTime==Dynamic)>
         (GemmFunctor(lhs, rhs, dst, actualAlpha, blocking), a_lhs.rows(), a_rhs.cols(), a_lhs.cols(), Dest::Flags&RowMajorBit);
   }
 };
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular.h`

 * *Files 7% similar despite different names*

```diff
@@ -21,59 +21,62 @@
 * This file implements a general A * B product while
 * evaluating only one triangular part of the product.
 * This is a more general version of self adjoint product (C += A A^T)
 * as the level 3 SYRK Blas routine.
 **********************************************************************/
 
 // forward declarations (defined at the end of this file)
-template<typename LhsScalar, typename RhsScalar, typename Index, int mr, int nr, bool ConjLhs, bool ConjRhs, int UpLo>
+template<typename LhsScalar, typename RhsScalar, typename Index, int mr, int nr, bool ConjLhs, bool ConjRhs, int ResInnerStride, int UpLo>
 struct tribb_kernel;
   
 /* Optimized matrix-matrix product evaluating only one triangular half */
 template <typename Index,
           typename LhsScalar, int LhsStorageOrder, bool ConjugateLhs,
           typename RhsScalar, int RhsStorageOrder, bool ConjugateRhs,
-                              int ResStorageOrder, int  UpLo, int Version = Specialized>
+                              int ResStorageOrder, int ResInnerStride, int  UpLo, int Version = Specialized>
 struct general_matrix_matrix_triangular_product;
 
 // as usual if the result is row major => we transpose the product
 template <typename Index, typename LhsScalar, int LhsStorageOrder, bool ConjugateLhs,
-                          typename RhsScalar, int RhsStorageOrder, bool ConjugateRhs, int  UpLo, int Version>
-struct general_matrix_matrix_triangular_product<Index,LhsScalar,LhsStorageOrder,ConjugateLhs,RhsScalar,RhsStorageOrder,ConjugateRhs,RowMajor,UpLo,Version>
+                          typename RhsScalar, int RhsStorageOrder, bool ConjugateRhs,
+                          int ResInnerStride, int  UpLo, int Version>
+struct general_matrix_matrix_triangular_product<Index,LhsScalar,LhsStorageOrder,ConjugateLhs,RhsScalar,RhsStorageOrder,ConjugateRhs,RowMajor,ResInnerStride,UpLo,Version>
 {
   typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
   static EIGEN_STRONG_INLINE void run(Index size, Index depth,const LhsScalar* lhs, Index lhsStride,
-                                      const RhsScalar* rhs, Index rhsStride, ResScalar* res, Index resStride,
+                                      const RhsScalar* rhs, Index rhsStride, ResScalar* res, Index resIncr, Index resStride,
                                       const ResScalar& alpha, level3_blocking<RhsScalar,LhsScalar>& blocking)
   {
     general_matrix_matrix_triangular_product<Index,
         RhsScalar, RhsStorageOrder==RowMajor ? ColMajor : RowMajor, ConjugateRhs,
         LhsScalar, LhsStorageOrder==RowMajor ? ColMajor : RowMajor, ConjugateLhs,
-        ColMajor, UpLo==Lower?Upper:Lower>
-      ::run(size,depth,rhs,rhsStride,lhs,lhsStride,res,resStride,alpha,blocking);
+        ColMajor, ResInnerStride, UpLo==Lower?Upper:Lower>
+      ::run(size,depth,rhs,rhsStride,lhs,lhsStride,res,resIncr,resStride,alpha,blocking);
   }
 };
 
 template <typename Index, typename LhsScalar, int LhsStorageOrder, bool ConjugateLhs,
-                          typename RhsScalar, int RhsStorageOrder, bool ConjugateRhs, int  UpLo, int Version>
-struct general_matrix_matrix_triangular_product<Index,LhsScalar,LhsStorageOrder,ConjugateLhs,RhsScalar,RhsStorageOrder,ConjugateRhs,ColMajor,UpLo,Version>
+                          typename RhsScalar, int RhsStorageOrder, bool ConjugateRhs,
+                          int ResInnerStride, int  UpLo, int Version>
+struct general_matrix_matrix_triangular_product<Index,LhsScalar,LhsStorageOrder,ConjugateLhs,RhsScalar,RhsStorageOrder,ConjugateRhs,ColMajor,ResInnerStride,UpLo,Version>
 {
   typedef typename ScalarBinaryOpTraits<LhsScalar, RhsScalar>::ReturnType ResScalar;
   static EIGEN_STRONG_INLINE void run(Index size, Index depth,const LhsScalar* _lhs, Index lhsStride,
-                                      const RhsScalar* _rhs, Index rhsStride, ResScalar* _res, Index resStride,
+                                      const RhsScalar* _rhs, Index rhsStride,
+                                      ResScalar* _res, Index resIncr, Index resStride,
                                       const ResScalar& alpha, level3_blocking<LhsScalar,RhsScalar>& blocking)
   {
     typedef gebp_traits<LhsScalar,RhsScalar> Traits;
 
     typedef const_blas_data_mapper<LhsScalar, Index, LhsStorageOrder> LhsMapper;
     typedef const_blas_data_mapper<RhsScalar, Index, RhsStorageOrder> RhsMapper;
-    typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor> ResMapper;
+    typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
     LhsMapper lhs(_lhs,lhsStride);
     RhsMapper rhs(_rhs,rhsStride);
-    ResMapper res(_res, resStride);
+    ResMapper res(_res, resStride, resIncr);
 
     Index kc = blocking.kc();
     Index mc = (std::min)(size,blocking.mc());
 
     // !!! mc must be a multiple of nr:
     if(mc > Traits::nr)
       mc = (mc/Traits::nr)*Traits::nr;
@@ -83,15 +86,15 @@
 
     ei_declare_aligned_stack_constructed_variable(LhsScalar, blockA, sizeA, blocking.blockA());
     ei_declare_aligned_stack_constructed_variable(RhsScalar, blockB, sizeB, blocking.blockB());
 
     gemm_pack_lhs<LhsScalar, Index, LhsMapper, Traits::mr, Traits::LhsProgress, typename Traits::LhsPacket4Packing, LhsStorageOrder> pack_lhs;
     gemm_pack_rhs<RhsScalar, Index, RhsMapper, Traits::nr, RhsStorageOrder> pack_rhs;
     gebp_kernel<LhsScalar, RhsScalar, Index, ResMapper, Traits::mr, Traits::nr, ConjugateLhs, ConjugateRhs> gebp;
-    tribb_kernel<LhsScalar, RhsScalar, Index, Traits::mr, Traits::nr, ConjugateLhs, ConjugateRhs, UpLo> sybb;
+    tribb_kernel<LhsScalar, RhsScalar, Index, Traits::mr, Traits::nr, ConjugateLhs, ConjugateRhs, ResInnerStride, UpLo> sybb;
 
     for(Index k2=0; k2<depth; k2+=kc)
     {
       const Index actual_kc = (std::min)(k2+kc,depth)-k2;
 
       // note that the actual rhs is the transpose/adjoint of mat
       pack_rhs(blockB, rhs.getSubMapper(k2,0), actual_kc, size);
@@ -106,15 +109,15 @@
         //  1 - before the diagonal => processed with gebp or skipped
         //  2 - the actual_mc x actual_mc symmetric block => processed with a special kernel
         //  3 - after the diagonal => processed with gebp or skipped
         if (UpLo==Lower)
           gebp(res.getSubMapper(i2, 0), blockA, blockB, actual_mc, actual_kc,
                (std::min)(size,i2), alpha, -1, -1, 0, 0);
 
-        sybb(_res+resStride*i2 + i2, resStride, blockA, blockB + actual_kc*i2, actual_mc, actual_kc, alpha);
+        sybb(_res+resStride*i2 + resIncr*i2, resIncr, resStride, blockA, blockB + actual_kc*i2, actual_mc, actual_kc, alpha);
 
         if (UpLo==Upper)
         {
           Index j2 = i2+actual_mc;
           gebp(res.getSubMapper(i2, j2), blockA, blockB+actual_kc*j2, actual_mc,
                actual_kc, (std::max)(Index(0), size-j2), alpha, -1, -1, 0, 0);
         }
@@ -128,65 +131,67 @@
 // - the current destination block is processed per panel of actual_mc x BlockSize
 //   where BlockSize is set to the minimal value allowing gebp to be as fast as possible
 // - then, as usual, each panel is split into three parts along the diagonal,
 //   the sub blocks above and below the diagonal are processed as usual,
 //   while the triangular block overlapping the diagonal is evaluated into a
 //   small temporary buffer which is then accumulated into the result using a
 //   triangular traversal.
-template<typename LhsScalar, typename RhsScalar, typename Index, int mr, int nr, bool ConjLhs, bool ConjRhs, int UpLo>
+template<typename LhsScalar, typename RhsScalar, typename Index, int mr, int nr, bool ConjLhs, bool ConjRhs, int ResInnerStride, int UpLo>
 struct tribb_kernel
 {
   typedef gebp_traits<LhsScalar,RhsScalar,ConjLhs,ConjRhs> Traits;
   typedef typename Traits::ResScalar ResScalar;
 
   enum {
     BlockSize  = meta_least_common_multiple<EIGEN_PLAIN_ENUM_MAX(mr,nr),EIGEN_PLAIN_ENUM_MIN(mr,nr)>::ret
   };
-  void operator()(ResScalar* _res, Index resStride, const LhsScalar* blockA, const RhsScalar* blockB, Index size, Index depth, const ResScalar& alpha)
+  void operator()(ResScalar* _res, Index resIncr, Index resStride, const LhsScalar* blockA, const RhsScalar* blockB, Index size, Index depth, const ResScalar& alpha)
   {
-    typedef blas_data_mapper<ResScalar, Index, ColMajor> ResMapper;
-    ResMapper res(_res, resStride);
-    gebp_kernel<LhsScalar, RhsScalar, Index, ResMapper, mr, nr, ConjLhs, ConjRhs> gebp_kernel;
+    typedef blas_data_mapper<ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
+    typedef blas_data_mapper<ResScalar, Index, ColMajor, Unaligned> BufferMapper;
+    ResMapper res(_res, resStride, resIncr);
+    gebp_kernel<LhsScalar, RhsScalar, Index, ResMapper, mr, nr, ConjLhs, ConjRhs> gebp_kernel1;
+    gebp_kernel<LhsScalar, RhsScalar, Index, BufferMapper, mr, nr, ConjLhs, ConjRhs> gebp_kernel2;
 
     Matrix<ResScalar,BlockSize,BlockSize,ColMajor> buffer((internal::constructor_without_unaligned_array_assert()));
 
     // let's process the block per panel of actual_mc x BlockSize,
     // again, each is split into three parts, etc.
     for (Index j=0; j<size; j+=BlockSize)
     {
       Index actualBlockSize = std::min<Index>(BlockSize,size - j);
       const RhsScalar* actual_b = blockB+j*depth;
 
       if(UpLo==Upper)
-        gebp_kernel(res.getSubMapper(0, j), blockA, actual_b, j, depth, actualBlockSize, alpha,
-                    -1, -1, 0, 0);
+        gebp_kernel1(res.getSubMapper(0, j), blockA, actual_b, j, depth, actualBlockSize, alpha,
+                     -1, -1, 0, 0);
       
       // selfadjoint micro block
       {
         Index i = j;
         buffer.setZero();
         // 1 - apply the kernel on the temporary buffer
-        gebp_kernel(ResMapper(buffer.data(), BlockSize), blockA+depth*i, actual_b, actualBlockSize, depth, actualBlockSize, alpha,
-                    -1, -1, 0, 0);
+        gebp_kernel2(BufferMapper(buffer.data(), BlockSize), blockA+depth*i, actual_b, actualBlockSize, depth, actualBlockSize, alpha,
+                     -1, -1, 0, 0);
 
         // 2 - triangular accumulation
         for(Index j1=0; j1<actualBlockSize; ++j1)
         {
-          ResScalar* r = &res(i, j + j1);
+          typename ResMapper::LinearMapper r = res.getLinearMapper(i,j+j1);
           for(Index i1=UpLo==Lower ? j1 : 0;
               UpLo==Lower ? i1<actualBlockSize : i1<=j1; ++i1)
-            r[i1] += buffer(i1,j1);
+            r(i1) += buffer(i1,j1);
         }
       }
 
       if(UpLo==Lower)
       {
         Index i = j+actualBlockSize;
-        gebp_kernel(res.getSubMapper(i, j), blockA+depth*i, actual_b, size-i, 
-                    depth, actualBlockSize, alpha, -1, -1, 0, 0);
+        gebp_kernel1(res.getSubMapper(i, j), blockA+depth*i, actual_b, size-i, 
+                     depth, actualBlockSize, alpha, -1, -1, 0, 0);
       }
     }
   }
 };
 
 } // end namespace internal
 
@@ -282,19 +287,20 @@
           MatrixType::MaxColsAtCompileTime, MatrixType::MaxColsAtCompileTime, _ActualRhs::MaxColsAtCompileTime> BlockingType;
 
     BlockingType blocking(size, size, depth, 1, false);
 
     internal::general_matrix_matrix_triangular_product<Index,
       typename Lhs::Scalar, LhsIsRowMajor ? RowMajor : ColMajor, LhsBlasTraits::NeedToConjugate,
       typename Rhs::Scalar, RhsIsRowMajor ? RowMajor : ColMajor, RhsBlasTraits::NeedToConjugate,
-      IsRowMajor ? RowMajor : ColMajor, UpLo&(Lower|Upper)>
+      IsRowMajor ? RowMajor : ColMajor, MatrixType::InnerStrideAtCompileTime, UpLo&(Lower|Upper)>
       ::run(size, depth,
             &actualLhs.coeffRef(SkipDiag&&(UpLo&Lower)==Lower ? 1 : 0,0), actualLhs.outerStride(),
             &actualRhs.coeffRef(0,SkipDiag&&(UpLo&Upper)==Upper ? 1 : 0), actualRhs.outerStride(),
-            mat.data() + (SkipDiag ? (bool(IsRowMajor) != ((UpLo&Lower)==Lower) ? 1 : mat.outerStride() ) : 0), mat.outerStride(), actualAlpha, blocking);
+            mat.data() + (SkipDiag ? (bool(IsRowMajor) != ((UpLo&Lower)==Lower) ? mat.innerStride() : mat.outerStride() ) : 0),
+            mat.innerStride(), mat.outerStride(), actualAlpha, blocking);
   }
 };
 
 template<typename MatrixType, unsigned int UpLo>
 template<typename ProductType>
 EIGEN_DEVICE_FUNC TriangularView<MatrixType,UpLo>& TriangularViewImpl<MatrixType,UpLo,Dense>::_assignProduct(const ProductType& prod, const Scalar& alpha, bool beta)
 {
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular_BLAS.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrixTriangular_BLAS.h`

 * *Files 2% similar despite different names*

```diff
@@ -36,35 +36,35 @@
 namespace Eigen {
 
 namespace internal {
 
 template <typename Index, typename Scalar, int AStorageOrder, bool ConjugateA, int ResStorageOrder, int UpLo>
 struct general_matrix_matrix_rankupdate :
        general_matrix_matrix_triangular_product<
-         Index,Scalar,AStorageOrder,ConjugateA,Scalar,AStorageOrder,ConjugateA,ResStorageOrder,UpLo,BuiltIn> {};
+         Index,Scalar,AStorageOrder,ConjugateA,Scalar,AStorageOrder,ConjugateA,ResStorageOrder,1,UpLo,BuiltIn> {};
 
 
 // try to go to BLAS specialization
 #define EIGEN_BLAS_RANKUPDATE_SPECIALIZE(Scalar) \
 template <typename Index, int LhsStorageOrder, bool ConjugateLhs, \
                           int RhsStorageOrder, bool ConjugateRhs, int  UpLo> \
 struct general_matrix_matrix_triangular_product<Index,Scalar,LhsStorageOrder,ConjugateLhs, \
-               Scalar,RhsStorageOrder,ConjugateRhs,ColMajor,UpLo,Specialized> { \
+               Scalar,RhsStorageOrder,ConjugateRhs,ColMajor,1,UpLo,Specialized> { \
   static EIGEN_STRONG_INLINE void run(Index size, Index depth,const Scalar* lhs, Index lhsStride, \
-                          const Scalar* rhs, Index rhsStride, Scalar* res, Index resStride, Scalar alpha, level3_blocking<Scalar, Scalar>& blocking) \
+                          const Scalar* rhs, Index rhsStride, Scalar* res, Index resIncr, Index resStride, Scalar alpha, level3_blocking<Scalar, Scalar>& blocking) \
   { \
     if ( lhs==rhs && ((UpLo&(Lower|Upper))==UpLo) ) { \
       general_matrix_matrix_rankupdate<Index,Scalar,LhsStorageOrder,ConjugateLhs,ColMajor,UpLo> \
       ::run(size,depth,lhs,lhsStride,rhs,rhsStride,res,resStride,alpha,blocking); \
     } else { \
       general_matrix_matrix_triangular_product<Index, \
         Scalar, LhsStorageOrder, ConjugateLhs, \
         Scalar, RhsStorageOrder, ConjugateRhs, \
-        ColMajor, UpLo, BuiltIn> \
-      ::run(size,depth,lhs,lhsStride,rhs,rhsStride,res,resStride,alpha,blocking); \
+        ColMajor, 1, UpLo, BuiltIn> \
+      ::run(size,depth,lhs,lhsStride,rhs,rhsStride,res,resIncr,resStride,alpha,blocking); \
     } \
   } \
 };
 
 EIGEN_BLAS_RANKUPDATE_SPECIALIZE(double)
 EIGEN_BLAS_RANKUPDATE_SPECIALIZE(float)
 // TODO handle complex cases
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixMatrix_BLAS.h`

 * *Files 2% similar despite different names*

```diff
@@ -47,28 +47,30 @@
 // gemm specialization
 
 #define GEMM_SPECIALIZATION(EIGTYPE, EIGPREFIX, BLASTYPE, BLASFUNC) \
 template< \
   typename Index, \
   int LhsStorageOrder, bool ConjugateLhs, \
   int RhsStorageOrder, bool ConjugateRhs> \
-struct general_matrix_matrix_product<Index,EIGTYPE,LhsStorageOrder,ConjugateLhs,EIGTYPE,RhsStorageOrder,ConjugateRhs,ColMajor> \
+struct general_matrix_matrix_product<Index,EIGTYPE,LhsStorageOrder,ConjugateLhs,EIGTYPE,RhsStorageOrder,ConjugateRhs,ColMajor,1> \
 { \
 typedef gebp_traits<EIGTYPE,EIGTYPE> Traits; \
 \
 static void run(Index rows, Index cols, Index depth, \
   const EIGTYPE* _lhs, Index lhsStride, \
   const EIGTYPE* _rhs, Index rhsStride, \
-  EIGTYPE* res, Index resStride, \
+  EIGTYPE* res, Index resIncr, Index resStride, \
   EIGTYPE alpha, \
   level3_blocking<EIGTYPE, EIGTYPE>& /*blocking*/, \
   GemmParallelInfo<Index>* /*info = 0*/) \
 { \
   using std::conj; \
 \
+  EIGEN_ONLY_USED_FOR_DEBUG(resIncr); \
+  eigen_assert(resIncr == 1); \
   char transa, transb; \
   BlasIndex m, n, k, lda, ldb, ldc; \
   const EIGTYPE *a, *b; \
   EIGTYPE beta(1); \
   MatrixX##EIGPREFIX a_tmp, b_tmp; \
 \
 /* Set transpose options */ \
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixVector.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixVector.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/GeneralMatrixVector_BLAS.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/GeneralMatrixVector_BLAS.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/Parallelizer.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/Parallelizer.h`

 * *Files 1% similar despite different names*

```diff
@@ -18,15 +18,15 @@
 
 namespace internal {
 
 /** \internal */
 inline void manage_multi_threading(Action action, int* v)
 {
   static int m_maxThreads = -1;
-  EIGEN_UNUSED_VARIABLE(m_maxThreads);
+  EIGEN_UNUSED_VARIABLE(m_maxThreads)
 
   if(action==SetAction)
   {
     eigen_internal_assert(v!=0);
     m_maxThreads = *v;
   }
   else if(action==GetAction)
@@ -125,15 +125,15 @@
   Index size = transpose ? rows : cols;
   Index pb_max_threads = std::max<Index>(1,size / Functor::Traits::nr);
 
   // compute the maximal number of threads from the total amount of work:
   double work = static_cast<double>(rows) * static_cast<double>(cols) *
       static_cast<double>(depth);
   double kMinTaskSize = 50000;  // FIXME improve this heuristic.
-  pb_max_threads = std::max<Index>(1, std::min<Index>(pb_max_threads, work / kMinTaskSize));
+  pb_max_threads = std::max<Index>(1, std::min<Index>(pb_max_threads, static_cast<Index>( work / kMinTaskSize ) ));
 
   // compute the number of threads we are going to use
   Index threads = std::min<Index>(nbThreads(), pb_max_threads);
 
   // if multi-threading is explicitly disabled, not useful, or if we already are in a parallel session,
   // then abort multi-threading
   // FIXME omp_get_num_threads()>1 only works for openmp, what if the user does not use openmp?
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix.h`

 * *Files 3% similar despite different names*

```diff
@@ -290,76 +290,79 @@
 
 /* Optimized selfadjoint matrix * matrix (_SYMM) product built on top of
  * the general matrix matrix product.
  */
 template <typename Scalar, typename Index,
           int LhsStorageOrder, bool LhsSelfAdjoint, bool ConjugateLhs,
           int RhsStorageOrder, bool RhsSelfAdjoint, bool ConjugateRhs,
-          int ResStorageOrder>
+          int ResStorageOrder, int ResInnerStride>
 struct product_selfadjoint_matrix;
 
 template <typename Scalar, typename Index,
           int LhsStorageOrder, bool LhsSelfAdjoint, bool ConjugateLhs,
-          int RhsStorageOrder, bool RhsSelfAdjoint, bool ConjugateRhs>
-struct product_selfadjoint_matrix<Scalar,Index,LhsStorageOrder,LhsSelfAdjoint,ConjugateLhs, RhsStorageOrder,RhsSelfAdjoint,ConjugateRhs,RowMajor>
+          int RhsStorageOrder, bool RhsSelfAdjoint, bool ConjugateRhs,
+          int ResInnerStride>
+struct product_selfadjoint_matrix<Scalar,Index,LhsStorageOrder,LhsSelfAdjoint,ConjugateLhs, RhsStorageOrder,RhsSelfAdjoint,ConjugateRhs,RowMajor,ResInnerStride>
 {
 
   static EIGEN_STRONG_INLINE void run(
     Index rows, Index cols,
     const Scalar* lhs, Index lhsStride,
     const Scalar* rhs, Index rhsStride,
-    Scalar* res,       Index resStride,
+    Scalar* res,       Index resIncr, Index resStride,
     const Scalar& alpha, level3_blocking<Scalar,Scalar>& blocking)
   {
     product_selfadjoint_matrix<Scalar, Index,
       EIGEN_LOGICAL_XOR(RhsSelfAdjoint,RhsStorageOrder==RowMajor) ? ColMajor : RowMajor,
       RhsSelfAdjoint, NumTraits<Scalar>::IsComplex && EIGEN_LOGICAL_XOR(RhsSelfAdjoint,ConjugateRhs),
       EIGEN_LOGICAL_XOR(LhsSelfAdjoint,LhsStorageOrder==RowMajor) ? ColMajor : RowMajor,
       LhsSelfAdjoint, NumTraits<Scalar>::IsComplex && EIGEN_LOGICAL_XOR(LhsSelfAdjoint,ConjugateLhs),
-      ColMajor>
-      ::run(cols, rows,  rhs, rhsStride,  lhs, lhsStride,  res, resStride,  alpha, blocking);
+      ColMajor,ResInnerStride>
+      ::run(cols, rows,  rhs, rhsStride,  lhs, lhsStride,  res, resIncr, resStride,  alpha, blocking);
   }
 };
 
 template <typename Scalar, typename Index,
           int LhsStorageOrder, bool ConjugateLhs,
-          int RhsStorageOrder, bool ConjugateRhs>
-struct product_selfadjoint_matrix<Scalar,Index,LhsStorageOrder,true,ConjugateLhs, RhsStorageOrder,false,ConjugateRhs,ColMajor>
+          int RhsStorageOrder, bool ConjugateRhs,
+          int ResInnerStride>
+struct product_selfadjoint_matrix<Scalar,Index,LhsStorageOrder,true,ConjugateLhs, RhsStorageOrder,false,ConjugateRhs,ColMajor,ResInnerStride>
 {
 
   static EIGEN_DONT_INLINE void run(
     Index rows, Index cols,
     const Scalar* _lhs, Index lhsStride,
     const Scalar* _rhs, Index rhsStride,
-    Scalar* res,        Index resStride,
+    Scalar* res,        Index resIncr, Index resStride,
     const Scalar& alpha, level3_blocking<Scalar,Scalar>& blocking);
 };
 
 template <typename Scalar, typename Index,
           int LhsStorageOrder, bool ConjugateLhs,
-          int RhsStorageOrder, bool ConjugateRhs>
-EIGEN_DONT_INLINE void product_selfadjoint_matrix<Scalar,Index,LhsStorageOrder,true,ConjugateLhs, RhsStorageOrder,false,ConjugateRhs,ColMajor>::run(
+          int RhsStorageOrder, bool ConjugateRhs,
+          int ResInnerStride>
+EIGEN_DONT_INLINE void product_selfadjoint_matrix<Scalar,Index,LhsStorageOrder,true,ConjugateLhs, RhsStorageOrder,false,ConjugateRhs,ColMajor,ResInnerStride>::run(
     Index rows, Index cols,
     const Scalar* _lhs, Index lhsStride,
     const Scalar* _rhs, Index rhsStride,
-    Scalar* _res,        Index resStride,
+    Scalar* _res,       Index resIncr, Index resStride,
     const Scalar& alpha, level3_blocking<Scalar,Scalar>& blocking)
   {
     Index size = rows;
 
     typedef gebp_traits<Scalar,Scalar> Traits;
 
     typedef const_blas_data_mapper<Scalar, Index, LhsStorageOrder> LhsMapper;
     typedef const_blas_data_mapper<Scalar, Index, (LhsStorageOrder == RowMajor) ? ColMajor : RowMajor> LhsTransposeMapper;
     typedef const_blas_data_mapper<Scalar, Index, RhsStorageOrder> RhsMapper;
-    typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor> ResMapper;
+    typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
     LhsMapper lhs(_lhs,lhsStride);
     LhsTransposeMapper lhs_transpose(_lhs,lhsStride);
     RhsMapper rhs(_rhs,rhsStride);
-    ResMapper res(_res, resStride);
+    ResMapper res(_res, resStride, resIncr);
 
     Index kc = blocking.kc();                   // cache block size along the K direction
     Index mc = (std::min)(rows,blocking.mc());  // cache block size along the M direction
     // kc must be smaller than mc
     kc = (std::min)(kc,mc);
     std::size_t sizeA = kc*mc;
     std::size_t sizeB = kc*cols;
@@ -411,44 +414,46 @@
       }
     }
   }
 
 // matrix * selfadjoint product
 template <typename Scalar, typename Index,
           int LhsStorageOrder, bool ConjugateLhs,
-          int RhsStorageOrder, bool ConjugateRhs>
-struct product_selfadjoint_matrix<Scalar,Index,LhsStorageOrder,false,ConjugateLhs, RhsStorageOrder,true,ConjugateRhs,ColMajor>
+          int RhsStorageOrder, bool ConjugateRhs,
+          int ResInnerStride>
+struct product_selfadjoint_matrix<Scalar,Index,LhsStorageOrder,false,ConjugateLhs, RhsStorageOrder,true,ConjugateRhs,ColMajor,ResInnerStride>
 {
 
   static EIGEN_DONT_INLINE void run(
     Index rows, Index cols,
     const Scalar* _lhs, Index lhsStride,
     const Scalar* _rhs, Index rhsStride,
-    Scalar* res,        Index resStride,
+    Scalar* res,        Index resIncr, Index resStride,
     const Scalar& alpha, level3_blocking<Scalar,Scalar>& blocking);
 };
 
 template <typename Scalar, typename Index,
           int LhsStorageOrder, bool ConjugateLhs,
-          int RhsStorageOrder, bool ConjugateRhs>
-EIGEN_DONT_INLINE void product_selfadjoint_matrix<Scalar,Index,LhsStorageOrder,false,ConjugateLhs, RhsStorageOrder,true,ConjugateRhs,ColMajor>::run(
+          int RhsStorageOrder, bool ConjugateRhs,
+          int ResInnerStride>
+EIGEN_DONT_INLINE void product_selfadjoint_matrix<Scalar,Index,LhsStorageOrder,false,ConjugateLhs, RhsStorageOrder,true,ConjugateRhs,ColMajor,ResInnerStride>::run(
     Index rows, Index cols,
     const Scalar* _lhs, Index lhsStride,
     const Scalar* _rhs, Index rhsStride,
-    Scalar* _res,        Index resStride,
+    Scalar* _res,       Index resIncr, Index resStride,
     const Scalar& alpha, level3_blocking<Scalar,Scalar>& blocking)
   {
     Index size = cols;
 
     typedef gebp_traits<Scalar,Scalar> Traits;
 
     typedef const_blas_data_mapper<Scalar, Index, LhsStorageOrder> LhsMapper;
-    typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor> ResMapper;
+    typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
     LhsMapper lhs(_lhs,lhsStride);
-    ResMapper res(_res,resStride);
+    ResMapper res(_res,resStride, resIncr);
 
     Index kc = blocking.kc();                   // cache block size along the K direction
     Index mc = (std::min)(rows,blocking.mc());  // cache block size along the M direction
     std::size_t sizeA = kc*mc;
     std::size_t sizeB = kc*cols;
     ei_declare_aligned_stack_constructed_variable(Scalar, blockA, sizeA, blocking.blockA());
     ei_declare_aligned_stack_constructed_variable(Scalar, blockB, sizeB, blocking.blockB());
@@ -516,20 +521,21 @@
     BlockingType blocking(lhs.rows(), rhs.cols(), lhs.cols(), 1, false);
 
     internal::product_selfadjoint_matrix<Scalar, Index,
       EIGEN_LOGICAL_XOR(LhsIsUpper,internal::traits<Lhs>::Flags &RowMajorBit) ? RowMajor : ColMajor, LhsIsSelfAdjoint,
       NumTraits<Scalar>::IsComplex && EIGEN_LOGICAL_XOR(LhsIsUpper,bool(LhsBlasTraits::NeedToConjugate)),
       EIGEN_LOGICAL_XOR(RhsIsUpper,internal::traits<Rhs>::Flags &RowMajorBit) ? RowMajor : ColMajor, RhsIsSelfAdjoint,
       NumTraits<Scalar>::IsComplex && EIGEN_LOGICAL_XOR(RhsIsUpper,bool(RhsBlasTraits::NeedToConjugate)),
-      internal::traits<Dest>::Flags&RowMajorBit  ? RowMajor : ColMajor>
+      internal::traits<Dest>::Flags&RowMajorBit  ? RowMajor : ColMajor,
+      Dest::InnerStrideAtCompileTime>
       ::run(
         lhs.rows(), rhs.cols(),                 // sizes
         &lhs.coeffRef(0,0), lhs.outerStride(),  // lhs info
         &rhs.coeffRef(0,0), rhs.outerStride(),  // rhs info
-        &dst.coeffRef(0,0), dst.outerStride(),  // result info
+        &dst.coeffRef(0,0), dst.innerStride(), dst.outerStride(),  // result info
         actualAlpha, blocking                   // alpha
       );
   }
 };
 
 } // end namespace internal
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix_BLAS.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixMatrix_BLAS.h`

 * *Files 6% similar despite different names*

```diff
@@ -40,24 +40,26 @@
 
 /* Optimized selfadjoint matrix * matrix (?SYMM/?HEMM) product */
 
 #define EIGEN_BLAS_SYMM_L(EIGTYPE, BLASTYPE, EIGPREFIX, BLASFUNC) \
 template <typename Index, \
           int LhsStorageOrder, bool ConjugateLhs, \
           int RhsStorageOrder, bool ConjugateRhs> \
-struct product_selfadjoint_matrix<EIGTYPE,Index,LhsStorageOrder,true,ConjugateLhs,RhsStorageOrder,false,ConjugateRhs,ColMajor> \
+struct product_selfadjoint_matrix<EIGTYPE,Index,LhsStorageOrder,true,ConjugateLhs,RhsStorageOrder,false,ConjugateRhs,ColMajor,1> \
 {\
 \
   static void run( \
     Index rows, Index cols, \
     const EIGTYPE* _lhs, Index lhsStride, \
     const EIGTYPE* _rhs, Index rhsStride, \
-    EIGTYPE* res,        Index resStride, \
+    EIGTYPE* res,        Index resIncr, Index resStride, \
     EIGTYPE alpha, level3_blocking<EIGTYPE, EIGTYPE>& /*blocking*/) \
   { \
+    EIGEN_ONLY_USED_FOR_DEBUG(resIncr); \
+    eigen_assert(resIncr == 1); \
     char side='L', uplo='L'; \
     BlasIndex m, n, lda, ldb, ldc; \
     const EIGTYPE *a, *b; \
     EIGTYPE beta(1); \
     MatrixX##EIGPREFIX b_tmp; \
 \
 /* Set transpose options */ \
@@ -87,23 +89,25 @@
 };
 
 
 #define EIGEN_BLAS_HEMM_L(EIGTYPE, BLASTYPE, EIGPREFIX, BLASFUNC) \
 template <typename Index, \
           int LhsStorageOrder, bool ConjugateLhs, \
           int RhsStorageOrder, bool ConjugateRhs> \
-struct product_selfadjoint_matrix<EIGTYPE,Index,LhsStorageOrder,true,ConjugateLhs,RhsStorageOrder,false,ConjugateRhs,ColMajor> \
+struct product_selfadjoint_matrix<EIGTYPE,Index,LhsStorageOrder,true,ConjugateLhs,RhsStorageOrder,false,ConjugateRhs,ColMajor,1> \
 {\
   static void run( \
     Index rows, Index cols, \
     const EIGTYPE* _lhs, Index lhsStride, \
     const EIGTYPE* _rhs, Index rhsStride, \
-    EIGTYPE* res,        Index resStride, \
+    EIGTYPE* res,        Index resIncr, Index resStride, \
     EIGTYPE alpha, level3_blocking<EIGTYPE, EIGTYPE>& /*blocking*/) \
   { \
+    EIGEN_ONLY_USED_FOR_DEBUG(resIncr); \
+    eigen_assert(resIncr == 1); \
     char side='L', uplo='L'; \
     BlasIndex m, n, lda, ldb, ldc; \
     const EIGTYPE *a, *b; \
     EIGTYPE beta(1); \
     MatrixX##EIGPREFIX b_tmp; \
     Matrix<EIGTYPE, Dynamic, Dynamic, LhsStorageOrder> a_tmp; \
 \
@@ -163,24 +167,26 @@
 
 /* Optimized matrix * selfadjoint matrix (?SYMM/?HEMM) product */
 
 #define EIGEN_BLAS_SYMM_R(EIGTYPE, BLASTYPE, EIGPREFIX, BLASFUNC) \
 template <typename Index, \
           int LhsStorageOrder, bool ConjugateLhs, \
           int RhsStorageOrder, bool ConjugateRhs> \
-struct product_selfadjoint_matrix<EIGTYPE,Index,LhsStorageOrder,false,ConjugateLhs,RhsStorageOrder,true,ConjugateRhs,ColMajor> \
+struct product_selfadjoint_matrix<EIGTYPE,Index,LhsStorageOrder,false,ConjugateLhs,RhsStorageOrder,true,ConjugateRhs,ColMajor,1> \
 {\
 \
   static void run( \
     Index rows, Index cols, \
     const EIGTYPE* _lhs, Index lhsStride, \
     const EIGTYPE* _rhs, Index rhsStride, \
-    EIGTYPE* res,        Index resStride, \
+    EIGTYPE* res,        Index resIncr, Index resStride, \
     EIGTYPE alpha, level3_blocking<EIGTYPE, EIGTYPE>& /*blocking*/) \
   { \
+    EIGEN_ONLY_USED_FOR_DEBUG(resIncr); \
+    eigen_assert(resIncr == 1); \
     char side='R', uplo='L'; \
     BlasIndex m, n, lda, ldb, ldc; \
     const EIGTYPE *a, *b; \
     EIGTYPE beta(1); \
     MatrixX##EIGPREFIX b_tmp; \
 \
 /* Set m, n, k */ \
@@ -209,23 +215,25 @@
 };
 
 
 #define EIGEN_BLAS_HEMM_R(EIGTYPE, BLASTYPE, EIGPREFIX, BLASFUNC) \
 template <typename Index, \
           int LhsStorageOrder, bool ConjugateLhs, \
           int RhsStorageOrder, bool ConjugateRhs> \
-struct product_selfadjoint_matrix<EIGTYPE,Index,LhsStorageOrder,false,ConjugateLhs,RhsStorageOrder,true,ConjugateRhs,ColMajor> \
+struct product_selfadjoint_matrix<EIGTYPE,Index,LhsStorageOrder,false,ConjugateLhs,RhsStorageOrder,true,ConjugateRhs,ColMajor,1> \
 {\
   static void run( \
     Index rows, Index cols, \
     const EIGTYPE* _lhs, Index lhsStride, \
     const EIGTYPE* _rhs, Index rhsStride, \
-    EIGTYPE* res,        Index resStride, \
+    EIGTYPE* res,        Index resIncr, Index resStride, \
     EIGTYPE alpha, level3_blocking<EIGTYPE, EIGTYPE>& /*blocking*/) \
   { \
+    EIGEN_ONLY_USED_FOR_DEBUG(resIncr); \
+    eigen_assert(resIncr == 1); \
     char side='R', uplo='L'; \
     BlasIndex m, n, lda, ldb, ldc; \
     const EIGTYPE *a, *b; \
     EIGTYPE beta(1); \
     MatrixX##EIGPREFIX b_tmp; \
     Matrix<EIGTYPE, Dynamic, Dynamic, RhsStorageOrder> a_tmp; \
 \
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixVector.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixVector.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixVector_BLAS.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointMatrixVector_BLAS.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointProduct.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointProduct.h`

 * *Files 2% similar despite different names*

```diff
@@ -105,18 +105,18 @@
 
     BlockingType blocking(size, size, depth, 1, false);
 
 
     internal::general_matrix_matrix_triangular_product<Index,
       Scalar, OtherIsRowMajor ? RowMajor : ColMajor,   OtherBlasTraits::NeedToConjugate  && NumTraits<Scalar>::IsComplex,
       Scalar, OtherIsRowMajor ? ColMajor : RowMajor, (!OtherBlasTraits::NeedToConjugate) && NumTraits<Scalar>::IsComplex,
-      IsRowMajor ? RowMajor : ColMajor, UpLo>
+      IsRowMajor ? RowMajor : ColMajor, MatrixType::InnerStrideAtCompileTime, UpLo>
       ::run(size, depth,
-            &actualOther.coeffRef(0,0), actualOther.outerStride(), &actualOther.coeffRef(0,0), actualOther.outerStride(),
-            mat.data(), mat.outerStride(), actualAlpha, blocking);
+            actualOther.data(), actualOther.outerStride(), actualOther.data(), actualOther.outerStride(),
+            mat.data(), mat.innerStride(), mat.outerStride(), actualAlpha, blocking);
   }
 };
 
 // high level API
 
 template<typename MatrixType, unsigned int UpLo>
 template<typename DerivedU>
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/SelfadjointRank2Update.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/SelfadjointRank2Update.h`

 * *Files 3% similar despite different names*

```diff
@@ -76,16 +76,16 @@
 
   enum { IsRowMajor = (internal::traits<MatrixType>::Flags&RowMajorBit) ? 1 : 0 };
   Scalar actualAlpha = alpha * UBlasTraits::extractScalarFactor(u.derived())
                              * numext::conj(VBlasTraits::extractScalarFactor(v.derived()));
   if (IsRowMajor)
     actualAlpha = numext::conj(actualAlpha);
 
-  typedef typename internal::remove_all<typename internal::conj_expr_if<IsRowMajor ^ UBlasTraits::NeedToConjugate,_ActualUType>::type>::type UType;
-  typedef typename internal::remove_all<typename internal::conj_expr_if<IsRowMajor ^ VBlasTraits::NeedToConjugate,_ActualVType>::type>::type VType;
+  typedef typename internal::remove_all<typename internal::conj_expr_if<int(IsRowMajor) ^ int(UBlasTraits::NeedToConjugate), _ActualUType>::type>::type UType;
+  typedef typename internal::remove_all<typename internal::conj_expr_if<int(IsRowMajor) ^ int(VBlasTraits::NeedToConjugate), _ActualVType>::type>::type VType;
   internal::selfadjoint_rank2_update_selector<Scalar, Index, UType, VType,
     (IsRowMajor ? int(UpLo==Upper ? Lower : Upper) : UpLo)>
     ::run(_expression().const_cast_derived().data(),_expression().outerStride(),UType(actualU),VType(actualV),actualAlpha);
 
   return *this;
 }
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularMatrixMatrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularMatrixMatrix.h`

 * *Files 6% similar despite different names*

```diff
@@ -41,92 +41,96 @@
 /* Optimized triangular matrix * matrix (_TRMM++) product built on top of
  * the general matrix matrix product.
  */
 template <typename Scalar, typename Index,
           int Mode, bool LhsIsTriangular,
           int LhsStorageOrder, bool ConjugateLhs,
           int RhsStorageOrder, bool ConjugateRhs,
-          int ResStorageOrder, int Version = Specialized>
+          int ResStorageOrder, int ResInnerStride,
+          int Version = Specialized>
 struct product_triangular_matrix_matrix;
 
 template <typename Scalar, typename Index,
           int Mode, bool LhsIsTriangular,
           int LhsStorageOrder, bool ConjugateLhs,
-          int RhsStorageOrder, bool ConjugateRhs, int Version>
+          int RhsStorageOrder, bool ConjugateRhs,
+          int ResInnerStride, int Version>
 struct product_triangular_matrix_matrix<Scalar,Index,Mode,LhsIsTriangular,
                                            LhsStorageOrder,ConjugateLhs,
-                                           RhsStorageOrder,ConjugateRhs,RowMajor,Version>
+                                           RhsStorageOrder,ConjugateRhs,RowMajor,ResInnerStride,Version>
 {
   static EIGEN_STRONG_INLINE void run(
     Index rows, Index cols, Index depth,
     const Scalar* lhs, Index lhsStride,
     const Scalar* rhs, Index rhsStride,
-    Scalar* res,       Index resStride,
+    Scalar* res,       Index resIncr, Index resStride,
     const Scalar& alpha, level3_blocking<Scalar,Scalar>& blocking)
   {
     product_triangular_matrix_matrix<Scalar, Index,
       (Mode&(UnitDiag|ZeroDiag)) | ((Mode&Upper) ? Lower : Upper),
       (!LhsIsTriangular),
       RhsStorageOrder==RowMajor ? ColMajor : RowMajor,
       ConjugateRhs,
       LhsStorageOrder==RowMajor ? ColMajor : RowMajor,
       ConjugateLhs,
-      ColMajor>
-      ::run(cols, rows, depth, rhs, rhsStride, lhs, lhsStride, res, resStride, alpha, blocking);
+      ColMajor, ResInnerStride>
+      ::run(cols, rows, depth, rhs, rhsStride, lhs, lhsStride, res, resIncr, resStride, alpha, blocking);
   }
 };
 
 // implements col-major += alpha * op(triangular) * op(general)
 template <typename Scalar, typename Index, int Mode,
           int LhsStorageOrder, bool ConjugateLhs,
-          int RhsStorageOrder, bool ConjugateRhs, int Version>
+          int RhsStorageOrder, bool ConjugateRhs,
+          int ResInnerStride, int Version>
 struct product_triangular_matrix_matrix<Scalar,Index,Mode,true,
                                            LhsStorageOrder,ConjugateLhs,
-                                           RhsStorageOrder,ConjugateRhs,ColMajor,Version>
+                                           RhsStorageOrder,ConjugateRhs,ColMajor,ResInnerStride,Version>
 {
   
   typedef gebp_traits<Scalar,Scalar> Traits;
   enum {
     SmallPanelWidth   = 2 * EIGEN_PLAIN_ENUM_MAX(Traits::mr,Traits::nr),
     IsLower = (Mode&Lower) == Lower,
     SetDiag = (Mode&(ZeroDiag|UnitDiag)) ? 0 : 1
   };
 
   static EIGEN_DONT_INLINE void run(
     Index _rows, Index _cols, Index _depth,
     const Scalar* _lhs, Index lhsStride,
     const Scalar* _rhs, Index rhsStride,
-    Scalar* res,        Index resStride,
+    Scalar* res,        Index resIncr, Index resStride,
     const Scalar& alpha, level3_blocking<Scalar,Scalar>& blocking);
 };
 
 template <typename Scalar, typename Index, int Mode,
           int LhsStorageOrder, bool ConjugateLhs,
-          int RhsStorageOrder, bool ConjugateRhs, int Version>
+          int RhsStorageOrder, bool ConjugateRhs,
+          int ResInnerStride, int Version>
 EIGEN_DONT_INLINE void product_triangular_matrix_matrix<Scalar,Index,Mode,true,
                                                         LhsStorageOrder,ConjugateLhs,
-                                                        RhsStorageOrder,ConjugateRhs,ColMajor,Version>::run(
+                                                        RhsStorageOrder,ConjugateRhs,ColMajor,ResInnerStride,Version>::run(
     Index _rows, Index _cols, Index _depth,
     const Scalar* _lhs, Index lhsStride,
     const Scalar* _rhs, Index rhsStride,
-    Scalar* _res,        Index resStride,
+    Scalar* _res,       Index resIncr, Index resStride,
     const Scalar& alpha, level3_blocking<Scalar,Scalar>& blocking)
   {
     // strip zeros
     Index diagSize  = (std::min)(_rows,_depth);
     Index rows      = IsLower ? _rows : diagSize;
     Index depth     = IsLower ? diagSize : _depth;
     Index cols      = _cols;
     
     typedef const_blas_data_mapper<Scalar, Index, LhsStorageOrder> LhsMapper;
     typedef const_blas_data_mapper<Scalar, Index, RhsStorageOrder> RhsMapper;
-    typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor> ResMapper;
+    typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
     LhsMapper lhs(_lhs,lhsStride);
     RhsMapper rhs(_rhs,rhsStride);
-    ResMapper res(_res, resStride);
+    ResMapper res(_res, resStride, resIncr);
 
     Index kc = blocking.kc();                   // cache block size along the K direction
     Index mc = (std::min)(rows,blocking.mc());  // cache block size along the M direction
     // The small panel size must not be larger than blocking size.
     // Usually this should never be the case because SmallPanelWidth^2 is very small
     // compared to L2 cache size, but let's be safe:
     Index panelWidth = (std::min)(Index(SmallPanelWidth),(std::min)(kc,mc));
@@ -231,59 +235,61 @@
       }
     }
   }
 
 // implements col-major += alpha * op(general) * op(triangular)
 template <typename Scalar, typename Index, int Mode,
           int LhsStorageOrder, bool ConjugateLhs,
-          int RhsStorageOrder, bool ConjugateRhs, int Version>
+          int RhsStorageOrder, bool ConjugateRhs,
+          int ResInnerStride, int Version>
 struct product_triangular_matrix_matrix<Scalar,Index,Mode,false,
                                         LhsStorageOrder,ConjugateLhs,
-                                        RhsStorageOrder,ConjugateRhs,ColMajor,Version>
+                                        RhsStorageOrder,ConjugateRhs,ColMajor,ResInnerStride,Version>
 {
   typedef gebp_traits<Scalar,Scalar> Traits;
   enum {
     SmallPanelWidth   = EIGEN_PLAIN_ENUM_MAX(Traits::mr,Traits::nr),
     IsLower = (Mode&Lower) == Lower,
     SetDiag = (Mode&(ZeroDiag|UnitDiag)) ? 0 : 1
   };
 
   static EIGEN_DONT_INLINE void run(
     Index _rows, Index _cols, Index _depth,
     const Scalar* _lhs, Index lhsStride,
     const Scalar* _rhs, Index rhsStride,
-    Scalar* res,        Index resStride,
+    Scalar* res,        Index resIncr, Index resStride,
     const Scalar& alpha, level3_blocking<Scalar,Scalar>& blocking);
 };
 
 template <typename Scalar, typename Index, int Mode,
           int LhsStorageOrder, bool ConjugateLhs,
-          int RhsStorageOrder, bool ConjugateRhs, int Version>
+          int RhsStorageOrder, bool ConjugateRhs,
+          int ResInnerStride, int Version>
 EIGEN_DONT_INLINE void product_triangular_matrix_matrix<Scalar,Index,Mode,false,
                                                         LhsStorageOrder,ConjugateLhs,
-                                                        RhsStorageOrder,ConjugateRhs,ColMajor,Version>::run(
+                                                        RhsStorageOrder,ConjugateRhs,ColMajor,ResInnerStride,Version>::run(
     Index _rows, Index _cols, Index _depth,
     const Scalar* _lhs, Index lhsStride,
     const Scalar* _rhs, Index rhsStride,
-    Scalar* _res,        Index resStride,
+    Scalar* _res,       Index resIncr, Index resStride,
     const Scalar& alpha, level3_blocking<Scalar,Scalar>& blocking)
   {
     const Index PacketBytes = packet_traits<Scalar>::size*sizeof(Scalar);
     // strip zeros
     Index diagSize  = (std::min)(_cols,_depth);
     Index rows      = _rows;
     Index depth     = IsLower ? _depth : diagSize;
     Index cols      = IsLower ? diagSize : _cols;
     
     typedef const_blas_data_mapper<Scalar, Index, LhsStorageOrder> LhsMapper;
     typedef const_blas_data_mapper<Scalar, Index, RhsStorageOrder> RhsMapper;
-    typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor> ResMapper;
+    typedef blas_data_mapper<typename Traits::ResScalar, Index, ColMajor, Unaligned, ResInnerStride> ResMapper;
     LhsMapper lhs(_lhs,lhsStride);
     RhsMapper rhs(_rhs,rhsStride);
-    ResMapper res(_res, resStride);
+    ResMapper res(_res, resStride, resIncr);
 
     Index kc = blocking.kc();                   // cache block size along the K direction
     Index mc = (std::min)(rows,blocking.mc());  // cache block size along the M direction
 
     std::size_t sizeA = kc*mc;
     std::size_t sizeB = kc*cols+EIGEN_MAX_ALIGN_BYTES/sizeof(Scalar);
 
@@ -429,20 +435,20 @@
 
     BlockingType blocking(stripedRows, stripedCols, stripedDepth, 1, false);
 
     internal::product_triangular_matrix_matrix<Scalar, Index,
       Mode, LhsIsTriangular,
       (internal::traits<ActualLhsTypeCleaned>::Flags&RowMajorBit) ? RowMajor : ColMajor, LhsBlasTraits::NeedToConjugate,
       (internal::traits<ActualRhsTypeCleaned>::Flags&RowMajorBit) ? RowMajor : ColMajor, RhsBlasTraits::NeedToConjugate,
-      (internal::traits<Dest          >::Flags&RowMajorBit) ? RowMajor : ColMajor>
+      (internal::traits<Dest          >::Flags&RowMajorBit) ? RowMajor : ColMajor, Dest::InnerStrideAtCompileTime>
       ::run(
         stripedRows, stripedCols, stripedDepth,   // sizes
         &lhs.coeffRef(0,0), lhs.outerStride(),    // lhs info
         &rhs.coeffRef(0,0), rhs.outerStride(),    // rhs info
-        &dst.coeffRef(0,0), dst.outerStride(),    // result info
+        &dst.coeffRef(0,0), dst.innerStride(), dst.outerStride(),    // result info
         actualAlpha, blocking
       );
 
     // Apply correction if the diagonal is unit and a scalar factor was nested:
     if ((Mode&UnitDiag)==UnitDiag)
     {
       if (LhsIsTriangular && lhs_alpha!=LhsScalar(1))
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularMatrixMatrix_BLAS.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularMatrixMatrix_BLAS.h`

 * *Files 1% similar despite different names*

```diff
@@ -42,30 +42,32 @@
           int Mode, bool LhsIsTriangular,
           int LhsStorageOrder, bool ConjugateLhs,
           int RhsStorageOrder, bool ConjugateRhs,
           int ResStorageOrder>
 struct product_triangular_matrix_matrix_trmm :
        product_triangular_matrix_matrix<Scalar,Index,Mode,
           LhsIsTriangular,LhsStorageOrder,ConjugateLhs,
-          RhsStorageOrder, ConjugateRhs, ResStorageOrder, BuiltIn> {};
+          RhsStorageOrder, ConjugateRhs, ResStorageOrder, 1, BuiltIn> {};
 
 
 // try to go to BLAS specialization
 #define EIGEN_BLAS_TRMM_SPECIALIZE(Scalar, LhsIsTriangular) \
 template <typename Index, int Mode, \
           int LhsStorageOrder, bool ConjugateLhs, \
           int RhsStorageOrder, bool ConjugateRhs> \
 struct product_triangular_matrix_matrix<Scalar,Index, Mode, LhsIsTriangular, \
-           LhsStorageOrder,ConjugateLhs, RhsStorageOrder,ConjugateRhs,ColMajor,Specialized> { \
+           LhsStorageOrder,ConjugateLhs, RhsStorageOrder,ConjugateRhs,ColMajor,1,Specialized> { \
   static inline void run(Index _rows, Index _cols, Index _depth, const Scalar* _lhs, Index lhsStride,\
-    const Scalar* _rhs, Index rhsStride, Scalar* res, Index resStride, Scalar alpha, level3_blocking<Scalar,Scalar>& blocking) { \
+    const Scalar* _rhs, Index rhsStride, Scalar* res, Index resIncr, Index resStride, Scalar alpha, level3_blocking<Scalar,Scalar>& blocking) { \
+      EIGEN_ONLY_USED_FOR_DEBUG(resIncr); \
+      eigen_assert(resIncr == 1); \
       product_triangular_matrix_matrix_trmm<Scalar,Index,Mode, \
         LhsIsTriangular,LhsStorageOrder,ConjugateLhs, \
         RhsStorageOrder, ConjugateRhs, ColMajor>::run( \
-        _rows, _cols, _depth, _lhs, lhsStride, _rhs, rhsStride, res, resStride, alpha, blocking); \
+          _rows, _cols, _depth, _lhs, lhsStride, _rhs, rhsStride, res, resStride, alpha, blocking); \
   } \
 };
 
 EIGEN_BLAS_TRMM_SPECIALIZE(double, true)
 EIGEN_BLAS_TRMM_SPECIALIZE(double, false)
 EIGEN_BLAS_TRMM_SPECIALIZE(dcomplex, true)
 EIGEN_BLAS_TRMM_SPECIALIZE(dcomplex, false)
@@ -111,25 +113,25 @@
 \
      /* FIXME handle mkl_domain_get_max_threads */ \
      /*int nthr = mkl_domain_get_max_threads(EIGEN_BLAS_DOMAIN_BLAS);*/ int nthr = 1;\
 \
      if (((nthr==1) && (((std::max)(rows,depth)-diagSize)/(double)diagSize < 0.5))) { \
      /* Most likely no benefit to call TRMM or GEMM from BLAS */ \
        product_triangular_matrix_matrix<EIGTYPE,Index,Mode,true, \
-       LhsStorageOrder,ConjugateLhs, RhsStorageOrder, ConjugateRhs, ColMajor, BuiltIn>::run( \
-           _rows, _cols, _depth, _lhs, lhsStride, _rhs, rhsStride, res, resStride, alpha, blocking); \
+       LhsStorageOrder,ConjugateLhs, RhsStorageOrder, ConjugateRhs, ColMajor, 1, BuiltIn>::run( \
+           _rows, _cols, _depth, _lhs, lhsStride, _rhs, rhsStride, res, 1, resStride, alpha, blocking); \
      /*std::cout << "TRMM_L: A is not square! Go to Eigen TRMM implementation!\n";*/ \
      } else { \
      /* Make sense to call GEMM */ \
        Map<const MatrixLhs, 0, OuterStride<> > lhsMap(_lhs,rows,depth,OuterStride<>(lhsStride)); \
        MatrixLhs aa_tmp=lhsMap.template triangularView<Mode>(); \
        BlasIndex aStride = convert_index<BlasIndex>(aa_tmp.outerStride()); \
        gemm_blocking_space<ColMajor,EIGTYPE,EIGTYPE,Dynamic,Dynamic,Dynamic> gemm_blocking(_rows,_cols,_depth, 1, true); \
-       general_matrix_matrix_product<Index,EIGTYPE,LhsStorageOrder,ConjugateLhs,EIGTYPE,RhsStorageOrder,ConjugateRhs,ColMajor>::run( \
-       rows, cols, depth, aa_tmp.data(), aStride, _rhs, rhsStride, res, resStride, alpha, gemm_blocking, 0); \
+       general_matrix_matrix_product<Index,EIGTYPE,LhsStorageOrder,ConjugateLhs,EIGTYPE,RhsStorageOrder,ConjugateRhs,ColMajor,1>::run( \
+       rows, cols, depth, aa_tmp.data(), aStride, _rhs, rhsStride, res, 1, resStride, alpha, gemm_blocking, 0); \
 \
      /*std::cout << "TRMM_L: A is not square! Go to BLAS GEMM implementation! " << nthr<<" \n";*/ \
      } \
      return; \
    } \
    char side = 'L', transa, uplo, diag = 'N'; \
    EIGTYPE *b; \
@@ -228,25 +230,25 @@
    if (cols != depth) { \
 \
      int nthr = 1 /*mkl_domain_get_max_threads(EIGEN_BLAS_DOMAIN_BLAS)*/; \
 \
      if ((nthr==1) && (((std::max)(cols,depth)-diagSize)/(double)diagSize < 0.5)) { \
      /* Most likely no benefit to call TRMM or GEMM from BLAS*/ \
        product_triangular_matrix_matrix<EIGTYPE,Index,Mode,false, \
-       LhsStorageOrder,ConjugateLhs, RhsStorageOrder, ConjugateRhs, ColMajor, BuiltIn>::run( \
-           _rows, _cols, _depth, _lhs, lhsStride, _rhs, rhsStride, res, resStride, alpha, blocking); \
+       LhsStorageOrder,ConjugateLhs, RhsStorageOrder, ConjugateRhs, ColMajor, 1, BuiltIn>::run( \
+           _rows, _cols, _depth, _lhs, lhsStride, _rhs, rhsStride, res, 1, resStride, alpha, blocking); \
        /*std::cout << "TRMM_R: A is not square! Go to Eigen TRMM implementation!\n";*/ \
      } else { \
      /* Make sense to call GEMM */ \
        Map<const MatrixRhs, 0, OuterStride<> > rhsMap(_rhs,depth,cols, OuterStride<>(rhsStride)); \
        MatrixRhs aa_tmp=rhsMap.template triangularView<Mode>(); \
        BlasIndex aStride = convert_index<BlasIndex>(aa_tmp.outerStride()); \
        gemm_blocking_space<ColMajor,EIGTYPE,EIGTYPE,Dynamic,Dynamic,Dynamic> gemm_blocking(_rows,_cols,_depth, 1, true); \
-       general_matrix_matrix_product<Index,EIGTYPE,LhsStorageOrder,ConjugateLhs,EIGTYPE,RhsStorageOrder,ConjugateRhs,ColMajor>::run( \
-       rows, cols, depth, _lhs, lhsStride, aa_tmp.data(), aStride, res, resStride, alpha, gemm_blocking, 0); \
+       general_matrix_matrix_product<Index,EIGTYPE,LhsStorageOrder,ConjugateLhs,EIGTYPE,RhsStorageOrder,ConjugateRhs,ColMajor,1>::run( \
+       rows, cols, depth, _lhs, lhsStride, aa_tmp.data(), aStride, res, 1, resStride, alpha, gemm_blocking, 0); \
 \
      /*std::cout << "TRMM_R: A is not square! Go to BLAS GEMM implementation! " << nthr<<" \n";*/ \
      } \
      return; \
    } \
    char side = 'R', transa, uplo, diag = 'N'; \
    EIGTYPE *b; \
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularMatrixVector.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularMatrixVector.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularMatrixVector_BLAS.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularMatrixVector_BLAS.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularSolverMatrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularSolverMatrix.h`

 * *Files 9% similar despite different names*

```diff
@@ -11,56 +11,56 @@
 #define EIGEN_TRIANGULAR_SOLVER_MATRIX_H
 
 namespace Eigen { 
 
 namespace internal {
 
 // if the rhs is row major, let's transpose the product
-template <typename Scalar, typename Index, int Side, int Mode, bool Conjugate, int TriStorageOrder>
-struct triangular_solve_matrix<Scalar,Index,Side,Mode,Conjugate,TriStorageOrder,RowMajor>
+template <typename Scalar, typename Index, int Side, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
+struct triangular_solve_matrix<Scalar,Index,Side,Mode,Conjugate,TriStorageOrder,RowMajor,OtherInnerStride>
 {
   static void run(
     Index size, Index cols,
     const Scalar*  tri, Index triStride,
-    Scalar* _other, Index otherStride,
+    Scalar* _other, Index otherIncr, Index otherStride,
     level3_blocking<Scalar,Scalar>& blocking)
   {
     triangular_solve_matrix<
       Scalar, Index, Side==OnTheLeft?OnTheRight:OnTheLeft,
       (Mode&UnitDiag) | ((Mode&Upper) ? Lower : Upper),
       NumTraits<Scalar>::IsComplex && Conjugate,
-      TriStorageOrder==RowMajor ? ColMajor : RowMajor, ColMajor>
-      ::run(size, cols, tri, triStride, _other, otherStride, blocking);
+      TriStorageOrder==RowMajor ? ColMajor : RowMajor, ColMajor, OtherInnerStride>
+      ::run(size, cols, tri, triStride, _other, otherIncr, otherStride, blocking);
   }
 };
 
 /* Optimized triangular solver with multiple right hand side and the triangular matrix on the left
  */
-template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder>
-struct triangular_solve_matrix<Scalar,Index,OnTheLeft,Mode,Conjugate,TriStorageOrder,ColMajor>
+template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder,int OtherInnerStride>
+struct triangular_solve_matrix<Scalar,Index,OnTheLeft,Mode,Conjugate,TriStorageOrder,ColMajor,OtherInnerStride>
 {
   static EIGEN_DONT_INLINE void run(
     Index size, Index otherSize,
     const Scalar* _tri, Index triStride,
-    Scalar* _other, Index otherStride,
+    Scalar* _other, Index otherIncr, Index otherStride,
     level3_blocking<Scalar,Scalar>& blocking);
 };
-template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder>
-EIGEN_DONT_INLINE void triangular_solve_matrix<Scalar,Index,OnTheLeft,Mode,Conjugate,TriStorageOrder,ColMajor>::run(
+template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
+EIGEN_DONT_INLINE void triangular_solve_matrix<Scalar,Index,OnTheLeft,Mode,Conjugate,TriStorageOrder,ColMajor,OtherInnerStride>::run(
     Index size, Index otherSize,
     const Scalar* _tri, Index triStride,
-    Scalar* _other, Index otherStride,
+    Scalar* _other, Index otherIncr, Index otherStride,
     level3_blocking<Scalar,Scalar>& blocking)
   {
     Index cols = otherSize;
 
     typedef const_blas_data_mapper<Scalar, Index, TriStorageOrder> TriMapper;
-    typedef blas_data_mapper<Scalar, Index, ColMajor> OtherMapper;
+    typedef blas_data_mapper<Scalar, Index, ColMajor, Unaligned, OtherInnerStride> OtherMapper;
     TriMapper tri(_tri, triStride);
-    OtherMapper other(_other, otherStride);
+    OtherMapper other(_other, otherStride, otherIncr);
 
     typedef gebp_traits<Scalar,Scalar> Traits;
 
     enum {
       SmallPanelWidth   = EIGEN_PLAIN_ENUM_MAX(Traits::mr,Traits::nr),
       IsLower = (Mode&Lower) == Lower
     };
@@ -124,27 +124,29 @@
             Scalar a = (Mode & UnitDiag) ? Scalar(1) : Scalar(1)/conj(tri(i,i));
             for (Index j=j2; j<j2+actual_cols; ++j)
             {
               if (TriStorageOrder==RowMajor)
               {
                 Scalar b(0);
                 const Scalar* l = &tri(i,s);
-                Scalar* r = &other(s,j);
+                typename OtherMapper::LinearMapper r = other.getLinearMapper(s,j);
                 for (Index i3=0; i3<k; ++i3)
-                  b += conj(l[i3]) * r[i3];
+                  b += conj(l[i3]) * r(i3);
 
                 other(i,j) = (other(i,j) - b)*a;
               }
               else
               {
-                Scalar b = (other(i,j) *= a);
-                Scalar* r = &other(s,j);
-                const Scalar* l = &tri(s,i);
+                Scalar& otherij = other(i,j);
+                otherij *= a;
+                Scalar b = otherij;
+                typename OtherMapper::LinearMapper r = other.getLinearMapper(s,j);
+                typename TriMapper::LinearMapper l = tri.getLinearMapper(s,i);
                 for (Index i3=0;i3<rs;++i3)
-                  r[i3] -= b * conj(l[i3]);
+                  r(i3) -= b * conj(l(i3));
               }
             }
           }
 
           Index lengthTarget = actual_kc-k1-actualPanelWidth;
           Index startBlock   = IsLower ? k2+k1 : k2-k1-actualPanelWidth;
           Index blockBOffset = IsLower ? k1 : lengthTarget;
@@ -181,36 +183,36 @@
         }
       }
     }
   }
 
 /* Optimized triangular solver with multiple left hand sides and the triangular matrix on the right
  */
-template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder>
-struct triangular_solve_matrix<Scalar,Index,OnTheRight,Mode,Conjugate,TriStorageOrder,ColMajor>
+template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
+struct triangular_solve_matrix<Scalar,Index,OnTheRight,Mode,Conjugate,TriStorageOrder,ColMajor,OtherInnerStride>
 {
   static EIGEN_DONT_INLINE void run(
     Index size, Index otherSize,
     const Scalar* _tri, Index triStride,
-    Scalar* _other, Index otherStride,
+    Scalar* _other, Index otherIncr, Index otherStride,
     level3_blocking<Scalar,Scalar>& blocking);
 };
-template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder>
-EIGEN_DONT_INLINE void triangular_solve_matrix<Scalar,Index,OnTheRight,Mode,Conjugate,TriStorageOrder,ColMajor>::run(
+template <typename Scalar, typename Index, int Mode, bool Conjugate, int TriStorageOrder, int OtherInnerStride>
+EIGEN_DONT_INLINE void triangular_solve_matrix<Scalar,Index,OnTheRight,Mode,Conjugate,TriStorageOrder,ColMajor,OtherInnerStride>::run(
     Index size, Index otherSize,
     const Scalar* _tri, Index triStride,
-    Scalar* _other, Index otherStride,
+    Scalar* _other, Index otherIncr, Index otherStride,
     level3_blocking<Scalar,Scalar>& blocking)
   {
     Index rows = otherSize;
     typedef typename NumTraits<Scalar>::Real RealScalar;
 
-    typedef blas_data_mapper<Scalar, Index, ColMajor> LhsMapper;
+    typedef blas_data_mapper<Scalar, Index, ColMajor, Unaligned, OtherInnerStride> LhsMapper;
     typedef const_blas_data_mapper<Scalar, Index, TriStorageOrder> RhsMapper;
-    LhsMapper lhs(_other, otherStride);
+    LhsMapper lhs(_other, otherStride, otherIncr);
     RhsMapper rhs(_tri, triStride);
 
     typedef gebp_traits<Scalar,Scalar> Traits;
     enum {
       RhsStorageOrder   = TriStorageOrder,
       SmallPanelWidth   = EIGEN_PLAIN_ENUM_MAX(Traits::mr,Traits::nr),
       IsLower = (Mode&Lower) == Lower
@@ -293,32 +295,32 @@
             }
 
             // unblocked triangular solve
             for (Index k=0; k<actualPanelWidth; ++k)
             {
               Index j = IsLower ? absolute_j2+actualPanelWidth-k-1 : absolute_j2+k;
 
-              Scalar* r = &lhs(i2,j);
+              typename LhsMapper::LinearMapper r = lhs.getLinearMapper(i2,j);
               for (Index k3=0; k3<k; ++k3)
               {
                 Scalar b = conj(rhs(IsLower ? j+1+k3 : absolute_j2+k3,j));
-                Scalar* a = &lhs(i2,IsLower ? j+1+k3 : absolute_j2+k3);
+                typename LhsMapper::LinearMapper a = lhs.getLinearMapper(i2,IsLower ? j+1+k3 : absolute_j2+k3);
                 for (Index i=0; i<actual_mc; ++i)
-                  r[i] -= a[i] * b;
+                  r(i) -= a(i) * b;
               }
               if((Mode & UnitDiag)==0)
               {
                 Scalar inv_rjj = RealScalar(1)/conj(rhs(j,j));
                 for (Index i=0; i<actual_mc; ++i)
-                  r[i] *= inv_rjj;
+                  r(i) *= inv_rjj;
               }
             }
 
             // pack the just computed part of lhs to A
-            pack_lhs_panel(blockA, LhsMapper(_other+absolute_j2*otherStride+i2, otherStride),
+            pack_lhs_panel(blockA, lhs.getSubMapper(i2,absolute_j2),
                            actualPanelWidth, actual_mc,
                            actual_kc, j2);
           }
         }
 
         if (rs>0)
           gebp_kernel(lhs.getSubMapper(i2, startPanel), blockA, geb,
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularSolverMatrix_BLAS.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularSolverMatrix_BLAS.h`

 * *Files 3% similar despite different names*

```diff
@@ -36,27 +36,29 @@
 namespace Eigen {
 
 namespace internal {
 
 // implements LeftSide op(triangular)^-1 * general
 #define EIGEN_BLAS_TRSM_L(EIGTYPE, BLASTYPE, BLASFUNC) \
 template <typename Index, int Mode, bool Conjugate, int TriStorageOrder> \
-struct triangular_solve_matrix<EIGTYPE,Index,OnTheLeft,Mode,Conjugate,TriStorageOrder,ColMajor> \
+struct triangular_solve_matrix<EIGTYPE,Index,OnTheLeft,Mode,Conjugate,TriStorageOrder,ColMajor,1> \
 { \
   enum { \
     IsLower = (Mode&Lower) == Lower, \
     IsUnitDiag  = (Mode&UnitDiag) ? 1 : 0, \
     IsZeroDiag  = (Mode&ZeroDiag) ? 1 : 0, \
     conjA = ((TriStorageOrder==ColMajor) && Conjugate) ? 1 : 0 \
   }; \
   static void run( \
       Index size, Index otherSize, \
       const EIGTYPE* _tri, Index triStride, \
-      EIGTYPE* _other, Index otherStride, level3_blocking<EIGTYPE,EIGTYPE>& /*blocking*/) \
+      EIGTYPE* _other, Index otherIncr, Index otherStride, level3_blocking<EIGTYPE,EIGTYPE>& /*blocking*/) \
   { \
+   EIGEN_ONLY_USED_FOR_DEBUG(otherIncr); \
+   eigen_assert(otherIncr == 1); \
    BlasIndex m = convert_index<BlasIndex>(size), n = convert_index<BlasIndex>(otherSize), lda, ldb; \
    char side = 'L', uplo, diag='N', transa; \
    /* Set alpha_ */ \
    EIGTYPE alpha(1); \
    ldb = convert_index<BlasIndex>(otherStride);\
 \
    const EIGTYPE *a; \
@@ -95,27 +97,29 @@
 EIGEN_BLAS_TRSM_L(float,    float,  strsm_)
 EIGEN_BLAS_TRSM_L(scomplex, float,  ctrsm_)
 #endif
 
 // implements RightSide general * op(triangular)^-1
 #define EIGEN_BLAS_TRSM_R(EIGTYPE, BLASTYPE, BLASFUNC) \
 template <typename Index, int Mode, bool Conjugate, int TriStorageOrder> \
-struct triangular_solve_matrix<EIGTYPE,Index,OnTheRight,Mode,Conjugate,TriStorageOrder,ColMajor> \
+struct triangular_solve_matrix<EIGTYPE,Index,OnTheRight,Mode,Conjugate,TriStorageOrder,ColMajor,1> \
 { \
   enum { \
     IsLower = (Mode&Lower) == Lower, \
     IsUnitDiag  = (Mode&UnitDiag) ? 1 : 0, \
     IsZeroDiag  = (Mode&ZeroDiag) ? 1 : 0, \
     conjA = ((TriStorageOrder==ColMajor) && Conjugate) ? 1 : 0 \
   }; \
   static void run( \
       Index size, Index otherSize, \
       const EIGTYPE* _tri, Index triStride, \
-      EIGTYPE* _other, Index otherStride, level3_blocking<EIGTYPE,EIGTYPE>& /*blocking*/) \
+      EIGTYPE* _other, Index otherIncr, Index otherStride, level3_blocking<EIGTYPE,EIGTYPE>& /*blocking*/) \
   { \
+   EIGEN_ONLY_USED_FOR_DEBUG(otherIncr); \
+   eigen_assert(otherIncr == 1); \
    BlasIndex m = convert_index<BlasIndex>(otherSize), n = convert_index<BlasIndex>(size), lda, ldb; \
    char side = 'R', uplo, diag='N', transa; \
    /* Set alpha_ */ \
    EIGTYPE alpha(1); \
    ldb = convert_index<BlasIndex>(otherStride);\
 \
    const EIGTYPE *a; \
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/products/TriangularSolverVector.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/products/TriangularSolverVector.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/BlasUtil.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/BlasUtil.h`

 * *Files 24% similar despite different names*

```diff
@@ -27,106 +27,22 @@
 template<typename Scalar, typename Index, typename DataMapper, int Pack1, int Pack2, typename Packet, int StorageOrder, bool Conjugate = false, bool PanelMode = false>
 struct gemm_pack_lhs;
 
 template<
   typename Index,
   typename LhsScalar, int LhsStorageOrder, bool ConjugateLhs,
   typename RhsScalar, int RhsStorageOrder, bool ConjugateRhs,
-  int ResStorageOrder>
+  int ResStorageOrder, int ResInnerStride>
 struct general_matrix_matrix_product;
 
 template<typename Index,
          typename LhsScalar, typename LhsMapper, int LhsStorageOrder, bool ConjugateLhs,
          typename RhsScalar, typename RhsMapper, bool ConjugateRhs, int Version=Specialized>
 struct general_matrix_vector_product;
 
-
-template<bool Conjugate> struct conj_if;
-
-template<> struct conj_if<true> {
-  template<typename T>
-  inline T operator()(const T& x) const { return numext::conj(x); }
-  template<typename T>
-  inline T pconj(const T& x) const { return internal::pconj(x); }
-};
-
-template<> struct conj_if<false> {
-  template<typename T>
-  inline const T& operator()(const T& x) const { return x; }
-  template<typename T>
-  inline const T& pconj(const T& x) const { return x; }
-};
-
-// Generic implementation for custom complex types.
-template<typename LhsScalar, typename RhsScalar, bool ConjLhs, bool ConjRhs>
-struct conj_helper
-{
-  typedef typename ScalarBinaryOpTraits<LhsScalar,RhsScalar>::ReturnType Scalar;
-
-  EIGEN_STRONG_INLINE Scalar pmadd(const LhsScalar& x, const RhsScalar& y, const Scalar& c) const
-  { return padd(c, pmul(x,y)); }
-
-  EIGEN_STRONG_INLINE Scalar pmul(const LhsScalar& x, const RhsScalar& y) const
-  { return conj_if<ConjLhs>()(x) *  conj_if<ConjRhs>()(y); }
-};
-
-template<typename Scalar> struct conj_helper<Scalar,Scalar,false,false>
-{
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar pmadd(const Scalar& x, const Scalar& y, const Scalar& c) const { return internal::pmadd(x,y,c); }
-  EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Scalar pmul(const Scalar& x, const Scalar& y) const { return internal::pmul(x,y); }
-};
-
-template<typename RealScalar> struct conj_helper<std::complex<RealScalar>, std::complex<RealScalar>, false,true>
-{
-  typedef std::complex<RealScalar> Scalar;
-  EIGEN_STRONG_INLINE Scalar pmadd(const Scalar& x, const Scalar& y, const Scalar& c) const
-  { return c + pmul(x,y); }
-
-  EIGEN_STRONG_INLINE Scalar pmul(const Scalar& x, const Scalar& y) const
-  { return Scalar(numext::real(x)*numext::real(y) + numext::imag(x)*numext::imag(y), numext::imag(x)*numext::real(y) - numext::real(x)*numext::imag(y)); }
-};
-
-template<typename RealScalar> struct conj_helper<std::complex<RealScalar>, std::complex<RealScalar>, true,false>
-{
-  typedef std::complex<RealScalar> Scalar;
-  EIGEN_STRONG_INLINE Scalar pmadd(const Scalar& x, const Scalar& y, const Scalar& c) const
-  { return c + pmul(x,y); }
-
-  EIGEN_STRONG_INLINE Scalar pmul(const Scalar& x, const Scalar& y) const
-  { return Scalar(numext::real(x)*numext::real(y) + numext::imag(x)*numext::imag(y), numext::real(x)*numext::imag(y) - numext::imag(x)*numext::real(y)); }
-};
-
-template<typename RealScalar> struct conj_helper<std::complex<RealScalar>, std::complex<RealScalar>, true,true>
-{
-  typedef std::complex<RealScalar> Scalar;
-  EIGEN_STRONG_INLINE Scalar pmadd(const Scalar& x, const Scalar& y, const Scalar& c) const
-  { return c + pmul(x,y); }
-
-  EIGEN_STRONG_INLINE Scalar pmul(const Scalar& x, const Scalar& y) const
-  { return Scalar(numext::real(x)*numext::real(y) - numext::imag(x)*numext::imag(y), - numext::real(x)*numext::imag(y) - numext::imag(x)*numext::real(y)); }
-};
-
-template<typename RealScalar,bool Conj> struct conj_helper<std::complex<RealScalar>, RealScalar, Conj,false>
-{
-  typedef std::complex<RealScalar> Scalar;
-  EIGEN_STRONG_INLINE Scalar pmadd(const Scalar& x, const RealScalar& y, const Scalar& c) const
-  { return padd(c, pmul(x,y)); }
-  EIGEN_STRONG_INLINE Scalar pmul(const Scalar& x, const RealScalar& y) const
-  { return conj_if<Conj>()(x)*y; }
-};
-
-template<typename RealScalar,bool Conj> struct conj_helper<RealScalar, std::complex<RealScalar>, false,Conj>
-{
-  typedef std::complex<RealScalar> Scalar;
-  EIGEN_STRONG_INLINE Scalar pmadd(const RealScalar& x, const Scalar& y, const Scalar& c) const
-  { return padd(c, pmul(x,y)); }
-  EIGEN_STRONG_INLINE Scalar pmul(const RealScalar& x, const Scalar& y) const
-  { return x*conj_if<Conj>()(y); }
-};
-
 template<typename From,typename To> struct get_factor {
   EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE To run(const From& x) { return To(x); }
 };
 
 template<typename Scalar> struct get_factor<Scalar,typename NumTraits<Scalar>::Real> {
   EIGEN_DEVICE_FUNC
   static EIGEN_STRONG_INLINE typename NumTraits<Scalar>::Real run(const Scalar& x) { return numext::real(x); }
@@ -151,19 +67,27 @@
     return (UIntPtr(m_data+i)%sizeof(Packet))==0;
   }
 
   protected:
   Scalar* m_data;
 };
 
+template<typename Scalar, typename Index, int AlignmentType, int Incr=1>
+class BlasLinearMapper;
+
 template<typename Scalar, typename Index, int AlignmentType>
-class BlasLinearMapper
+class BlasLinearMapper<Scalar,Index,AlignmentType>
 {
 public:
-  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE BlasLinearMapper(Scalar *data) : m_data(data) {}
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE BlasLinearMapper(Scalar *data, Index incr=1)
+    : m_data(data)
+  {
+    EIGEN_ONLY_USED_FOR_DEBUG(incr);
+    eigen_assert(incr==1);
+  }
 
   EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void prefetch(int i) const {
     internal::prefetch(&operator()(i));
   }
 
   EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar& operator()(Index i) const {
     return m_data[i];
@@ -180,22 +104,79 @@
   }
 
 protected:
   Scalar *m_data;
 };
 
 // Lightweight helper class to access matrix coefficients.
-template<typename Scalar, typename Index, int StorageOrder, int AlignmentType = Unaligned>
-class blas_data_mapper
+template<typename Scalar, typename Index, int StorageOrder, int AlignmentType = Unaligned, int Incr = 1>
+class blas_data_mapper;
+
+// TMP to help PacketBlock store implementation.
+// There's currently no known use case for PacketBlock load.
+// The default implementation assumes ColMajor order.
+// It always store each packet sequentially one `stride` apart.
+template<typename Index, typename Scalar, typename Packet, int n, int idx, int StorageOrder>
+struct PacketBlockManagement
+{
+  PacketBlockManagement<Index, Scalar, Packet, n, idx - 1, StorageOrder> pbm;
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(Scalar *to, const Index stride, Index i, Index j, const PacketBlock<Packet, n> &block) const {
+    pbm.store(to, stride, i, j, block);
+    pstoreu<Scalar>(to + i + (j + idx)*stride, block.packet[idx]);
+  }
+};
+
+// PacketBlockManagement specialization to take care of RowMajor order without ifs.
+template<typename Index, typename Scalar, typename Packet, int n, int idx>
+struct PacketBlockManagement<Index, Scalar, Packet, n, idx, RowMajor>
+{
+  PacketBlockManagement<Index, Scalar, Packet, n, idx - 1, RowMajor> pbm;
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(Scalar *to, const Index stride, Index i, Index j, const PacketBlock<Packet, n> &block) const {
+    pbm.store(to, stride, i, j, block);
+    pstoreu<Scalar>(to + j + (i + idx)*stride, block.packet[idx]);
+  }
+};
+
+template<typename Index, typename Scalar, typename Packet, int n, int StorageOrder>
+struct PacketBlockManagement<Index, Scalar, Packet, n, -1, StorageOrder>
+{
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(Scalar *to, const Index stride, Index i, Index j, const PacketBlock<Packet, n> &block) const {
+    EIGEN_UNUSED_VARIABLE(to);
+    EIGEN_UNUSED_VARIABLE(stride);
+    EIGEN_UNUSED_VARIABLE(i);
+    EIGEN_UNUSED_VARIABLE(j);
+    EIGEN_UNUSED_VARIABLE(block);
+  }
+};
+
+template<typename Index, typename Scalar, typename Packet, int n>
+struct PacketBlockManagement<Index, Scalar, Packet, n, -1, RowMajor>
+{
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(Scalar *to, const Index stride, Index i, Index j, const PacketBlock<Packet, n> &block) const {
+    EIGEN_UNUSED_VARIABLE(to);
+    EIGEN_UNUSED_VARIABLE(stride);
+    EIGEN_UNUSED_VARIABLE(i);
+    EIGEN_UNUSED_VARIABLE(j);
+    EIGEN_UNUSED_VARIABLE(block);
+  }
+};
+
+template<typename Scalar, typename Index, int StorageOrder, int AlignmentType>
+class blas_data_mapper<Scalar,Index,StorageOrder,AlignmentType,1>
 {
 public:
   typedef BlasLinearMapper<Scalar, Index, AlignmentType> LinearMapper;
   typedef BlasVectorMapper<Scalar, Index> VectorMapper;
 
-  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE blas_data_mapper(Scalar* data, Index stride) : m_data(data), m_stride(stride) {}
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE blas_data_mapper(Scalar* data, Index stride, Index incr=1)
+   : m_data(data), m_stride(stride)
+  {
+    EIGEN_ONLY_USED_FOR_DEBUG(incr);
+    eigen_assert(incr==1);
+  }
 
   EIGEN_DEVICE_FUNC  EIGEN_ALWAYS_INLINE blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType>
   getSubMapper(Index i, Index j) const {
     return blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType>(&operator()(i, j), m_stride);
   }
 
   EIGEN_DEVICE_FUNC  EIGEN_ALWAYS_INLINE LinearMapper getLinearMapper(Index i, Index j) const {
@@ -238,17 +219,173 @@
   EIGEN_DEVICE_FUNC Index firstAligned(Index size) const {
     if (UIntPtr(m_data)%sizeof(Scalar)) {
       return -1;
     }
     return internal::first_default_aligned(m_data, size);
   }
 
+  template<typename SubPacket, int n>
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacketBlock(Index i, Index j, const PacketBlock<SubPacket, n> &block) const {
+    PacketBlockManagement<Index, Scalar, SubPacket, n, n-1, StorageOrder> pbm;
+    pbm.store(m_data, m_stride, i, j, block);
+  }
+protected:
+  Scalar* EIGEN_RESTRICT m_data;
+  const Index m_stride;
+};
+
+// Implementation of non-natural increment (i.e. inner-stride != 1)
+// The exposed API is not complete yet compared to the Incr==1 case
+// because some features makes less sense in this case.
+template<typename Scalar, typename Index, int AlignmentType, int Incr>
+class BlasLinearMapper
+{
+public:
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE BlasLinearMapper(Scalar *data,Index incr) : m_data(data), m_incr(incr) {}
+
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void prefetch(int i) const {
+    internal::prefetch(&operator()(i));
+  }
+
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE Scalar& operator()(Index i) const {
+    return m_data[i*m_incr.value()];
+  }
+
+  template<typename PacketType>
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketType loadPacket(Index i) const {
+    return pgather<Scalar,PacketType>(m_data + i*m_incr.value(), m_incr.value());
+  }
+
+  template<typename PacketType>
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacket(Index i, const PacketType &p) const {
+    pscatter<Scalar, PacketType>(m_data + i*m_incr.value(), p, m_incr.value());
+  }
+
+protected:
+  Scalar *m_data;
+  const internal::variable_if_dynamic<Index,Incr> m_incr;
+};
+
+template<typename Scalar, typename Index, int StorageOrder, int AlignmentType,int Incr>
+class blas_data_mapper
+{
+public:
+  typedef BlasLinearMapper<Scalar, Index, AlignmentType,Incr> LinearMapper;
+
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE blas_data_mapper(Scalar* data, Index stride, Index incr) : m_data(data), m_stride(stride), m_incr(incr) {}
+
+  EIGEN_DEVICE_FUNC  EIGEN_ALWAYS_INLINE blas_data_mapper
+  getSubMapper(Index i, Index j) const {
+    return blas_data_mapper(&operator()(i, j), m_stride, m_incr.value());
+  }
+
+  EIGEN_DEVICE_FUNC  EIGEN_ALWAYS_INLINE LinearMapper getLinearMapper(Index i, Index j) const {
+    return LinearMapper(&operator()(i, j), m_incr.value());
+  }
+
+  EIGEN_DEVICE_FUNC
+  EIGEN_ALWAYS_INLINE Scalar& operator()(Index i, Index j) const {
+    return m_data[StorageOrder==RowMajor ? j*m_incr.value() + i*m_stride : i*m_incr.value() + j*m_stride];
+  }
+
+  template<typename PacketType>
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketType loadPacket(Index i, Index j) const {
+    return pgather<Scalar,PacketType>(&operator()(i, j),m_incr.value());
+  }
+
+  template <typename PacketT, int AlignmentT>
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE PacketT load(Index i, Index j) const {
+    return pgather<Scalar,PacketT>(&operator()(i, j),m_incr.value());
+  }
+
+  template<typename SubPacket>
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void scatterPacket(Index i, Index j, const SubPacket &p) const {
+    pscatter<Scalar, SubPacket>(&operator()(i, j), p, m_stride);
+  }
+
+  template<typename SubPacket>
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE SubPacket gatherPacket(Index i, Index j) const {
+    return pgather<Scalar, SubPacket>(&operator()(i, j), m_stride);
+  }
+
+  // storePacketBlock_helper defines a way to access values inside the PacketBlock, this is essentially required by the Complex types.
+  template<typename SubPacket, typename ScalarT, int n, int idx>
+  struct storePacketBlock_helper
+  {
+    storePacketBlock_helper<SubPacket, ScalarT, n, idx-1> spbh;
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup, Index i, Index j, const PacketBlock<SubPacket, n>& block) const {
+      spbh.store(sup, i,j,block);
+      for(int l = 0; l < unpacket_traits<SubPacket>::size; l++)
+      {
+        ScalarT *v = &sup->operator()(i+l, j+idx);
+        *v = block.packet[idx][l];
+      }
+    }
+  };
+
+  template<typename SubPacket, int n, int idx>
+  struct storePacketBlock_helper<SubPacket, std::complex<float>, n, idx>
+  {
+    storePacketBlock_helper<SubPacket, std::complex<float>, n, idx-1> spbh;
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup, Index i, Index j, const PacketBlock<SubPacket, n>& block) const {
+      spbh.store(sup,i,j,block);
+      for(int l = 0; l < unpacket_traits<SubPacket>::size; l++)
+      {
+        std::complex<float> *v = &sup->operator()(i+l, j+idx);
+        v->real(block.packet[idx].v[2*l+0]);
+        v->imag(block.packet[idx].v[2*l+1]);
+      }
+    }
+  };
+
+  template<typename SubPacket, int n, int idx>
+  struct storePacketBlock_helper<SubPacket, std::complex<double>, n, idx>
+  {
+    storePacketBlock_helper<SubPacket, std::complex<double>, n, idx-1> spbh;
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>* sup, Index i, Index j, const PacketBlock<SubPacket, n>& block) const {
+      spbh.store(sup,i,j,block);
+      for(int l = 0; l < unpacket_traits<SubPacket>::size; l++)
+      {
+        std::complex<double> *v = &sup->operator()(i+l, j+idx);
+        v->real(block.packet[idx].v[2*l+0]);
+        v->imag(block.packet[idx].v[2*l+1]);
+      }
+    }
+  };
+
+  template<typename SubPacket, typename ScalarT, int n>
+  struct storePacketBlock_helper<SubPacket, ScalarT, n, -1>
+  {
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*, Index, Index, const PacketBlock<SubPacket, n>& ) const {
+    }
+  };
+
+  template<typename SubPacket, int n>
+  struct storePacketBlock_helper<SubPacket, std::complex<float>, n, -1>
+  {
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*, Index, Index, const PacketBlock<SubPacket, n>& ) const {
+    }
+  };
+
+  template<typename SubPacket, int n>
+  struct storePacketBlock_helper<SubPacket, std::complex<double>, n, -1>
+  {
+    EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void store(const blas_data_mapper<Scalar, Index, StorageOrder, AlignmentType, Incr>*, Index, Index, const PacketBlock<SubPacket, n>& ) const {
+    }
+  };
+  // This function stores a PacketBlock on m_data, this approach is really quite slow compare to Incr=1 and should be avoided when possible.
+  template<typename SubPacket, int n>
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE void storePacketBlock(Index i, Index j, const PacketBlock<SubPacket, n>&block) const {
+    storePacketBlock_helper<SubPacket, Scalar, n, n-1> spb;
+    spb.store(this, i,j,block);
+  }
 protected:
   Scalar* EIGEN_RESTRICT m_data;
   const Index m_stride;
+  const internal::variable_if_dynamic<Index,Incr> m_incr;
 };
 
 // lightweight helper class to access matrix coefficients (const version)
 template<typename Scalar, typename Index, int StorageOrder>
 class const_blas_data_mapper : public blas_data_mapper<const Scalar, Index, StorageOrder> {
   public:
   EIGEN_ALWAYS_INLINE const_blas_data_mapper(const Scalar *data, Index stride) : blas_data_mapper<const Scalar, Index, StorageOrder>(data, stride) {}
@@ -377,28 +514,70 @@
 template<typename T>
 struct blas_traits<const T>
      : blas_traits<T>
 {};
 
 template<typename T, bool HasUsableDirectAccess=blas_traits<T>::HasUsableDirectAccess>
 struct extract_data_selector {
-  static const typename T::Scalar* run(const T& m)
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static const typename T::Scalar* run(const T& m)
   {
     return blas_traits<T>::extract(m).data();
   }
 };
 
 template<typename T>
 struct extract_data_selector<T,false> {
   static typename T::Scalar* run(const T&) { return 0; }
 };
 
-template<typename T> const typename T::Scalar* extract_data(const T& m)
+template<typename T>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE const typename T::Scalar* extract_data(const T& m)
 {
   return extract_data_selector<T>::run(m);
 }
 
+/**
+ * \c combine_scalar_factors extracts and multiplies factors from GEMM and GEMV products.
+ * There is a specialization for booleans
+ */
+template<typename ResScalar, typename Lhs, typename Rhs>
+struct combine_scalar_factors_impl
+{
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static ResScalar run(const Lhs& lhs, const Rhs& rhs)
+  {
+    return blas_traits<Lhs>::extractScalarFactor(lhs) * blas_traits<Rhs>::extractScalarFactor(rhs);
+  }
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static ResScalar run(const ResScalar& alpha, const Lhs& lhs, const Rhs& rhs)
+  {
+    return alpha * blas_traits<Lhs>::extractScalarFactor(lhs) * blas_traits<Rhs>::extractScalarFactor(rhs);
+  }
+};
+template<typename Lhs, typename Rhs>
+struct combine_scalar_factors_impl<bool, Lhs, Rhs>
+{
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static bool run(const Lhs& lhs, const Rhs& rhs)
+  {
+    return blas_traits<Lhs>::extractScalarFactor(lhs) && blas_traits<Rhs>::extractScalarFactor(rhs);
+  }
+  EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE static bool run(const bool& alpha, const Lhs& lhs, const Rhs& rhs)
+  {
+    return alpha && blas_traits<Lhs>::extractScalarFactor(lhs) && blas_traits<Rhs>::extractScalarFactor(rhs);
+  }
+};
+
+template<typename ResScalar, typename Lhs, typename Rhs>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE ResScalar combine_scalar_factors(const ResScalar& alpha, const Lhs& lhs, const Rhs& rhs)
+{
+  return combine_scalar_factors_impl<ResScalar,Lhs,Rhs>::run(alpha, lhs, rhs);
+}
+template<typename ResScalar, typename Lhs, typename Rhs>
+EIGEN_DEVICE_FUNC EIGEN_ALWAYS_INLINE ResScalar combine_scalar_factors(const Lhs& lhs, const Rhs& rhs)
+{
+  return combine_scalar_factors_impl<ResScalar,Lhs,Rhs>::run(lhs, rhs);
+}
+
+
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_BLASUTIL_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/ConfigureVectorization.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/ConfigureVectorization.h`

 * *Files 17% similar despite different names*

```diff
@@ -1,11 +1,12 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
 // Copyright (C) 2008-2018 Gael Guennebaud <gael.guennebaud@inria.fr>
+// Copyright (C) 2020, Arm Limited and Contributors
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_CONFIGURE_VECTORIZATION_H
 #define EIGEN_CONFIGURE_VECTORIZATION_H
@@ -208,15 +209,14 @@
   #endif
 #else
   #if (defined __SSE2__) && ( (!EIGEN_COMP_GNUC) || EIGEN_COMP_ICC || EIGEN_GNUC_AT_LEAST(4,2) )
     #define EIGEN_SSE2_ON_NON_MSVC_BUT_NOT_OLD_GCC
   #endif
 #endif
 
-
 #if !(defined(EIGEN_DONT_VECTORIZE) || defined(EIGEN_GPUCC))
 
   #if defined (EIGEN_SSE2_ON_NON_MSVC_BUT_NOT_OLD_GCC) || defined(EIGEN_SSE2_ON_MSVC_2008_OR_LATER)
 
     // Defines symbols for compile-time detection of which instructions are
     // used.
     // EIGEN_VECTORIZE_YY is defined if and only if the instruction set YY is used
@@ -237,23 +237,27 @@
     #ifdef __SSE4_1__
       #define EIGEN_VECTORIZE_SSE4_1
     #endif
     #ifdef __SSE4_2__
       #define EIGEN_VECTORIZE_SSE4_2
     #endif
     #ifdef __AVX__
-      #define EIGEN_VECTORIZE_AVX
+      #ifndef EIGEN_USE_SYCL 
+        #define EIGEN_VECTORIZE_AVX
+      #endif
       #define EIGEN_VECTORIZE_SSE3
       #define EIGEN_VECTORIZE_SSSE3
       #define EIGEN_VECTORIZE_SSE4_1
       #define EIGEN_VECTORIZE_SSE4_2
     #endif
     #ifdef __AVX2__
-      #define EIGEN_VECTORIZE_AVX2
-      #define EIGEN_VECTORIZE_AVX
+      #ifndef EIGEN_USE_SYCL 
+        #define EIGEN_VECTORIZE_AVX2
+        #define EIGEN_VECTORIZE_AVX
+      #endif
       #define EIGEN_VECTORIZE_SSE3
       #define EIGEN_VECTORIZE_SSSE3
       #define EIGEN_VECTORIZE_SSE4_1
       #define EIGEN_VECTORIZE_SSE4_2
     #endif
     #if defined(__FMA__) || (EIGEN_COMP_MSVC && defined(__AVX2__))
       // MSVC does not expose a switch dedicated for FMA
@@ -264,28 +268,67 @@
       #ifndef EIGEN_VECTORIZE_FMA
       #if EIGEN_COMP_GNUC
       #error Please add -mfma to your compiler flags: compiling with -mavx512f alone without SSE/AVX FMA is not supported (bug 1638).
       #else
       #error Please enable FMA in your compiler flags (e.g. -mfma): compiling with AVX512 alone without SSE/AVX FMA is not supported (bug 1638).
       #endif
       #endif
-      #define EIGEN_VECTORIZE_AVX512
-      #define EIGEN_VECTORIZE_AVX2
-      #define EIGEN_VECTORIZE_AVX
+      #ifndef EIGEN_USE_SYCL
+        #define EIGEN_VECTORIZE_AVX512
+        #define EIGEN_VECTORIZE_AVX2
+        #define EIGEN_VECTORIZE_AVX
+      #endif
       #define EIGEN_VECTORIZE_FMA
       #define EIGEN_VECTORIZE_SSE3
       #define EIGEN_VECTORIZE_SSSE3
       #define EIGEN_VECTORIZE_SSE4_1
       #define EIGEN_VECTORIZE_SSE4_2
-      #ifdef __AVX512DQ__
-        #define EIGEN_VECTORIZE_AVX512DQ
+      #ifndef EIGEN_USE_SYCL
+        #ifdef __AVX512DQ__
+          #define EIGEN_VECTORIZE_AVX512DQ
+        #endif
+        #ifdef __AVX512ER__
+          #define EIGEN_VECTORIZE_AVX512ER
+        #endif
+        #ifdef __AVX512BF16__
+          #define EIGEN_VECTORIZE_AVX512BF16
+        #endif
       #endif
-      #ifdef __AVX512ER__
-        #define EIGEN_VECTORIZE_AVX512ER
+    #endif
+
+    // Disable AVX support on broken xcode versions
+    #if defined(__apple_build_version__) && (__apple_build_version__ == 11000033 ) && ( __MAC_OS_X_VERSION_MIN_REQUIRED == 101500 )
+      // A nasty bug in the clang compiler shipped with xcode in a common compilation situation
+      // when XCode 11.0 and Mac deployment target macOS 10.15 is https://trac.macports.org/ticket/58776#no1
+      #ifdef EIGEN_VECTORIZE_AVX
+        #undef EIGEN_VECTORIZE_AVX
+        #warning "Disabling AVX support: clang compiler shipped with XCode 11.[012] generates broken assembly with -macosx-version-min=10.15 and AVX enabled. "
+        #ifdef EIGEN_VECTORIZE_AVX2
+          #undef EIGEN_VECTORIZE_AVX2
+        #endif
+        #ifdef EIGEN_VECTORIZE_FMA
+          #undef EIGEN_VECTORIZE_FMA
+        #endif
+        #ifdef EIGEN_VECTORIZE_AVX512
+          #undef EIGEN_VECTORIZE_AVX512
+        #endif
+        #ifdef EIGEN_VECTORIZE_AVX512DQ
+          #undef EIGEN_VECTORIZE_AVX512DQ
+        #endif
+        #ifdef EIGEN_VECTORIZE_AVX512ER
+          #undef EIGEN_VECTORIZE_AVX512ER
+        #endif
       #endif
+      // NOTE: Confirmed test failures in XCode 11.0, and XCode 11.2 with  -macosx-version-min=10.15 and AVX
+      // NOTE using -macosx-version-min=10.15 with Xcode 11.0 results in runtime segmentation faults in many tests, 11.2 produce core dumps in 3 tests
+      // NOTE using -macosx-version-min=10.14 produces functioning and passing tests in all cases
+      // NOTE __clang_version__ "11.0.0 (clang-1100.0.33.8)"  XCode 11.0 <- Produces many segfault and core dumping tests
+      //                                                                    with  -macosx-version-min=10.15 and AVX
+      // NOTE __clang_version__ "11.0.0 (clang-1100.0.33.12)" XCode 11.2 <- Produces 3 core dumping tests with  
+      //                                                                    -macosx-version-min=10.15 and AVX
     #endif
 
     // include files
 
     // This extern "C" works around a MINGW-w64 compilation issue
     // https://sourceforge.net/tracker/index.php?func=detail&aid=3018394&group_id=202880&atid=983354
     // In essence, intrin.h is included by windows.h and also declares intrinsics (just as emmintrin.h etc. below do).
@@ -338,51 +381,76 @@
     #include <altivec.h>
     // We need to #undef all these ugly tokens defined in <altivec.h>
     // => use __vector instead of vector
     #undef bool
     #undef vector
     #undef pixel
 
-  #elif (defined  __ARM_NEON) || (defined __ARM_NEON__)
+  #elif ((defined  __ARM_NEON) || (defined __ARM_NEON__)) && !(defined EIGEN_ARM64_USE_SVE)
 
     #define EIGEN_VECTORIZE
     #define EIGEN_VECTORIZE_NEON
     #include <arm_neon.h>
 
-  #elif (defined __s390x__ && defined __VEC__)
+  // We currently require SVE to be enabled explicitly via EIGEN_ARM64_USE_SVE and
+  // will not select the backend automatically
+  #elif (defined __ARM_FEATURE_SVE) && (defined EIGEN_ARM64_USE_SVE)
 
     #define EIGEN_VECTORIZE
-    #define EIGEN_VECTORIZE_ZVECTOR
-    #include <vecintrin.h>
+    #define EIGEN_VECTORIZE_SVE
+    #include <arm_sve.h>
 
-  #elif defined __mips_msa
+    // Since we depend on knowing SVE vector lengths at compile-time, we need
+    // to ensure a fixed lengths is set
+    #if defined __ARM_FEATURE_SVE_BITS
+      #define EIGEN_ARM64_SVE_VL __ARM_FEATURE_SVE_BITS
+    #else
+#error "Eigen requires a fixed SVE lector length but EIGEN_ARM64_SVE_VL is not set."
+#endif
+
+#elif (defined __s390x__ && defined __VEC__)
+
+#define EIGEN_VECTORIZE
+#define EIGEN_VECTORIZE_ZVECTOR
+#include <vecintrin.h>
+
+#elif defined __mips_msa
+
+// Limit MSA optimizations to little-endian CPUs for now.
+// TODO: Perhaps, eventually support MSA optimizations on big-endian CPUs?
+#if defined(__BYTE_ORDER__) && (__BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)
+#if defined(__LP64__)
+#define EIGEN_MIPS_64
+#else
+#define EIGEN_MIPS_32
+#endif
+#define EIGEN_VECTORIZE
+#define EIGEN_VECTORIZE_MSA
+#include <msa.h>
+#endif
 
-    // Limit MSA optimizations to little-endian CPUs for now.
-    // TODO: Perhaps, eventually support MSA optimizations on big-endian CPUs?
-    #if defined(__BYTE_ORDER__) && (__BYTE_ORDER__ == __ORDER_LITTLE_ENDIAN__)
-      #if defined(__LP64__)
-        #define EIGEN_MIPS_64
-      #else
-        #define EIGEN_MIPS_32
-      #endif
-      #define EIGEN_VECTORIZE
-      #define EIGEN_VECTORIZE_MSA
-      #include <msa.h>
-    #endif
+#endif
+#endif
 
-  #endif
+// Following the Arm ACLE arm_neon.h should also include arm_fp16.h but not all
+// compilers seem to follow this. We therefore include it explicitly.
+// See also: https://bugs.llvm.org/show_bug.cgi?id=47955
+#if defined(EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC)
+  #include <arm_fp16.h>
 #endif
 
-#if defined(__F16C__) && (!defined(EIGEN_COMP_CLANG) || EIGEN_COMP_CLANG>=380)
+#if defined(__F16C__) && (!defined(EIGEN_GPUCC) && (!EIGEN_COMP_CLANG || EIGEN_COMP_CLANG>=380))
   // We can use the optimized fp16 to float and float to fp16 conversion routines
   #define EIGEN_HAS_FP16_C
 
-  #if defined(EIGEN_COMP_CLANG)
-    // Workaround for clang: The FP16C intrinsics for clang are included by
-    // immintrin.h, as opposed to emmintrin.h as suggested by Intel:
+  #if EIGEN_COMP_GNUC
+    // Make sure immintrin.h is included, even if e.g. vectorization is
+    // explicitly disabled (see also issue #2395).
+    // Note that FP16C intrinsics for gcc and clang are included by immintrin.h,
+    // as opposed to emmintrin.h as suggested by Intel:
     // https://software.intel.com/sites/landingpage/IntrinsicsGuide/#othertechs=FP16C&expand=1711
     #include <immintrin.h>
   #endif
 #endif
 
 #if defined EIGEN_CUDACC
   #define EIGEN_VECTORIZE_GPU
@@ -396,17 +464,14 @@
   #include <cuda_runtime_api.h>
   #include <cuda_fp16.h>
 #endif
 
 #if defined(EIGEN_HIPCC)
   #define EIGEN_VECTORIZE_GPU
   #include <hip/hip_vector_types.h>
-#endif
-
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
   #define EIGEN_HAS_HIP_FP16
   #include <hip/hip_fp16.h>
 #endif
 
 
 /** \brief Namespace containing all symbols from the %Eigen library. */
 namespace Eigen {
@@ -428,14 +493,16 @@
   return "SSE, SSE2";
 #elif defined(EIGEN_VECTORIZE_ALTIVEC)
   return "AltiVec";
 #elif defined(EIGEN_VECTORIZE_VSX)
   return "VSX";
 #elif defined(EIGEN_VECTORIZE_NEON)
   return "ARM NEON";
+#elif defined(EIGEN_VECTORIZE_SVE)
+  return "ARM SVE";
 #elif defined(EIGEN_VECTORIZE_ZVECTOR)
   return "S390X ZVECTOR";
 #elif defined(EIGEN_VECTORIZE_MSA)
   return "MIPS MSA";
 #else
   return "None";
 #endif
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/Constants.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/Constants.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 // This file is part of Eigen, a lightweight C++ template library
 // for linear algebra.
 //
 // Copyright (C) 2008-2015 Gael Guennebaud <gael.guennebaud@inria.fr>
 // Copyright (C) 2007-2009 Benoit Jacob <jacob.benoit.1@gmail.com>
+// Copyright (C) 2020, Arm Limited and Contributors
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_CONSTANTS_H
 #define EIGEN_CONSTANTS_H
@@ -152,15 +153,15 @@
   * See the comment on LvalueBit for an explanation of how LvalueBit and DirectAccessBit are mutually orthogonal.
   */
 const unsigned int DirectAccessBit = 0x40;
 
 /** \deprecated \ingroup flags
   *
   * means the first coefficient packet is guaranteed to be aligned.
-  * An expression cannot has the AlignedBit without the PacketAccessBit flag.
+  * An expression cannot have the AlignedBit without the PacketAccessBit flag.
   * In other words, this means we are allow to perform an aligned packet access to the first element regardless
   * of the expression kind:
   * \code
   * expression.packet<Aligned>(0);
   * \endcode
   */
 EIGEN_DEPRECATED const unsigned int AlignedBit = 0x80;
@@ -251,20 +252,14 @@
   AlignedMax = Unaligned
 #else
 #error Invalid value for EIGEN_MAX_ALIGN_BYTES
 #endif
 };
 
 /** \ingroup enums
- * Enum used by DenseBase::corner() in Eigen2 compatibility mode. */
-// FIXME after the corner() API change, this was not needed anymore, except by AlignedBox
-// TODO: find out what to do with that. Adapt the AlignedBox API ?
-enum CornerType { TopLeft, TopRight, BottomLeft, BottomRight };
-
-/** \ingroup enums
   * Enum containing possible values for the \p Direction parameter of
   * Reverse, PartialReduxExpr and VectorwiseOp. */
 enum DirectionType { 
   /** For Reverse, all columns are reversed; 
     * for PartialReduxExpr and VectorwiseOp, act on columns. */
   Vertical, 
   /** For Reverse, all rows are reversed; 
@@ -330,20 +325,29 @@
   DontAlign = 0x2
 };
 
 /** \ingroup enums
   * Enum for specifying whether to apply or solve on the left or right. */
 enum SideType {
   /** Apply transformation on the left. */
-  OnTheLeft = 1,  
+  OnTheLeft = 1,
   /** Apply transformation on the right. */
-  OnTheRight = 2  
+  OnTheRight = 2
 };
 
-
+/** \ingroup enums
+ * Enum for specifying NaN-propagation behavior, e.g. for coeff-wise min/max. */
+enum NaNPropagationOptions {
+  /**  Implementation defined behavior if NaNs are present. */
+  PropagateFast = 0,
+  /**  Always propagate NaNs. */
+  PropagateNaN,
+  /**  Always propagate not-NaNs. */
+  PropagateNumbers
+};
 
 /* the following used to be written as:
  *
  *   struct NoChange_t {};
  *   namespace {
  *     EIGEN_UNUSED NoChange_t NoChange;
  *   }
@@ -467,22 +471,25 @@
   enum Type {
     Generic = 0x0,
     SSE = 0x1,
     AltiVec = 0x2,
     VSX = 0x3,
     NEON = 0x4,
     MSA = 0x5,
+    SVE = 0x6,
 #if defined EIGEN_VECTORIZE_SSE
     Target = SSE
 #elif defined EIGEN_VECTORIZE_ALTIVEC
     Target = AltiVec
 #elif defined EIGEN_VECTORIZE_VSX
     Target = VSX
 #elif defined EIGEN_VECTORIZE_NEON
     Target = NEON
+#elif defined EIGEN_VECTORIZE_SVE
+    Target = SVE
 #elif defined EIGEN_VECTORIZE_MSA
     Target = MSA
 #else
     Target = Generic
 #endif
   };
 }
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/ForwardDeclarations.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/ForwardDeclarations.h`

 * *Files 4% similar despite different names*

```diff
@@ -106,15 +106,15 @@
 template<typename Derived> class TranspositionsBase;
 template<typename _IndicesType> class PermutationWrapper;
 template<typename _IndicesType> class TranspositionsWrapper;
 
 template<typename Derived,
          int Level = internal::accessors_level<Derived>::has_write_access ? WriteAccessors : ReadOnlyAccessors
 > class MapBase;
-template<int InnerStrideAtCompileTime, int OuterStrideAtCompileTime> class Stride;
+template<int OuterStrideAtCompileTime, int InnerStrideAtCompileTime> class Stride;
 template<int Value = Dynamic> class InnerStride;
 template<int Value = Dynamic> class OuterStride;
 template<typename MatrixType, int MapOptions=Unaligned, typename StrideType = Stride<0,0> > class Map;
 template<typename Derived> class RefBase;
 template<typename PlainObjectType, int Options = 0,
          typename StrideType = typename internal::conditional<PlainObjectType::IsVectorAtCompileTime,InnerStride<1>,OuterStride<> >::type > class Ref;
 
@@ -130,14 +130,15 @@
 template<typename Derived> class SolverBase;
 template<typename XprType> class InnerIterator;
 
 namespace internal {
 template<typename XprType> class generic_randaccess_stl_iterator;
 template<typename XprType> class pointer_based_stl_iterator;
 template<typename XprType, DirectionType Direction> class subvector_stl_iterator;
+template<typename XprType, DirectionType Direction> class subvector_stl_reverse_iterator;
 template<typename DecompositionType> struct kernel_retval_base;
 template<typename DecompositionType> struct kernel_retval;
 template<typename DecompositionType> struct image_retval_base;
 template<typename DecompositionType> struct image_retval;
 } // end namespace internal
 
 namespace internal {
@@ -175,22 +176,23 @@
 // Provides scalar/packet-wise product and product with accumulation
 // with optional conjugation of the arguments.
 template<typename LhsScalar, typename RhsScalar, bool ConjLhs=false, bool ConjRhs=false> struct conj_helper;
 
 template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_sum_op;
 template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_difference_op;
 template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_conj_product_op;
-template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_min_op;
-template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_max_op;
+template<typename LhsScalar,typename RhsScalar=LhsScalar, int NaNPropagation=PropagateFast> struct scalar_min_op;
+template<typename LhsScalar,typename RhsScalar=LhsScalar, int NaNPropagation=PropagateFast> struct scalar_max_op;
 template<typename Scalar> struct scalar_opposite_op;
 template<typename Scalar> struct scalar_conjugate_op;
 template<typename Scalar> struct scalar_real_op;
 template<typename Scalar> struct scalar_imag_op;
 template<typename Scalar> struct scalar_abs_op;
 template<typename Scalar> struct scalar_abs2_op;
+template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_absolute_difference_op;
 template<typename Scalar> struct scalar_sqrt_op;
 template<typename Scalar> struct scalar_rsqrt_op;
 template<typename Scalar> struct scalar_exp_op;
 template<typename Scalar> struct scalar_log_op;
 template<typename Scalar> struct scalar_cos_op;
 template<typename Scalar> struct scalar_sin_op;
 template<typename Scalar> struct scalar_acos_op;
@@ -199,30 +201,46 @@
 template<typename Scalar> struct scalar_inverse_op;
 template<typename Scalar> struct scalar_square_op;
 template<typename Scalar> struct scalar_cube_op;
 template<typename Scalar, typename NewType> struct scalar_cast_op;
 template<typename Scalar> struct scalar_random_op;
 template<typename Scalar> struct scalar_constant_op;
 template<typename Scalar> struct scalar_identity_op;
-template<typename Scalar,bool iscpx> struct scalar_sign_op;
+template<typename Scalar,bool is_complex, bool is_integer> struct scalar_sign_op;
 template<typename Scalar,typename ScalarExponent> struct scalar_pow_op;
 template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_hypot_op;
 template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_product_op;
 template<typename LhsScalar,typename RhsScalar=LhsScalar> struct scalar_quotient_op;
 
 // SpecialFunctions module
 template<typename Scalar> struct scalar_lgamma_op;
 template<typename Scalar> struct scalar_digamma_op;
 template<typename Scalar> struct scalar_erf_op;
 template<typename Scalar> struct scalar_erfc_op;
+template<typename Scalar> struct scalar_ndtri_op;
 template<typename Scalar> struct scalar_igamma_op;
 template<typename Scalar> struct scalar_igammac_op;
 template<typename Scalar> struct scalar_zeta_op;
 template<typename Scalar> struct scalar_betainc_op;
 
+// Bessel functions in SpecialFunctions module
+template<typename Scalar> struct scalar_bessel_i0_op;
+template<typename Scalar> struct scalar_bessel_i0e_op;
+template<typename Scalar> struct scalar_bessel_i1_op;
+template<typename Scalar> struct scalar_bessel_i1e_op;
+template<typename Scalar> struct scalar_bessel_j0_op;
+template<typename Scalar> struct scalar_bessel_y0_op;
+template<typename Scalar> struct scalar_bessel_j1_op;
+template<typename Scalar> struct scalar_bessel_y1_op;
+template<typename Scalar> struct scalar_bessel_k0_op;
+template<typename Scalar> struct scalar_bessel_k0e_op;
+template<typename Scalar> struct scalar_bessel_k1_op;
+template<typename Scalar> struct scalar_bessel_k1e_op;
+
+
 } // end namespace internal
 
 struct IOFormat;
 
 // Array module
 template<typename _Scalar, int _Rows, int _Cols,
          int _Options = AutoAlign |
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/IndexedViewHelper.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/IndexedViewHelper.h`

 * *Files 5% similar despite different names*

```diff
@@ -74,15 +74,15 @@
 // Extract increment/step at compile time
 template<typename T, typename EnableIf = void> struct get_compile_time_incr {
   enum { value = UndefinedIncr };
 };
 
 // Analogue of std::get<0>(x), but tailored for our needs.
 template<typename T>
-Index first(const T& x) { return x.first(); }
+EIGEN_CONSTEXPR Index first(const T& x) EIGEN_NOEXCEPT { return x.first(); }
 
 // IndexedViewCompatibleType/makeIndexedViewCompatible turn an arbitrary object of type T into something usable by MatrixSlice
 // The generic implementation is a no-op
 template<typename T,int XprSize,typename EnableIf=void>
 struct IndexedViewCompatibleType {
   typedef T type;
 };
@@ -96,16 +96,16 @@
 
 struct SingleRange {
   enum {
     SizeAtCompileTime = 1
   };
   SingleRange(Index val) : m_value(val) {}
   Index operator[](Index) const { return m_value; }
-  Index size() const { return 1; }
-  Index first() const { return m_value; }
+  static EIGEN_CONSTEXPR Index size() EIGEN_NOEXCEPT { return 1; }
+  Index first() const EIGEN_NOEXCEPT { return m_value; }
   Index m_value;
 };
 
 template<> struct get_compile_time_incr<SingleRange> {
   enum { value = 1 }; // 1 or 0 ??
 };
 
@@ -137,17 +137,17 @@
 struct all_t { all_t() {} };
 
 // Convert a symbolic 'all' into a usable range type
 template<int XprSize>
 struct AllRange {
   enum { SizeAtCompileTime = XprSize };
   AllRange(Index size = XprSize) : m_size(size) {}
-  Index operator[](Index i) const { return i; }
-  Index size() const { return m_size.value(); }
-  Index first() const { return 0; }
+  EIGEN_CONSTEXPR Index operator[](Index i) const EIGEN_NOEXCEPT { return i; }
+  EIGEN_CONSTEXPR Index size() const EIGEN_NOEXCEPT { return m_size.value(); }
+  EIGEN_CONSTEXPR Index first() const EIGEN_NOEXCEPT { return 0; }
   variable_if_dynamic<Index,XprSize> m_size;
 };
 
 template<int XprSize>
 struct IndexedViewCompatibleType<all_t,XprSize> {
   typedef AllRange<XprSize> type;
 };
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/IntegralConstant.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/IntegralConstant.h`

 * *Files 4% similar despite different names*

```diff
@@ -48,15 +48,15 @@
   *
   * \sa fix<N>, class VariableAndFixedInt
   */
 template<int N> class FixedInt
 {
 public:
   static const int value = N;
-  operator int() const { return value; }
+  EIGEN_CONSTEXPR operator int() const { return value; }
   FixedInt() {}
   FixedInt( VariableAndFixedInt<N> other) {
     #ifndef EIGEN_INTERNAL_DEBUGGING
     EIGEN_UNUSED_VARIABLE(other);
     #endif
     eigen_internal_assert(int(other)==N);
   }
@@ -73,15 +73,15 @@
   template<int M>
   FixedInt<N%M> operator%( FixedInt<M>) const { return FixedInt<N%M>(); }
   template<int M>
   FixedInt<N|M> operator|( FixedInt<M>) const { return FixedInt<N|M>(); }
   template<int M>
   FixedInt<N&M> operator&( FixedInt<M>) const { return FixedInt<N&M>(); }
 
-#if EIGEN_HAS_CXX14
+#if EIGEN_HAS_CXX14_VARIABLE_TEMPLATES
   // Needed in C++14 to allow fix<N>():
   FixedInt operator() () const { return *this; }
 
   VariableAndFixedInt<N> operator() (int val) const { return VariableAndFixedInt<N>(val); }
 #else
   FixedInt ( FixedInt<N> (*)() ) {}
 #endif
@@ -134,15 +134,15 @@
   static const int value = Default;
 };
 
 template<int N,int Default> struct get_fixed_value<FixedInt<N>,Default> {
   static const int value = N;
 };
 
-#if !EIGEN_HAS_CXX14
+#if !EIGEN_HAS_CXX14_VARIABLE_TEMPLATES
 template<int N,int Default> struct get_fixed_value<FixedInt<N> (*)(),Default> {
   static const int value = N;
 };
 #endif
 
 template<int N,int Default> struct get_fixed_value<VariableAndFixedInt<N>,Default> {
   static const int value = N ;
@@ -150,27 +150,27 @@
 
 template<typename T, int N, int Default>
 struct get_fixed_value<variable_if_dynamic<T,N>,Default> {
   static const int value = N;
 };
 
 template<typename T> EIGEN_DEVICE_FUNC Index get_runtime_value(const T &x) { return x; }
-#if !EIGEN_HAS_CXX14
+#if !EIGEN_HAS_CXX14_VARIABLE_TEMPLATES
 template<int N> EIGEN_DEVICE_FUNC Index get_runtime_value(FixedInt<N> (*)()) { return N; }
 #endif
 
 // Cleanup integer/FixedInt/VariableAndFixedInt/etc types:
 
 // By default, no cleanup:
 template<typename T, int DynamicKey=Dynamic, typename EnableIf=void> struct cleanup_index_type { typedef T type; };
 
 // Convert any integral type (e.g., short, int, unsigned int, etc.) to Eigen::Index
 template<typename T, int DynamicKey> struct cleanup_index_type<T,DynamicKey,typename internal::enable_if<internal::is_integral<T>::value>::type> { typedef Index type; };
 
-#if !EIGEN_HAS_CXX14
+#if !EIGEN_HAS_CXX14_VARIABLE_TEMPLATES
 // In c++98/c++11, fix<N> is a pointer to function that we better cleanup to a true FixedInt<N>:
 template<int N, int DynamicKey> struct cleanup_index_type<FixedInt<N> (*)(), DynamicKey> { typedef FixedInt<N> type; };
 #endif
 
 // If VariableAndFixedInt does not match DynamicKey, then we turn it to a pure compile-time value:
 template<int N, int DynamicKey> struct cleanup_index_type<VariableAndFixedInt<N>, DynamicKey> { typedef FixedInt<N> type; };
 // If VariableAndFixedInt matches DynamicKey, then we turn it to a pure runtime-value (aka Index):
@@ -180,15 +180,15 @@
 template<int N, int DynamicKey> struct cleanup_index_type<std::integral_constant<int,N>, DynamicKey> { typedef FixedInt<N> type; };
 #endif
 
 } // end namespace internal
 
 #ifndef EIGEN_PARSED_BY_DOXYGEN
 
-#if EIGEN_HAS_CXX14
+#if EIGEN_HAS_CXX14_VARIABLE_TEMPLATES
 template<int N>
 static const internal::FixedInt<N> fix{};
 #else
 template<int N>
 inline internal::FixedInt<N> fix() { return internal::FixedInt<N>(); }
 
 // The generic typename T is mandatory. Otherwise, a code like fix<N> could refer to either the function above or this next overload.
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/MKL_support.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/MKL_support.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/Macros.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/Macros.h`

 * *Files 8% similar despite different names*

```diff
@@ -12,16 +12,16 @@
 #define EIGEN_MACROS_H
 
 //------------------------------------------------------------------------------------------
 // Eigen version and basic defaults
 //------------------------------------------------------------------------------------------
 
 #define EIGEN_WORLD_VERSION 3
-#define EIGEN_MAJOR_VERSION 3
-#define EIGEN_MINOR_VERSION 90
+#define EIGEN_MAJOR_VERSION 4
+#define EIGEN_MINOR_VERSION 0
 
 #define EIGEN_VERSION_AT_LEAST(x,y,z) (EIGEN_WORLD_VERSION>x || (EIGEN_WORLD_VERSION>=x && \
                                       (EIGEN_MAJOR_VERSION>y || (EIGEN_MAJOR_VERSION>=y && \
                                                                  EIGEN_MINOR_VERSION>=z))))
 
 #ifdef EIGEN_DEFAULT_TO_ROW_MAJOR
 #define EIGEN_DEFAULT_MATRIX_STORAGE_ORDER_OPTION Eigen::RowMajor
@@ -68,14 +68,20 @@
 /// \internal EIGEN_COMP_CLANG set to major+minor version (e.g., 307 for clang 3.7) if the compiler is clang
 #if defined(__clang__)
   #define EIGEN_COMP_CLANG (__clang_major__*100+__clang_minor__)
 #else
   #define EIGEN_COMP_CLANG 0
 #endif
 
+/// \internal EIGEN_COMP_CASTXML set to 1 if being preprocessed by CastXML
+#if defined(__castxml__)
+  #define EIGEN_COMP_CASTXML 1
+#else
+  #define EIGEN_COMP_CASTXML 0
+#endif
 
 /// \internal EIGEN_COMP_LLVM set to 1 if the compiler backend is llvm
 #if defined(__llvm__)
   #define EIGEN_COMP_LLVM 1
 #else
   #define EIGEN_COMP_LLVM 0
 #endif
@@ -152,16 +158,16 @@
   #define EIGEN_COMP_MSVC_STRICT _MSC_VER
 #else
   #define EIGEN_COMP_MSVC_STRICT 0
 #endif
 
 /// \internal EIGEN_COMP_IBM set to xlc version if the compiler is IBM XL C++
 // XLC   version
-// 3.1   0x0301	
-// 4.5   0x0405	
+// 3.1   0x0301
+// 4.5   0x0405
 // 5.0   0x0500
 // 12.1  0x0C01
 #if defined(__IBMCPP__) || defined(__xlc__) || defined(__ibmxl__)
   #define EIGEN_COMP_IBM __xlC__
 #else
   #define EIGEN_COMP_IBM 0
 #endif
@@ -176,15 +182,15 @@
 /// \internal EIGEN_COMP_ARM set to 1 if the compiler is ARM Compiler
 #if defined(__CC_ARM) || defined(__ARMCC_VERSION)
   #define EIGEN_COMP_ARM 1
 #else
   #define EIGEN_COMP_ARM 0
 #endif
 
-/// \internal EIGEN_COMP_ARM set to 1 if the compiler is ARM Compiler
+/// \internal EIGEN_COMP_EMSCRIPTEN set to 1 if the compiler is Emscripten Compiler
 #if defined(__EMSCRIPTEN__)
   #define EIGEN_COMP_EMSCRIPTEN 1
 #else
   #define EIGEN_COMP_EMSCRIPTEN 0
 #endif
 
 
@@ -216,15 +222,15 @@
 
 
 //------------------------------------------------------------------------------------------
 // Architecture identification, EIGEN_ARCH_*
 //------------------------------------------------------------------------------------------
 
 
-#if defined(__x86_64__) || defined(_M_X64) || defined(__amd64)
+#if defined(__x86_64__) || (defined(_M_X64) && !defined(_M_ARM64EC)) || defined(__amd64)
   #define EIGEN_ARCH_x86_64 1
 #else
   #define EIGEN_ARCH_x86_64 0
 #endif
 
 #if defined(__i386__) || defined(_M_IX86) || defined(_X86_) || defined(__i386)
   #define EIGEN_ARCH_i386 1
@@ -242,26 +248,69 @@
 #if defined(__arm__)
   #define EIGEN_ARCH_ARM 1
 #else
   #define EIGEN_ARCH_ARM 0
 #endif
 
 /// \internal EIGEN_ARCH_ARM64 set to 1 if the architecture is ARM64
-#if defined(__aarch64__)
+#if defined(__aarch64__) || defined(_M_ARM64) || defined(_M_ARM64EC)
   #define EIGEN_ARCH_ARM64 1
 #else
   #define EIGEN_ARCH_ARM64 0
 #endif
 
+/// \internal EIGEN_ARCH_ARM_OR_ARM64 set to 1 if the architecture is ARM or ARM64
 #if EIGEN_ARCH_ARM || EIGEN_ARCH_ARM64
   #define EIGEN_ARCH_ARM_OR_ARM64 1
 #else
   #define EIGEN_ARCH_ARM_OR_ARM64 0
 #endif
 
+/// \internal EIGEN_ARCH_ARMV8 set to 1 if the architecture is armv8 or greater.
+#if EIGEN_ARCH_ARM_OR_ARM64 && defined(__ARM_ARCH) && __ARM_ARCH >= 8
+#define EIGEN_ARCH_ARMV8 1
+#else
+#define EIGEN_ARCH_ARMV8 0
+#endif
+
+
+/// \internal EIGEN_HAS_ARM64_FP16 set to 1 if the architecture provides an IEEE
+/// compliant Arm fp16 type
+#if EIGEN_ARCH_ARM64
+  #ifndef EIGEN_HAS_ARM64_FP16
+    #if defined(__ARM_FP16_FORMAT_IEEE)
+      #define EIGEN_HAS_ARM64_FP16 1
+    #else
+      #define EIGEN_HAS_ARM64_FP16 0
+    #endif
+  #endif
+#endif
+
+/// \internal EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC set to 1 if the architecture
+/// supports Neon vector intrinsics for fp16.
+#if EIGEN_ARCH_ARM64
+  #ifndef EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC
+    #if defined(__ARM_FEATURE_FP16_VECTOR_ARITHMETIC)
+      #define EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC 1
+    #else
+      #define EIGEN_HAS_ARM64_FP16_VECTOR_ARITHMETIC 0
+    #endif
+  #endif
+#endif
+
+/// \internal EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC set to 1 if the architecture
+/// supports Neon scalar intrinsics for fp16.
+#if EIGEN_ARCH_ARM64
+  #ifndef EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC
+    #if defined(__ARM_FEATURE_FP16_SCALAR_ARITHMETIC)
+      #define EIGEN_HAS_ARM64_FP16_SCALAR_ARITHMETIC 1
+    #endif
+  #endif
+#endif
+
 /// \internal EIGEN_ARCH_MIPS set to 1 if the architecture is MIPS
 #if defined(__mips__) || defined(__mips)
   #define EIGEN_ARCH_MIPS 1
 #else
   #define EIGEN_ARCH_MIPS 0
 #endif
 
@@ -436,16 +485,35 @@
   // ++ host_defines.h which contains the defines for the __host__ and __device__ macros
   #include <hip/hip_runtime.h>
 
   #if defined(__HIP_DEVICE_COMPILE__)
     // analogous to EIGEN_CUDA_ARCH, but for HIP
     #define EIGEN_HIP_DEVICE_COMPILE __HIP_DEVICE_COMPILE__
   #endif
+
+  // For HIP (ROCm 3.5 and higher), we need to explicitly set the launch_bounds attribute
+  // value to 1024. The compiler assigns a default value of 256 when the attribute is not
+  // specified. This results in failures on the HIP platform, for cases when a GPU kernel
+  // without an explicit launch_bounds attribute is called with a threads_per_block value
+  // greater than 256.
+  //
+  // This is a regression in functioanlity and is expected to be fixed within the next
+  // couple of ROCm releases (compiler will go back to using 1024 value as the default)
+  //
+  // In the meantime, we will use a "only enabled for HIP" macro to set the launch_bounds
+  // attribute.
+
+  #define EIGEN_HIP_LAUNCH_BOUNDS_1024 __launch_bounds__(1024)
+
 #endif
 
+#if !defined(EIGEN_HIP_LAUNCH_BOUNDS_1024)
+#define EIGEN_HIP_LAUNCH_BOUNDS_1024
+#endif // !defined(EIGEN_HIP_LAUNCH_BOUNDS_1024)
+
 // Unify CUDA/HIPCC
 
 #if defined(EIGEN_CUDACC) || defined(EIGEN_HIPCC)
 //
 // If either EIGEN_CUDACC or EIGEN_HIPCC is defined, then define EIGEN_GPUCC
 //
 #define EIGEN_GPUCC
@@ -533,26 +601,52 @@
                               || (defined(__apple_build_version__) && (__apple_build_version__ < 9000000)))  \
       || EIGEN_COMP_GNUC_STRICT && EIGEN_COMP_GNUC<49)
 #define EIGEN_HAS_STATIC_ARRAY_TEMPLATE 1
 #else
 #define EIGEN_HAS_STATIC_ARRAY_TEMPLATE 0
 #endif
 
+// The macro EIGEN_CPLUSPLUS is a replacement for __cplusplus/_MSVC_LANG that
+// works for both platforms, indicating the C++ standard version number.
+//
+// With MSVC, without defining /Zc:__cplusplus, the __cplusplus macro will
+// report 199711L regardless of the language standard specified via /std.
+// We need to rely on _MSVC_LANG instead, which is only available after
+// VS2015.3.
+#if EIGEN_COMP_MSVC_LANG > 0
+#define EIGEN_CPLUSPLUS EIGEN_COMP_MSVC_LANG
+#elif EIGEN_COMP_MSVC >= 1900
+#define EIGEN_CPLUSPLUS 201103L
+#elif defined(__cplusplus)
+#define EIGEN_CPLUSPLUS __cplusplus
+#else
+#define EIGEN_CPLUSPLUS 0
+#endif
 
 // The macro EIGEN_COMP_CXXVER defines the c++ verson expected by the compiler.
 // For instance, if compiling with gcc and -std=c++17, then EIGEN_COMP_CXXVER
 // is defined to 17.
-#if   (defined(__cplusplus) && (__cplusplus >  201402L) || EIGEN_COMP_MSVC_LANG > 201402L)
-#define EIGEN_COMP_CXXVER 17
-#elif (defined(__cplusplus) && (__cplusplus >  201103L) || EIGEN_COMP_MSVC >= 1910)
-#define EIGEN_COMP_CXXVER 14
-#elif (defined(__cplusplus) && (__cplusplus >= 201103L) || EIGEN_COMP_MSVC >= 1900)
-#define EIGEN_COMP_CXXVER 11
-#else
-#define EIGEN_COMP_CXXVER 03
+#if EIGEN_CPLUSPLUS > 201703L
+  #define EIGEN_COMP_CXXVER 20
+#elif EIGEN_CPLUSPLUS > 201402L
+  #define EIGEN_COMP_CXXVER 17
+#elif EIGEN_CPLUSPLUS > 201103L
+  #define EIGEN_COMP_CXXVER 14
+#elif EIGEN_CPLUSPLUS >= 201103L
+  #define EIGEN_COMP_CXXVER 11
+#else
+  #define EIGEN_COMP_CXXVER 03
+#endif
+
+#ifndef EIGEN_HAS_CXX14_VARIABLE_TEMPLATES
+  #if defined(__cpp_variable_templates) && __cpp_variable_templates >= 201304 && EIGEN_MAX_CPP_VER>=14
+    #define EIGEN_HAS_CXX14_VARIABLE_TEMPLATES 1
+  #else
+    #define EIGEN_HAS_CXX14_VARIABLE_TEMPLATES 0
+  #endif
 #endif
 
 
 // The macros EIGEN_HAS_CXX?? defines a rough estimate of available c++ features
 // but in practice we should not rely on them but rather on the availabilty of
 // individual features as defined later.
 // This is why there is no EIGEN_HAS_CXX17.
@@ -569,16 +663,15 @@
 #define EIGEN_HAS_CXX14 0
 #endif
 
 // Do we support r-value references?
 #ifndef EIGEN_HAS_RVALUE_REFERENCES
 #if EIGEN_MAX_CPP_VER>=11 && \
     (__has_feature(cxx_rvalue_references) || \
-    (defined(__cplusplus) && __cplusplus >= 201103L) || \
-    (EIGEN_COMP_MSVC >= 1600))
+     (EIGEN_COMP_CXXVER >= 11) || (EIGEN_COMP_MSVC >= 1600))
   #define EIGEN_HAS_RVALUE_REFERENCES 1
 #else
   #define EIGEN_HAS_RVALUE_REFERENCES 0
 #endif
 #endif
 
 // Does the compiler support C99?
@@ -593,25 +686,42 @@
   #define EIGEN_HAS_C99_MATH 1
 #else
   #define EIGEN_HAS_C99_MATH 0
 #endif
 #endif
 
 // Does the compiler support result_of?
-// It's likely that MSVC 2013 supports result_of but I couldn't not find a good source for that,
-// so let's be conservative.
+// result_of was deprecated in c++17 and removed in c++ 20
 #ifndef EIGEN_HAS_STD_RESULT_OF
-#if EIGEN_MAX_CPP_VER>=11 && \
-    (__has_feature(cxx_lambdas) || (defined(__cplusplus) && __cplusplus >= 201103L) || EIGEN_COMP_MSVC >= 1900)
+#if EIGEN_HAS_CXX11 && EIGEN_COMP_CXXVER < 17
 #define EIGEN_HAS_STD_RESULT_OF 1
 #else
 #define EIGEN_HAS_STD_RESULT_OF 0
 #endif
 #endif
 
+// Does the compiler support std::hash?
+#ifndef EIGEN_HAS_STD_HASH
+// The std::hash struct is defined in C++11 but is not labelled as a __device__
+// function and is not constexpr, so cannot be used on device.
+#if EIGEN_HAS_CXX11 && !defined(EIGEN_GPU_COMPILE_PHASE)
+#define EIGEN_HAS_STD_HASH 1
+#else
+#define EIGEN_HAS_STD_HASH 0
+#endif
+#endif  // EIGEN_HAS_STD_HASH
+
+#ifndef EIGEN_HAS_STD_INVOKE_RESULT
+#if EIGEN_MAX_CPP_VER >= 17 && EIGEN_COMP_CXXVER >= 17
+#define EIGEN_HAS_STD_INVOKE_RESULT 1
+#else
+#define EIGEN_HAS_STD_INVOKE_RESULT 0
+#endif
+#endif
+
 #ifndef EIGEN_HAS_ALIGNAS
 #if EIGEN_MAX_CPP_VER>=11 && EIGEN_HAS_CXX11 &&   \
       (     __has_feature(cxx_alignas)            \
         ||  EIGEN_HAS_CXX14                       \
         || (EIGEN_COMP_MSVC >= 1800)              \
         || (EIGEN_GNUC_AT_LEAST(4,8))             \
         || (EIGEN_COMP_CLANG>=305)                \
@@ -636,102 +746,106 @@
 #else
 #define EIGEN_HAS_TYPE_TRAITS 0
 #endif
 #endif
 
 // Does the compiler support variadic templates?
 #ifndef EIGEN_HAS_VARIADIC_TEMPLATES
-#if EIGEN_MAX_CPP_VER>=11 && (__cplusplus > 199711L || EIGEN_COMP_MSVC >= 1900) \
+#if EIGEN_MAX_CPP_VER>=11 && (EIGEN_COMP_CXXVER >= 11) \
   && (!defined(__NVCC__) || !EIGEN_ARCH_ARM_OR_ARM64 || (EIGEN_COMP_NVCC >= 80000) )
     // ^^ Disable the use of variadic templates when compiling with versions of nvcc older than 8.0 on ARM devices:
     //    this prevents nvcc from crashing when compiling Eigen on Tegra X1
 #define EIGEN_HAS_VARIADIC_TEMPLATES 1
-#elif  EIGEN_MAX_CPP_VER>=11 && (__cplusplus > 199711L || EIGEN_COMP_MSVC >= 1900) && defined(SYCL_DEVICE_ONLY)
+#elif  EIGEN_MAX_CPP_VER>=11 && (EIGEN_COMP_CXXVER >= 11) && defined(SYCL_DEVICE_ONLY)
 #define EIGEN_HAS_VARIADIC_TEMPLATES 1
 #else
 #define EIGEN_HAS_VARIADIC_TEMPLATES 0
 #endif
 #endif
 
 // Does the compiler fully support const expressions? (as in c++14)
 #ifndef EIGEN_HAS_CONSTEXPR
   #if defined(EIGEN_CUDACC)
   // Const expressions are supported provided that c++11 is enabled and we're using either clang or nvcc 7.5 or above
-    #if EIGEN_MAX_CPP_VER>=14 && (__cplusplus > 199711L && (EIGEN_COMP_CLANG || EIGEN_COMP_NVCC >= 70500))
+    #if EIGEN_MAX_CPP_VER>=14 && (EIGEN_COMP_CXXVER >= 11 && (EIGEN_COMP_CLANG || EIGEN_COMP_NVCC >= 70500))
       #define EIGEN_HAS_CONSTEXPR 1
     #endif
-  #elif EIGEN_MAX_CPP_VER>=14 && (__has_feature(cxx_relaxed_constexpr) || (defined(__cplusplus) && __cplusplus >= 201402L) || \
-    (EIGEN_GNUC_AT_LEAST(4,8) && (__cplusplus > 199711L)) || \
-    (EIGEN_COMP_CLANG >= 306 && (__cplusplus > 199711L)))
+  #elif EIGEN_MAX_CPP_VER>=14 && (__has_feature(cxx_relaxed_constexpr) || (EIGEN_COMP_CXXVER >= 14) || \
+    (EIGEN_GNUC_AT_LEAST(4,8) && (EIGEN_COMP_CXXVER >= 11)) || \
+    (EIGEN_COMP_CLANG >= 306 && (EIGEN_COMP_CXXVER >= 11)))
     #define EIGEN_HAS_CONSTEXPR 1
   #endif
 
   #ifndef EIGEN_HAS_CONSTEXPR
     #define EIGEN_HAS_CONSTEXPR 0
   #endif
 
 #endif // EIGEN_HAS_CONSTEXPR
 
+#if EIGEN_HAS_CONSTEXPR
+#define EIGEN_CONSTEXPR constexpr
+#else
+#define EIGEN_CONSTEXPR
+#endif
+
 // Does the compiler support C++11 math?
 // Let's be conservative and enable the default C++11 implementation only if we are sure it exists
 #ifndef EIGEN_HAS_CXX11_MATH
-  #if EIGEN_MAX_CPP_VER>=11 && ((__cplusplus > 201103L) || (__cplusplus >= 201103L) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_MSVC || EIGEN_COMP_ICC)  \
+  #if EIGEN_MAX_CPP_VER>=11 && ((EIGEN_COMP_CXXVER > 11) || (EIGEN_COMP_CXXVER == 11) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_MSVC || EIGEN_COMP_ICC)  \
       && (EIGEN_ARCH_i386_OR_x86_64) && (EIGEN_OS_GNULINUX || EIGEN_OS_WIN_STRICT || EIGEN_OS_MAC))
     #define EIGEN_HAS_CXX11_MATH 1
   #else
     #define EIGEN_HAS_CXX11_MATH 0
   #endif
 #endif
 
 // Does the compiler support proper C++11 containers?
 #ifndef EIGEN_HAS_CXX11_CONTAINERS
   #if    EIGEN_MAX_CPP_VER>=11 && \
-         ((__cplusplus > 201103L) \
-      || ((__cplusplus >= 201103L) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_ICC>=1400)) \
-      || EIGEN_COMP_MSVC >= 1900)
+         ((EIGEN_COMP_CXXVER > 11) \
+      || ((EIGEN_COMP_CXXVER == 11) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_MSVC || EIGEN_COMP_ICC>=1400)))
     #define EIGEN_HAS_CXX11_CONTAINERS 1
   #else
     #define EIGEN_HAS_CXX11_CONTAINERS 0
   #endif
 #endif
 
 // Does the compiler support C++11 noexcept?
 #ifndef EIGEN_HAS_CXX11_NOEXCEPT
   #if    EIGEN_MAX_CPP_VER>=11 && \
          (__has_feature(cxx_noexcept) \
-      || (__cplusplus > 201103L) \
-      || ((__cplusplus >= 201103L) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_ICC>=1400)) \
-      || EIGEN_COMP_MSVC >= 1900)
+      || (EIGEN_COMP_CXXVER > 11) \
+      || ((EIGEN_COMP_CXXVER == 11) && (EIGEN_COMP_GNUC_STRICT || EIGEN_COMP_CLANG || EIGEN_COMP_MSVC || EIGEN_COMP_ICC>=1400)))
     #define EIGEN_HAS_CXX11_NOEXCEPT 1
   #else
     #define EIGEN_HAS_CXX11_NOEXCEPT 0
   #endif
 #endif
 
 #ifndef EIGEN_HAS_CXX11_ATOMIC
   #if    EIGEN_MAX_CPP_VER>=11 && \
          (__has_feature(cxx_atomic) \
-      || (__cplusplus > 201103L) \
-      || ((__cplusplus >= 201103L) && (EIGEN_COMP_MSVC==0 || EIGEN_COMP_MSVC >= 1700)))
+      || (EIGEN_COMP_CXXVER > 11) \
+      || ((EIGEN_COMP_CXXVER == 11) && (EIGEN_COMP_MSVC==0 || EIGEN_COMP_MSVC >= 1700)))
     #define EIGEN_HAS_CXX11_ATOMIC 1
   #else
     #define EIGEN_HAS_CXX11_ATOMIC 0
   #endif
 #endif
 
 #ifndef EIGEN_HAS_CXX11_OVERRIDE_FINAL
   #if    EIGEN_MAX_CPP_VER>=11 && \
-       (__cplusplus >= 201103L || EIGEN_COMP_MSVC >= 1700)
+       (EIGEN_COMP_CXXVER >= 11 || EIGEN_COMP_MSVC >= 1700)
     #define EIGEN_HAS_CXX11_OVERRIDE_FINAL 1
   #else
     #define EIGEN_HAS_CXX11_OVERRIDE_FINAL 0
   #endif
 #endif
 
-// NOTE: the required Apple's clang version is very conservative 
+// NOTE: the required Apple's clang version is very conservative
 //       and it could be that XCode 9 works just fine.
 // NOTE: the MSVC version is based on https://en.cppreference.com/w/cpp/compiler_support
 //       and not tested.
 #ifndef EIGEN_HAS_CXX17_OVERALIGN
 #if EIGEN_MAX_CPP_VER>=17 && EIGEN_COMP_CXXVER>=17 && (                                 \
            (EIGEN_COMP_MSVC >= 1912)                                                    \
         || (EIGEN_GNUC_AT_LEAST(7,0))                                                   \
@@ -753,14 +867,29 @@
     #endif
   #elif defined(__clang__) && defined(__CUDA__) && __has_feature(cxx_relaxed_constexpr)
     // clang++ always considers constexpr functions as implicitly __host__ __device__
     #define EIGEN_CONSTEXPR_ARE_DEVICE_FUNC
   #endif
 #endif
 
+// Does the compiler support the __int128 and __uint128_t extensions for 128-bit
+// integer arithmetic?
+//
+// Clang and GCC define __SIZEOF_INT128__ when these extensions are supported,
+// but we avoid using them in certain cases:
+//
+// * Building using Clang for Windows, where the Clang runtime library has
+//   128-bit support only on LP64 architectures, but Windows is LLP64.
+#ifndef EIGEN_HAS_BUILTIN_INT128
+#if defined(__SIZEOF_INT128__) && !(EIGEN_OS_WIN && EIGEN_COMP_CLANG)
+#define EIGEN_HAS_BUILTIN_INT128 1
+#else
+#define EIGEN_HAS_BUILTIN_INT128 0
+#endif
+#endif
 
 //------------------------------------------------------------------------------------------
 // Preprocessor programming helpers
 //------------------------------------------------------------------------------------------
 
 // This macro can be used to prevent from macro expansion, e.g.:
 //   std::max EIGEN_NOT_A_MACRO(a,b)
@@ -778,15 +907,15 @@
 #define EIGEN_MAKESTRING2(a) #a
 #define EIGEN_MAKESTRING(a) EIGEN_MAKESTRING2(a)
 
 // EIGEN_STRONG_INLINE is a stronger version of the inline, using __forceinline on MSVC,
 // but it still doesn't use GCC's always_inline. This is useful in (common) situations where MSVC needs forceinline
 // but GCC is still doing fine with just inline.
 #ifndef EIGEN_STRONG_INLINE
-#if EIGEN_COMP_MSVC || EIGEN_COMP_ICC
+#if (EIGEN_COMP_MSVC || EIGEN_COMP_ICC) && !defined(EIGEN_GPUCC)
 #define EIGEN_STRONG_INLINE __forceinline
 #else
 #define EIGEN_STRONG_INLINE inline
 #endif
 #endif
 
 // EIGEN_ALWAYS_INLINE is the stronget, it has the effect of making the function inline and adding every possible
@@ -835,17 +964,17 @@
   #endif
 #endif
 
 #if defined(SYCL_DEVICE_ONLY)
   #ifndef EIGEN_DONT_VECTORIZE
     #define EIGEN_DONT_VECTORIZE
   #endif
-  #define EIGEN_DEVICE_FUNC __attribute__((always_inline))
+  #define EIGEN_DEVICE_FUNC __attribute__((flatten)) __attribute__((always_inline))
 // All functions callable from CUDA/HIP code must be qualified with __device__
-#elif defined(EIGEN_GPUCC) 
+#elif defined(EIGEN_GPUCC)
     #define EIGEN_DEVICE_FUNC __host__ __device__
 #else
   #define EIGEN_DEVICE_FUNC
 #endif
 
 
 // this macro allows to get rid of linking errors about multiply defined functions.
@@ -864,15 +993,15 @@
 // eigen_plain_assert is where we implement the workaround for the assert() bug in GCC <= 4.3, see bug 89
 #ifdef EIGEN_NO_DEBUG
   #ifdef SYCL_DEVICE_ONLY // used to silence the warning on SYCL device
     #define eigen_plain_assert(x) EIGEN_UNUSED_VARIABLE(x)
   #else
     #define eigen_plain_assert(x)
   #endif
-#else 
+#else
   #if EIGEN_SAFE_TO_USE_STANDARD_ASSERT_MACRO
     namespace Eigen {
     namespace internal {
     inline bool copy_bool(bool b) { return b; }
     }
     }
     #define eigen_plain_assert(x) assert(x)
@@ -951,14 +1080,84 @@
     #define EIGEN_ASM_COMMENT(X)  __asm__("#" X)
   #else
     #define EIGEN_ASM_COMMENT(X)
   #endif
 #endif
 
 
+// Acts as a barrier preventing operations involving `X` from crossing. This
+// occurs, for example, in the fast rounding trick where a magic constant is
+// added then subtracted, which is otherwise compiled away with -ffast-math.
+//
+// See bug 1674
+#if !defined(EIGEN_OPTIMIZATION_BARRIER)
+  #if EIGEN_COMP_GNUC
+    // According to https://gcc.gnu.org/onlinedocs/gcc/Constraints.html:
+    //   X: Any operand whatsoever.
+    //   r: A register operand is allowed provided that it is in a general
+    //      register.
+    //   g: Any register, memory or immediate integer operand is allowed, except
+    //      for registers that are not general registers.
+    //   w: (AArch32/AArch64) Floating point register, Advanced SIMD vector
+    //      register or SVE vector register.
+    //   x: (SSE) Any SSE register.
+    //      (AArch64) Like w, but restricted to registers 0 to 15 inclusive.
+    //   v: (PowerPC) An Altivec vector register.
+    //   wa:(PowerPC) A VSX register.
+    //
+    // "X" (uppercase) should work for all cases, though this seems to fail for
+    // some versions of GCC for arm/aarch64 with
+    //   "error: inconsistent operand constraints in an 'asm'"
+    // Clang x86_64/arm/aarch64 seems to require "g" to support both scalars and
+    // vectors, otherwise
+    //   "error: non-trivial scalar-to-vector conversion, possible invalid
+    //    constraint for vector type"
+    //
+    // GCC for ppc64le generates an internal compiler error with x/X/g.
+    // GCC for AVX generates an internal compiler error with X.
+    //
+    // Tested on icc/gcc/clang for sse, avx, avx2, avx512dq
+    //           gcc for arm, aarch64,
+    //           gcc for ppc64le,
+    // both vectors and scalars.
+    //
+    // Note that this is restricted to plain types - this will not work
+    // directly for std::complex<T>, Eigen::half, Eigen::bfloat16. For these,
+    // you will need to apply to the underlying POD type.
+    #if EIGEN_ARCH_PPC && EIGEN_COMP_GNUC_STRICT
+      // This seems to be broken on clang.  Packet4f is loaded into a single
+      //   register rather than a vector, zeroing out some entries.  Integer
+      //   types also generate a compile error.
+      // General, Altivec, VSX.
+      #define EIGEN_OPTIMIZATION_BARRIER(X)  __asm__  ("" : "+r,v,wa" (X));
+    #elif EIGEN_ARCH_ARM_OR_ARM64
+      // General, NEON.
+      // Clang doesn't like "r",
+      //    error: non-trivial scalar-to-vector conversion, possible invalid
+      //           constraint for vector type
+      // GCC < 5 doesn't like "g",
+      //    error: 'asm' operand requires impossible reload
+      #if EIGEN_COMP_GNUC_STRICT && EIGEN_GNUC_AT_MOST(5, 0)
+        #define EIGEN_OPTIMIZATION_BARRIER(X)  __asm__  ("" : "+r,w" (X));
+      #else
+        #define EIGEN_OPTIMIZATION_BARRIER(X)  __asm__  ("" : "+g,w" (X));
+      #endif
+    #elif EIGEN_ARCH_i386_OR_x86_64
+      // General, SSE.
+      #define EIGEN_OPTIMIZATION_BARRIER(X)  __asm__  ("" : "+g,x" (X));
+    #else
+      // Not implemented for other architectures.
+      #define EIGEN_OPTIMIZATION_BARRIER(X)
+    #endif
+  #else
+    // Not implemented for other compilers.
+    #define EIGEN_OPTIMIZATION_BARRIER(X)
+  #endif
+#endif
+
 #if EIGEN_COMP_MSVC
   // NOTE MSVC often gives C4127 warnings with compiletime if statements. See bug 1362.
   // This workaround is ugly, but it does the job.
 #  define EIGEN_CONST_CONDITIONAL(cond)  (void)0, cond
 #else
 #  define EIGEN_CONST_CONDITIONAL(cond)  cond
 #endif
@@ -986,35 +1185,25 @@
 
 
 // When compiling CUDA/HIP device code with NVCC or HIPCC
 // pull in math functions from the global namespace.
 // In host mode, and when device code is compiled with clang,
 // use the std versions.
 #if (defined(EIGEN_CUDA_ARCH) && defined(__NVCC__)) || defined(EIGEN_HIP_DEVICE_COMPILE)
-  #define EIGEN_USING_STD_MATH(FUNC) using ::FUNC;
-#else
-  #define EIGEN_USING_STD_MATH(FUNC) using std::FUNC;
-#endif
-
-
-// When compiling HIP device code with HIPCC, certain functions
-// from the stdlib need to be pulled in from the global namespace
-// (as opposed to from the std:: namespace). This is because HIPCC
-// does not natively support all the std:: routines in device code.
-// Instead it contains header files that declare the corresponding
-// routines in the global namespace such they can be used in device code.
-#if defined(EIGEN_HIP_DEVICE_COMPILE)
   #define EIGEN_USING_STD(FUNC) using ::FUNC;
 #else
   #define EIGEN_USING_STD(FUNC) using std::FUNC;
 #endif
 
-
-#if EIGEN_COMP_MSVC_STRICT && (EIGEN_COMP_MSVC < 1900 || EIGEN_COMP_NVCC)
-  // for older MSVC versions, as well as 1900 && CUDA 8, using the base operator is sufficient (cf Bugs 1000, 1324)
+#if EIGEN_COMP_MSVC_STRICT && (EIGEN_COMP_MSVC < 1900 || (EIGEN_COMP_MSVC == 1900 && EIGEN_COMP_NVCC))
+  // For older MSVC versions, as well as 1900 && CUDA 8, using the base operator is necessary,
+  //   otherwise we get duplicate definition errors
+  // For later MSVC versions, we require explicit operator= definition, otherwise we get
+  //   use of implicitly deleted operator errors.
+  // (cf Bugs 920, 1000, 1324, 2291)
   #define EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived) \
     using Base::operator =;
 #elif EIGEN_COMP_CLANG // workaround clang bug (see http://forum.kde.org/viewtopic.php?f=74&t=102653)
   #define EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived) \
     using Base::operator =; \
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator=(const Derived& other) { Base::operator=(other); return *this; } \
     template <typename OtherDerived> \
@@ -1026,19 +1215,56 @@
     { \
       Base::operator=(other); \
       return *this; \
     }
 #endif
 
 
+/**
+ * \internal
+ * \brief Macro to explicitly define the default copy constructor.
+ * This is necessary, because the implicit definition is deprecated if the copy-assignment is overridden.
+ */
+#if EIGEN_HAS_CXX11
+#define EIGEN_DEFAULT_COPY_CONSTRUCTOR(CLASS) EIGEN_DEVICE_FUNC CLASS(const CLASS&) = default;
+#else
+#define EIGEN_DEFAULT_COPY_CONSTRUCTOR(CLASS)
+#endif
+
+
+
 /** \internal
  * \brief Macro to manually inherit assignment operators.
  * This is necessary, because the implicitly defined assignment operator gets deleted when a custom operator= is defined.
+ * With C++11 or later this also default-implements the copy-constructor
+ */
+#define EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Derived)  \
+    EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived) \
+    EIGEN_DEFAULT_COPY_CONSTRUCTOR(Derived)
+
+/** \internal
+ * \brief Macro to manually define default constructors and destructors.
+ * This is necessary when the copy constructor is re-defined.
+ * For empty helper classes this should usually be protected, to avoid accidentally creating empty objects.
+ *
+ * Hiding the default destructor lead to problems in C++03 mode together with boost::multiprecision
  */
-#define EIGEN_INHERIT_ASSIGNMENT_OPERATORS(Derived) EIGEN_INHERIT_ASSIGNMENT_EQUAL_OPERATOR(Derived)
+#if EIGEN_HAS_CXX11
+#define EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(Derived)  \
+    EIGEN_DEVICE_FUNC Derived() = default; \
+    EIGEN_DEVICE_FUNC ~Derived() = default;
+#else
+#define EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(Derived)  \
+    EIGEN_DEVICE_FUNC Derived() {}; \
+    /* EIGEN_DEVICE_FUNC ~Derived() {}; */
+#endif
+
+
+
+
 
 /**
 * Just a side note. Commenting within defines works only by documenting
 * behind the object (via '!<'). Comments cannot be multi-line and thus
 * we have these extra long lines. What is confusing doxygen over here is
 * that we use '\' and basically have a bunch of typedefs with their
 * documentation in a single line.
@@ -1093,14 +1319,22 @@
 #define EIGEN_SIZE_MAX(a,b) (((int)a == Dynamic || (int)b == Dynamic) ? Dynamic \
                            : ((int)a >= (int)b) ? (int)a : (int)b)
 
 #define EIGEN_LOGICAL_XOR(a,b) (((a) || (b)) && !((a) && (b)))
 
 #define EIGEN_IMPLIES(a,b) (!(a) || (b))
 
+#if EIGEN_HAS_BUILTIN(__builtin_expect) || EIGEN_COMP_GNUC
+#define EIGEN_PREDICT_FALSE(x) (__builtin_expect(x, false))
+#define EIGEN_PREDICT_TRUE(x) (__builtin_expect(false || (x), true))
+#else
+#define EIGEN_PREDICT_FALSE(x) (x)
+#define EIGEN_PREDICT_TRUE(x) (x)
+#endif
+
 // the expression type of a standard coefficient wise binary operation
 #define EIGEN_CWISE_BINARY_RETURN_TYPE(LHS,RHS,OPNAME) \
     CwiseBinaryOp< \
       EIGEN_CAT(EIGEN_CAT(internal::scalar_,OPNAME),_op)< \
           typename internal::traits<LHS>::Scalar, \
           typename internal::traits<RHS>::Scalar \
       >, \
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/Memory.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/Memory.h`

 * *Files 2% similar despite different names*

```diff
@@ -78,15 +78,16 @@
     //
     // "throw_std_bad_alloc" has the EIGEN_DEVICE_FUNC attribute, so it seems that hipcc expects
     // the same on "operator new"
     // Reverting code back to the old version in this #if block for the hipcc compiler
     //
     new int[huge];
     #else
-    ::operator new(huge);
+    void* unused = ::operator new(huge);
+    EIGEN_UNUSED_VARIABLE(unused);
     #endif
   #endif
 }
 
 /*****************************************************************************
 *** Implementation of handmade aligned functions                           ***
 *****************************************************************************/
@@ -209,15 +210,15 @@
 /**
   * \internal
   * \brief Reallocates an aligned block of memory.
   * \throws std::bad_alloc on allocation failure
   */
 inline void* aligned_realloc(void *ptr, std::size_t new_size, std::size_t old_size)
 {
-  EIGEN_UNUSED_VARIABLE(old_size);
+  EIGEN_UNUSED_VARIABLE(old_size)
 
   void *result;
 #if (EIGEN_DEFAULT_ALIGN_BYTES==0) || EIGEN_MALLOC_ALREADY_ALIGNED
   result = std::realloc(ptr,new_size);
 #else
   result = handmade_aligned_realloc(ptr,new_size,old_size);
 #endif
@@ -561,14 +562,25 @@
     {
       std::ptrdiff_t count = (std::ptrdiff_t(end)-std::ptrdiff_t(start)) / sizeof(T);
       std::copy_backward(start, end, target + count);
     }
   }
 };
 
+#if EIGEN_HAS_RVALUE_REFERENCES
+template<typename T> EIGEN_DEVICE_FUNC T* smart_move(T* start, T* end, T* target)
+{
+  return std::move(start, end, target);
+}
+#else
+template<typename T> EIGEN_DEVICE_FUNC T* smart_move(T* start, T* end, T* target)
+{
+  return std::copy(start, end, target);
+}
+#endif
 
 /*****************************************************************************
 *** Implementation of runtime stack allocation (falling back to malloc)    ***
 *****************************************************************************/
 
 // you can overwrite Eigen's default behavior regarding alloca by defining EIGEN_ALLOCA
 // to the appropriate stack allocation function
@@ -775,40 +787,53 @@
 #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign)
 #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)
 #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW
 #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF_VECTORIZABLE_FIXED_SIZE(Scalar,Size)
 
 #else
 
-#if EIGEN_MAX_ALIGN_BYTES!=0
+// HIP does not support new/delete on device.
+#if EIGEN_MAX_ALIGN_BYTES!=0 && !defined(EIGEN_HIP_DEVICE_COMPILE)
   #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign) \
+      EIGEN_DEVICE_FUNC \
       void* operator new(std::size_t size, const std::nothrow_t&) EIGEN_NO_THROW { \
         EIGEN_TRY { return Eigen::internal::conditional_aligned_malloc<NeedsToAlign>(size); } \
         EIGEN_CATCH (...) { return 0; } \
       }
   #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign) \
+      EIGEN_DEVICE_FUNC \
       void *operator new(std::size_t size) { \
         return Eigen::internal::conditional_aligned_malloc<NeedsToAlign>(size); \
       } \
+      EIGEN_DEVICE_FUNC \
       void *operator new[](std::size_t size) { \
         return Eigen::internal::conditional_aligned_malloc<NeedsToAlign>(size); \
       } \
+      EIGEN_DEVICE_FUNC \
       void operator delete(void * ptr) EIGEN_NO_THROW { Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr); } \
+      EIGEN_DEVICE_FUNC \
       void operator delete[](void * ptr) EIGEN_NO_THROW { Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr); } \
+      EIGEN_DEVICE_FUNC \
       void operator delete(void * ptr, std::size_t /* sz */) EIGEN_NO_THROW { Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr); } \
+      EIGEN_DEVICE_FUNC \
       void operator delete[](void * ptr, std::size_t /* sz */) EIGEN_NO_THROW { Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr); } \
       /* in-place new and delete. since (at least afaik) there is no actual   */ \
       /* memory allocated we can safely let the default implementation handle */ \
       /* this particular case. */ \
+      EIGEN_DEVICE_FUNC \
       static void *operator new(std::size_t size, void *ptr) { return ::operator new(size,ptr); } \
+      EIGEN_DEVICE_FUNC \
       static void *operator new[](std::size_t size, void* ptr) { return ::operator new[](size,ptr); } \
+      EIGEN_DEVICE_FUNC \
       void operator delete(void * memory, void *ptr) EIGEN_NO_THROW { return ::operator delete(memory,ptr); } \
+      EIGEN_DEVICE_FUNC \
       void operator delete[](void * memory, void *ptr) EIGEN_NO_THROW { return ::operator delete[](memory,ptr); } \
       /* nothrow-new (returns zero instead of std::bad_alloc) */ \
       EIGEN_MAKE_ALIGNED_OPERATOR_NEW_NOTHROW(NeedsToAlign) \
+      EIGEN_DEVICE_FUNC \
       void operator delete(void *ptr, const std::nothrow_t&) EIGEN_NO_THROW { \
         Eigen::internal::conditional_aligned_free<NeedsToAlign>(ptr); \
       } \
       typedef void eigen_aligned_operator_new_marker_type;
 #else
   #define EIGEN_MAKE_ALIGNED_OPERATOR_NEW_IF(NeedsToAlign)
 #endif
@@ -1043,28 +1068,40 @@
   l3 *= 1024;
 }
 
 inline void queryCacheSizes_intel(int& l1, int& l2, int& l3, int max_std_funcs)
 {
   if(max_std_funcs>=4)
     queryCacheSizes_intel_direct(l1,l2,l3);
-  else
+  else if(max_std_funcs>=2)
     queryCacheSizes_intel_codes(l1,l2,l3);
+  else
+    l1 = l2 = l3 = 0;
 }
 
 inline void queryCacheSizes_amd(int& l1, int& l2, int& l3)
 {
   int abcd[4];
   abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
-  EIGEN_CPUID(abcd,0x80000005,0);
-  l1 = (abcd[2] >> 24) * 1024; // C[31:24] = L1 size in KB
-  abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
-  EIGEN_CPUID(abcd,0x80000006,0);
-  l2 = (abcd[2] >> 16) * 1024; // C[31;16] = l2 cache size in KB
-  l3 = ((abcd[3] & 0xFFFC000) >> 18) * 512 * 1024; // D[31;18] = l3 cache size in 512KB
+  
+  // First query the max supported function.
+  EIGEN_CPUID(abcd,0x80000000,0);
+  if(static_cast<numext::uint32_t>(abcd[0]) >= static_cast<numext::uint32_t>(0x80000006))
+  {
+    EIGEN_CPUID(abcd,0x80000005,0);
+    l1 = (abcd[2] >> 24) * 1024; // C[31:24] = L1 size in KB
+    abcd[0] = abcd[1] = abcd[2] = abcd[3] = 0;
+    EIGEN_CPUID(abcd,0x80000006,0);
+    l2 = (abcd[2] >> 16) * 1024; // C[31;16] = l2 cache size in KB
+    l3 = ((abcd[3] & 0xFFFC000) >> 18) * 512 * 1024; // D[31;18] = l3 cache size in 512KB
+  }
+  else
+  {
+    l1 = l2 = l3 = 0;
+  }
 }
 #endif
 
 /** \internal
  * Queries and returns the cache sizes in Bytes of the L1, L2, and L3 data caches respectively */
 inline void queryCacheSizes(int& l1, int& l2, int& l3)
 {
@@ -1072,15 +1109,15 @@
   int abcd[4];
   const int GenuineIntel[] = {0x756e6547, 0x49656e69, 0x6c65746e};
   const int AuthenticAMD[] = {0x68747541, 0x69746e65, 0x444d4163};
   const int AMDisbetter_[] = {0x69444d41, 0x74656273, 0x21726574}; // "AMDisbetter!"
 
   // identify the CPU vendor
   EIGEN_CPUID(abcd,0x0,0);
-  int max_std_funcs = abcd[1];
+  int max_std_funcs = abcd[0];
   if(cpuid_is_vendor(abcd,GenuineIntel))
     queryCacheSizes_intel(l1,l2,l3,max_std_funcs);
   else if(cpuid_is_vendor(abcd,AuthenticAMD) || cpuid_is_vendor(abcd,AMDisbetter_))
     queryCacheSizes_amd(l1,l2,l3);
   else
     // by default let's use Intel's API
     queryCacheSizes_intel(l1,l2,l3,max_std_funcs);
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/Meta.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/Meta.h`

 * *Files 26% similar despite different names*

```diff
@@ -21,16 +21,48 @@
 
  #if defined(EIGEN_HIP_DEVICE_COMPILE)
   #include "Eigen/src/Core/arch/HIP/hcc/math_constants.h"
   #endif
 
 #endif
 
-#if EIGEN_COMP_ICC>=1600 &&  __cplusplus >= 201103L
+// Recent versions of ICC require <cstdint> for pointer types below.
+#define EIGEN_ICC_NEEDS_CSTDINT (EIGEN_COMP_ICC>=1600 && EIGEN_COMP_CXXVER >= 11)
+
+// Define portable (u)int{32,64} types
+#if EIGEN_HAS_CXX11 || EIGEN_ICC_NEEDS_CSTDINT
 #include <cstdint>
+namespace Eigen {
+namespace numext {
+typedef std::uint8_t  uint8_t;
+typedef std::int8_t   int8_t;
+typedef std::uint16_t uint16_t;
+typedef std::int16_t  int16_t;
+typedef std::uint32_t uint32_t;
+typedef std::int32_t  int32_t;
+typedef std::uint64_t uint64_t;
+typedef std::int64_t  int64_t;
+}
+}
+#else
+// Without c++11, all compilers able to compile Eigen also
+// provide the C99 stdint.h header file.
+#include <stdint.h>
+namespace Eigen {
+namespace numext {
+typedef ::uint8_t  uint8_t;
+typedef ::int8_t   int8_t;
+typedef ::uint16_t uint16_t;
+typedef ::int16_t  int16_t;
+typedef ::uint32_t uint32_t;
+typedef ::int32_t  int32_t;
+typedef ::uint64_t uint64_t;
+typedef ::int64_t  int64_t;
+}
+}
 #endif
 
 namespace Eigen {
 
 typedef EIGEN_DEFAULT_DENSE_INDEX_TYPE DenseIndex;
 
 /**
@@ -48,34 +80,41 @@
   * This file contains generic metaprogramming classes which are not specifically related to Eigen.
   * \note In case you wonder, yes we're aware that Boost already provides all these features,
   * we however don't want to add a dependency to Boost.
   */
 
 // Only recent versions of ICC complain about using ptrdiff_t to hold pointers,
 // and older versions do not provide *intptr_t types.
-#if EIGEN_COMP_ICC>=1600 &&  __cplusplus >= 201103L
+#if EIGEN_ICC_NEEDS_CSTDINT
 typedef std::intptr_t  IntPtr;
 typedef std::uintptr_t UIntPtr;
 #else
 typedef std::ptrdiff_t IntPtr;
 typedef std::size_t UIntPtr;
 #endif
+#undef EIGEN_ICC_NEEDS_CSTDINT
 
 struct true_type {  enum { value = 1 }; };
 struct false_type { enum { value = 0 }; };
 
+template<bool Condition>
+struct bool_constant;
+
+template<>
+struct bool_constant<true> : true_type {};
+
+template<>
+struct bool_constant<false> : false_type {};
+
 template<bool Condition, typename Then, typename Else>
 struct conditional { typedef Then type; };
 
 template<typename Then, typename Else>
 struct conditional <false, Then, Else> { typedef Else type; };
 
-template<typename T, typename U> struct is_same { enum { value = 0 }; };
-template<typename T> struct is_same<T,T> { enum { value = 1 }; };
-
 template<typename T> struct remove_reference { typedef T type; };
 template<typename T> struct remove_reference<T&> { typedef T type; };
 
 template<typename T> struct remove_pointer { typedef T type; };
 template<typename T> struct remove_pointer<T*> { typedef T type; };
 template<typename T> struct remove_pointer<T*const> { typedef T type; };
 
@@ -102,14 +141,20 @@
 template<> struct is_arithmetic<signed short>  { enum { value = true }; };
 template<> struct is_arithmetic<unsigned short>{ enum { value = true }; };
 template<> struct is_arithmetic<signed int>    { enum { value = true }; };
 template<> struct is_arithmetic<unsigned int>  { enum { value = true }; };
 template<> struct is_arithmetic<signed long>   { enum { value = true }; };
 template<> struct is_arithmetic<unsigned long> { enum { value = true }; };
 
+template<typename T, typename U> struct is_same { enum { value = 0 }; };
+template<typename T> struct is_same<T,T> { enum { value = 1 }; };
+
+template< class T >
+struct is_void : is_same<void, typename remove_const<T>::type> {};
+
 #if EIGEN_HAS_CXX11
 template<> struct is_arithmetic<signed long long>   { enum { value = true }; };
 template<> struct is_arithmetic<unsigned long long> { enum { value = true }; };
 using std::is_integral;
 #else
 template<typename T> struct is_integral               { enum { value = false }; };
 template<> struct is_integral<bool>                   { enum { value = true }; };
@@ -144,28 +189,43 @@
 template<> struct make_unsigned<unsigned int>     { typedef unsigned int type; };
 template<> struct make_unsigned<signed long>      { typedef unsigned long type; };
 template<> struct make_unsigned<unsigned long>    { typedef unsigned long type; };
 #if EIGEN_COMP_MSVC
 template<> struct make_unsigned<signed __int64>   { typedef unsigned __int64 type; };
 template<> struct make_unsigned<unsigned __int64> { typedef unsigned __int64 type; };
 #endif
+
+// Some platforms define int64_t as `long long` even for C++03, where
+// `long long` is not guaranteed by the standard. In this case we are missing
+// the definition for make_unsigned. If we just define it, we run into issues
+// where `long long` doesn't exist in some compilers for C++03. We therefore add
+// the specialization for these platforms only.
+#if EIGEN_OS_MAC || EIGEN_COMP_MINGW
+template<> struct make_unsigned<unsigned long long> { typedef unsigned long long type; };
+template<> struct make_unsigned<long long>          { typedef unsigned long long type; };
+#endif
 #endif
 
 template <typename T> struct add_const { typedef const T type; };
 template <typename T> struct add_const<T&> { typedef T& type; };
 
 template <typename T> struct is_const { enum { value = 0 }; };
 template <typename T> struct is_const<T const> { enum { value = 1 }; };
 
 template<typename T> struct add_const_on_value_type            { typedef const T type;  };
 template<typename T> struct add_const_on_value_type<T&>        { typedef T const& type; };
 template<typename T> struct add_const_on_value_type<T*>        { typedef T const* type; };
 template<typename T> struct add_const_on_value_type<T* const>  { typedef T const* const type; };
 template<typename T> struct add_const_on_value_type<T const* const>  { typedef T const* const type; };
 
+#if EIGEN_HAS_CXX11
+
+using std::is_convertible;
+
+#else
 
 template<typename From, typename To>
 struct is_convertible_impl
 {
 private:
   struct any_conversion
   {
@@ -195,52 +255,60 @@
 
 template<typename From, typename To>
 struct is_convertible
 {
   enum { value = is_convertible_impl<From,To>::value };
 };
 
+template<typename T>
+struct is_convertible<T,T&> { enum { value = false }; };
+
+template<typename T>
+struct is_convertible<const T,const T&> { enum { value = true }; };
+
+#endif
+
 /** \internal Allows to enable/disable an overload
   * according to a compile time condition.
   */
 template<bool Condition, typename T=void> struct enable_if;
 
 template<typename T> struct enable_if<true,T>
 { typedef T type; };
 
-#if defined(EIGEN_GPU_COMPILE_PHASE)
+#if defined(EIGEN_GPU_COMPILE_PHASE) && !EIGEN_HAS_CXX11
 #if !defined(__FLT_EPSILON__)
 #define __FLT_EPSILON__ FLT_EPSILON
 #define __DBL_EPSILON__ DBL_EPSILON
 #endif
 
 namespace device {
 
 template<typename T> struct numeric_limits
 {
   EIGEN_DEVICE_FUNC
-  static T epsilon() { return 0; }
+  static EIGEN_CONSTEXPR T epsilon() { return 0; }
   static T (max)() { assert(false && "Highest not supported for this type"); }
   static T (min)() { assert(false && "Lowest not supported for this type"); }
   static T infinity() { assert(false && "Infinity not supported for this type"); }
   static T quiet_NaN() { assert(false && "quiet_NaN not supported for this type"); }
 };
 template<> struct numeric_limits<float>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static float epsilon() { return __FLT_EPSILON__; }
   EIGEN_DEVICE_FUNC
   static float (max)() {
   #if defined(EIGEN_CUDA_ARCH)
     return CUDART_MAX_NORMAL_F;
   #else
     return HIPRT_MAX_NORMAL_F;
   #endif
   }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static float (min)() { return FLT_MIN; }
   EIGEN_DEVICE_FUNC
   static float infinity() {
   #if defined(EIGEN_CUDA_ARCH)
     return CUDART_INF_F;
   #else
     return HIPRT_INF_F;
@@ -253,19 +321,19 @@
   #else
     return HIPRT_NAN_F;
   #endif
   }
 };
 template<> struct numeric_limits<double>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static double epsilon() { return __DBL_EPSILON__; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static double (max)() { return DBL_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static double (min)() { return DBL_MIN; }
   EIGEN_DEVICE_FUNC
   static double infinity() {
   #if defined(EIGEN_CUDA_ARCH)
     return CUDART_INF;
   #else
     return HIPRT_INF;
@@ -278,70 +346,79 @@
   #else
     return HIPRT_NAN;
   #endif
   }
 };
 template<> struct numeric_limits<int>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int (max)() { return INT_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static int (min)() { return INT_MIN; }
 };
 template<> struct numeric_limits<unsigned int>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned int epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned int (max)() { return UINT_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned int (min)() { return 0; }
 };
 template<> struct numeric_limits<long>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long (max)() { return LONG_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long (min)() { return LONG_MIN; }
 };
 template<> struct numeric_limits<unsigned long>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long (max)() { return ULONG_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long (min)() { return 0; }
 };
 template<> struct numeric_limits<long long>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long long epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long long (max)() { return LLONG_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static long long (min)() { return LLONG_MIN; }
 };
 template<> struct numeric_limits<unsigned long long>
 {
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long long epsilon() { return 0; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long long (max)() { return ULLONG_MAX; }
-  EIGEN_DEVICE_FUNC
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
   static unsigned long long (min)() { return 0; }
 };
+template<> struct numeric_limits<bool>
+{
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  static bool epsilon() { return false; }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  static bool (max)() { return true; }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR 
+  static bool (min)() { return false; }
+};
 
 }
 
-#endif
+#endif // defined(EIGEN_GPU_COMPILE_PHASE) && !EIGEN_HAS_CXX11
 
 /** \internal
   * A base class do disable default copy ctor and copy assignment operator.
   */
 class noncopyable
 {
   EIGEN_DEVICE_FUNC noncopyable(const noncopyable&);
@@ -395,38 +472,76 @@
   *
   * It currently supports:
   *  - any types T defining a member T::size() const
   *  - plain C arrays as T[N]
   *
   */
 template<typename T>
-Index size(const T& x) { return x.size(); }
+EIGEN_CONSTEXPR Index size(const T& x) { return x.size(); }
 
 template<typename T,std::size_t N>
-Index size(const T (&) [N]) { return N; }
+EIGEN_CONSTEXPR Index size(const T (&) [N]) { return N; }
 
 /** \internal
-  * Convenient struct to get the result type of a unary or binary functor.
-  *
-  * It supports both the current STL mechanism (using the result_type member) as well as
-  * upcoming next STL generation (using a templated result member).
-  * If none of these members is provided, then the type of the first argument is returned. FIXME, that behavior is a pretty bad hack.
+  * Convenient struct to get the result type of a nullary, unary, binary, or
+  * ternary functor.
+  * 
+  * Pre C++11:
+  * Supports both a Func::result_type member and templated
+  * Func::result<Func(ArgTypes...)>::type member.
+  * 
+  * If none of these members is provided, then the type of the first
+  * argument is returned.
+  * 
+  * Post C++11:
+  * This uses std::result_of. However, note the `type` member removes
+  * const and converts references/pointers to their corresponding value type.
   */
-#if EIGEN_HAS_STD_RESULT_OF
+#if EIGEN_HAS_STD_INVOKE_RESULT
+template<typename T> struct result_of;
+
+template<typename F, typename... ArgTypes>
+struct result_of<F(ArgTypes...)> {
+  typedef typename std::invoke_result<F, ArgTypes...>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+#elif EIGEN_HAS_STD_RESULT_OF
 template<typename T> struct result_of {
   typedef typename std::result_of<T>::type type1;
   typedef typename remove_all<type1>::type type;
 };
 #else
 template<typename T> struct result_of { };
 
 struct has_none {int a[1];};
 struct has_std_result_type {int a[2];};
 struct has_tr1_result {int a[3];};
 
+template<typename Func, int SizeOf>
+struct nullary_result_of_select {};
+
+template<typename Func>
+struct nullary_result_of_select<Func, sizeof(has_std_result_type)> {typedef typename Func::result_type type;};
+
+template<typename Func>
+struct nullary_result_of_select<Func, sizeof(has_tr1_result)> {typedef typename Func::template result<Func()>::type type;};
+
+template<typename Func>
+struct result_of<Func()> {
+    template<typename T>
+    static has_std_result_type    testFunctor(T const *, typename T::result_type const * = 0);
+    template<typename T>
+    static has_tr1_result         testFunctor(T const *, typename T::template result<T()>::type const * = 0);
+    static has_none               testFunctor(...);
+
+    // note that the following indirection is needed for gcc-3.3
+    enum {FunctorType = sizeof(testFunctor(static_cast<Func*>(0)))};
+    typedef typename nullary_result_of_select<Func, FunctorType>::type type;
+};
+
 template<typename Func, typename ArgType, int SizeOf=sizeof(has_none)>
 struct unary_result_of_select {typedef typename internal::remove_all<ArgType>::type type;};
 
 template<typename Func, typename ArgType>
 struct unary_result_of_select<Func, ArgType, sizeof(has_std_result_type)> {typedef typename Func::result_type type;};
 
 template<typename Func, typename ArgType>
@@ -488,14 +603,53 @@
     static has_tr1_result         testFunctor(T const *, typename T::template result<T(ArgType0,ArgType1,ArgType2)>::type const * = 0);
     static has_none               testFunctor(...);
 
     // note that the following indirection is needed for gcc-3.3
     enum {FunctorType = sizeof(testFunctor(static_cast<Func*>(0)))};
     typedef typename ternary_result_of_select<Func, ArgType0, ArgType1, ArgType2, FunctorType>::type type;
 };
+
+#endif
+
+#if EIGEN_HAS_STD_INVOKE_RESULT
+template<typename F, typename... ArgTypes>
+struct invoke_result {
+  typedef typename std::invoke_result<F, ArgTypes...>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+#elif EIGEN_HAS_CXX11
+template<typename F, typename... ArgTypes>
+struct invoke_result {
+  typedef typename result_of<F(ArgTypes...)>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+#else
+template<typename F, typename ArgType0 = void, typename ArgType1 = void, typename ArgType2 = void>
+struct invoke_result {
+  typedef typename result_of<F(ArgType0, ArgType1, ArgType2)>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+
+template<typename F>
+struct invoke_result<F, void, void, void> {
+  typedef typename result_of<F()>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+
+template<typename F, typename ArgType0>
+struct invoke_result<F, ArgType0, void, void> {
+  typedef typename result_of<F(ArgType0)>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
+
+template<typename F, typename ArgType0, typename ArgType1>
+struct invoke_result<F, ArgType0, ArgType1, void> {
+  typedef typename result_of<F(ArgType0, ArgType1)>::type type1;
+  typedef typename remove_all<type1>::type type;
+};
 #endif
 
 struct meta_yes { char a[1]; };
 struct meta_no  { char a[2]; };
 
 // Check whether T::ReturnType does exist
 template <typename T>
@@ -557,51 +711,66 @@
 };
 
 template<int Y, int InfX, int SupX>
 class meta_sqrt<Y, InfX, SupX, true> { public:  enum { ret = (SupX*SupX <= Y) ? SupX : InfX }; };
 
 
 /** \internal Computes the least common multiple of two positive integer A and B
-  * at compile-time. It implements a naive algorithm testing all multiples of A.
-  * It thus works better if A>=B.
+  * at compile-time. 
   */
-template<int A, int B, int K=1, bool Done = ((A*K)%B)==0>
+template<int A, int B, int K=1, bool Done = ((A*K)%B)==0, bool Big=(A>=B)>
 struct meta_least_common_multiple
 {
   enum { ret = meta_least_common_multiple<A,B,K+1>::ret };
 };
+template<int A, int B, int K, bool Done>
+struct meta_least_common_multiple<A,B,K,Done,false>
+{
+  enum { ret = meta_least_common_multiple<B,A,K>::ret };
+};
 template<int A, int B, int K>
-struct meta_least_common_multiple<A,B,K,true>
+struct meta_least_common_multiple<A,B,K,true,true>
 {
   enum { ret = A*K };
 };
 
+
 /** \internal determines whether the product of two numeric types is allowed and what the return type is */
 template<typename T, typename U> struct scalar_product_traits
 {
   enum { Defined = 0 };
 };
 
 // FIXME quick workaround around current limitation of result_of
 // template<typename Scalar, typename ArgType0, typename ArgType1>
 // struct result_of<scalar_product_op<Scalar>(ArgType0,ArgType1)> {
 // typedef typename scalar_product_traits<typename remove_all<ArgType0>::type, typename remove_all<ArgType1>::type>::ReturnType type;
 // };
 
+/** \internal Obtains a POD type suitable to use as storage for an object of a size
+  * of at most Len bytes, aligned as specified by \c Align.
+  */
+template<unsigned Len, unsigned Align>
+struct aligned_storage {
+  struct type {
+    EIGEN_ALIGN_TO_BOUNDARY(Align) unsigned char data[Len];
+  };
+};
+
 } // end namespace internal
 
 namespace numext {
 
 #if defined(EIGEN_GPU_COMPILE_PHASE)
 template<typename T> EIGEN_DEVICE_FUNC   void swap(T &a, T &b) { T tmp = b; b = a; a = tmp; }
 #else
 template<typename T> EIGEN_STRONG_INLINE void swap(T &a, T &b) { std::swap(a,b); }
 #endif
 
-#if defined(EIGEN_GPU_COMPILE_PHASE)
+#if defined(EIGEN_GPU_COMPILE_PHASE) && !EIGEN_HAS_CXX11
 using internal::device::numeric_limits;
 #else
 using std::numeric_limits;
 #endif
 
 // Integer division with rounding up.
 // T is assumed to be an integer type with a>=0, and b>0
@@ -632,45 +801,12 @@
 template<> EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC
 bool not_equal_strict(const float& x,const float& y) { return std::not_equal_to<float>()(x,y); }
 
 template<> EIGEN_STRONG_INLINE EIGEN_DEVICE_FUNC
 bool not_equal_strict(const double& x,const double& y) { return std::not_equal_to<double>()(x,y); }
 #endif
 
-/** \internal extract the bits of the float \a x */
-inline unsigned int as_uint(float x)
-{
-  unsigned int ret;
-  std::memcpy(&ret, &x, sizeof(float));
-  return ret;
-}
-
 } // end namespace numext
 
 } // end namespace Eigen
 
-// Define portable (u)int{32,64} types
-#if EIGEN_HAS_CXX11
-#include <cstdint>
-namespace Eigen {
-namespace numext {
-typedef std::uint32_t uint32_t;
-typedef std::int32_t  int32_t;
-typedef std::uint64_t uint64_t;
-typedef std::int64_t  int64_t;
-}
-}
-#else
-// Without c++11, all compilers able to compile Eigen also
-// provides the C99 stdint.h header file.
-#include <stdint.h>
-namespace Eigen {
-namespace numext {
-typedef ::uint32_t uint32_t;
-typedef ::int32_t  int32_t;
-typedef ::uint64_t uint64_t;
-typedef ::int64_t  int64_t;
-}
-}
-#endif
-
 #endif // EIGEN_META_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/ReenableStupidWarnings.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/ReenableStupidWarnings.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/ReshapedHelper.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/ReshapedHelper.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/StaticAssert.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/StaticAssert.h`

 * *Files 1% similar despite different names*

```diff
@@ -23,15 +23,15 @@
  *  - currently EIGEN_STATIC_ASSERT can only be used in function scope
  *
  */
 
 #ifndef EIGEN_STATIC_ASSERT
 #ifndef EIGEN_NO_STATIC_ASSERT
 
-  #if EIGEN_MAX_CPP_VER>=11 && (__has_feature(cxx_static_assert) || (defined(__cplusplus) && __cplusplus >= 201103L) || (EIGEN_COMP_MSVC >= 1600))
+  #if EIGEN_MAX_CPP_VER>=11 && (__has_feature(cxx_static_assert) || (EIGEN_COMP_CXXVER >= 11) || (EIGEN_COMP_MSVC >= 1600))
 
     // if native static_assert is enabled, let's use it
     #define EIGEN_STATIC_ASSERT(X,MSG) static_assert(X,#MSG);
 
   #else // not CXX0X
 
     namespace Eigen {
@@ -101,15 +101,16 @@
         MATRIX_FREE_CONJUGATE_GRADIENT_IS_COMPATIBLE_WITH_UPPER_UNION_LOWER_MODE_ONLY=1,
         THIS_TYPE_IS_NOT_SUPPORTED=1,
         STORAGE_KIND_MUST_MATCH=1,
         STORAGE_INDEX_MUST_MATCH=1,
         CHOLMOD_SUPPORTS_DOUBLE_PRECISION_ONLY=1,
         SELFADJOINTVIEW_ACCEPTS_UPPER_AND_LOWER_MODE_ONLY=1,
         INVALID_TEMPLATE_PARAMETER=1,
-        GPU_TENSOR_CONTRACTION_DOES_NOT_SUPPORT_OUTPUT_KERNELS=1
+        GPU_TENSOR_CONTRACTION_DOES_NOT_SUPPORT_OUTPUT_KERNELS=1,
+        THE_ARRAY_SIZE_SHOULD_EQUAL_WITH_PACKET_SIZE=1
       };
     };
 
     } // end namespace internal
 
     } // end namespace Eigen
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/SymbolicIndex.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/SymbolicIndex.h`

 * *Files 1% similar despite different names*

```diff
@@ -61,15 +61,15 @@
 // Specialization for compile-time value,
 // It is similar to ValueExpr(N) but this version helps the compiler to generate better code.
 template<int N>
 class ValueExpr<internal::FixedInt<N> > {
 public:
   ValueExpr() {}
   template<typename T>
-  Index eval_impl(const T&) const { return N; }
+  EIGEN_CONSTEXPR Index eval_impl(const T&) const { return N; }
 };
 
 
 /** \class BaseExpr
   * \ingroup Core_Module
   * Common base class of any symbolic expressions
   */
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Core/util/XprHelper.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Core/util/XprHelper.h`

 * *Files 1% similar despite different names*

```diff
@@ -106,14 +106,17 @@
 struct promote_scalar_arg_unsupported<S,T,S,false,true> {};
 
 //classes inheriting no_assignment_operator don't generate a default operator=.
 class no_assignment_operator
 {
   private:
     no_assignment_operator& operator=(const no_assignment_operator&);
+  protected:
+    EIGEN_DEFAULT_COPY_CONSTRUCTOR(no_assignment_operator)
+    EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(no_assignment_operator)
 };
 
 /** \internal return the index type with the largest number of bits */
 template<typename I1, typename I2>
 struct promote_index_type
 {
   typedef typename conditional<(sizeof(I1)<sizeof(I2)), I2, I1>::type type;
@@ -122,41 +125,45 @@
 /** \internal If the template parameter Value is Dynamic, this class is just a wrapper around a T variable that
   * can be accessed using value() and setValue().
   * Otherwise, this class is an empty structure and value() just returns the template parameter Value.
   */
 template<typename T, int Value> class variable_if_dynamic
 {
   public:
-    EIGEN_EMPTY_STRUCT_CTOR(variable_if_dynamic)
+    EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(variable_if_dynamic)
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamic(T v) { EIGEN_ONLY_USED_FOR_DEBUG(v); eigen_assert(v == T(Value)); }
-    EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE T value() { return T(Value); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE operator T() const { return T(Value); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void setValue(T) {}
+    EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    T value() { return T(Value); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    operator T() const { return T(Value); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+    void setValue(T v) const { EIGEN_ONLY_USED_FOR_DEBUG(v); eigen_assert(v == T(Value)); }
 };
 
 template<typename T> class variable_if_dynamic<T, Dynamic>
 {
     T m_value;
-    EIGEN_DEVICE_FUNC variable_if_dynamic() { eigen_assert(false); }
   public:
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamic(T value) : m_value(value) {}
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamic(T value = 0) EIGEN_NO_THROW : m_value(value) {}
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE T value() const { return m_value; }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE operator T() const { return m_value; }
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void setValue(T value) { m_value = value; }
 };
 
 /** \internal like variable_if_dynamic but for DynamicIndex
   */
 template<typename T, int Value> class variable_if_dynamicindex
 {
   public:
     EIGEN_EMPTY_STRUCT_CTOR(variable_if_dynamicindex)
     EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE explicit variable_if_dynamicindex(T v) { EIGEN_ONLY_USED_FOR_DEBUG(v); eigen_assert(v == T(Value)); }
-    EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE T value() { return T(Value); }
-    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE void setValue(T) {}
+    EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
+    T value() { return T(Value); }
+    EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+    void setValue(T) {}
 };
 
 template<typename T> class variable_if_dynamicindex<T, DynamicIndex>
 {
     T m_value;
     EIGEN_DEVICE_FUNC variable_if_dynamicindex() { eigen_assert(false); }
   public:
@@ -173,27 +180,15 @@
     PacketAccess = false,
     IsRepeatable = false
   };
 };
 
 template<typename T> struct packet_traits;
 
-template<typename T> struct unpacket_traits
-{
-  typedef T type;
-  typedef T half;
-  enum
-  {
-    size = 1,
-    alignment = 1,
-    vectorizable = false,
-    masked_load_available=false,
-    masked_store_available=false
-  };
-};
+template<typename T> struct unpacket_traits;
 
 template<int Size, typename PacketType,
          bool Stop = Size==Dynamic || (Size%unpacket_traits<PacketType>::size)==0 || is_same<PacketType,typename unpacket_traits<PacketType>::half>::value>
 struct find_best_packet_helper;
 
 template< int Size, typename PacketType>
 struct find_best_packet_helper<Size,PacketType,true>
@@ -421,15 +416,15 @@
 struct ref_selector
 {
   typedef typename conditional<
     bool(traits<T>::Flags & NestByRefBit),
     T const&,
     const T
   >::type type;
-  
+
   typedef typename conditional<
     bool(traits<T>::Flags & NestByRefBit),
     T &,
     T
   >::type non_const_type;
 };
 
@@ -600,37 +595,37 @@
 /** \internal gives the plain matrix or array type to store a row/column/diagonal of a matrix type.
   * \tparam Scalar optional parameter allowing to pass a different scalar type than the one of the MatrixType.
   */
 template<typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
 struct plain_row_type
 {
   typedef Matrix<Scalar, 1, ExpressionType::ColsAtCompileTime,
-                 ExpressionType::PlainObject::Options | RowMajor, 1, ExpressionType::MaxColsAtCompileTime> MatrixRowType;
+                 int(ExpressionType::PlainObject::Options) | int(RowMajor), 1, ExpressionType::MaxColsAtCompileTime> MatrixRowType;
   typedef Array<Scalar, 1, ExpressionType::ColsAtCompileTime,
-                 ExpressionType::PlainObject::Options | RowMajor, 1, ExpressionType::MaxColsAtCompileTime> ArrayRowType;
+                 int(ExpressionType::PlainObject::Options) | int(RowMajor), 1, ExpressionType::MaxColsAtCompileTime> ArrayRowType;
 
   typedef typename conditional<
     is_same< typename traits<ExpressionType>::XprKind, MatrixXpr >::value,
     MatrixRowType,
-    ArrayRowType 
+    ArrayRowType
   >::type type;
 };
 
 template<typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
 struct plain_col_type
 {
   typedef Matrix<Scalar, ExpressionType::RowsAtCompileTime, 1,
                  ExpressionType::PlainObject::Options & ~RowMajor, ExpressionType::MaxRowsAtCompileTime, 1> MatrixColType;
   typedef Array<Scalar, ExpressionType::RowsAtCompileTime, 1,
                  ExpressionType::PlainObject::Options & ~RowMajor, ExpressionType::MaxRowsAtCompileTime, 1> ArrayColType;
 
   typedef typename conditional<
     is_same< typename traits<ExpressionType>::XprKind, MatrixXpr >::value,
     MatrixColType,
-    ArrayColType 
+    ArrayColType
   >::type type;
 };
 
 template<typename ExpressionType, typename Scalar = typename ExpressionType::Scalar>
 struct plain_diag_type
 {
   enum { diag_size = EIGEN_SIZE_MIN_PREFER_DYNAMIC(ExpressionType::RowsAtCompileTime, ExpressionType::ColsAtCompileTime),
@@ -638,15 +633,15 @@
   };
   typedef Matrix<Scalar, diag_size, 1, ExpressionType::PlainObject::Options & ~RowMajor, max_diag_size, 1> MatrixDiagType;
   typedef Array<Scalar, diag_size, 1, ExpressionType::PlainObject::Options & ~RowMajor, max_diag_size, 1> ArrayDiagType;
 
   typedef typename conditional<
     is_same< typename traits<ExpressionType>::XprKind, MatrixXpr >::value,
     MatrixDiagType,
-    ArrayDiagType 
+    ArrayDiagType
   >::type type;
 };
 
 template<typename Expr,typename Scalar = typename Expr::Scalar>
 struct plain_constant_type
 {
   enum { Options = (traits<Expr>::Flags&RowMajorBit)?RowMajor:0 };
@@ -754,15 +749,15 @@
   if(f&RowMajorBit)                 res += " | RowMajor";
   if(f&PacketAccessBit)             res += " | Packet";
   if(f&LinearAccessBit)             res += " | Linear";
   if(f&LvalueBit)                   res += " | Lvalue";
   if(f&DirectAccessBit)             res += " | Direct";
   if(f&NestByRefBit)                res += " | NestByRef";
   if(f&NoPreferredStorageOrderBit)  res += " | NoPreferredStorageOrderBit";
-  
+
   return res;
 }
 #endif
 
 } // end namespace internal
 
 
@@ -851,11 +846,11 @@
 // We require Lhs and Rhs to have "compatible" scalar types.
 // It is tempting to always allow mixing different types but remember that this is often impossible in the vectorized paths.
 // So allowing mixing different types gives very unexpected errors when enabling vectorization, when the user tries to
 // add together a float matrix and a double matrix.
 #define EIGEN_CHECK_BINARY_COMPATIBILIY(BINOP,LHS,RHS) \
   EIGEN_STATIC_ASSERT((Eigen::internal::has_ReturnType<ScalarBinaryOpTraits<LHS, RHS,BINOP> >::value), \
     YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY)
-    
+
 } // end namespace Eigen
 
 #endif // EIGEN_XPRHELPER_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/ComplexEigenSolver.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/ComplexEigenSolver.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/ComplexSchur.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/ComplexSchur.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/ComplexSchur_LAPACKE.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/ComplexSchur_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/EigenSolver.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/EigenSolver.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/GeneralizedEigenSolver.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/GeneralizedEigenSolver.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/GeneralizedSelfAdjointEigenSolver.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/GeneralizedSelfAdjointEigenSolver.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/HessenbergDecomposition.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/HessenbergDecomposition.h`

 * *Files 0% similar despite different names*

```diff
@@ -263,15 +263,15 @@
     {
       eigen_assert(m_isInitialized && "HessenbergDecomposition is not initialized.");
       return MatrixHReturnType(*this);
     }
 
   private:
 
-    typedef Matrix<Scalar, 1, Size, Options | RowMajor, 1, MaxSize> VectorType;
+    typedef Matrix<Scalar, 1, Size, int(Options) | int(RowMajor), 1, MaxSize> VectorType;
     typedef typename NumTraits<Scalar>::Real RealScalar;
     static void _compute(MatrixType& matA, CoeffVectorType& hCoeffs, VectorType& temp);
 
   protected:
     MatrixType m_matrix;
     CoeffVectorType m_hCoeffs;
     VectorType m_temp;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/MatrixBaseEigenvalues.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/MatrixBaseEigenvalues.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/RealQZ.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/RealQZ.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/RealSchur.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/RealSchur.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/RealSchur_LAPACKE.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/RealSchur_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver.h`

 * *Files 2% similar despite different names*

```diff
@@ -40,18 +40,22 @@
   * A matrix \f$ A \f$ is selfadjoint if it equals its adjoint. For real
   * matrices, this means that the matrix is symmetric: it equals its
   * transpose. This class computes the eigenvalues and eigenvectors of a
   * selfadjoint matrix. These are the scalars \f$ \lambda \f$ and vectors
   * \f$ v \f$ such that \f$ Av = \lambda v \f$.  The eigenvalues of a
   * selfadjoint matrix are always real. If \f$ D \f$ is a diagonal matrix with
   * the eigenvalues on the diagonal, and \f$ V \f$ is a matrix with the
-  * eigenvectors as its columns, then \f$ A = V D V^{-1} \f$ (for selfadjoint
-  * matrices, the matrix \f$ V \f$ is always invertible). This is called the
+  * eigenvectors as its columns, then \f$ A = V D V^{-1} \f$. This is called the
   * eigendecomposition.
   *
+  * For a selfadjoint matrix, \f$ V \f$ is unitary, meaning its inverse is equal
+  * to its adjoint, \f$ V^{-1} = V^{\dagger} \f$. If \f$ A \f$ is real, then
+  * \f$ V \f$ is also real and therefore orthogonal, meaning its inverse is
+  * equal to its transpose, \f$ V^{-1} = V^T \f$.
+  *
   * The algorithm exploits the fact that the matrix is selfadjoint, making it
   * faster and more accurate than the general purpose eigenvalue algorithms
   * implemented in EigenSolver and ComplexEigenSolver.
   *
   * Only the \b lower \b triangular \b part of the input matrix is referenced.
   *
   * Call the function compute() to compute the eigenvalues and eigenvectors of
@@ -117,14 +121,15 @@
       * Output: \verbinclude SelfAdjointEigenSolver_SelfAdjointEigenSolver.out
       */
     EIGEN_DEVICE_FUNC
     SelfAdjointEigenSolver()
         : m_eivec(),
           m_eivalues(),
           m_subdiag(),
+          m_hcoeffs(),
           m_info(InvalidInput),
           m_isInitialized(false),
           m_eigenvectorsOk(false)
     { }
 
     /** \brief Constructor, pre-allocates memory for dynamic-size matrices.
       *
@@ -139,14 +144,15 @@
       * \sa compute() for an example
       */
     EIGEN_DEVICE_FUNC
     explicit SelfAdjointEigenSolver(Index size)
         : m_eivec(size, size),
           m_eivalues(size),
           m_subdiag(size > 1 ? size - 1 : 1),
+          m_hcoeffs(size > 1 ? size - 1 : 1),
           m_isInitialized(false),
           m_eigenvectorsOk(false)
     {}
 
     /** \brief Constructor; computes eigendecomposition of given matrix.
       *
       * \param[in]  matrix  Selfadjoint matrix whose eigendecomposition is to
@@ -164,14 +170,15 @@
       */
     template<typename InputType>
     EIGEN_DEVICE_FUNC
     explicit SelfAdjointEigenSolver(const EigenBase<InputType>& matrix, int options = ComputeEigenvectors)
       : m_eivec(matrix.rows(), matrix.cols()),
         m_eivalues(matrix.cols()),
         m_subdiag(matrix.rows() > 1 ? matrix.rows() - 1 : 1),
+        m_hcoeffs(matrix.cols() > 1 ? matrix.cols() - 1 : 1),
         m_isInitialized(false),
         m_eigenvectorsOk(false)
     {
       compute(matrix.derived(), options);
     }
 
     /** \brief Computes eigendecomposition of given matrix.
@@ -252,14 +259,19 @@
       * Column \f$ k \f$ of the returned matrix is an eigenvector corresponding
       * to eigenvalue number \f$ k \f$ as returned by eigenvalues().  The
       * eigenvectors are normalized to have (Euclidean) norm equal to one. If
       * this object was used to solve the eigenproblem for the selfadjoint
       * matrix \f$ A \f$, then the matrix returned by this function is the
       * matrix \f$ V \f$ in the eigendecomposition \f$ A = V D V^{-1} \f$.
       *
+      * For a selfadjoint matrix, \f$ V \f$ is unitary, meaning its inverse is equal
+      * to its adjoint, \f$ V^{-1} = V^{\dagger} \f$. If \f$ A \f$ is real, then
+      * \f$ V \f$ is also real and therefore orthogonal, meaning its inverse is
+      * equal to its transpose, \f$ V^{-1} = V^T \f$.
+      *
       * Example: \include SelfAdjointEigenSolver_eigenvectors.cpp
       * Output: \verbinclude SelfAdjointEigenSolver_eigenvectors.out
       *
       * \sa eigenvalues()
       */
     EIGEN_DEVICE_FUNC
     const EigenvectorsType& eigenvectors() const
@@ -365,14 +377,15 @@
     {
       EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar);
     }
     
     EigenvectorsType m_eivec;
     RealVectorType m_eivalues;
     typename TridiagonalizationType::SubDiagonalType m_subdiag;
+    typename TridiagonalizationType::CoeffVectorType m_hcoeffs;
     ComputationInfo m_info;
     bool m_isInitialized;
     bool m_eigenvectorsOk;
 };
 
 namespace internal {
 /** \internal
@@ -406,15 +419,15 @@
 SelfAdjointEigenSolver<MatrixType>& SelfAdjointEigenSolver<MatrixType>
 ::compute(const EigenBase<InputType>& a_matrix, int options)
 {
   check_template_parameters();
   
   const InputType &matrix(a_matrix.derived());
   
-  EIGEN_USING_STD_MATH(abs);
+  EIGEN_USING_STD(abs);
   eigen_assert(matrix.cols() == matrix.rows());
   eigen_assert((options&~(EigVecMask|GenEigMask))==0
           && (options&EigVecMask)!=EigVecMask
           && "invalid option parameter");
   bool computeEigenvectors = (options&ComputeEigenvectors)==ComputeEigenvectors;
   Index n = matrix.cols();
   m_eivalues.resize(n,1);
@@ -437,15 +450,16 @@
 
   // map the matrix coefficients to [-1:1] to avoid over- and underflow.
   mat = matrix.template triangularView<Lower>();
   RealScalar scale = mat.cwiseAbs().maxCoeff();
   if(scale==RealScalar(0)) scale = RealScalar(1);
   mat.template triangularView<Lower>() /= scale;
   m_subdiag.resize(n-1);
-  internal::tridiagonalization_inplace(mat, diag, m_subdiag, computeEigenvectors);
+  m_hcoeffs.resize(n-1);
+  internal::tridiagonalization_inplace(mat, diag, m_subdiag, m_hcoeffs, computeEigenvectors);
 
   m_info = internal::computeFromTridiagonal_impl(diag, m_subdiag, m_maxIterations, computeEigenvectors, m_eivec);
   
   // scale back the eigen values
   m_eivalues *= scale;
 
   m_isInitialized = true;
@@ -485,35 +499,41 @@
   * \param[out] eivec : The matrix to store the eigenvectors if computeEigenvectors==true. Must be allocated on input.
   * \returns \c Success or \c NoConvergence
   */
 template<typename MatrixType, typename DiagType, typename SubDiagType>
 EIGEN_DEVICE_FUNC
 ComputationInfo computeFromTridiagonal_impl(DiagType& diag, SubDiagType& subdiag, const Index maxIterations, bool computeEigenvectors, MatrixType& eivec)
 {
-  EIGEN_USING_STD_MATH(abs);
-
   ComputationInfo info;
   typedef typename MatrixType::Scalar Scalar;
 
   Index n = diag.size();
   Index end = n-1;
   Index start = 0;
   Index iter = 0; // total number of iterations
   
   typedef typename DiagType::RealScalar RealScalar;
   const RealScalar considerAsZero = (std::numeric_limits<RealScalar>::min)();
-  const RealScalar precision = RealScalar(2)*NumTraits<RealScalar>::epsilon();
-  
+  const RealScalar precision_inv = RealScalar(1)/NumTraits<RealScalar>::epsilon();
   while (end>0)
   {
-    for (Index i = start; i<end; ++i)
-      if (internal::isMuchSmallerThan(abs(subdiag[i]),(abs(diag[i])+abs(diag[i+1])),precision) || abs(subdiag[i]) <= considerAsZero)
-        subdiag[i] = 0;
+    for (Index i = start; i<end; ++i) {
+      if (numext::abs(subdiag[i]) < considerAsZero) {
+        subdiag[i] = RealScalar(0);
+      } else {
+        // abs(subdiag[i]) <= epsilon * sqrt(abs(diag[i]) + abs(diag[i+1]))
+        // Scaled to prevent underflows.
+        const RealScalar scaled_subdiag = precision_inv * subdiag[i];
+        if (scaled_subdiag * scaled_subdiag <= (numext::abs(diag[i])+numext::abs(diag[i+1]))) {
+          subdiag[i] = RealScalar(0);
+        }
+      }
+    }
 
-    // find the largest unreduced block
+    // find the largest unreduced block at the end of the matrix.
     while (end>0 && subdiag[end-1]==RealScalar(0))
     {
       end--;
     }
     if (end<=0)
       break;
 
@@ -570,18 +590,18 @@
   /** \internal
    * Computes the roots of the characteristic polynomial of \a m.
    * For numerical stability m.trace() should be near zero and to avoid over- or underflow m should be normalized.
    */
   EIGEN_DEVICE_FUNC
   static inline void computeRoots(const MatrixType& m, VectorType& roots)
   {
-    EIGEN_USING_STD_MATH(sqrt)
-    EIGEN_USING_STD_MATH(atan2)
-    EIGEN_USING_STD_MATH(cos)
-    EIGEN_USING_STD_MATH(sin)
+    EIGEN_USING_STD(sqrt)
+    EIGEN_USING_STD(atan2)
+    EIGEN_USING_STD(cos)
+    EIGEN_USING_STD(sin)
     const Scalar s_inv3 = Scalar(1)/Scalar(3);
     const Scalar s_sqrt3 = sqrt(Scalar(3));
 
     // The characteristic equation is x^3 - c2*x^2 + c1*x - c0 = 0.  The
     // eigenvalues are the roots to this equation, all guaranteed to be
     // real-valued, because the matrix is symmetric.
     Scalar c0 = m(0,0)*m(1,1)*m(2,2) + Scalar(2)*m(1,0)*m(2,0)*m(2,1) - m(0,0)*m(2,1)*m(2,1) - m(1,1)*m(2,0)*m(2,0) - m(2,2)*m(1,0)*m(1,0);
@@ -609,16 +629,16 @@
     roots(1) = c2_over_3 - rho*(cos_theta - s_sqrt3*sin_theta); // == 2*rho*cos(theta+ pi/3)
     roots(2) = c2_over_3 + Scalar(2)*rho*cos_theta;
   }
 
   EIGEN_DEVICE_FUNC
   static inline bool extract_kernel(MatrixType& mat, Ref<VectorType> res, Ref<VectorType> representative)
   {
-    EIGEN_USING_STD_MATH(abs);
-    EIGEN_USING_STD_MATH(sqrt);
+    EIGEN_USING_STD(abs);
+    EIGEN_USING_STD(sqrt);
     Index i0;
     // Find non-zero column i0 (by construction, there must exist a non zero coefficient on the diagonal):
     mat.diagonal().cwiseAbs().maxCoeff(&i0);
     // mat.col(i0) is a good candidate for an orthogonal vector to the current eigenvector,
     // so let's save it:
     representative = mat.col(i0);
     Scalar n0, n1;
@@ -724,26 +744,26 @@
   typedef typename SolverType::RealVectorType VectorType;
   typedef typename SolverType::Scalar Scalar;
   typedef typename SolverType::EigenvectorsType EigenvectorsType;
   
   EIGEN_DEVICE_FUNC
   static inline void computeRoots(const MatrixType& m, VectorType& roots)
   {
-    EIGEN_USING_STD_MATH(sqrt);
+    EIGEN_USING_STD(sqrt);
     const Scalar t0 = Scalar(0.5) * sqrt( numext::abs2(m(0,0)-m(1,1)) + Scalar(4)*numext::abs2(m(1,0)));
     const Scalar t1 = Scalar(0.5) * (m(0,0) + m(1,1));
     roots(0) = t1 - t0;
     roots(1) = t1 + t0;
   }
   
   EIGEN_DEVICE_FUNC
   static inline void run(SolverType& solver, const MatrixType& mat, int options)
   {
-    EIGEN_USING_STD_MATH(sqrt);
-    EIGEN_USING_STD_MATH(abs);
+    EIGEN_USING_STD(sqrt);
+    EIGEN_USING_STD(abs);
     
     eigen_assert(mat.cols() == 2 && mat.cols() == mat.rows());
     eigen_assert((options&~(EigVecMask|GenEigMask))==0
             && (options&EigVecMask)!=EigVecMask
             && "invalid option parameter");
     bool computeEigenvectors = (options&ComputeEigenvectors)==ComputeEigenvectors;
     
@@ -808,58 +828,63 @@
 ::computeDirect(const MatrixType& matrix, int options)
 {
   internal::direct_selfadjoint_eigenvalues<SelfAdjointEigenSolver,Size,NumTraits<Scalar>::IsComplex>::run(*this,matrix,options);
   return *this;
 }
 
 namespace internal {
+
+// Francis implicit QR step.
 template<int StorageOrder,typename RealScalar, typename Scalar, typename Index>
 EIGEN_DEVICE_FUNC
 static void tridiagonal_qr_step(RealScalar* diag, RealScalar* subdiag, Index start, Index end, Scalar* matrixQ, Index n)
 {
-  EIGEN_USING_STD_MATH(abs);
+  // Wilkinson Shift.
   RealScalar td = (diag[end-1] - diag[end])*RealScalar(0.5);
   RealScalar e = subdiag[end-1];
   // Note that thanks to scaling, e^2 or td^2 cannot overflow, however they can still
   // underflow thus leading to inf/NaN values when using the following commented code:
-//   RealScalar e2 = numext::abs2(subdiag[end-1]);
-//   RealScalar mu = diag[end] - e2 / (td + (td>0 ? 1 : -1) * sqrt(td*td + e2));
+  //   RealScalar e2 = numext::abs2(subdiag[end-1]);
+  //   RealScalar mu = diag[end] - e2 / (td + (td>0 ? 1 : -1) * sqrt(td*td + e2));
   // This explain the following, somewhat more complicated, version:
   RealScalar mu = diag[end];
-  if(td==RealScalar(0))
-    mu -= abs(e);
-  else
-  {
-    RealScalar e2 = numext::abs2(subdiag[end-1]);
-    RealScalar h = numext::hypot(td,e);
-    if(e2==RealScalar(0)) mu -= (e / (td + (td>RealScalar(0) ? RealScalar(1) : RealScalar(-1)))) * (e / h);
-    else                  mu -= e2 / (td + (td>RealScalar(0) ? h : -h));
+  if(td==RealScalar(0)) {
+    mu -= numext::abs(e);
+  } else if (e != RealScalar(0)) {
+    const RealScalar e2 = numext::abs2(e);
+    const RealScalar h = numext::hypot(td,e);
+    if(e2 == RealScalar(0)) {
+      mu -= e / ((td + (td>RealScalar(0) ? h : -h)) / e);
+    } else {
+      mu -= e2 / (td + (td>RealScalar(0) ? h : -h)); 
+    }
   }
-  
+
   RealScalar x = diag[start] - mu;
   RealScalar z = subdiag[start];
-  for (Index k = start; k < end; ++k)
+  // If z ever becomes zero, the Givens rotation will be the identity and
+  // z will stay zero for all future iterations.
+  for (Index k = start; k < end && z != RealScalar(0); ++k)
   {
     JacobiRotation<RealScalar> rot;
     rot.makeGivens(x, z);
 
     // do T = G' T G
     RealScalar sdk = rot.s() * diag[k] + rot.c() * subdiag[k];
     RealScalar dkp1 = rot.s() * subdiag[k] + rot.c() * diag[k+1];
 
     diag[k] = rot.c() * (rot.c() * diag[k] - rot.s() * subdiag[k]) - rot.s() * (rot.c() * subdiag[k] - rot.s() * diag[k+1]);
     diag[k+1] = rot.s() * sdk + rot.c() * dkp1;
     subdiag[k] = rot.c() * sdk - rot.s() * dkp1;
     
-
     if (k > start)
       subdiag[k - 1] = rot.c() * subdiag[k-1] - rot.s() * z;
 
+    // "Chasing the bulge" to return to triangular form.
     x = subdiag[k];
-
     if (k < end - 1)
     {
       z = -rot.s() * subdiag[k+1];
       subdiag[k + 1] = rot.c() * subdiag[k+1];
     }
     
     // apply the givens rotation to the unit matrix Q = Q * G
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver_LAPACKE.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/SelfAdjointEigenSolver_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Eigenvalues/Tridiagonalization.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Eigenvalues/Tridiagonalization.h`

 * *Files 2% similar despite different names*

```diff
@@ -7,18 +7,18 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_TRIDIAGONALIZATION_H
 #define EIGEN_TRIDIAGONALIZATION_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
-  
+
 template<typename MatrixType> struct TridiagonalizationMatrixTReturnType;
 template<typename MatrixType>
 struct traits<TridiagonalizationMatrixTReturnType<MatrixType> >
   : public traits<typename MatrixType::PlainObject>
 {
   typedef typename MatrixType::PlainObject ReturnType; // FIXME shall it be a BandMatrix?
   enum { Flags = 0 };
@@ -350,15 +350,15 @@
 {
   using numext::conj;
   typedef typename MatrixType::Scalar Scalar;
   typedef typename MatrixType::RealScalar RealScalar;
   Index n = matA.rows();
   eigen_assert(n==matA.cols());
   eigen_assert(n==hCoeffs.size()+1 || n==1);
-  
+
   for (Index i = 0; i<n-1; ++i)
   {
     Index remainingSize = n-i-1;
     RealScalar beta;
     Scalar h;
     matA.col(i).tail(remainingSize).makeHouseholderInPlace(h, beta);
 
@@ -421,36 +421,35 @@
   * Example (this uses the same matrix as the example in
   *    Tridiagonalization::Tridiagonalization(const MatrixType&)):
   *    \include Tridiagonalization_decomposeInPlace.cpp
   * Output: \verbinclude Tridiagonalization_decomposeInPlace.out
   *
   * \sa class Tridiagonalization
   */
-template<typename MatrixType, typename DiagonalType, typename SubDiagonalType>
+template<typename MatrixType, typename DiagonalType, typename SubDiagonalType, typename CoeffVectorType>
 EIGEN_DEVICE_FUNC
-void tridiagonalization_inplace(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, bool extractQ)
+void tridiagonalization_inplace(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag,
+                                CoeffVectorType& hcoeffs, bool extractQ)
 {
   eigen_assert(mat.cols()==mat.rows() && diag.size()==mat.rows() && subdiag.size()==mat.rows()-1);
-  tridiagonalization_inplace_selector<MatrixType>::run(mat, diag, subdiag, extractQ);
+  tridiagonalization_inplace_selector<MatrixType>::run(mat, diag, subdiag, hcoeffs, extractQ);
 }
 
 /** \internal
   * General full tridiagonalization
   */
 template<typename MatrixType, int Size, bool IsComplex>
 struct tridiagonalization_inplace_selector
 {
-  typedef typename Tridiagonalization<MatrixType>::CoeffVectorType CoeffVectorType;
   typedef typename Tridiagonalization<MatrixType>::HouseholderSequenceType HouseholderSequenceType;
-  template<typename DiagonalType, typename SubDiagonalType>
+  template<typename DiagonalType, typename SubDiagonalType, typename CoeffVectorType>
   static EIGEN_DEVICE_FUNC
-  void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, bool extractQ)
+      void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, CoeffVectorType& hCoeffs, bool extractQ)
   {
-    CoeffVectorType hCoeffs(mat.cols()-1);
-    tridiagonalization_inplace(mat,hCoeffs);
+    tridiagonalization_inplace(mat, hCoeffs);
     diag = mat.diagonal().real();
     subdiag = mat.template diagonal<-1>().real();
     if(extractQ)
       mat = HouseholderSequenceType(mat, hCoeffs.conjugate())
             .setLength(mat.rows() - 1)
             .setShift(1);
   }
@@ -462,16 +461,16 @@
   */
 template<typename MatrixType>
 struct tridiagonalization_inplace_selector<MatrixType,3,false>
 {
   typedef typename MatrixType::Scalar Scalar;
   typedef typename MatrixType::RealScalar RealScalar;
 
-  template<typename DiagonalType, typename SubDiagonalType>
-  static void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, bool extractQ)
+  template<typename DiagonalType, typename SubDiagonalType, typename CoeffVectorType>
+  static void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType& subdiag, CoeffVectorType&, bool extractQ)
   {
     using std::sqrt;
     const RealScalar tol = (std::numeric_limits<RealScalar>::min)();
     diag[0] = mat(0,0);
     RealScalar v1norm2 = numext::abs2(mat(2,0));
     if(v1norm2 <= tol)
     {
@@ -507,17 +506,17 @@
   * Trivial specialization for 1x1 matrices
   */
 template<typename MatrixType, bool IsComplex>
 struct tridiagonalization_inplace_selector<MatrixType,1,IsComplex>
 {
   typedef typename MatrixType::Scalar Scalar;
 
-  template<typename DiagonalType, typename SubDiagonalType>
+  template<typename DiagonalType, typename SubDiagonalType, typename CoeffVectorType>
   static EIGEN_DEVICE_FUNC
-  void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType&, bool extractQ)
+  void run(MatrixType& mat, DiagonalType& diag, SubDiagonalType&, CoeffVectorType&, bool extractQ)
   {
     diag(0,0) = numext::real(mat(0,0));
     if(extractQ)
       mat(0,0) = Scalar(1);
   }
 };
 
@@ -543,16 +542,16 @@
     {
       result.setZero();
       result.template diagonal<1>() = m_matrix.template diagonal<-1>().conjugate();
       result.diagonal() = m_matrix.diagonal();
       result.template diagonal<-1>() = m_matrix.template diagonal<-1>();
     }
 
-    Index rows() const { return m_matrix.rows(); }
-    Index cols() const { return m_matrix.cols(); }
+    EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows(); }
+    EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
   protected:
     typename MatrixType::Nested m_matrix;
 };
 
 } // end namespace internal
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/AlignedBox.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/AlignedBox.h`

 * *Files 23% similar despite different names*

```diff
@@ -3,18 +3,54 @@
 //
 // Copyright (C) 2008 Gael Guennebaud <gael.guennebaud@inria.fr>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
+// Function void Eigen::AlignedBox::transform(const Transform& transform)
+// is provided under the following license agreement:
+//
+// Software License Agreement (BSD License)
+//
+// Copyright (c) 2011-2014, Willow Garage, Inc.
+// Copyright (c) 2014-2015, Open Source Robotics Foundation
+// All rights reserved.
+//
+// Redistribution and use in source and binary forms, with or without
+// modification, are permitted provided that the following conditions
+// are met:
+//
+//  * Redistributions of source code must retain the above copyright
+//    notice, this list of conditions and the following disclaimer.
+//  * Redistributions in binary form must reproduce the above
+//    copyright notice, this list of conditions and the following
+//    disclaimer in the documentation and/or other materials provided
+//    with the distribution.
+//  * Neither the name of Open Source Robotics Foundation nor the names of its
+//    contributors may be used to endorse or promote products derived
+//    from this software without specific prior written permission.
+//
+// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+// "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+// LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
+// FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
+// COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
+// INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
+// BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
+// LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
+// CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
+// LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
+// ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
+// POSSIBILITY OF SUCH DAMAGE.
+
 #ifndef EIGEN_ALIGNEDBOX_H
 #define EIGEN_ALIGNEDBOX_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \geometry_module \ingroup Geometry_Module
   *
   *
   * \class AlignedBox
   *
   * \brief An axis aligned box
@@ -227,29 +263,38 @@
   /** Returns an AlignedBox that is the intersection of \a b and \c *this
    * \note If the boxes don't intersect, the resulting box is empty.
    * \sa intersects(), clamp, contains()  */
   EIGEN_DEVICE_FUNC inline AlignedBox intersection(const AlignedBox& b) const
   {return AlignedBox(m_min.cwiseMax(b.m_min), m_max.cwiseMin(b.m_max)); }
 
   /** Returns an AlignedBox that is the union of \a b and \c *this.
-   * \note Merging with an empty box may result in a box bigger than \c *this. 
+   * \note Merging with an empty box may result in a box bigger than \c *this.
    * \sa extend(const AlignedBox&) */
   EIGEN_DEVICE_FUNC inline AlignedBox merged(const AlignedBox& b) const
   { return AlignedBox(m_min.cwiseMin(b.m_min), m_max.cwiseMax(b.m_max)); }
 
   /** Translate \c *this by the vector \a t and returns a reference to \c *this. */
   template<typename Derived>
   EIGEN_DEVICE_FUNC inline AlignedBox& translate(const MatrixBase<Derived>& a_t)
   {
     const typename internal::nested_eval<Derived,2>::type t(a_t.derived());
     m_min += t;
     m_max += t;
     return *this;
   }
 
+  /** \returns a copy of \c *this translated by the vector \a t. */
+  template<typename Derived>
+  EIGEN_DEVICE_FUNC inline AlignedBox translated(const MatrixBase<Derived>& a_t) const
+  {
+    AlignedBox result(m_min, m_max);
+    result.translate(a_t);
+    return result;
+  }
+
   /** \returns the squared distance between the point \a p and the box \c *this,
     * and zero if \a p is inside the box.
     * \sa exteriorDistance(const MatrixBase&), squaredExteriorDistance(const AlignedBox&)
     */
   template<typename Derived>
   EIGEN_DEVICE_FUNC inline Scalar squaredExteriorDistance(const MatrixBase<Derived>& p) const;
 
@@ -261,22 +306,71 @@
 
   /** \returns the distance between the point \a p and the box \c *this,
     * and zero if \a p is inside the box.
     * \sa squaredExteriorDistance(const MatrixBase&), exteriorDistance(const AlignedBox&)
     */
   template<typename Derived>
   EIGEN_DEVICE_FUNC inline NonInteger exteriorDistance(const MatrixBase<Derived>& p) const
-  { EIGEN_USING_STD_MATH(sqrt) return sqrt(NonInteger(squaredExteriorDistance(p))); }
+  { EIGEN_USING_STD(sqrt) return sqrt(NonInteger(squaredExteriorDistance(p))); }
 
   /** \returns the distance between the boxes \a b and \c *this,
     * and zero if the boxes intersect.
     * \sa squaredExteriorDistance(const AlignedBox&), exteriorDistance(const MatrixBase&)
     */
   EIGEN_DEVICE_FUNC inline NonInteger exteriorDistance(const AlignedBox& b) const
-  { EIGEN_USING_STD_MATH(sqrt) return sqrt(NonInteger(squaredExteriorDistance(b))); }
+  { EIGEN_USING_STD(sqrt) return sqrt(NonInteger(squaredExteriorDistance(b))); }
+
+  /**
+   * Specialization of transform for pure translation.
+   */
+  template<int Mode, int Options>
+  EIGEN_DEVICE_FUNC inline void transform(
+      const typename Transform<Scalar, AmbientDimAtCompileTime, Mode, Options>::TranslationType& translation)
+  {
+    this->translate(translation);
+  }
+
+  /**
+   * Transforms this box by \a transform and recomputes it to
+   * still be an axis-aligned box.
+   *
+   * \note This method is provided under BSD license (see the top of this file).
+   */
+  template<int Mode, int Options>
+  EIGEN_DEVICE_FUNC inline void transform(const Transform<Scalar, AmbientDimAtCompileTime, Mode, Options>& transform)
+  {
+    // Only Affine and Isometry transforms are currently supported.
+    EIGEN_STATIC_ASSERT(Mode == Affine || Mode == AffineCompact || Mode == Isometry, THIS_METHOD_IS_ONLY_FOR_SPECIFIC_TRANSFORMATIONS);
+
+    // Method adapted from FCL src/shape/geometric_shapes_utility.cpp#computeBV<AABB, Box>(...)
+    // https://github.com/flexible-collision-library/fcl/blob/fcl-0.4/src/shape/geometric_shapes_utility.cpp#L292
+    //
+    // Here's a nice explanation why it works: https://zeuxcg.org/2010/10/17/aabb-from-obb-with-component-wise-abs/
+
+    // two times rotated extent
+    const VectorType rotated_extent_2 = transform.linear().cwiseAbs() * sizes();
+    // two times new center
+    const VectorType rotated_center_2 = transform.linear() * (this->m_max + this->m_min) +
+        Scalar(2) * transform.translation();
+
+    this->m_max = (rotated_center_2 + rotated_extent_2) / Scalar(2);
+    this->m_min = (rotated_center_2 - rotated_extent_2) / Scalar(2);
+  }
+
+  /**
+   * \returns a copy of \c *this transformed by \a transform and recomputed to
+   * still be an axis-aligned box.
+   */
+  template<int Mode, int Options>
+  EIGEN_DEVICE_FUNC AlignedBox transformed(const Transform<Scalar, AmbientDimAtCompileTime, Mode, Options>& transform) const
+  {
+    AlignedBox result(m_min, m_max);
+    result.transform(transform);
+    return result;
+  }
 
   /** \returns \c *this with scalar type casted to \a NewScalarType
     *
     * Note that if \a NewScalarType is equal to the current scalar type of \c *this
     * then this function smartly returns a const reference to \c *this.
     */
   template<typename NewScalarType>
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/AngleAxis.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/AngleAxis.h`

 * *Files 1% similar despite different names*

```diff
@@ -165,16 +165,16 @@
   * 
   * This function implicitly normalizes the quaternion \a q.
   */
 template<typename Scalar>
 template<typename QuatDerived>
 EIGEN_DEVICE_FUNC AngleAxis<Scalar>& AngleAxis<Scalar>::operator=(const QuaternionBase<QuatDerived>& q)
 {
-  EIGEN_USING_STD_MATH(atan2)
-  EIGEN_USING_STD_MATH(abs)
+  EIGEN_USING_STD(atan2)
+  EIGEN_USING_STD(abs)
   Scalar n = q.vec().norm();
   if(n<NumTraits<Scalar>::epsilon())
     n = q.vec().stableNorm();
 
   if (n != Scalar(0))
   {
     m_angle = Scalar(2)*atan2(n, abs(q.w()));
@@ -213,16 +213,16 @@
 
 /** Constructs and \returns an equivalent 3x3 rotation matrix.
   */
 template<typename Scalar>
 typename AngleAxis<Scalar>::Matrix3
 EIGEN_DEVICE_FUNC AngleAxis<Scalar>::toRotationMatrix(void) const
 {
-  EIGEN_USING_STD_MATH(sin)
-  EIGEN_USING_STD_MATH(cos)
+  EIGEN_USING_STD(sin)
+  EIGEN_USING_STD(cos)
   Matrix3 res;
   Vector3 sin_axis  = sin(m_angle) * m_axis;
   Scalar c = cos(m_angle);
   Vector3 cos1_axis = (Scalar(1)-c) * m_axis;
 
   Scalar tmp;
   tmp = cos1_axis.x() * m_axis.y();
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/EulerAngles.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/EulerAngles.h`

 * *Files 1% similar despite different names*

```diff
@@ -32,17 +32,17 @@
   * 
   * \sa class AngleAxis
   */
 template<typename Derived>
 EIGEN_DEVICE_FUNC inline Matrix<typename MatrixBase<Derived>::Scalar,3,1>
 MatrixBase<Derived>::eulerAngles(Index a0, Index a1, Index a2) const
 {
-  EIGEN_USING_STD_MATH(atan2)
-  EIGEN_USING_STD_MATH(sin)
-  EIGEN_USING_STD_MATH(cos)
+  EIGEN_USING_STD(atan2)
+  EIGEN_USING_STD(sin)
+  EIGEN_USING_STD(cos)
   /* Implemented from Graphics Gems IV */
   EIGEN_STATIC_ASSERT_MATRIX_SPECIFIC_SIZE(Derived,3,3)
 
   Matrix<Scalar,3,1> res;
   typedef Matrix<typename Derived::Scalar,2,1> Vector2;
 
   const Index odd = ((a0+1)%3 == a1) ? 0 : 1;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Homogeneous.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Homogeneous.h`

 * *Files 2% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_HOMOGENEOUS_H
 #define EIGEN_HOMOGENEOUS_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \geometry_module \ingroup Geometry_Module
   *
   * \class Homogeneous
   *
   * \brief Expression of one (or a set of) homogeneous vector(s)
   *
@@ -68,17 +68,19 @@
     typedef MatrixBase<Homogeneous> Base;
     EIGEN_DENSE_PUBLIC_INTERFACE(Homogeneous)
 
     EIGEN_DEVICE_FUNC explicit inline Homogeneous(const MatrixType& matrix)
       : m_matrix(matrix)
     {}
 
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_matrix.rows() + (int(Direction)==Vertical   ? 1 : 0); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_matrix.cols() + (int(Direction)==Horizontal ? 1 : 0); }
-    
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_matrix.rows() + (int(Direction)==Vertical   ? 1 : 0); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols() + (int(Direction)==Horizontal ? 1 : 0); }
+
     EIGEN_DEVICE_FUNC const NestedExpression& nestedExpression() const { return m_matrix; }
 
     template<typename Rhs>
     EIGEN_DEVICE_FUNC inline const Product<Homogeneous,Rhs>
     operator* (const MatrixBase<Rhs>& rhs) const
     {
       eigen_assert(int(Direction)==Horizontal);
@@ -258,16 +260,18 @@
   typedef typename remove_all<LhsMatrixType>::type LhsMatrixTypeCleaned;
   typedef typename remove_all<typename LhsMatrixTypeCleaned::Nested>::type LhsMatrixTypeNested;
   EIGEN_DEVICE_FUNC homogeneous_left_product_impl(const Lhs& lhs, const MatrixType& rhs)
     : m_lhs(take_matrix_for_product<Lhs>::run(lhs)),
       m_rhs(rhs)
   {}
 
-  EIGEN_DEVICE_FUNC inline Index rows() const { return m_lhs.rows(); }
-  EIGEN_DEVICE_FUNC inline Index cols() const { return m_rhs.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  inline Index rows() const EIGEN_NOEXCEPT { return m_lhs.rows(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  inline Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
 
   template<typename Dest> EIGEN_DEVICE_FUNC void evalTo(Dest& dst) const
   {
     // FIXME investigate how to allow lazy evaluation of this product when possible
     dst = Block<const LhsMatrixTypeNested,
               LhsMatrixTypeNested::RowsAtCompileTime,
               LhsMatrixTypeNested::ColsAtCompileTime==Dynamic?Dynamic:LhsMatrixTypeNested::ColsAtCompileTime-1>
@@ -296,16 +300,16 @@
   : public ReturnByValue<homogeneous_right_product_impl<Homogeneous<MatrixType,Horizontal>,Rhs> >
 {
   typedef typename remove_all<typename Rhs::Nested>::type RhsNested;
   EIGEN_DEVICE_FUNC homogeneous_right_product_impl(const MatrixType& lhs, const Rhs& rhs)
     : m_lhs(lhs), m_rhs(rhs)
   {}
 
-  EIGEN_DEVICE_FUNC inline Index rows() const { return m_lhs.rows(); }
-  EIGEN_DEVICE_FUNC inline Index cols() const { return m_rhs.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return m_lhs.rows(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
 
   template<typename Dest> EIGEN_DEVICE_FUNC void evalTo(Dest& dst) const
   {
     // FIXME investigate how to allow lazy evaluation of this product when possible
     dst = m_lhs * Block<const RhsNested,
                         RhsNested::RowsAtCompileTime==Dynamic?Dynamic:RhsNested::RowsAtCompileTime-1,
                         RhsNested::ColsAtCompileTime>
@@ -318,15 +322,15 @@
   typename Rhs::Nested m_rhs;
 };
 
 template<typename ArgType,int Direction>
 struct evaluator_traits<Homogeneous<ArgType,Direction> >
 {
   typedef typename storage_kind_to_evaluator_kind<typename ArgType::StorageKind>::Kind Kind;
-  typedef HomogeneousShape Shape;  
+  typedef HomogeneousShape Shape;
 };
 
 template<> struct AssignmentKind<DenseShape,HomogeneousShape> { typedef Dense2Dense Kind; };
 
 
 template<typename ArgType,int Direction>
 struct unary_evaluator<Homogeneous<ArgType,Direction>, IndexBased>
@@ -410,15 +414,15 @@
  : public evaluator<typename homogeneous_right_product_refactoring_helper<typename Lhs::NestedExpression,Rhs>::Xpr>
 {
   typedef Product<Lhs, Rhs, LazyProduct> XprType;
   typedef homogeneous_right_product_refactoring_helper<typename Lhs::NestedExpression,Rhs> helper;
   typedef typename helper::ConstantBlock ConstantBlock;
   typedef typename helper::Xpr RefactoredXpr;
   typedef evaluator<RefactoredXpr> Base;
-  
+
   EIGEN_DEVICE_FUNC explicit product_evaluator(const XprType& xpr)
     : Base(  xpr.lhs().nestedExpression() .lazyProduct(  xpr.rhs().template topRows<helper::Dim>(xpr.lhs().nestedExpression().cols()) )
             + ConstantBlock(xpr.rhs().row(xpr.rhs().rows()-1),xpr.lhs().rows(), 1) )
   {}
 };
 
 template<typename Lhs, typename RhsArg, int ProductTag>
@@ -463,15 +467,15 @@
  : public evaluator<typename homogeneous_left_product_refactoring_helper<Lhs,typename Rhs::NestedExpression>::Xpr>
 {
   typedef Product<Lhs, Rhs, LazyProduct> XprType;
   typedef homogeneous_left_product_refactoring_helper<Lhs,typename Rhs::NestedExpression> helper;
   typedef typename helper::ConstantBlock ConstantBlock;
   typedef typename helper::Xpr RefactoredXpr;
   typedef evaluator<RefactoredXpr> Base;
-  
+
   EIGEN_DEVICE_FUNC explicit product_evaluator(const XprType& xpr)
     : Base(   xpr.lhs().template leftCols<helper::Dim>(xpr.rhs().nestedExpression().rows()) .lazyProduct( xpr.rhs().nestedExpression() )
             + ConstantBlock(xpr.lhs().col(xpr.lhs().cols()-1),1,xpr.rhs().cols()) )
   {}
 };
 
 template<typename Scalar, int Dim, int Mode,int Options, typename RhsArg, int ProductTag>
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Hyperplane.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Hyperplane.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/OrthoMethods.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/OrthoMethods.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/ParametrizedLine.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/ParametrizedLine.h`

 * *Files 1% similar despite different names*

```diff
@@ -83,15 +83,15 @@
   {
     VectorType diff = p - origin();
     return (diff - direction().dot(diff) * direction()).squaredNorm();
   }
   /** \returns the distance of a point \a p to its projection onto the line \c *this.
     * \sa squaredDistance()
     */
-  EIGEN_DEVICE_FUNC RealScalar distance(const VectorType& p) const { EIGEN_USING_STD_MATH(sqrt) return sqrt(squaredDistance(p)); }
+  EIGEN_DEVICE_FUNC RealScalar distance(const VectorType& p) const { EIGEN_USING_STD(sqrt) return sqrt(squaredDistance(p)); }
 
   /** \returns the projection of a point \a p onto the line \c *this. */
   EIGEN_DEVICE_FUNC VectorType projection(const VectorType& p) const
   { return origin() + direction().dot(p-origin()) * direction(); }
 
   EIGEN_DEVICE_FUNC VectorType pointAt(const Scalar& t) const;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Quaternion.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Quaternion.h`

 * *Files 3% similar despite different names*

```diff
@@ -137,15 +137,15 @@
     * \sa angularDistance()
     */
   template<class OtherDerived> EIGEN_DEVICE_FUNC inline Scalar dot(const QuaternionBase<OtherDerived>& other) const { return coeffs().dot(other.coeffs()); }
 
   template<class OtherDerived> EIGEN_DEVICE_FUNC Scalar angularDistance(const QuaternionBase<OtherDerived>& other) const;
 
   /** \returns an equivalent 3x3 rotation matrix */
-  EIGEN_DEVICE_FUNC Matrix3 toRotationMatrix() const;
+  EIGEN_DEVICE_FUNC inline Matrix3 toRotationMatrix() const;
 
   /** \returns the quaternion which transform \a a into \a b through a rotation */
   template<typename Derived1, typename Derived2>
   EIGEN_DEVICE_FUNC Derived& setFromTwoVectors(const MatrixBase<Derived1>& a, const MatrixBase<Derived2>& b);
 
   template<class OtherDerived> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Quaternion<Scalar> operator* (const QuaternionBase<OtherDerived>& q) const;
   template<class OtherDerived> EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& operator*= (const QuaternionBase<OtherDerived>& q);
@@ -154,39 +154,80 @@
   EIGEN_DEVICE_FUNC Quaternion<Scalar> inverse() const;
 
   /** \returns the conjugated quaternion */
   EIGEN_DEVICE_FUNC Quaternion<Scalar> conjugate() const;
 
   template<class OtherDerived> EIGEN_DEVICE_FUNC Quaternion<Scalar> slerp(const Scalar& t, const QuaternionBase<OtherDerived>& other) const;
 
+  /** \returns true if each coefficients of \c *this and \a other are all exactly equal.
+    * \warning When using floating point scalar values you probably should rather use a
+    *          fuzzy comparison such as isApprox()
+    * \sa isApprox(), operator!= */
+  template<class OtherDerived>
+  EIGEN_DEVICE_FUNC inline bool operator==(const QuaternionBase<OtherDerived>& other) const
+  { return coeffs() == other.coeffs(); }
+
+  /** \returns true if at least one pair of coefficients of \c *this and \a other are not exactly equal to each other.
+    * \warning When using floating point scalar values you probably should rather use a
+    *          fuzzy comparison such as isApprox()
+    * \sa isApprox(), operator== */
+  template<class OtherDerived>
+  EIGEN_DEVICE_FUNC inline bool operator!=(const QuaternionBase<OtherDerived>& other) const
+  { return coeffs() != other.coeffs(); }
+
   /** \returns \c true if \c *this is approximately equal to \a other, within the precision
     * determined by \a prec.
     *
     * \sa MatrixBase::isApprox() */
   template<class OtherDerived>
   EIGEN_DEVICE_FUNC bool isApprox(const QuaternionBase<OtherDerived>& other, const RealScalar& prec = NumTraits<Scalar>::dummy_precision()) const
   { return coeffs().isApprox(other.coeffs(), prec); }
 
   /** return the result vector of \a v through the rotation*/
   EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Vector3 _transformVector(const Vector3& v) const;
 
+  #ifdef EIGEN_PARSED_BY_DOXYGEN
   /** \returns \c *this with scalar type casted to \a NewScalarType
     *
     * Note that if \a NewScalarType is equal to the current scalar type of \c *this
     * then this function smartly returns a const reference to \c *this.
     */
   template<typename NewScalarType>
-  EIGEN_DEVICE_FUNC inline typename internal::cast_return_type<Derived,Quaternion<NewScalarType> >::type cast() const
+  EIGEN_DEVICE_FUNC inline typename internal::cast_return_type<Derived,Quaternion<NewScalarType> >::type cast() const;
+
+  #else
+
+  template<typename NewScalarType>
+  EIGEN_DEVICE_FUNC inline
+  typename internal::enable_if<internal::is_same<Scalar,NewScalarType>::value,const Derived&>::type cast() const
+  {
+    return derived();
+  }
+
+  template<typename NewScalarType>
+  EIGEN_DEVICE_FUNC inline
+  typename internal::enable_if<!internal::is_same<Scalar,NewScalarType>::value,Quaternion<NewScalarType> >::type cast() const
   {
-    return typename internal::cast_return_type<Derived,Quaternion<NewScalarType> >::type(derived());
+    return Quaternion<NewScalarType>(coeffs().template cast<NewScalarType>());
   }
+  #endif
+
+#ifndef EIGEN_NO_IO
+  friend std::ostream& operator<<(std::ostream& s, const QuaternionBase<Derived>& q) {
+    s << q.x() << "i + " << q.y() << "j + " << q.z() << "k" << " + " << q.w();
+    return s;
+  }
+#endif
 
 #ifdef EIGEN_QUATERNIONBASE_PLUGIN
 # include EIGEN_QUATERNIONBASE_PLUGIN
 #endif
+protected:
+  EIGEN_DEFAULT_COPY_CONSTRUCTOR(QuaternionBase)
+  EIGEN_DEFAULT_EMPTY_CONSTRUCTOR_AND_DESTRUCTOR(QuaternionBase)
 };
 
 /***************************************************************************
 * Definition/implementation of Quaternion<Scalar>
 ***************************************************************************/
 
 /** \geometry_module \ingroup Geometry_Module
@@ -285,20 +326,14 @@
 
   /** Default move assignment operator */
   EIGEN_DEVICE_FUNC Quaternion& operator=(Quaternion&& other) EIGEN_NOEXCEPT_IF(std::is_nothrow_move_assignable<Scalar>::value)
   {
     m_coeffs = std::move(other.coeffs());
     return *this;
   }
-
-  // And now because we declared a constructor, we don't get an implicit copy constructor. Say we want one.
-  /** Default copy constructor */
-  EIGEN_DEVICE_FUNC Quaternion(const Quaternion& other)
-    : m_coeffs(other.coeffs())
-  {}
 #endif
 
   EIGEN_DEVICE_FUNC static Quaternion UnitRandom();
 
   template<typename Derived1, typename Derived2>
   EIGEN_DEVICE_FUNC static Quaternion FromTwoVectors(const MatrixBase<Derived1>& a, const MatrixBase<Derived2>& b);
 
@@ -521,16 +556,16 @@
 }
 
 /** Set \c *this from an angle-axis \a aa and returns a reference to \c *this
   */
 template<class Derived>
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE Derived& QuaternionBase<Derived>::operator=(const AngleAxisType& aa)
 {
-  EIGEN_USING_STD_MATH(cos)
-  EIGEN_USING_STD_MATH(sin)
+  EIGEN_USING_STD(cos)
+  EIGEN_USING_STD(sin)
   Scalar ha = Scalar(0.5)*aa.angle(); // Scalar(0.5) to suppress precision loss warnings
   this->w() = cos(ha);
   this->vec() = sin(ha) * aa.axis();
   return derived();
 }
 
 /** Set \c *this from the expression \a xpr:
@@ -598,15 +633,15 @@
   * Note that the two input vectors do \b not have to be normalized, and
   * do not need to have the same norm.
   */
 template<class Derived>
 template<typename Derived1, typename Derived2>
 EIGEN_DEVICE_FUNC inline Derived& QuaternionBase<Derived>::setFromTwoVectors(const MatrixBase<Derived1>& a, const MatrixBase<Derived2>& b)
 {
-  EIGEN_USING_STD_MATH(sqrt)
+  EIGEN_USING_STD(sqrt)
   Vector3 v0 = a.normalized();
   Vector3 v1 = b.normalized();
   Scalar c = v1.dot(v0);
 
   // if dot == -1, vectors are nearly opposites
   // => accurately compute the rotation axis by computing the
   //    intersection of the two planes. This is done by solving:
@@ -639,17 +674,17 @@
 /** \returns a random unit quaternion following a uniform distribution law on SO(3)
   *
   * \note The implementation is based on http://planning.cs.uiuc.edu/node198.html
   */
 template<typename Scalar, int Options>
 EIGEN_DEVICE_FUNC Quaternion<Scalar,Options> Quaternion<Scalar,Options>::UnitRandom()
 {
-  EIGEN_USING_STD_MATH(sqrt)
-  EIGEN_USING_STD_MATH(sin)
-  EIGEN_USING_STD_MATH(cos)
+  EIGEN_USING_STD(sqrt)
+  EIGEN_USING_STD(sin)
+  EIGEN_USING_STD(cos)
   const Scalar u1 = internal::random<Scalar>(0, 1),
                u2 = internal::random<Scalar>(0, 2*EIGEN_PI),
                u3 = internal::random<Scalar>(0, 2*EIGEN_PI);
   const Scalar a = sqrt(Scalar(1) - u1),
                b = sqrt(u1);
   return Quaternion (a * sin(u2), a * cos(u2), b * sin(u3), b * cos(u3));
 }
@@ -724,15 +759,15 @@
   * \sa dot()
   */
 template <class Derived>
 template <class OtherDerived>
 EIGEN_DEVICE_FUNC inline typename internal::traits<Derived>::Scalar
 QuaternionBase<Derived>::angularDistance(const QuaternionBase<OtherDerived>& other) const
 {
-  EIGEN_USING_STD_MATH(atan2)
+  EIGEN_USING_STD(atan2)
   Quaternion<Scalar> d = (*this) * other.conjugate();
   return Scalar(2) * atan2( d.vec().norm(), numext::abs(d.w()) );
 }
 
  
     
 /** \returns the spherical linear interpolation between the two quaternions
@@ -742,16 +777,16 @@
   * see also http://en.wikipedia.org/wiki/Slerp.
   */
 template <class Derived>
 template <class OtherDerived>
 EIGEN_DEVICE_FUNC Quaternion<typename internal::traits<Derived>::Scalar>
 QuaternionBase<Derived>::slerp(const Scalar& t, const QuaternionBase<OtherDerived>& other) const
 {
-  EIGEN_USING_STD_MATH(acos)
-  EIGEN_USING_STD_MATH(sin)
+  EIGEN_USING_STD(acos)
+  EIGEN_USING_STD(sin)
   const Scalar one = Scalar(1) - NumTraits<Scalar>::epsilon();
   Scalar d = this->dot(other);
   Scalar absD = numext::abs(d);
 
   Scalar scale0;
   Scalar scale1;
 
@@ -780,15 +815,15 @@
 template<typename Other>
 struct quaternionbase_assign_impl<Other,3,3>
 {
   typedef typename Other::Scalar Scalar;
   template<class Derived> EIGEN_DEVICE_FUNC static inline void run(QuaternionBase<Derived>& q, const Other& a_mat)
   {
     const typename internal::nested_eval<Other,2>::type mat(a_mat);
-    EIGEN_USING_STD_MATH(sqrt)
+    EIGEN_USING_STD(sqrt)
     // This algorithm comes from  "Quaternion Calculus and Fast Animation",
     // Ken Shoemake, 1987 SIGGRAPH course notes
     Scalar t = mat.trace();
     if (t > Scalar(0))
     {
       t = sqrt(t + Scalar(1.0));
       q.w() = Scalar(0.5)*t;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Rotation2D.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Rotation2D.h`

 * *Files 2% similar despite different names*

```diff
@@ -171,28 +171,28 @@
   * In other words, this function extract the rotation angle
   * from the rotation matrix.
   */
 template<typename Scalar>
 template<typename Derived>
 EIGEN_DEVICE_FUNC Rotation2D<Scalar>& Rotation2D<Scalar>::fromRotationMatrix(const MatrixBase<Derived>& mat)
 {
-  EIGEN_USING_STD_MATH(atan2)
+  EIGEN_USING_STD(atan2)
   EIGEN_STATIC_ASSERT(Derived::RowsAtCompileTime==2 && Derived::ColsAtCompileTime==2,YOU_MADE_A_PROGRAMMING_MISTAKE)
   m_angle = atan2(mat.coeff(1,0), mat.coeff(0,0));
   return *this;
 }
 
 /** Constructs and \returns an equivalent 2x2 rotation matrix.
   */
 template<typename Scalar>
 typename Rotation2D<Scalar>::Matrix2
 EIGEN_DEVICE_FUNC Rotation2D<Scalar>::toRotationMatrix(void) const
 {
-  EIGEN_USING_STD_MATH(sin)
-  EIGEN_USING_STD_MATH(cos)
+  EIGEN_USING_STD(sin)
+  EIGEN_USING_STD(cos)
   Scalar sinA = sin(m_angle);
   Scalar cosA = cos(m_angle);
   return (Matrix2() << cosA, -sinA, sinA, cosA).finished();
 }
 
 } // end namespace Eigen
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/RotationBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/RotationBase.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Scaling.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Scaling.h`

 * *Files 0% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 #ifndef EIGEN_SCALING_H
 #define EIGEN_SCALING_H
 
 namespace Eigen { 
 
 /** \geometry_module \ingroup Geometry_Module
   *
-  * \class Scaling
+  * \class UniformScaling
   *
   * \brief Represents a generic uniform scaling transformation
   *
   * \tparam _Scalar the scalar type, i.e., the type of the coefficients.
   *
   * This class represent a uniform scaling transformation. It is the return
   * type of Scaling(Scalar), and most of the time this is the only way it
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Transform.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Transform.h`

 * *Files 1% similar despite different names*

```diff
@@ -8,15 +8,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_TRANSFORM_H
 #define EIGEN_TRANSFORM_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename Transform>
 struct transform_traits
 {
   enum
@@ -43,15 +43,15 @@
           int HDim,
           int OtherRows=Other::RowsAtCompileTime,
           int OtherCols=Other::ColsAtCompileTime>
 struct transform_left_product_impl;
 
 template< typename Lhs,
           typename Rhs,
-          bool AnyProjective = 
+          bool AnyProjective =
             transform_traits<Lhs>::IsProjective ||
             transform_traits<Rhs>::IsProjective>
 struct transform_transform_product_impl;
 
 template< typename Other,
           int Mode,
           int Options,
@@ -219,17 +219,17 @@
   /** type of the matrix used to represent the transformation */
   typedef typename internal::make_proper_matrix_type<Scalar,Rows,HDim,Options>::type MatrixType;
   /** constified MatrixType */
   typedef const MatrixType ConstMatrixType;
   /** type of the matrix used to represent the linear part of the transformation */
   typedef Matrix<Scalar,Dim,Dim,Options> LinearMatrixType;
   /** type of read/write reference to the linear part of the transformation */
-  typedef Block<MatrixType,Dim,Dim,int(Mode)==(AffineCompact) && (Options&RowMajor)==0> LinearPart;
+  typedef Block<MatrixType,Dim,Dim,int(Mode)==(AffineCompact) && (int(Options)&RowMajor)==0> LinearPart;
   /** type of read reference to the linear part of the transformation */
-  typedef const Block<ConstMatrixType,Dim,Dim,int(Mode)==(AffineCompact) && (Options&RowMajor)==0> ConstLinearPart;
+  typedef const Block<ConstMatrixType,Dim,Dim,int(Mode)==(AffineCompact) && (int(Options)&RowMajor)==0> ConstLinearPart;
   /** type of read/write reference to the affine part of the transformation */
   typedef typename internal::conditional<int(Mode)==int(AffineCompact),
                               MatrixType&,
                               Block<MatrixType,Dim,HDim> >::type AffinePart;
   /** type of read reference to the affine part of the transformation */
   typedef typename internal::conditional<int(Mode)==int(AffineCompact),
                               const MatrixType&,
@@ -238,15 +238,15 @@
   typedef Matrix<Scalar,Dim,1> VectorType;
   /** type of a read/write reference to the translation part of the rotation */
   typedef Block<MatrixType,Dim,1,!(internal::traits<MatrixType>::Flags & RowMajorBit)> TranslationPart;
   /** type of a read reference to the translation part of the rotation */
   typedef const Block<ConstMatrixType,Dim,1,!(internal::traits<MatrixType>::Flags & RowMajorBit)> ConstTranslationPart;
   /** corresponding translation type */
   typedef Translation<Scalar,Dim> TranslationType;
-  
+
   // this intermediate enum is needed to avoid an ICE with gcc 3.4 and 4.0
   enum { TransformTimeDiagonalMode = ((Mode==int(Isometry))?Affine:int(Mode)) };
   /** The return type of the product between a diagonal matrix and a transform */
   typedef Transform<Scalar,Dim,TransformTimeDiagonalMode> TransformTimeDiagonalReturnType;
 
 protected:
 
@@ -258,20 +258,14 @@
     * If Mode==Affine or Mode==Isometry, then the last row is set to [0 ... 0 1] */
   EIGEN_DEVICE_FUNC inline Transform()
   {
     check_template_params();
     internal::transform_make_affine<(int(Mode)==Affine || int(Mode)==Isometry) ? Affine : AffineCompact>::run(m_matrix);
   }
 
-  EIGEN_DEVICE_FUNC inline Transform(const Transform& other)
-  {
-    check_template_params();
-    m_matrix = other.m_matrix;
-  }
-
   EIGEN_DEVICE_FUNC inline explicit Transform(const TranslationType& t)
   {
     check_template_params();
     *this = t;
   }
   EIGEN_DEVICE_FUNC inline explicit Transform(const UniformScaling<Scalar>& s)
   {
@@ -281,17 +275,14 @@
   template<typename Derived>
   EIGEN_DEVICE_FUNC inline explicit Transform(const RotationBase<Derived, Dim>& r)
   {
     check_template_params();
     *this = r;
   }
 
-  EIGEN_DEVICE_FUNC inline Transform& operator=(const Transform& other)
-  { m_matrix = other.m_matrix; return *this; }
-
   typedef internal::transform_take_affine_part<Transform> take_affine_part;
 
   /** Constructs and initializes a transformation from a Dim^2 or a (Dim+1)^2 matrix. */
   template<typename OtherDerived>
   EIGEN_DEVICE_FUNC inline explicit Transform(const EigenBase<OtherDerived>& other)
   {
     EIGEN_STATIC_ASSERT((internal::is_same<Scalar,typename OtherDerived::Scalar>::value),
@@ -307,15 +298,15 @@
   {
     EIGEN_STATIC_ASSERT((internal::is_same<Scalar,typename OtherDerived::Scalar>::value),
       YOU_MIXED_DIFFERENT_NUMERIC_TYPES__YOU_NEED_TO_USE_THE_CAST_METHOD_OF_MATRIXBASE_TO_CAST_NUMERIC_TYPES_EXPLICITLY);
 
     internal::transform_construct_from_matrix<OtherDerived,Mode,Options,Dim,HDim>::run(this, other.derived());
     return *this;
   }
-  
+
   template<int OtherOptions>
   EIGEN_DEVICE_FUNC inline Transform(const Transform<Scalar,Dim,Mode,OtherOptions>& other)
   {
     check_template_params();
     // only the options change, we can directly copy the matrices
     m_matrix = other.matrix();
   }
@@ -379,17 +370,17 @@
   inline Transform(const QMatrix& other);
   inline Transform& operator=(const QMatrix& other);
   inline QMatrix toQMatrix(void) const;
   inline Transform(const QTransform& other);
   inline Transform& operator=(const QTransform& other);
   inline QTransform toQTransform(void) const;
   #endif
-  
-  EIGEN_DEVICE_FUNC Index rows() const { return int(Mode)==int(Projective) ? m_matrix.cols() : (m_matrix.cols()-1); }
-  EIGEN_DEVICE_FUNC Index cols() const { return m_matrix.cols(); }
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return int(Mode)==int(Projective) ? m_matrix.cols() : (m_matrix.cols()-1); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_matrix.cols(); }
 
   /** shortcut for m_matrix(row,col);
     * \sa MatrixBase::operator(Index,Index) const */
   EIGEN_DEVICE_FUNC inline Scalar operator() (Index row, Index col) const { return m_matrix(row,col); }
   /** shortcut for m_matrix(row,col);
     * \sa MatrixBase::operator(Index,Index) */
   EIGEN_DEVICE_FUNC inline Scalar& operator() (Index row, Index col) { return m_matrix(row,col); }
@@ -455,30 +446,30 @@
   EIGEN_DEVICE_FUNC inline const typename internal::transform_left_product_impl<OtherDerived,Mode,Options,_Dim,_Dim+1>::ResultType
     operator * (const EigenBase<OtherDerived> &a, const Transform &b)
   { return internal::transform_left_product_impl<OtherDerived,Mode,Options,Dim,HDim>::run(a.derived(),b); }
 
   /** \returns The product expression of a transform \a a times a diagonal matrix \a b
     *
     * The rhs diagonal matrix is interpreted as an affine scaling transformation. The
-    * product results in a Transform of the same type (mode) as the lhs only if the lhs 
+    * product results in a Transform of the same type (mode) as the lhs only if the lhs
     * mode is no isometry. In that case, the returned transform is an affinity.
     */
   template<typename DiagonalDerived>
   EIGEN_DEVICE_FUNC inline const TransformTimeDiagonalReturnType
     operator * (const DiagonalBase<DiagonalDerived> &b) const
   {
     TransformTimeDiagonalReturnType res(*this);
     res.linearExt() *= b;
     return res;
   }
 
   /** \returns The product expression of a diagonal matrix \a a times a transform \a b
     *
     * The lhs diagonal matrix is interpreted as an affine scaling transformation. The
-    * product results in a Transform of the same type (mode) as the lhs only if the lhs 
+    * product results in a Transform of the same type (mode) as the lhs only if the lhs
     * mode is no isometry. In that case, the returned transform is an affinity.
     */
   template<typename DiagonalDerived>
   EIGEN_DEVICE_FUNC friend inline TransformTimeDiagonalReturnType
     operator * (const DiagonalBase<DiagonalDerived> &a, const Transform &b)
   {
     TransformTimeDiagonalReturnType res;
@@ -493,30 +484,30 @@
   EIGEN_DEVICE_FUNC inline Transform& operator*=(const EigenBase<OtherDerived>& other) { return *this = *this * other; }
 
   /** Concatenates two transformations */
   EIGEN_DEVICE_FUNC inline const Transform operator * (const Transform& other) const
   {
     return internal::transform_transform_product_impl<Transform,Transform>::run(*this,other);
   }
-  
+
   #if EIGEN_COMP_ICC
 private:
   // this intermediate structure permits to workaround a bug in ICC 11:
   //   error: template instantiation resulted in unexpected function type of "Eigen::Transform<double, 3, 32, 0>
   //             (const Eigen::Transform<double, 3, 2, 0> &) const"
   //  (the meaning of a name may have changed since the template declaration -- the type of the template is:
   // "Eigen::internal::transform_transform_product_impl<Eigen::Transform<double, 3, 32, 0>,
   //     Eigen::Transform<double, 3, Mode, Options>, <expression>>::ResultType (const Eigen::Transform<double, 3, Mode, Options> &) const")
-  // 
+  //
   template<int OtherMode,int OtherOptions> struct icc_11_workaround
   {
     typedef internal::transform_transform_product_impl<Transform,Transform<Scalar,Dim,OtherMode,OtherOptions> > ProductType;
     typedef typename ProductType::ResultType ResultType;
   };
-  
+
 public:
   /** Concatenates two different transformations */
   template<int OtherMode,int OtherOptions>
   inline typename icc_11_workaround<OtherMode,OtherOptions>::ResultType
     operator * (const Transform<Scalar,Dim,OtherMode,OtherOptions>& other) const
   {
     typedef typename icc_11_workaround<OtherMode,OtherOptions>::ProductType ProductType;
@@ -541,15 +532,15 @@
    */
   EIGEN_DEVICE_FUNC static const Transform Identity()
   {
     return Transform(MatrixType::Identity());
   }
 
   template<typename OtherDerived>
-  EIGEN_DEVICE_FUNC 
+  EIGEN_DEVICE_FUNC
   inline Transform& scale(const MatrixBase<OtherDerived> &other);
 
   template<typename OtherDerived>
   EIGEN_DEVICE_FUNC
   inline Transform& prescale(const MatrixBase<OtherDerived> &other);
 
   EIGEN_DEVICE_FUNC inline Transform& scale(const Scalar& s);
@@ -571,26 +562,26 @@
   EIGEN_DEVICE_FUNC
   inline Transform& prerotate(const RotationType& rotation);
 
   EIGEN_DEVICE_FUNC Transform& shear(const Scalar& sx, const Scalar& sy);
   EIGEN_DEVICE_FUNC Transform& preshear(const Scalar& sx, const Scalar& sy);
 
   EIGEN_DEVICE_FUNC inline Transform& operator=(const TranslationType& t);
-  
+
   EIGEN_DEVICE_FUNC
   inline Transform& operator*=(const TranslationType& t) { return translate(t.vector()); }
-  
+
   EIGEN_DEVICE_FUNC inline Transform operator*(const TranslationType& t) const;
 
-  EIGEN_DEVICE_FUNC 
+  EIGEN_DEVICE_FUNC
   inline Transform& operator=(const UniformScaling<Scalar>& t);
-  
+
   EIGEN_DEVICE_FUNC
   inline Transform& operator*=(const UniformScaling<Scalar>& s) { return scale(s.factor()); }
-  
+
   EIGEN_DEVICE_FUNC
   inline TransformTimeDiagonalReturnType operator*(const UniformScaling<Scalar>& s) const
   {
     TransformTimeDiagonalReturnType res = *this;
     res.scale(s.factor());
     return res;
   }
@@ -685,15 +676,15 @@
   EIGEN_DEVICE_FUNC inline const Block<MatrixType,int(Mode)==int(Projective)?HDim:Dim,1> translationExt() const
   { return m_matrix.template block<int(Mode)==int(Projective)?HDim:Dim,1>(0,Dim); }
 
 
   #ifdef EIGEN_TRANSFORM_PLUGIN
   #include EIGEN_TRANSFORM_PLUGIN
   #endif
-  
+
 protected:
   #ifndef EIGEN_PARSED_BY_DOXYGEN
     EIGEN_DEVICE_FUNC static EIGEN_STRONG_INLINE void check_template_params()
     {
       EIGEN_STATIC_ASSERT((Options & (DontAlign|RowMajor)) == Options, INVALID_MATRIX_TEMPLATE_PARAMETERS)
     }
   #endif
@@ -1053,15 +1044,15 @@
 
 namespace internal {
 template<int Mode> struct transform_rotation_impl {
   template<typename TransformType>
   EIGEN_DEVICE_FUNC static inline
   const typename TransformType::LinearMatrixType run(const TransformType& t)
   {
-    typedef typename TransformType::LinearMatrixType LinearMatrixType; 
+    typedef typename TransformType::LinearMatrixType LinearMatrixType;
     LinearMatrixType result;
     t.computeRotationScaling(&result, (LinearMatrixType*)0);
     return result;
   }
 };
 template<> struct transform_rotation_impl<Isometry> {
   template<typename TransformType>
@@ -1102,24 +1093,25 @@
   *
   * \sa computeScalingRotation(), rotation(), class SVD
   */
 template<typename Scalar, int Dim, int Mode, int Options>
 template<typename RotationMatrixType, typename ScalingMatrixType>
 EIGEN_DEVICE_FUNC void Transform<Scalar,Dim,Mode,Options>::computeRotationScaling(RotationMatrixType *rotation, ScalingMatrixType *scaling) const
 {
+  // Note that JacobiSVD is faster than BDCSVD for small matrices.
   JacobiSVD<LinearMatrixType> svd(linear(), ComputeFullU | ComputeFullV);
 
-  Scalar x = (svd.matrixU() * svd.matrixV().adjoint()).determinant(); // so x has absolute value 1
+  Scalar x = (svd.matrixU() * svd.matrixV().adjoint()).determinant() < Scalar(0) ? Scalar(-1) : Scalar(1); // so x has absolute value 1
   VectorType sv(svd.singularValues());
-  sv.coeffRef(0) *= x;
+  sv.coeffRef(Dim-1) *= x;
   if(scaling) *scaling = svd.matrixV() * sv.asDiagonal() * svd.matrixV().adjoint();
   if(rotation)
   {
     LinearMatrixType m(svd.matrixU());
-    m.col(0) /= x;
+    m.col(Dim-1) *= x;
     *rotation = m * svd.matrixV().adjoint();
   }
 }
 
 /** decomposes the linear part of the transformation as a product scaling x rotation, the scaling being
   * not necessarily positive.
   *
@@ -1131,24 +1123,25 @@
   *
   * \sa computeRotationScaling(), rotation(), class SVD
   */
 template<typename Scalar, int Dim, int Mode, int Options>
 template<typename ScalingMatrixType, typename RotationMatrixType>
 EIGEN_DEVICE_FUNC void Transform<Scalar,Dim,Mode,Options>::computeScalingRotation(ScalingMatrixType *scaling, RotationMatrixType *rotation) const
 {
+  // Note that JacobiSVD is faster than BDCSVD for small matrices.
   JacobiSVD<LinearMatrixType> svd(linear(), ComputeFullU | ComputeFullV);
 
-  Scalar x = (svd.matrixU() * svd.matrixV().adjoint()).determinant(); // so x has absolute value 1
+  Scalar x = (svd.matrixU() * svd.matrixV().adjoint()).determinant() < Scalar(0) ? Scalar(-1) : Scalar(1); // so x has absolute value 1
   VectorType sv(svd.singularValues());
-  sv.coeffRef(0) *= x;
+  sv.coeffRef(Dim-1) *= x;
   if(scaling) *scaling = svd.matrixU() * sv.asDiagonal() * svd.matrixU().adjoint();
   if(rotation)
   {
     LinearMatrixType m(svd.matrixU());
-    m.col(0) /= x;
+    m.col(Dim-1) *= x;
     *rotation = m * svd.matrixV().adjoint();
   }
 }
 
 /** Convenient method to set \c *this from a position, orientation and scale
   * of a 3D object.
   */
@@ -1180,15 +1173,15 @@
 };
 
 template<>
 struct transform_make_affine<AffineCompact>
 {
   template<typename MatrixType> EIGEN_DEVICE_FUNC static void run(MatrixType &) { }
 };
-    
+
 // selector needed to avoid taking the inverse of a 3x4 matrix
 template<typename TransformType, int Mode=TransformType::Mode>
 struct projective_transform_inverse
 {
   EIGEN_DEVICE_FUNC static inline void run(const TransformType&, TransformType&)
   {}
 };
@@ -1321,74 +1314,74 @@
 /**********************************************************
 ***   Specializations of operator* with rhs EigenBase   ***
 **********************************************************/
 
 template<int LhsMode,int RhsMode>
 struct transform_product_result
 {
-  enum 
-  { 
+  enum
+  {
     Mode =
       (LhsMode == (int)Projective    || RhsMode == (int)Projective    ) ? Projective :
       (LhsMode == (int)Affine        || RhsMode == (int)Affine        ) ? Affine :
       (LhsMode == (int)AffineCompact || RhsMode == (int)AffineCompact ) ? AffineCompact :
       (LhsMode == (int)Isometry      || RhsMode == (int)Isometry      ) ? Isometry : Projective
   };
 };
 
 template< typename TransformType, typename MatrixType, int RhsCols>
 struct transform_right_product_impl< TransformType, MatrixType, 0, RhsCols>
 {
   typedef typename MatrixType::PlainObject ResultType;
 
-  static EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
   {
     return T.matrix() * other;
   }
 };
 
 template< typename TransformType, typename MatrixType, int RhsCols>
 struct transform_right_product_impl< TransformType, MatrixType, 1, RhsCols>
 {
-  enum { 
-    Dim = TransformType::Dim, 
+  enum {
+    Dim = TransformType::Dim,
     HDim = TransformType::HDim,
     OtherRows = MatrixType::RowsAtCompileTime,
     OtherCols = MatrixType::ColsAtCompileTime
   };
 
   typedef typename MatrixType::PlainObject ResultType;
 
-  static EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
   {
     EIGEN_STATIC_ASSERT(OtherRows==HDim, YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES);
 
     typedef Block<ResultType, Dim, OtherCols, int(MatrixType::RowsAtCompileTime)==Dim> TopLeftLhs;
 
     ResultType res(other.rows(),other.cols());
     TopLeftLhs(res, 0, 0, Dim, other.cols()).noalias() = T.affine() * other;
     res.row(OtherRows-1) = other.row(OtherRows-1);
-    
+
     return res;
   }
 };
 
 template< typename TransformType, typename MatrixType, int RhsCols>
 struct transform_right_product_impl< TransformType, MatrixType, 2, RhsCols>
 {
-  enum { 
-    Dim = TransformType::Dim, 
+  enum {
+    Dim = TransformType::Dim,
     HDim = TransformType::HDim,
     OtherRows = MatrixType::RowsAtCompileTime,
     OtherCols = MatrixType::ColsAtCompileTime
   };
 
   typedef typename MatrixType::PlainObject ResultType;
 
-  static EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
   {
     EIGEN_STATIC_ASSERT(OtherRows==Dim, YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES);
 
     typedef Block<ResultType, Dim, OtherCols, true> TopLeftLhs;
     ResultType res(Replicate<typename TransformType::ConstTranslationPart, 1, OtherCols>(T.translation(),1,other.cols()));
     TopLeftLhs(res, 0, 0, Dim, other.cols()).noalias() += T.linear() * other;
 
@@ -1405,15 +1398,15 @@
     HDim = TransformType::HDim,
     OtherRows = MatrixType::RowsAtCompileTime,
     WorkingRows = EIGEN_PLAIN_ENUM_MIN(TransformMatrix::RowsAtCompileTime,HDim)
   };
 
   typedef typename MatrixType::PlainObject ResultType;
 
-  static EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
+  static EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE ResultType run(const TransformType& T, const MatrixType& other)
   {
     EIGEN_STATIC_ASSERT(OtherRows==Dim, YOU_MIXED_MATRICES_OF_DIFFERENT_SIZES);
 
     Matrix<typename ResultType::Scalar, Dim+1, 1> rhs;
     rhs.template head<Dim>() = other; rhs[Dim] = typename ResultType::Scalar(1);
     Matrix<typename ResultType::Scalar, WorkingRows, 1> res(T.matrix() * rhs);
     return res.template head<Dim>();
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Translation.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Translation.h`

 * *Files 1% similar despite different names*

```diff
@@ -134,20 +134,14 @@
   inline typename internal::enable_if<Derived::IsVectorAtCompileTime,VectorType>::type
   operator* (const MatrixBase<Derived>& vec) const
   { return m_coeffs + vec.derived(); }
 
   /** \returns the inverse translation (opposite) */
   Translation inverse() const { return Translation(-m_coeffs); }
 
-  Translation& operator=(const Translation& other)
-  {
-    m_coeffs = other.m_coeffs;
-    return *this;
-  }
-
   static const Translation Identity() { return Translation(VectorType::Zero()); }
 
   /** \returns \c *this with scalar type casted to \a NewScalarType
     *
     * Note that if \a NewScalarType is equal to the current scalar type of \c *this
     * then this function smartly returns a const reference to \c *this.
     */
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/Umeyama.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/Umeyama.h`

 * *Files 1% similar despite different names*

```diff
@@ -83,15 +83,15 @@
 * \param src Source points \f$ \mathbf{x} = \left( x_1, \hdots, x_n \right) \f$.
 * \param dst Destination points \f$ \mathbf{y} = \left( y_1, \hdots, y_n \right) \f$.
 * \param with_scaling Sets \f$ c=1 \f$ when <code>false</code> is passed.
 * \return The homogeneous transformation 
 * \f{align*}
 *   T = \begin{bmatrix} c\mathbf{R} & \mathbf{t} \\ \mathbf{0} & 1 \end{bmatrix}
 * \f}
-* minimizing the resudiual above. This transformation is always returned as an 
+* minimizing the residual above. This transformation is always returned as an 
 * Eigen::Matrix.
 */
 template <typename Derived, typename OtherDerived>
 typename internal::umeyama_transform_matrix_type<Derived, OtherDerived>::type
 umeyama(const MatrixBase<Derived>& src, const MatrixBase<OtherDerived>& dst, bool with_scaling = true)
 {
   typedef typename internal::umeyama_transform_matrix_type<Derived, OtherDerived>::type TransformationMatrixType;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Geometry/arch/Geometry_SSE.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Geometry/arch/Geometry_SIMD.h`

 * *Files 9% similar despite different names*

```diff
@@ -4,35 +4,37 @@
 // Copyright (C) 2009 Rohit Garg <rpg.314@gmail.com>
 // Copyright (C) 2009-2010 Gael Guennebaud <gael.guennebaud@inria.fr>
 //
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
-#ifndef EIGEN_GEOMETRY_SSE_H
-#define EIGEN_GEOMETRY_SSE_H
+#ifndef EIGEN_GEOMETRY_SIMD_H
+#define EIGEN_GEOMETRY_SIMD_H
 
 namespace Eigen { 
 
 namespace internal {
 
 template<class Derived, class OtherDerived>
-struct quat_product<Architecture::SSE, Derived, OtherDerived, float>
+struct quat_product<Architecture::Target, Derived, OtherDerived, float>
 {
   enum {
     AAlignment = traits<Derived>::Alignment,
     BAlignment = traits<OtherDerived>::Alignment,
     ResAlignment = traits<Quaternion<float> >::Alignment
   };
   static inline Quaternion<float> run(const QuaternionBase<Derived>& _a, const QuaternionBase<OtherDerived>& _b)
   {
     evaluator<typename Derived::Coefficients> ae(_a.coeffs());
     evaluator<typename OtherDerived::Coefficients> be(_b.coeffs());
     Quaternion<float> res;
-    const Packet4f mask = _mm_setr_ps(0.f,0.f,0.f,-0.f);
+    const float neg_zero = numext::bit_cast<float>(0x80000000u);
+    const float arr[4] = {0.f, 0.f, 0.f, neg_zero};
+    const Packet4f mask = ploadu<Packet4f>(arr);
     Packet4f a = ae.template packet<AAlignment,Packet4f>(0);
     Packet4f b = be.template packet<BAlignment,Packet4f>(0);
     Packet4f s1 = pmul(vec4f_swizzle1(a,1,2,0,2),vec4f_swizzle1(b,2,0,1,2));
     Packet4f s2 = pmul(vec4f_swizzle1(a,3,3,3,1),vec4f_swizzle1(b,0,1,2,1));
     pstoret<float,Packet4f,ResAlignment>(
               &res.x(),
               padd(psub(pmul(a,vec4f_swizzle1(b,3,3,3,3)),
@@ -41,32 +43,34 @@
                          pxor(mask,padd(s1,s2))));
     
     return res;
   }
 };
 
 template<class Derived>
-struct quat_conj<Architecture::SSE, Derived, float>
+struct quat_conj<Architecture::Target, Derived, float>
 {
   enum {
     ResAlignment = traits<Quaternion<float> >::Alignment
   };
   static inline Quaternion<float> run(const QuaternionBase<Derived>& q)
   {
     evaluator<typename Derived::Coefficients> qe(q.coeffs());
     Quaternion<float> res;
-    const Packet4f mask = _mm_setr_ps(-0.f,-0.f,-0.f,0.f);
+    const float neg_zero = numext::bit_cast<float>(0x80000000u);
+    const float arr[4] = {neg_zero, neg_zero, neg_zero,0.f};
+    const Packet4f mask = ploadu<Packet4f>(arr);
     pstoret<float,Packet4f,ResAlignment>(&res.x(), pxor(mask, qe.template packet<traits<Derived>::Alignment,Packet4f>(0)));
     return res;
   }
 };
 
 
 template<typename VectorLhs,typename VectorRhs>
-struct cross3_impl<Architecture::SSE,VectorLhs,VectorRhs,float,true>
+struct cross3_impl<Architecture::Target,VectorLhs,VectorRhs,float,true>
 {
   enum {
     ResAlignment = traits<typename plain_matrix_type<VectorLhs>::type>::Alignment
   };
   static inline typename plain_matrix_type<VectorLhs>::type
   run(const VectorLhs& lhs, const VectorRhs& rhs)
   {
@@ -80,27 +84,26 @@
     pstoret<float,Packet4f,ResAlignment>(&res.x(),psub(mul1,mul2));
     return res;
   }
 };
 
 
 
+#if (defined EIGEN_VECTORIZE_SSE) || (EIGEN_ARCH_ARM64)
 
 template<class Derived, class OtherDerived>
-struct quat_product<Architecture::SSE, Derived, OtherDerived, double>
+struct quat_product<Architecture::Target, Derived, OtherDerived, double>
 {
   enum {
     BAlignment = traits<OtherDerived>::Alignment,
     ResAlignment = traits<Quaternion<double> >::Alignment
   };
 
   static inline Quaternion<double> run(const QuaternionBase<Derived>& _a, const QuaternionBase<OtherDerived>& _b)
   {
-  const Packet2d mask = _mm_castsi128_pd(_mm_set_epi32(0x0,0x0,0x80000000,0x0));
-
   Quaternion<double> res;
 
   evaluator<typename Derived::Coefficients> ae(_a.coeffs());
   evaluator<typename OtherDerived::Coefficients> be(_b.coeffs());
 
   const double* a = _a.coeffs().data();
   Packet2d b_xy = be.template packet<BAlignment,Packet2d>(0);
@@ -116,55 +119,50 @@
   /*
    * t1 = ww*xy + yy*zw
    * t2 = zz*xy - xx*zw
    * res.xy = t1 +/- swap(t2)
    */
   t1 = padd(pmul(a_ww, b_xy), pmul(a_yy, b_zw));
   t2 = psub(pmul(a_zz, b_xy), pmul(a_xx, b_zw));
-#ifdef EIGEN_VECTORIZE_SSE3
-  EIGEN_UNUSED_VARIABLE(mask)
-  pstoret<double,Packet2d,ResAlignment>(&res.x(), _mm_addsub_pd(t1, preverse(t2)));
-#else
-  pstoret<double,Packet2d,ResAlignment>(&res.x(), padd(t1, pxor(mask,preverse(t2))));
-#endif
+  pstoret<double,Packet2d,ResAlignment>(&res.x(), paddsub(t1, preverse(t2)));
   
   /*
    * t1 = ww*zw - yy*xy
    * t2 = zz*zw + xx*xy
    * res.zw = t1 -/+ swap(t2) = swap( swap(t1) +/- t2)
    */
   t1 = psub(pmul(a_ww, b_zw), pmul(a_yy, b_xy));
   t2 = padd(pmul(a_zz, b_zw), pmul(a_xx, b_xy));
-#ifdef EIGEN_VECTORIZE_SSE3
-  EIGEN_UNUSED_VARIABLE(mask)
-  pstoret<double,Packet2d,ResAlignment>(&res.z(), preverse(_mm_addsub_pd(preverse(t1), t2)));
-#else
-  pstoret<double,Packet2d,ResAlignment>(&res.z(), psub(t1, pxor(mask,preverse(t2))));
-#endif
+  pstoret<double,Packet2d,ResAlignment>(&res.z(), preverse(paddsub(preverse(t1), t2)));
 
   return res;
 }
 };
 
 template<class Derived>
-struct quat_conj<Architecture::SSE, Derived, double>
+struct quat_conj<Architecture::Target, Derived, double>
 {
   enum {
     ResAlignment = traits<Quaternion<double> >::Alignment
   };
   static inline Quaternion<double> run(const QuaternionBase<Derived>& q)
   {
     evaluator<typename Derived::Coefficients> qe(q.coeffs());
     Quaternion<double> res;
-    const Packet2d mask0 = _mm_setr_pd(-0.,-0.);
-    const Packet2d mask2 = _mm_setr_pd(-0.,0.);
+    const double neg_zero = numext::bit_cast<double>(0x8000000000000000ull);
+    const double arr1[2] = {neg_zero, neg_zero};
+    const double arr2[2] = {neg_zero,  0.0};
+    const Packet2d mask0 = ploadu<Packet2d>(arr1);
+    const Packet2d mask2 = ploadu<Packet2d>(arr2);
     pstoret<double,Packet2d,ResAlignment>(&res.x(), pxor(mask0, qe.template packet<traits<Derived>::Alignment,Packet2d>(0)));
     pstoret<double,Packet2d,ResAlignment>(&res.z(), pxor(mask2, qe.template packet<traits<Derived>::Alignment,Packet2d>(2)));
     return res;
   }
 };
 
+#endif // end EIGEN_VECTORIZE_SSE_OR_EIGEN_ARCH_ARM64
+
 } // end namespace internal
 
 } // end namespace Eigen
 
-#endif // EIGEN_GEOMETRY_SSE_H
+#endif // EIGEN_GEOMETRY_SIMD_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Householder/BlockHouseholder.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Householder/BlockHouseholder.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Householder/Householder.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Householder/Householder.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Householder/HouseholderSequence.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Householder/HouseholderSequence.h`

 * *Files 2% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_HOUSEHOLDER_SEQUENCE_H
 #define EIGEN_HOUSEHOLDER_SEQUENCE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \ingroup Householder_Module
   * \householder_module
   * \class HouseholderSequence
   * \brief Sequence of Householder reflections acting on subspaces with decreasing size
   * \tparam VectorsType type of matrix containing the Householder vectors
   * \tparam CoeffsType  type of vector containing the Householder coefficients
@@ -30,16 +30,16 @@
   * HessenbergDecomposition::matrixQ(), Tridiagonalization::matrixQ(), HouseholderQR::householderQ(),
   * and ColPivHouseholderQR::householderQ() all return a %HouseholderSequence.
   *
   * More precisely, the class %HouseholderSequence represents an \f$ n \times n \f$ matrix \f$ H \f$ of the
   * form \f$ H = \prod_{i=0}^{n-1} H_i \f$ where the i-th Householder reflection is \f$ H_i = I - h_i v_i
   * v_i^* \f$. The i-th Householder coefficient \f$ h_i \f$ is a scalar and the i-th Householder vector \f$
   * v_i \f$ is a vector of the form
-  * \f[ 
-  * v_i = [\underbrace{0, \ldots, 0}_{i-1\mbox{ zeros}}, 1, \underbrace{*, \ldots,*}_{n-i\mbox{ arbitrary entries}} ]. 
+  * \f[
+  * v_i = [\underbrace{0, \ldots, 0}_{i-1\mbox{ zeros}}, 1, \underbrace{*, \ldots,*}_{n-i\mbox{ arbitrary entries}} ].
   * \f]
   * The last \f$ n-i \f$ entries of \f$ v_i \f$ are called the essential part of the Householder vector.
   *
   * Typical usages are listed below, where H is a HouseholderSequence:
   * \code
   * A.applyOnTheRight(H);             // A = A * H
   * A.applyOnTheLeft(H);              // A = H * A
@@ -116,15 +116,15 @@
 
 } // end namespace internal
 
 template<typename VectorsType, typename CoeffsType, int Side> class HouseholderSequence
   : public EigenBase<HouseholderSequence<VectorsType,CoeffsType,Side> >
 {
     typedef typename internal::hseq_side_dependent_impl<VectorsType,CoeffsType,Side>::EssentialVectorType EssentialVectorType;
-  
+
   public:
     enum {
       RowsAtCompileTime = internal::traits<HouseholderSequence>::RowsAtCompileTime,
       ColsAtCompileTime = internal::traits<HouseholderSequence>::ColsAtCompileTime,
       MaxRowsAtCompileTime = internal::traits<HouseholderSequence>::MaxRowsAtCompileTime,
       MaxColsAtCompileTime = internal::traits<HouseholderSequence>::MaxColsAtCompileTime
     };
@@ -194,35 +194,35 @@
         m_reverse(other.m_reverse),
         m_length(other.m_length),
         m_shift(other.m_shift)
     {
     }
 
     /** \brief Number of rows of transformation viewed as a matrix.
-      * \returns Number of rows 
+      * \returns Number of rows
       * \details This equals the dimension of the space that the transformation acts on.
       */
-    EIGEN_DEVICE_FUNC
-    Index rows() const { return Side==OnTheLeft ? m_vectors.rows() : m_vectors.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index rows() const EIGEN_NOEXCEPT { return Side==OnTheLeft ? m_vectors.rows() : m_vectors.cols(); }
 
     /** \brief Number of columns of transformation viewed as a matrix.
       * \returns Number of columns
       * \details This equals the dimension of the space that the transformation acts on.
       */
-    EIGEN_DEVICE_FUNC
-    Index cols() const { return rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    Index cols() const EIGEN_NOEXCEPT { return rows(); }
 
     /** \brief Essential part of a Householder vector.
       * \param[in]  k  Index of Householder reflection
       * \returns    Vector containing non-trivial entries of k-th Householder vector
       *
       * This function returns the essential part of the Householder vector \f$ v_i \f$. This is a vector of
       * length \f$ n-i \f$ containing the last \f$ n-i \f$ entries of the vector
-      * \f[ 
-      * v_i = [\underbrace{0, \ldots, 0}_{i-1\mbox{ zeros}}, 1, \underbrace{*, \ldots,*}_{n-i\mbox{ arbitrary entries}} ]. 
+      * \f[
+      * v_i = [\underbrace{0, \ldots, 0}_{i-1\mbox{ zeros}}, 1, \underbrace{*, \ldots,*}_{n-i\mbox{ arbitrary entries}} ].
       * \f]
       * The index \f$ i \f$ equals \p k + shift(), corresponding to the k-th column of the matrix \p v
       * passed to the constructor.
       *
       * \sa setShift(), shift()
       */
     EIGEN_DEVICE_FUNC
@@ -377,15 +377,15 @@
         Index blockSize = m_length<Index(2*BlockSize) ? (m_length+1)/2 : Index(BlockSize);
         for(Index i = 0; i < m_length; i+=blockSize)
         {
           Index end = m_reverse ? (std::min)(m_length,i+blockSize) : m_length-i;
           Index k = m_reverse ? i : (std::max)(Index(0),end-blockSize);
           Index bs = end-k;
           Index start = k + m_shift;
-          
+
           typedef Block<typename internal::remove_all<VectorsType>::type,Dynamic,Dynamic> SubVectorsType;
           SubVectorsType sub_vecs1(m_vectors.const_cast_derived(), Side==OnTheRight ? k : start,
                                                                    Side==OnTheRight ? start : k,
                                                                    Side==OnTheRight ? bs : m_vectors.rows()-start,
                                                                    Side==OnTheRight ? m_vectors.cols()-start : bs);
           typename internal::conditional<Side==OnTheRight, Transpose<SubVectorsType>, SubVectorsType&>::type sub_vecs(sub_vecs1);
 
@@ -515,25 +515,25 @@
   typename internal::matrix_type_times_scalar_type<typename VectorsType::Scalar,OtherDerived>::Type
     res(other.template cast<typename internal::matrix_type_times_scalar_type<typename VectorsType::Scalar,OtherDerived>::ResultScalar>());
   h.applyThisOnTheRight(res);
   return res;
 }
 
 /** \ingroup Householder_Module \householder_module
-  * \brief Convenience function for constructing a Householder sequence. 
+  * \brief Convenience function for constructing a Householder sequence.
   * \returns A HouseholderSequence constructed from the specified arguments.
   */
 template<typename VectorsType, typename CoeffsType>
 HouseholderSequence<VectorsType,CoeffsType> householderSequence(const VectorsType& v, const CoeffsType& h)
 {
   return HouseholderSequence<VectorsType,CoeffsType,OnTheLeft>(v, h);
 }
 
 /** \ingroup Householder_Module \householder_module
-  * \brief Convenience function for constructing a Householder sequence. 
+  * \brief Convenience function for constructing a Householder sequence.
   * \returns A HouseholderSequence constructed from the specified arguments.
   * \details This function differs from householderSequence() in that the template argument \p OnTheSide of
   * the constructed HouseholderSequence is set to OnTheRight, instead of the default OnTheLeft.
   */
 template<typename VectorsType, typename CoeffsType>
 HouseholderSequence<VectorsType,CoeffsType,OnTheRight> rightHouseholderSequence(const VectorsType& v, const CoeffsType& h)
 {
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/BasicPreconditioners.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/BasicPreconditioners.h`

 * *Files 1% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_BASIC_PRECONDITIONERS_H
 #define EIGEN_BASIC_PRECONDITIONERS_H
 
-namespace Eigen { 
+namespace Eigen {
 
 /** \ingroup IterativeLinearSolvers_Module
   * \brief A preconditioner based on the digonal entries
   *
   * This class allows to approximately solve for A.x = b problems assuming A is a diagonal matrix.
   * In other words, this preconditioner neglects all off diagonal entries and, in Eigen's language, solves for:
     \code
@@ -48,23 +48,23 @@
 
     template<typename MatType>
     explicit DiagonalPreconditioner(const MatType& mat) : m_invdiag(mat.cols())
     {
       compute(mat);
     }
 
-    Index rows() const { return m_invdiag.size(); }
-    Index cols() const { return m_invdiag.size(); }
-    
+    EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_invdiag.size(); }
+    EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_invdiag.size(); }
+
     template<typename MatType>
     DiagonalPreconditioner& analyzePattern(const MatType& )
     {
       return *this;
     }
-    
+
     template<typename MatType>
     DiagonalPreconditioner& factorize(const MatType& mat)
     {
       m_invdiag.resize(mat.cols());
       for(int j=0; j<mat.outerSize(); ++j)
       {
         typename MatType::InnerIterator it(mat,j);
@@ -73,15 +73,15 @@
           m_invdiag(j) = Scalar(1)/it.value();
         else
           m_invdiag(j) = Scalar(1);
       }
       m_isInitialized = true;
       return *this;
     }
-    
+
     template<typename MatType>
     DiagonalPreconditioner& compute(const MatType& mat)
     {
       return factorize(mat);
     }
 
     /** \internal */
@@ -95,15 +95,15 @@
     solve(const MatrixBase<Rhs>& b) const
     {
       eigen_assert(m_isInitialized && "DiagonalPreconditioner is not initialized.");
       eigen_assert(m_invdiag.size()==b.rows()
                 && "DiagonalPreconditioner::solve(): invalid number of rows of the right hand side matrix b");
       return Solve<DiagonalPreconditioner, Rhs>(*this, b.derived());
     }
-    
+
     ComputationInfo info() { return Success; }
 
   protected:
     Vector m_invdiag;
     bool m_isInitialized;
 };
 
@@ -117,15 +117,15 @@
     \endcode
   *
   * \tparam _Scalar the type of the scalar.
   *
   * \implsparsesolverconcept
   *
   * The diagonal entries are pre-inverted and stored into a dense vector.
-  * 
+  *
   * \sa class LeastSquaresConjugateGradient, class DiagonalPreconditioner
   */
 template <typename _Scalar>
 class LeastSquareDiagonalPreconditioner : public DiagonalPreconditioner<_Scalar>
 {
     typedef _Scalar Scalar;
     typedef typename NumTraits<Scalar>::Real RealScalar;
@@ -142,15 +142,15 @@
     }
 
     template<typename MatType>
     LeastSquareDiagonalPreconditioner& analyzePattern(const MatType& )
     {
       return *this;
     }
-    
+
     template<typename MatType>
     LeastSquareDiagonalPreconditioner& factorize(const MatType& mat)
     {
       // Compute the inverse squared-norm of each column of mat
       m_invdiag.resize(mat.cols());
       if(MatType::IsRowMajor)
       {
@@ -174,21 +174,21 @@
           else
             m_invdiag(j) = RealScalar(1);
         }
       }
       Base::m_isInitialized = true;
       return *this;
     }
-    
+
     template<typename MatType>
     LeastSquareDiagonalPreconditioner& compute(const MatType& mat)
     {
       return factorize(mat);
     }
-    
+
     ComputationInfo info() { return Success; }
 
   protected:
 };
 
 /** \ingroup IterativeLinearSolvers_Module
   * \brief A naive preconditioner which approximates any matrix as the identity matrix
@@ -201,26 +201,26 @@
 {
   public:
 
     IdentityPreconditioner() {}
 
     template<typename MatrixType>
     explicit IdentityPreconditioner(const MatrixType& ) {}
-    
+
     template<typename MatrixType>
     IdentityPreconditioner& analyzePattern(const MatrixType& ) { return *this; }
-    
+
     template<typename MatrixType>
     IdentityPreconditioner& factorize(const MatrixType& ) { return *this; }
 
     template<typename MatrixType>
     IdentityPreconditioner& compute(const MatrixType& ) { return *this; }
-    
+
     template<typename Rhs>
     inline const Rhs& solve(const Rhs& b) const { return b; }
-    
+
     ComputationInfo info() { return Success; }
 };
 
 } // end namespace Eigen
 
 #endif // EIGEN_BASIC_PRECONDITIONERS_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/BiCGSTAB.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/BiCGSTAB.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/ConjugateGradient.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/ConjugateGradient.h`

 * *Files 1% similar despite different names*

```diff
@@ -47,15 +47,15 @@
   {
     x.setZero();
     iters = 0;
     tol_error = 0;
     return;
   }
   const RealScalar considerAsZero = (std::numeric_limits<RealScalar>::min)();
-  RealScalar threshold = numext::maxi(tol*tol*rhsNorm2,considerAsZero);
+  RealScalar threshold = numext::maxi(RealScalar(tol*tol*rhsNorm2),considerAsZero);
   RealScalar residualNorm2 = residual.squaredNorm();
   if (residualNorm2 < threshold)
   {
     iters = 0;
     tol_error = sqrt(residualNorm2 / rhsNorm2);
     return;
   }
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/IncompleteCholesky.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/IncompleteCholesky.h`

 * *Files 3% similar despite different names*

```diff
@@ -10,16 +10,16 @@
 
 #ifndef EIGEN_INCOMPLETE_CHOlESKY_H
 #define EIGEN_INCOMPLETE_CHOlESKY_H
 
 #include <vector>
 #include <list>
 
-namespace Eigen {  
-/** 
+namespace Eigen {
+/**
   * \brief Modified Incomplete Cholesky with dual threshold
   *
   * References : C-J. Lin and J. J. Moré, Incomplete Cholesky Factorizations with
   *              Limited memory, SIAM J. Sci. Comput.  21(1), pp. 24-45, 1999
   *
   * \tparam Scalar the scalar type of the input matrices
   * \tparam _UpLo The triangular part that will be used for the computations. It can be Lower
@@ -44,110 +44,110 @@
 template <typename Scalar, int _UpLo = Lower, typename _OrderingType = AMDOrdering<int> >
 class IncompleteCholesky : public SparseSolverBase<IncompleteCholesky<Scalar,_UpLo,_OrderingType> >
 {
   protected:
     typedef SparseSolverBase<IncompleteCholesky<Scalar,_UpLo,_OrderingType> > Base;
     using Base::m_isInitialized;
   public:
-    typedef typename NumTraits<Scalar>::Real RealScalar; 
+    typedef typename NumTraits<Scalar>::Real RealScalar;
     typedef _OrderingType OrderingType;
     typedef typename OrderingType::PermutationType PermutationType;
-    typedef typename PermutationType::StorageIndex StorageIndex; 
+    typedef typename PermutationType::StorageIndex StorageIndex;
     typedef SparseMatrix<Scalar,ColMajor,StorageIndex> FactorType;
     typedef Matrix<Scalar,Dynamic,1> VectorSx;
     typedef Matrix<RealScalar,Dynamic,1> VectorRx;
     typedef Matrix<StorageIndex,Dynamic, 1> VectorIx;
-    typedef std::vector<std::list<StorageIndex> > VectorList; 
+    typedef std::vector<std::list<StorageIndex> > VectorList;
     enum { UpLo = _UpLo };
     enum {
       ColsAtCompileTime = Dynamic,
       MaxColsAtCompileTime = Dynamic
     };
   public:
 
     /** Default constructor leaving the object in a partly non-initialized stage.
       *
       * You must call compute() or the pair analyzePattern()/factorize() to make it valid.
       *
       * \sa IncompleteCholesky(const MatrixType&)
       */
     IncompleteCholesky() : m_initialShift(1e-3),m_analysisIsOk(false),m_factorizationIsOk(false) {}
-    
+
     /** Constructor computing the incomplete factorization for the given matrix \a matrix.
       */
     template<typename MatrixType>
     IncompleteCholesky(const MatrixType& matrix) : m_initialShift(1e-3),m_analysisIsOk(false),m_factorizationIsOk(false)
     {
       compute(matrix);
     }
-    
+
     /** \returns number of rows of the factored matrix */
-    Index rows() const { return m_L.rows(); }
-    
+    EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_L.rows(); }
+
     /** \returns number of columns of the factored matrix */
-    Index cols() const { return m_L.cols(); }
-    
+    EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_L.cols(); }
+
 
     /** \brief Reports whether previous computation was successful.
       *
       * It triggers an assertion if \c *this has not been initialized through the respective constructor,
       * or a call to compute() or analyzePattern().
       *
       * \returns \c Success if computation was successful,
       *          \c NumericalIssue if the matrix appears to be negative.
       */
     ComputationInfo info() const
     {
       eigen_assert(m_isInitialized && "IncompleteCholesky is not initialized.");
       return m_info;
     }
-    
+
     /** \brief Set the initial shift parameter \f$ \sigma \f$.
       */
     void setInitialShift(RealScalar shift) { m_initialShift = shift; }
-    
+
     /** \brief Computes the fill reducing permutation vector using the sparsity pattern of \a mat
       */
     template<typename MatrixType>
     void analyzePattern(const MatrixType& mat)
     {
-      OrderingType ord; 
+      OrderingType ord;
       PermutationType pinv;
-      ord(mat.template selfadjointView<UpLo>(), pinv); 
+      ord(mat.template selfadjointView<UpLo>(), pinv);
       if(pinv.size()>0) m_perm = pinv.inverse();
       else              m_perm.resize(0);
       m_L.resize(mat.rows(), mat.cols());
       m_analysisIsOk = true;
       m_isInitialized = true;
       m_info = Success;
     }
-    
+
     /** \brief Performs the numerical factorization of the input matrix \a mat
       *
       * The method analyzePattern() or compute() must have been called beforehand
       * with a matrix having the same pattern.
       *
       * \sa compute(), analyzePattern()
       */
     template<typename MatrixType>
     void factorize(const MatrixType& mat);
-    
+
     /** Computes or re-computes the incomplete Cholesky factorization of the input matrix \a mat
       *
       * It is a shortcut for a sequential call to the analyzePattern() and factorize() methods.
       *
       * \sa analyzePattern(), factorize()
       */
     template<typename MatrixType>
     void compute(const MatrixType& mat)
     {
       analyzePattern(mat);
       factorize(mat);
     }
-    
+
     // internal
     template<typename Rhs, typename Dest>
     void _solve_impl(const Rhs& b, Dest& x) const
     {
       eigen_assert(m_factorizationIsOk && "factorize() should be called first");
       if (m_perm.rows() == b.rows())  x = m_perm * b;
       else                            x = b;
@@ -166,98 +166,98 @@
     const VectorRx& scalingS() const { eigen_assert("m_factorizationIsOk"); return m_scale; }
 
     /** \returns the fill-in reducing permutation P (can be empty for a natural ordering) */
     const PermutationType& permutationP() const { eigen_assert("m_analysisIsOk"); return m_perm; }
 
   protected:
     FactorType m_L;              // The lower part stored in CSC
-    VectorRx m_scale;            // The vector for scaling the matrix 
+    VectorRx m_scale;            // The vector for scaling the matrix
     RealScalar m_initialShift;   // The initial shift parameter
-    bool m_analysisIsOk; 
-    bool m_factorizationIsOk; 
+    bool m_analysisIsOk;
+    bool m_factorizationIsOk;
     ComputationInfo m_info;
-    PermutationType m_perm; 
+    PermutationType m_perm;
 
   private:
-    inline void updateList(Ref<const VectorIx> colPtr, Ref<VectorIx> rowIdx, Ref<VectorSx> vals, const Index& col, const Index& jk, VectorIx& firstElt, VectorList& listCol); 
-}; 
+    inline void updateList(Ref<const VectorIx> colPtr, Ref<VectorIx> rowIdx, Ref<VectorSx> vals, const Index& col, const Index& jk, VectorIx& firstElt, VectorList& listCol);
+};
 
 // Based on the following paper:
 //   C-J. Lin and J. J. Moré, Incomplete Cholesky Factorizations with
 //   Limited memory, SIAM J. Sci. Comput.  21(1), pp. 24-45, 1999
 //   http://ftp.mcs.anl.gov/pub/tech_reports/reports/P682.pdf
 template<typename Scalar, int _UpLo, typename OrderingType>
 template<typename _MatrixType>
 void IncompleteCholesky<Scalar,_UpLo, OrderingType>::factorize(const _MatrixType& mat)
 {
   using std::sqrt;
-  eigen_assert(m_analysisIsOk && "analyzePattern() should be called first"); 
-    
+  eigen_assert(m_analysisIsOk && "analyzePattern() should be called first");
+
   // Dropping strategy : Keep only the p largest elements per column, where p is the number of elements in the column of the original matrix. Other strategies will be added
-  
+
   // Apply the fill-reducing permutation computed in analyzePattern()
   if (m_perm.rows() == mat.rows() ) // To detect the null permutation
   {
     // The temporary is needed to make sure that the diagonal entry is properly sorted
     FactorType tmp(mat.rows(), mat.cols());
     tmp = mat.template selfadjointView<_UpLo>().twistedBy(m_perm);
     m_L.template selfadjointView<Lower>() = tmp.template selfadjointView<Lower>();
   }
   else
   {
     m_L.template selfadjointView<Lower>() = mat.template selfadjointView<_UpLo>();
   }
-  
-  Index n = m_L.cols(); 
+
+  Index n = m_L.cols();
   Index nnz = m_L.nonZeros();
   Map<VectorSx> vals(m_L.valuePtr(), nnz);         //values
   Map<VectorIx> rowIdx(m_L.innerIndexPtr(), nnz);  //Row indices
   Map<VectorIx> colPtr( m_L.outerIndexPtr(), n+1); // Pointer to the beginning of each row
   VectorIx firstElt(n-1); // for each j, points to the next entry in vals that will be used in the factorization
   VectorList listCol(n);  // listCol(j) is a linked list of columns to update column j
   VectorSx col_vals(n);   // Store a  nonzero values in each column
   VectorIx col_irow(n);   // Row indices of nonzero elements in each column
   VectorIx col_pattern(n);
   col_pattern.fill(-1);
   StorageIndex col_nnz;
-  
-  
-  // Computes the scaling factors 
+
+
+  // Computes the scaling factors
   m_scale.resize(n);
   m_scale.setZero();
   for (Index j = 0; j < n; j++)
     for (Index k = colPtr[j]; k < colPtr[j+1]; k++)
     {
       m_scale(j) += numext::abs2(vals(k));
       if(rowIdx[k]!=j)
         m_scale(rowIdx[k]) += numext::abs2(vals(k));
     }
-  
+
   m_scale = m_scale.cwiseSqrt().cwiseSqrt();
 
   for (Index j = 0; j < n; ++j)
     if(m_scale(j)>(std::numeric_limits<RealScalar>::min)())
       m_scale(j) = RealScalar(1)/m_scale(j);
     else
       m_scale(j) = 1;
 
   // TODO disable scaling if not needed, i.e., if it is roughly uniform? (this will make solve() faster)
-  
-  // Scale and compute the shift for the matrix 
+
+  // Scale and compute the shift for the matrix
   RealScalar mindiag = NumTraits<RealScalar>::highest();
   for (Index j = 0; j < n; j++)
   {
     for (Index k = colPtr[j]; k < colPtr[j+1]; k++)
       vals[k] *= (m_scale(j)*m_scale(rowIdx[k]));
     eigen_internal_assert(rowIdx[colPtr[j]]==j && "IncompleteCholesky: only the lower triangular part must be stored");
     mindiag = numext::mini(numext::real(vals[colPtr[j]]), mindiag);
   }
 
   FactorType L_save = m_L;
-  
+
   RealScalar shift = 0;
   if(mindiag <= RealScalar(0.))
     shift = m_initialShift - mindiag;
 
   m_info = NumericalIssue;
 
   // Try to perform the incomplete factorization using the current shift
@@ -371,24 +371,24 @@
 
 template<typename Scalar, int _UpLo, typename OrderingType>
 inline void IncompleteCholesky<Scalar,_UpLo, OrderingType>::updateList(Ref<const VectorIx> colPtr, Ref<VectorIx> rowIdx, Ref<VectorSx> vals, const Index& col, const Index& jk, VectorIx& firstElt, VectorList& listCol)
 {
   if (jk < colPtr(col+1) )
   {
     Index p = colPtr(col+1) - jk;
-    Index minpos; 
+    Index minpos;
     rowIdx.segment(jk,p).minCoeff(&minpos);
     minpos += jk;
     if (rowIdx(minpos) != rowIdx(jk))
     {
       //Swap
       std::swap(rowIdx(jk),rowIdx(minpos));
       std::swap(vals(jk),vals(minpos));
     }
     firstElt(col) = internal::convert_index<StorageIndex,Index>(jk);
     listCol[rowIdx(jk)].push_back(internal::convert_index<StorageIndex,Index>(col));
   }
 }
 
-} // end namespace Eigen 
+} // end namespace Eigen
 
 #endif
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/IncompleteLUT.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/IncompleteLUT.h`

 * *Files 2% similar despite different names*

```diff
@@ -8,90 +8,90 @@
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_INCOMPLETE_LUT_H
 #define EIGEN_INCOMPLETE_LUT_H
 
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
-    
+
 /** \internal
-  * Compute a quick-sort split of a vector 
+  * Compute a quick-sort split of a vector
   * On output, the vector row is permuted such that its elements satisfy
   * abs(row(i)) >= abs(row(ncut)) if i<ncut
-  * abs(row(i)) <= abs(row(ncut)) if i>ncut 
+  * abs(row(i)) <= abs(row(ncut)) if i>ncut
   * \param row The vector of values
   * \param ind The array of index for the elements in @p row
   * \param ncut  The number of largest elements to keep
-  **/ 
+  **/
 template <typename VectorV, typename VectorI>
 Index QuickSplit(VectorV &row, VectorI &ind, Index ncut)
 {
   typedef typename VectorV::RealScalar RealScalar;
   using std::swap;
   using std::abs;
   Index mid;
   Index n = row.size(); /* length of the vector */
   Index first, last ;
-  
+
   ncut--; /* to fit the zero-based indices */
-  first = 0; 
-  last = n-1; 
+  first = 0;
+  last = n-1;
   if (ncut < first || ncut > last ) return 0;
-  
+
   do {
-    mid = first; 
-    RealScalar abskey = abs(row(mid)); 
+    mid = first;
+    RealScalar abskey = abs(row(mid));
     for (Index j = first + 1; j <= last; j++) {
       if ( abs(row(j)) > abskey) {
         ++mid;
         swap(row(mid), row(j));
         swap(ind(mid), ind(j));
       }
     }
     /* Interchange for the pivot element */
     swap(row(mid), row(first));
     swap(ind(mid), ind(first));
-    
+
     if (mid > ncut) last = mid - 1;
-    else if (mid < ncut ) first = mid + 1; 
+    else if (mid < ncut ) first = mid + 1;
   } while (mid != ncut );
-  
-  return 0; /* mid is equal to ncut */ 
+
+  return 0; /* mid is equal to ncut */
 }
 
 }// end namespace internal
 
 /** \ingroup IterativeLinearSolvers_Module
   * \class IncompleteLUT
   * \brief Incomplete LU factorization with dual-threshold strategy
   *
   * \implsparsesolverconcept
   *
   * During the numerical factorization, two dropping rules are used :
   *  1) any element whose magnitude is less than some tolerance is dropped.
-  *    This tolerance is obtained by multiplying the input tolerance @p droptol 
+  *    This tolerance is obtained by multiplying the input tolerance @p droptol
   *    by the average magnitude of all the original elements in the current row.
-  *  2) After the elimination of the row, only the @p fill largest elements in 
-  *    the L part and the @p fill largest elements in the U part are kept 
-  *    (in addition to the diagonal element ). Note that @p fill is computed from 
-  *    the input parameter @p fillfactor which is used the ratio to control the fill_in 
+  *  2) After the elimination of the row, only the @p fill largest elements in
+  *    the L part and the @p fill largest elements in the U part are kept
+  *    (in addition to the diagonal element ). Note that @p fill is computed from
+  *    the input parameter @p fillfactor which is used the ratio to control the fill_in
   *    relatively to the initial number of nonzero elements.
-  * 
+  *
   * The two extreme cases are when @p droptol=0 (to keep all the @p fill*2 largest elements)
-  * and when @p fill=n/2 with @p droptol being different to zero. 
-  * 
-  * References : Yousef Saad, ILUT: A dual threshold incomplete LU factorization, 
+  * and when @p fill=n/2 with @p droptol being different to zero.
+  *
+  * References : Yousef Saad, ILUT: A dual threshold incomplete LU factorization,
   *              Numerical Linear Algebra with Applications, 1(4), pp 387-402, 1994.
-  * 
+  *
   * NOTE : The following implementation is derived from the ILUT implementation
-  * in the SPARSKIT package, Copyright (C) 2005, the Regents of the University of Minnesota 
-  *  released under the terms of the GNU LGPL: 
+  * in the SPARSKIT package, Copyright (C) 2005, the Regents of the University of Minnesota
+  *  released under the terms of the GNU LGPL:
   *    http://www-users.cs.umn.edu/~saad/software/SPARSKIT/README
   * However, Yousef Saad gave us permission to relicense his ILUT code to MPL2.
   * See the Eigen mailing list archive, thread: ILUT, date: July 8, 2012:
   *   http://listengine.tuxfamily.org/lists.tuxfamily.org/eigen/2012/07/msg00064.html
   * alternatively, on GMANE:
   *   http://comments.gmane.org/gmane.comp.lib.eigen/3302
   */
@@ -111,73 +111,73 @@
 
     enum {
       ColsAtCompileTime = Dynamic,
       MaxColsAtCompileTime = Dynamic
     };
 
   public:
-    
+
     IncompleteLUT()
       : m_droptol(NumTraits<Scalar>::dummy_precision()), m_fillfactor(10),
         m_analysisIsOk(false), m_factorizationIsOk(false)
     {}
-    
+
     template<typename MatrixType>
     explicit IncompleteLUT(const MatrixType& mat, const RealScalar& droptol=NumTraits<Scalar>::dummy_precision(), int fillfactor = 10)
       : m_droptol(droptol),m_fillfactor(fillfactor),
         m_analysisIsOk(false),m_factorizationIsOk(false)
     {
       eigen_assert(fillfactor != 0);
-      compute(mat); 
+      compute(mat);
     }
-    
-    Index rows() const { return m_lu.rows(); }
-    
-    Index cols() const { return m_lu.cols(); }
+
+    EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return m_lu.rows(); }
+
+    EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return m_lu.cols(); }
 
     /** \brief Reports whether previous computation was successful.
       *
       * \returns \c Success if computation was successful,
       *          \c NumericalIssue if the matrix.appears to be negative.
       */
     ComputationInfo info() const
     {
       eigen_assert(m_isInitialized && "IncompleteLUT is not initialized.");
       return m_info;
     }
-    
+
     template<typename MatrixType>
     void analyzePattern(const MatrixType& amat);
-    
+
     template<typename MatrixType>
     void factorize(const MatrixType& amat);
-    
+
     /**
       * Compute an incomplete LU factorization with dual threshold on the matrix mat
       * No pivoting is done in this version
-      * 
+      *
       **/
     template<typename MatrixType>
     IncompleteLUT& compute(const MatrixType& amat)
     {
-      analyzePattern(amat); 
+      analyzePattern(amat);
       factorize(amat);
       return *this;
     }
 
-    void setDroptol(const RealScalar& droptol); 
-    void setFillfactor(int fillfactor); 
-    
+    void setDroptol(const RealScalar& droptol);
+    void setFillfactor(int fillfactor);
+
     template<typename Rhs, typename Dest>
     void _solve_impl(const Rhs& b, Dest& x) const
     {
       x = m_Pinv * b;
       x = m_lu.template triangularView<UnitLower>().solve(x);
       x = m_lu.template triangularView<Upper>().solve(x);
-      x = m_P * x; 
+      x = m_P * x;
     }
 
 protected:
 
     /** keeps off-diagonal entries; drops diagonal entries */
     struct keep_diag {
       inline bool operator() (const Index& row, const Index& col, const Scalar&) const
@@ -196,30 +196,30 @@
     ComputationInfo m_info;
     PermutationMatrix<Dynamic,Dynamic,StorageIndex> m_P;     // Fill-reducing permutation
     PermutationMatrix<Dynamic,Dynamic,StorageIndex> m_Pinv;  // Inverse permutation
 };
 
 /**
  * Set control parameter droptol
- *  \param droptol   Drop any element whose magnitude is less than this tolerance 
- **/ 
+ *  \param droptol   Drop any element whose magnitude is less than this tolerance
+ **/
 template<typename Scalar, typename StorageIndex>
 void IncompleteLUT<Scalar,StorageIndex>::setDroptol(const RealScalar& droptol)
 {
-  this->m_droptol = droptol;   
+  this->m_droptol = droptol;
 }
 
 /**
  * Set control parameter fillfactor
- * \param fillfactor  This is used to compute the  number @p fill_in of largest elements to keep on each row. 
- **/ 
+ * \param fillfactor  This is used to compute the  number @p fill_in of largest elements to keep on each row.
+ **/
 template<typename Scalar, typename StorageIndex>
 void IncompleteLUT<Scalar,StorageIndex>::setFillfactor(int fillfactor)
 {
-  this->m_fillfactor = fillfactor;   
+  this->m_fillfactor = fillfactor;
 }
 
 template <typename Scalar, typename StorageIndex>
 template<typename _MatrixType>
 void IncompleteLUT<Scalar,StorageIndex>::analyzePattern(const _MatrixType& amat)
 {
   // Compute the Fill-reducing permutation
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/IterativeSolverBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/IterativeSolverBase.h`

 * *Files 3% similar despite different names*

```diff
@@ -6,15 +6,15 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_ITERATIVE_SOLVER_BASE_H
 #define EIGEN_ITERATIVE_SOLVER_BASE_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename MatrixType>
 struct is_ref_compatible_impl
 {
 private:
@@ -141,15 +141,15 @@
   */
 template< typename Derived>
 class IterativeSolverBase : public SparseSolverBase<Derived>
 {
 protected:
   typedef SparseSolverBase<Derived> Base;
   using Base::m_isInitialized;
-  
+
 public:
   typedef typename internal::traits<Derived>::MatrixType MatrixType;
   typedef typename internal::traits<Derived>::Preconditioner Preconditioner;
   typedef typename MatrixType::Scalar Scalar;
   typedef typename MatrixType::StorageIndex StorageIndex;
   typedef typename MatrixType::RealScalar RealScalar;
 
@@ -165,33 +165,33 @@
   /** Default constructor. */
   IterativeSolverBase()
   {
     init();
   }
 
   /** Initialize the solver with matrix \a A for further \c Ax=b solving.
-    * 
+    *
     * This constructor is a shortcut for the default constructor followed
     * by a call to compute().
-    * 
+    *
     * \warning this class stores a reference to the matrix A as well as some
     * precomputed values that depend on it. Therefore, if \a A is changed
     * this class becomes invalid. Call compute() to update it with the new
     * matrix A, or modify a copy of A.
     */
   template<typename MatrixDerived>
   explicit IterativeSolverBase(const EigenBase<MatrixDerived>& A)
     : m_matrixWrapper(A.derived())
   {
     init();
     compute(matrix());
   }
 
   ~IterativeSolverBase() {}
-  
+
   /** Initializes the iterative solver for the sparsity pattern of the matrix \a A for further solving \c Ax=b problems.
     *
     * Currently, this function mostly calls analyzePattern on the preconditioner. In the future
     * we might, for instance, implement column reordering for faster matrix vector products.
     */
   template<typename MatrixDerived>
   Derived& analyzePattern(const EigenBase<MatrixDerived>& A)
@@ -199,28 +199,28 @@
     grab(A.derived());
     m_preconditioner.analyzePattern(matrix());
     m_isInitialized = true;
     m_analysisIsOk = true;
     m_info = m_preconditioner.info();
     return derived();
   }
-  
+
   /** Initializes the iterative solver with the numerical values of the matrix \a A for further solving \c Ax=b problems.
     *
     * Currently, this function mostly calls factorize on the preconditioner.
     *
     * \warning this class stores a reference to the matrix A as well as some
     * precomputed values that depend on it. Therefore, if \a A is changed
     * this class becomes invalid. Call compute() to update it with the new
     * matrix A, or modify a copy of A.
     */
   template<typename MatrixDerived>
   Derived& factorize(const EigenBase<MatrixDerived>& A)
   {
-    eigen_assert(m_analysisIsOk && "You must first call analyzePattern()"); 
+    eigen_assert(m_analysisIsOk && "You must first call analyzePattern()");
     grab(A.derived());
     m_preconditioner.factorize(matrix());
     m_factorizationIsOk = true;
     m_info = m_preconditioner.info();
     return derived();
   }
 
@@ -243,50 +243,50 @@
     m_analysisIsOk = true;
     m_factorizationIsOk = true;
     m_info = m_preconditioner.info();
     return derived();
   }
 
   /** \internal */
-  Index rows() const { return matrix().rows(); }
+  EIGEN_CONSTEXPR Index rows() const EIGEN_NOEXCEPT { return matrix().rows(); }
 
   /** \internal */
-  Index cols() const { return matrix().cols(); }
+  EIGEN_CONSTEXPR Index cols() const EIGEN_NOEXCEPT { return matrix().cols(); }
 
   /** \returns the tolerance threshold used by the stopping criteria.
     * \sa setTolerance()
     */
   RealScalar tolerance() const { return m_tolerance; }
-  
+
   /** Sets the tolerance threshold used by the stopping criteria.
     *
     * This value is used as an upper bound to the relative residual error: |Ax-b|/|b|.
     * The default value is the machine precision given by NumTraits<Scalar>::epsilon()
     */
   Derived& setTolerance(const RealScalar& tolerance)
   {
     m_tolerance = tolerance;
     return derived();
   }
 
   /** \returns a read-write reference to the preconditioner for custom configuration. */
   Preconditioner& preconditioner() { return m_preconditioner; }
-  
+
   /** \returns a read-only reference to the preconditioner. */
   const Preconditioner& preconditioner() const { return m_preconditioner; }
 
   /** \returns the max number of iterations.
     * It is either the value set by setMaxIterations or, by default,
     * twice the number of columns of the matrix.
     */
   Index maxIterations() const
   {
     return (m_maxIterations<0) ? 2*matrix().cols() : m_maxIterations;
   }
-  
+
   /** Sets the max number of iterations.
     * Default is twice the number of columns of the matrix.
     */
   Derived& setMaxIterations(Index maxIters)
   {
     m_maxIterations = maxIters;
     return derived();
@@ -324,21 +324,21 @@
 
   /** \returns Success if the iterations converged, and NoConvergence otherwise. */
   ComputationInfo info() const
   {
     eigen_assert(m_isInitialized && "IterativeSolverBase is not initialized.");
     return m_info;
   }
-  
+
   /** \internal */
   template<typename Rhs, typename DestDerived>
   void _solve_with_guess_impl(const Rhs& b, SparseMatrixBase<DestDerived> &aDest) const
   {
     eigen_assert(rows()==b.rows());
-    
+
     Index rhsCols = b.cols();
     Index size = b.rows();
     DestDerived& dest(aDest.derived());
     typedef typename DestDerived::Scalar DestScalar;
     Eigen::Matrix<DestScalar,Dynamic,1> tb(size);
     Eigen::Matrix<DestScalar,Dynamic,1> tx(cols());
     // We do not directly fill dest because sparse expressions have to be free of aliasing issue.
@@ -364,15 +364,15 @@
   }
 
   template<typename Rhs, typename DestDerived>
   typename internal::enable_if<Rhs::ColsAtCompileTime!=1 && DestDerived::ColsAtCompileTime!=1>::type
   _solve_with_guess_impl(const Rhs& b, MatrixBase<DestDerived> &aDest) const
   {
     eigen_assert(rows()==b.rows());
-    
+
     Index rhsCols = b.cols();
     DestDerived& dest(aDest.derived());
     ComputationInfo global_info = Success;
     for(Index k=0; k<rhsCols; ++k)
     {
       typename DestDerived::ColXpr xk(dest,k);
       typename Rhs::ConstColXpr bk(b,k);
@@ -416,27 +416,27 @@
   typedef internal::generic_matrix_wrapper<MatrixType> MatrixWrapper;
   typedef typename MatrixWrapper::ActualMatrixType ActualMatrixType;
 
   const ActualMatrixType& matrix() const
   {
     return m_matrixWrapper.matrix();
   }
-  
+
   template<typename InputType>
   void grab(const InputType &A)
   {
     m_matrixWrapper.grab(A);
   }
-  
+
   MatrixWrapper m_matrixWrapper;
   Preconditioner m_preconditioner;
 
   Index m_maxIterations;
   RealScalar m_tolerance;
-  
+
   mutable RealScalar m_error;
   mutable Index m_iterations;
   mutable ComputationInfo m_info;
   mutable bool m_analysisIsOk, m_factorizationIsOk;
 };
 
 } // end namespace Eigen
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/LeastSquareConjugateGradient.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/LeastSquareConjugateGradient.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/IterativeLinearSolvers/SolveWithGuess.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/IterativeLinearSolvers/SolveWithGuess.h`

 * *Files 8% similar despite different names*

```diff
@@ -9,15 +9,15 @@
 
 #ifndef EIGEN_SOLVEWITHGUESS_H
 #define EIGEN_SOLVEWITHGUESS_H
 
 namespace Eigen {
 
 template<typename Decomposition, typename RhsType, typename GuessType> class SolveWithGuess;
-  
+
 /** \class SolveWithGuess
   * \ingroup IterativeLinearSolvers_Module
   *
   * \brief Pseudo expression representing a solving operation
   *
   * \tparam Decomposition the type of the matrix or decomposion object
   * \tparam Rhstype the type of the right-hand side
@@ -41,31 +41,33 @@
 class SolveWithGuess : public internal::generic_xpr_base<SolveWithGuess<Decomposition,RhsType,GuessType>, MatrixXpr, typename internal::traits<RhsType>::StorageKind>::type
 {
 public:
   typedef typename internal::traits<SolveWithGuess>::Scalar Scalar;
   typedef typename internal::traits<SolveWithGuess>::PlainObject PlainObject;
   typedef typename internal::generic_xpr_base<SolveWithGuess<Decomposition,RhsType,GuessType>, MatrixXpr, typename internal::traits<RhsType>::StorageKind>::type Base;
   typedef typename internal::ref_selector<SolveWithGuess>::type Nested;
-  
+
   SolveWithGuess(const Decomposition &dec, const RhsType &rhs, const GuessType &guess)
     : m_dec(dec), m_rhs(rhs), m_guess(guess)
   {}
-  
-  EIGEN_DEVICE_FUNC Index rows() const { return m_dec.cols(); }
-  EIGEN_DEVICE_FUNC Index cols() const { return m_rhs.cols(); }
+
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  Index rows() const EIGEN_NOEXCEPT { return m_dec.cols(); }
+  EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+  Index cols() const EIGEN_NOEXCEPT { return m_rhs.cols(); }
 
   EIGEN_DEVICE_FUNC const Decomposition& dec()   const { return m_dec; }
   EIGEN_DEVICE_FUNC const RhsType&       rhs()   const { return m_rhs; }
   EIGEN_DEVICE_FUNC const GuessType&     guess() const { return m_guess; }
 
 protected:
   const Decomposition &m_dec;
   const RhsType       &m_rhs;
   const GuessType     &m_guess;
-  
+
 private:
   Scalar coeff(Index row, Index col) const;
   Scalar coeff(Index i) const;
 };
 
 namespace internal {
 
@@ -81,16 +83,16 @@
   evaluator(const SolveType& solve)
     : m_result(solve.rows(), solve.cols())
   {
     ::new (static_cast<Base*>(this)) Base(m_result);
     m_result = solve.guess();
     solve.dec()._solve_with_guess_impl(solve.rhs(), m_result);
   }
-  
-protected:  
+
+protected:
   PlainObject m_result;
 };
 
 // Specialization for "dst = dec.solveWithGuess(rhs)"
 // NOTE we need to specialize it for Dense2Dense to avoid ambiguous specialization error and a Sparse2Sparse specialization must exist somewhere
 template<typename DstXprType, typename DecType, typename RhsType, typename GuessType, typename Scalar>
 struct Assignment<DstXprType, SolveWithGuess<DecType,RhsType,GuessType>, internal::assign_op<Scalar,Scalar>, Dense2Dense>
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/Jacobi/Jacobi.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/Jacobi/Jacobi.h`

 * *Files 1% similar despite different names*

```diff
@@ -449,15 +449,15 @@
 };
 
 template<typename VectorX, typename VectorY, typename OtherScalar>
 EIGEN_DEVICE_FUNC
 void /*EIGEN_DONT_INLINE*/ apply_rotation_in_the_plane(DenseBase<VectorX>& xpr_x, DenseBase<VectorY>& xpr_y, const JacobiRotation<OtherScalar>& j)
 {
   typedef typename VectorX::Scalar Scalar;
-  const bool Vectorizable =    (VectorX::Flags & VectorY::Flags & PacketAccessBit)
+  const bool Vectorizable =    (int(VectorX::Flags) & int(VectorY::Flags) & PacketAccessBit)
                             && (int(packet_traits<Scalar>::size) == int(packet_traits<OtherScalar>::size));
 
   eigen_assert(xpr_x.size() == xpr_y.size());
   Index size = xpr_x.size();
   Index incrx = xpr_x.derived().innerStride();
   Index incry = xpr_y.derived().innerStride();
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/KLUSupport/KLUSupport.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/KLUSupport/KLUSupport.h`

 * *Files 2% similar despite different names*

```diff
@@ -97,16 +97,16 @@
 
     ~KLU()
     {
       if(m_symbolic) klu_free_symbolic(&m_symbolic,&m_common);
       if(m_numeric)  klu_free_numeric(&m_numeric,&m_common);
     }
 
-    inline Index rows() const { return mp_matrix.rows(); }
-    inline Index cols() const { return mp_matrix.cols(); }
+    EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return mp_matrix.rows(); }
+    EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return mp_matrix.cols(); }
 
     /** \brief Reports whether previous computation was successful.
       *
       * \returns \c Success if computation was successful,
       *          \c NumericalIssue if the matrix.appears to be negative.
       */
     ComputationInfo info() const
@@ -249,15 +249,15 @@
     }
 
     void factorize_impl()
     {
 
       m_numeric = klu_factor(const_cast<StorageIndex*>(mp_matrix.outerIndexPtr()), const_cast<StorageIndex*>(mp_matrix.innerIndexPtr()), const_cast<Scalar*>(mp_matrix.valuePtr()),
                                     m_symbolic, &m_common, Scalar());
-                                         
+
 
       m_info = m_numeric ? Success : NumericalIssue;
       m_factorizationIsOk = m_numeric ? 1 : 0;
       m_extractedDataAreDirty = true;
     }
 
     template<typename MatrixDerived>
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/LU/Determinant.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/LU/Determinant.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/LU/FullPivLU.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/LU/FullPivLU.h`

 * *Files 0% similar despite different names*

```diff
@@ -400,16 +400,18 @@
       eigen_assert(m_isInitialized && "LU is not initialized.");
       eigen_assert(m_lu.rows() == m_lu.cols() && "You can't take the inverse of a non-square matrix!");
       return Inverse<FullPivLU>(*this);
     }
 
     MatrixType reconstructedMatrix() const;
 
-    EIGEN_DEVICE_FUNC inline Index rows() const { return m_lu.rows(); }
-    EIGEN_DEVICE_FUNC inline Index cols() const { return m_lu.cols(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index rows() const EIGEN_NOEXCEPT { return m_lu.rows(); }
+    EIGEN_DEVICE_FUNC EIGEN_CONSTEXPR
+    inline Index cols() const EIGEN_NOEXCEPT { return m_lu.cols(); }
 
     #ifndef EIGEN_PARSED_BY_DOXYGEN
     template<typename RhsType, typename DstType>
     void _solve_impl(const RhsType &rhs, DstType &dst) const;
 
     template<bool Conjugate, typename RhsType, typename DstType>
     void _solve_impl_transposed(const RhsType &rhs, DstType &dst) const;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/LU/InverseImpl.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/LU/InverseImpl.h`

 * *Files 2% similar despite different names*

```diff
@@ -73,18 +73,19 @@
 
 template<typename MatrixType, typename ResultType>
 EIGEN_DEVICE_FUNC 
 inline void compute_inverse_size2_helper(
     const MatrixType& matrix, const typename ResultType::Scalar& invdet,
     ResultType& result)
 {
+  typename ResultType::Scalar temp = matrix.coeff(0,0);
   result.coeffRef(0,0) =  matrix.coeff(1,1) * invdet;
   result.coeffRef(1,0) = -matrix.coeff(1,0) * invdet;
   result.coeffRef(0,1) = -matrix.coeff(0,1) * invdet;
-  result.coeffRef(1,1) =  matrix.coeff(0,0) * invdet;
+  result.coeffRef(1,1) =  temp * invdet;
 }
 
 template<typename MatrixType, typename ResultType>
 struct compute_inverse<MatrixType, ResultType, 2>
 {
   EIGEN_DEVICE_FUNC
   static inline void run(const MatrixType& matrix, ResultType& result)
@@ -139,21 +140,26 @@
 EIGEN_DEVICE_FUNC
 inline void compute_inverse_size3_helper(
     const MatrixType& matrix,
     const typename ResultType::Scalar& invdet,
     const Matrix<typename ResultType::Scalar,3,1>& cofactors_col0,
     ResultType& result)
 {
-  result.row(0) = cofactors_col0 * invdet;
-  result.coeffRef(1,0) =  cofactor_3x3<MatrixType,0,1>(matrix) * invdet;
-  result.coeffRef(1,1) =  cofactor_3x3<MatrixType,1,1>(matrix) * invdet;
+  // Compute cofactors in a way that avoids aliasing issues.
+  typedef typename ResultType::Scalar Scalar;
+  const Scalar c01 = cofactor_3x3<MatrixType,0,1>(matrix) * invdet;
+  const Scalar c11 = cofactor_3x3<MatrixType,1,1>(matrix) * invdet;
+  const Scalar c02 = cofactor_3x3<MatrixType,0,2>(matrix) * invdet;
   result.coeffRef(1,2) =  cofactor_3x3<MatrixType,2,1>(matrix) * invdet;
-  result.coeffRef(2,0) =  cofactor_3x3<MatrixType,0,2>(matrix) * invdet;
   result.coeffRef(2,1) =  cofactor_3x3<MatrixType,1,2>(matrix) * invdet;
   result.coeffRef(2,2) =  cofactor_3x3<MatrixType,2,2>(matrix) * invdet;
+  result.coeffRef(1,0) =  c01;
+  result.coeffRef(1,1) =  c11;
+  result.coeffRef(2,0) =  c02;  
+  result.row(0) = cofactors_col0 * invdet;
 }
 
 template<typename MatrixType, typename ResultType>
 struct compute_inverse<MatrixType, ResultType, 3>
 {
   EIGEN_DEVICE_FUNC
   static inline void run(const MatrixType& matrix, ResultType& result)
@@ -177,22 +183,21 @@
     const MatrixType& matrix,
     const typename MatrixType::RealScalar& absDeterminantThreshold,
     ResultType& inverse,
     typename ResultType::Scalar& determinant,
     bool& invertible
   )
   {
-    using std::abs;
     typedef typename ResultType::Scalar Scalar;
     Matrix<Scalar,3,1> cofactors_col0;
     cofactors_col0.coeffRef(0) =  cofactor_3x3<MatrixType,0,0>(matrix);
     cofactors_col0.coeffRef(1) =  cofactor_3x3<MatrixType,1,0>(matrix);
     cofactors_col0.coeffRef(2) =  cofactor_3x3<MatrixType,2,0>(matrix);
     determinant = (cofactors_col0.cwiseProduct(matrix.col(0))).sum();
-    invertible = abs(determinant) > absDeterminantThreshold;
+    invertible = Eigen::numext::abs(determinant) > absDeterminantThreshold;
     if(!invertible) return;
     const Scalar invdet = Scalar(1) / determinant;
     compute_inverse_size3_helper(matrix, invdet, cofactors_col0, inverse);
   }
 };
 
 /****************************
@@ -269,15 +274,21 @@
     typename ResultType::Scalar& determinant,
     bool& invertible
   )
   {
     using std::abs;
     determinant = matrix.determinant();
     invertible = abs(determinant) > absDeterminantThreshold;
-    if(invertible) compute_inverse<MatrixType, ResultType>::run(matrix, inverse);
+    if(invertible && extract_data(matrix) != extract_data(inverse)) {
+      compute_inverse<MatrixType, ResultType>::run(matrix, inverse);
+    }
+    else if(invertible) {
+      MatrixType matrix_t = matrix;
+      compute_inverse<MatrixType, ResultType>::run(matrix_t, inverse);
+    }
   }
 };
 
 /*************************
 *** MatrixBase methods ***
 *************************/
 
@@ -343,14 +354,16 @@
 
 /** \lu_module
   *
   * Computation of matrix inverse and determinant, with invertibility check.
   *
   * This is only for fixed-size square matrices of size up to 4x4.
   *
+  * Notice that it will trigger a copy of input matrix when trying to do the inverse in place.
+  *
   * \param inverse Reference to the matrix in which to store the inverse.
   * \param determinant Reference to the variable in which to store the determinant.
   * \param invertible Reference to the bool variable in which to store whether the matrix is invertible.
   * \param absDeterminantThreshold Optional parameter controlling the invertibility check.
   *                                The matrix will be declared invertible if the absolute value of its
   *                                determinant is greater than this threshold.
   *
@@ -383,14 +396,16 @@
 
 /** \lu_module
   *
   * Computation of matrix inverse, with invertibility check.
   *
   * This is only for fixed-size square matrices of size up to 4x4.
   *
+  * Notice that it will trigger a copy of input matrix when trying to do the inverse in place.
+  *
   * \param inverse Reference to the matrix in which to store the inverse.
   * \param invertible Reference to the bool variable in which to store whether the matrix is invertible.
   * \param absDeterminantThreshold Optional parameter controlling the invertibility check.
   *                                The matrix will be declared invertible if the absolute value of its
   *                                determinant is greater than this threshold.
   *
   * Example: \include MatrixBase_computeInverseWithCheck.cpp
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/LU/PartialPivLU.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/LU/PartialPivLU.h`

 * *Files 1% similar despite different names*

```diff
@@ -66,15 +66,15 @@
   * This LU decomposition is suitable to invert invertible matrices. It is what MatrixBase::inverse() uses
   * in the general case.
   * On the other hand, it is \b not suitable to determine whether a given matrix is invertible.
   *
   * The data of the LU decomposition can be directly accessed through the methods matrixLU(), permutationP().
   *
   * This class supports the \link InplaceDecomposition inplace decomposition \endlink mechanism.
-  * 
+  *
   * \sa MatrixBase::partialPivLu(), MatrixBase::determinant(), MatrixBase::inverse(), MatrixBase::computeInverse(), class FullPivLU
   */
 template<typename _MatrixType> class PartialPivLU
   : public SolverBase<PartialPivLU<_MatrixType> >
 {
   public:
 
@@ -212,16 +212,16 @@
       *
       * \sa MatrixBase::determinant()
       */
     Scalar determinant() const;
 
     MatrixType reconstructedMatrix() const;
 
-    inline Index rows() const { return m_lu.rows(); }
-    inline Index cols() const { return m_lu.cols(); }
+    EIGEN_CONSTEXPR inline Index rows() const EIGEN_NOEXCEPT { return m_lu.rows(); }
+    EIGEN_CONSTEXPR inline Index cols() const EIGEN_NOEXCEPT { return m_lu.cols(); }
 
     #ifndef EIGEN_PARSED_BY_DOXYGEN
     template<typename RhsType, typename DstType>
     EIGEN_DEVICE_FUNC
     void _solve_impl(const RhsType &rhs, DstType &dst) const {
      /* The decomposition PA = LU can be rewritten as A = P^{-1} L U.
       * So we proceed as follows:
@@ -500,16 +500,21 @@
 };
 
 /** \internal performs the LU decomposition with partial pivoting in-place.
   */
 template<typename MatrixType, typename TranspositionType>
 void partial_lu_inplace(MatrixType& lu, TranspositionType& row_transpositions, typename TranspositionType::StorageIndex& nb_transpositions)
 {
+  // Special-case of zero matrix.
+  if (lu.rows() == 0 || lu.cols() == 0) {
+    nb_transpositions = 0;
+    return;
+  }
   eigen_assert(lu.cols() == row_transpositions.size());
-  eigen_assert((&row_transpositions.coeffRef(1)-&row_transpositions.coeffRef(0)) == 1);
+  eigen_assert(row_transpositions.size() < 2 || (&row_transpositions.coeffRef(1)-&row_transpositions.coeffRef(0)) == 1);
 
   partial_lu_impl
     < typename MatrixType::Scalar, MatrixType::Flags&RowMajorBit?RowMajor:ColMajor,
       typename TranspositionType::StorageIndex,
       EIGEN_SIZE_MIN_PREFER_FIXED(MatrixType::RowsAtCompileTime,MatrixType::ColsAtCompileTime)>
     ::blocked_lu(lu.rows(), lu.cols(), &lu.coeffRef(0,0), lu.outerStride(), &row_transpositions.coeffRef(0), nb_transpositions);
 }
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/LU/PartialPivLU_LAPACKE.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/LU/PartialPivLU_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/MetisSupport/MetisSupport.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/MetisSupport/MetisSupport.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/OrderingMethods/Amd.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/OrderingMethods/Amd.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/OrderingMethods/Eigen_Colamd.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/OrderingMethods/Eigen_Colamd.h`

 * *Files 8% similar despite different names*

```diff
@@ -9,133 +9,137 @@
 
 // This file is modified from the colamd/symamd library. The copyright is below
 
 //   The authors of the code itself are Stefan I. Larimore and Timothy A.
 //   Davis (davis@cise.ufl.edu), University of Florida.  The algorithm was
 //   developed in collaboration with John Gilbert, Xerox PARC, and Esmond
 //   Ng, Oak Ridge National Laboratory.
-// 
+//
 //     Date:
-// 
+//
 //   September 8, 2003.  Version 2.3.
-// 
+//
 //     Acknowledgements:
-// 
+//
 //   This work was supported by the National Science Foundation, under
 //   grants DMS-9504974 and DMS-9803599.
-// 
+//
 //     Notice:
-// 
+//
 //   Copyright (c) 1998-2003 by the University of Florida.
 //   All Rights Reserved.
-// 
+//
 //   THIS MATERIAL IS PROVIDED AS IS, WITH ABSOLUTELY NO WARRANTY
 //   EXPRESSED OR IMPLIED.  ANY USE IS AT YOUR OWN RISK.
-// 
+//
 //   Permission is hereby granted to use, copy, modify, and/or distribute
 //   this program, provided that the Copyright, this License, and the
 //   Availability of the original version is retained on all copies and made
 //   accessible to the end-user of any code or package that includes COLAMD
-//   or any modified version of COLAMD. 
-// 
+//   or any modified version of COLAMD.
+//
 //     Availability:
-// 
+//
 //   The colamd/symamd library is available at
-// 
+//
 //       http://www.suitesparse.com
 
-  
+
 #ifndef EIGEN_COLAMD_H
 #define EIGEN_COLAMD_H
 
 namespace internal {
+
+namespace Colamd {
+
 /* Ensure that debugging is turned off: */
 #ifndef COLAMD_NDEBUG
 #define COLAMD_NDEBUG
 #endif /* NDEBUG */
+
+
 /* ========================================================================== */
 /* === Knob and statistics definitions ====================================== */
 /* ========================================================================== */
 
 /* size of the knobs [ ] array.  Only knobs [0..1] are currently used. */
-#define COLAMD_KNOBS 20
+const int NKnobs = 20;
 
 /* number of output statistics.  Only stats [0..6] are currently used. */
-#define COLAMD_STATS 20 
-
-/* knobs [0] and stats [0]: dense row knob and output statistic. */
-#define COLAMD_DENSE_ROW 0
-
-/* knobs [1] and stats [1]: dense column knob and output statistic. */
-#define COLAMD_DENSE_COL 1
-
-/* stats [2]: memory defragmentation count output statistic */
-#define COLAMD_DEFRAG_COUNT 2
-
-/* stats [3]: colamd status:  zero OK, > 0 warning or notice, < 0 error */
-#define COLAMD_STATUS 3
+const int NStats = 20;
 
-/* stats [4..6]: error info, or info on jumbled columns */ 
-#define COLAMD_INFO1 4
-#define COLAMD_INFO2 5
-#define COLAMD_INFO3 6
+/* Indices into knobs and stats array. */
+enum KnobsStatsIndex {
+  /* knobs [0] and stats [0]: dense row knob and output statistic. */
+  DenseRow = 0,
+
+  /* knobs [1] and stats [1]: dense column knob and output statistic. */
+  DenseCol = 1,
+
+  /* stats [2]: memory defragmentation count output statistic */
+  DefragCount = 2,
+
+  /* stats [3]: colamd status:  zero OK, > 0 warning or notice, < 0 error */
+  Status = 3,
+
+  /* stats [4..6]: error info, or info on jumbled columns */
+  Info1 = 4,
+  Info2 = 5,
+  Info3 = 6
+};
 
 /* error codes returned in stats [3]: */
-#define COLAMD_OK       (0)
-#define COLAMD_OK_BUT_JUMBLED     (1)
-#define COLAMD_ERROR_A_not_present    (-1)
-#define COLAMD_ERROR_p_not_present    (-2)
-#define COLAMD_ERROR_nrow_negative    (-3)
-#define COLAMD_ERROR_ncol_negative    (-4)
-#define COLAMD_ERROR_nnz_negative   (-5)
-#define COLAMD_ERROR_p0_nonzero     (-6)
-#define COLAMD_ERROR_A_too_small    (-7)
-#define COLAMD_ERROR_col_length_negative  (-8)
-#define COLAMD_ERROR_row_index_out_of_bounds  (-9)
-#define COLAMD_ERROR_out_of_memory    (-10)
-#define COLAMD_ERROR_internal_error   (-999)
-
+enum Status {
+  Ok = 0,
+  OkButJumbled = 1,
+  ErrorANotPresent = -1,
+  ErrorPNotPresent = -2,
+  ErrorNrowNegative = -3,
+  ErrorNcolNegative = -4,
+  ErrorNnzNegative = -5,
+  ErrorP0Nonzero = -6,
+  ErrorATooSmall = -7,
+  ErrorColLengthNegative = -8,
+  ErrorRowIndexOutOfBounds = -9,
+  ErrorOutOfMemory = -10,
+  ErrorInternalError = -999
+};
 /* ========================================================================== */
 /* === Definitions ========================================================== */
 /* ========================================================================== */
 
-#define ONES_COMPLEMENT(r) (-(r)-1)
+template <typename IndexType>
+IndexType ones_complement(const IndexType r) {
+  return (-(r)-1);
+}
 
 /* -------------------------------------------------------------------------- */
-
-#define COLAMD_EMPTY (-1)
+const int Empty = -1;
 
 /* Row and column status */
-#define ALIVE (0)
-#define DEAD  (-1)
+enum RowColumnStatus {
+  Alive = 0,
+  Dead = -1
+};
 
 /* Column status */
-#define DEAD_PRINCIPAL    (-1)
-#define DEAD_NON_PRINCIPAL  (-2)
-
-/* Macros for row and column status update and checking. */
-#define ROW_IS_DEAD(r)      ROW_IS_MARKED_DEAD (Row[r].shared2.mark)
-#define ROW_IS_MARKED_DEAD(row_mark)  (row_mark < ALIVE)
-#define ROW_IS_ALIVE(r)     (Row [r].shared2.mark >= ALIVE)
-#define COL_IS_DEAD(c)      (Col [c].start < ALIVE)
-#define COL_IS_ALIVE(c)     (Col [c].start >= ALIVE)
-#define COL_IS_DEAD_PRINCIPAL(c)  (Col [c].start == DEAD_PRINCIPAL)
-#define KILL_ROW(r)     { Row [r].shared2.mark = DEAD ; }
-#define KILL_PRINCIPAL_COL(c)   { Col [c].start = DEAD_PRINCIPAL ; }
-#define KILL_NON_PRINCIPAL_COL(c) { Col [c].start = DEAD_NON_PRINCIPAL ; }
+enum ColumnStatus {
+  DeadPrincipal = -1,
+  DeadNonPrincipal = -2
+};
 
 /* ========================================================================== */
 /* === Colamd reporting mechanism =========================================== */
 /* ========================================================================== */
 
 // == Row and Column structures ==
 template <typename IndexType>
-struct colamd_col
+struct ColStructure
 {
-  IndexType start ;   /* index for A of first row in this column, or DEAD */
+  IndexType start ;   /* index for A of first row in this column, or Dead */
   /* if column is dead */
   IndexType length ;  /* number of rows in this column */
   union
   {
     IndexType thickness ; /* number of original columns represented by this */
     /* col, if the column is alive */
     IndexType parent ;  /* parent in parent tree super-column structure, if */
@@ -155,321 +159,336 @@
     /* degree list (but not at the head of a degree list) */
   } shared3 ;
   union
   {
     IndexType degree_next ; /* next column, if col is in a degree list */
     IndexType hash_next ;   /* next column, if col is in a hash list */
   } shared4 ;
-  
+
+  inline bool is_dead() const { return start < Alive; }
+
+  inline bool is_alive() const { return start >= Alive; }
+
+  inline bool is_dead_principal() const { return start == DeadPrincipal; }
+
+  inline void kill_principal() { start = DeadPrincipal; }
+
+  inline void kill_non_principal() { start = DeadNonPrincipal; }
+
 };
- 
+
 template <typename IndexType>
-struct Colamd_Row
+struct RowStructure
 {
   IndexType start ;   /* index for A of first col in this row */
   IndexType length ;  /* number of principal columns in this row */
   union
   {
     IndexType degree ;  /* number of principal & non-principal columns in row */
     IndexType p ;   /* used as a row pointer in init_rows_cols () */
   } shared1 ;
   union
   {
     IndexType mark ;  /* for computing set differences and marking dead rows*/
     IndexType first_column ;/* first column in row (used in garbage collection) */
   } shared2 ;
-  
+
+  inline bool is_dead() const { return shared2.mark < Alive; }
+
+  inline bool is_alive() const { return shared2.mark >= Alive; }
+
+  inline void kill() { shared2.mark = Dead; }
+
 };
- 
+
 /* ========================================================================== */
 /* === Colamd recommended memory size ======================================= */
 /* ========================================================================== */
- 
+
 /*
   The recommended length Alen of the array A passed to colamd is given by
   the COLAMD_RECOMMENDED (nnz, n_row, n_col) macro.  It returns -1 if any
   argument is negative.  2*nnz space is required for the row and column
   indices of the matrix. colamd_c (n_col) + colamd_r (n_row) space is
   required for the Col and Row arrays, respectively, which are internal to
   colamd.  An additional n_col space is the minimal amount of "elbow room",
   and nnz/5 more space is recommended for run time efficiency.
-  
+
   This macro is not needed when using symamd.
-  
+
   Explicit typecast to IndexType added Sept. 23, 2002, COLAMD version 2.2, to avoid
   gcc -pedantic warning messages.
 */
 template <typename IndexType>
-inline IndexType colamd_c(IndexType n_col) 
-{ return IndexType( ((n_col) + 1) * sizeof (colamd_col<IndexType>) / sizeof (IndexType) ) ; }
+inline IndexType colamd_c(IndexType n_col)
+{ return IndexType( ((n_col) + 1) * sizeof (ColStructure<IndexType>) / sizeof (IndexType) ) ; }
 
 template <typename IndexType>
 inline IndexType  colamd_r(IndexType n_row)
-{ return IndexType(((n_row) + 1) * sizeof (Colamd_Row<IndexType>) / sizeof (IndexType)); }
+{ return IndexType(((n_row) + 1) * sizeof (RowStructure<IndexType>) / sizeof (IndexType)); }
 
 // Prototypes of non-user callable routines
 template <typename IndexType>
-static IndexType init_rows_cols (IndexType n_row, IndexType n_col, Colamd_Row<IndexType> Row [], colamd_col<IndexType> col [], IndexType A [], IndexType p [], IndexType stats[COLAMD_STATS] ); 
+static IndexType init_rows_cols (IndexType n_row, IndexType n_col, RowStructure<IndexType> Row [], ColStructure<IndexType> col [], IndexType A [], IndexType p [], IndexType stats[NStats] );
 
 template <typename IndexType>
-static void init_scoring (IndexType n_row, IndexType n_col, Colamd_Row<IndexType> Row [], colamd_col<IndexType> Col [], IndexType A [], IndexType head [], double knobs[COLAMD_KNOBS], IndexType *p_n_row2, IndexType *p_n_col2, IndexType *p_max_deg);
+static void init_scoring (IndexType n_row, IndexType n_col, RowStructure<IndexType> Row [], ColStructure<IndexType> Col [], IndexType A [], IndexType head [], double knobs[NKnobs], IndexType *p_n_row2, IndexType *p_n_col2, IndexType *p_max_deg);
 
 template <typename IndexType>
-static IndexType find_ordering (IndexType n_row, IndexType n_col, IndexType Alen, Colamd_Row<IndexType> Row [], colamd_col<IndexType> Col [], IndexType A [], IndexType head [], IndexType n_col2, IndexType max_deg, IndexType pfree);
+static IndexType find_ordering (IndexType n_row, IndexType n_col, IndexType Alen, RowStructure<IndexType> Row [], ColStructure<IndexType> Col [], IndexType A [], IndexType head [], IndexType n_col2, IndexType max_deg, IndexType pfree);
 
 template <typename IndexType>
-static void order_children (IndexType n_col, colamd_col<IndexType> Col [], IndexType p []);
+static void order_children (IndexType n_col, ColStructure<IndexType> Col [], IndexType p []);
 
 template <typename IndexType>
-static void detect_super_cols (colamd_col<IndexType> Col [], IndexType A [], IndexType head [], IndexType row_start, IndexType row_length ) ;
+static void detect_super_cols (ColStructure<IndexType> Col [], IndexType A [], IndexType head [], IndexType row_start, IndexType row_length ) ;
 
 template <typename IndexType>
-static IndexType garbage_collection (IndexType n_row, IndexType n_col, Colamd_Row<IndexType> Row [], colamd_col<IndexType> Col [], IndexType A [], IndexType *pfree) ;
+static IndexType garbage_collection (IndexType n_row, IndexType n_col, RowStructure<IndexType> Row [], ColStructure<IndexType> Col [], IndexType A [], IndexType *pfree) ;
 
 template <typename IndexType>
-static inline  IndexType clear_mark (IndexType n_row, Colamd_Row<IndexType> Row [] ) ;
+static inline  IndexType clear_mark (IndexType n_row, RowStructure<IndexType> Row [] ) ;
 
 /* === No debugging ========================================================= */
 
 #define COLAMD_DEBUG0(params) ;
 #define COLAMD_DEBUG1(params) ;
 #define COLAMD_DEBUG2(params) ;
 #define COLAMD_DEBUG3(params) ;
 #define COLAMD_DEBUG4(params) ;
 
 #define COLAMD_ASSERT(expression) ((void) 0)
 
 
 /**
- * \brief Returns the recommended value of Alen 
- * 
- * Returns recommended value of Alen for use by colamd.  
- * Returns -1 if any input argument is negative.  
- * The use of this routine or macro is optional.  
- * Note that the macro uses its arguments   more than once, 
- * so be careful for side effects, if you pass expressions as arguments to COLAMD_RECOMMENDED.  
- * 
+ * \brief Returns the recommended value of Alen
+ *
+ * Returns recommended value of Alen for use by colamd.
+ * Returns -1 if any input argument is negative.
+ * The use of this routine or macro is optional.
+ * Note that the macro uses its arguments   more than once,
+ * so be careful for side effects, if you pass expressions as arguments to COLAMD_RECOMMENDED.
+ *
  * \param nnz nonzeros in A
  * \param n_row number of rows in A
  * \param n_col number of columns in A
  * \return recommended value of Alen for use by colamd
  */
 template <typename IndexType>
-inline IndexType colamd_recommended ( IndexType nnz, IndexType n_row, IndexType n_col)
+inline IndexType recommended ( IndexType nnz, IndexType n_row, IndexType n_col)
 {
   if ((nnz) < 0 || (n_row) < 0 || (n_col) < 0)
     return (-1);
   else
-    return (2 * (nnz) + colamd_c (n_col) + colamd_r (n_row) + (n_col) + ((nnz) / 5)); 
+    return (2 * (nnz) + colamd_c (n_col) + colamd_r (n_row) + (n_col) + ((nnz) / 5));
 }
 
 /**
  * \brief set default parameters  The use of this routine is optional.
- * 
- * Colamd: rows with more than (knobs [COLAMD_DENSE_ROW] * n_col)
+ *
+ * Colamd: rows with more than (knobs [DenseRow] * n_col)
  * entries are removed prior to ordering.  Columns with more than
- * (knobs [COLAMD_DENSE_COL] * n_row) entries are removed prior to
- * ordering, and placed last in the output column ordering. 
+ * (knobs [DenseCol] * n_row) entries are removed prior to
+ * ordering, and placed last in the output column ordering.
  *
- * COLAMD_DENSE_ROW and COLAMD_DENSE_COL are defined as 0 and 1,
+ * DenseRow and DenseCol are defined as 0 and 1,
  * respectively, in colamd.h.  Default values of these two knobs
  * are both 0.5.  Currently, only knobs [0] and knobs [1] are
  * used, but future versions may use more knobs.  If so, they will
  * be properly set to their defaults by the future version of
  * colamd_set_defaults, so that the code that calls colamd will
  * not need to change, assuming that you either use
  * colamd_set_defaults, or pass a (double *) NULL pointer as the
  * knobs array to colamd or symamd.
- * 
+ *
  * \param knobs parameter settings for colamd
  */
 
-static inline void colamd_set_defaults(double knobs[COLAMD_KNOBS])
+static inline void set_defaults(double knobs[NKnobs])
 {
   /* === Local variables ================================================== */
-  
+
   int i ;
 
   if (!knobs)
   {
     return ;      /* no knobs to initialize */
   }
-  for (i = 0 ; i < COLAMD_KNOBS ; i++)
+  for (i = 0 ; i < NKnobs ; i++)
   {
     knobs [i] = 0 ;
   }
-  knobs [COLAMD_DENSE_ROW] = 0.5 ;  /* ignore rows over 50% dense */
-  knobs [COLAMD_DENSE_COL] = 0.5 ;  /* ignore columns over 50% dense */
+  knobs [Colamd::DenseRow] = 0.5 ;  /* ignore rows over 50% dense */
+  knobs [Colamd::DenseCol] = 0.5 ;  /* ignore columns over 50% dense */
 }
 
-/** 
+/**
  * \brief  Computes a column ordering using the column approximate minimum degree ordering
- * 
+ *
  * Computes a column ordering (Q) of A such that P(AQ)=LU or
  * (AQ)'AQ=LL' have less fill-in and require fewer floating point
  * operations than factorizing the unpermuted matrix A or A'A,
  * respectively.
- * 
- * 
+ *
+ *
  * \param n_row number of rows in A
  * \param n_col number of columns in A
  * \param Alen, size of the array A
  * \param A row indices of the matrix, of size ALen
  * \param p column pointers of A, of size n_col+1
  * \param knobs parameter settings for colamd
  * \param stats colamd output statistics and error codes
  */
 template <typename IndexType>
-static bool colamd(IndexType n_row, IndexType n_col, IndexType Alen, IndexType *A, IndexType *p, double knobs[COLAMD_KNOBS], IndexType stats[COLAMD_STATS])
+static bool compute_ordering(IndexType n_row, IndexType n_col, IndexType Alen, IndexType *A, IndexType *p, double knobs[NKnobs], IndexType stats[NStats])
 {
   /* === Local variables ================================================== */
-  
+
   IndexType i ;     /* loop index */
   IndexType nnz ;     /* nonzeros in A */
   IndexType Row_size ;    /* size of Row [], in integers */
   IndexType Col_size ;    /* size of Col [], in integers */
   IndexType need ;      /* minimum required length of A */
-  Colamd_Row<IndexType> *Row ;   /* pointer into A of Row [0..n_row] array */
-  colamd_col<IndexType> *Col ;   /* pointer into A of Col [0..n_col] array */
+  Colamd::RowStructure<IndexType> *Row ;   /* pointer into A of Row [0..n_row] array */
+  Colamd::ColStructure<IndexType> *Col ;   /* pointer into A of Col [0..n_col] array */
   IndexType n_col2 ;    /* number of non-dense, non-empty columns */
   IndexType n_row2 ;    /* number of non-dense, non-empty rows */
   IndexType ngarbage ;    /* number of garbage collections performed */
   IndexType max_deg ;   /* maximum row degree */
-  double default_knobs [COLAMD_KNOBS] ; /* default knobs array */
-  
-  
+  double default_knobs [NKnobs] ; /* default knobs array */
+
+
   /* === Check the input arguments ======================================== */
-  
+
   if (!stats)
   {
     COLAMD_DEBUG0 (("colamd: stats not present\n")) ;
     return (false) ;
   }
-  for (i = 0 ; i < COLAMD_STATS ; i++)
+  for (i = 0 ; i < NStats ; i++)
   {
     stats [i] = 0 ;
   }
-  stats [COLAMD_STATUS] = COLAMD_OK ;
-  stats [COLAMD_INFO1] = -1 ;
-  stats [COLAMD_INFO2] = -1 ;
-  
+  stats [Colamd::Status] = Colamd::Ok ;
+  stats [Colamd::Info1] = -1 ;
+  stats [Colamd::Info2] = -1 ;
+
   if (!A)   /* A is not present */
   {
-    stats [COLAMD_STATUS] = COLAMD_ERROR_A_not_present ;
+    stats [Colamd::Status] = Colamd::ErrorANotPresent ;
     COLAMD_DEBUG0 (("colamd: A not present\n")) ;
     return (false) ;
   }
-  
+
   if (!p)   /* p is not present */
   {
-    stats [COLAMD_STATUS] = COLAMD_ERROR_p_not_present ;
+    stats [Colamd::Status] = Colamd::ErrorPNotPresent ;
     COLAMD_DEBUG0 (("colamd: p not present\n")) ;
     return (false) ;
   }
-  
+
   if (n_row < 0)  /* n_row must be >= 0 */
   {
-    stats [COLAMD_STATUS] = COLAMD_ERROR_nrow_negative ;
-    stats [COLAMD_INFO1] = n_row ;
+    stats [Colamd::Status] = Colamd::ErrorNrowNegative ;
+    stats [Colamd::Info1] = n_row ;
     COLAMD_DEBUG0 (("colamd: nrow negative %d\n", n_row)) ;
     return (false) ;
   }
-  
+
   if (n_col < 0)  /* n_col must be >= 0 */
   {
-    stats [COLAMD_STATUS] = COLAMD_ERROR_ncol_negative ;
-    stats [COLAMD_INFO1] = n_col ;
+    stats [Colamd::Status] = Colamd::ErrorNcolNegative ;
+    stats [Colamd::Info1] = n_col ;
     COLAMD_DEBUG0 (("colamd: ncol negative %d\n", n_col)) ;
     return (false) ;
   }
-  
+
   nnz = p [n_col] ;
   if (nnz < 0)  /* nnz must be >= 0 */
   {
-    stats [COLAMD_STATUS] = COLAMD_ERROR_nnz_negative ;
-    stats [COLAMD_INFO1] = nnz ;
+    stats [Colamd::Status] = Colamd::ErrorNnzNegative ;
+    stats [Colamd::Info1] = nnz ;
     COLAMD_DEBUG0 (("colamd: number of entries negative %d\n", nnz)) ;
     return (false) ;
   }
-  
+
   if (p [0] != 0)
   {
-    stats [COLAMD_STATUS] = COLAMD_ERROR_p0_nonzero ;
-    stats [COLAMD_INFO1] = p [0] ;
+    stats [Colamd::Status] = Colamd::ErrorP0Nonzero ;
+    stats [Colamd::Info1] = p [0] ;
     COLAMD_DEBUG0 (("colamd: p[0] not zero %d\n", p [0])) ;
     return (false) ;
   }
-  
+
   /* === If no knobs, set default knobs =================================== */
-  
+
   if (!knobs)
   {
-    colamd_set_defaults (default_knobs) ;
+    set_defaults (default_knobs) ;
     knobs = default_knobs ;
   }
-  
+
   /* === Allocate the Row and Col arrays from array A ===================== */
-  
+
   Col_size = colamd_c (n_col) ;
   Row_size = colamd_r (n_row) ;
   need = 2*nnz + n_col + Col_size + Row_size ;
-  
+
   if (need > Alen)
   {
     /* not enough space in array A to perform the ordering */
-    stats [COLAMD_STATUS] = COLAMD_ERROR_A_too_small ;
-    stats [COLAMD_INFO1] = need ;
-    stats [COLAMD_INFO2] = Alen ;
+    stats [Colamd::Status] = Colamd::ErrorATooSmall ;
+    stats [Colamd::Info1] = need ;
+    stats [Colamd::Info2] = Alen ;
     COLAMD_DEBUG0 (("colamd: Need Alen >= %d, given only Alen = %d\n", need,Alen));
     return (false) ;
   }
-  
+
   Alen -= Col_size + Row_size ;
-  Col = (colamd_col<IndexType> *) &A [Alen] ;
-  Row = (Colamd_Row<IndexType> *) &A [Alen + Col_size] ;
+  Col = (ColStructure<IndexType> *) &A [Alen] ;
+  Row = (RowStructure<IndexType> *) &A [Alen + Col_size] ;
 
   /* === Construct the row and column data structures ===================== */
-  
-  if (!Eigen::internal::init_rows_cols (n_row, n_col, Row, Col, A, p, stats))
+
+  if (!Colamd::init_rows_cols (n_row, n_col, Row, Col, A, p, stats))
   {
     /* input matrix is invalid */
     COLAMD_DEBUG0 (("colamd: Matrix invalid\n")) ;
     return (false) ;
   }
-  
+
   /* === Initialize scores, kill dense rows/columns ======================= */
 
-  Eigen::internal::init_scoring (n_row, n_col, Row, Col, A, p, knobs,
+  Colamd::init_scoring (n_row, n_col, Row, Col, A, p, knobs,
 		&n_row2, &n_col2, &max_deg) ;
-  
+
   /* === Order the supercolumns =========================================== */
-  
-  ngarbage = Eigen::internal::find_ordering (n_row, n_col, Alen, Row, Col, A, p,
+
+  ngarbage = Colamd::find_ordering (n_row, n_col, Alen, Row, Col, A, p,
 			    n_col2, max_deg, 2*nnz) ;
-  
+
   /* === Order the non-principal columns ================================== */
-  
-  Eigen::internal::order_children (n_col, Col, p) ;
-  
+
+  Colamd::order_children (n_col, Col, p) ;
+
   /* === Return statistics in stats ======================================= */
-  
-  stats [COLAMD_DENSE_ROW] = n_row - n_row2 ;
-  stats [COLAMD_DENSE_COL] = n_col - n_col2 ;
-  stats [COLAMD_DEFRAG_COUNT] = ngarbage ;
-  COLAMD_DEBUG0 (("colamd: done.\n")) ; 
+
+  stats [Colamd::DenseRow] = n_row - n_row2 ;
+  stats [Colamd::DenseCol] = n_col - n_col2 ;
+  stats [Colamd::DefragCount] = ngarbage ;
+  COLAMD_DEBUG0 (("colamd: done.\n")) ;
   return (true) ;
 }
 
 /* ========================================================================== */
 /* === NON-USER-CALLABLE ROUTINES: ========================================== */
 /* ========================================================================== */
 
 /* There are no user-callable routines beyond this point in the file */
 
-
 /* ========================================================================== */
 /* === init_rows_cols ======================================================= */
 /* ========================================================================== */
 
 /*
   Takes the column form of the matrix in A and creates the row form of the
   matrix.  Also, row and column attributes are stored in the Col and Row
@@ -481,19 +500,19 @@
 template <typename IndexType>
 static IndexType init_rows_cols  /* returns true if OK, or false otherwise */
   (
     /* === Parameters ======================================================= */
 
     IndexType n_row,      /* number of rows of A */
     IndexType n_col,      /* number of columns of A */
-    Colamd_Row<IndexType> Row [],    /* of size n_row+1 */
-    colamd_col<IndexType> Col [],    /* of size n_col+1 */
+    RowStructure<IndexType> Row [],    /* of size n_row+1 */
+    ColStructure<IndexType> Col [],    /* of size n_col+1 */
     IndexType A [],     /* row indices of A, of size Alen */
     IndexType p [],     /* pointers to columns in A, of size n_col+1 */
-    IndexType stats [COLAMD_STATS]  /* colamd statistics */ 
+    IndexType stats [NStats]  /* colamd statistics */
     )
 {
   /* === Local variables ================================================== */
 
   IndexType col ;     /* a column index */
   IndexType row ;     /* a row index */
   IndexType *cp ;     /* a column pointer */
@@ -508,32 +527,32 @@
   {
     Col [col].start = p [col] ;
     Col [col].length = p [col+1] - p [col] ;
 
     if ((Col [col].length) < 0) // extra parentheses to work-around gcc bug 10200
     {
       /* column pointers must be non-decreasing */
-      stats [COLAMD_STATUS] = COLAMD_ERROR_col_length_negative ;
-      stats [COLAMD_INFO1] = col ;
-      stats [COLAMD_INFO2] = Col [col].length ;
+      stats [Colamd::Status] = Colamd::ErrorColLengthNegative ;
+      stats [Colamd::Info1] = col ;
+      stats [Colamd::Info2] = Col [col].length ;
       COLAMD_DEBUG0 (("colamd: col %d length %d < 0\n", col, Col [col].length)) ;
       return (false) ;
     }
 
     Col [col].shared1.thickness = 1 ;
     Col [col].shared2.score = 0 ;
-    Col [col].shared3.prev = COLAMD_EMPTY ;
-    Col [col].shared4.degree_next = COLAMD_EMPTY ;
+    Col [col].shared3.prev = Empty ;
+    Col [col].shared4.degree_next = Empty ;
   }
 
   /* p [0..n_col] no longer needed, used as "head" in subsequent routines */
 
   /* === Scan columns, compute row degrees, and check row indices ========= */
 
-  stats [COLAMD_INFO3] = 0 ;  /* number of duplicate or unsorted row indices*/
+  stats [Info3] = 0 ;  /* number of duplicate or unsorted row indices*/
 
   for (row = 0 ; row < n_row ; row++)
   {
     Row [row].length = 0 ;
     Row [row].shared2.mark = -1 ;
   }
 
@@ -547,30 +566,30 @@
     while (cp < cp_end)
     {
       row = *cp++ ;
 
       /* make sure row indices within range */
       if (row < 0 || row >= n_row)
       {
-	stats [COLAMD_STATUS] = COLAMD_ERROR_row_index_out_of_bounds ;
-	stats [COLAMD_INFO1] = col ;
-	stats [COLAMD_INFO2] = row ;
-	stats [COLAMD_INFO3] = n_row ;
+	stats [Colamd::Status] = Colamd::ErrorRowIndexOutOfBounds ;
+	stats [Colamd::Info1] = col ;
+	stats [Colamd::Info2] = row ;
+	stats [Colamd::Info3] = n_row ;
 	COLAMD_DEBUG0 (("colamd: row %d col %d out of bounds\n", row, col)) ;
 	return (false) ;
       }
 
       if (row <= last_row || Row [row].shared2.mark == col)
       {
 	/* row index are unsorted or repeated (or both), thus col */
 	/* is jumbled.  This is a notice, not an error condition. */
-	stats [COLAMD_STATUS] = COLAMD_OK_BUT_JUMBLED ;
-	stats [COLAMD_INFO1] = col ;
-	stats [COLAMD_INFO2] = row ;
-	(stats [COLAMD_INFO3]) ++ ;
+	stats [Colamd::Status] = Colamd::OkButJumbled ;
+	stats [Colamd::Info1] = col ;
+	stats [Colamd::Info2] = row ;
+	(stats [Colamd::Info3]) ++ ;
 	COLAMD_DEBUG1 (("colamd: row %d col %d unsorted/duplicate\n",row,col));
       }
 
       if (Row [row].shared2.mark != col)
       {
 	Row [row].length++ ;
       }
@@ -600,15 +619,15 @@
     Row [row].start = Row [row-1].start + Row [row-1].length ;
     Row [row].shared1.p = Row [row].start ;
     Row [row].shared2.mark = -1 ;
   }
 
   /* === Create row form ================================================== */
 
-  if (stats [COLAMD_STATUS] == COLAMD_OK_BUT_JUMBLED)
+  if (stats [Status] == OkButJumbled)
   {
     /* if cols jumbled, watch for repeated row indices */
     for (col = 0 ; col < n_col ; col++)
     {
       cp = &A [p [col]] ;
       cp_end = &A [p [col+1]] ;
       while (cp < cp_end)
@@ -642,15 +661,15 @@
   {
     Row [row].shared2.mark = 0 ;
     Row [row].shared1.degree = Row [row].length ;
   }
 
   /* === See if we need to re-create columns ============================== */
 
-  if (stats [COLAMD_STATUS] == COLAMD_OK_BUT_JUMBLED)
+  if (stats [Status] == OkButJumbled)
   {
     COLAMD_DEBUG0 (("colamd: reconstructing column form, matrix jumbled\n")) ;
 
 
     /* === Compute col pointers ========================================= */
 
     /* col form of the matrix starts at A [0]. */
@@ -697,19 +716,19 @@
 template <typename IndexType>
 static void init_scoring
   (
     /* === Parameters ======================================================= */
 
     IndexType n_row,      /* number of rows of A */
     IndexType n_col,      /* number of columns of A */
-    Colamd_Row<IndexType> Row [],    /* of size n_row+1 */
-    colamd_col<IndexType> Col [],    /* of size n_col+1 */
+    RowStructure<IndexType> Row [],    /* of size n_row+1 */
+    ColStructure<IndexType> Col [],    /* of size n_col+1 */
     IndexType A [],     /* column form and row form of A */
     IndexType head [],    /* of size n_col+1 */
-    double knobs [COLAMD_KNOBS],/* parameters */
+    double knobs [NKnobs],/* parameters */
     IndexType *p_n_row2,    /* number of non-dense, non-empty rows */
     IndexType *p_n_col2,    /* number of non-dense, non-empty columns */
     IndexType *p_max_deg    /* maximum row degree */
     )
 {
   /* === Local variables ================================================== */
 
@@ -728,16 +747,16 @@
   IndexType min_score ;   /* smallest column score */
   IndexType max_deg ;   /* maximum row degree */
   IndexType next_col ;    /* Used to add to degree list.*/
 
 
   /* === Extract knobs ==================================================== */
 
-  dense_row_count = numext::maxi(IndexType(0), numext::mini(IndexType(knobs [COLAMD_DENSE_ROW] * n_col), n_col)) ;
-  dense_col_count = numext::maxi(IndexType(0), numext::mini(IndexType(knobs [COLAMD_DENSE_COL] * n_row), n_row)) ;
+  dense_row_count = numext::maxi(IndexType(0), numext::mini(IndexType(knobs [Colamd::DenseRow] * n_col), n_col)) ;
+  dense_col_count = numext::maxi(IndexType(0), numext::mini(IndexType(knobs [Colamd::DenseCol] * n_row), n_row)) ;
   COLAMD_DEBUG1 (("colamd: densecount: %d %d\n", dense_row_count, dense_col_count)) ;
   max_deg = 0 ;
   n_col2 = n_col ;
   n_row2 = n_row ;
 
   /* === Kill empty columns =============================================== */
 
@@ -746,26 +765,26 @@
   for (c = n_col-1 ; c >= 0 ; c--)
   {
     deg = Col [c].length ;
     if (deg == 0)
     {
       /* this is a empty column, kill and order it last */
       Col [c].shared2.order = --n_col2 ;
-      KILL_PRINCIPAL_COL (c) ;
+      Col[c].kill_principal() ;
     }
   }
   COLAMD_DEBUG1 (("colamd: null columns killed: %d\n", n_col - n_col2)) ;
 
   /* === Kill dense columns =============================================== */
 
   /* Put the dense columns at the end, in their natural order */
   for (c = n_col-1 ; c >= 0 ; c--)
   {
     /* skip any dead columns */
-    if (COL_IS_DEAD (c))
+    if (Col[c].is_dead())
     {
       continue ;
     }
     deg = Col [c].length ;
     if (deg > dense_col_count)
     {
       /* this is a dense column, kill and order it last */
@@ -773,29 +792,29 @@
       /* decrement the row degrees */
       cp = &A [Col [c].start] ;
       cp_end = cp + Col [c].length ;
       while (cp < cp_end)
       {
 	Row [*cp++].shared1.degree-- ;
       }
-      KILL_PRINCIPAL_COL (c) ;
+      Col[c].kill_principal() ;
     }
   }
   COLAMD_DEBUG1 (("colamd: Dense and null columns killed: %d\n", n_col - n_col2)) ;
 
   /* === Kill dense and empty rows ======================================== */
 
   for (r = 0 ; r < n_row ; r++)
   {
     deg = Row [r].shared1.degree ;
     COLAMD_ASSERT (deg >= 0 && deg <= n_col) ;
     if (deg > dense_row_count || deg == 0)
     {
       /* kill a dense or empty row */
-      KILL_ROW (r) ;
+      Row[r].kill() ;
       --n_row2 ;
     }
     else
     {
       /* keep track of max degree of remaining rows */
       max_deg = numext::maxi(max_deg, deg) ;
     }
@@ -809,28 +828,28 @@
   /* Some "live" columns may contain only dead rows, however.  These are */
   /* pruned in the code below. */
 
   /* now find the initial matlab score for each column */
   for (c = n_col-1 ; c >= 0 ; c--)
   {
     /* skip dead column */
-    if (COL_IS_DEAD (c))
+    if (Col[c].is_dead())
     {
       continue ;
     }
     score = 0 ;
     cp = &A [Col [c].start] ;
     new_cp = cp ;
     cp_end = cp + Col [c].length ;
     while (cp < cp_end)
     {
       /* get a row */
       row = *cp++ ;
       /* skip if dead */
-      if (ROW_IS_DEAD (row))
+      if (Row[row].is_dead())
       {
 	continue ;
       }
       /* compact the column */
       *new_cp++ = row ;
       /* add row's external degree */
       score += Row [row].shared1.degree - 1 ;
@@ -841,15 +860,15 @@
     col_length = (IndexType) (new_cp - &A [Col [c].start]) ;
     if (col_length == 0)
     {
       /* a newly-made null column (all rows in this col are "dense" */
       /* and have already been killed) */
       COLAMD_DEBUG2 (("Newly null killed: %d\n", c)) ;
       Col [c].shared2.order = --n_col2 ;
-      KILL_PRINCIPAL_COL (c) ;
+      Col[c].kill_principal() ;
     }
     else
     {
       /* set column length and set score */
       COLAMD_ASSERT (score >= 0) ;
       COLAMD_ASSERT (score <= n_col) ;
       Col [c].length = col_length ;
@@ -866,45 +885,45 @@
 
   /* === Initialize degree lists ========================================== */
 
 
   /* clear the hash buckets */
   for (c = 0 ; c <= n_col ; c++)
   {
-    head [c] = COLAMD_EMPTY ;
+    head [c] = Empty ;
   }
   min_score = n_col ;
   /* place in reverse order, so low column indices are at the front */
   /* of the lists.  This is to encourage natural tie-breaking */
   for (c = n_col-1 ; c >= 0 ; c--)
   {
     /* only add principal columns to degree lists */
-    if (COL_IS_ALIVE (c))
+    if (Col[c].is_alive())
     {
       COLAMD_DEBUG4 (("place %d score %d minscore %d ncol %d\n",
 		      c, Col [c].shared2.score, min_score, n_col)) ;
 
       /* === Add columns score to DList =============================== */
 
       score = Col [c].shared2.score ;
 
       COLAMD_ASSERT (min_score >= 0) ;
       COLAMD_ASSERT (min_score <= n_col) ;
       COLAMD_ASSERT (score >= 0) ;
       COLAMD_ASSERT (score <= n_col) ;
-      COLAMD_ASSERT (head [score] >= COLAMD_EMPTY) ;
+      COLAMD_ASSERT (head [score] >= Empty) ;
 
       /* now add this column to dList at proper score location */
       next_col = head [score] ;
-      Col [c].shared3.prev = COLAMD_EMPTY ;
+      Col [c].shared3.prev = Empty ;
       Col [c].shared4.degree_next = next_col ;
 
       /* if there already was a column with the same score, set its */
       /* previous pointer to this new column */
-      if (next_col != COLAMD_EMPTY)
+      if (next_col != Empty)
       {
 	Col [next_col].shared3.prev = c ;
       }
       head [score] = c ;
 
       /* see if this score is less than current min */
       min_score = numext::mini(min_score, score) ;
@@ -935,16 +954,16 @@
 static IndexType find_ordering /* return the number of garbage collections */
   (
     /* === Parameters ======================================================= */
 
     IndexType n_row,      /* number of rows of A */
     IndexType n_col,      /* number of columns of A */
     IndexType Alen,     /* size of A, 2*nnz + n_col or larger */
-    Colamd_Row<IndexType> Row [],    /* of size n_row+1 */
-    colamd_col<IndexType> Col [],    /* of size n_col+1 */
+    RowStructure<IndexType> Row [],    /* of size n_row+1 */
+    ColStructure<IndexType> Col [],    /* of size n_col+1 */
     IndexType A [],     /* column form and row form of A */
     IndexType head [],    /* of size n_col+1 */
     IndexType n_col2,     /* Remaining columns to order */
     IndexType max_deg,    /* Maximum row degree */
     IndexType pfree     /* index of first free slot (2*nnz on entry) */
     )
 {
@@ -982,46 +1001,46 @@
   IndexType next_col ;    /* Used by Dlist operations. */
   IndexType ngarbage ;    /* number of garbage collections performed */
 
 
   /* === Initialization and clear mark ==================================== */
 
   max_mark = INT_MAX - n_col ;  /* INT_MAX defined in <limits.h> */
-  tag_mark = Eigen::internal::clear_mark (n_row, Row) ;
+  tag_mark = Colamd::clear_mark (n_row, Row) ;
   min_score = 0 ;
   ngarbage = 0 ;
   COLAMD_DEBUG1 (("colamd: Ordering, n_col2=%d\n", n_col2)) ;
 
   /* === Order the columns ================================================ */
 
   for (k = 0 ; k < n_col2 ; /* 'k' is incremented below */)
   {
 
     /* === Select pivot column, and order it ============================ */
 
     /* make sure degree list isn't empty */
     COLAMD_ASSERT (min_score >= 0) ;
     COLAMD_ASSERT (min_score <= n_col) ;
-    COLAMD_ASSERT (head [min_score] >= COLAMD_EMPTY) ;
+    COLAMD_ASSERT (head [min_score] >= Empty) ;
 
     /* get pivot column from head of minimum degree list */
-    while (min_score < n_col && head [min_score] == COLAMD_EMPTY)
+    while (min_score < n_col && head [min_score] == Empty)
     {
       min_score++ ;
     }
     pivot_col = head [min_score] ;
     COLAMD_ASSERT (pivot_col >= 0 && pivot_col <= n_col) ;
     next_col = Col [pivot_col].shared4.degree_next ;
     head [min_score] = next_col ;
-    if (next_col != COLAMD_EMPTY)
+    if (next_col != Empty)
     {
-      Col [next_col].shared3.prev = COLAMD_EMPTY ;
+      Col [next_col].shared3.prev = Empty ;
     }
 
-    COLAMD_ASSERT (COL_IS_ALIVE (pivot_col)) ;
+    COLAMD_ASSERT (Col[pivot_col].is_alive()) ;
     COLAMD_DEBUG3 (("Pivot col: %d\n", pivot_col)) ;
 
     /* remember score for defrag check */
     pivot_col_score = Col [pivot_col].shared2.score ;
 
     /* the pivot column is the kth column in the pivot order */
     Col [pivot_col].shared2.order = k ;
@@ -1032,20 +1051,20 @@
     COLAMD_ASSERT (pivot_col_thickness > 0) ;
 
     /* === Garbage_collection, if necessary ============================= */
 
     needed_memory = numext::mini(pivot_col_score, n_col - k) ;
     if (pfree + needed_memory >= Alen)
     {
-      pfree = Eigen::internal::garbage_collection (n_row, n_col, Row, Col, A, &A [pfree]) ;
+      pfree = Colamd::garbage_collection (n_row, n_col, Row, Col, A, &A [pfree]) ;
       ngarbage++ ;
       /* after garbage collection we will have enough */
       COLAMD_ASSERT (pfree + needed_memory < Alen) ;
       /* garbage collection has wiped out the Row[].shared2.mark array */
-      tag_mark = Eigen::internal::clear_mark (n_row, Row) ;
+      tag_mark = Colamd::clear_mark (n_row, Row) ;
 
     }
 
     /* === Compute pivot row pattern ==================================== */
 
     /* get starting location for this new merged row */
     pivot_row_start = pfree ;
@@ -1060,29 +1079,29 @@
     /* pivot row is the union of all rows in the pivot column pattern */
     cp = &A [Col [pivot_col].start] ;
     cp_end = cp + Col [pivot_col].length ;
     while (cp < cp_end)
     {
       /* get a row */
       row = *cp++ ;
-      COLAMD_DEBUG4 (("Pivot col pattern %d %d\n", ROW_IS_ALIVE (row), row)) ;
+      COLAMD_DEBUG4 (("Pivot col pattern %d %d\n", Row[row].is_alive(), row)) ;
       /* skip if row is dead */
-      if (ROW_IS_DEAD (row))
+      if (Row[row].is_dead())
       {
 	continue ;
       }
       rp = &A [Row [row].start] ;
       rp_end = rp + Row [row].length ;
       while (rp < rp_end)
       {
 	/* get a column */
 	col = *rp++ ;
 	/* add the column, if alive and untagged */
 	col_thickness = Col [col].shared1.thickness ;
-	if (col_thickness > 0 && COL_IS_ALIVE (col))
+	if (col_thickness > 0 && Col[col].is_alive())
 	{
 	  /* tag column in pivot row */
 	  Col [col].shared1.thickness = -col_thickness ;
 	  COLAMD_ASSERT (pfree < Alen) ;
 	  /* place column in pivot row */
 	  A [pfree++] = col ;
 	  pivot_row_degree += col_thickness ;
@@ -1101,30 +1120,30 @@
     cp = &A [Col [pivot_col].start] ;
     cp_end = cp + Col [pivot_col].length ;
     while (cp < cp_end)
     {
       /* may be killing an already dead row */
       row = *cp++ ;
       COLAMD_DEBUG3 (("Kill row in pivot col: %d\n", row)) ;
-      KILL_ROW (row) ;
+      Row[row].kill() ;
     }
 
     /* === Select a row index to use as the new pivot row =============== */
 
     pivot_row_length = pfree - pivot_row_start ;
     if (pivot_row_length > 0)
     {
       /* pick the "pivot" row arbitrarily (first row in col) */
       pivot_row = A [Col [pivot_col].start] ;
       COLAMD_DEBUG3 (("Pivotal row is %d\n", pivot_row)) ;
     }
     else
     {
       /* there is no pivot row, since it is of zero length */
-      pivot_row = COLAMD_EMPTY ;
+      pivot_row = Empty ;
       COLAMD_ASSERT (pivot_row_length == 0) ;
     }
     COLAMD_ASSERT (Col [pivot_col].length > 0 || pivot_row_length == 0) ;
 
     /* === Approximate degree computation =============================== */
 
     /* Here begins the computation of the approximate degree.  The column */
@@ -1153,57 +1172,57 @@
     COLAMD_DEBUG3 (("Pivot row: ")) ;
     /* for each column in pivot row */
     rp = &A [pivot_row_start] ;
     rp_end = rp + pivot_row_length ;
     while (rp < rp_end)
     {
       col = *rp++ ;
-      COLAMD_ASSERT (COL_IS_ALIVE (col) && col != pivot_col) ;
+      COLAMD_ASSERT (Col[col].is_alive() && col != pivot_col) ;
       COLAMD_DEBUG3 (("Col: %d\n", col)) ;
 
       /* clear tags used to construct pivot row pattern */
       col_thickness = -Col [col].shared1.thickness ;
       COLAMD_ASSERT (col_thickness > 0) ;
       Col [col].shared1.thickness = col_thickness ;
 
       /* === Remove column from degree list =========================== */
 
       cur_score = Col [col].shared2.score ;
       prev_col = Col [col].shared3.prev ;
       next_col = Col [col].shared4.degree_next ;
       COLAMD_ASSERT (cur_score >= 0) ;
       COLAMD_ASSERT (cur_score <= n_col) ;
-      COLAMD_ASSERT (cur_score >= COLAMD_EMPTY) ;
-      if (prev_col == COLAMD_EMPTY)
+      COLAMD_ASSERT (cur_score >= Empty) ;
+      if (prev_col == Empty)
       {
 	head [cur_score] = next_col ;
       }
       else
       {
 	Col [prev_col].shared4.degree_next = next_col ;
       }
-      if (next_col != COLAMD_EMPTY)
+      if (next_col != Empty)
       {
 	Col [next_col].shared3.prev = prev_col ;
       }
 
       /* === Scan the column ========================================== */
 
       cp = &A [Col [col].start] ;
       cp_end = cp + Col [col].length ;
       while (cp < cp_end)
       {
 	/* get a row */
 	row = *cp++ ;
-	row_mark = Row [row].shared2.mark ;
 	/* skip if dead */
-	if (ROW_IS_MARKED_DEAD (row_mark))
+	if (Row[row].is_dead())
 	{
 	  continue ;
 	}
+  row_mark = Row [row].shared2.mark ;
 	COLAMD_ASSERT (row != pivot_row) ;
 	set_difference = row_mark - tag_mark ;
 	/* check if the row has been seen yet */
 	if (set_difference < 0)
 	{
 	  COLAMD_ASSERT (Row [row].shared1.degree <= max_deg) ;
 	  set_difference = Row [row].shared1.degree ;
@@ -1211,15 +1230,15 @@
 	/* subtract column thickness from this row's set difference */
 	set_difference -= col_thickness ;
 	COLAMD_ASSERT (set_difference >= 0) ;
 	/* absorb this row if the set difference becomes zero */
 	if (set_difference == 0)
 	{
 	  COLAMD_DEBUG3 (("aggressive absorption. Row: %d\n", row)) ;
-	  KILL_ROW (row) ;
+	  Row[row].kill() ;
 	}
 	else
 	{
 	  /* save the new mark */
 	  Row [row].shared2.mark = set_difference + tag_mark ;
 	}
       }
@@ -1233,35 +1252,35 @@
     /* for each column in pivot row */
     rp = &A [pivot_row_start] ;
     rp_end = rp + pivot_row_length ;
     while (rp < rp_end)
     {
       /* get a column */
       col = *rp++ ;
-      COLAMD_ASSERT (COL_IS_ALIVE (col) && col != pivot_col) ;
+      COLAMD_ASSERT (Col[col].is_alive() && col != pivot_col) ;
       hash = 0 ;
       cur_score = 0 ;
       cp = &A [Col [col].start] ;
       /* compact the column */
       new_cp = cp ;
       cp_end = cp + Col [col].length ;
 
       COLAMD_DEBUG4 (("Adding set diffs for Col: %d.\n", col)) ;
 
       while (cp < cp_end)
       {
 	/* get a row */
 	row = *cp++ ;
 	COLAMD_ASSERT(row >= 0 && row < n_row) ;
-	row_mark = Row [row].shared2.mark ;
 	/* skip if dead */
-	if (ROW_IS_MARKED_DEAD (row_mark))
+	if (Row [row].is_dead())
 	{
 	  continue ;
 	}
+  row_mark = Row [row].shared2.mark ;
 	COLAMD_ASSERT (row_mark > tag_mark) ;
 	/* compact the column */
 	*new_cp++ = row ;
 	/* compute hash function */
 	hash += row ;
 	/* add set difference */
 	cur_score += row_mark - tag_mark ;
@@ -1274,15 +1293,15 @@
 
       /* === Further mass elimination ================================= */
 
       if (Col [col].length == 0)
       {
 	COLAMD_DEBUG4 (("further mass elimination. Col: %d\n", col)) ;
 	/* nothing left but the pivot row in this column */
-	KILL_PRINCIPAL_COL (col) ;
+	Col[col].kill_principal() ;
 	pivot_row_degree -= Col [col].shared1.thickness ;
 	COLAMD_ASSERT (pivot_row_degree >= 0) ;
 	/* order it */
 	Col [col].shared2.order = k ;
 	/* increment order count by column thickness */
 	k += Col [col].shared1.thickness ;
       }
@@ -1298,15 +1317,15 @@
 	/* add column to hash table, for supercolumn detection */
 	hash %= n_col + 1 ;
 
 	COLAMD_DEBUG4 ((" Hash = %d, n_col = %d.\n", hash, n_col)) ;
 	COLAMD_ASSERT (hash <= n_col) ;
 
 	head_column = head [hash] ;
-	if (head_column > COLAMD_EMPTY)
+	if (head_column > Empty)
 	{
 	  /* degree list "hash" is non-empty, use prev (shared3) of */
 	  /* first column in degree list as head of hash bucket */
 	  first_col = Col [head_column].shared3.headhash ;
 	  Col [head_column].shared3.headhash = col ;
 	}
 	else
@@ -1315,37 +1334,37 @@
 	  first_col = - (head_column + 2) ;
 	  head [hash] = - (col + 2) ;
 	}
 	Col [col].shared4.hash_next = first_col ;
 
 	/* save hash function in Col [col].shared3.hash */
 	Col [col].shared3.hash = (IndexType) hash ;
-	COLAMD_ASSERT (COL_IS_ALIVE (col)) ;
+	COLAMD_ASSERT (Col[col].is_alive()) ;
       }
     }
 
     /* The approximate external column degree is now computed.  */
 
     /* === Supercolumn detection ======================================== */
 
     COLAMD_DEBUG3 (("** Supercolumn detection phase. **\n")) ;
 
-    Eigen::internal::detect_super_cols (Col, A, head, pivot_row_start, pivot_row_length) ;
+    Colamd::detect_super_cols (Col, A, head, pivot_row_start, pivot_row_length) ;
 
     /* === Kill the pivotal column ====================================== */
 
-    KILL_PRINCIPAL_COL (pivot_col) ;
+    Col[pivot_col].kill_principal() ;
 
     /* === Clear mark =================================================== */
 
     tag_mark += (max_deg + 1) ;
     if (tag_mark >= max_mark)
     {
       COLAMD_DEBUG2 (("clearing tag_mark\n")) ;
-      tag_mark = Eigen::internal::clear_mark (n_row, Row) ;
+      tag_mark = Colamd::clear_mark (n_row, Row) ;
     }
 
     /* === Finalize the new pivot row, and column scores ================ */
 
     COLAMD_DEBUG3 (("** Finalize scores phase. **\n")) ;
 
     /* for each column in pivot row */
@@ -1353,15 +1372,15 @@
     /* compact the pivot row */
     new_rp = rp ;
     rp_end = rp + pivot_row_length ;
     while (rp < rp_end)
     {
       col = *rp++ ;
       /* skip dead columns */
-      if (COL_IS_DEAD (col))
+      if (Col[col].is_dead())
       {
 	continue ;
       }
       *new_rp++ = col ;
       /* add new pivot row to column */
       A [Col [col].start + (Col [col].length++)] = pivot_row ;
 
@@ -1387,19 +1406,19 @@
 
       /* === Place column back in degree list ========================= */
 
       COLAMD_ASSERT (min_score >= 0) ;
       COLAMD_ASSERT (min_score <= n_col) ;
       COLAMD_ASSERT (cur_score >= 0) ;
       COLAMD_ASSERT (cur_score <= n_col) ;
-      COLAMD_ASSERT (head [cur_score] >= COLAMD_EMPTY) ;
+      COLAMD_ASSERT (head [cur_score] >= Empty) ;
       next_col = head [cur_score] ;
       Col [col].shared4.degree_next = next_col ;
-      Col [col].shared3.prev = COLAMD_EMPTY ;
-      if (next_col != COLAMD_EMPTY)
+      Col [col].shared3.prev = Empty ;
+      if (next_col != Empty)
       {
 	Col [next_col].shared3.prev = col ;
       }
       head [cur_score] = col ;
 
       /* see if this score is less than current min */
       min_score = numext::mini(min_score, cur_score) ;
@@ -1444,15 +1463,15 @@
 */
 template <typename IndexType>
 static inline  void order_children
 (
   /* === Parameters ======================================================= */
 
   IndexType n_col,      /* number of columns of A */
-  colamd_col<IndexType> Col [],    /* of size n_col+1 */
+  ColStructure<IndexType> Col [],    /* of size n_col+1 */
   IndexType p []      /* p [0 ... n_col-1] is the column permutation*/
   )
 {
   /* === Local variables ================================================== */
 
   IndexType i ;     /* loop counter for all columns */
   IndexType c ;     /* column index */
@@ -1460,46 +1479,46 @@
   IndexType order ;     /* column's order */
 
   /* === Order each non-principal column ================================== */
 
   for (i = 0 ; i < n_col ; i++)
   {
     /* find an un-ordered non-principal column */
-    COLAMD_ASSERT (COL_IS_DEAD (i)) ;
-    if (!COL_IS_DEAD_PRINCIPAL (i) && Col [i].shared2.order == COLAMD_EMPTY)
+    COLAMD_ASSERT (col_is_dead(Col, i)) ;
+    if (!Col[i].is_dead_principal() && Col [i].shared2.order == Empty)
     {
       parent = i ;
       /* once found, find its principal parent */
       do
       {
 	parent = Col [parent].shared1.parent ;
-      } while (!COL_IS_DEAD_PRINCIPAL (parent)) ;
+      } while (!Col[parent].is_dead_principal()) ;
 
       /* now, order all un-ordered non-principal columns along path */
       /* to this parent.  collapse tree at the same time */
       c = i ;
       /* get order of parent */
       order = Col [parent].shared2.order ;
 
       do
       {
-	COLAMD_ASSERT (Col [c].shared2.order == COLAMD_EMPTY) ;
+	COLAMD_ASSERT (Col [c].shared2.order == Empty) ;
 
 	/* order this column */
 	Col [c].shared2.order = order++ ;
 	/* collaps tree */
 	Col [c].shared1.parent = parent ;
 
 	/* get immediate parent of this column */
 	c = Col [c].shared1.parent ;
 
 	/* continue until we hit an ordered column.  There are */
 	/* guaranteed not to be anymore unordered columns */
 	/* above an ordered column */
-      } while (Col [c].shared2.order == COLAMD_EMPTY) ;
+      } while (Col [c].shared2.order == Empty) ;
 
       /* re-order the super_col parent to largest order for this group */
       Col [parent].shared2.order = order ;
     }
   }
 
   /* === Generate the permutation ========================================= */
@@ -1543,16 +1562,16 @@
   just been computed in the approximate degree computation.
   Not user-callable.
 */
 template <typename IndexType>
 static void detect_super_cols
 (
   /* === Parameters ======================================================= */
-  
-  colamd_col<IndexType> Col [],    /* of size n_col+1 */
+
+  ColStructure<IndexType> Col [],    /* of size n_col+1 */
   IndexType A [],     /* row indices of A */
   IndexType head [],    /* head of degree lists and hash buckets */
   IndexType row_start,    /* pointer to set of columns to check */
   IndexType row_length    /* number of columns to check */
 )
 {
   /* === Local variables ================================================== */
@@ -1574,54 +1593,54 @@
   /* === Consider each column in the row ================================== */
 
   rp = &A [row_start] ;
   rp_end = rp + row_length ;
   while (rp < rp_end)
   {
     col = *rp++ ;
-    if (COL_IS_DEAD (col))
+    if (Col[col].is_dead())
     {
       continue ;
     }
 
     /* get hash number for this column */
     hash = Col [col].shared3.hash ;
     COLAMD_ASSERT (hash <= n_col) ;
 
     /* === Get the first column in this hash bucket ===================== */
 
     head_column = head [hash] ;
-    if (head_column > COLAMD_EMPTY)
+    if (head_column > Empty)
     {
       first_col = Col [head_column].shared3.headhash ;
     }
     else
     {
       first_col = - (head_column + 2) ;
     }
 
     /* === Consider each column in the hash bucket ====================== */
 
-    for (super_c = first_col ; super_c != COLAMD_EMPTY ;
+    for (super_c = first_col ; super_c != Empty ;
 	 super_c = Col [super_c].shared4.hash_next)
     {
-      COLAMD_ASSERT (COL_IS_ALIVE (super_c)) ;
+      COLAMD_ASSERT (Col [super_c].is_alive()) ;
       COLAMD_ASSERT (Col [super_c].shared3.hash == hash) ;
       length = Col [super_c].length ;
 
       /* prev_c is the column preceding column c in the hash bucket */
       prev_c = super_c ;
 
       /* === Compare super_c with all columns after it ================ */
 
       for (c = Col [super_c].shared4.hash_next ;
-	   c != COLAMD_EMPTY ; c = Col [c].shared4.hash_next)
+	   c != Empty ; c = Col [c].shared4.hash_next)
       {
 	COLAMD_ASSERT (c != super_c) ;
-	COLAMD_ASSERT (COL_IS_ALIVE (c)) ;
+	COLAMD_ASSERT (Col[c].is_alive()) ;
 	COLAMD_ASSERT (Col [c].shared3.hash == hash) ;
 
 	/* not identical if lengths or scores are different */
 	if (Col [c].length != length ||
 	    Col [c].shared2.score != Col [super_c].shared2.score)
 	{
 	  prev_c = c ;
@@ -1631,16 +1650,16 @@
 	/* compare the two columns */
 	cp1 = &A [Col [super_c].start] ;
 	cp2 = &A [Col [c].start] ;
 
 	for (i = 0 ; i < length ; i++)
 	{
 	  /* the columns are "clean" (no dead rows) */
-	  COLAMD_ASSERT (ROW_IS_ALIVE (*cp1))  ;
-	  COLAMD_ASSERT (ROW_IS_ALIVE (*cp2))  ;
+	  COLAMD_ASSERT ( cp1->is_alive() );
+	  COLAMD_ASSERT ( cp2->is_alive() );
 	  /* row indices will same order for both supercols, */
 	  /* no gather scatter necessary */
 	  if (*cp1++ != *cp2++)
 	  {
 	    break ;
 	  }
 	}
@@ -1654,33 +1673,33 @@
 
 	/* === Got it!  two columns are identical =================== */
 
 	COLAMD_ASSERT (Col [c].shared2.score == Col [super_c].shared2.score) ;
 
 	Col [super_c].shared1.thickness += Col [c].shared1.thickness ;
 	Col [c].shared1.parent = super_c ;
-	KILL_NON_PRINCIPAL_COL (c) ;
+	Col[c].kill_non_principal() ;
 	/* order c later, in order_children() */
-	Col [c].shared2.order = COLAMD_EMPTY ;
+	Col [c].shared2.order = Empty ;
 	/* remove c from hash bucket */
 	Col [prev_c].shared4.hash_next = Col [c].shared4.hash_next ;
       }
     }
 
     /* === Empty this hash bucket ======================================= */
 
-    if (head_column > COLAMD_EMPTY)
+    if (head_column > Empty)
     {
       /* corresponding degree list "hash" is not empty */
-      Col [head_column].shared3.headhash = COLAMD_EMPTY ;
+      Col [head_column].shared3.headhash = Empty ;
     }
     else
     {
       /* corresponding degree list "hash" is empty */
-      head [hash] = COLAMD_EMPTY ;
+      head [hash] = Empty ;
     }
   }
 }
 
 
 /* ========================================================================== */
 /* === garbage_collection =================================================== */
@@ -1694,19 +1713,19 @@
   itself linear in the number of nonzeros in the input matrix.
   Not user-callable.
 */
 template <typename IndexType>
 static IndexType garbage_collection  /* returns the new value of pfree */
   (
     /* === Parameters ======================================================= */
-    
+
     IndexType n_row,      /* number of rows */
     IndexType n_col,      /* number of columns */
-    Colamd_Row<IndexType> Row [],    /* row info */
-    colamd_col<IndexType> Col [],    /* column info */
+    RowStructure<IndexType> Row [],    /* row info */
+    ColStructure<IndexType> Col [],    /* column info */
     IndexType A [],     /* A [0 ... Alen-1] holds the matrix */
     IndexType *pfree      /* &A [0] ... pfree is in use */
     )
 {
   /* === Local variables ================================================== */
 
   IndexType *psrc ;     /* source pointer */
@@ -1717,54 +1736,54 @@
   IndexType length ;    /* length of a row or column */
 
   /* === Defragment the columns =========================================== */
 
   pdest = &A[0] ;
   for (c = 0 ; c < n_col ; c++)
   {
-    if (COL_IS_ALIVE (c))
+    if (Col[c].is_alive())
     {
       psrc = &A [Col [c].start] ;
 
       /* move and compact the column */
       COLAMD_ASSERT (pdest <= psrc) ;
       Col [c].start = (IndexType) (pdest - &A [0]) ;
       length = Col [c].length ;
       for (j = 0 ; j < length ; j++)
       {
 	r = *psrc++ ;
-	if (ROW_IS_ALIVE (r))
+	if (Row[r].is_alive())
 	{
 	  *pdest++ = r ;
 	}
       }
       Col [c].length = (IndexType) (pdest - &A [Col [c].start]) ;
     }
   }
 
   /* === Prepare to defragment the rows =================================== */
 
   for (r = 0 ; r < n_row ; r++)
   {
-    if (ROW_IS_ALIVE (r))
+    if (Row[r].is_alive())
     {
       if (Row [r].length == 0)
       {
-	/* this row is of zero length.  cannot compact it, so kill it */
-	COLAMD_DEBUG3 (("Defrag row kill\n")) ;
-	KILL_ROW (r) ;
+        /* this row is of zero length.  cannot compact it, so kill it */
+        COLAMD_DEBUG3 (("Defrag row kill\n")) ;
+        Row[r].kill() ;
       }
       else
       {
-	/* save first column index in Row [r].shared2.first_column */
-	psrc = &A [Row [r].start] ;
-	Row [r].shared2.first_column = *psrc ;
-	COLAMD_ASSERT (ROW_IS_ALIVE (r)) ;
-	/* flag the start of the row with the one's complement of row */
-	*psrc = ONES_COMPLEMENT (r) ;
+        /* save first column index in Row [r].shared2.first_column */
+        psrc = &A [Row [r].start] ;
+        Row [r].shared2.first_column = *psrc ;
+        COLAMD_ASSERT (Row[r].is_alive()) ;
+        /* flag the start of the row with the one's complement of row */
+        *psrc = ones_complement(r) ;
 
       }
     }
   }
 
   /* === Defragment the rows ============================================== */
 
@@ -1772,28 +1791,28 @@
   while (psrc < pfree)
   {
     /* find a negative number ... the start of a row */
     if (*psrc++ < 0)
     {
       psrc-- ;
       /* get the row index */
-      r = ONES_COMPLEMENT (*psrc) ;
+      r = ones_complement(*psrc) ;
       COLAMD_ASSERT (r >= 0 && r < n_row) ;
       /* restore first column index */
       *psrc = Row [r].shared2.first_column ;
-      COLAMD_ASSERT (ROW_IS_ALIVE (r)) ;
+      COLAMD_ASSERT (Row[r].is_alive()) ;
 
       /* move and compact the row */
       COLAMD_ASSERT (pdest <= psrc) ;
       Row [r].start = (IndexType) (pdest - &A [0]) ;
       length = Row [r].length ;
       for (j = 0 ; j < length ; j++)
       {
 	c = *psrc++ ;
-	if (COL_IS_ALIVE (c))
+	if (Col[c].is_alive())
 	{
 	  *pdest++ = c ;
 	}
       }
       Row [r].length = (IndexType) (pdest - &A [Row [r].start]) ;
 
     }
@@ -1817,27 +1836,28 @@
 */
 template <typename IndexType>
 static inline  IndexType clear_mark  /* return the new value for tag_mark */
   (
       /* === Parameters ======================================================= */
 
     IndexType n_row,    /* number of rows in A */
-    Colamd_Row<IndexType> Row [] /* Row [0 ... n_row-1].shared2.mark is set to zero */
+    RowStructure<IndexType> Row [] /* Row [0 ... n_row-1].shared2.mark is set to zero */
     )
 {
   /* === Local variables ================================================== */
 
   IndexType r ;
 
   for (r = 0 ; r < n_row ; r++)
   {
-    if (ROW_IS_ALIVE (r))
+    if (Row[r].is_alive())
     {
       Row [r].shared2.mark = 0 ;
     }
   }
   return (1) ;
 }
 
+} // namespace Colamd
 
-} // namespace internal 
+} // namespace internal
 #endif
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/OrderingMethods/Ordering.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/OrderingMethods/Ordering.h`

 * *Files 6% similar despite different names*

```diff
@@ -125,25 +125,25 @@
     {
       eigen_assert(mat.isCompressed() && "COLAMDOrdering requires a sparse matrix in compressed mode. Call .makeCompressed() before passing it to COLAMDOrdering");
       
       StorageIndex m = StorageIndex(mat.rows());
       StorageIndex n = StorageIndex(mat.cols());
       StorageIndex nnz = StorageIndex(mat.nonZeros());
       // Get the recommended value of Alen to be used by colamd
-      StorageIndex Alen = internal::colamd_recommended(nnz, m, n); 
+      StorageIndex Alen = internal::Colamd::recommended(nnz, m, n); 
       // Set the default parameters
-      double knobs [COLAMD_KNOBS]; 
-      StorageIndex stats [COLAMD_STATS];
-      internal::colamd_set_defaults(knobs);
+      double knobs [internal::Colamd::NKnobs]; 
+      StorageIndex stats [internal::Colamd::NStats];
+      internal::Colamd::set_defaults(knobs);
       
       IndexVector p(n+1), A(Alen); 
       for(StorageIndex i=0; i <= n; i++)   p(i) = mat.outerIndexPtr()[i];
       for(StorageIndex i=0; i < nnz; i++)  A(i) = mat.innerIndexPtr()[i];
       // Call Colamd routine to compute the ordering 
-      StorageIndex info = internal::colamd(m, n, Alen, A.data(), p.data(), knobs, stats); 
+      StorageIndex info = internal::Colamd::compute_ordering(m, n, Alen, A.data(), p.data(), knobs, stats); 
       EIGEN_UNUSED_VARIABLE(info);
       eigen_assert( info && "COLAMD failed " );
       
       perm.resize(n);
       for (StorageIndex i = 0; i < n; i++) perm.indices()(p(i)) = i;
     }
 };
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/PaStiXSupport/PaStiXSupport.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/PaStiXSupport/PaStiXSupport.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/PardisoSupport/PardisoSupport.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/PardisoSupport/PardisoSupport.h`

 * *Files 0% similar despite different names*

```diff
@@ -382,22 +382,23 @@
   * \sa \ref TutorialSparseSolverConcept, class SparseLU
   */
 template<typename MatrixType>
 class PardisoLU : public PardisoImpl< PardisoLU<MatrixType> >
 {
   protected:
     typedef PardisoImpl<PardisoLU> Base;
-    typedef typename Base::Scalar Scalar;
-    typedef typename Base::RealScalar RealScalar;
     using Base::pardisoInit;
     using Base::m_matrix;
     friend class PardisoImpl< PardisoLU<MatrixType> >;
 
   public:
 
+    typedef typename Base::Scalar Scalar;
+    typedef typename Base::RealScalar RealScalar;
+
     using Base::compute;
     using Base::solve;
 
     PardisoLU()
       : Base()
     {
       pardisoInit(Base::ScalarIsComplex ? 13 : 11);
@@ -437,22 +438,22 @@
   * \sa \ref TutorialSparseSolverConcept, class SimplicialLLT
   */
 template<typename MatrixType, int _UpLo>
 class PardisoLLT : public PardisoImpl< PardisoLLT<MatrixType,_UpLo> >
 {
   protected:
     typedef PardisoImpl< PardisoLLT<MatrixType,_UpLo> > Base;
-    typedef typename Base::Scalar Scalar;
-    typedef typename Base::RealScalar RealScalar;
     using Base::pardisoInit;
     using Base::m_matrix;
     friend class PardisoImpl< PardisoLLT<MatrixType,_UpLo> >;
 
   public:
 
+    typedef typename Base::Scalar Scalar;
+    typedef typename Base::RealScalar RealScalar;
     typedef typename Base::StorageIndex StorageIndex;
     enum { UpLo = _UpLo };
     using Base::compute;
 
     PardisoLLT()
       : Base()
     {
@@ -500,22 +501,22 @@
   * \sa \ref TutorialSparseSolverConcept, class SimplicialLDLT
   */
 template<typename MatrixType, int Options>
 class PardisoLDLT : public PardisoImpl< PardisoLDLT<MatrixType,Options> >
 {
   protected:
     typedef PardisoImpl< PardisoLDLT<MatrixType,Options> > Base;
-    typedef typename Base::Scalar Scalar;
-    typedef typename Base::RealScalar RealScalar;
     using Base::pardisoInit;
     using Base::m_matrix;
     friend class PardisoImpl< PardisoLDLT<MatrixType,Options> >;
 
   public:
 
+    typedef typename Base::Scalar Scalar;
+    typedef typename Base::RealScalar RealScalar;
     typedef typename Base::StorageIndex StorageIndex;
     using Base::compute;
     enum { UpLo = Options&(Upper|Lower) };
 
     PardisoLDLT()
       : Base()
     {
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/QR/ColPivHouseholderQR.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/QR/ColPivHouseholderQR.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/QR/ColPivHouseholderQR_LAPACKE.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/QR/ColPivHouseholderQR_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/QR/CompleteOrthogonalDecomposition.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/QR/CompleteOrthogonalDecomposition.h`

 * *Files 2% similar despite different names*

```diff
@@ -588,22 +588,30 @@
 
   dst.applyOnTheLeft(householderQ().setLength(rank).template conjugateIf<!Conjugate>() );
 }
 #endif
 
 namespace internal {
 
+template<typename MatrixType>
+struct traits<Inverse<CompleteOrthogonalDecomposition<MatrixType> > >
+  : traits<typename Transpose<typename MatrixType::PlainObject>::PlainObject>
+{
+  enum { Flags = 0 };
+};
+
 template<typename DstXprType, typename MatrixType>
 struct Assignment<DstXprType, Inverse<CompleteOrthogonalDecomposition<MatrixType> >, internal::assign_op<typename DstXprType::Scalar,typename CompleteOrthogonalDecomposition<MatrixType>::Scalar>, Dense2Dense>
 {
   typedef CompleteOrthogonalDecomposition<MatrixType> CodType;
   typedef Inverse<CodType> SrcXprType;
   static void run(DstXprType &dst, const SrcXprType &src, const internal::assign_op<typename DstXprType::Scalar,typename CodType::Scalar> &)
   {
-    dst = src.nestedExpression().solve(MatrixType::Identity(src.rows(), src.rows()));
+    typedef Matrix<typename CodType::Scalar, CodType::RowsAtCompileTime, CodType::RowsAtCompileTime, 0, CodType::MaxRowsAtCompileTime, CodType::MaxRowsAtCompileTime> IdentityMatrixType;
+    dst = src.nestedExpression().solve(IdentityMatrixType::Identity(src.cols(), src.cols()));
   }
 };
 
 } // end namespace internal
 
 /** \returns the matrix Q as a sequence of householder transformations */
 template <typename MatrixType>
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/QR/FullPivHouseholderQR.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/QR/FullPivHouseholderQR.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/QR/HouseholderQR.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/QR/HouseholderQR.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/QR/HouseholderQR_LAPACKE.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/QR/HouseholderQR_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SPQRSupport/SuiteSparseQRSupport.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SPQRSupport/SuiteSparseQRSupport.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SVD/BDCSVD.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SVD/BDCSVD.h`

 * *Files 2% similar despite different names*

```diff
@@ -23,14 +23,18 @@
 // #define EIGEN_BDCSVD_SANITY_CHECKS
 
 #ifdef EIGEN_BDCSVD_SANITY_CHECKS
 #undef eigen_internal_assert
 #define eigen_internal_assert(X) assert(X);
 #endif
 
+#ifdef EIGEN_BDCSVD_DEBUG_VERBOSE
+#include <iostream>
+#endif
+
 namespace Eigen {
 
 #ifdef EIGEN_BDCSVD_DEBUG_VERBOSE
 IOFormat bdcsvdfmt(8, 0, ", ", "\n", "  [", "]");
 #endif
   
 template<typename _MatrixType> class BDCSVD;
@@ -168,15 +172,15 @@
   BDCSVD& compute(const MatrixType& matrix)
   {
     return compute(matrix, this->m_computationOptions);
   }
 
   void setSwitchSize(int s) 
   {
-    eigen_assert(s>3 && "BDCSVD the size of the algo switch has to be greater than 3");
+    eigen_assert(s>=3 && "BDCSVD the size of the algo switch has to be at least 3.");
     m_algoswap = s;
   }
  
 private:
   void allocate(Index rows, Index cols, unsigned int computationOptions);
   void divide(Index firstCol, Index lastCol, Index firstRowW, Index firstColW, Index shift);
   void computeSVDofM(Index firstCol, Index n, MatrixXr& U, VectorType& singVals, MatrixXr& V);
@@ -204,14 +208,15 @@
   using Base::m_diagSize;
   using Base::m_computeFullU;
   using Base::m_computeFullV;
   using Base::m_computeThinU;
   using Base::m_computeThinV;
   using Base::m_matrixU;
   using Base::m_matrixV;
+  using Base::m_info;
   using Base::m_isInitialized;
   using Base::m_nonzeroSingularValues;
 
 public:  
   int m_numIters;
 }; //end class BDCSVD
 
@@ -252,24 +257,33 @@
   const RealScalar considerZero = (std::numeric_limits<RealScalar>::min)();
   
   //**** step -1 - If the problem is too small, directly falls back to JacobiSVD and return
   if(matrix.cols() < m_algoswap)
   {
     // FIXME this line involves temporaries
     JacobiSVD<MatrixType> jsvd(matrix,computationOptions);
-    if(computeU()) m_matrixU = jsvd.matrixU();
-    if(computeV()) m_matrixV = jsvd.matrixV();
-    m_singularValues = jsvd.singularValues();
-    m_nonzeroSingularValues = jsvd.nonzeroSingularValues();
     m_isInitialized = true;
+    m_info = jsvd.info();
+    if (m_info == Success || m_info == NoConvergence) {
+      if(computeU()) m_matrixU = jsvd.matrixU();
+      if(computeV()) m_matrixV = jsvd.matrixV();
+      m_singularValues = jsvd.singularValues();
+      m_nonzeroSingularValues = jsvd.nonzeroSingularValues();
+    }
     return *this;
   }
   
   //**** step 0 - Copy the input matrix and apply scaling to reduce over/under-flows
-  RealScalar scale = matrix.cwiseAbs().maxCoeff();
+  RealScalar scale = matrix.cwiseAbs().template maxCoeff<PropagateNaN>();
+  if (!(numext::isfinite)(scale)) {
+    m_isInitialized = true;
+    m_info = InvalidInput;
+    return *this;
+  }
+
   if(scale==Literal(0)) scale = Literal(1);
   MatrixX copy;
   if (m_isTranspose) copy = matrix.adjoint()/scale;
   else               copy = matrix/scale;
   
   //**** step 1 - Bidiagonalization
   // FIXME this line involves temporaries
@@ -278,15 +292,19 @@
   //**** step 2 - Divide & Conquer
   m_naiveU.setZero();
   m_naiveV.setZero();
   // FIXME this line involves a temporary matrix
   m_computed.topRows(m_diagSize) = bid.bidiagonal().toDenseMatrix().transpose();
   m_computed.template bottomRows<1>().setZero();
   divide(0, m_diagSize - 1, 0, 0, 0);
-
+  if (m_info != Success && m_info != NoConvergence) {
+    m_isInitialized = true;
+    return *this;
+  }
+    
   //**** step 3 - Copy singular values and vectors
   for (int i=0; i<m_diagSize; i++)
   {
     RealScalar a = abs(m_computed.coeff(i, i));
     m_singularValues.coeffRef(i) = a * scale;
     if (a<considerZero)
     {
@@ -386,19 +404,19 @@
 // The divide algorithm is done "in place", we are always working on subsets of the same matrix. The divide methods takes as argument the 
 // place of the submatrix we are currently working on.
 
 //@param firstCol : The Index of the first column of the submatrix of m_computed and for m_naiveU;
 //@param lastCol : The Index of the last column of the submatrix of m_computed and for m_naiveU; 
 // lastCol + 1 - firstCol is the size of the submatrix.
 //@param firstRowW : The Index of the first row of the matrix W that we are to change. (see the reference paper section 1 for more information on W)
-//@param firstRowW : Same as firstRowW with the column.
+//@param firstColW : Same as firstRowW with the column.
 //@param shift : Each time one takes the left submatrix, one must add 1 to the shift. Why? Because! We actually want the last column of the U submatrix 
 // to become the first column (*coeff) and to shift all the other columns to the right. There are more details on the reference paper.
 template<typename MatrixType>
-void BDCSVD<MatrixType>::divide (Eigen::Index firstCol, Eigen::Index lastCol, Eigen::Index firstRowW, Eigen::Index firstColW, Eigen::Index shift)
+void BDCSVD<MatrixType>::divide(Eigen::Index firstCol, Eigen::Index lastCol, Eigen::Index firstRowW, Eigen::Index firstColW, Eigen::Index shift)
 {
   // requires rows = cols + 1;
   using std::pow;
   using std::sqrt;
   using std::abs;
   const Index n = lastCol - firstCol + 1;
   const Index k = n/2;
@@ -410,14 +428,16 @@
   VectorType l, f;
   // We use the other algorithm which is more efficient for small 
   // matrices.
   if (n < m_algoswap)
   {
     // FIXME this line involves temporaries
     JacobiSVD<MatrixXr> b(m_computed.block(firstCol, firstCol, n + 1, n), ComputeFullU | (m_compV ? ComputeFullV : 0));
+    m_info = b.info();
+    if (m_info != Success && m_info != NoConvergence) return;
     if (m_compU)
       m_naiveU.block(firstCol, firstCol, n + 1, n + 1).real() = b.matrixU();
     else 
     {
       m_naiveU.row(0).segment(firstCol, n + 1).real() = b.matrixU().row(0);
       m_naiveU.row(1).segment(firstCol, n + 1).real() = b.matrixU().row(n);
     }
@@ -429,15 +449,17 @@
   // We use the divide and conquer algorithm
   alphaK =  m_computed(firstCol + k, firstCol + k);
   betaK = m_computed(firstCol + k + 1, firstCol + k);
   // The divide must be done in that order in order to have good results. Divide change the data inside the submatrices
   // and the divide of the right submatrice reads one column of the left submatrice. That's why we need to treat the 
   // right submatrix before the left one. 
   divide(k + 1 + firstCol, lastCol, k + 1 + firstRowW, k + 1 + firstColW, shift);
+  if (m_info != Success && m_info != NoConvergence) return;
   divide(firstCol, k - 1 + firstCol, firstRowW, firstColW + 1, shift + 1);
+  if (m_info != Success && m_info != NoConvergence) return;
 
   if (m_compU)
   {
     lambda = m_naiveU(firstCol + k, firstCol + k);
     phi = m_naiveU(firstCol + k + 1, lastCol + 1);
   } 
   else 
@@ -877,15 +899,15 @@
         else
           rightShifted = -(std::numeric_limits<RealScalar>::min)();
       }
 
       RealScalar fLeft = secularEq(leftShifted, col0, diag, perm, diagShifted, shift);
       eigen_internal_assert(fLeft<Literal(0));
 
-#if defined EIGEN_INTERNAL_DEBUGGING || defined EIGEN_BDCSVD_SANITY_CHECKS
+#if defined EIGEN_BDCSVD_DEBUG_VERBOSE || defined EIGEN_BDCSVD_SANITY_CHECKS || defined EIGEN_INTERNAL_DEBUGGING
       RealScalar fRight = secularEq(rightShifted, col0, diag, perm, diagShifted, shift);
 #endif
 
 #ifdef EIGEN_BDCSVD_SANITY_CHECKS
       if(!(numext::isfinite)(fLeft))
         std::cout << "f(" << leftShifted << ") =" << fLeft << " ; " << left << " " << shift << " " << right << "\n";
       assert((numext::isfinite)(fLeft));
@@ -952,16 +974,16 @@
     assert(k==0 || singVals[k]>=singVals[k-1]);
     assert(singVals[k]>=diag(k));
 #endif
 
     // perturb singular value slightly if it equals diagonal entry to avoid division by zero later
     // (deflation is supposed to avoid this from happening)
     // - this does no seem to be necessary anymore -
-//     if (singVals[k] == left) singVals[k] *= 1 + NumTraits<RealScalar>::epsilon();
-//     if (singVals[k] == right) singVals[k] *= 1 - NumTraits<RealScalar>::epsilon();
+    // if (singVals[k] == left) singVals[k] *= 1 + NumTraits<RealScalar>::epsilon();
+    // if (singVals[k] == right) singVals[k] *= 1 - NumTraits<RealScalar>::epsilon();
   }
 }
 
 
 // zhat is perturbation of col0 for which singular vectors can be computed stably (see Section 3.1)
 template <typename MatrixType>
 void BDCSVD<MatrixType>::perturbCol0
@@ -1007,15 +1029,22 @@
             std::cout << "Error in perturbCol0\n";
             std::cout << "  " << k << "/" << n << " "  << l << "/" << m << " " << i << "/" << n << " ; " << col0(k) << " " << diag(k) << " "  <<  "\n";
             std::cout << "  " <<diag(i) << "\n";
             Index j = (i<k /*|| l==0*/) ? i : perm(l-1);
             std::cout << "  " << "j=" << j << "\n";
           }
 #endif
-          Index j = i<k ? i : perm(l-1);
+          // Avoid index out of bounds.
+          // Will end up setting zhat(k) = 0.
+          if (l == 0) {
+            m_info = NumericalIssue;
+            prod = 0;
+            break;
+          }
+          Index j = i<k ? i : l > 0 ? perm(l-1) : i;
 #ifdef EIGEN_BDCSVD_SANITY_CHECKS
           if(!(dk!=Literal(0) || diag(i)!=Literal(0)))
           {
             std::cout << "k=" << k << ", i=" << i << ", l=" << l << ", perm.size()=" << perm.size() << "\n";
           }
           assert(dk!=Literal(0) || diag(i)!=Literal(0));
 #endif
@@ -1220,16 +1249,16 @@
 #endif
 #ifdef EIGEN_BDCSVD_DEBUG_VERBOSE
   std::cout << "to be sorted: " << diag.transpose() << "\n\n";
   std::cout << "            : " << col0.transpose() << "\n\n";
 #endif
   {
     // Check for total deflation
-    // If we have a total deflation, then we have to consider col0(0)==diag(0) as a singular value during sorting
-    bool total_deflation = (col0.tail(length-1).array()<considerZero).all();
+    // If we have a total deflation, then we have to consider col0(0)==diag(0) as a singular value during sorting.
+    const bool total_deflation = (col0.tail(length-1).array().abs()<considerZero).all();
     
     // Sort the diagonal entries, since diag(1:k-1) and diag(k:length) are already sorted, let's do a sorted merge.
     // First, compute the respective permutation.
     Index *permutation = m_workspaceI.data();
     {
       permutation[0] = 0;
       Index p = 1;
@@ -1326,25 +1355,23 @@
 #ifdef EIGEN_BDCSVD_SANITY_CHECKS
   assert(m_naiveU.allFinite());
   assert(m_naiveV.allFinite());
   assert(m_computed.allFinite());
 #endif
 }//end deflation
 
-#if !defined(EIGEN_GPUCC)
 /** \svd_module
   *
   * \return the singular value decomposition of \c *this computed by Divide & Conquer algorithm
   *
   * \sa class BDCSVD
   */
 template<typename Derived>
 BDCSVD<typename MatrixBase<Derived>::PlainObject>
 MatrixBase<Derived>::bdcSvd(unsigned int computationOptions) const
 {
   return BDCSVD<PlainObject>(*this, computationOptions);
 }
-#endif
 
 } // end namespace Eigen
 
 #endif
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SVD/JacobiSVD.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SVD/JacobiSVD.h`

 * *Files 2% similar despite different names*

```diff
@@ -108,20 +108,20 @@
   typedef typename MatrixType::Scalar Scalar;
   enum
   {
     RowsAtCompileTime = MatrixType::RowsAtCompileTime,
     ColsAtCompileTime = MatrixType::ColsAtCompileTime,
     MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
     MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
-    TrOptions = RowsAtCompileTime==1 ? (MatrixType::Options & ~(RowMajor))
-              : ColsAtCompileTime==1 ? (MatrixType::Options |   RowMajor)
-              : MatrixType::Options
+    Options = MatrixType::Options
   };
-  typedef Matrix<Scalar, ColsAtCompileTime, RowsAtCompileTime, TrOptions, MaxColsAtCompileTime, MaxRowsAtCompileTime>
-          TransposeTypeWithSameStorageOrder;
+
+  typedef typename internal::make_proper_matrix_type<
+    Scalar, ColsAtCompileTime, RowsAtCompileTime, Options, MaxColsAtCompileTime, MaxRowsAtCompileTime
+  >::type TransposeTypeWithSameStorageOrder;
 
   void allocate(const JacobiSVD<MatrixType, FullPivHouseholderQRPreconditioner>& svd)
   {
     if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols())
     {
       m_qr.~QRType();
       ::new (&m_qr) QRType(svd.cols(), svd.rows());
@@ -198,21 +198,20 @@
   typedef typename MatrixType::Scalar Scalar;
   enum
   {
     RowsAtCompileTime = MatrixType::RowsAtCompileTime,
     ColsAtCompileTime = MatrixType::ColsAtCompileTime,
     MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
     MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
-    TrOptions = RowsAtCompileTime==1 ? (MatrixType::Options & ~(RowMajor))
-              : ColsAtCompileTime==1 ? (MatrixType::Options |   RowMajor)
-              : MatrixType::Options
+    Options = MatrixType::Options
   };
 
-  typedef Matrix<Scalar, ColsAtCompileTime, RowsAtCompileTime, TrOptions, MaxColsAtCompileTime, MaxRowsAtCompileTime>
-          TransposeTypeWithSameStorageOrder;
+  typedef typename internal::make_proper_matrix_type<
+    Scalar, ColsAtCompileTime, RowsAtCompileTime, Options, MaxColsAtCompileTime, MaxRowsAtCompileTime
+  >::type TransposeTypeWithSameStorageOrder;
 
   void allocate(const JacobiSVD<MatrixType, ColPivHouseholderQRPreconditioner>& svd)
   {
     if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols())
     {
       m_qr.~QRType();
       ::new (&m_qr) QRType(svd.cols(), svd.rows());
@@ -299,16 +298,17 @@
     RowsAtCompileTime = MatrixType::RowsAtCompileTime,
     ColsAtCompileTime = MatrixType::ColsAtCompileTime,
     MaxRowsAtCompileTime = MatrixType::MaxRowsAtCompileTime,
     MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime,
     Options = MatrixType::Options
   };
 
-  typedef Matrix<Scalar, ColsAtCompileTime, RowsAtCompileTime, Options, MaxColsAtCompileTime, MaxRowsAtCompileTime>
-          TransposeTypeWithSameStorageOrder;
+  typedef typename internal::make_proper_matrix_type<
+    Scalar, ColsAtCompileTime, RowsAtCompileTime, Options, MaxColsAtCompileTime, MaxRowsAtCompileTime
+  >::type TransposeTypeWithSameStorageOrder;
 
   void allocate(const JacobiSVD<MatrixType, HouseholderQRPreconditioner>& svd)
   {
     if (svd.cols() != m_qr.rows() || svd.rows() != m_qr.cols())
     {
       m_qr.~QRType();
       ::new (&m_qr) QRType(svd.cols(), svd.rows());
@@ -581,14 +581,15 @@
   private:
     void allocate(Index rows, Index cols, unsigned int computationOptions);
 
   protected:
     using Base::m_matrixU;
     using Base::m_matrixV;
     using Base::m_singularValues;
+    using Base::m_info;
     using Base::m_isInitialized;
     using Base::m_isAllocated;
     using Base::m_usePrescribedThreshold;
     using Base::m_computeFullU;
     using Base::m_computeThinU;
     using Base::m_computeFullV;
     using Base::m_computeThinV;
@@ -621,14 +622,15 @@
       computationOptions == m_computationOptions)
   {
     return;
   }
 
   m_rows = rows;
   m_cols = cols;
+  m_info = Success;
   m_isInitialized = false;
   m_isAllocated = true;
   m_computationOptions = computationOptions;
   m_computeFullU = (computationOptions & ComputeFullU) != 0;
   m_computeThinU = (computationOptions & ComputeThinU) != 0;
   m_computeFullV = (computationOptions & ComputeFullV) != 0;
   m_computeThinV = (computationOptions & ComputeThinV) != 0;
@@ -670,15 +672,20 @@
   // only worsening the precision of U and V as we accumulate more rotations
   const RealScalar precision = RealScalar(2) * NumTraits<Scalar>::epsilon();
 
   // limit for denormal numbers to be considered zero in order to avoid infinite loops (see bug 286)
   const RealScalar considerAsZero = (std::numeric_limits<RealScalar>::min)();
 
   // Scaling factor to reduce over/under-flows
-  RealScalar scale = matrix.cwiseAbs().maxCoeff();
+  RealScalar scale = matrix.cwiseAbs().template maxCoeff<PropagateNaN>();
+  if (!(numext::isfinite)(scale)) {
+    m_isInitialized = true;
+    m_info = InvalidInput;
+    return *this;
+  }
   if(scale==RealScalar(0)) scale = RealScalar(1);
   
   /*** step 1. The R-SVD step: we use a QR decomposition to reduce to the case of a square matrix */
 
   if(m_rows!=m_cols)
   {
     m_scaledMatrix = matrix / scale;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SVD/JacobiSVD_LAPACKE.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SVD/JacobiSVD_LAPACKE.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SVD/SVDBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SVD/SVDBase.h`

 * *Files 13% similar despite different names*

```diff
@@ -47,16 +47,19 @@
  * Singular values are always sorted in decreasing order.
  *
  * 
  * You can ask for only \em thin \a U or \a V to be computed, meaning the following. In case of a rectangular n-by-p matrix, letting \a m be the
  * smaller value among \a n and \a p, there are only \a m singular vectors; the remaining columns of \a U and \a V do not correspond to actual
  * singular vectors. Asking for \em thin \a U or \a V means asking for only their \a m first columns to be formed. So \a U is then a n-by-m matrix,
  * and \a V is then a p-by-m matrix. Notice that thin \a U and \a V are all you need for (least squares) solving.
+ * 
+ * The status of the computation can be retrived using the \a info() method. Unless \a info() returns \a Success, the results should be not
+ * considered well defined.
  *  
- * If the input matrix has inf or nan coefficients, the result of the computation is undefined, but the computation is guaranteed to
+ * If the input matrix has inf or nan coefficients, the result of the computation is undefined, and \a info() will return \a InvalidInput, but the computation is guaranteed to
  * terminate in finite (and reasonable) time.
  * \sa class BDCSVD, class JacobiSVD
  */
 template<typename Derived> class SVDBase
  : public SolverBase<SVDBase<Derived> >
 {
 public: 
@@ -93,15 +96,15 @@
    *
    * The \a m first columns of \a U are the left singular vectors of the matrix being decomposed.
    *
    * This method asserts that you asked for \a U to be computed.
    */
   const MatrixUType& matrixU() const
   {
-    eigen_assert(m_isInitialized && "SVD is not initialized.");
+    _check_compute_assertions();
     eigen_assert(computeU() && "This SVD decomposition didn't compute U. Did you ask for it?");
     return m_matrixU;
   }
 
   /** \returns the \a V matrix.
    *
    * For the SVD decomposition of a n-by-p matrix, letting \a m be the minimum of \a n and \a p,
@@ -109,47 +112,47 @@
    *
    * The \a m first columns of \a V are the right singular vectors of the matrix being decomposed.
    *
    * This method asserts that you asked for \a V to be computed.
    */
   const MatrixVType& matrixV() const
   {
-    eigen_assert(m_isInitialized && "SVD is not initialized.");
+    _check_compute_assertions();
     eigen_assert(computeV() && "This SVD decomposition didn't compute V. Did you ask for it?");
     return m_matrixV;
   }
 
   /** \returns the vector of singular values.
    *
    * For the SVD decomposition of a n-by-p matrix, letting \a m be the minimum of \a n and \a p, the
    * returned vector has size \a m.  Singular values are always sorted in decreasing order.
    */
   const SingularValuesType& singularValues() const
   {
-    eigen_assert(m_isInitialized && "SVD is not initialized.");
+    _check_compute_assertions();
     return m_singularValues;
   }
 
   /** \returns the number of singular values that are not exactly 0 */
   Index nonzeroSingularValues() const
   {
-    eigen_assert(m_isInitialized && "SVD is not initialized.");
+    _check_compute_assertions();
     return m_nonzeroSingularValues;
   }
   
   /** \returns the rank of the matrix of which \c *this is the SVD.
     *
     * \note This method has to determine which singular values should be considered nonzero.
     *       For that, it uses the threshold value that you can control by calling
     *       setThreshold(const RealScalar&).
     */
   inline Index rank() const
   {
     using std::abs;
-    eigen_assert(m_isInitialized && "JacobiSVD is not initialized.");
+    _check_compute_assertions();
     if(m_singularValues.size()==0) return 0;
     RealScalar premultiplied_threshold = numext::maxi<RealScalar>(m_singularValues.coeff(0) * threshold(), (std::numeric_limits<RealScalar>::min)());
     Index i = m_nonzeroSingularValues-1;
     while(i>=0 && m_singularValues.coeff(i) < premultiplied_threshold) --i;
     return i+1;
   }
   
@@ -220,56 +223,74 @@
     * In other words, the returned solution is guaranteed to minimize the Euclidean norm \f$ \Vert A x - b \Vert \f$.
     */
   template<typename Rhs>
   inline const Solve<Derived, Rhs>
   solve(const MatrixBase<Rhs>& b) const;
   #endif
 
+
+  /** \brief Reports whether previous computation was successful.
+   *
+   * \returns \c Success if computation was successful.
+   */
+  EIGEN_DEVICE_FUNC
+  ComputationInfo info() const
+  {
+    eigen_assert(m_isInitialized && "SVD is not initialized.");
+    return m_info;
+  }
+
   #ifndef EIGEN_PARSED_BY_DOXYGEN
   template<typename RhsType, typename DstType>
   void _solve_impl(const RhsType &rhs, DstType &dst) const;
 
   template<bool Conjugate, typename RhsType, typename DstType>
   void _solve_impl_transposed(const RhsType &rhs, DstType &dst) const;
   #endif
 
 protected:
-  
+
   static void check_template_parameters()
   {
     EIGEN_STATIC_ASSERT_NON_INTEGER(Scalar);
   }
 
+  void _check_compute_assertions() const {
+    eigen_assert(m_isInitialized && "SVD is not initialized.");
+  }
+
   template<bool Transpose_, typename Rhs>
   void _check_solve_assertion(const Rhs& b) const {
       EIGEN_ONLY_USED_FOR_DEBUG(b);
-      eigen_assert(m_isInitialized && "SVD is not initialized.");
+      _check_compute_assertions();
       eigen_assert(computeU() && computeV() && "SVDBase::solve(): Both unitaries U and V are required to be computed (thin unitaries suffice).");
       eigen_assert((Transpose_?cols():rows())==b.rows() && "SVDBase::solve(): invalid number of rows of the right hand side matrix b");
   }
-  
+
   // return true if already allocated
   bool allocate(Index rows, Index cols, unsigned int computationOptions) ;
 
   MatrixUType m_matrixU;
   MatrixVType m_matrixV;
   SingularValuesType m_singularValues;
+  ComputationInfo m_info;
   bool m_isInitialized, m_isAllocated, m_usePrescribedThreshold;
   bool m_computeFullU, m_computeThinU;
   bool m_computeFullV, m_computeThinV;
   unsigned int m_computationOptions;
   Index m_nonzeroSingularValues, m_rows, m_cols, m_diagSize;
   RealScalar m_prescribedThreshold;
 
   /** \brief Default Constructor.
    *
    * Default constructor of SVDBase
    */
   SVDBase()
-    : m_isInitialized(false),
+    : m_info(Success),
+      m_isInitialized(false),
       m_isAllocated(false),
       m_usePrescribedThreshold(false),
       m_computeFullU(false),
       m_computeThinU(false),
       m_computeFullV(false),
       m_computeThinV(false),
       m_computationOptions(0),
@@ -323,14 +344,15 @@
       computationOptions == m_computationOptions)
   {
     return true;
   }
 
   m_rows = rows;
   m_cols = cols;
+  m_info = Success;
   m_isInitialized = false;
   m_isAllocated = true;
   m_computationOptions = computationOptions;
   m_computeFullU = (computationOptions & ComputeFullU) != 0;
   m_computeThinU = (computationOptions & ComputeThinU) != 0;
   m_computeFullV = (computationOptions & ComputeFullV) != 0;
   m_computeThinV = (computationOptions & ComputeThinV) != 0;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SVD/UpperBidiagonalization.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SVD/UpperBidiagonalization.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCholesky/SimplicialCholesky.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCholesky/SimplicialCholesky.h`

 * *Files 2% similar despite different names*

```diff
@@ -214,15 +214,15 @@
     void factorize(const MatrixType& a)
     {
       eigen_assert(a.rows()==a.cols());
       Index size = a.cols();
       CholMatrixType tmp(size,size);
       ConstCholMatrixPtr pmat;
       
-      if(m_P.size()==0 && (UpLo&Upper)==Upper)
+      if(m_P.size() == 0 && (int(UpLo) & int(Upper)) == Upper)
       {
         // If there is no ordering, try to directly use the input matrix without any copy
         internal::simplicial_cholesky_grab_input<CholMatrixType,MatrixType>::run(a, pmat, tmp);
       }
       else
       {
         tmp.template selfadjointView<Upper>() = a.template selfadjointView<UpLo>().twistedBy(m_P);
@@ -283,30 +283,30 @@
   typedef _Ordering OrderingType;
   enum { UpLo = _UpLo };
   typedef typename MatrixType::Scalar                         Scalar;
   typedef typename MatrixType::StorageIndex                   StorageIndex;
   typedef SparseMatrix<Scalar, ColMajor, StorageIndex>        CholMatrixType;
   typedef TriangularView<const CholMatrixType, Eigen::Lower>  MatrixL;
   typedef TriangularView<const typename CholMatrixType::AdjointReturnType, Eigen::Upper>   MatrixU;
-  static inline MatrixL getL(const MatrixType& m) { return MatrixL(m); }
-  static inline MatrixU getU(const MatrixType& m) { return MatrixU(m.adjoint()); }
+  static inline MatrixL getL(const CholMatrixType& m) { return MatrixL(m); }
+  static inline MatrixU getU(const CholMatrixType& m) { return MatrixU(m.adjoint()); }
 };
 
 template<typename _MatrixType,int _UpLo, typename _Ordering> struct traits<SimplicialLDLT<_MatrixType,_UpLo,_Ordering> >
 {
   typedef _MatrixType MatrixType;
   typedef _Ordering OrderingType;
   enum { UpLo = _UpLo };
   typedef typename MatrixType::Scalar                             Scalar;
   typedef typename MatrixType::StorageIndex                       StorageIndex;
   typedef SparseMatrix<Scalar, ColMajor, StorageIndex>            CholMatrixType;
   typedef TriangularView<const CholMatrixType, Eigen::UnitLower>  MatrixL;
   typedef TriangularView<const typename CholMatrixType::AdjointReturnType, Eigen::UnitUpper> MatrixU;
-  static inline MatrixL getL(const MatrixType& m) { return MatrixL(m); }
-  static inline MatrixU getU(const MatrixType& m) { return MatrixU(m.adjoint()); }
+  static inline MatrixL getL(const CholMatrixType& m) { return MatrixL(m); }
+  static inline MatrixU getU(const CholMatrixType& m) { return MatrixU(m.adjoint()); }
 };
 
 template<typename _MatrixType, int _UpLo, typename _Ordering> struct traits<SimplicialCholesky<_MatrixType,_UpLo,_Ordering> >
 {
   typedef _MatrixType MatrixType;
   typedef _Ordering OrderingType;
   enum { UpLo = _UpLo };
@@ -612,15 +612,15 @@
         if(m_LDLT)
           LDLTTraits::getL(Base::m_matrix).solveInPlace(dest);
         else
           LLTTraits::getL(Base::m_matrix).solveInPlace(dest);
       }
 
       if(Base::m_diag.size()>0)
-        dest = Base::m_diag.asDiagonal().inverse() * dest;
+        dest = Base::m_diag.real().asDiagonal().inverse() * dest;
 
       if (Base::m_matrix.nonZeros()>0) // otherwise I==I
       {
         if(m_LDLT)
           LDLTTraits::getU(Base::m_matrix).solveInPlace(dest);
         else
           LLTTraits::getU(Base::m_matrix).solveInPlace(dest);
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCholesky/SimplicialCholesky_impl.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCholesky/SimplicialCholesky_impl.h`

 * *Files 2% similar despite different names*

```diff
@@ -127,15 +127,15 @@
       Index i = pattern[top];       /* pattern[top:n-1] is pattern of L(:,k) */
       Scalar yi = y[i];             /* get and clear Y(i) */
       y[i] = Scalar(0);
 
       /* the nonzero entry L(k,i) */
       Scalar l_ki;
       if(DoLDLT)
-        l_ki = yi / m_diag[i];
+        l_ki = yi / numext::real(m_diag[i]);
       else
         yi = l_ki = yi / Lx[Lp[i]];
 
       Index p2 = Lp[i] + m_nonZerosPerCol[i];
       Index p;
       for(p = Lp[i] + (DoLDLT ? 0 : 1); p < p2; ++p)
         y[Li[p]] -= numext::conj(Lx[p]) * yi;
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/AmbiVector.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/AmbiVector.h`

 * *Files 3% similar despite different names*

```diff
@@ -24,15 +24,15 @@
 {
   public:
     typedef _Scalar Scalar;
     typedef _StorageIndex StorageIndex;
     typedef typename NumTraits<Scalar>::Real RealScalar;
 
     explicit AmbiVector(Index size)
-      : m_buffer(0), m_zero(0), m_size(0), m_allocatedSize(0), m_allocatedElements(0), m_mode(-1)
+      : m_buffer(0), m_zero(0), m_size(0), m_end(0), m_allocatedSize(0), m_allocatedElements(0), m_mode(-1)
     {
       resize(size);
     }
 
     void init(double estimatedDensity);
     void init(int mode);
 
@@ -143,15 +143,16 @@
     init(IsSparse);
 }
 
 template<typename _Scalar,typename _StorageIndex>
 void AmbiVector<_Scalar,_StorageIndex>::init(int mode)
 {
   m_mode = mode;
-  if (m_mode==IsSparse)
+  // This is only necessary in sparse mode, but we set these unconditionally to avoid some maybe-uninitialized warnings
+  // if (m_mode==IsSparse)
   {
     m_llSize = 0;
     m_llStart = -1;
   }
 }
 
 /** Must be called whenever we might perform a write access
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/CompressedStorage.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/CompressedStorage.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/ConservativeSparseSparseProduct.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/ConservativeSparseSparseProduct.h`

 * *Files 1% similar despite different names*

```diff
@@ -6,39 +6,39 @@
 // This Source Code Form is subject to the terms of the Mozilla
 // Public License v. 2.0. If a copy of the MPL was not distributed
 // with this file, You can obtain one at http://mozilla.org/MPL/2.0/.
 
 #ifndef EIGEN_CONSERVATIVESPARSESPARSEPRODUCT_H
 #define EIGEN_CONSERVATIVESPARSESPARSEPRODUCT_H
 
-namespace Eigen { 
+namespace Eigen {
 
 namespace internal {
 
 template<typename Lhs, typename Rhs, typename ResultType>
 static void conservative_sparse_sparse_product_impl(const Lhs& lhs, const Rhs& rhs, ResultType& res, bool sortedInsertion = false)
 {
   typedef typename remove_all<Lhs>::type::Scalar LhsScalar;
   typedef typename remove_all<Rhs>::type::Scalar RhsScalar;
   typedef typename remove_all<ResultType>::type::Scalar ResScalar;
 
   // make sure to call innerSize/outerSize since we fake the storage order.
   Index rows = lhs.innerSize();
   Index cols = rhs.outerSize();
   eigen_assert(lhs.outerSize() == rhs.innerSize());
-  
+
   ei_declare_aligned_stack_constructed_variable(bool,   mask,     rows, 0);
   ei_declare_aligned_stack_constructed_variable(ResScalar, values,   rows, 0);
   ei_declare_aligned_stack_constructed_variable(Index,  indices,  rows, 0);
-  
+
   std::memset(mask,0,sizeof(bool)*rows);
 
   evaluator<Lhs> lhsEval(lhs);
   evaluator<Rhs> rhsEval(rhs);
-  
+
   // estimate the number of non zero entries
   // given a rhs column containing Y non zeros, we assume that the respective Y columns
   // of the lhs differs in average of one non zeros, thus the number of non zeros for
   // the product of a rhs column with the lhs is X+Y where X is the average number of non zero
   // per column of the lhs.
   // Therefore, we have nnz(lhs*rhs) = nnz(lhs) + nnz(rhs)
   Index estimated_nnz_prod = lhsEval.nonZerosEstimate() + rhsEval.nonZerosEstimate();
@@ -137,29 +137,29 @@
   typedef typename LhsCleaned::Scalar Scalar;
 
   static void run(const Lhs& lhs, const Rhs& rhs, ResultType& res)
   {
     typedef SparseMatrix<typename ResultType::Scalar,RowMajor,typename ResultType::StorageIndex> RowMajorMatrix;
     typedef SparseMatrix<typename ResultType::Scalar,ColMajor,typename ResultType::StorageIndex> ColMajorMatrixAux;
     typedef typename sparse_eval<ColMajorMatrixAux,ResultType::RowsAtCompileTime,ResultType::ColsAtCompileTime,ColMajorMatrixAux::Flags>::type ColMajorMatrix;
-    
+
     // If the result is tall and thin (in the extreme case a column vector)
     // then it is faster to sort the coefficients inplace instead of transposing twice.
     // FIXME, the following heuristic is probably not very good.
     if(lhs.rows()>rhs.cols())
     {
       ColMajorMatrix resCol(lhs.rows(),rhs.cols());
       // perform sorted insertion
       internal::conservative_sparse_sparse_product_impl<Lhs,Rhs,ColMajorMatrix>(lhs, rhs, resCol, true);
       res = resCol.markAsRValue();
     }
     else
     {
       ColMajorMatrixAux resCol(lhs.rows(),rhs.cols());
-      // ressort to transpose to sort the entries
+      // resort to transpose to sort the entries
       internal::conservative_sparse_sparse_product_impl<Lhs,Rhs,ColMajorMatrixAux>(lhs, rhs, resCol, false);
       RowMajorMatrix resRow(resCol);
       res = resRow.markAsRValue();
     }
   }
 };
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/MappedSparseMatrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/MappedSparseMatrix.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseAssign.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseAssign.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseBlock.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseBlock.h`

 * *Files 2% similar despite different names*

```diff
@@ -160,15 +160,15 @@
 
         matrix.data().swap(newdata);
 
         update_trailing_pointers = true;
       }
       else
       {
-        if(m_matrix.isCompressed())
+        if(m_matrix.isCompressed() && nnz!=block_size)
         {
           // no need to realloc, simply copy the tail at its respective position and insert tmp
           matrix.data().resize(start + nnz + tail_size);
 
           internal::smart_memmove(matrix.valuePtr()+end,      matrix.valuePtr() + end+tail_size,      matrix.valuePtr() + start+nnz);
           internal::smart_memmove(matrix.innerIndexPtr()+end, matrix.innerIndexPtr() + end+tail_size, matrix.innerIndexPtr() + start+nnz);
 
@@ -442,83 +442,91 @@
     typedef typename internal::conditional<OuterVector,OuterVectorInnerIterator,InnerVectorInnerIterator>::type InnerIterator;
 
     explicit unary_evaluator(const XprType& op)
       : m_argImpl(op.nestedExpression()), m_block(op)
     {}
 
     inline Index nonZerosEstimate() const {
-      Index nnz = m_block.nonZeros();
-      if(nnz<0)
-        return m_argImpl.nonZerosEstimate() * m_block.size() / m_block.nestedExpression().size();
+      const Index nnz = m_block.nonZeros();
+      if(nnz < 0) {
+        // Scale the non-zero estimate for the underlying expression linearly with block size.
+        // Return zero if the underlying block is empty.
+        const Index nested_sz = m_block.nestedExpression().size();        
+        return nested_sz == 0 ? 0 : m_argImpl.nonZerosEstimate() * m_block.size() / nested_sz;
+      }
       return nnz;
     }
 
   protected:
     typedef typename evaluator<ArgType>::InnerIterator EvalIterator;
 
     evaluator<ArgType> m_argImpl;
     const XprType &m_block;
 };
 
 template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 class unary_evaluator<Block<ArgType,BlockRows,BlockCols,InnerPanel>, IteratorBased>::InnerVectorInnerIterator
  : public EvalIterator
 {
-  enum { IsRowMajor = unary_evaluator::IsRowMajor };
+  // NOTE MSVC fails to compile if we don't explicitely "import" IsRowMajor from unary_evaluator
+  //      because the base class EvalIterator has a private IsRowMajor enum too. (bug #1786)
+  // NOTE We cannot call it IsRowMajor because it would shadow unary_evaluator::IsRowMajor
+  enum { XprIsRowMajor = unary_evaluator::IsRowMajor };
   const XprType& m_block;
   Index m_end;
 public:
 
   EIGEN_STRONG_INLINE InnerVectorInnerIterator(const unary_evaluator& aEval, Index outer)
-    : EvalIterator(aEval.m_argImpl, outer + (IsRowMajor ? aEval.m_block.startRow() : aEval.m_block.startCol())),
+    : EvalIterator(aEval.m_argImpl, outer + (XprIsRowMajor ? aEval.m_block.startRow() : aEval.m_block.startCol())),
       m_block(aEval.m_block),
-      m_end(IsRowMajor ? aEval.m_block.startCol()+aEval.m_block.blockCols() : aEval.m_block.startRow()+aEval.m_block.blockRows())
+      m_end(XprIsRowMajor ? aEval.m_block.startCol()+aEval.m_block.blockCols() : aEval.m_block.startRow()+aEval.m_block.blockRows())
   {
-    while( (EvalIterator::operator bool()) && (EvalIterator::index() < (IsRowMajor ? m_block.startCol() : m_block.startRow())) )
+    while( (EvalIterator::operator bool()) && (EvalIterator::index() < (XprIsRowMajor ? m_block.startCol() : m_block.startRow())) )
       EvalIterator::operator++();
   }
 
-  inline StorageIndex index() const { return EvalIterator::index() - convert_index<StorageIndex>(IsRowMajor ? m_block.startCol() : m_block.startRow()); }
-  inline Index outer()  const { return EvalIterator::outer() - (IsRowMajor ? m_block.startRow() : m_block.startCol()); }
+  inline StorageIndex index() const { return EvalIterator::index() - convert_index<StorageIndex>(XprIsRowMajor ? m_block.startCol() : m_block.startRow()); }
+  inline Index outer()  const { return EvalIterator::outer() - (XprIsRowMajor ? m_block.startRow() : m_block.startCol()); }
   inline Index row()    const { return EvalIterator::row()   - m_block.startRow(); }
   inline Index col()    const { return EvalIterator::col()   - m_block.startCol(); }
 
   inline operator bool() const { return EvalIterator::operator bool() && EvalIterator::index() < m_end; }
 };
 
 template<typename ArgType, int BlockRows, int BlockCols, bool InnerPanel>
 class unary_evaluator<Block<ArgType,BlockRows,BlockCols,InnerPanel>, IteratorBased>::OuterVectorInnerIterator
 {
-  enum { IsRowMajor = unary_evaluator::IsRowMajor };
+  // NOTE see above
+  enum { XprIsRowMajor = unary_evaluator::IsRowMajor };
   const unary_evaluator& m_eval;
   Index m_outerPos;
   const Index m_innerIndex;
   Index m_end;
   EvalIterator m_it;
 public:
 
   EIGEN_STRONG_INLINE OuterVectorInnerIterator(const unary_evaluator& aEval, Index outer)
     : m_eval(aEval),
-      m_outerPos( (IsRowMajor ? aEval.m_block.startCol() : aEval.m_block.startRow()) ),
-      m_innerIndex(IsRowMajor ? aEval.m_block.startRow() : aEval.m_block.startCol()),
-      m_end(IsRowMajor ? aEval.m_block.startCol()+aEval.m_block.blockCols() : aEval.m_block.startRow()+aEval.m_block.blockRows()),
+      m_outerPos( (XprIsRowMajor ? aEval.m_block.startCol() : aEval.m_block.startRow()) ),
+      m_innerIndex(XprIsRowMajor ? aEval.m_block.startRow() : aEval.m_block.startCol()),
+      m_end(XprIsRowMajor ? aEval.m_block.startCol()+aEval.m_block.blockCols() : aEval.m_block.startRow()+aEval.m_block.blockRows()),
       m_it(m_eval.m_argImpl, m_outerPos)
   {
     EIGEN_UNUSED_VARIABLE(outer);
     eigen_assert(outer==0);
 
     while(m_it && m_it.index() < m_innerIndex) ++m_it;
     if((!m_it) || (m_it.index()!=m_innerIndex))
       ++(*this);
   }
 
-  inline StorageIndex index() const { return convert_index<StorageIndex>(m_outerPos - (IsRowMajor ? m_eval.m_block.startCol() : m_eval.m_block.startRow())); }
+  inline StorageIndex index() const { return convert_index<StorageIndex>(m_outerPos - (XprIsRowMajor ? m_eval.m_block.startCol() : m_eval.m_block.startRow())); }
   inline Index outer()  const { return 0; }
-  inline Index row()    const { return IsRowMajor ? 0 : index(); }
-  inline Index col()    const { return IsRowMajor ? index() : 0; }
+  inline Index row()    const { return XprIsRowMajor ? 0 : index(); }
+  inline Index col()    const { return XprIsRowMajor ? index() : 0; }
 
   inline Scalar value() const { return m_it.value(); }
   inline Scalar& valueRef() { return m_it.valueRef(); }
 
   inline OuterVectorInnerIterator& operator++()
   {
     // search next non-zero entry
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseColEtree.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseColEtree.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseCompressedBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseCompressedBase.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseCwiseBinaryOp.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseCwiseBinaryOp.h`

 * *Files 3% similar despite different names*

```diff
@@ -97,15 +97,15 @@
       {
         m_id = m_rhsIter.index();
         m_value = m_functor(Scalar(0), m_rhsIter.value());
         ++m_rhsIter;
       }
       else
       {
-        m_value = 0; // this is to avoid a compilation warning
+        m_value = Scalar(0); // this is to avoid a compilation warning
         m_id = -1;
       }
       return *this;
     }
 
     EIGEN_STRONG_INLINE Scalar value() const { return m_value; }
 
@@ -122,15 +122,15 @@
     const BinaryOp& m_functor;
     Scalar m_value;
     StorageIndex m_id;
   };
   
   
   enum {
-    CoeffReadCost = evaluator<Lhs>::CoeffReadCost + evaluator<Rhs>::CoeffReadCost + functor_traits<BinaryOp>::Cost,
+    CoeffReadCost = int(evaluator<Lhs>::CoeffReadCost) + int(evaluator<Rhs>::CoeffReadCost) + int(functor_traits<BinaryOp>::Cost),
     Flags = XprType::Flags
   };
   
   explicit binary_evaluator(const XprType& xpr)
     : m_functor(xpr.functor()),
       m_lhsImpl(xpr.lhs()), 
       m_rhsImpl(xpr.rhs())  
@@ -207,15 +207,15 @@
     Scalar m_value;
     StorageIndex m_id;
     StorageIndex m_innerSize;
   };
 
 
   enum {
-    CoeffReadCost = evaluator<Lhs>::CoeffReadCost + evaluator<Rhs>::CoeffReadCost + functor_traits<BinaryOp>::Cost,
+    CoeffReadCost = int(evaluator<Lhs>::CoeffReadCost) + int(evaluator<Rhs>::CoeffReadCost) + int(functor_traits<BinaryOp>::Cost),
     Flags = XprType::Flags
   };
 
   explicit binary_evaluator(const XprType& xpr)
     : m_functor(xpr.functor()),
       m_lhsImpl(xpr.lhs()),
       m_rhsImpl(xpr.rhs()),
@@ -294,15 +294,15 @@
     Scalar m_value;
     StorageIndex m_id;
     StorageIndex m_innerSize;
   };
 
 
   enum {
-    CoeffReadCost = evaluator<Lhs>::CoeffReadCost + evaluator<Rhs>::CoeffReadCost + functor_traits<BinaryOp>::Cost,
+    CoeffReadCost = int(evaluator<Lhs>::CoeffReadCost) + int(evaluator<Rhs>::CoeffReadCost) + int(functor_traits<BinaryOp>::Cost),
     Flags = XprType::Flags
   };
 
   explicit binary_evaluator(const XprType& xpr)
     : m_functor(xpr.functor()),
       m_lhsImpl(xpr.lhs()),
       m_rhsImpl(xpr.rhs()),
@@ -453,15 +453,15 @@
     LhsIterator m_lhsIter;
     RhsIterator m_rhsIter;
     const BinaryOp& m_functor;
   };
   
   
   enum {
-    CoeffReadCost = evaluator<LhsArg>::CoeffReadCost + evaluator<RhsArg>::CoeffReadCost + functor_traits<BinaryOp>::Cost,
+    CoeffReadCost = int(evaluator<LhsArg>::CoeffReadCost) + int(evaluator<RhsArg>::CoeffReadCost) + int(functor_traits<BinaryOp>::Cost),
     Flags = XprType::Flags
   };
   
   explicit sparse_conjunction_evaluator(const XprType& xpr)
     : m_functor(xpr.functor()),
       m_lhsImpl(xpr.lhs()), 
       m_rhsImpl(xpr.rhs())  
@@ -526,15 +526,15 @@
     RhsIterator m_rhsIter;
     const BinaryOp& m_functor;
     const Index m_outer;
   };
   
   
   enum {
-    CoeffReadCost = evaluator<LhsArg>::CoeffReadCost + evaluator<RhsArg>::CoeffReadCost + functor_traits<BinaryOp>::Cost,
+    CoeffReadCost = int(evaluator<LhsArg>::CoeffReadCost) + int(evaluator<RhsArg>::CoeffReadCost) + int(functor_traits<BinaryOp>::Cost),
     Flags = XprType::Flags
   };
   
   explicit sparse_conjunction_evaluator(const XprType& xpr)
     : m_functor(xpr.functor()),
       m_lhsImpl(xpr.lhs()), 
       m_rhsImpl(xpr.rhs())  
@@ -600,15 +600,15 @@
     const evaluator<RhsArg> &m_rhsEval;
     const BinaryOp& m_functor;
     const Index m_outer;
   };
   
   
   enum {
-    CoeffReadCost = evaluator<LhsArg>::CoeffReadCost + evaluator<RhsArg>::CoeffReadCost + functor_traits<BinaryOp>::Cost,
+    CoeffReadCost = int(evaluator<LhsArg>::CoeffReadCost) + int(evaluator<RhsArg>::CoeffReadCost) + int(functor_traits<BinaryOp>::Cost),
     Flags = XprType::Flags
   };
   
   explicit sparse_conjunction_evaluator(const XprType& xpr)
     : m_functor(xpr.functor()),
       m_lhsImpl(xpr.lhs()), 
       m_rhsImpl(xpr.rhs())
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseCwiseUnaryOp.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseCwiseUnaryOp.h`

 * *Files 5% similar despite different names*

```diff
@@ -20,15 +20,15 @@
 {
   public:
     typedef CwiseUnaryOp<UnaryOp, ArgType> XprType;
 
     class InnerIterator;
     
     enum {
-      CoeffReadCost = evaluator<ArgType>::CoeffReadCost + functor_traits<UnaryOp>::Cost,
+      CoeffReadCost = int(evaluator<ArgType>::CoeffReadCost) + int(functor_traits<UnaryOp>::Cost),
       Flags = XprType::Flags
     };
     
     explicit unary_evaluator(const XprType& op) : m_functor(op.functor()), m_argImpl(op.nestedExpression())
     {
       EIGEN_INTERNAL_CHECK_COST_VALUE(functor_traits<UnaryOp>::Cost);
       EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
@@ -45,14 +45,15 @@
     evaluator<ArgType> m_argImpl;
 };
 
 template<typename UnaryOp, typename ArgType>
 class unary_evaluator<CwiseUnaryOp<UnaryOp,ArgType>, IteratorBased>::InnerIterator
     : public unary_evaluator<CwiseUnaryOp<UnaryOp,ArgType>, IteratorBased>::EvalIterator
 {
+  protected:
     typedef typename XprType::Scalar Scalar;
     typedef typename unary_evaluator<CwiseUnaryOp<UnaryOp,ArgType>, IteratorBased>::EvalIterator Base;
   public:
 
     EIGEN_STRONG_INLINE InnerIterator(const unary_evaluator& unaryOp, Index outer)
       : Base(unaryOp.m_argImpl,outer), m_functor(unaryOp.m_functor)
     {}
@@ -74,15 +75,15 @@
 {
   public:
     typedef CwiseUnaryView<ViewOp, ArgType> XprType;
 
     class InnerIterator;
     
     enum {
-      CoeffReadCost = evaluator<ArgType>::CoeffReadCost + functor_traits<ViewOp>::Cost,
+      CoeffReadCost = int(evaluator<ArgType>::CoeffReadCost) + int(functor_traits<ViewOp>::Cost),
       Flags = XprType::Flags
     };
     
     explicit unary_evaluator(const XprType& op) : m_functor(op.functor()), m_argImpl(op.nestedExpression())
     {
       EIGEN_INTERNAL_CHECK_COST_VALUE(functor_traits<ViewOp>::Cost);
       EIGEN_INTERNAL_CHECK_COST_VALUE(CoeffReadCost);
@@ -95,14 +96,15 @@
     evaluator<ArgType> m_argImpl;
 };
 
 template<typename ViewOp, typename ArgType>
 class unary_evaluator<CwiseUnaryView<ViewOp,ArgType>, IteratorBased>::InnerIterator
     : public unary_evaluator<CwiseUnaryView<ViewOp,ArgType>, IteratorBased>::EvalIterator
 {
+  protected:
     typedef typename XprType::Scalar Scalar;
     typedef typename unary_evaluator<CwiseUnaryView<ViewOp,ArgType>, IteratorBased>::EvalIterator Base;
   public:
 
     EIGEN_STRONG_INLINE InnerIterator(const unary_evaluator& unaryOp, Index outer)
       : Base(unaryOp.m_argImpl,outer), m_functor(unaryOp.m_functor)
     {}
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseDenseProduct.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseDenseProduct.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseDiagonalProduct.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseDiagonalProduct.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseDot.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseDot.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseFuzzy.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseFuzzy.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseMap.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseMap.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseMatrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseMatrix.h`

 * *Files 0% similar despite different names*

```diff
@@ -325,15 +325,16 @@
             m_data.index(newOuterIndex[j]+i) = m_data.index(m_outerIndex[j]+i);
             m_data.value(newOuterIndex[j]+i) = m_data.value(m_outerIndex[j]+i);
           }
           previousOuterIndex = m_outerIndex[j];
           m_outerIndex[j] = newOuterIndex[j];
           m_innerNonZeros[j] = innerNNZ;
         }
-        m_outerIndex[m_outerSize] = m_outerIndex[m_outerSize-1] + m_innerNonZeros[m_outerSize-1] + reserveSizes[m_outerSize-1];
+        if(m_outerSize>0)
+          m_outerIndex[m_outerSize] = m_outerIndex[m_outerSize-1] + m_innerNonZeros[m_outerSize-1] + reserveSizes[m_outerSize-1];
         
         m_data.resize(m_outerIndex[m_outerSize]);
       }
       else
       {
         StorageIndex* newOuterIndex = static_cast<StorageIndex*>(std::malloc((m_outerSize+1)*sizeof(StorageIndex)));
         if (!newOuterIndex) internal::throw_std_bad_alloc();
@@ -574,18 +575,20 @@
         
         for(Index i=m_outerSize; i<m_outerSize+outerChange; i++)          
           m_innerNonZeros[i] = 0;
       } 
       else if (innerChange < 0) 
       {
         // Inner size decreased: allocate a new m_innerNonZeros
-        m_innerNonZeros = static_cast<StorageIndex*>(std::malloc((m_outerSize+outerChange+1) * sizeof(StorageIndex)));
+        m_innerNonZeros = static_cast<StorageIndex*>(std::malloc((m_outerSize + outerChange) * sizeof(StorageIndex)));
         if (!m_innerNonZeros) internal::throw_std_bad_alloc();
-        for(Index i = 0; i < m_outerSize; i++)
+        for(Index i = 0; i < m_outerSize + (std::min)(outerChange, Index(0)); i++)
           m_innerNonZeros[i] = m_outerIndex[i+1] - m_outerIndex[i];
+        for(Index i = m_outerSize; i < m_outerSize + outerChange; i++)
+          m_innerNonZeros[i] = 0;
       }
       
       // Change the m_innerNonZeros in case of a decrease of inner size
       if (m_innerNonZeros && innerChange < 0)
       {
         for(Index i = 0; i < m_outerSize + (std::min)(outerChange, Index(0)); i++)
         {
@@ -778,14 +781,17 @@
       return *this;
     }
 
 #ifndef EIGEN_PARSED_BY_DOXYGEN
     template<typename OtherDerived>
     inline SparseMatrix& operator=(const EigenBase<OtherDerived>& other)
     { return Base::operator=(other.derived()); }
+
+    template<typename Lhs, typename Rhs>
+    inline SparseMatrix& operator=(const Product<Lhs,Rhs,AliasFreeProduct>& other);
 #endif // EIGEN_PARSED_BY_DOXYGEN
 
     template<typename OtherDerived>
     EIGEN_DONT_INLINE SparseMatrix& operator=(const SparseMatrixBase<OtherDerived>& other);
 
     friend std::ostream & operator << (std::ostream & s, const SparseMatrix& m)
     {
@@ -1078,15 +1084,15 @@
   * \endcode
   * See for instance the Eigen::Triplet template class.
   *
   * Here is a typical usage example:
   * \code
     typedef Triplet<double> T;
     std::vector<T> tripletList;
-    triplets.reserve(estimation_of_entries);
+    tripletList.reserve(estimation_of_entries);
     for(...)
     {
       // ...
       tripletList.push_back(T(i,j,v_ij));
     }
     SparseMatrixType m(rows,cols);
     m.setFromTriplets(tripletList.begin(), tripletList.end());
@@ -1337,15 +1343,15 @@
     {
       m_data.index(p) = m_data.index(p-1);
       m_data.value(p) = m_data.value(p-1);
       --p;
     }
     
     m_data.index(p) = convert_index(inner);
-    return (m_data.value(p) = 0);
+    return (m_data.value(p) = Scalar(0));
   }
   
   if(m_data.size() != m_data.allocatedSize())
   {
     // make sure the matrix is compatible to random un-compressed insertion:
     m_data.resize(m_data.allocatedSize());
     this->reserveInnerVectors(Array<StorageIndex,Dynamic,1>::Constant(m_outerSize, 2));
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseMatrixBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseMatrixBase.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparsePermutation.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparsePermutation.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseProduct.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseProduct.h`

 * *Files 4% similar despite different names*

```diff
@@ -160,10 +160,22 @@
 
 protected:
   PlainObject m_result;
 };
 
 } // end namespace internal
 
+// sparse matrix = sparse-product (can be sparse*sparse, sparse*perm, etc.)
+template<typename Scalar, int _Options, typename _StorageIndex>
+template<typename Lhs, typename Rhs>
+SparseMatrix<Scalar,_Options,_StorageIndex>& SparseMatrix<Scalar,_Options,_StorageIndex>::operator=(const Product<Lhs,Rhs,AliasFreeProduct>& src)
+{
+  // std::cout << "in Assignment : " << DstOptions << "\n";
+  SparseMatrix dst(src.rows(),src.cols());
+  internal::generic_product_impl<Lhs, Rhs>::evalTo(dst,src.lhs(),src.rhs());
+  this->swap(dst);
+  return *this;
+}
+
 } // end namespace Eigen
 
 #endif // EIGEN_SPARSEPRODUCT_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseRedux.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseRedux.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseRef.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseRef.h`

 * *Files 2% similar despite different names*

```diff
@@ -197,48 +197,48 @@
     template<typename OtherRef>
     inline Ref(const RefBase<OtherRef>& other) : m_hasCopy(false) {
       construct(other.derived(), typename Traits::template match<OtherRef>::type());
     }
 
     ~Ref() {
       if(m_hasCopy) {
-        TPlainObjectType* obj = reinterpret_cast<TPlainObjectType*>(m_object_bytes);
+        TPlainObjectType* obj = reinterpret_cast<TPlainObjectType*>(&m_storage);
         obj->~TPlainObjectType();
       }
     }
 
   protected:
 
     template<typename Expression>
     void construct(const Expression& expr,internal::true_type)
     {
       if((Options & int(StandardCompressedFormat)) && (!expr.isCompressed()))
       {
-        TPlainObjectType* obj = reinterpret_cast<TPlainObjectType*>(m_object_bytes);
+        TPlainObjectType* obj = reinterpret_cast<TPlainObjectType*>(&m_storage);
         ::new (obj) TPlainObjectType(expr);
         m_hasCopy = true;
         Base::construct(*obj);
       }
       else
       {
         Base::construct(expr);
       }
     }
 
     template<typename Expression>
     void construct(const Expression& expr, internal::false_type)
     {
-      TPlainObjectType* obj = reinterpret_cast<TPlainObjectType*>(m_object_bytes);
+      TPlainObjectType* obj = reinterpret_cast<TPlainObjectType*>(&m_storage);
       ::new (obj) TPlainObjectType(expr);
       m_hasCopy = true;
       Base::construct(*obj);
     }
 
   protected:
-    char m_object_bytes[sizeof(TPlainObjectType)];
+    typename internal::aligned_storage<sizeof(TPlainObjectType), EIGEN_ALIGNOF(TPlainObjectType)>::type m_storage;
     bool m_hasCopy;
 };
 
 
 
 /**
   * \ingroup SparseCore_Module
@@ -315,15 +315,15 @@
     template<typename OtherRef>
     inline Ref(const RefBase<OtherRef>& other) : m_hasCopy(false) {
       construct(other.derived(), typename Traits::template match<OtherRef>::type());
     }
 
     ~Ref() {
       if(m_hasCopy) {
-        TPlainObjectType* obj = reinterpret_cast<TPlainObjectType*>(m_object_bytes);
+        TPlainObjectType* obj = reinterpret_cast<TPlainObjectType*>(&m_storage);
         obj->~TPlainObjectType();
       }
     }
 
   protected:
 
     template<typename Expression>
@@ -331,22 +331,22 @@
     {
       Base::construct(expr);
     }
 
     template<typename Expression>
     void construct(const Expression& expr, internal::false_type)
     {
-      TPlainObjectType* obj = reinterpret_cast<TPlainObjectType*>(m_object_bytes);
+      TPlainObjectType* obj = reinterpret_cast<TPlainObjectType*>(&m_storage);
       ::new (obj) TPlainObjectType(expr);
       m_hasCopy = true;
       Base::construct(*obj);
     }
 
   protected:
-    char m_object_bytes[sizeof(TPlainObjectType)];
+    typename internal::aligned_storage<sizeof(TPlainObjectType), EIGEN_ALIGNOF(TPlainObjectType)>::type m_storage;
     bool m_hasCopy;
 };
 
 namespace internal {
 
 // FIXME shall we introduce a general evaluatior_ref that we can specialize for any sparse object once, and thus remove this copy-pasta thing...
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseSelfAdjointView.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseSelfAdjointView.h`

 * *Files 1% similar despite different names*

```diff
@@ -138,14 +138,17 @@
 
     SparseSelfAdjointView& operator=(const SparseSelfAdjointView& src)
     {
       PermutationMatrix<Dynamic,Dynamic,StorageIndex> pnull;
       return *this = src.twistedBy(pnull);
     }
 
+    // Since we override the copy-assignment operator, we need to explicitly re-declare the copy-constructor
+    EIGEN_DEFAULT_COPY_CONSTRUCTOR(SparseSelfAdjointView)
+
     template<typename SrcMatrixType,unsigned int SrcMode>
     SparseSelfAdjointView& operator=(const SparseSelfAdjointView<SrcMatrixType,SrcMode>& src)
     {
       PermutationMatrix<Dynamic,Dynamic,StorageIndex> pnull;
       return *this = src.twistedBy(pnull);
     }
     
@@ -449,15 +452,15 @@
     Index jp = perm ? perm[j] : j;
     for(MatIterator it(matEval,j); it; ++it)
     {
       Index i = it.index();
       Index r = it.row();
       Index c = it.col();
       Index ip = perm ? perm[i] : i;
-      if(Mode==(Upper|Lower))
+      if(Mode==int(Upper|Lower))
         count[StorageOrderMatch ? jp : ip]++;
       else if(r==c)
         count[ip]++;
       else if(( Mode==Lower && r>c) || ( Mode==Upper && r<c))
       {
         count[ip]++;
         count[jp]++;
@@ -482,15 +485,15 @@
       StorageIndex i = internal::convert_index<StorageIndex>(it.index());
       Index r = it.row();
       Index c = it.col();
       
       StorageIndex jp = perm ? perm[j] : j;
       StorageIndex ip = perm ? perm[i] : i;
       
-      if(Mode==(Upper|Lower))
+      if(Mode==int(Upper|Lower))
       {
         Index k = count[StorageOrderMatch ? jp : ip]++;
         dest.innerIndexPtr()[k] = StorageOrderMatch ? ip : jp;
         dest.valuePtr()[k] = it.value();
       }
       else if(r==c)
       {
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseSolverBase.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseSolverBase.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseSparseProductWithPruning.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseSparseProductWithPruning.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseTranspose.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseTranspose.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseTriangularView.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseTriangularView.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseUtil.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseUtil.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseVector.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseVector.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/SparseView.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/SparseView.h`

 * *Files 1% similar despite different names*

```diff
@@ -86,14 +86,15 @@
 {
     typedef typename evaluator<ArgType>::InnerIterator EvalIterator;
   public:
     typedef SparseView<ArgType> XprType;
     
     class InnerIterator : public EvalIterator
     {
+      protected:
         typedef typename XprType::Scalar Scalar;
       public:
 
         EIGEN_STRONG_INLINE InnerIterator(const unary_evaluator& sve, Index outer)
           : EvalIterator(sve.m_argImpl,outer), m_view(sve.m_view)
         {
           incrementToNonZero();
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseCore/TriangularSolver.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseCore/TriangularSolver.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU.h`

 * *Files 13% similar despite different names*

```diff
@@ -14,14 +14,71 @@
 
 namespace Eigen {
 
 template <typename _MatrixType, typename _OrderingType = COLAMDOrdering<typename _MatrixType::StorageIndex> > class SparseLU;
 template <typename MappedSparseMatrixType> struct SparseLUMatrixLReturnType;
 template <typename MatrixLType, typename MatrixUType> struct SparseLUMatrixUReturnType;
 
+template <bool Conjugate,class SparseLUType>
+class SparseLUTransposeView : public SparseSolverBase<SparseLUTransposeView<Conjugate,SparseLUType> >
+{
+protected:
+  typedef SparseSolverBase<SparseLUTransposeView<Conjugate,SparseLUType> > APIBase;
+  using APIBase::m_isInitialized;
+public:
+  typedef typename SparseLUType::Scalar Scalar;
+  typedef typename SparseLUType::StorageIndex StorageIndex;
+  typedef typename SparseLUType::MatrixType MatrixType;
+  typedef typename SparseLUType::OrderingType OrderingType;
+
+  enum {
+    ColsAtCompileTime = MatrixType::ColsAtCompileTime,
+    MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
+  };
+
+  SparseLUTransposeView() : m_sparseLU(NULL) {}
+  SparseLUTransposeView(const SparseLUTransposeView& view) {
+    this->m_sparseLU = view.m_sparseLU;
+  }
+  void setIsInitialized(const bool isInitialized) {this->m_isInitialized = isInitialized;}
+  void setSparseLU(SparseLUType* sparseLU) {m_sparseLU = sparseLU;}
+  using APIBase::_solve_impl;
+  template<typename Rhs, typename Dest>
+  bool _solve_impl(const MatrixBase<Rhs> &B, MatrixBase<Dest> &X_base) const
+  {
+    Dest& X(X_base.derived());
+    eigen_assert(m_sparseLU->info() == Success && "The matrix should be factorized first");
+    EIGEN_STATIC_ASSERT((Dest::Flags&RowMajorBit)==0,
+                        THIS_METHOD_IS_ONLY_FOR_COLUMN_MAJOR_MATRICES);
+
+
+    // this ugly const_cast_derived() helps to detect aliasing when applying the permutations
+    for(Index j = 0; j < B.cols(); ++j){
+      X.col(j) = m_sparseLU->colsPermutation() * B.const_cast_derived().col(j);
+    }
+    //Forward substitution with transposed or adjoint of U
+    m_sparseLU->matrixU().template solveTransposedInPlace<Conjugate>(X);
+
+    //Backward substitution with transposed or adjoint of L
+    m_sparseLU->matrixL().template solveTransposedInPlace<Conjugate>(X);
+
+    // Permute back the solution
+    for (Index j = 0; j < B.cols(); ++j)
+      X.col(j) = m_sparseLU->rowsPermutation().transpose() * X.col(j);
+    return true;
+  }
+  inline Index rows() const { return m_sparseLU->rows(); }
+  inline Index cols() const { return m_sparseLU->cols(); }
+
+private:
+  SparseLUType *m_sparseLU;
+  SparseLUTransposeView& operator=(const SparseLUTransposeView&);
+};
+
+
 /** \ingroup SparseLU_Module
   * \class SparseLU
   * 
   * \brief Sparse supernodal LU factorization for general matrices
   * 
   * This class implements the supernodal LU factorization for general matrices.
   * It uses the main techniques from the sequential SuperLU package 
@@ -93,14 +150,15 @@
 
     enum {
       ColsAtCompileTime = MatrixType::ColsAtCompileTime,
       MaxColsAtCompileTime = MatrixType::MaxColsAtCompileTime
     };
     
   public:
+
     SparseLU():m_lastError(""),m_Ustore(0,0,0,0,0,0),m_symmetricmode(false),m_diagpivotthresh(1.0),m_detPermR(1)
     {
       initperfvalues(); 
     }
     explicit SparseLU(const MatrixType& matrix)
       : m_lastError(""),m_Ustore(0,0,0,0,0,0),m_symmetricmode(false),m_diagpivotthresh(1.0),m_detPermR(1)
     {
@@ -124,14 +182,53 @@
     void compute (const MatrixType& matrix)
     {
       // Analyze 
       analyzePattern(matrix); 
       //Factorize
       factorize(matrix);
     } 
+
+    /** \returns an expression of the transposed of the factored matrix.
+      *
+      * A typical usage is to solve for the transposed problem A^T x = b:
+      * \code
+      * solver.compute(A);
+      * x = solver.transpose().solve(b);
+      * \endcode
+      *
+      * \sa adjoint(), solve()
+      */
+    const SparseLUTransposeView<false,SparseLU<_MatrixType,_OrderingType> > transpose()
+    {
+      SparseLUTransposeView<false,  SparseLU<_MatrixType,_OrderingType> > transposeView;
+      transposeView.setSparseLU(this);
+      transposeView.setIsInitialized(this->m_isInitialized);
+      return transposeView;
+    }
+
+
+    /** \returns an expression of the adjoint of the factored matrix
+      *
+      * A typical usage is to solve for the adjoint problem A' x = b:
+      * \code
+      * solver.compute(A);
+      * x = solver.adjoint().solve(b);
+      * \endcode
+      *
+      * For real scalar types, this function is equivalent to transpose().
+      *
+      * \sa transpose(), solve()
+      */
+    const SparseLUTransposeView<true, SparseLU<_MatrixType,_OrderingType> > adjoint()
+    {
+      SparseLUTransposeView<true,  SparseLU<_MatrixType,_OrderingType> > adjointView;
+      adjointView.setSparseLU(this);
+      adjointView.setIsInitialized(this->m_isInitialized);
+      return adjointView;
+    }
     
     inline Index rows() const { return m_mat.rows(); }
     inline Index cols() const { return m_mat.cols(); }
     /** Indicate that the pattern of the input matrix is symmetric */
     void isSymmetric(bool sym)
     {
       m_symmetricmode = sym;
@@ -351,14 +448,17 @@
             break;
           }
         }
       }
       return (m_detPermR * m_detPermC) > 0 ? det : -det;
     }
 
+    Index nnzL() const { return m_nnzL; };
+    Index nnzU() const { return m_nnzU; };
+
   protected:
     // Functions 
     void initperfvalues()
     {
       m_perfv.panel_size = 16;
       m_perfv.relax = 1; 
       m_perfv.maxsuper = 128; 
@@ -387,15 +487,14 @@
     internal::perfvalues m_perfv;
     RealScalar m_diagpivotthresh; // Specifies the threshold used for a diagonal entry to be an acceptable pivot
     Index m_nnzL, m_nnzU; // Nonzeros in L and U factors
     Index m_detPermR, m_detPermC; // Determinants of the permutation matrices
   private:
     // Disable copy constructor 
     SparseLU (const SparseLU& );
-  
 }; // End class SparseLU
 
 
 
 // Functions needed by the anaysis phase
 /** 
   * Compute the column permutation to minimize the fill-in
@@ -580,15 +679,14 @@
   m_glu.supno(0) = emptyIdxLU; m_glu.xsup.setConstant(0);
   m_glu.xsup(0) = m_glu.xlsub(0) = m_glu.xusub(0) = m_glu.xlusup(0) = Index(0);
   
   // Work on one 'panel' at a time. A panel is one of the following :
   //  (a) a relaxed supernode at the bottom of the etree, or
   //  (b) panel_size contiguous columns, <panel_size> defined by the user
   Index jcol; 
-  IndexVector panel_histo(n);
   Index pivrow; // Pivotal row number in the original row matrix
   Index nseg1; // Number of segments in U-column above panel row jcol
   Index nseg; // Number of segments in each U-column 
   Index irep; 
   Index i, k, jj; 
   for (jcol = 0; jcol < n; )
   {
@@ -706,14 +804,20 @@
   Index rows() const { return m_mapL.rows(); }
   Index cols() const { return m_mapL.cols(); }
   template<typename Dest>
   void solveInPlace( MatrixBase<Dest> &X) const
   {
     m_mapL.solveInPlace(X);
   }
+  template<bool Conjugate, typename Dest>
+  void solveTransposedInPlace( MatrixBase<Dest> &X) const
+  {
+    m_mapL.template solveTransposedInPlace<Conjugate>(X);
+  }
+
   const MappedSupernodalType& m_mapL;
 };
 
 template<typename MatrixLType, typename MatrixUType>
 struct SparseLUMatrixUReturnType : internal::no_assignment_operator
 {
   typedef typename MatrixLType::Scalar Scalar;
@@ -760,14 +864,60 @@
             Index irow = it.index();
             X(irow, j) -= X(jcol, j) * it.value();
           }
         }
       }
     } // End For U-solve
   }
+
+  template<bool Conjugate, typename Dest>   void solveTransposedInPlace(MatrixBase<Dest> &X) const
+  {
+    using numext::conj;
+    Index nrhs = X.cols();
+    Index n    = X.rows();
+    // Forward solve with U
+    for (Index k = 0; k <=  m_mapL.nsuper(); k++)
+    {
+      Index fsupc = m_mapL.supToCol()[k];
+      Index lda = m_mapL.colIndexPtr()[fsupc+1] - m_mapL.colIndexPtr()[fsupc]; // leading dimension
+      Index nsupc = m_mapL.supToCol()[k+1] - fsupc;
+      Index luptr = m_mapL.colIndexPtr()[fsupc];
+
+      for (Index j = 0; j < nrhs; ++j)
+      {
+        for (Index jcol = fsupc; jcol < fsupc + nsupc; jcol++)
+        {
+          typename MatrixUType::InnerIterator it(m_mapU, jcol);
+          for ( ; it; ++it)
+          {
+            Index irow = it.index();
+            X(jcol, j) -= X(irow, j) * (Conjugate? conj(it.value()): it.value());
+          }
+        }
+      }
+      if (nsupc == 1)
+      {
+        for (Index j = 0; j < nrhs; j++)
+        {
+          X(fsupc, j) /= (Conjugate? conj(m_mapL.valuePtr()[luptr]) : m_mapL.valuePtr()[luptr]);
+        }
+      }
+      else
+      {
+        Map<const Matrix<Scalar,Dynamic,Dynamic, ColMajor>, 0, OuterStride<> > A( &(m_mapL.valuePtr()[luptr]), nsupc, nsupc, OuterStride<>(lda) );
+        Map< Matrix<Scalar,Dynamic,Dest::ColsAtCompileTime, ColMajor>, 0, OuterStride<> > U (&(X(fsupc,0)), nsupc, nrhs, OuterStride<>(n) );
+        if(Conjugate)
+          U = A.adjoint().template triangularView<Lower>().solve(U);
+        else
+          U = A.transpose().template triangularView<Lower>().solve(U);
+      }
+    }// End For U-solve
+  }
+
+
   const MatrixLType& m_mapL;
   const MatrixUType& m_mapU;
 };
 
 } // End namespace Eigen 
 
 #endif
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLUImpl.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLUImpl.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_Memory.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_Memory.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_Structs.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_Structs.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_SupernodalMatrix.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_SupernodalMatrix.h`

 * *Files 18% similar despite different names*

```diff
@@ -152,14 +152,17 @@
     {
       return m_nsuper; 
     }
     
     class InnerIterator; 
     template<typename Dest>
     void solveInPlace( MatrixBase<Dest>&X) const;
+    template<bool Conjugate, typename Dest>
+    void solveTransposedInPlace( MatrixBase<Dest>&X) const;
+
     
       
       
     
   protected:
     Index m_row; // Number of rows
     Index m_col; // Number of columns
@@ -290,12 +293,83 @@
             iptr++;
           }
         }
       }
     } 
 }
 
+template<typename Scalar, typename Index_>
+template<bool Conjugate, typename Dest>
+void MappedSuperNodalMatrix<Scalar,Index_>::solveTransposedInPlace( MatrixBase<Dest>&X) const
+{
+    using numext::conj;
+  Index n    = int(X.rows());
+  Index nrhs = Index(X.cols());
+  const Scalar * Lval = valuePtr();                 // Nonzero values
+  Matrix<Scalar,Dynamic,Dest::ColsAtCompileTime, ColMajor> work(n, nrhs);     // working vector
+  work.setZero();
+  for (Index k = nsuper(); k >= 0; k--)
+  {
+    Index fsupc = supToCol()[k];                    // First column of the current supernode
+    Index istart = rowIndexPtr()[fsupc];            // Pointer index to the subscript of the current column
+    Index nsupr = rowIndexPtr()[fsupc+1] - istart;  // Number of rows in the current supernode
+    Index nsupc = supToCol()[k+1] - fsupc;          // Number of columns in the current supernode
+    Index nrow = nsupr - nsupc;                     // Number of rows in the non-diagonal part of the supernode
+    Index irow;                                     //Current index row
+
+    if (nsupc == 1 )
+    {
+      for (Index j = 0; j < nrhs; j++)
+      {
+        InnerIterator it(*this, fsupc);
+        ++it; // Skip the diagonal element
+        for (; it; ++it)
+        {
+          irow = it.row();
+          X(fsupc,j) -= X(irow, j) * (Conjugate?conj(it.value()):it.value());
+        }
+      }
+    }
+    else
+    {
+      // The supernode has more than one column
+      Index luptr = colIndexPtr()[fsupc];
+      Index lda = colIndexPtr()[fsupc+1] - luptr;
+
+      //Begin Gather
+      for (Index j = 0; j < nrhs; j++)
+      {
+        Index iptr = istart + nsupc;
+        for (Index i = 0; i < nrow; i++)
+        {
+          irow = rowIndex()[iptr];
+          work.topRows(nrow)(i,j)= X(irow,j); // Gather operation
+          iptr++;
+        }
+      }
+
+      // Matrix-vector product with transposed submatrix
+      Map<const Matrix<Scalar,Dynamic,Dynamic, ColMajor>, 0, OuterStride<> > A( &(Lval[luptr+nsupc]), nrow, nsupc, OuterStride<>(lda) );
+      Map< Matrix<Scalar,Dynamic,Dest::ColsAtCompileTime, ColMajor>, 0, OuterStride<> > U (&(X(fsupc,0)), nsupc, nrhs, OuterStride<>(n) );
+      if(Conjugate)
+        U = U - A.adjoint() * work.topRows(nrow);
+      else
+        U = U - A.transpose() * work.topRows(nrow);
+
+      // Triangular solve (of transposed diagonal block)
+      new (&A) Map<const Matrix<Scalar,Dynamic,Dynamic, ColMajor>, 0, OuterStride<> > ( &(Lval[luptr]), nsupc, nsupc, OuterStride<>(lda) );
+      if(Conjugate)
+        U = A.adjoint().template triangularView<UnitUpper>().solve(U);
+      else
+        U = A.transpose().template triangularView<UnitUpper>().solve(U);
+
+    }
+
+  }
+}
+
+
 } // end namespace internal
 
 } // end namespace Eigen
 
 #endif // EIGEN_SPARSELU_MATRIX_H
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_Utils.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_Utils.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_column_bmod.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_column_bmod.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_column_dfs.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_column_dfs.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_copy_to_ucol.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_copy_to_ucol.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_gemm_kernel.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_gemm_kernel.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_heap_relax_snode.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_heap_relax_snode.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_kernel_bmod.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_kernel_bmod.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_panel_bmod.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_panel_bmod.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_panel_dfs.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_panel_dfs.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_pivotL.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_pivotL.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_pruneL.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_pruneL.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseLU/SparseLU_relax_snode.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseLU/SparseLU_relax_snode.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SparseQR/SparseQR.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SparseQR/SparseQR.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/StlSupport/StdDeque.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/StlSupport/StdDeque.h`

 * *Files 10% similar despite different names*

```diff
@@ -94,25 +94,15 @@
   void push_front(const value_type& x)
   { deque_base::push_front(x); }
   using deque_base::insert;  
   iterator insert(const_iterator position, const value_type& x)
   { return deque_base::insert(position,x); }
   void insert(const_iterator position, size_type new_size, const value_type& x)
   { deque_base::insert(position, new_size, x); }
-#elif defined(_GLIBCXX_DEQUE) && EIGEN_GNUC_AT_LEAST(4,2)
-  // workaround GCC std::deque implementation
-  void resize(size_type new_size, const value_type& x)
-  {
-    if (new_size < deque_base::size())
-      deque_base::_M_erase_at_end(this->_M_impl._M_start + new_size);
-    else
-      deque_base::insert(deque_base::end(), new_size - deque_base::size(), x);
-  }
 #else
-  // either GCC 4.1 or non-GCC
   // default implementation which should always work.
   void resize(size_type new_size, const value_type& x)
   {
     if (new_size < deque_base::size())
       deque_base::erase(deque_base::begin() + new_size, deque_base::end());
     else if (new_size > deque_base::size())
       deque_base::insert(deque_base::end(), new_size - deque_base::size(), x);
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/StlSupport/StdList.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/StlSupport/StdList.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/StlSupport/StdVector.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/StlSupport/StdVector.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/StlSupport/details.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/StlSupport/details.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/SuperLUSupport/SuperLUSupport.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/SuperLUSupport/SuperLUSupport.h`

 * *Files 1% similar despite different names*

```diff
@@ -213,20 +213,20 @@
     res.storage.values    = mat.valuePtr();
     res.storage.innerInd  = mat.innerIndexPtr();
     res.storage.outerInd  = mat.outerIndexPtr();
 
     res.setScalarType<typename MatrixType::Scalar>();
 
     // FIXME the following is not very accurate
-    if (MatrixType::Flags & Upper)
+    if (int(MatrixType::Flags) & int(Upper))
       res.Mtype = SLU_TRU;
-    if (MatrixType::Flags & Lower)
+    if (int(MatrixType::Flags) & int(Lower))
       res.Mtype = SLU_TRL;
 
-    eigen_assert(((MatrixType::Flags & SelfAdjoint)==0) && "SelfAdjoint matrix shape not supported by SuperLU");
+    eigen_assert(((int(MatrixType::Flags) & int(SelfAdjoint))==0) && "SelfAdjoint matrix shape not supported by SuperLU");
 
     return res;
   }
 };
 
 template<typename Scalar, int Rows, int Cols, int Options, int MRows, int MCols>
 struct SluMatrixMapHelper<Matrix<Scalar,Rows,Cols,Options,MRows,MCols> >
@@ -646,17 +646,16 @@
 
 template<typename MatrixType>
 template<typename Rhs,typename Dest>
 void SuperLU<MatrixType>::_solve_impl(const MatrixBase<Rhs> &b, MatrixBase<Dest>& x) const
 {
   eigen_assert(m_factorizationIsOk && "The decomposition is not in a valid state for solving, you must first call either compute() or analyzePattern()/factorize()");
 
-  const Index size = m_matrix.rows();
   const Index rhsCols = b.cols();
-  eigen_assert(size==b.rows());
+  eigen_assert(m_matrix.rows()==b.rows());
 
   m_sluOptions.Trans = NOTRANS;
   m_sluOptions.Fact = FACTORED;
   m_sluOptions.IterRefine = NOREFINE;
   
 
   m_sluFerr.resize(rhsCols);
@@ -970,17 +969,16 @@
 #ifndef EIGEN_PARSED_BY_DOXYGEN
 template<typename MatrixType>
 template<typename Rhs,typename Dest>
 void SuperILU<MatrixType>::_solve_impl(const MatrixBase<Rhs> &b, MatrixBase<Dest>& x) const
 {
   eigen_assert(m_factorizationIsOk && "The decomposition is not in a valid state for solving, you must first call either compute() or analyzePattern()/factorize()");
 
-  const int size = m_matrix.rows();
   const int rhsCols = b.cols();
-  eigen_assert(size==b.rows());
+  eigen_assert(m_matrix.rows()==b.rows());
 
   m_sluOptions.Trans = NOTRANS;
   m_sluOptions.Fact = FACTORED;
   m_sluOptions.IterRefine = NOREFINE;
 
   m_sluFerr.resize(rhsCols);
   m_sluBerr.resize(rhsCols);
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/UmfPackSupport/UmfPackSupport.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/UmfPackSupport/UmfPackSupport.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/misc/Image.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/misc/Image.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/misc/Kernel.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/misc/Kernel.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/misc/RealSvd2x2.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/misc/RealSvd2x2.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/misc/blas.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/misc/blas.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/misc/lapack.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/misc/lapack.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/misc/lapacke.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/misc/lapacke.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/ArrayCwiseBinaryOps.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/ArrayCwiseBinaryOps.h`

 * *Files 15% similar despite different names*

```diff
@@ -26,57 +26,159 @@
 /** \returns an expression of the coefficient-wise min of \c *this and \a other
   *
   * Example: \include Cwise_min.cpp
   * Output: \verbinclude Cwise_min.out
   *
   * \sa max()
   */
-EIGEN_MAKE_CWISE_BINARY_OP(min,min)
+template <int NaNPropagation, typename OtherDerived>
+EIGEN_DEVICE_FUNC
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar,NaNPropagation>, const Derived, const OtherDerived>
+#ifdef EIGEN_PARSED_BY_DOXYGEN
+min
+#else
+(min)
+#endif
+(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const
+{
+  return CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar,NaNPropagation>, const Derived, const OtherDerived>(derived(), other.derived());
+}
+
+template <typename OtherDerived>
+EIGEN_DEVICE_FUNC
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar,PropagateFast>, const Derived, const OtherDerived>
+#ifdef EIGEN_PARSED_BY_DOXYGEN
+min
+#else
+(min)
+#endif
+(const OtherDerived &other) const
+{
+  return (min<PropagateFast>)(other);
+}
 
 /** \returns an expression of the coefficient-wise min of \c *this and scalar \a other
   *
   * \sa max()
   */
+template <int NaNPropagation>
 EIGEN_DEVICE_FUNC
-EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar>, const Derived,
-                                        const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> >
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar,NaNPropagation>, const Derived,
+    const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> >
 #ifdef EIGEN_PARSED_BY_DOXYGEN
 min
 #else
 (min)
 #endif
 (const Scalar &other) const
 {
-  return (min)(Derived::PlainObject::Constant(rows(), cols(), other));
+  return (min<NaNPropagation>)(Derived::PlainObject::Constant(rows(), cols(), other));
+}
+
+EIGEN_DEVICE_FUNC
+    EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar,PropagateFast>, const Derived,
+    const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> >
+#ifdef EIGEN_PARSED_BY_DOXYGEN
+min
+#else
+(min)
+#endif
+(const Scalar &other) const
+{
+  return (min<PropagateFast>)(Derived::PlainObject::Constant(rows(), cols(), other));
 }
 
 /** \returns an expression of the coefficient-wise max of \c *this and \a other
   *
   * Example: \include Cwise_max.cpp
   * Output: \verbinclude Cwise_max.out
   *
   * \sa min()
   */
-EIGEN_MAKE_CWISE_BINARY_OP(max,max)
+template <int NaNPropagation, typename OtherDerived>
+EIGEN_DEVICE_FUNC
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar,NaNPropagation>, const Derived, const OtherDerived>
+#ifdef EIGEN_PARSED_BY_DOXYGEN
+max
+#else
+(max)
+#endif
+(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const
+{
+  return CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar,NaNPropagation>, const Derived, const OtherDerived>(derived(), other.derived());
+}
+
+template <typename OtherDerived>
+EIGEN_DEVICE_FUNC
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar,PropagateFast>, const Derived, const OtherDerived>
+#ifdef EIGEN_PARSED_BY_DOXYGEN
+max
+#else
+(max)
+#endif
+(const OtherDerived &other) const
+{
+  return (max<PropagateFast>)(other);
+}
 
 /** \returns an expression of the coefficient-wise max of \c *this and scalar \a other
   *
   * \sa min()
   */
+template <int NaNPropagation>
 EIGEN_DEVICE_FUNC
-EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar>, const Derived,
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar,NaNPropagation>, const Derived,
                                         const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> >
 #ifdef EIGEN_PARSED_BY_DOXYGEN
 max
 #else
 (max)
 #endif
 (const Scalar &other) const
 {
-  return (max)(Derived::PlainObject::Constant(rows(), cols(), other));
+  return (max<NaNPropagation>)(Derived::PlainObject::Constant(rows(), cols(), other));
+}
+
+EIGEN_DEVICE_FUNC
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar,PropagateFast>, const Derived,
+                                        const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> >
+#ifdef EIGEN_PARSED_BY_DOXYGEN
+max
+#else
+(max)
+#endif
+(const Scalar &other) const
+{
+  return (max<PropagateFast>)(Derived::PlainObject::Constant(rows(), cols(), other));
+}
+
+/** \returns an expression of the coefficient-wise absdiff of \c *this and \a other
+  *
+  * Example: \include Cwise_absolute_difference.cpp
+  * Output: \verbinclude Cwise_absolute_difference.out
+  *
+  * \sa absolute_difference()
+  */
+EIGEN_MAKE_CWISE_BINARY_OP(absolute_difference,absolute_difference)
+
+/** \returns an expression of the coefficient-wise absolute_difference of \c *this and scalar \a other
+  *
+  * \sa absolute_difference()
+  */
+EIGEN_DEVICE_FUNC
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_absolute_difference_op<Scalar,Scalar>, const Derived,
+                                        const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> >
+#ifdef EIGEN_PARSED_BY_DOXYGEN
+absolute_difference
+#else
+(absolute_difference)
+#endif
+(const Scalar &other) const
+{
+  return (absolute_difference)(Derived::PlainObject::Constant(rows(), cols(), other));
 }
 
 /** \returns an expression of the coefficient-wise power of \c *this to the given array of \a exponents.
   *
   * This function computes the coefficient-wise power.
   *
   * Example: \include Cwise_array_power_array.cpp
@@ -115,15 +217,15 @@
 typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar,Scalar, internal::cmp_ ## COMPARATOR>, const Derived, const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject> > Cmp ## COMPARATOR ## ReturnType; \
 typedef CwiseBinaryOp<internal::scalar_cmp_op<Scalar,Scalar, internal::cmp_ ## COMPARATOR>, const CwiseNullaryOp<internal::scalar_constant_op<Scalar>, PlainObject>, const Derived > RCmp ## COMPARATOR ## ReturnType; \
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const Cmp ## COMPARATOR ## ReturnType \
 OP(const Scalar& s) const { \
   return this->OP(Derived::PlainObject::Constant(rows(), cols(), s)); \
 } \
 EIGEN_DEVICE_FUNC friend EIGEN_STRONG_INLINE const RCmp ## COMPARATOR ## ReturnType \
-OP(const Scalar& s, const Derived& d) { \
+OP(const Scalar& s, const EIGEN_CURRENT_STORAGE_BASE_CLASS<Derived>& d) { \
   return Derived::PlainObject::Constant(d.rows(), d.cols(), s).OP(d); \
 }
 
 #define EIGEN_MAKE_CWISE_COMP_R_OP(OP, R_OP, RCOMPARATOR) \
 template<typename OtherDerived> \
 EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_cmp_op<typename OtherDerived::Scalar, Scalar, internal::cmp_##RCOMPARATOR>, const OtherDerived, const Derived> \
 OP(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const \
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/ArrayCwiseUnaryOps.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/ArrayCwiseUnaryOps.h`

 * *Files 8% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 typedef CwiseUnaryOp<internal::scalar_boolean_not_op<Scalar>, const Derived> BooleanNotReturnType;
 
 typedef CwiseUnaryOp<internal::scalar_exp_op<Scalar>, const Derived> ExpReturnType;
 typedef CwiseUnaryOp<internal::scalar_expm1_op<Scalar>, const Derived> Expm1ReturnType;
 typedef CwiseUnaryOp<internal::scalar_log_op<Scalar>, const Derived> LogReturnType;
 typedef CwiseUnaryOp<internal::scalar_log1p_op<Scalar>, const Derived> Log1pReturnType;
 typedef CwiseUnaryOp<internal::scalar_log10_op<Scalar>, const Derived> Log10ReturnType;
+typedef CwiseUnaryOp<internal::scalar_log2_op<Scalar>, const Derived> Log2ReturnType;
 typedef CwiseUnaryOp<internal::scalar_cos_op<Scalar>, const Derived> CosReturnType;
 typedef CwiseUnaryOp<internal::scalar_sin_op<Scalar>, const Derived> SinReturnType;
 typedef CwiseUnaryOp<internal::scalar_tan_op<Scalar>, const Derived> TanReturnType;
 typedef CwiseUnaryOp<internal::scalar_acos_op<Scalar>, const Derived> AcosReturnType;
 typedef CwiseUnaryOp<internal::scalar_asin_op<Scalar>, const Derived> AsinReturnType;
 typedef CwiseUnaryOp<internal::scalar_atan_op<Scalar>, const Derived> AtanReturnType;
 typedef CwiseUnaryOp<internal::scalar_tanh_op<Scalar>, const Derived> TanhReturnType;
@@ -28,14 +29,15 @@
 typedef CwiseUnaryOp<internal::scalar_asinh_op<Scalar>, const Derived> AsinhReturnType;
 typedef CwiseUnaryOp<internal::scalar_acosh_op<Scalar>, const Derived> AcoshReturnType;
 #endif
 typedef CwiseUnaryOp<internal::scalar_cosh_op<Scalar>, const Derived> CoshReturnType;
 typedef CwiseUnaryOp<internal::scalar_square_op<Scalar>, const Derived> SquareReturnType;
 typedef CwiseUnaryOp<internal::scalar_cube_op<Scalar>, const Derived> CubeReturnType;
 typedef CwiseUnaryOp<internal::scalar_round_op<Scalar>, const Derived> RoundReturnType;
+typedef CwiseUnaryOp<internal::scalar_rint_op<Scalar>, const Derived> RintReturnType;
 typedef CwiseUnaryOp<internal::scalar_floor_op<Scalar>, const Derived> FloorReturnType;
 typedef CwiseUnaryOp<internal::scalar_ceil_op<Scalar>, const Derived> CeilReturnType;
 typedef CwiseUnaryOp<internal::scalar_isnan_op<Scalar>, const Derived> IsNaNReturnType;
 typedef CwiseUnaryOp<internal::scalar_isinf_op<Scalar>, const Derived> IsInfReturnType;
 typedef CwiseUnaryOp<internal::scalar_isfinite_op<Scalar>, const Derived> IsFiniteReturnType;
 
 /** \returns an expression of the coefficient-wise absolute value of \c *this
@@ -154,14 +156,26 @@
 EIGEN_DEVICE_FUNC
 inline const Log10ReturnType
 log10() const
 {
   return Log10ReturnType(derived());
 }
 
+/** \returns an expression of the coefficient-wise base-2 logarithm of *this.
+  *
+  * This function computes the coefficient-wise base-2 logarithm.
+  *
+  */
+EIGEN_DEVICE_FUNC
+inline const Log2ReturnType
+log2() const
+{
+  return Log2ReturnType(derived());
+}
+
 /** \returns an expression of the coefficient-wise square root of *this.
   *
   * This function computes the coefficient-wise square root. The function MatrixBase::sqrt() in the
   * unsupported module MatrixFunctions computes the matrix square root.
   *
   * Example: \include Cwise_sqrt.cpp
   * Output: \verbinclude Cwise_sqrt.out
@@ -423,14 +437,28 @@
 EIGEN_DEVICE_FUNC
 inline const CubeReturnType
 cube() const
 {
   return CubeReturnType(derived());
 }
 
+/** \returns an expression of the coefficient-wise rint of *this.
+  *
+  * Example: \include Cwise_rint.cpp
+  * Output: \verbinclude Cwise_rint.out
+  *
+  * \sa <a href="group__CoeffwiseMathFunctions.html#cwisetable_rint">Math functions</a>, ceil(), floor()
+  */
+EIGEN_DEVICE_FUNC
+inline const RintReturnType
+rint() const
+{
+  return RintReturnType(derived());
+}
+
 /** \returns an expression of the coefficient-wise round of *this.
   *
   * Example: \include Cwise_round.cpp
   * Output: \verbinclude Cwise_round.out
   *
   * \sa <a href="group__CoeffwiseMathFunctions.html#cwisetable_round">Math functions</a>, ceil(), floor()
   */
@@ -465,14 +493,53 @@
 EIGEN_DEVICE_FUNC
 inline const CeilReturnType
 ceil() const
 {
   return CeilReturnType(derived());
 }
 
+template<int N> struct ShiftRightXpr {
+  typedef CwiseUnaryOp<internal::scalar_shift_right_op<Scalar, N>, const Derived> Type;
+};
+
+/** \returns an expression of \c *this with the \a Scalar type arithmetically
+  * shifted right by \a N bit positions.
+  *
+  * The template parameter \a N specifies the number of bit positions to shift.
+  * 
+  * \sa shiftLeft()
+  */
+template<int N>
+EIGEN_DEVICE_FUNC
+typename ShiftRightXpr<N>::Type
+shiftRight() const
+{
+  return typename ShiftRightXpr<N>::Type(derived());
+}
+
+
+template<int N> struct ShiftLeftXpr {
+  typedef CwiseUnaryOp<internal::scalar_shift_left_op<Scalar, N>, const Derived> Type;
+};
+
+/** \returns an expression of \c *this with the \a Scalar type logically
+  * shifted left by \a N bit positions.
+  *
+  * The template parameter \a N specifies the number of bit positions to shift.
+  *
+  * \sa shiftRight()
+  */
+template<int N>
+EIGEN_DEVICE_FUNC
+typename ShiftLeftXpr<N>::Type
+shiftLeft() const
+{
+  return typename ShiftLeftXpr<N>::Type(derived());
+}
+
 /** \returns an expression of the coefficient-wise isnan of *this.
   *
   * Example: \include Cwise_isNaN.cpp
   * Output: \verbinclude Cwise_isNaN.out
   *
   * \sa isfinite(), isinf()
   */
@@ -532,22 +599,20 @@
 
 // --- SpecialFunctions module ---
 
 typedef CwiseUnaryOp<internal::scalar_lgamma_op<Scalar>, const Derived> LgammaReturnType;
 typedef CwiseUnaryOp<internal::scalar_digamma_op<Scalar>, const Derived> DigammaReturnType;
 typedef CwiseUnaryOp<internal::scalar_erf_op<Scalar>, const Derived> ErfReturnType;
 typedef CwiseUnaryOp<internal::scalar_erfc_op<Scalar>, const Derived> ErfcReturnType;
+typedef CwiseUnaryOp<internal::scalar_ndtri_op<Scalar>, const Derived> NdtriReturnType;
 
 /** \cpp11 \returns an expression of the coefficient-wise ln(|gamma(*this)|).
   *
   * \specialfunctions_module
   *
-  * Example: \include Cwise_lgamma.cpp
-  * Output: \verbinclude Cwise_lgamma.out
-  *
   * \note This function supports only float and double scalar types in c++11 mode. To support other scalar types,
   * or float/double in non c++11 mode, the user has to provide implementations of lgamma(T) for any scalar
   * type T to be supported.
   *
   * \sa <a href="group__CoeffwiseMathFunctions.html#cwisetable_lgamma">Math functions</a>, digamma()
   */
 EIGEN_DEVICE_FUNC
@@ -575,17 +640,14 @@
 }
 
 /** \cpp11 \returns an expression of the coefficient-wise Gauss error
   * function of *this.
   *
   * \specialfunctions_module
   *
-  * Example: \include Cwise_erf.cpp
-  * Output: \verbinclude Cwise_erf.out
-  *
   * \note This function supports only float and double scalar types in c++11 mode. To support other scalar types,
   * or float/double in non c++11 mode, the user has to provide implementations of erf(T) for any scalar
   * type T to be supported.
   *
   * \sa <a href="group__CoeffwiseMathFunctions.html#cwisetable_erf">Math functions</a>, erfc()
   */
 EIGEN_DEVICE_FUNC
@@ -596,22 +658,39 @@
 }
 
 /** \cpp11 \returns an expression of the coefficient-wise Complementary error
   * function of *this.
   *
   * \specialfunctions_module
   *
-  * Example: \include Cwise_erfc.cpp
-  * Output: \verbinclude Cwise_erfc.out
-  *
   * \note This function supports only float and double scalar types in c++11 mode. To support other scalar types,
   * or float/double in non c++11 mode, the user has to provide implementations of erfc(T) for any scalar
   * type T to be supported.
   *
   * \sa <a href="group__CoeffwiseMathFunctions.html#cwisetable_erfc">Math functions</a>, erf()
   */
 EIGEN_DEVICE_FUNC
 inline const ErfcReturnType
 erfc() const
 {
   return ErfcReturnType(derived());
 }
+
+/** \returns an expression of the coefficient-wise inverse of the CDF of the Normal distribution function
+  * function of *this.
+  *
+  * \specialfunctions_module
+  * 
+  * In other words, considering `x = ndtri(y)`, it returns the argument, x, for which the area under the
+  * Gaussian probability density function (integrated from minus infinity to x) is equal to y.
+  *
+  * \note This function supports only float and double scalar types. To support other scalar types,
+  * the user has to provide implementations of ndtri(T) for any scalar type T to be supported.
+  *
+  * \sa <a href="group__CoeffwiseMathFunctions.html#cwisetable_ndtri">Math functions</a>
+  */
+EIGEN_DEVICE_FUNC
+inline const NdtriReturnType
+ndtri() const
+{
+  return NdtriReturnType(derived());
+}
```

#### html2text {}

```diff
@@ -8,14 +8,15 @@
 Scalar>, const Derived> InverseReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> BooleanNotReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> ExpReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> Expm1ReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> LogReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> Log1pReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> Log10ReturnType; typedef CwiseUnaryOp
+Scalar>, const Derived> Log2ReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> CosReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> SinReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> TanReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> AcosReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> AsinReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> AtanReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> TanhReturnType; typedef CwiseUnaryOp
@@ -25,14 +26,15 @@
 Scalar>, const Derived> AtanhReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> AsinhReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> AcoshReturnType; #endif typedef CwiseUnaryOp
 Scalar>, const Derived> CoshReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> SquareReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> CubeReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> RoundReturnType; typedef CwiseUnaryOp
+Scalar>, const Derived> RintReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> FloorReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> CeilReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> IsNaNReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> IsInfReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> IsFiniteReturnType; /** \returns an expression of the
 coefficient-wise absolute value of \c *this * * Example: \include Cwise_abs.cpp
 * Output: \verbinclude Cwise_abs.out * * \sa Math_functions, abs2() */
@@ -69,50 +71,53 @@
 functions, log() */ EIGEN_DEVICE_FUNC inline const Log1pReturnType log1p()
 const { return Log1pReturnType(derived()); } /** \returns an expression of the
 coefficient-wise base-10 logarithm of *this. * * This function computes the
 coefficient-wise base-10 logarithm. * * Example: \include Cwise_log10.cpp *
 Output: \verbinclude Cwise_log10.out * * \sa Math_functions, log() */
 EIGEN_DEVICE_FUNC inline const Log10ReturnType log10() const { return
 Log10ReturnType(derived()); } /** \returns an expression of the coefficient-
-wise square root of *this. * * This function computes the coefficient-wise
-square root. The function MatrixBase::sqrt() in the * unsupported module
-MatrixFunctions computes the matrix square root. * * Example: \include
-Cwise_sqrt.cpp * Output: \verbinclude Cwise_sqrt.out * * \sa Math_functions,
-pow(), square() */ EIGEN_DEVICE_FUNC inline const SqrtReturnType sqrt() const
-{ return SqrtReturnType(derived()); } /** \returns an expression of the
-coefficient-wise inverse square root of *this. * * This function computes the
-coefficient-wise inverse square root. * * Example: \include Cwise_sqrt.cpp *
-Output: \verbinclude Cwise_sqrt.out * * \sa pow(), square() */
-EIGEN_DEVICE_FUNC inline const RsqrtReturnType rsqrt() const { return
-RsqrtReturnType(derived()); } /** \returns an expression of the coefficient-
-wise signum of *this. * * This function computes the coefficient-wise signum. *
-* Example: \include Cwise_sign.cpp * Output: \verbinclude Cwise_sign.out * *
-\sa pow(), square() */ EIGEN_DEVICE_FUNC inline const SignReturnType sign()
-const { return SignReturnType(derived()); } /** \returns an expression of the
-coefficient-wise cosine of *this. * * This function computes the coefficient-
-wise cosine. The function MatrixBase::cos() in the * unsupported module
-MatrixFunctions computes the matrix cosine. * * Example: \include Cwise_cos.cpp
-* Output: \verbinclude Cwise_cos.out * * \sa Math_functions, sin(), acos() */
-EIGEN_DEVICE_FUNC inline const CosReturnType cos() const { return CosReturnType
-(derived()); } /** \returns an expression of the coefficient-wise sine of
-*this. * * This function computes the coefficient-wise sine. The function
-MatrixBase::sin() in the * unsupported module MatrixFunctions computes the
-matrix sine. * * Example: \include Cwise_sin.cpp * Output: \verbinclude
-Cwise_sin.out * * \sa Math_functions, cos(), asin() */ EIGEN_DEVICE_FUNC inline
-const SinReturnType sin() const { return SinReturnType(derived()); } /**
-\returns an expression of the coefficient-wise tan of *this. * * Example:
-\include Cwise_tan.cpp * Output: \verbinclude Cwise_tan.out * * \sa Math
-functions, cos(), sin() */ EIGEN_DEVICE_FUNC inline const TanReturnType tan()
-const { return TanReturnType(derived()); } /** \returns an expression of the
-coefficient-wise arc tan of *this. * * Example: \include Cwise_atan.cpp *
-Output: \verbinclude Cwise_atan.out * * \sa Math_functions, tan(), asin(), acos
-() */ EIGEN_DEVICE_FUNC inline const AtanReturnType atan() const { return
-AtanReturnType(derived()); } /** \returns an expression of the coefficient-wise
-arc cosine of *this. * * Example: \include Cwise_acos.cpp * Output:
-\verbinclude Cwise_acos.out * * \sa Math_functions, cos(), asin() */
+wise base-2 logarithm of *this. * * This function computes the coefficient-wise
+base-2 logarithm. * */ EIGEN_DEVICE_FUNC inline const Log2ReturnType log2()
+const { return Log2ReturnType(derived()); } /** \returns an expression of the
+coefficient-wise square root of *this. * * This function computes the
+coefficient-wise square root. The function MatrixBase::sqrt() in the *
+unsupported module MatrixFunctions computes the matrix square root. * *
+Example: \include Cwise_sqrt.cpp * Output: \verbinclude Cwise_sqrt.out * * \sa
+Math_functions, pow(), square() */ EIGEN_DEVICE_FUNC inline const
+SqrtReturnType sqrt() const { return SqrtReturnType(derived()); } /** \returns
+an expression of the coefficient-wise inverse square root of *this. * * This
+function computes the coefficient-wise inverse square root. * * Example:
+\include Cwise_sqrt.cpp * Output: \verbinclude Cwise_sqrt.out * * \sa pow(),
+square() */ EIGEN_DEVICE_FUNC inline const RsqrtReturnType rsqrt() const
+{ return RsqrtReturnType(derived()); } /** \returns an expression of the
+coefficient-wise signum of *this. * * This function computes the coefficient-
+wise signum. * * Example: \include Cwise_sign.cpp * Output: \verbinclude
+Cwise_sign.out * * \sa pow(), square() */ EIGEN_DEVICE_FUNC inline const
+SignReturnType sign() const { return SignReturnType(derived()); } /** \returns
+an expression of the coefficient-wise cosine of *this. * * This function
+computes the coefficient-wise cosine. The function MatrixBase::cos() in the *
+unsupported module MatrixFunctions computes the matrix cosine. * * Example:
+\include Cwise_cos.cpp * Output: \verbinclude Cwise_cos.out * * \sa Math
+functions, sin(), acos() */ EIGEN_DEVICE_FUNC inline const CosReturnType cos()
+const { return CosReturnType(derived()); } /** \returns an expression of the
+coefficient-wise sine of *this. * * This function computes the coefficient-wise
+sine. The function MatrixBase::sin() in the * unsupported module
+MatrixFunctions computes the matrix sine. * * Example: \include Cwise_sin.cpp *
+Output: \verbinclude Cwise_sin.out * * \sa Math_functions, cos(), asin() */
+EIGEN_DEVICE_FUNC inline const SinReturnType sin() const { return SinReturnType
+(derived()); } /** \returns an expression of the coefficient-wise tan of *this.
+* * Example: \include Cwise_tan.cpp * Output: \verbinclude Cwise_tan.out * *
+\sa Math_functions, cos(), sin() */ EIGEN_DEVICE_FUNC inline const
+TanReturnType tan() const { return TanReturnType(derived()); } /** \returns an
+expression of the coefficient-wise arc tan of *this. * * Example: \include
+Cwise_atan.cpp * Output: \verbinclude Cwise_atan.out * * \sa Math_functions,
+tan(), asin(), acos() */ EIGEN_DEVICE_FUNC inline const AtanReturnType atan()
+const { return AtanReturnType(derived()); } /** \returns an expression of the
+coefficient-wise arc cosine of *this. * * Example: \include Cwise_acos.cpp *
+Output: \verbinclude Cwise_acos.out * * \sa Math_functions, cos(), asin() */
 EIGEN_DEVICE_FUNC inline const AcosReturnType acos() const { return
 AcosReturnType(derived()); } /** \returns an expression of the coefficient-wise
 arc sine of *this. * * Example: \include Cwise_asin.cpp * Output: \verbinclude
 Cwise_asin.out * * \sa Math_functions, sin(), acos() */ EIGEN_DEVICE_FUNC
 inline const AsinReturnType asin() const { return AsinReturnType(derived()); }
 /** \returns an expression of the coefficient-wise hyperbolic tan of *this. * *
 Example: \include Cwise_tanh.cpp * Output: \verbinclude Cwise_tanh.out * * \sa
@@ -146,26 +151,42 @@
 \include Cwise_square.cpp * Output: \verbinclude Cwise_square.out * * \sa Math
 functions, abs2(), cube(), pow() */ EIGEN_DEVICE_FUNC inline const
 SquareReturnType square() const { return SquareReturnType(derived()); } /**
 \returns an expression of the coefficient-wise cube of *this. * * Example:
 \include Cwise_cube.cpp * Output: \verbinclude Cwise_cube.out * * \sa Math
 functions, square(), pow() */ EIGEN_DEVICE_FUNC inline const CubeReturnType
 cube() const { return CubeReturnType(derived()); } /** \returns an expression
-of the coefficient-wise round of *this. * * Example: \include Cwise_round.cpp *
-Output: \verbinclude Cwise_round.out * * \sa Math_functions, ceil(), floor() */
-EIGEN_DEVICE_FUNC inline const RoundReturnType round() const { return
-RoundReturnType(derived()); } /** \returns an expression of the coefficient-
-wise floor of *this. * * Example: \include Cwise_floor.cpp * Output:
-\verbinclude Cwise_floor.out * * \sa Math_functions, ceil(), round() */
-EIGEN_DEVICE_FUNC inline const FloorReturnType floor() const { return
-FloorReturnType(derived()); } /** \returns an expression of the coefficient-
-wise ceil of *this. * * Example: \include Cwise_ceil.cpp * Output: \verbinclude
-Cwise_ceil.out * * \sa Math_functions, floor(), round() */ EIGEN_DEVICE_FUNC
-inline const CeilReturnType ceil() const { return CeilReturnType(derived()); }
-/** \returns an expression of the coefficient-wise isnan of *this. * * Example:
+of the coefficient-wise rint of *this. * * Example: \include Cwise_rint.cpp *
+Output: \verbinclude Cwise_rint.out * * \sa Math_functions, ceil(), floor() */
+EIGEN_DEVICE_FUNC inline const RintReturnType rint() const { return
+RintReturnType(derived()); } /** \returns an expression of the coefficient-wise
+round of *this. * * Example: \include Cwise_round.cpp * Output: \verbinclude
+Cwise_round.out * * \sa Math_functions, ceil(), floor() */ EIGEN_DEVICE_FUNC
+inline const RoundReturnType round() const { return RoundReturnType(derived());
+} /** \returns an expression of the coefficient-wise floor of *this. * *
+Example: \include Cwise_floor.cpp * Output: \verbinclude Cwise_floor.out * *
+\sa Math_functions, ceil(), round() */ EIGEN_DEVICE_FUNC inline const
+FloorReturnType floor() const { return FloorReturnType(derived()); } /**
+\returns an expression of the coefficient-wise ceil of *this. * * Example:
+\include Cwise_ceil.cpp * Output: \verbinclude Cwise_ceil.out * * \sa Math
+functions, floor(), round() */ EIGEN_DEVICE_FUNC inline const CeilReturnType
+ceil() const { return CeilReturnType(derived()); } template struct
+ShiftRightXpr { typedef CwiseUnaryOp
+Scalar, N>, const Derived> Type; }; /** \returns an expression of \c *this with
+the \a Scalar type arithmetically * shifted right by \a N bit positions. * *
+The template parameter \a N specifies the number of bit positions to shift. * *
+\sa shiftLeft() */ template EIGEN_DEVICE_FUNC typename ShiftRightXpr::Type
+shiftRight() const { return typename ShiftRightXpr::Type(derived()); } template
+struct ShiftLeftXpr { typedef CwiseUnaryOp
+Scalar, N>, const Derived> Type; }; /** \returns an expression of \c *this with
+the \a Scalar type logically * shifted left by \a N bit positions. * * The
+template parameter \a N specifies the number of bit positions to shift. * * \sa
+shiftRight() */ template EIGEN_DEVICE_FUNC typename ShiftLeftXpr::Type
+shiftLeft() const { return typename ShiftLeftXpr::Type(derived()); } /**
+\returns an expression of the coefficient-wise isnan of *this. * * Example:
 \include Cwise_isNaN.cpp * Output: \verbinclude Cwise_isNaN.out * * \sa
 isfinite(), isinf() */ EIGEN_DEVICE_FUNC inline const IsNaNReturnType isNaN()
 const { return IsNaNReturnType(derived()); } /** \returns an expression of the
 coefficient-wise isinf of *this. * * Example: \include Cwise_isInf.cpp *
 Output: \verbinclude Cwise_isInf.out * * \sa isnan(), isfinite() */
 EIGEN_DEVICE_FUNC inline const IsInfReturnType isInf() const { return
 IsInfReturnType(derived()); } /** \returns an expression of the coefficient-
@@ -179,37 +200,44 @@
 operator!() const { EIGEN_STATIC_ASSERT((internal::is_same
 Scalar>::value), THIS_METHOD_IS_ONLY_FOR_EXPRESSIONS_OF_BOOL); return
 BooleanNotReturnType(derived()); } // --- SpecialFunctions module --- typedef
 CwiseUnaryOp
 Scalar>, const Derived> LgammaReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> DigammaReturnType; typedef CwiseUnaryOp
 Scalar>, const Derived> ErfReturnType; typedef CwiseUnaryOp
-Scalar>, const Derived> ErfcReturnType; /** \cpp11 \returns an expression of
-the coefficient-wise ln(|gamma(*this)|). * * \specialfunctions_module * *
-Example: \include Cwise_lgamma.cpp * Output: \verbinclude Cwise_lgamma.out * *
-\note This function supports only float and double scalar types in c++11 mode.
-To support other scalar types, * or float/double in non c++11 mode, the user
-has to provide implementations of lgamma(T) for any scalar * type T to be
+Scalar>, const Derived> ErfcReturnType; typedef CwiseUnaryOp
+Scalar>, const Derived> NdtriReturnType; /** \cpp11 \returns an expression of
+the coefficient-wise ln(|gamma(*this)|). * * \specialfunctions_module * * \note
+This function supports only float and double scalar types in c++11 mode. To
+support other scalar types, * or float/double in non c++11 mode, the user has
+to provide implementations of lgamma(T) for any scalar * type T to be
 supported. * * \sa Math_functions, digamma() */ EIGEN_DEVICE_FUNC inline const
 LgammaReturnType lgamma() const { return LgammaReturnType(derived()); } /**
 \returns an expression of the coefficient-wise digamma (psi, derivative of
 lgamma). * * \specialfunctions_module * * \note This function supports only
 float and double scalar types. To support other scalar types, * the user has to
 provide implementations of digamma(T) for any scalar * type T to be supported.
 * * \sa Math_functions, Eigen::digamma(), Eigen::polygamma(), lgamma() */
 EIGEN_DEVICE_FUNC inline const DigammaReturnType digamma() const { return
 DigammaReturnType(derived()); } /** \cpp11 \returns an expression of the
 coefficient-wise Gauss error * function of *this. * * \specialfunctions_module
-* * Example: \include Cwise_erf.cpp * Output: \verbinclude Cwise_erf.out * *
-\note This function supports only float and double scalar types in c++11 mode.
-To support other scalar types, * or float/double in non c++11 mode, the user
-has to provide implementations of erf(T) for any scalar * type T to be
+* * \note This function supports only float and double scalar types in c++11
+mode. To support other scalar types, * or float/double in non c++11 mode, the
+user has to provide implementations of erf(T) for any scalar * type T to be
 supported. * * \sa Math_functions, erfc() */ EIGEN_DEVICE_FUNC inline const
 ErfReturnType erf() const { return ErfReturnType(derived()); } /** \cpp11
 \returns an expression of the coefficient-wise Complementary error * function
-of *this. * * \specialfunctions_module * * Example: \include Cwise_erfc.cpp *
-Output: \verbinclude Cwise_erfc.out * * \note This function supports only float
-and double scalar types in c++11 mode. To support other scalar types, * or
-float/double in non c++11 mode, the user has to provide implementations of erfc
-(T) for any scalar * type T to be supported. * * \sa Math_functions, erf() */
-EIGEN_DEVICE_FUNC inline const ErfcReturnType erfc() const { return
-ErfcReturnType(derived()); }
+of *this. * * \specialfunctions_module * * \note This function supports only
+float and double scalar types in c++11 mode. To support other scalar types, *
+or float/double in non c++11 mode, the user has to provide implementations of
+erfc(T) for any scalar * type T to be supported. * * \sa Math_functions, erf()
+*/ EIGEN_DEVICE_FUNC inline const ErfcReturnType erfc() const { return
+ErfcReturnType(derived()); } /** \returns an expression of the coefficient-wise
+inverse of the CDF of the Normal distribution function * function of *this. * *
+\specialfunctions_module * * In other words, considering `x = ndtri(y)`, it
+returns the argument, x, for which the area under the * Gaussian probability
+density function (integrated from minus infinity to x) is equal to y. * * \note
+This function supports only float and double scalar types. To support other
+scalar types, * the user has to provide implementations of ndtri(T) for any
+scalar type T to be supported. * * \sa Math_functions */ EIGEN_DEVICE_FUNC
+inline const NdtriReturnType ndtri() const { return NdtriReturnType(derived());
+}
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/BlockMethods.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/BlockMethods.h`

 * *Files 0% similar despite different names*

```diff
@@ -1433,11 +1433,10 @@
   return typename internal::conditional<Direction==Vertical,ConstColXpr,ConstRowXpr>::type(derived(),i);
 }
 
 /** \returns the number of subvectors (rows or columns) in the direction \c Direction
   * \sa subVector(Index)
   */
 template<DirectionType Direction>
-EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE
+EIGEN_DEVICE_FUNC EIGEN_STRONG_INLINE EIGEN_CONSTEXPR
 Index subVectors() const
 { return (Direction==Vertical)?cols():rows(); }
-
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/CommonCwiseBinaryOps.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/CommonCwiseBinaryOps.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/CommonCwiseUnaryOps.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/CommonCwiseUnaryOps.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/IndexedViewMethods.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/IndexedViewMethods.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/MatrixCwiseBinaryOps.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/MatrixCwiseBinaryOps.h`

 * *Files 21% similar despite different names*

```diff
@@ -35,18 +35,18 @@
   * Example: \include MatrixBase_cwiseEqual.cpp
   * Output: \verbinclude MatrixBase_cwiseEqual.out
   *
   * \sa cwiseNotEqual(), isApprox(), isMuchSmallerThan()
   */
 template<typename OtherDerived>
 EIGEN_DEVICE_FUNC
-inline const CwiseBinaryOp<std::equal_to<Scalar>, const Derived, const OtherDerived>
+inline const CwiseBinaryOp<numext::equal_to<Scalar>, const Derived, const OtherDerived>
 cwiseEqual(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const
 {
-  return CwiseBinaryOp<std::equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
+  return CwiseBinaryOp<numext::equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
 }
 
 /** \returns an expression of the coefficient-wise != operator of *this and \a other
   *
   * \warning this performs an exact comparison, which is generally a bad idea with floating-point types.
   * In order to check for equality between two vectors or matrices with floating-point coefficients, it is
   * generally a far better idea to use a fuzzy comparison as provided by isApprox() and
@@ -55,70 +55,102 @@
   * Example: \include MatrixBase_cwiseNotEqual.cpp
   * Output: \verbinclude MatrixBase_cwiseNotEqual.out
   *
   * \sa cwiseEqual(), isApprox(), isMuchSmallerThan()
   */
 template<typename OtherDerived>
 EIGEN_DEVICE_FUNC
-inline const CwiseBinaryOp<std::not_equal_to<Scalar>, const Derived, const OtherDerived>
+inline const CwiseBinaryOp<numext::not_equal_to<Scalar>, const Derived, const OtherDerived>
 cwiseNotEqual(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const
 {
-  return CwiseBinaryOp<std::not_equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
+  return CwiseBinaryOp<numext::not_equal_to<Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
 }
 
 /** \returns an expression of the coefficient-wise min of *this and \a other
   *
   * Example: \include MatrixBase_cwiseMin.cpp
   * Output: \verbinclude MatrixBase_cwiseMin.out
   *
   * \sa class CwiseBinaryOp, max()
   */
+template<int NaNPropagation, typename OtherDerived>
+EIGEN_DEVICE_FUNC
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar,NaNPropagation>, const Derived, const OtherDerived>
+cwiseMin(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const
+{
+  return CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar,NaNPropagation>, const Derived, const OtherDerived>(derived(), other.derived());
+}
+
 template<typename OtherDerived>
 EIGEN_DEVICE_FUNC
-EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar>, const Derived, const OtherDerived>
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar,PropagateFast>, const Derived, const OtherDerived>
 cwiseMin(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const
 {
-  return CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
+  return cwiseMin<PropagateFast>(other);
 }
 
 /** \returns an expression of the coefficient-wise min of *this and scalar \a other
   *
   * \sa class CwiseBinaryOp, min()
   */
+template<int NaNPropagation>
+EIGEN_DEVICE_FUNC
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar,NaNPropagation>, const Derived, const ConstantReturnType>
+cwiseMin(const Scalar &other) const
+{
+  return cwiseMin<NaNPropagation>(Derived::Constant(rows(), cols(), other));
+}
+
 EIGEN_DEVICE_FUNC
-EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar>, const Derived, const ConstantReturnType>
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_min_op<Scalar,Scalar,PropagateFast>, const Derived, const ConstantReturnType>
 cwiseMin(const Scalar &other) const
 {
-  return cwiseMin(Derived::Constant(rows(), cols(), other));
+  return cwiseMin<PropagateFast>(Derived::Constant(rows(), cols(), other));
 }
 
 /** \returns an expression of the coefficient-wise max of *this and \a other
   *
   * Example: \include MatrixBase_cwiseMax.cpp
   * Output: \verbinclude MatrixBase_cwiseMax.out
   *
   * \sa class CwiseBinaryOp, min()
   */
+template<int NaNPropagation, typename OtherDerived>
+EIGEN_DEVICE_FUNC
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar,NaNPropagation>, const Derived, const OtherDerived>
+cwiseMax(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const
+{
+  return CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar,NaNPropagation>, const Derived, const OtherDerived>(derived(), other.derived());
+}
+
 template<typename OtherDerived>
 EIGEN_DEVICE_FUNC
-EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar>, const Derived, const OtherDerived>
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar,PropagateFast>, const Derived, const OtherDerived>
 cwiseMax(const EIGEN_CURRENT_STORAGE_BASE_CLASS<OtherDerived> &other) const
 {
-  return CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar>, const Derived, const OtherDerived>(derived(), other.derived());
+  return cwiseMax<PropagateFast>(other);
 }
 
 /** \returns an expression of the coefficient-wise max of *this and scalar \a other
   *
   * \sa class CwiseBinaryOp, min()
   */
+template<int NaNPropagation>
+EIGEN_DEVICE_FUNC
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar,NaNPropagation>, const Derived, const ConstantReturnType>
+cwiseMax(const Scalar &other) const
+{
+  return cwiseMax<NaNPropagation>(Derived::Constant(rows(), cols(), other));
+}
+
 EIGEN_DEVICE_FUNC
-EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar>, const Derived, const ConstantReturnType>
+EIGEN_STRONG_INLINE const CwiseBinaryOp<internal::scalar_max_op<Scalar,Scalar,PropagateFast>, const Derived, const ConstantReturnType>
 cwiseMax(const Scalar &other) const
 {
-  return cwiseMax(Derived::Constant(rows(), cols(), other));
+  return cwiseMax<PropagateFast>(Derived::Constant(rows(), cols(), other));
 }
 
 
 /** \returns an expression of the coefficient-wise quotient of *this and \a other
   *
   * Example: \include MatrixBase_cwiseQuotient.cpp
   * Output: \verbinclude MatrixBase_cwiseQuotient.out
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/MatrixCwiseUnaryOps.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/MatrixCwiseUnaryOps.h`

 * *Files 7% similar despite different names*

```diff
@@ -10,14 +10,15 @@
 
 // This file is included into the body of the base classes supporting matrix specific coefficient-wise functions.
 // This include MatrixBase and SparseMatrixBase.
 
 
 typedef CwiseUnaryOp<internal::scalar_abs_op<Scalar>, const Derived> CwiseAbsReturnType;
 typedef CwiseUnaryOp<internal::scalar_abs2_op<Scalar>, const Derived> CwiseAbs2ReturnType;
+typedef CwiseUnaryOp<internal::scalar_arg_op<Scalar>, const Derived> CwiseArgReturnType;
 typedef CwiseUnaryOp<internal::scalar_sqrt_op<Scalar>, const Derived> CwiseSqrtReturnType;
 typedef CwiseUnaryOp<internal::scalar_sign_op<Scalar>, const Derived> CwiseSignReturnType;
 typedef CwiseUnaryOp<internal::scalar_inverse_op<Scalar>, const Derived> CwiseInverseReturnType;
 
 /// \returns an expression of the coefficient-wise absolute value of \c *this
 ///
 /// Example: \include MatrixBase_cwiseAbs.cpp
@@ -78,8 +79,17 @@
 ///
 /// \sa cwiseProduct()
 ///
 EIGEN_DEVICE_FUNC
 inline const CwiseInverseReturnType
 cwiseInverse() const { return CwiseInverseReturnType(derived()); }
 
+/// \returns an expression of the coefficient-wise phase angle of \c *this
+///
+/// Example: \include MatrixBase_cwiseArg.cpp
+/// Output: \verbinclude MatrixBase_cwiseArg.out
+///
+EIGEN_DOC_UNARY_ADDONS(cwiseArg,arg)
 
+EIGEN_DEVICE_FUNC
+inline const CwiseArgReturnType
+cwiseArg() const { return CwiseArgReturnType(derived()); }
```

### Comparing `affine_transform-0.2.9/extern/eigen/Eigen/src/plugins/ReshapedMethods.h` & `affine_transform-0.3.0/extern/eigen/Eigen/src/plugins/ReshapedMethods.h`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/attr.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/attr.h`

 * *Files 22% similar despite different names*

```diff
@@ -6,73 +6,121 @@
 
     All rights reserved. Use of this source code is governed by a
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
+#include "detail/common.h"
 #include "cast.h"
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+#include <functional>
+
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
 
 /// \addtogroup annotations
 /// @{
 
 /// Annotation for methods
-struct is_method { handle class_; is_method(const handle &c) : class_(c) { } };
+struct is_method {
+    handle class_;
+    explicit is_method(const handle &c) : class_(c) {}
+};
 
 /// Annotation for operators
-struct is_operator { };
+struct is_operator {};
+
+/// Annotation for classes that cannot be subclassed
+struct is_final {};
 
 /// Annotation for parent scope
-struct scope { handle value; scope(const handle &s) : value(s) { } };
+struct scope {
+    handle value;
+    explicit scope(const handle &s) : value(s) {}
+};
 
 /// Annotation for documentation
-struct doc { const char *value; doc(const char *value) : value(value) { } };
+struct doc {
+    const char *value;
+    explicit doc(const char *value) : value(value) {}
+};
 
 /// Annotation for function names
-struct name { const char *value; name(const char *value) : value(value) { } };
+struct name {
+    const char *value;
+    explicit name(const char *value) : value(value) {}
+};
 
 /// Annotation indicating that a function is an overload associated with a given "sibling"
-struct sibling { handle value; sibling(const handle &value) : value(value.ptr()) { } };
+struct sibling {
+    handle value;
+    explicit sibling(const handle &value) : value(value.ptr()) {}
+};
 
 /// Annotation indicating that a class derives from another given type
-template <typename T> struct base {
-    PYBIND11_DEPRECATED("base<T>() was deprecated in favor of specifying 'T' as a template argument to class_")
-    base() { }
+template <typename T>
+struct base {
+
+    PYBIND11_DEPRECATED(
+        "base<T>() was deprecated in favor of specifying 'T' as a template argument to class_")
+    base() = default;
 };
 
 /// Keep patient alive while nurse lives
-template <size_t Nurse, size_t Patient> struct keep_alive { };
+template <size_t Nurse, size_t Patient>
+struct keep_alive {};
 
 /// Annotation indicating that a class is involved in a multiple inheritance relationship
-struct multiple_inheritance { };
+struct multiple_inheritance {};
 
 /// Annotation which enables dynamic attributes, i.e. adds `__dict__` to a class
-struct dynamic_attr { };
+struct dynamic_attr {};
 
 /// Annotation which enables the buffer protocol for a type
-struct buffer_protocol { };
+struct buffer_protocol {};
 
 /// Annotation which requests that a special metaclass is created for a type
 struct metaclass {
     handle value;
 
     PYBIND11_DEPRECATED("py::metaclass() is no longer required. It's turned on by default now.")
-    metaclass() {}
+    metaclass() = default;
 
     /// Override pybind11's default metaclass
-    explicit metaclass(handle value) : value(value) { }
+    explicit metaclass(handle value) : value(value) {}
+};
+
+/// Specifies a custom callback with signature `void (PyHeapTypeObject*)` that
+/// may be used to customize the Python type.
+///
+/// The callback is invoked immediately before `PyType_Ready`.
+///
+/// Note: This is an advanced interface, and uses of it may require changes to
+/// work with later versions of pybind11.  You may wish to consult the
+/// implementation of `make_new_python_type` in `detail/classes.h` to understand
+/// the context in which the callback will be run.
+struct custom_type_setup {
+    using callback = std::function<void(PyHeapTypeObject *heap_type)>;
+
+    explicit custom_type_setup(callback value) : value(std::move(value)) {}
+
+    callback value;
 };
 
 /// Annotation that marks a class as local to the module:
-struct module_local { const bool value; constexpr module_local(bool v = true) : value(v) { } };
+struct module_local {
+    const bool value;
+    constexpr explicit module_local(bool v = true) : value(v) {}
+};
 
 /// Annotation to mark enums as an arithmetic type
-struct arithmetic { };
+struct arithmetic {};
+
+/// Mark a function for addition at the beginning of the existing overload chain instead of the end
+struct prepend {};
 
 /** \rst
     A call policy which places one or more guard variables (``Ts...``) around the function call.
 
     For example, this definition:
 
     .. code-block:: cpp
@@ -84,17 +132,21 @@
     .. code-block:: cpp
 
         m.def("foo", [](args...) {
             T scope_guard;
             return foo(args...); // forwarded arguments
         });
  \endrst */
-template <typename... Ts> struct call_guard;
+template <typename... Ts>
+struct call_guard;
 
-template <> struct call_guard<> { using type = detail::void_type; };
+template <>
+struct call_guard<> {
+    using type = detail::void_type;
+};
 
 template <typename T>
 struct call_guard<T> {
     static_assert(std::is_default_constructible<T>::value,
                   "The guard type must be default constructible");
 
     using type = T;
@@ -106,60 +158,63 @@
         T guard{}; // Compose multiple guard types with left-to-right default-constructor order
         typename call_guard<Ts...>::type next{};
     };
 };
 
 /// @} annotations
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
 /* Forward declarations */
 enum op_id : int;
 enum op_type : int;
 struct undefined_t;
-template <op_id id, op_type ot, typename L = undefined_t, typename R = undefined_t> struct op_;
-inline void keep_alive_impl(size_t Nurse, size_t Patient, function_call &call, handle ret);
+template <op_id id, op_type ot, typename L = undefined_t, typename R = undefined_t>
+struct op_;
+void keep_alive_impl(size_t Nurse, size_t Patient, function_call &call, handle ret);
 
 /// Internal data structure which holds metadata about a keyword argument
 struct argument_record {
     const char *name;  ///< Argument name
     const char *descr; ///< Human-readable version of the argument value
     handle value;      ///< Associated Python object
     bool convert : 1;  ///< True if the argument is allowed to convert when loading
     bool none : 1;     ///< True if None is allowed when loading
 
     argument_record(const char *name, const char *descr, handle value, bool convert, bool none)
-        : name(name), descr(descr), value(value), convert(convert), none(none) { }
+        : name(name), descr(descr), value(value), convert(convert), none(none) {}
 };
 
-/// Internal data structure which holds metadata about a bound function (signature, overloads, etc.)
+/// Internal data structure which holds metadata about a bound function (signature, overloads,
+/// etc.)
 struct function_record {
     function_record()
         : is_constructor(false), is_new_style_constructor(false), is_stateless(false),
-          is_operator(false), has_args(false), has_kwargs(false), is_method(false) { }
+          is_operator(false), is_method(false), has_args(false), has_kwargs(false),
+          prepend(false) {}
 
     /// Function name
     char *name = nullptr; /* why no C++ strings? They generate heavier code.. */
 
     // User-specified documentation string
     char *doc = nullptr;
 
     /// Human-readable version of the function signature
     char *signature = nullptr;
 
     /// List of registered keyword arguments
     std::vector<argument_record> args;
 
     /// Pointer to lambda function which converts arguments and performs the actual call
-    handle (*impl) (function_call &) = nullptr;
+    handle (*impl)(function_call &) = nullptr;
 
     /// Storage for the wrapped function pointer and captured data, if any
-    void *data[3] = { };
+    void *data[3] = {};
 
     /// Pointer to custom destructor for 'data' (if needed)
-    void (*free_data) (function_record *ptr) = nullptr;
+    void (*free_data)(function_record *ptr) = nullptr;
 
     /// Return value policy associated with this function
     return_value_policy policy = return_value_policy::automatic;
 
     /// True if name == '__init__'
     bool is_constructor : 1;
 
@@ -168,26 +223,36 @@
 
     /// True if this is a stateless function pointer
     bool is_stateless : 1;
 
     /// True if this is an operator (__add__), etc.
     bool is_operator : 1;
 
+    /// True if this is a method
+    bool is_method : 1;
+
     /// True if the function has a '*args' argument
     bool has_args : 1;
 
     /// True if the function has a '**kwargs' argument
     bool has_kwargs : 1;
 
-    /// True if this is a method
-    bool is_method : 1;
+    /// True if this function is to be inserted at the beginning of the overload resolution chain
+    bool prepend : 1;
 
     /// Number of arguments (including py::args and/or py::kwargs, if present)
     std::uint16_t nargs;
 
+    /// Number of leading positional arguments, which are terminated by a py::args or py::kwargs
+    /// argument or by a py::kw_only annotation.
+    std::uint16_t nargs_pos = 0;
+
+    /// Number of leading arguments (counted in `nargs`) that are positional-only
+    std::uint16_t nargs_pos_only = 0;
+
     /// Python method object
     PyMethodDef *def = nullptr;
 
     /// Python handle to the parent scope (a class or a module)
     handle scope;
 
     /// Python handle to the sibling function representing an overload chain
@@ -197,15 +262,15 @@
     function_record *next = nullptr;
 };
 
 /// Special data structure which (temporarily) holds metadata about a bound class
 struct type_record {
     PYBIND11_NOINLINE type_record()
         : multiple_inheritance(false), dynamic_attr(false), buffer_protocol(false),
-          default_holder(true), module_local(false) { }
+          default_holder(true), module_local(false), is_final(false) {}
 
     /// Handle to the parent scope
     handle scope;
 
     /// Name of the class
     const char *name = nullptr;
 
@@ -235,14 +300,17 @@
 
     /// Optional docstring
     const char *doc = nullptr;
 
     /// Custom metaclass (optional)
     handle metaclass;
 
+    /// Custom type setup.
+    custom_type_setup::callback custom_type_setup_callback;
+
     /// Multiple inheritance marker
     bool multiple_inheritance : 1;
 
     /// Does the class manage a __dict__?
     bool dynamic_attr : 1;
 
     /// Does the class implement the buffer protocol?
@@ -250,244 +318,361 @@
 
     /// Is the default (unique_ptr) holder type used?
     bool default_holder : 1;
 
     /// Is the class definition local to the module shared object?
     bool module_local : 1;
 
-    PYBIND11_NOINLINE void add_base(const std::type_info &base, void *(*caster)(void *)) {
-        auto base_info = detail::get_type_info(base, false);
+    /// Is the class inheritable from python classes?
+    bool is_final : 1;
+
+    PYBIND11_NOINLINE void add_base(const std::type_info &base, void *(*caster)(void *) ) {
+        auto *base_info = detail::get_type_info(base, false);
         if (!base_info) {
             std::string tname(base.name());
             detail::clean_type_id(tname);
-            pybind11_fail("generic_type: type \"" + std::string(name) +
-                          "\" referenced unknown base type \"" + tname + "\"");
+            pybind11_fail("generic_type: type \"" + std::string(name)
+                          + "\" referenced unknown base type \"" + tname + "\"");
         }
 
         if (default_holder != base_info->default_holder) {
             std::string tname(base.name());
             detail::clean_type_id(tname);
-            pybind11_fail("generic_type: type \"" + std::string(name) + "\" " +
-                    (default_holder ? "does not have" : "has") +
-                    " a non-default holder type while its base \"" + tname + "\" " +
-                    (base_info->default_holder ? "does not" : "does"));
+            pybind11_fail("generic_type: type \"" + std::string(name) + "\" "
+                          + (default_holder ? "does not have" : "has")
+                          + " a non-default holder type while its base \"" + tname + "\" "
+                          + (base_info->default_holder ? "does not" : "does"));
         }
 
         bases.append((PyObject *) base_info->type);
 
-        if (base_info->type->tp_dictoffset != 0)
-            dynamic_attr = true;
+#if PY_VERSION_HEX < 0x030B0000
+        dynamic_attr |= base_info->type->tp_dictoffset != 0;
+#else
+        dynamic_attr |= (base_info->type->tp_flags & Py_TPFLAGS_MANAGED_DICT) != 0;
+#endif
 
-        if (caster)
+        if (caster) {
             base_info->implicit_casts.emplace_back(type, caster);
+        }
     }
 };
 
-inline function_call::function_call(const function_record &f, handle p) :
-        func(f), parent(p) {
+inline function_call::function_call(const function_record &f, handle p) : func(f), parent(p) {
     args.reserve(f.nargs);
     args_convert.reserve(f.nargs);
 }
 
 /// Tag for a new-style `__init__` defined in `detail/init.h`
-struct is_new_style_constructor { };
+struct is_new_style_constructor {};
 
 /**
  * Partial template specializations to process custom attributes provided to
  * cpp_function_ and class_. These are either used to initialize the respective
  * fields in the type_record and function_record data structures or executed at
  * runtime to deal with custom call policies (e.g. keep_alive).
  */
-template <typename T, typename SFINAE = void> struct process_attribute;
+template <typename T, typename SFINAE = void>
+struct process_attribute;
 
-template <typename T> struct process_attribute_default {
+template <typename T>
+struct process_attribute_default {
     /// Default implementation: do nothing
-    static void init(const T &, function_record *) { }
-    static void init(const T &, type_record *) { }
-    static void precall(function_call &) { }
-    static void postcall(function_call &, handle) { }
+    static void init(const T &, function_record *) {}
+    static void init(const T &, type_record *) {}
+    static void precall(function_call &) {}
+    static void postcall(function_call &, handle) {}
 };
 
 /// Process an attribute specifying the function's name
-template <> struct process_attribute<name> : process_attribute_default<name> {
+template <>
+struct process_attribute<name> : process_attribute_default<name> {
     static void init(const name &n, function_record *r) { r->name = const_cast<char *>(n.value); }
 };
 
 /// Process an attribute specifying the function's docstring
-template <> struct process_attribute<doc> : process_attribute_default<doc> {
+template <>
+struct process_attribute<doc> : process_attribute_default<doc> {
     static void init(const doc &n, function_record *r) { r->doc = const_cast<char *>(n.value); }
 };
 
 /// Process an attribute specifying the function's docstring (provided as a C-style string)
-template <> struct process_attribute<const char *> : process_attribute_default<const char *> {
+template <>
+struct process_attribute<const char *> : process_attribute_default<const char *> {
     static void init(const char *d, function_record *r) { r->doc = const_cast<char *>(d); }
-    static void init(const char *d, type_record *r) { r->doc = const_cast<char *>(d); }
+    static void init(const char *d, type_record *r) { r->doc = d; }
 };
-template <> struct process_attribute<char *> : process_attribute<const char *> { };
+template <>
+struct process_attribute<char *> : process_attribute<const char *> {};
 
 /// Process an attribute indicating the function's return value policy
-template <> struct process_attribute<return_value_policy> : process_attribute_default<return_value_policy> {
+template <>
+struct process_attribute<return_value_policy> : process_attribute_default<return_value_policy> {
     static void init(const return_value_policy &p, function_record *r) { r->policy = p; }
 };
 
-/// Process an attribute which indicates that this is an overloaded function associated with a given sibling
-template <> struct process_attribute<sibling> : process_attribute_default<sibling> {
+/// Process an attribute which indicates that this is an overloaded function associated with a
+/// given sibling
+template <>
+struct process_attribute<sibling> : process_attribute_default<sibling> {
     static void init(const sibling &s, function_record *r) { r->sibling = s.value; }
 };
 
 /// Process an attribute which indicates that this function is a method
-template <> struct process_attribute<is_method> : process_attribute_default<is_method> {
-    static void init(const is_method &s, function_record *r) { r->is_method = true; r->scope = s.class_; }
+template <>
+struct process_attribute<is_method> : process_attribute_default<is_method> {
+    static void init(const is_method &s, function_record *r) {
+        r->is_method = true;
+        r->scope = s.class_;
+    }
 };
 
 /// Process an attribute which indicates the parent scope of a method
-template <> struct process_attribute<scope> : process_attribute_default<scope> {
+template <>
+struct process_attribute<scope> : process_attribute_default<scope> {
     static void init(const scope &s, function_record *r) { r->scope = s.value; }
 };
 
 /// Process an attribute which indicates that this function is an operator
-template <> struct process_attribute<is_operator> : process_attribute_default<is_operator> {
+template <>
+struct process_attribute<is_operator> : process_attribute_default<is_operator> {
     static void init(const is_operator &, function_record *r) { r->is_operator = true; }
 };
 
-template <> struct process_attribute<is_new_style_constructor> : process_attribute_default<is_new_style_constructor> {
-    static void init(const is_new_style_constructor &, function_record *r) { r->is_new_style_constructor = true; }
+template <>
+struct process_attribute<is_new_style_constructor>
+    : process_attribute_default<is_new_style_constructor> {
+    static void init(const is_new_style_constructor &, function_record *r) {
+        r->is_new_style_constructor = true;
+    }
 };
 
+inline void check_kw_only_arg(const arg &a, function_record *r) {
+    if (r->args.size() > r->nargs_pos && (!a.name || a.name[0] == '\0')) {
+        pybind11_fail("arg(): cannot specify an unnamed argument after a kw_only() annotation or "
+                      "args() argument");
+    }
+}
+
+inline void append_self_arg_if_needed(function_record *r) {
+    if (r->is_method && r->args.empty()) {
+        r->args.emplace_back("self", nullptr, handle(), /*convert=*/true, /*none=*/false);
+    }
+}
+
 /// Process a keyword argument attribute (*without* a default value)
-template <> struct process_attribute<arg> : process_attribute_default<arg> {
+template <>
+struct process_attribute<arg> : process_attribute_default<arg> {
     static void init(const arg &a, function_record *r) {
-        if (r->is_method && r->args.empty())
-            r->args.emplace_back("self", nullptr, handle(), true /*convert*/, false /*none not allowed*/);
+        append_self_arg_if_needed(r);
         r->args.emplace_back(a.name, nullptr, handle(), !a.flag_noconvert, a.flag_none);
+
+        check_kw_only_arg(a, r);
     }
 };
 
 /// Process a keyword argument attribute (*with* a default value)
-template <> struct process_attribute<arg_v> : process_attribute_default<arg_v> {
+template <>
+struct process_attribute<arg_v> : process_attribute_default<arg_v> {
     static void init(const arg_v &a, function_record *r) {
-        if (r->is_method && r->args.empty())
-            r->args.emplace_back("self", nullptr /*descr*/, handle() /*parent*/, true /*convert*/, false /*none not allowed*/);
+        if (r->is_method && r->args.empty()) {
+            r->args.emplace_back(
+                "self", /*descr=*/nullptr, /*parent=*/handle(), /*convert=*/true, /*none=*/false);
+        }
 
         if (!a.value) {
-#if !defined(NDEBUG)
+#if defined(PYBIND11_DETAILED_ERROR_MESSAGES)
             std::string descr("'");
-            if (a.name) descr += std::string(a.name) + ": ";
+            if (a.name) {
+                descr += std::string(a.name) + ": ";
+            }
             descr += a.type + "'";
             if (r->is_method) {
-                if (r->name)
-                    descr += " in method '" + (std::string) str(r->scope) + "." + (std::string) r->name + "'";
-                else
+                if (r->name) {
+                    descr += " in method '" + (std::string) str(r->scope) + "."
+                             + (std::string) r->name + "'";
+                } else {
                     descr += " in method of '" + (std::string) str(r->scope) + "'";
+                }
             } else if (r->name) {
                 descr += " in function '" + (std::string) r->name + "'";
             }
-            pybind11_fail("arg(): could not convert default argument "
-                          + descr + " into a Python object (type not registered yet?)");
+            pybind11_fail("arg(): could not convert default argument " + descr
+                          + " into a Python object (type not registered yet?)");
 #else
             pybind11_fail("arg(): could not convert default argument "
                           "into a Python object (type not registered yet?). "
-                          "Compile in debug mode for more information.");
+                          "#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for "
+                          "more information.");
 #endif
         }
         r->args.emplace_back(a.name, a.descr, a.value.inc_ref(), !a.flag_noconvert, a.flag_none);
+
+        check_kw_only_arg(a, r);
+    }
+};
+
+/// Process a keyword-only-arguments-follow pseudo argument
+template <>
+struct process_attribute<kw_only> : process_attribute_default<kw_only> {
+    static void init(const kw_only &, function_record *r) {
+        append_self_arg_if_needed(r);
+        if (r->has_args && r->nargs_pos != static_cast<std::uint16_t>(r->args.size())) {
+            pybind11_fail("Mismatched args() and kw_only(): they must occur at the same relative "
+                          "argument location (or omit kw_only() entirely)");
+        }
+        r->nargs_pos = static_cast<std::uint16_t>(r->args.size());
     }
 };
 
-/// Process a parent class attribute.  Single inheritance only (class_ itself already guarantees that)
+/// Process a positional-only-argument maker
+template <>
+struct process_attribute<pos_only> : process_attribute_default<pos_only> {
+    static void init(const pos_only &, function_record *r) {
+        append_self_arg_if_needed(r);
+        r->nargs_pos_only = static_cast<std::uint16_t>(r->args.size());
+        if (r->nargs_pos_only > r->nargs_pos) {
+            pybind11_fail("pos_only(): cannot follow a py::args() argument");
+        }
+        // It also can't follow a kw_only, but a static_assert in pybind11.h checks that
+    }
+};
+
+/// Process a parent class attribute.  Single inheritance only (class_ itself already guarantees
+/// that)
 template <typename T>
-struct process_attribute<T, enable_if_t<is_pyobject<T>::value>> : process_attribute_default<handle> {
+struct process_attribute<T, enable_if_t<is_pyobject<T>::value>>
+    : process_attribute_default<handle> {
     static void init(const handle &h, type_record *r) { r->bases.append(h); }
 };
 
 /// Process a parent class attribute (deprecated, does not support multiple inheritance)
 template <typename T>
 struct process_attribute<base<T>> : process_attribute_default<base<T>> {
     static void init(const base<T> &, type_record *r) { r->add_base(typeid(T), nullptr); }
 };
 
 /// Process a multiple inheritance attribute
 template <>
 struct process_attribute<multiple_inheritance> : process_attribute_default<multiple_inheritance> {
-    static void init(const multiple_inheritance &, type_record *r) { r->multiple_inheritance = true; }
+    static void init(const multiple_inheritance &, type_record *r) {
+        r->multiple_inheritance = true;
+    }
 };
 
 template <>
 struct process_attribute<dynamic_attr> : process_attribute_default<dynamic_attr> {
     static void init(const dynamic_attr &, type_record *r) { r->dynamic_attr = true; }
 };
 
 template <>
+struct process_attribute<custom_type_setup> {
+    static void init(const custom_type_setup &value, type_record *r) {
+        r->custom_type_setup_callback = value.value;
+    }
+};
+
+template <>
+struct process_attribute<is_final> : process_attribute_default<is_final> {
+    static void init(const is_final &, type_record *r) { r->is_final = true; }
+};
+
+template <>
 struct process_attribute<buffer_protocol> : process_attribute_default<buffer_protocol> {
     static void init(const buffer_protocol &, type_record *r) { r->buffer_protocol = true; }
 };
 
 template <>
 struct process_attribute<metaclass> : process_attribute_default<metaclass> {
     static void init(const metaclass &m, type_record *r) { r->metaclass = m.value; }
 };
 
 template <>
 struct process_attribute<module_local> : process_attribute_default<module_local> {
     static void init(const module_local &l, type_record *r) { r->module_local = l.value; }
 };
 
+/// Process a 'prepend' attribute, putting this at the beginning of the overload chain
+template <>
+struct process_attribute<prepend> : process_attribute_default<prepend> {
+    static void init(const prepend &, function_record *r) { r->prepend = true; }
+};
+
 /// Process an 'arithmetic' attribute for enums (does nothing here)
 template <>
 struct process_attribute<arithmetic> : process_attribute_default<arithmetic> {};
 
 template <typename... Ts>
-struct process_attribute<call_guard<Ts...>> : process_attribute_default<call_guard<Ts...>> { };
+struct process_attribute<call_guard<Ts...>> : process_attribute_default<call_guard<Ts...>> {};
 
 /**
  * Process a keep_alive call policy -- invokes keep_alive_impl during the
  * pre-call handler if both Nurse, Patient != 0 and use the post-call handler
  * otherwise
  */
-template <size_t Nurse, size_t Patient> struct process_attribute<keep_alive<Nurse, Patient>> : public process_attribute_default<keep_alive<Nurse, Patient>> {
+template <size_t Nurse, size_t Patient>
+struct process_attribute<keep_alive<Nurse, Patient>>
+    : public process_attribute_default<keep_alive<Nurse, Patient>> {
     template <size_t N = Nurse, size_t P = Patient, enable_if_t<N != 0 && P != 0, int> = 0>
-    static void precall(function_call &call) { keep_alive_impl(Nurse, Patient, call, handle()); }
+    static void precall(function_call &call) {
+        keep_alive_impl(Nurse, Patient, call, handle());
+    }
     template <size_t N = Nurse, size_t P = Patient, enable_if_t<N != 0 && P != 0, int> = 0>
-    static void postcall(function_call &, handle) { }
+    static void postcall(function_call &, handle) {}
     template <size_t N = Nurse, size_t P = Patient, enable_if_t<N == 0 || P == 0, int> = 0>
-    static void precall(function_call &) { }
+    static void precall(function_call &) {}
     template <size_t N = Nurse, size_t P = Patient, enable_if_t<N == 0 || P == 0, int> = 0>
-    static void postcall(function_call &call, handle ret) { keep_alive_impl(Nurse, Patient, call, ret); }
+    static void postcall(function_call &call, handle ret) {
+        keep_alive_impl(Nurse, Patient, call, ret);
+    }
 };
 
 /// Recursively iterate over variadic template arguments
-template <typename... Args> struct process_attributes {
-    static void init(const Args&... args, function_record *r) {
-        int unused[] = { 0, (process_attribute<typename std::decay<Args>::type>::init(args, r), 0) ... };
-        ignore_unused(unused);
-    }
-    static void init(const Args&... args, type_record *r) {
-        int unused[] = { 0, (process_attribute<typename std::decay<Args>::type>::init(args, r), 0) ... };
-        ignore_unused(unused);
+template <typename... Args>
+struct process_attributes {
+    static void init(const Args &...args, function_record *r) {
+        PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(r);
+        PYBIND11_WORKAROUND_INCORRECT_GCC_UNUSED_BUT_SET_PARAMETER(r);
+        using expander = int[];
+        (void) expander{
+            0, ((void) process_attribute<typename std::decay<Args>::type>::init(args, r), 0)...};
+    }
+    static void init(const Args &...args, type_record *r) {
+        PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(r);
+        PYBIND11_WORKAROUND_INCORRECT_GCC_UNUSED_BUT_SET_PARAMETER(r);
+        using expander = int[];
+        (void) expander{0,
+                        (process_attribute<typename std::decay<Args>::type>::init(args, r), 0)...};
     }
     static void precall(function_call &call) {
-        int unused[] = { 0, (process_attribute<typename std::decay<Args>::type>::precall(call), 0) ... };
-        ignore_unused(unused);
+        PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(call);
+        using expander = int[];
+        (void) expander{0,
+                        (process_attribute<typename std::decay<Args>::type>::precall(call), 0)...};
     }
     static void postcall(function_call &call, handle fn_ret) {
-        int unused[] = { 0, (process_attribute<typename std::decay<Args>::type>::postcall(call, fn_ret), 0) ... };
-        ignore_unused(unused);
+        PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(call, fn_ret);
+        PYBIND11_WORKAROUND_INCORRECT_GCC_UNUSED_BUT_SET_PARAMETER(fn_ret);
+        using expander = int[];
+        (void) expander{
+            0, (process_attribute<typename std::decay<Args>::type>::postcall(call, fn_ret), 0)...};
     }
 };
 
 template <typename T>
 using is_call_guard = is_instantiation<call_guard, T>;
 
 /// Extract the ``type`` from the first `call_guard` in `Extras...` (or `void_type` if none found)
 template <typename... Extra>
 using extract_guard_t = typename exactly_one_t<is_call_guard, call_guard<>, Extra...>::type;
 
 /// Check the number of named arguments at compile time
 template <typename... Extra,
           size_t named = constexpr_sum(std::is_base_of<arg, Extra>::value...),
-          size_t self  = constexpr_sum(std::is_same<is_method, Extra>::value...)>
+          size_t self = constexpr_sum(std::is_same<is_method, Extra>::value...)>
 constexpr bool expected_num_args(size_t nargs, bool has_args, bool has_kwargs) {
-    return named == 0 || (self + named + has_args + has_kwargs) == nargs;
+    PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(nargs, has_args, has_kwargs);
+    return named == 0 || (self + named + size_t(has_args) + size_t(has_kwargs)) == nargs;
 }
 
-NAMESPACE_END(detail)
-NAMESPACE_END(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/cast.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/cast.h`

 * *Files 26% similar despite different names*

```diff
@@ -6,1853 +6,1353 @@
 
     All rights reserved. Use of this source code is governed by a
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
-#include "pytypes.h"
-#include "detail/typeid.h"
+#include "detail/common.h"
 #include "detail/descr.h"
-#include "detail/internals.h"
+#include "detail/type_caster_base.h"
+#include "detail/typeid.h"
+#include "pytypes.h"
+
 #include <array>
-#include <limits>
+#include <cstring>
+#include <functional>
+#include <iosfwd>
+#include <iterator>
+#include <memory>
+#include <string>
 #include <tuple>
 #include <type_traits>
+#include <utility>
+#include <vector>
 
-#if defined(PYBIND11_CPP17)
-#  if defined(__has_include)
-#    if __has_include(<string_view>)
-#      define PYBIND11_HAS_STRING_VIEW
-#    endif
-#  elif defined(_MSC_VER)
-#    define PYBIND11_HAS_STRING_VIEW
-#  endif
-#endif
-#ifdef PYBIND11_HAS_STRING_VIEW
-#include <string_view>
-#endif
-
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
-NAMESPACE_BEGIN(detail)
-
-/// A life support system for temporary objects created by `type_caster::load()`.
-/// Adding a patient will keep it alive up until the enclosing function returns.
-class loader_life_support {
-public:
-    /// A new patient frame is created when a function is entered
-    loader_life_support() {
-        get_internals().loader_patient_stack.push_back(nullptr);
-    }
-
-    /// ... and destroyed after it returns
-    ~loader_life_support() {
-        auto &stack = get_internals().loader_patient_stack;
-        if (stack.empty())
-            pybind11_fail("loader_life_support: internal error");
-
-        auto ptr = stack.back();
-        stack.pop_back();
-        Py_CLEAR(ptr);
-
-        // A heuristic to reduce the stack's capacity (e.g. after long recursive calls)
-        if (stack.capacity() > 16 && stack.size() != 0 && stack.capacity() / stack.size() > 2)
-            stack.shrink_to_fit();
-    }
-
-    /// This can only be used inside a pybind11-bound function, either by `argument_loader`
-    /// at argument preparation time or by `py::cast()` at execution time.
-    PYBIND11_NOINLINE static void add_patient(handle h) {
-        auto &stack = get_internals().loader_patient_stack;
-        if (stack.empty())
-            throw cast_error("When called outside a bound function, py::cast() cannot "
-                             "do Python -> C++ conversions which require the creation "
-                             "of temporary values");
-
-        auto &list_ptr = stack.back();
-        if (list_ptr == nullptr) {
-            list_ptr = PyList_New(1);
-            if (!list_ptr)
-                pybind11_fail("loader_life_support: error allocating list");
-            PyList_SET_ITEM(list_ptr, 0, h.inc_ref().ptr());
-        } else {
-            auto result = PyList_Append(list_ptr, h.ptr());
-            if (result == -1)
-                pybind11_fail("loader_life_support: error adding patient");
-        }
-    }
-};
-
-// Gets the cache entry for the given type, creating it if necessary.  The return value is the pair
-// returned by emplace, i.e. an iterator for the entry and a bool set to `true` if the entry was
-// just created.
-inline std::pair<decltype(internals::registered_types_py)::iterator, bool> all_type_info_get_cache(PyTypeObject *type);
-
-// Populates a just-created cache entry.
-PYBIND11_NOINLINE inline void all_type_info_populate(PyTypeObject *t, std::vector<type_info *> &bases) {
-    std::vector<PyTypeObject *> check;
-    for (handle parent : reinterpret_borrow<tuple>(t->tp_bases))
-        check.push_back((PyTypeObject *) parent.ptr());
-
-    auto const &type_dict = get_internals().registered_types_py;
-    for (size_t i = 0; i < check.size(); i++) {
-        auto type = check[i];
-        // Ignore Python2 old-style class super type:
-        if (!PyType_Check((PyObject *) type)) continue;
-
-        // Check `type` in the current set of registered python types:
-        auto it = type_dict.find(type);
-        if (it != type_dict.end()) {
-            // We found a cache entry for it, so it's either pybind-registered or has pre-computed
-            // pybind bases, but we have to make sure we haven't already seen the type(s) before: we
-            // want to follow Python/virtual C++ rules that there should only be one instance of a
-            // common base.
-            for (auto *tinfo : it->second) {
-                // NB: Could use a second set here, rather than doing a linear search, but since
-                // having a large number of immediate pybind11-registered types seems fairly
-                // unlikely, that probably isn't worthwhile.
-                bool found = false;
-                for (auto *known : bases) {
-                    if (known == tinfo) { found = true; break; }
-                }
-                if (!found) bases.push_back(tinfo);
-            }
-        }
-        else if (type->tp_bases) {
-            // It's some python type, so keep follow its bases classes to look for one or more
-            // registered types
-            if (i + 1 == check.size()) {
-                // When we're at the end, we can pop off the current element to avoid growing
-                // `check` when adding just one base (which is typical--i.e. when there is no
-                // multiple inheritance)
-                check.pop_back();
-                i--;
-            }
-            for (handle parent : reinterpret_borrow<tuple>(type->tp_bases))
-                check.push_back((PyTypeObject *) parent.ptr());
-        }
-    }
-}
-
-/**
- * Extracts vector of type_info pointers of pybind-registered roots of the given Python type.  Will
- * be just 1 pybind type for the Python type of a pybind-registered class, or for any Python-side
- * derived class that uses single inheritance.  Will contain as many types as required for a Python
- * class that uses multiple inheritance to inherit (directly or indirectly) from multiple
- * pybind-registered classes.  Will be empty if neither the type nor any base classes are
- * pybind-registered.
- *
- * The value is cached for the lifetime of the Python type.
- */
-inline const std::vector<detail::type_info *> &all_type_info(PyTypeObject *type) {
-    auto ins = all_type_info_get_cache(type);
-    if (ins.second)
-        // New cache entry: populate it
-        all_type_info_populate(type, ins.first->second);
-
-    return ins.first->second;
-}
-
-/**
- * Gets a single pybind11 type info for a python type.  Returns nullptr if neither the type nor any
- * ancestors are pybind11-registered.  Throws an exception if there are multiple bases--use
- * `all_type_info` instead if you want to support multiple bases.
- */
-PYBIND11_NOINLINE inline detail::type_info* get_type_info(PyTypeObject *type) {
-    auto &bases = all_type_info(type);
-    if (bases.size() == 0)
-        return nullptr;
-    if (bases.size() > 1)
-        pybind11_fail("pybind11::detail::get_type_info: type has multiple pybind11-registered bases");
-    return bases.front();
-}
-
-inline detail::type_info *get_local_type_info(const std::type_index &tp) {
-    auto &locals = registered_local_types_cpp();
-    auto it = locals.find(tp);
-    if (it != locals.end())
-        return it->second;
-    return nullptr;
-}
-
-inline detail::type_info *get_global_type_info(const std::type_index &tp) {
-    auto &types = get_internals().registered_types_cpp;
-    auto it = types.find(tp);
-    if (it != types.end())
-        return it->second;
-    return nullptr;
-}
-
-/// Return the type info for a given C++ type; on lookup failure can either throw or return nullptr.
-PYBIND11_NOINLINE inline detail::type_info *get_type_info(const std::type_index &tp,
-                                                          bool throw_if_missing = false) {
-    if (auto ltype = get_local_type_info(tp))
-        return ltype;
-    if (auto gtype = get_global_type_info(tp))
-        return gtype;
-
-    if (throw_if_missing) {
-        std::string tname = tp.name();
-        detail::clean_type_id(tname);
-        pybind11_fail("pybind11::detail::get_type_info: unable to find type info for \"" + tname + "\"");
-    }
-    return nullptr;
-}
-
-PYBIND11_NOINLINE inline handle get_type_handle(const std::type_info &tp, bool throw_if_missing) {
-    detail::type_info *type_info = get_type_info(tp, throw_if_missing);
-    return handle(type_info ? ((PyObject *) type_info->type) : nullptr);
-}
-
-struct value_and_holder {
-    instance *inst = nullptr;
-    size_t index = 0u;
-    const detail::type_info *type = nullptr;
-    void **vh = nullptr;
-
-    // Main constructor for a found value/holder:
-    value_and_holder(instance *i, const detail::type_info *type, size_t vpos, size_t index) :
-        inst{i}, index{index}, type{type},
-        vh{inst->simple_layout ? inst->simple_value_holder : &inst->nonsimple.values_and_holders[vpos]}
-    {}
-
-    // Default constructor (used to signal a value-and-holder not found by get_value_and_holder())
-    value_and_holder() {}
-
-    // Used for past-the-end iterator
-    value_and_holder(size_t index) : index{index} {}
-
-    template <typename V = void> V *&value_ptr() const {
-        return reinterpret_cast<V *&>(vh[0]);
-    }
-    // True if this `value_and_holder` has a non-null value pointer
-    explicit operator bool() const { return value_ptr(); }
-
-    template <typename H> H &holder() const {
-        return reinterpret_cast<H &>(vh[1]);
-    }
-    bool holder_constructed() const {
-        return inst->simple_layout
-            ? inst->simple_holder_constructed
-            : inst->nonsimple.status[index] & instance::status_holder_constructed;
-    }
-    void set_holder_constructed(bool v = true) {
-        if (inst->simple_layout)
-            inst->simple_holder_constructed = v;
-        else if (v)
-            inst->nonsimple.status[index] |= instance::status_holder_constructed;
-        else
-            inst->nonsimple.status[index] &= (uint8_t) ~instance::status_holder_constructed;
-    }
-    bool instance_registered() const {
-        return inst->simple_layout
-            ? inst->simple_instance_registered
-            : inst->nonsimple.status[index] & instance::status_instance_registered;
-    }
-    void set_instance_registered(bool v = true) {
-        if (inst->simple_layout)
-            inst->simple_instance_registered = v;
-        else if (v)
-            inst->nonsimple.status[index] |= instance::status_instance_registered;
-        else
-            inst->nonsimple.status[index] &= (uint8_t) ~instance::status_instance_registered;
-    }
-};
-
-// Container for accessing and iterating over an instance's values/holders
-struct values_and_holders {
-private:
-    instance *inst;
-    using type_vec = std::vector<detail::type_info *>;
-    const type_vec &tinfo;
-
-public:
-    values_and_holders(instance *inst) : inst{inst}, tinfo(all_type_info(Py_TYPE(inst))) {}
-
-    struct iterator {
-    private:
-        instance *inst = nullptr;
-        const type_vec *types = nullptr;
-        value_and_holder curr;
-        friend struct values_and_holders;
-        iterator(instance *inst, const type_vec *tinfo)
-            : inst{inst}, types{tinfo},
-            curr(inst /* instance */,
-                 types->empty() ? nullptr : (*types)[0] /* type info */,
-                 0, /* vpos: (non-simple types only): the first vptr comes first */
-                 0 /* index */)
-        {}
-        // Past-the-end iterator:
-        iterator(size_t end) : curr(end) {}
-    public:
-        bool operator==(const iterator &other) { return curr.index == other.curr.index; }
-        bool operator!=(const iterator &other) { return curr.index != other.curr.index; }
-        iterator &operator++() {
-            if (!inst->simple_layout)
-                curr.vh += 1 + (*types)[curr.index]->holder_size_in_ptrs;
-            ++curr.index;
-            curr.type = curr.index < types->size() ? (*types)[curr.index] : nullptr;
-            return *this;
-        }
-        value_and_holder &operator*() { return curr; }
-        value_and_holder *operator->() { return &curr; }
-    };
-
-    iterator begin() { return iterator(inst, &tinfo); }
-    iterator end() { return iterator(tinfo.size()); }
-
-    iterator find(const type_info *find_type) {
-        auto it = begin(), endit = end();
-        while (it != endit && it->type != find_type) ++it;
-        return it;
-    }
-
-    size_t size() { return tinfo.size(); }
-};
-
-/**
- * Extracts C++ value and holder pointer references from an instance (which may contain multiple
- * values/holders for python-side multiple inheritance) that match the given type.  Throws an error
- * if the given type (or ValueType, if omitted) is not a pybind11 base of the given instance.  If
- * `find_type` is omitted (or explicitly specified as nullptr) the first value/holder are returned,
- * regardless of type (and the resulting .type will be nullptr).
- *
- * The returned object should be short-lived: in particular, it must not outlive the called-upon
- * instance.
- */
-PYBIND11_NOINLINE inline value_and_holder instance::get_value_and_holder(const type_info *find_type /*= nullptr default in common.h*/, bool throw_if_missing /*= true in common.h*/) {
-    // Optimize common case:
-    if (!find_type || Py_TYPE(this) == find_type->type)
-        return value_and_holder(this, find_type, 0, 0);
-
-    detail::values_and_holders vhs(this);
-    auto it = vhs.find(find_type);
-    if (it != vhs.end())
-        return *it;
-
-    if (!throw_if_missing)
-        return value_and_holder();
-
-#if defined(NDEBUG)
-    pybind11_fail("pybind11::detail::instance::get_value_and_holder: "
-            "type is not a pybind11 base of the given instance "
-            "(compile in debug mode for type details)");
-#else
-    pybind11_fail("pybind11::detail::instance::get_value_and_holder: `" +
-            std::string(find_type->type->tp_name) + "' is not a pybind11 base of the given `" +
-            std::string(Py_TYPE(this)->tp_name) + "' instance");
-#endif
-}
-
-PYBIND11_NOINLINE inline void instance::allocate_layout() {
-    auto &tinfo = all_type_info(Py_TYPE(this));
-
-    const size_t n_types = tinfo.size();
-
-    if (n_types == 0)
-        pybind11_fail("instance allocation failed: new instance has no pybind11-registered base types");
-
-    simple_layout =
-        n_types == 1 && tinfo.front()->holder_size_in_ptrs <= instance_simple_holder_in_ptrs();
-
-    // Simple path: no python-side multiple inheritance, and a small-enough holder
-    if (simple_layout) {
-        simple_value_holder[0] = nullptr;
-        simple_holder_constructed = false;
-        simple_instance_registered = false;
-    }
-    else { // multiple base types or a too-large holder
-        // Allocate space to hold: [v1*][h1][v2*][h2]...[bb...] where [vN*] is a value pointer,
-        // [hN] is the (uninitialized) holder instance for value N, and [bb...] is a set of bool
-        // values that tracks whether each associated holder has been initialized.  Each [block] is
-        // padded, if necessary, to an integer multiple of sizeof(void *).
-        size_t space = 0;
-        for (auto t : tinfo) {
-            space += 1; // value pointer
-            space += t->holder_size_in_ptrs; // holder instance
-        }
-        size_t flags_at = space;
-        space += size_in_ptrs(n_types); // status bytes (holder_constructed and instance_registered)
-
-        // Allocate space for flags, values, and holders, and initialize it to 0 (flags and values,
-        // in particular, need to be 0).  Use Python's memory allocation functions: in Python 3.6
-        // they default to using pymalloc, which is designed to be efficient for small allocations
-        // like the one we're doing here; in earlier versions (and for larger allocations) they are
-        // just wrappers around malloc.
-#if PY_VERSION_HEX >= 0x03050000
-        nonsimple.values_and_holders = (void **) PyMem_Calloc(space, sizeof(void *));
-        if (!nonsimple.values_and_holders) throw std::bad_alloc();
-#else
-        nonsimple.values_and_holders = (void **) PyMem_New(void *, space);
-        if (!nonsimple.values_and_holders) throw std::bad_alloc();
-        std::memset(nonsimple.values_and_holders, 0, space * sizeof(void *));
-#endif
-        nonsimple.status = reinterpret_cast<uint8_t *>(&nonsimple.values_and_holders[flags_at]);
-    }
-    owned = true;
-}
-
-PYBIND11_NOINLINE inline void instance::deallocate_layout() {
-    if (!simple_layout)
-        PyMem_Free(nonsimple.values_and_holders);
-}
-
-PYBIND11_NOINLINE inline bool isinstance_generic(handle obj, const std::type_info &tp) {
-    handle type = detail::get_type_handle(tp, false);
-    if (!type)
-        return false;
-    return isinstance(obj, type);
-}
-
-PYBIND11_NOINLINE inline std::string error_string() {
-    if (!PyErr_Occurred()) {
-        PyErr_SetString(PyExc_RuntimeError, "Unknown internal error occurred");
-        return "Unknown internal error occurred";
-    }
-
-    error_scope scope; // Preserve error state
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
 
-    std::string errorString;
-    if (scope.type) {
-        errorString += handle(scope.type).attr("__name__").cast<std::string>();
-        errorString += ": ";
-    }
-    if (scope.value)
-        errorString += (std::string) str(scope.value);
+PYBIND11_WARNING_DISABLE_MSVC(4127)
 
-    PyErr_NormalizeException(&scope.type, &scope.value, &scope.trace);
+PYBIND11_NAMESPACE_BEGIN(detail)
 
-#if PY_MAJOR_VERSION >= 3
-    if (scope.trace != nullptr)
-        PyException_SetTraceback(scope.value, scope.trace);
-#endif
-
-#if !defined(PYPY_VERSION)
-    if (scope.trace) {
-        PyTracebackObject *trace = (PyTracebackObject *) scope.trace;
-
-        /* Get the deepest trace possible */
-        while (trace->tb_next)
-            trace = trace->tb_next;
-
-        PyFrameObject *frame = trace->tb_frame;
-        errorString += "\n\nAt:\n";
-        while (frame) {
-            int lineno = PyFrame_GetLineNumber(frame);
-            errorString +=
-                "  " + handle(frame->f_code->co_filename).cast<std::string>() +
-                "(" + std::to_string(lineno) + "): " +
-                handle(frame->f_code->co_name).cast<std::string>() + "\n";
-            frame = frame->f_back;
-        }
-    }
-#endif
-
-    return errorString;
-}
-
-PYBIND11_NOINLINE inline handle get_object_handle(const void *ptr, const detail::type_info *type ) {
-    auto &instances = get_internals().registered_instances;
-    auto range = instances.equal_range(ptr);
-    for (auto it = range.first; it != range.second; ++it) {
-        for (auto vh : values_and_holders(it->second)) {
-            if (vh.type == type)
-                return handle((PyObject *) it->second);
-        }
-    }
-    return handle();
-}
-
-inline PyThreadState *get_thread_state_unchecked() {
-#if defined(PYPY_VERSION)
-    return PyThreadState_GET();
-#elif PY_VERSION_HEX < 0x03000000
-    return _PyThreadState_Current;
-#elif PY_VERSION_HEX < 0x03050000
-    return (PyThreadState*) _Py_atomic_load_relaxed(&_PyThreadState_Current);
-#elif PY_VERSION_HEX < 0x03050200
-    return (PyThreadState*) _PyThreadState_Current.value;
-#else
-    return _PyThreadState_UncheckedGet();
-#endif
-}
-
-// Forward declarations
-inline void keep_alive_impl(handle nurse, handle patient);
-inline PyObject *make_new_instance(PyTypeObject *type);
-
-class type_caster_generic {
-public:
-    PYBIND11_NOINLINE type_caster_generic(const std::type_info &type_info)
-        : typeinfo(get_type_info(type_info)), cpptype(&type_info) { }
-
-    type_caster_generic(const type_info *typeinfo)
-        : typeinfo(typeinfo), cpptype(typeinfo ? typeinfo->cpptype : nullptr) { }
-
-    bool load(handle src, bool convert) {
-        return load_impl<type_caster_generic>(src, convert);
-    }
-
-    PYBIND11_NOINLINE static handle cast(const void *_src, return_value_policy policy, handle parent,
-                                         const detail::type_info *tinfo,
-                                         void *(*copy_constructor)(const void *),
-                                         void *(*move_constructor)(const void *),
-                                         const void *existing_holder = nullptr) {
-        if (!tinfo) // no type info: error will be set already
-            return handle();
-
-        void *src = const_cast<void *>(_src);
-        if (src == nullptr)
-            return none().release();
-
-        auto it_instances = get_internals().registered_instances.equal_range(src);
-        for (auto it_i = it_instances.first; it_i != it_instances.second; ++it_i) {
-            for (auto instance_type : detail::all_type_info(Py_TYPE(it_i->second))) {
-                if (instance_type && same_type(*instance_type->cpptype, *tinfo->cpptype))
-                    return handle((PyObject *) it_i->second).inc_ref();
-            }
-        }
-
-        auto inst = reinterpret_steal<object>(make_new_instance(tinfo->type));
-        auto wrapper = reinterpret_cast<instance *>(inst.ptr());
-        wrapper->owned = false;
-        void *&valueptr = values_and_holders(wrapper).begin()->value_ptr();
-
-        switch (policy) {
-            case return_value_policy::automatic:
-            case return_value_policy::take_ownership:
-                valueptr = src;
-                wrapper->owned = true;
-                break;
-
-            case return_value_policy::automatic_reference:
-            case return_value_policy::reference:
-                valueptr = src;
-                wrapper->owned = false;
-                break;
-
-            case return_value_policy::copy:
-                if (copy_constructor)
-                    valueptr = copy_constructor(src);
-                else
-                    throw cast_error("return_value_policy = copy, but the "
-                                     "object is non-copyable!");
-                wrapper->owned = true;
-                break;
-
-            case return_value_policy::move:
-                if (move_constructor)
-                    valueptr = move_constructor(src);
-                else if (copy_constructor)
-                    valueptr = copy_constructor(src);
-                else
-                    throw cast_error("return_value_policy = move, but the "
-                                     "object is neither movable nor copyable!");
-                wrapper->owned = true;
-                break;
-
-            case return_value_policy::reference_internal:
-                valueptr = src;
-                wrapper->owned = false;
-                keep_alive_impl(inst, parent);
-                break;
-
-            default:
-                throw cast_error("unhandled return_value_policy: should not happen!");
-        }
-
-        tinfo->init_instance(wrapper, existing_holder);
-
-        return inst.release();
-    }
-
-    // Base methods for generic caster; there are overridden in copyable_holder_caster
-    void load_value(value_and_holder &&v_h) {
-        auto *&vptr = v_h.value_ptr();
-        // Lazy allocation for unallocated values:
-        if (vptr == nullptr) {
-            auto *type = v_h.type ? v_h.type : typeinfo;
-            if (type->operator_new) {
-                vptr = type->operator_new(type->type_size);
-            } else {
-                #if defined(PYBIND11_CPP17)
-                    if (type->type_align > __STDCPP_DEFAULT_NEW_ALIGNMENT__)
-                        vptr = ::operator new(type->type_size,
-                                              (std::align_val_t) type->type_align);
-                    else
-                #endif
-                vptr = ::operator new(type->type_size);
-            }
-        }
-        value = vptr;
-    }
-    bool try_implicit_casts(handle src, bool convert) {
-        for (auto &cast : typeinfo->implicit_casts) {
-            type_caster_generic sub_caster(*cast.first);
-            if (sub_caster.load(src, convert)) {
-                value = cast.second(sub_caster.value);
-                return true;
-            }
-        }
-        return false;
-    }
-    bool try_direct_conversions(handle src) {
-        for (auto &converter : *typeinfo->direct_conversions) {
-            if (converter(src.ptr(), value))
-                return true;
-        }
-        return false;
-    }
-    void check_holder_compat() {}
-
-    PYBIND11_NOINLINE static void *local_load(PyObject *src, const type_info *ti) {
-        auto caster = type_caster_generic(ti);
-        if (caster.load(src, false))
-            return caster.value;
-        return nullptr;
-    }
-
-    /// Try to load with foreign typeinfo, if available. Used when there is no
-    /// native typeinfo, or when the native one wasn't able to produce a value.
-    PYBIND11_NOINLINE bool try_load_foreign_module_local(handle src) {
-        constexpr auto *local_key = PYBIND11_MODULE_LOCAL_ID;
-        const auto pytype = src.get_type();
-        if (!hasattr(pytype, local_key))
-            return false;
-
-        type_info *foreign_typeinfo = reinterpret_borrow<capsule>(getattr(pytype, local_key));
-        // Only consider this foreign loader if actually foreign and is a loader of the correct cpp type
-        if (foreign_typeinfo->module_local_load == &local_load
-            || (cpptype && !same_type(*cpptype, *foreign_typeinfo->cpptype)))
-            return false;
-
-        if (auto result = foreign_typeinfo->module_local_load(src.ptr(), foreign_typeinfo)) {
-            value = result;
-            return true;
-        }
-        return false;
-    }
-
-    // Implementation of `load`; this takes the type of `this` so that it can dispatch the relevant
-    // bits of code between here and copyable_holder_caster where the two classes need different
-    // logic (without having to resort to virtual inheritance).
-    template <typename ThisT>
-    PYBIND11_NOINLINE bool load_impl(handle src, bool convert) {
-        if (!src) return false;
-        if (!typeinfo) return try_load_foreign_module_local(src);
-        if (src.is_none()) {
-            // Defer accepting None to other overloads (if we aren't in convert mode):
-            if (!convert) return false;
-            value = nullptr;
-            return true;
-        }
-
-        auto &this_ = static_cast<ThisT &>(*this);
-        this_.check_holder_compat();
-
-        PyTypeObject *srctype = Py_TYPE(src.ptr());
-
-        // Case 1: If src is an exact type match for the target type then we can reinterpret_cast
-        // the instance's value pointer to the target type:
-        if (srctype == typeinfo->type) {
-            this_.load_value(reinterpret_cast<instance *>(src.ptr())->get_value_and_holder());
-            return true;
-        }
-        // Case 2: We have a derived class
-        else if (PyType_IsSubtype(srctype, typeinfo->type)) {
-            auto &bases = all_type_info(srctype);
-            bool no_cpp_mi = typeinfo->simple_type;
-
-            // Case 2a: the python type is a Python-inherited derived class that inherits from just
-            // one simple (no MI) pybind11 class, or is an exact match, so the C++ instance is of
-            // the right type and we can use reinterpret_cast.
-            // (This is essentially the same as case 2b, but because not using multiple inheritance
-            // is extremely common, we handle it specially to avoid the loop iterator and type
-            // pointer lookup overhead)
-            if (bases.size() == 1 && (no_cpp_mi || bases.front()->type == typeinfo->type)) {
-                this_.load_value(reinterpret_cast<instance *>(src.ptr())->get_value_and_holder());
-                return true;
-            }
-            // Case 2b: the python type inherits from multiple C++ bases.  Check the bases to see if
-            // we can find an exact match (or, for a simple C++ type, an inherited match); if so, we
-            // can safely reinterpret_cast to the relevant pointer.
-            else if (bases.size() > 1) {
-                for (auto base : bases) {
-                    if (no_cpp_mi ? PyType_IsSubtype(base->type, typeinfo->type) : base->type == typeinfo->type) {
-                        this_.load_value(reinterpret_cast<instance *>(src.ptr())->get_value_and_holder(base));
-                        return true;
-                    }
-                }
-            }
-
-            // Case 2c: C++ multiple inheritance is involved and we couldn't find an exact type match
-            // in the registered bases, above, so try implicit casting (needed for proper C++ casting
-            // when MI is involved).
-            if (this_.try_implicit_casts(src, convert))
-                return true;
-        }
-
-        // Perform an implicit conversion
-        if (convert) {
-            for (auto &converter : typeinfo->implicit_conversions) {
-                auto temp = reinterpret_steal<object>(converter(src.ptr(), typeinfo->type));
-                if (load_impl<ThisT>(temp, false)) {
-                    loader_life_support::add_patient(temp);
-                    return true;
-                }
-            }
-            if (this_.try_direct_conversions(src))
-                return true;
-        }
-
-        // Failed to match local typeinfo. Try again with global.
-        if (typeinfo->module_local) {
-            if (auto gtype = get_global_type_info(*typeinfo->cpptype)) {
-                typeinfo = gtype;
-                return load(src, false);
-            }
-        }
-
-        // Global typeinfo has precedence over foreign module_local
-        return try_load_foreign_module_local(src);
-    }
-
-
-    // Called to do type lookup and wrap the pointer and type in a pair when a dynamic_cast
-    // isn't needed or can't be used.  If the type is unknown, sets the error and returns a pair
-    // with .second = nullptr.  (p.first = nullptr is not an error: it becomes None).
-    PYBIND11_NOINLINE static std::pair<const void *, const type_info *> src_and_type(
-            const void *src, const std::type_info &cast_type, const std::type_info *rtti_type = nullptr) {
-        if (auto *tpi = get_type_info(cast_type))
-            return {src, const_cast<const type_info *>(tpi)};
-
-        // Not found, set error:
-        std::string tname = rtti_type ? rtti_type->name() : cast_type.name();
-        detail::clean_type_id(tname);
-        std::string msg = "Unregistered type : " + tname;
-        PyErr_SetString(PyExc_TypeError, msg.c_str());
-        return {nullptr, nullptr};
-    }
-
-    const type_info *typeinfo = nullptr;
-    const std::type_info *cpptype = nullptr;
-    void *value = nullptr;
-};
-
-/**
- * Determine suitable casting operator for pointer-or-lvalue-casting type casters.  The type caster
- * needs to provide `operator T*()` and `operator T&()` operators.
- *
- * If the type supports moving the value away via an `operator T&&() &&` method, it should use
- * `movable_cast_op_type` instead.
- */
-template <typename T>
-using cast_op_type =
-    conditional_t<std::is_pointer<remove_reference_t<T>>::value,
-        typename std::add_pointer<intrinsic_t<T>>::type,
-        typename std::add_lvalue_reference<intrinsic_t<T>>::type>;
-
-/**
- * Determine suitable casting operator for a type caster with a movable value.  Such a type caster
- * needs to provide `operator T*()`, `operator T&()`, and `operator T&&() &&`.  The latter will be
- * called in appropriate contexts where the value can be moved rather than copied.
- *
- * These operator are automatically provided when using the PYBIND11_TYPE_CASTER macro.
- */
-template <typename T>
-using movable_cast_op_type =
-    conditional_t<std::is_pointer<typename std::remove_reference<T>::type>::value,
-        typename std::add_pointer<intrinsic_t<T>>::type,
-    conditional_t<std::is_rvalue_reference<T>::value,
-        typename std::add_rvalue_reference<intrinsic_t<T>>::type,
-        typename std::add_lvalue_reference<intrinsic_t<T>>::type>>;
-
-// std::is_copy_constructible isn't quite enough: it lets std::vector<T> (and similar) through when
-// T is non-copyable, but code containing such a copy constructor fails to actually compile.
-template <typename T, typename SFINAE = void> struct is_copy_constructible : std::is_copy_constructible<T> {};
-
-// Specialization for types that appear to be copy constructible but also look like stl containers
-// (we specifically check for: has `value_type` and `reference` with `reference = value_type&`): if
-// so, copy constructability depends on whether the value_type is copy constructible.
-template <typename Container> struct is_copy_constructible<Container, enable_if_t<all_of<
-        std::is_copy_constructible<Container>,
-        std::is_same<typename Container::value_type &, typename Container::reference>
-    >::value>> : is_copy_constructible<typename Container::value_type> {};
-
-#if !defined(PYBIND11_CPP17)
-// Likewise for std::pair before C++17 (which mandates that the copy constructor not exist when the
-// two types aren't themselves copy constructible).
-template <typename T1, typename T2> struct is_copy_constructible<std::pair<T1, T2>>
-    : all_of<is_copy_constructible<T1>, is_copy_constructible<T2>> {};
-#endif
-
-NAMESPACE_END(detail)
-
-// polymorphic_type_hook<itype>::get(src, tinfo) determines whether the object pointed
-// to by `src` actually is an instance of some class derived from `itype`.
-// If so, it sets `tinfo` to point to the std::type_info representing that derived
-// type, and returns a pointer to the start of the most-derived object of that type
-// (in which `src` is a subobject; this will be the same address as `src` in most
-// single inheritance cases). If not, or if `src` is nullptr, it simply returns `src`
-// and leaves `tinfo` at its default value of nullptr.
-//
-// The default polymorphic_type_hook just returns src. A specialization for polymorphic
-// types determines the runtime type of the passed object and adjusts the this-pointer
-// appropriately via dynamic_cast<void*>. This is what enables a C++ Animal* to appear
-// to Python as a Dog (if Dog inherits from Animal, Animal is polymorphic, Dog is
-// registered with pybind11, and this Animal is in fact a Dog).
-//
-// You may specialize polymorphic_type_hook yourself for types that want to appear
-// polymorphic to Python but do not use C++ RTTI. (This is a not uncommon pattern
-// in performance-sensitive applications, used most notably in LLVM.)
-template <typename itype, typename SFINAE = void>
-struct polymorphic_type_hook
-{
-    static const void *get(const itype *src, const std::type_info*&) { return src; }
-};
-template <typename itype>
-struct polymorphic_type_hook<itype, detail::enable_if_t<std::is_polymorphic<itype>::value>>
-{
-    static const void *get(const itype *src, const std::type_info*& type) {
-        type = src ? &typeid(*src) : nullptr;
-        return dynamic_cast<const void*>(src);
-    }
-};
-
-NAMESPACE_BEGIN(detail)
-
-/// Generic type caster for objects stored on the heap
-template <typename type> class type_caster_base : public type_caster_generic {
-    using itype = intrinsic_t<type>;
-
-public:
-    static constexpr auto name = _<type>();
-
-    type_caster_base() : type_caster_base(typeid(type)) { }
-    explicit type_caster_base(const std::type_info &info) : type_caster_generic(info) { }
-
-    static handle cast(const itype &src, return_value_policy policy, handle parent) {
-        if (policy == return_value_policy::automatic || policy == return_value_policy::automatic_reference)
-            policy = return_value_policy::copy;
-        return cast(&src, policy, parent);
-    }
-
-    static handle cast(itype &&src, return_value_policy, handle parent) {
-        return cast(&src, return_value_policy::move, parent);
-    }
-
-    // Returns a (pointer, type_info) pair taking care of necessary type lookup for a
-    // polymorphic type (using RTTI by default, but can be overridden by specializing
-    // polymorphic_type_hook). If the instance isn't derived, returns the base version.
-    static std::pair<const void *, const type_info *> src_and_type(const itype *src) {
-        auto &cast_type = typeid(itype);
-        const std::type_info *instance_type = nullptr;
-        const void *vsrc = polymorphic_type_hook<itype>::get(src, instance_type);
-        if (instance_type && !same_type(cast_type, *instance_type)) {
-            // This is a base pointer to a derived type. If the derived type is registered
-            // with pybind11, we want to make the full derived object available.
-            // In the typical case where itype is polymorphic, we get the correct
-            // derived pointer (which may be != base pointer) by a dynamic_cast to
-            // most derived type. If itype is not polymorphic, we won't get here
-            // except via a user-provided specialization of polymorphic_type_hook,
-            // and the user has promised that no this-pointer adjustment is
-            // required in that case, so it's OK to use static_cast.
-            if (const auto *tpi = get_type_info(*instance_type))
-                return {vsrc, tpi};
-        }
-        // Otherwise we have either a nullptr, an `itype` pointer, or an unknown derived pointer, so
-        // don't do a cast
-        return type_caster_generic::src_and_type(src, cast_type, instance_type);
-    }
-
-    static handle cast(const itype *src, return_value_policy policy, handle parent) {
-        auto st = src_and_type(src);
-        return type_caster_generic::cast(
-            st.first, policy, parent, st.second,
-            make_copy_constructor(src), make_move_constructor(src));
-    }
-
-    static handle cast_holder(const itype *src, const void *holder) {
-        auto st = src_and_type(src);
-        return type_caster_generic::cast(
-            st.first, return_value_policy::take_ownership, {}, st.second,
-            nullptr, nullptr, holder);
-    }
-
-    template <typename T> using cast_op_type = detail::cast_op_type<T>;
-
-    operator itype*() { return (type *) value; }
-    operator itype&() { if (!value) throw reference_cast_error(); return *((itype *) value); }
-
-protected:
-    using Constructor = void *(*)(const void *);
-
-    /* Only enabled when the types are {copy,move}-constructible *and* when the type
-       does not have a private operator new implementation. */
-    template <typename T, typename = enable_if_t<is_copy_constructible<T>::value>>
-    static auto make_copy_constructor(const T *x) -> decltype(new T(*x), Constructor{}) {
-        return [](const void *arg) -> void * {
-            return new T(*reinterpret_cast<const T *>(arg));
-        };
-    }
-
-    template <typename T, typename = enable_if_t<std::is_move_constructible<T>::value>>
-    static auto make_move_constructor(const T *x) -> decltype(new T(std::move(*const_cast<T *>(x))), Constructor{}) {
-        return [](const void *arg) -> void * {
-            return new T(std::move(*const_cast<T *>(reinterpret_cast<const T *>(arg))));
-        };
-    }
-
-    static Constructor make_copy_constructor(...) { return nullptr; }
-    static Constructor make_move_constructor(...) { return nullptr; }
-};
-
-template <typename type, typename SFINAE = void> class type_caster : public type_caster_base<type> { };
-template <typename type> using make_caster = type_caster<intrinsic_t<type>>;
+template <typename type, typename SFINAE = void>
+class type_caster : public type_caster_base<type> {};
+template <typename type>
+using make_caster = type_caster<intrinsic_t<type>>;
 
 // Shortcut for calling a caster's `cast_op_type` cast operator for casting a type_caster to a T
-template <typename T> typename make_caster<T>::template cast_op_type<T> cast_op(make_caster<T> &caster) {
+template <typename T>
+typename make_caster<T>::template cast_op_type<T> cast_op(make_caster<T> &caster) {
     return caster.operator typename make_caster<T>::template cast_op_type<T>();
 }
-template <typename T> typename make_caster<T>::template cast_op_type<typename std::add_rvalue_reference<T>::type>
+template <typename T>
+typename make_caster<T>::template cast_op_type<typename std::add_rvalue_reference<T>::type>
 cast_op(make_caster<T> &&caster) {
-    return std::move(caster).operator
-        typename make_caster<T>::template cast_op_type<typename std::add_rvalue_reference<T>::type>();
+    return std::move(caster).operator typename make_caster<T>::
+        template cast_op_type<typename std::add_rvalue_reference<T>::type>();
 }
 
-template <typename type> class type_caster<std::reference_wrapper<type>> {
+template <typename type>
+class type_caster<std::reference_wrapper<type>> {
 private:
     using caster_t = make_caster<type>;
     caster_t subcaster;
-    using subcaster_cast_op_type = typename caster_t::template cast_op_type<type>;
-    static_assert(std::is_same<typename std::remove_const<type>::type &, subcaster_cast_op_type>::value,
-            "std::reference_wrapper<T> caster requires T to have a caster with an `T &` operator");
+    using reference_t = type &;
+    using subcaster_cast_op_type = typename caster_t::template cast_op_type<reference_t>;
+
+    static_assert(
+        std::is_same<typename std::remove_const<type>::type &, subcaster_cast_op_type>::value
+            || std::is_same<reference_t, subcaster_cast_op_type>::value,
+        "std::reference_wrapper<T> caster requires T to have a caster with an "
+        "`operator T &()` or `operator const T &()`");
+
 public:
     bool load(handle src, bool convert) { return subcaster.load(src, convert); }
     static constexpr auto name = caster_t::name;
-    static handle cast(const std::reference_wrapper<type> &src, return_value_policy policy, handle parent) {
+    static handle
+    cast(const std::reference_wrapper<type> &src, return_value_policy policy, handle parent) {
         // It is definitely wrong to take ownership of this pointer, so mask that rvp
-        if (policy == return_value_policy::take_ownership || policy == return_value_policy::automatic)
+        if (policy == return_value_policy::take_ownership
+            || policy == return_value_policy::automatic) {
             policy = return_value_policy::automatic_reference;
+        }
         return caster_t::cast(&src.get(), policy, parent);
     }
-    template <typename T> using cast_op_type = std::reference_wrapper<type>;
-    operator std::reference_wrapper<type>() { return subcaster.operator subcaster_cast_op_type&(); }
+    template <typename T>
+    using cast_op_type = std::reference_wrapper<type>;
+    explicit operator std::reference_wrapper<type>() { return cast_op<type &>(subcaster); }
 };
 
-#define PYBIND11_TYPE_CASTER(type, py_name) \
-    protected: \
-        type value; \
-    public: \
-        static constexpr auto name = py_name; \
-        template <typename T_, enable_if_t<std::is_same<type, remove_cv_t<T_>>::value, int> = 0> \
-        static handle cast(T_ *src, return_value_policy policy, handle parent) { \
-            if (!src) return none().release(); \
-            if (policy == return_value_policy::take_ownership) { \
-                auto h = cast(std::move(*src), policy, parent); delete src; return h; \
-            } else { \
-                return cast(*src, policy, parent); \
-            } \
-        } \
-        operator type*() { return &value; } \
-        operator type&() { return value; } \
-        operator type&&() && { return std::move(value); } \
-        template <typename T_> using cast_op_type = pybind11::detail::movable_cast_op_type<T_>
-
-
-template <typename CharT> using is_std_char_type = any_of<
-    std::is_same<CharT, char>, /* std::string */
-    std::is_same<CharT, char16_t>, /* std::u16string */
-    std::is_same<CharT, char32_t>, /* std::u32string */
-    std::is_same<CharT, wchar_t> /* std::wstring */
->;
+#define PYBIND11_TYPE_CASTER(type, py_name)                                                       \
+protected:                                                                                        \
+    type value;                                                                                   \
+                                                                                                  \
+public:                                                                                           \
+    static constexpr auto name = py_name;                                                         \
+    template <typename T_,                                                                        \
+              ::pybind11::detail::enable_if_t<                                                    \
+                  std::is_same<type, ::pybind11::detail::remove_cv_t<T_>>::value,                 \
+                  int>                                                                            \
+              = 0>                                                                                \
+    static ::pybind11::handle cast(                                                               \
+        T_ *src, ::pybind11::return_value_policy policy, ::pybind11::handle parent) {             \
+        if (!src)                                                                                 \
+            return ::pybind11::none().release();                                                  \
+        if (policy == ::pybind11::return_value_policy::take_ownership) {                          \
+            auto h = cast(std::move(*src), policy, parent);                                       \
+            delete src;                                                                           \
+            return h;                                                                             \
+        }                                                                                         \
+        return cast(*src, policy, parent);                                                        \
+    }                                                                                             \
+    operator type *() { return &value; }               /* NOLINT(bugprone-macro-parentheses) */   \
+    operator type &() { return value; }                /* NOLINT(bugprone-macro-parentheses) */   \
+    operator type &&() && { return std::move(value); } /* NOLINT(bugprone-macro-parentheses) */   \
+    template <typename T_>                                                                        \
+    using cast_op_type = ::pybind11::detail::movable_cast_op_type<T_>
+
+template <typename CharT>
+using is_std_char_type = any_of<std::is_same<CharT, char>, /* std::string */
+#if defined(PYBIND11_HAS_U8STRING)
+                                std::is_same<CharT, char8_t>, /* std::u8string */
+#endif
+                                std::is_same<CharT, char16_t>, /* std::u16string */
+                                std::is_same<CharT, char32_t>, /* std::u32string */
+                                std::is_same<CharT, wchar_t>   /* std::wstring */
+                                >;
 
 template <typename T>
 struct type_caster<T, enable_if_t<std::is_arithmetic<T>::value && !is_std_char_type<T>::value>> {
     using _py_type_0 = conditional_t<sizeof(T) <= sizeof(long), long, long long>;
-    using _py_type_1 = conditional_t<std::is_signed<T>::value, _py_type_0, typename std::make_unsigned<_py_type_0>::type>;
+    using _py_type_1 = conditional_t<std::is_signed<T>::value,
+                                     _py_type_0,
+                                     typename std::make_unsigned<_py_type_0>::type>;
     using py_type = conditional_t<std::is_floating_point<T>::value, double, _py_type_1>;
-public:
 
+public:
     bool load(handle src, bool convert) {
         py_type py_value;
 
-        if (!src)
+        if (!src) {
             return false;
+        }
+
+#if !defined(PYPY_VERSION)
+        auto index_check = [](PyObject *o) { return PyIndex_Check(o); };
+#else
+        // In PyPy 7.3.3, `PyIndex_Check` is implemented by calling `__index__`,
+        // while CPython only considers the existence of `nb_index`/`__index__`.
+        auto index_check = [](PyObject *o) { return hasattr(o, "__index__"); };
+#endif
 
         if (std::is_floating_point<T>::value) {
-            if (convert || PyFloat_Check(src.ptr()))
+            if (convert || PyFloat_Check(src.ptr())) {
                 py_value = (py_type) PyFloat_AsDouble(src.ptr());
-            else
+            } else {
                 return false;
-        } else if (PyFloat_Check(src.ptr())) {
+            }
+        } else if (PyFloat_Check(src.ptr())
+                   || (!convert && !PYBIND11_LONG_CHECK(src.ptr()) && !index_check(src.ptr()))) {
             return false;
-        } else if (std::is_unsigned<py_type>::value) {
-            py_value = as_unsigned<py_type>(src.ptr());
-        } else { // signed integer:
-            py_value = sizeof(T) <= sizeof(long)
-                ? (py_type) PyLong_AsLong(src.ptr())
-                : (py_type) PYBIND11_LONG_AS_LONGLONG(src.ptr());
+        } else {
+            handle src_or_index = src;
+            // PyPy: 7.3.7's 3.8 does not implement PyLong_*'s __index__ calls.
+#if PY_VERSION_HEX < 0x03080000 || defined(PYPY_VERSION)
+            object index;
+            if (!PYBIND11_LONG_CHECK(src.ptr())) { // So: index_check(src.ptr())
+                index = reinterpret_steal<object>(PyNumber_Index(src.ptr()));
+                if (!index) {
+                    PyErr_Clear();
+                    if (!convert)
+                        return false;
+                } else {
+                    src_or_index = index;
+                }
+            }
+#endif
+            if (std::is_unsigned<py_type>::value) {
+                py_value = as_unsigned<py_type>(src_or_index.ptr());
+            } else { // signed integer:
+                py_value = sizeof(T) <= sizeof(long)
+                               ? (py_type) PyLong_AsLong(src_or_index.ptr())
+                               : (py_type) PYBIND11_LONG_AS_LONGLONG(src_or_index.ptr());
+            }
         }
 
+        // Python API reported an error
         bool py_err = py_value == (py_type) -1 && PyErr_Occurred();
-        if (py_err || (std::is_integral<T>::value && sizeof(py_type) != sizeof(T) &&
-                       (py_value < (py_type) std::numeric_limits<T>::min() ||
-                        py_value > (py_type) std::numeric_limits<T>::max()))) {
-            bool type_error = py_err && PyErr_ExceptionMatches(
-#if PY_VERSION_HEX < 0x03000000 && !defined(PYPY_VERSION)
-                PyExc_SystemError
-#else
-                PyExc_TypeError
-#endif
-            );
+
+        // Check to see if the conversion is valid (integers should match exactly)
+        // Signed/unsigned checks happen elsewhere
+        if (py_err
+            || (std::is_integral<T>::value && sizeof(py_type) != sizeof(T)
+                && py_value != (py_type) (T) py_value)) {
             PyErr_Clear();
-            if (type_error && convert && PyNumber_Check(src.ptr())) {
+            if (py_err && convert && (PyNumber_Check(src.ptr()) != 0)) {
                 auto tmp = reinterpret_steal<object>(std::is_floating_point<T>::value
-                                                     ? PyNumber_Float(src.ptr())
-                                                     : PyNumber_Long(src.ptr()));
+                                                         ? PyNumber_Float(src.ptr())
+                                                         : PyNumber_Long(src.ptr()));
                 PyErr_Clear();
                 return load(tmp, false);
             }
             return false;
         }
 
         value = (T) py_value;
         return true;
     }
 
-    template<typename U = T>
+    template <typename U = T>
     static typename std::enable_if<std::is_floating_point<U>::value, handle>::type
     cast(U src, return_value_policy /* policy */, handle /* parent */) {
         return PyFloat_FromDouble((double) src);
     }
 
-    template<typename U = T>
-    static typename std::enable_if<!std::is_floating_point<U>::value && std::is_signed<U>::value && (sizeof(U) <= sizeof(long)), handle>::type
+    template <typename U = T>
+    static typename std::enable_if<!std::is_floating_point<U>::value && std::is_signed<U>::value
+                                       && (sizeof(U) <= sizeof(long)),
+                                   handle>::type
     cast(U src, return_value_policy /* policy */, handle /* parent */) {
         return PYBIND11_LONG_FROM_SIGNED((long) src);
     }
 
-    template<typename U = T>
-    static typename std::enable_if<!std::is_floating_point<U>::value && std::is_unsigned<U>::value && (sizeof(U) <= sizeof(unsigned long)), handle>::type
+    template <typename U = T>
+    static typename std::enable_if<!std::is_floating_point<U>::value && std::is_unsigned<U>::value
+                                       && (sizeof(U) <= sizeof(unsigned long)),
+                                   handle>::type
     cast(U src, return_value_policy /* policy */, handle /* parent */) {
         return PYBIND11_LONG_FROM_UNSIGNED((unsigned long) src);
     }
 
-    template<typename U = T>
-    static typename std::enable_if<!std::is_floating_point<U>::value && std::is_signed<U>::value && (sizeof(U) > sizeof(long)), handle>::type
+    template <typename U = T>
+    static typename std::enable_if<!std::is_floating_point<U>::value && std::is_signed<U>::value
+                                       && (sizeof(U) > sizeof(long)),
+                                   handle>::type
     cast(U src, return_value_policy /* policy */, handle /* parent */) {
         return PyLong_FromLongLong((long long) src);
     }
 
-    template<typename U = T>
-    static typename std::enable_if<!std::is_floating_point<U>::value && std::is_unsigned<U>::value && (sizeof(U) > sizeof(unsigned long)), handle>::type
+    template <typename U = T>
+    static typename std::enable_if<!std::is_floating_point<U>::value && std::is_unsigned<U>::value
+                                       && (sizeof(U) > sizeof(unsigned long)),
+                                   handle>::type
     cast(U src, return_value_policy /* policy */, handle /* parent */) {
         return PyLong_FromUnsignedLongLong((unsigned long long) src);
     }
 
-    PYBIND11_TYPE_CASTER(T, _<std::is_integral<T>::value>("int", "float"));
+    PYBIND11_TYPE_CASTER(T, const_name<std::is_integral<T>::value>("int", "float"));
 };
 
-template<typename T> struct void_caster {
+template <typename T>
+struct void_caster {
 public:
     bool load(handle src, bool) {
-        if (src && src.is_none())
+        if (src && src.is_none()) {
             return true;
+        }
         return false;
     }
     static handle cast(T, return_value_policy /* policy */, handle /* parent */) {
-        return none().inc_ref();
+        return none().release();
     }
-    PYBIND11_TYPE_CASTER(T, _("None"));
+    PYBIND11_TYPE_CASTER(T, const_name("None"));
 };
 
-template <> class type_caster<void_type> : public void_caster<void_type> {};
+template <>
+class type_caster<void_type> : public void_caster<void_type> {};
 
-template <> class type_caster<void> : public type_caster<void_type> {
+template <>
+class type_caster<void> : public type_caster<void_type> {
 public:
     using type_caster<void_type>::cast;
 
     bool load(handle h, bool) {
         if (!h) {
             return false;
-        } else if (h.is_none()) {
+        }
+        if (h.is_none()) {
             value = nullptr;
             return true;
         }
 
         /* Check if this is a capsule */
         if (isinstance<capsule>(h)) {
             value = reinterpret_borrow<capsule>(h);
             return true;
         }
 
         /* Check if this is a C++ type */
-        auto &bases = all_type_info((PyTypeObject *) h.get_type().ptr());
+        const auto &bases = all_type_info((PyTypeObject *) type::handle_of(h).ptr());
         if (bases.size() == 1) { // Only allowing loading from a single-value type
             value = values_and_holders(reinterpret_cast<instance *>(h.ptr())).begin()->value_ptr();
             return true;
         }
 
         /* Fail */
         return false;
     }
 
     static handle cast(const void *ptr, return_value_policy /* policy */, handle /* parent */) {
-        if (ptr)
+        if (ptr) {
             return capsule(ptr).release();
-        else
-            return none().inc_ref();
+        }
+        return none().release();
     }
 
-    template <typename T> using cast_op_type = void*&;
-    operator void *&() { return value; }
-    static constexpr auto name = _("capsule");
+    template <typename T>
+    using cast_op_type = void *&;
+    explicit operator void *&() { return value; }
+    static constexpr auto name = const_name("capsule");
+
 private:
     void *value = nullptr;
 };
 
-template <> class type_caster<std::nullptr_t> : public void_caster<std::nullptr_t> { };
+template <>
+class type_caster<std::nullptr_t> : public void_caster<std::nullptr_t> {};
 
-template <> class type_caster<bool> {
+template <>
+class type_caster<bool> {
 public:
     bool load(handle src, bool convert) {
-        if (!src) return false;
-        else if (src.ptr() == Py_True) { value = true; return true; }
-        else if (src.ptr() == Py_False) { value = false; return true; }
-        else if (convert || !strcmp("numpy.bool_", Py_TYPE(src.ptr())->tp_name)) {
+        if (!src) {
+            return false;
+        }
+        if (src.ptr() == Py_True) {
+            value = true;
+            return true;
+        }
+        if (src.ptr() == Py_False) {
+            value = false;
+            return true;
+        }
+        if (convert || (std::strcmp("numpy.bool_", Py_TYPE(src.ptr())->tp_name) == 0)) {
             // (allow non-implicit conversion for numpy booleans)
 
             Py_ssize_t res = -1;
             if (src.is_none()) {
-                res = 0;  // None is implicitly converted to False
+                res = 0; // None is implicitly converted to False
             }
-            #if defined(PYPY_VERSION)
-            // On PyPy, check that "__bool__" (or "__nonzero__" on Python 2.7) attr exists
+#if defined(PYPY_VERSION)
+            // On PyPy, check that "__bool__" attr exists
             else if (hasattr(src, PYBIND11_BOOL_ATTR)) {
                 res = PyObject_IsTrue(src.ptr());
             }
-            #else
+#else
             // Alternate approach for CPython: this does the same as the above, but optimized
             // using the CPython API so as to avoid an unneeded attribute lookup.
-            else if (auto tp_as_number = src.ptr()->ob_type->tp_as_number) {
+            else if (auto *tp_as_number = src.ptr()->ob_type->tp_as_number) {
                 if (PYBIND11_NB_BOOL(tp_as_number)) {
                     res = (*PYBIND11_NB_BOOL(tp_as_number))(src.ptr());
                 }
             }
-            #endif
+#endif
             if (res == 0 || res == 1) {
-                value = (bool) res;
+                value = (res != 0);
                 return true;
             }
+            PyErr_Clear();
         }
         return false;
     }
     static handle cast(bool src, return_value_policy /* policy */, handle /* parent */) {
         return handle(src ? Py_True : Py_False).inc_ref();
     }
-    PYBIND11_TYPE_CASTER(bool, _("bool"));
+    PYBIND11_TYPE_CASTER(bool, const_name("bool"));
 };
 
 // Helper class for UTF-{8,16,32} C++ stl strings:
-template <typename StringType, bool IsView = false> struct string_caster {
+template <typename StringType, bool IsView = false>
+struct string_caster {
     using CharT = typename StringType::value_type;
 
     // Simplify life by being able to assume standard char sizes (the standard only guarantees
     // minimums, but Python requires exact sizes)
-    static_assert(!std::is_same<CharT, char>::value || sizeof(CharT) == 1, "Unsupported char size != 1");
-    static_assert(!std::is_same<CharT, char16_t>::value || sizeof(CharT) == 2, "Unsupported char16_t size != 2");
-    static_assert(!std::is_same<CharT, char32_t>::value || sizeof(CharT) == 4, "Unsupported char32_t size != 4");
+    static_assert(!std::is_same<CharT, char>::value || sizeof(CharT) == 1,
+                  "Unsupported char size != 1");
+#if defined(PYBIND11_HAS_U8STRING)
+    static_assert(!std::is_same<CharT, char8_t>::value || sizeof(CharT) == 1,
+                  "Unsupported char8_t size != 1");
+#endif
+    static_assert(!std::is_same<CharT, char16_t>::value || sizeof(CharT) == 2,
+                  "Unsupported char16_t size != 2");
+    static_assert(!std::is_same<CharT, char32_t>::value || sizeof(CharT) == 4,
+                  "Unsupported char32_t size != 4");
     // wchar_t can be either 16 bits (Windows) or 32 (everywhere else)
     static_assert(!std::is_same<CharT, wchar_t>::value || sizeof(CharT) == 2 || sizeof(CharT) == 4,
-            "Unsupported wchar_t size != 2/4");
+                  "Unsupported wchar_t size != 2/4");
     static constexpr size_t UTF_N = 8 * sizeof(CharT);
 
     bool load(handle src, bool) {
-#if PY_MAJOR_VERSION < 3
-        object temp;
-#endif
         handle load_src = src;
         if (!src) {
             return false;
-        } else if (!PyUnicode_Check(load_src.ptr())) {
-#if PY_MAJOR_VERSION >= 3
-            return load_bytes(load_src);
-#else
-            if (sizeof(CharT) == 1) {
-                return load_bytes(load_src);
-            }
+        }
+        if (!PyUnicode_Check(load_src.ptr())) {
+            return load_raw(load_src);
+        }
 
-            // The below is a guaranteed failure in Python 3 when PyUnicode_Check returns false
-            if (!PYBIND11_BYTES_CHECK(load_src.ptr()))
+        // For UTF-8 we avoid the need for a temporary `bytes` object by using
+        // `PyUnicode_AsUTF8AndSize`.
+        if (UTF_N == 8) {
+            Py_ssize_t size = -1;
+            const auto *buffer
+                = reinterpret_cast<const CharT *>(PyUnicode_AsUTF8AndSize(load_src.ptr(), &size));
+            if (!buffer) {
+                PyErr_Clear();
                 return false;
-
-            temp = reinterpret_steal<object>(PyUnicode_FromObject(load_src.ptr()));
-            if (!temp) { PyErr_Clear(); return false; }
-            load_src = temp;
-#endif
+            }
+            value = StringType(buffer, static_cast<size_t>(size));
+            return true;
         }
 
-        object utfNbytes = reinterpret_steal<object>(PyUnicode_AsEncodedString(
-            load_src.ptr(), UTF_N == 8 ? "utf-8" : UTF_N == 16 ? "utf-16" : "utf-32", nullptr));
-        if (!utfNbytes) { PyErr_Clear(); return false; }
+        auto utfNbytes
+            = reinterpret_steal<object>(PyUnicode_AsEncodedString(load_src.ptr(),
+                                                                  UTF_N == 8    ? "utf-8"
+                                                                  : UTF_N == 16 ? "utf-16"
+                                                                                : "utf-32",
+                                                                  nullptr));
+        if (!utfNbytes) {
+            PyErr_Clear();
+            return false;
+        }
 
-        const CharT *buffer = reinterpret_cast<const CharT *>(PYBIND11_BYTES_AS_STRING(utfNbytes.ptr()));
+        const auto *buffer
+            = reinterpret_cast<const CharT *>(PYBIND11_BYTES_AS_STRING(utfNbytes.ptr()));
         size_t length = (size_t) PYBIND11_BYTES_SIZE(utfNbytes.ptr()) / sizeof(CharT);
-        if (UTF_N > 8) { buffer++; length--; } // Skip BOM for UTF-16/32
+        // Skip BOM for UTF-16/32
+        if (UTF_N > 8) {
+            buffer++;
+            length--;
+        }
         value = StringType(buffer, length);
 
         // If we're loading a string_view we need to keep the encoded Python object alive:
-        if (IsView)
+        if (IsView) {
             loader_life_support::add_patient(utfNbytes);
+        }
 
         return true;
     }
 
-    static handle cast(const StringType &src, return_value_policy /* policy */, handle /* parent */) {
+    static handle
+    cast(const StringType &src, return_value_policy /* policy */, handle /* parent */) {
         const char *buffer = reinterpret_cast<const char *>(src.data());
-        ssize_t nbytes = ssize_t(src.size() * sizeof(CharT));
+        auto nbytes = ssize_t(src.size() * sizeof(CharT));
         handle s = decode_utfN(buffer, nbytes);
-        if (!s) throw error_already_set();
+        if (!s) {
+            throw error_already_set();
+        }
         return s;
     }
 
-    PYBIND11_TYPE_CASTER(StringType, _(PYBIND11_STRING_NAME));
+    PYBIND11_TYPE_CASTER(StringType, const_name(PYBIND11_STRING_NAME));
 
 private:
     static handle decode_utfN(const char *buffer, ssize_t nbytes) {
 #if !defined(PYPY_VERSION)
-        return
-            UTF_N == 8  ? PyUnicode_DecodeUTF8(buffer, nbytes, nullptr) :
-            UTF_N == 16 ? PyUnicode_DecodeUTF16(buffer, nbytes, nullptr, nullptr) :
-                          PyUnicode_DecodeUTF32(buffer, nbytes, nullptr, nullptr);
+        return UTF_N == 8    ? PyUnicode_DecodeUTF8(buffer, nbytes, nullptr)
+               : UTF_N == 16 ? PyUnicode_DecodeUTF16(buffer, nbytes, nullptr, nullptr)
+                             : PyUnicode_DecodeUTF32(buffer, nbytes, nullptr, nullptr);
 #else
-        // PyPy seems to have multiple problems related to PyUnicode_UTF*: the UTF8 version
-        // sometimes segfaults for unknown reasons, while the UTF16 and 32 versions require a
-        // non-const char * arguments, which is also a nuisance, so bypass the whole thing by just
-        // passing the encoding as a string value, which works properly:
-        return PyUnicode_Decode(buffer, nbytes, UTF_N == 8 ? "utf-8" : UTF_N == 16 ? "utf-16" : "utf-32", nullptr);
+        // PyPy segfaults when on PyUnicode_DecodeUTF16 (and possibly on PyUnicode_DecodeUTF32 as
+        // well), so bypass the whole thing by just passing the encoding as a string value, which
+        // works properly:
+        return PyUnicode_Decode(buffer,
+                                nbytes,
+                                UTF_N == 8    ? "utf-8"
+                                : UTF_N == 16 ? "utf-16"
+                                              : "utf-32",
+                                nullptr);
 #endif
     }
 
-    // When loading into a std::string or char*, accept a bytes object as-is (i.e.
+    // When loading into a std::string or char*, accept a bytes/bytearray object as-is (i.e.
     // without any encoding/decoding attempt).  For other C++ char sizes this is a no-op.
     // which supports loading a unicode from a str, doesn't take this path.
     template <typename C = CharT>
-    bool load_bytes(enable_if_t<sizeof(C) == 1, handle> src) {
+    bool load_raw(enable_if_t<std::is_same<C, char>::value, handle> src) {
         if (PYBIND11_BYTES_CHECK(src.ptr())) {
-            // We were passed a Python 3 raw bytes; accept it into a std::string or char*
+            // We were passed raw bytes; accept it into a std::string or char*
             // without any encoding attempt.
             const char *bytes = PYBIND11_BYTES_AS_STRING(src.ptr());
-            if (bytes) {
-                value = StringType(bytes, (size_t) PYBIND11_BYTES_SIZE(src.ptr()));
-                return true;
+            if (!bytes) {
+                pybind11_fail("Unexpected PYBIND11_BYTES_AS_STRING() failure.");
             }
+            value = StringType(bytes, (size_t) PYBIND11_BYTES_SIZE(src.ptr()));
+            return true;
+        }
+        if (PyByteArray_Check(src.ptr())) {
+            // We were passed a bytearray; accept it into a std::string or char*
+            // without any encoding attempt.
+            const char *bytearray = PyByteArray_AsString(src.ptr());
+            if (!bytearray) {
+                pybind11_fail("Unexpected PyByteArray_AsString() failure.");
+            }
+            value = StringType(bytearray, (size_t) PyByteArray_Size(src.ptr()));
+            return true;
         }
 
         return false;
     }
 
     template <typename C = CharT>
-    bool load_bytes(enable_if_t<sizeof(C) != 1, handle>) { return false; }
+    bool load_raw(enable_if_t<!std::is_same<C, char>::value, handle>) {
+        return false;
+    }
 };
 
 template <typename CharT, class Traits, class Allocator>
-struct type_caster<std::basic_string<CharT, Traits, Allocator>, enable_if_t<is_std_char_type<CharT>::value>>
+struct type_caster<std::basic_string<CharT, Traits, Allocator>,
+                   enable_if_t<is_std_char_type<CharT>::value>>
     : string_caster<std::basic_string<CharT, Traits, Allocator>> {};
 
 #ifdef PYBIND11_HAS_STRING_VIEW
 template <typename CharT, class Traits>
-struct type_caster<std::basic_string_view<CharT, Traits>, enable_if_t<is_std_char_type<CharT>::value>>
+struct type_caster<std::basic_string_view<CharT, Traits>,
+                   enable_if_t<is_std_char_type<CharT>::value>>
     : string_caster<std::basic_string_view<CharT, Traits>, true> {};
 #endif
 
 // Type caster for C-style strings.  We basically use a std::string type caster, but also add the
 // ability to use None as a nullptr char* (which the string caster doesn't allow).
-template <typename CharT> struct type_caster<CharT, enable_if_t<is_std_char_type<CharT>::value>> {
+template <typename CharT>
+struct type_caster<CharT, enable_if_t<is_std_char_type<CharT>::value>> {
     using StringType = std::basic_string<CharT>;
-    using StringCaster = type_caster<StringType>;
+    using StringCaster = make_caster<StringType>;
     StringCaster str_caster;
     bool none = false;
     CharT one_char = 0;
+
 public:
     bool load(handle src, bool convert) {
-        if (!src) return false;
+        if (!src) {
+            return false;
+        }
         if (src.is_none()) {
             // Defer accepting None to other overloads (if we aren't in convert mode):
-            if (!convert) return false;
+            if (!convert) {
+                return false;
+            }
             none = true;
             return true;
         }
         return str_caster.load(src, convert);
     }
 
     static handle cast(const CharT *src, return_value_policy policy, handle parent) {
-        if (src == nullptr) return pybind11::none().inc_ref();
+        if (src == nullptr) {
+            return pybind11::none().release();
+        }
         return StringCaster::cast(StringType(src), policy, parent);
     }
 
     static handle cast(CharT src, return_value_policy policy, handle parent) {
         if (std::is_same<char, CharT>::value) {
             handle s = PyUnicode_DecodeLatin1((const char *) &src, 1, nullptr);
-            if (!s) throw error_already_set();
+            if (!s) {
+                throw error_already_set();
+            }
             return s;
         }
         return StringCaster::cast(StringType(1, src), policy, parent);
     }
 
-    operator CharT*() { return none ? nullptr : const_cast<CharT *>(static_cast<StringType &>(str_caster).c_str()); }
-    operator CharT&() {
-        if (none)
+    explicit operator CharT *() {
+        return none ? nullptr : const_cast<CharT *>(static_cast<StringType &>(str_caster).c_str());
+    }
+    explicit operator CharT &() {
+        if (none) {
             throw value_error("Cannot convert None to a character");
+        }
 
         auto &value = static_cast<StringType &>(str_caster);
         size_t str_len = value.size();
-        if (str_len == 0)
+        if (str_len == 0) {
             throw value_error("Cannot convert empty string to a character");
+        }
 
         // If we're in UTF-8 mode, we have two possible failures: one for a unicode character that
-        // is too high, and one for multiple unicode characters (caught later), so we need to figure
-        // out how long the first encoded character is in bytes to distinguish between these two
-        // errors.  We also allow want to allow unicode characters U+0080 through U+00FF, as those
-        // can fit into a single char value.
+        // is too high, and one for multiple unicode characters (caught later), so we need to
+        // figure out how long the first encoded character is in bytes to distinguish between these
+        // two errors.  We also allow want to allow unicode characters U+0080 through U+00FF, as
+        // those can fit into a single char value.
         if (StringCaster::UTF_N == 8 && str_len > 1 && str_len <= 4) {
-            unsigned char v0 = static_cast<unsigned char>(value[0]);
-            size_t char0_bytes = !(v0 & 0x80) ? 1 : // low bits only: 0-127
-                (v0 & 0xE0) == 0xC0 ? 2 : // 0b110xxxxx - start of 2-byte sequence
-                (v0 & 0xF0) == 0xE0 ? 3 : // 0b1110xxxx - start of 3-byte sequence
-                4; // 0b11110xxx - start of 4-byte sequence
+            auto v0 = static_cast<unsigned char>(value[0]);
+            // low bits only: 0-127
+            // 0b110xxxxx - start of 2-byte sequence
+            // 0b1110xxxx - start of 3-byte sequence
+            // 0b11110xxx - start of 4-byte sequence
+            size_t char0_bytes = (v0 & 0x80) == 0      ? 1
+                                 : (v0 & 0xE0) == 0xC0 ? 2
+                                 : (v0 & 0xF0) == 0xE0 ? 3
+                                                       : 4;
 
             if (char0_bytes == str_len) {
                 // If we have a 128-255 value, we can decode it into a single char:
                 if (char0_bytes == 2 && (v0 & 0xFC) == 0xC0) { // 0x110000xx 0x10xxxxxx
-                    one_char = static_cast<CharT>(((v0 & 3) << 6) + (static_cast<unsigned char>(value[1]) & 0x3F));
+                    one_char = static_cast<CharT>(((v0 & 3) << 6)
+                                                  + (static_cast<unsigned char>(value[1]) & 0x3F));
                     return one_char;
                 }
                 // Otherwise we have a single character, but it's > U+00FF
                 throw value_error("Character code point not in range(0x100)");
             }
         }
 
         // UTF-16 is much easier: we can only have a surrogate pair for values above U+FFFF, thus a
         // surrogate pair with total length 2 instantly indicates a range error (but not a "your
         // string was too long" error).
         else if (StringCaster::UTF_N == 16 && str_len == 2) {
             one_char = static_cast<CharT>(value[0]);
-            if (one_char >= 0xD800 && one_char < 0xE000)
+            if (one_char >= 0xD800 && one_char < 0xE000) {
                 throw value_error("Character code point not in range(0x10000)");
+            }
         }
 
-        if (str_len != 1)
+        if (str_len != 1) {
             throw value_error("Expected a character, but multi-character string found");
+        }
 
         one_char = value[0];
         return one_char;
     }
 
-    static constexpr auto name = _(PYBIND11_STRING_NAME);
-    template <typename _T> using cast_op_type = pybind11::detail::cast_op_type<_T>;
+    static constexpr auto name = const_name(PYBIND11_STRING_NAME);
+    template <typename _T>
+    using cast_op_type = pybind11::detail::cast_op_type<_T>;
 };
 
 // Base implementation for std::tuple and std::pair
-template <template<typename...> class Tuple, typename... Ts> class tuple_caster {
+template <template <typename...> class Tuple, typename... Ts>
+class tuple_caster {
     using type = Tuple<Ts...>;
     static constexpr auto size = sizeof...(Ts);
     using indices = make_index_sequence<size>;
-public:
 
+public:
     bool load(handle src, bool convert) {
-        if (!isinstance<sequence>(src))
+        if (!isinstance<sequence>(src)) {
             return false;
+        }
         const auto seq = reinterpret_borrow<sequence>(src);
-        if (seq.size() != size)
+        if (seq.size() != size) {
             return false;
+        }
         return load_impl(seq, convert, indices{});
     }
 
     template <typename T>
     static handle cast(T &&src, return_value_policy policy, handle parent) {
         return cast_impl(std::forward<T>(src), policy, parent, indices{});
     }
 
-    static constexpr auto name = _("Tuple[") + concat(make_caster<Ts>::name...) + _("]");
+    // copied from the PYBIND11_TYPE_CASTER macro
+    template <typename T>
+    static handle cast(T *src, return_value_policy policy, handle parent) {
+        if (!src) {
+            return none().release();
+        }
+        if (policy == return_value_policy::take_ownership) {
+            auto h = cast(std::move(*src), policy, parent);
+            delete src;
+            return h;
+        }
+        return cast(*src, policy, parent);
+    }
+
+    static constexpr auto name
+        = const_name("Tuple[") + concat(make_caster<Ts>::name...) + const_name("]");
 
-    template <typename T> using cast_op_type = type;
+    template <typename T>
+    using cast_op_type = type;
 
-    operator type() & { return implicit_cast(indices{}); }
-    operator type() && { return std::move(*this).implicit_cast(indices{}); }
+    explicit operator type() & { return implicit_cast(indices{}); }
+    explicit operator type() && { return std::move(*this).implicit_cast(indices{}); }
 
 protected:
     template <size_t... Is>
-    type implicit_cast(index_sequence<Is...>) & { return type(cast_op<Ts>(std::get<Is>(subcasters))...); }
+    type implicit_cast(index_sequence<Is...>) & {
+        return type(cast_op<Ts>(std::get<Is>(subcasters))...);
+    }
     template <size_t... Is>
-    type implicit_cast(index_sequence<Is...>) && { return type(cast_op<Ts>(std::move(std::get<Is>(subcasters)))...); }
+    type implicit_cast(index_sequence<Is...>) && {
+        return type(cast_op<Ts>(std::move(std::get<Is>(subcasters)))...);
+    }
 
     static constexpr bool load_impl(const sequence &, bool, index_sequence<>) { return true; }
 
     template <size_t... Is>
     bool load_impl(const sequence &seq, bool convert, index_sequence<Is...>) {
-        for (bool r : {std::get<Is>(subcasters).load(seq[Is], convert)...})
-            if (!r)
+#ifdef __cpp_fold_expressions
+        if ((... || !std::get<Is>(subcasters).load(seq[Is], convert))) {
+            return false;
+        }
+#else
+        for (bool r : {std::get<Is>(subcasters).load(seq[Is], convert)...}) {
+            if (!r) {
                 return false;
+            }
+        }
+#endif
         return true;
     }
 
     /* Implementation: Convert a C++ tuple into a Python tuple */
     template <typename T, size_t... Is>
-    static handle cast_impl(T &&src, return_value_policy policy, handle parent, index_sequence<Is...>) {
-        std::array<object, size> entries{{
-            reinterpret_steal<object>(make_caster<Ts>::cast(std::get<Is>(std::forward<T>(src)), policy, parent))...
-        }};
-        for (const auto &entry: entries)
-            if (!entry)
+    static handle
+    cast_impl(T &&src, return_value_policy policy, handle parent, index_sequence<Is...>) {
+        PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(src, policy, parent);
+        PYBIND11_WORKAROUND_INCORRECT_GCC_UNUSED_BUT_SET_PARAMETER(policy, parent);
+        std::array<object, size> entries{{reinterpret_steal<object>(
+            make_caster<Ts>::cast(std::get<Is>(std::forward<T>(src)), policy, parent))...}};
+        for (const auto &entry : entries) {
+            if (!entry) {
                 return handle();
+            }
+        }
         tuple result(size);
         int counter = 0;
-        for (auto & entry: entries)
+        for (auto &entry : entries) {
             PyTuple_SET_ITEM(result.ptr(), counter++, entry.release().ptr());
+        }
         return result.release();
     }
 
     Tuple<make_caster<Ts>...> subcasters;
 };
 
-template <typename T1, typename T2> class type_caster<std::pair<T1, T2>>
-    : public tuple_caster<std::pair, T1, T2> {};
+template <typename T1, typename T2>
+class type_caster<std::pair<T1, T2>> : public tuple_caster<std::pair, T1, T2> {};
 
-template <typename... Ts> class type_caster<std::tuple<Ts...>>
-    : public tuple_caster<std::tuple, Ts...> {};
+template <typename... Ts>
+class type_caster<std::tuple<Ts...>> : public tuple_caster<std::tuple, Ts...> {};
 
 /// Helper class which abstracts away certain actions. Users can provide specializations for
 /// custom holders, but it's only necessary if the type has a non-standard interface.
 template <typename T>
 struct holder_helper {
     static auto get(const T &p) -> decltype(p.get()) { return p.get(); }
 };
 
 /// Type caster for holder types like std::shared_ptr, etc.
-template <typename type, typename holder_type>
+/// The SFINAE hook is provided to help work around the current lack of support
+/// for smart-pointer interoperability. Please consider it an implementation
+/// detail that may change in the future, as formal support for smart-pointer
+/// interoperability is added into pybind11.
+template <typename type, typename holder_type, typename SFINAE = void>
 struct copyable_holder_caster : public type_caster_base<type> {
 public:
     using base = type_caster_base<type>;
     static_assert(std::is_base_of<base, type_caster<type>>::value,
-            "Holder classes are only supported for custom types");
+                  "Holder classes are only supported for custom types");
     using base::base;
     using base::cast;
     using base::typeinfo;
     using base::value;
 
     bool load(handle src, bool convert) {
         return base::template load_impl<copyable_holder_caster<type, holder_type>>(src, convert);
     }
 
-    explicit operator type*() { return this->value; }
-    explicit operator type&() { return *(this->value); }
-    explicit operator holder_type*() { return std::addressof(holder); }
-
-    // Workaround for Intel compiler bug
-    // see pybind11 issue 94
-    #if defined(__ICC) || defined(__INTEL_COMPILER)
-    operator holder_type&() { return holder; }
-    #else
-    explicit operator holder_type&() { return holder; }
-    #endif
+    explicit operator type *() { return this->value; }
+    // static_cast works around compiler error with MSVC 17 and CUDA 10.2
+    // see issue #2180
+    explicit operator type &() { return *(static_cast<type *>(this->value)); }
+    explicit operator holder_type *() { return std::addressof(holder); }
+    explicit operator holder_type &() { return holder; }
 
     static handle cast(const holder_type &src, return_value_policy, handle) {
         const auto *ptr = holder_helper<holder_type>::get(src);
         return type_caster_base<type>::cast_holder(ptr, &src);
     }
 
 protected:
     friend class type_caster_generic;
     void check_holder_compat() {
-        if (typeinfo->default_holder)
+        if (typeinfo->default_holder) {
             throw cast_error("Unable to load a custom holder type from a default-holder instance");
+        }
     }
 
     bool load_value(value_and_holder &&v_h) {
         if (v_h.holder_constructed()) {
             value = v_h.value_ptr();
             holder = v_h.template holder<holder_type>();
             return true;
-        } else {
-            throw cast_error("Unable to cast from non-held to held instance (T& to Holder<T>) "
-#if defined(NDEBUG)
-                             "(compile in debug mode for type information)");
+        }
+        throw cast_error("Unable to cast from non-held to held instance (T& to Holder<T>) "
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES)
+                         "(#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for "
+                         "type information)");
 #else
-                             "of type '" + type_id<holder_type>() + "''");
+                         "of type '"
+                         + type_id<holder_type>() + "''");
 #endif
-        }
     }
 
-    template <typename T = holder_type, detail::enable_if_t<!std::is_constructible<T, const T &, type*>::value, int> = 0>
-    bool try_implicit_casts(handle, bool) { return false; }
+    template <typename T = holder_type,
+              detail::enable_if_t<!std::is_constructible<T, const T &, type *>::value, int> = 0>
+    bool try_implicit_casts(handle, bool) {
+        return false;
+    }
 
-    template <typename T = holder_type, detail::enable_if_t<std::is_constructible<T, const T &, type*>::value, int> = 0>
+    template <typename T = holder_type,
+              detail::enable_if_t<std::is_constructible<T, const T &, type *>::value, int> = 0>
     bool try_implicit_casts(handle src, bool convert) {
         for (auto &cast : typeinfo->implicit_casts) {
             copyable_holder_caster sub_caster(*cast.first);
             if (sub_caster.load(src, convert)) {
                 value = cast.second(sub_caster.value);
                 holder = holder_type(sub_caster.holder, (type *) value);
                 return true;
             }
         }
         return false;
     }
 
     static bool try_direct_conversions(handle) { return false; }
 
-
     holder_type holder;
 };
 
 /// Specialize for the common std::shared_ptr, so users don't need to
 template <typename T>
-class type_caster<std::shared_ptr<T>> : public copyable_holder_caster<T, std::shared_ptr<T>> { };
+class type_caster<std::shared_ptr<T>> : public copyable_holder_caster<T, std::shared_ptr<T>> {};
 
-template <typename type, typename holder_type>
+/// Type caster for holder types like std::unique_ptr.
+/// Please consider the SFINAE hook an implementation detail, as explained
+/// in the comment for the copyable_holder_caster.
+template <typename type, typename holder_type, typename SFINAE = void>
 struct move_only_holder_caster {
     static_assert(std::is_base_of<type_caster_base<type>, type_caster<type>>::value,
-            "Holder classes are only supported for custom types");
+                  "Holder classes are only supported for custom types");
 
     static handle cast(holder_type &&src, return_value_policy, handle) {
         auto *ptr = holder_helper<holder_type>::get(src);
         return type_caster_base<type>::cast_holder(ptr, std::addressof(src));
     }
     static constexpr auto name = type_caster_base<type>::name;
 };
 
 template <typename type, typename deleter>
 class type_caster<std::unique_ptr<type, deleter>>
-    : public move_only_holder_caster<type, std::unique_ptr<type, deleter>> { };
+    : public move_only_holder_caster<type, std::unique_ptr<type, deleter>> {};
 
 template <typename type, typename holder_type>
 using type_caster_holder = conditional_t<is_copy_constructible<holder_type>::value,
                                          copyable_holder_caster<type, holder_type>,
                                          move_only_holder_caster<type, holder_type>>;
 
-template <typename T, bool Value = false> struct always_construct_holder { static constexpr bool value = Value; };
+template <typename T, bool Value = false>
+struct always_construct_holder {
+    static constexpr bool value = Value;
+};
 
 /// Create a specialization for custom holder types (silently ignores std::shared_ptr)
-#define PYBIND11_DECLARE_HOLDER_TYPE(type, holder_type, ...) \
-    namespace pybind11 { namespace detail { \
-    template <typename type> \
-    struct always_construct_holder<holder_type> : always_construct_holder<void, ##__VA_ARGS__>  { }; \
-    template <typename type> \
-    class type_caster<holder_type, enable_if_t<!is_shared_ptr<holder_type>::value>> \
-        : public type_caster_holder<type, holder_type> { }; \
-    }}
+#define PYBIND11_DECLARE_HOLDER_TYPE(type, holder_type, ...)                                      \
+    PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)                                                  \
+    namespace detail {                                                                            \
+    template <typename type>                                                                      \
+    struct always_construct_holder<holder_type> : always_construct_holder<void, ##__VA_ARGS__> {  \
+    };                                                                                            \
+    template <typename type>                                                                      \
+    class type_caster<holder_type, enable_if_t<!is_shared_ptr<holder_type>::value>>               \
+        : public type_caster_holder<type, holder_type> {};                                        \
+    }                                                                                             \
+    PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
 
 // PYBIND11_DECLARE_HOLDER_TYPE holder types:
-template <typename base, typename holder> struct is_holder_type :
-    std::is_base_of<detail::type_caster_holder<base, holder>, detail::type_caster<holder>> {};
+template <typename base, typename holder>
+struct is_holder_type
+    : std::is_base_of<detail::type_caster_holder<base, holder>, detail::type_caster<holder>> {};
 // Specialization for always-supported unique_ptr holders:
-template <typename base, typename deleter> struct is_holder_type<base, std::unique_ptr<base, deleter>> :
-    std::true_type {};
+template <typename base, typename deleter>
+struct is_holder_type<base, std::unique_ptr<base, deleter>> : std::true_type {};
 
-template <typename T> struct handle_type_name { static constexpr auto name = _<T>(); };
-template <> struct handle_type_name<bytes> { static constexpr auto name = _(PYBIND11_BYTES_NAME); };
-template <> struct handle_type_name<args> { static constexpr auto name = _("*args"); };
-template <> struct handle_type_name<kwargs> { static constexpr auto name = _("**kwargs"); };
+template <typename T>
+struct handle_type_name {
+    static constexpr auto name = const_name<T>();
+};
+template <>
+struct handle_type_name<bool_> {
+    static constexpr auto name = const_name("bool");
+};
+template <>
+struct handle_type_name<bytes> {
+    static constexpr auto name = const_name(PYBIND11_BYTES_NAME);
+};
+template <>
+struct handle_type_name<int_> {
+    static constexpr auto name = const_name("int");
+};
+template <>
+struct handle_type_name<iterable> {
+    static constexpr auto name = const_name("Iterable");
+};
+template <>
+struct handle_type_name<iterator> {
+    static constexpr auto name = const_name("Iterator");
+};
+template <>
+struct handle_type_name<float_> {
+    static constexpr auto name = const_name("float");
+};
+template <>
+struct handle_type_name<none> {
+    static constexpr auto name = const_name("None");
+};
+template <>
+struct handle_type_name<args> {
+    static constexpr auto name = const_name("*args");
+};
+template <>
+struct handle_type_name<kwargs> {
+    static constexpr auto name = const_name("**kwargs");
+};
 
 template <typename type>
 struct pyobject_caster {
     template <typename T = type, enable_if_t<std::is_same<T, handle>::value, int> = 0>
-    bool load(handle src, bool /* convert */) { value = src; return static_cast<bool>(value); }
+    pyobject_caster() : value() {}
+
+    // `type` may not be default constructible (e.g. frozenset, anyset).  Initializing `value`
+    // to a nil handle is safe since it will only be accessed if `load` succeeds.
+    template <typename T = type, enable_if_t<std::is_base_of<object, T>::value, int> = 0>
+    pyobject_caster() : value(reinterpret_steal<type>(handle())) {}
+
+    template <typename T = type, enable_if_t<std::is_same<T, handle>::value, int> = 0>
+    bool load(handle src, bool /* convert */) {
+        value = src;
+        return static_cast<bool>(value);
+    }
 
     template <typename T = type, enable_if_t<std::is_base_of<object, T>::value, int> = 0>
     bool load(handle src, bool /* convert */) {
-        if (!isinstance<type>(src))
+        if (!isinstance<type>(src)) {
             return false;
+        }
         value = reinterpret_borrow<type>(src);
         return true;
     }
 
     static handle cast(const handle &src, return_value_policy /* policy */, handle /* parent */) {
         return src.inc_ref();
     }
     PYBIND11_TYPE_CASTER(type, handle_type_name<type>::name);
 };
 
 template <typename T>
-class type_caster<T, enable_if_t<is_pyobject<T>::value>> : public pyobject_caster<T> { };
+class type_caster<T, enable_if_t<is_pyobject<T>::value>> : public pyobject_caster<T> {};
 
 // Our conditions for enabling moving are quite restrictive:
 // At compile time:
 // - T needs to be a non-const, non-pointer, non-reference type
 // - type_caster<T>::operator T&() must exist
 // - the type must be move constructible (obviously)
 // At run-time:
 // - if the type is non-copy-constructible, the object must be the sole owner of the type (i.e. it
 //   must have ref_count() == 1)h
 // If any of the above are not satisfied, we fall back to copying.
-template <typename T> using move_is_plain_type = satisfies_none_of<T,
-    std::is_void, std::is_pointer, std::is_reference, std::is_const
->;
-template <typename T, typename SFINAE = void> struct move_always : std::false_type {};
-template <typename T> struct move_always<T, enable_if_t<all_of<
-    move_is_plain_type<T>,
-    negation<is_copy_constructible<T>>,
-    std::is_move_constructible<T>,
-    std::is_same<decltype(std::declval<make_caster<T>>().operator T&()), T&>
->::value>> : std::true_type {};
-template <typename T, typename SFINAE = void> struct move_if_unreferenced : std::false_type {};
-template <typename T> struct move_if_unreferenced<T, enable_if_t<all_of<
-    move_is_plain_type<T>,
-    negation<move_always<T>>,
-    std::is_move_constructible<T>,
-    std::is_same<decltype(std::declval<make_caster<T>>().operator T&()), T&>
->::value>> : std::true_type {};
-template <typename T> using move_never = none_of<move_always<T>, move_if_unreferenced<T>>;
+template <typename T>
+using move_is_plain_type
+    = satisfies_none_of<T, std::is_void, std::is_pointer, std::is_reference, std::is_const>;
+template <typename T, typename SFINAE = void>
+struct move_always : std::false_type {};
+template <typename T>
+struct move_always<
+    T,
+    enable_if_t<
+        all_of<move_is_plain_type<T>,
+               negation<is_copy_constructible<T>>,
+               std::is_move_constructible<T>,
+               std::is_same<decltype(std::declval<make_caster<T>>().operator T &()), T &>>::value>>
+    : std::true_type {};
+template <typename T, typename SFINAE = void>
+struct move_if_unreferenced : std::false_type {};
+template <typename T>
+struct move_if_unreferenced<
+    T,
+    enable_if_t<
+        all_of<move_is_plain_type<T>,
+               negation<move_always<T>>,
+               std::is_move_constructible<T>,
+               std::is_same<decltype(std::declval<make_caster<T>>().operator T &()), T &>>::value>>
+    : std::true_type {};
+template <typename T>
+using move_never = none_of<move_always<T>, move_if_unreferenced<T>>;
 
 // Detect whether returning a `type` from a cast on type's type_caster is going to result in a
 // reference or pointer to a local variable of the type_caster.  Basically, only
 // non-reference/pointer `type`s and reference/pointers from a type_caster_generic are safe;
 // everything else returns a reference/pointer to a local variable.
-template <typename type> using cast_is_temporary_value_reference = bool_constant<
-    (std::is_reference<type>::value || std::is_pointer<type>::value) &&
-    !std::is_base_of<type_caster_generic, make_caster<type>>::value &&
-    !std::is_same<intrinsic_t<type>, void>::value
->;
+template <typename type>
+using cast_is_temporary_value_reference
+    = bool_constant<(std::is_reference<type>::value || std::is_pointer<type>::value)
+                    && !std::is_base_of<type_caster_generic, make_caster<type>>::value
+                    && !std::is_same<intrinsic_t<type>, void>::value>;
 
 // When a value returned from a C++ function is being cast back to Python, we almost always want to
 // force `policy = move`, regardless of the return value policy the function/method was declared
 // with.
-template <typename Return, typename SFINAE = void> struct return_value_policy_override {
+template <typename Return, typename SFINAE = void>
+struct return_value_policy_override {
     static return_value_policy policy(return_value_policy p) { return p; }
 };
 
-template <typename Return> struct return_value_policy_override<Return,
-        detail::enable_if_t<std::is_base_of<type_caster_generic, make_caster<Return>>::value, void>> {
+template <typename Return>
+struct return_value_policy_override<
+    Return,
+    detail::enable_if_t<std::is_base_of<type_caster_generic, make_caster<Return>>::value, void>> {
     static return_value_policy policy(return_value_policy p) {
-        return !std::is_lvalue_reference<Return>::value &&
-               !std::is_pointer<Return>::value
-                   ? return_value_policy::move : p;
+        return !std::is_lvalue_reference<Return>::value && !std::is_pointer<Return>::value
+                   ? return_value_policy::move
+                   : p;
     }
 };
 
 // Basic python -> C++ casting; throws if casting fails
-template <typename T, typename SFINAE> type_caster<T, SFINAE> &load_type(type_caster<T, SFINAE> &conv, const handle &handle) {
+template <typename T, typename SFINAE>
+type_caster<T, SFINAE> &load_type(type_caster<T, SFINAE> &conv, const handle &handle) {
+    static_assert(!detail::is_pyobject<T>::value,
+                  "Internal error: type_caster should only be used for C++ types");
     if (!conv.load(handle, true)) {
-#if defined(NDEBUG)
-        throw cast_error("Unable to cast Python instance to C++ type (compile in debug mode for details)");
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES)
+        throw cast_error("Unable to cast Python instance to C++ type (#define "
+                         "PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)");
 #else
-        throw cast_error("Unable to cast Python instance of type " +
-            (std::string) str(handle.get_type()) + " to C++ type '" + type_id<T>() + "'");
+        throw cast_error("Unable to cast Python instance of type "
+                         + (std::string) str(type::handle_of(handle)) + " to C++ type '"
+                         + type_id<T>() + "'");
 #endif
     }
     return conv;
 }
 // Wrapper around the above that also constructs and returns a type_caster
-template <typename T> make_caster<T> load_type(const handle &handle) {
+template <typename T>
+make_caster<T> load_type(const handle &handle) {
     make_caster<T> conv;
     load_type(conv, handle);
     return conv;
 }
 
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
 
 // pytype -> C++ type
 template <typename T, detail::enable_if_t<!detail::is_pyobject<T>::value, int> = 0>
 T cast(const handle &handle) {
     using namespace detail;
     static_assert(!cast_is_temporary_value_reference<T>::value,
-            "Unable to cast type to reference: value is local to type caster");
+                  "Unable to cast type to reference: value is local to type caster");
     return cast_op<T>(load_type<T>(handle));
 }
 
 // pytype -> pytype (calls converting constructor)
 template <typename T, detail::enable_if_t<detail::is_pyobject<T>::value, int> = 0>
-T cast(const handle &handle) { return T(reinterpret_borrow<object>(handle)); }
+T cast(const handle &handle) {
+    return T(reinterpret_borrow<object>(handle));
+}
 
 // C++ type -> py::object
 template <typename T, detail::enable_if_t<!detail::is_pyobject<T>::value, int> = 0>
-object cast(const T &value, return_value_policy policy = return_value_policy::automatic_reference,
+object cast(T &&value,
+            return_value_policy policy = return_value_policy::automatic_reference,
             handle parent = handle()) {
-    if (policy == return_value_policy::automatic)
-        policy = std::is_pointer<T>::value ? return_value_policy::take_ownership : return_value_policy::copy;
-    else if (policy == return_value_policy::automatic_reference)
-        policy = std::is_pointer<T>::value ? return_value_policy::reference : return_value_policy::copy;
-    return reinterpret_steal<object>(detail::make_caster<T>::cast(value, policy, parent));
+    using no_ref_T = typename std::remove_reference<T>::type;
+    if (policy == return_value_policy::automatic) {
+        policy = std::is_pointer<no_ref_T>::value     ? return_value_policy::take_ownership
+                 : std::is_lvalue_reference<T>::value ? return_value_policy::copy
+                                                      : return_value_policy::move;
+    } else if (policy == return_value_policy::automatic_reference) {
+        policy = std::is_pointer<no_ref_T>::value     ? return_value_policy::reference
+                 : std::is_lvalue_reference<T>::value ? return_value_policy::copy
+                                                      : return_value_policy::move;
+    }
+    return reinterpret_steal<object>(
+        detail::make_caster<T>::cast(std::forward<T>(value), policy, parent));
 }
 
-template <typename T> T handle::cast() const { return pybind11::cast<T>(*this); }
-template <> inline void handle::cast() const { return; }
+template <typename T>
+T handle::cast() const {
+    return pybind11::cast<T>(*this);
+}
+template <>
+inline void handle::cast() const {
+    return;
+}
 
 template <typename T>
 detail::enable_if_t<!detail::move_never<T>::value, T> move(object &&obj) {
-    if (obj.ref_count() > 1)
-#if defined(NDEBUG)
-        throw cast_error("Unable to cast Python instance to C++ rvalue: instance has multiple references"
-            " (compile in debug mode for details)");
+    if (obj.ref_count() > 1) {
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES)
+        throw cast_error(
+            "Unable to cast Python instance to C++ rvalue: instance has multiple references"
+            " (#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)");
 #else
-        throw cast_error("Unable to move from Python " + (std::string) str(obj.get_type()) +
-                " instance to C++ " + type_id<T>() + " instance: instance has multiple references");
+        throw cast_error("Unable to move from Python " + (std::string) str(type::handle_of(obj))
+                         + " instance to C++ " + type_id<T>()
+                         + " instance: instance has multiple references");
 #endif
+    }
 
     // Move into a temporary and return that, because the reference may be a local value of `conv`
-    T ret = std::move(detail::load_type<T>(obj).operator T&());
+    T ret = std::move(detail::load_type<T>(obj).operator T &());
     return ret;
 }
 
-// Calling cast() on an rvalue calls pybind::cast with the object rvalue, which does:
+// Calling cast() on an rvalue calls pybind11::cast with the object rvalue, which does:
 // - If we have to move (because T has no copy constructor), do it.  This will fail if the moved
 //   object has multiple references, but trying to copy will fail to compile.
 // - If both movable and copyable, check ref count: if 1, move; otherwise copy
 // - Otherwise (not movable), copy.
-template <typename T> detail::enable_if_t<detail::move_always<T>::value, T> cast(object &&object) {
+template <typename T>
+detail::enable_if_t<!detail::is_pyobject<T>::value && detail::move_always<T>::value, T>
+cast(object &&object) {
     return move<T>(std::move(object));
 }
-template <typename T> detail::enable_if_t<detail::move_if_unreferenced<T>::value, T> cast(object &&object) {
-    if (object.ref_count() > 1)
+template <typename T>
+detail::enable_if_t<!detail::is_pyobject<T>::value && detail::move_if_unreferenced<T>::value, T>
+cast(object &&object) {
+    if (object.ref_count() > 1) {
         return cast<T>(object);
-    else
-        return move<T>(std::move(object));
+    }
+    return move<T>(std::move(object));
 }
-template <typename T> detail::enable_if_t<detail::move_never<T>::value, T> cast(object &&object) {
+template <typename T>
+detail::enable_if_t<!detail::is_pyobject<T>::value && detail::move_never<T>::value, T>
+cast(object &&object) {
     return cast<T>(object);
 }
 
-template <typename T> T object::cast() const & { return pybind11::cast<T>(*this); }
-template <typename T> T object::cast() && { return pybind11::cast<T>(std::move(*this)); }
-template <> inline void object::cast() const & { return; }
-template <> inline void object::cast() && { return; }
+// pytype rvalue -> pytype (calls converting constructor)
+template <typename T>
+detail::enable_if_t<detail::is_pyobject<T>::value, T> cast(object &&object) {
+    return T(std::move(object));
+}
 
-NAMESPACE_BEGIN(detail)
+template <typename T>
+T object::cast() const & {
+    return pybind11::cast<T>(*this);
+}
+template <typename T>
+T object::cast() && {
+    return pybind11::cast<T>(std::move(*this));
+}
+template <>
+inline void object::cast() const & {
+    return;
+}
+template <>
+inline void object::cast() && {
+    return;
+}
+
+PYBIND11_NAMESPACE_BEGIN(detail)
 
 // Declared in pytypes.h:
 template <typename T, enable_if_t<!is_pyobject<T>::value, int>>
-object object_or_cast(T &&o) { return pybind11::cast(std::forward<T>(o)); }
+object object_or_cast(T &&o) {
+    return pybind11::cast(std::forward<T>(o));
+}
 
-struct overload_unused {}; // Placeholder type for the unneeded (and dead code) static variable in the OVERLOAD_INT macro
-template <typename ret_type> using overload_caster_t = conditional_t<
-    cast_is_temporary_value_reference<ret_type>::value, make_caster<ret_type>, overload_unused>;
+// Placeholder type for the unneeded (and dead code) static variable in the
+// PYBIND11_OVERRIDE_OVERRIDE macro
+struct override_unused {};
+template <typename ret_type>
+using override_caster_t = conditional_t<cast_is_temporary_value_reference<ret_type>::value,
+                                        make_caster<ret_type>,
+                                        override_unused>;
 
 // Trampoline use: for reference/pointer types to value-converted values, we do a value cast, then
 // store the result in the given variable.  For other types, this is a no-op.
-template <typename T> enable_if_t<cast_is_temporary_value_reference<T>::value, T> cast_ref(object &&o, make_caster<T> &caster) {
+template <typename T>
+enable_if_t<cast_is_temporary_value_reference<T>::value, T> cast_ref(object &&o,
+                                                                     make_caster<T> &caster) {
     return cast_op<T>(load_type(caster, o));
 }
-template <typename T> enable_if_t<!cast_is_temporary_value_reference<T>::value, T> cast_ref(object &&, overload_unused &) {
-    pybind11_fail("Internal error: cast_ref fallback invoked"); }
+template <typename T>
+enable_if_t<!cast_is_temporary_value_reference<T>::value, T> cast_ref(object &&,
+                                                                      override_unused &) {
+    pybind11_fail("Internal error: cast_ref fallback invoked");
+}
 
-// Trampoline use: Having a pybind11::cast with an invalid reference type is going to static_assert, even
-// though if it's in dead code, so we provide a "trampoline" to pybind11::cast that only does anything in
-// cases where pybind11::cast is valid.
-template <typename T> enable_if_t<!cast_is_temporary_value_reference<T>::value, T> cast_safe(object &&o) {
-    return pybind11::cast<T>(std::move(o)); }
-template <typename T> enable_if_t<cast_is_temporary_value_reference<T>::value, T> cast_safe(object &&) {
-    pybind11_fail("Internal error: cast_safe fallback invoked"); }
-template <> inline void cast_safe<void>(object &&) {}
+// Trampoline use: Having a pybind11::cast with an invalid reference type is going to
+// static_assert, even though if it's in dead code, so we provide a "trampoline" to pybind11::cast
+// that only does anything in cases where pybind11::cast is valid.
+template <typename T>
+enable_if_t<cast_is_temporary_value_reference<T>::value, T> cast_safe(object &&) {
+    pybind11_fail("Internal error: cast_safe fallback invoked");
+}
+template <typename T>
+enable_if_t<std::is_void<T>::value, void> cast_safe(object &&) {}
+template <typename T>
+enable_if_t<detail::none_of<cast_is_temporary_value_reference<T>, std::is_void<T>>::value, T>
+cast_safe(object &&o) {
+    return pybind11::cast<T>(std::move(o));
+}
 
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
+
+// The overloads could coexist, i.e. the #if is not strictly speaking needed,
+// but it is an easy minor optimization.
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES)
+inline cast_error cast_error_unable_to_convert_call_arg() {
+    return cast_error("Unable to convert call argument to Python object (#define "
+                      "PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)");
+}
+#else
+inline cast_error cast_error_unable_to_convert_call_arg(const std::string &name,
+                                                        const std::string &type) {
+    return cast_error("Unable to convert call argument '" + name + "' of type '" + type
+                      + "' to Python object");
+}
+#endif
 
 template <return_value_policy policy = return_value_policy::automatic_reference>
-tuple make_tuple() { return tuple(0); }
+tuple make_tuple() {
+    return tuple(0);
+}
 
-template <return_value_policy policy = return_value_policy::automatic_reference,
-          typename... Args> tuple make_tuple(Args&&... args_) {
+template <return_value_policy policy = return_value_policy::automatic_reference, typename... Args>
+tuple make_tuple(Args &&...args_) {
     constexpr size_t size = sizeof...(Args);
-    std::array<object, size> args {
-        { reinterpret_steal<object>(detail::make_caster<Args>::cast(
-            std::forward<Args>(args_), policy, nullptr))... }
-    };
+    std::array<object, size> args{{reinterpret_steal<object>(
+        detail::make_caster<Args>::cast(std::forward<Args>(args_), policy, nullptr))...}};
     for (size_t i = 0; i < args.size(); i++) {
         if (!args[i]) {
-#if defined(NDEBUG)
-            throw cast_error("make_tuple(): unable to convert arguments to Python object (compile in debug mode for details)");
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES)
+            throw cast_error_unable_to_convert_call_arg();
 #else
-            std::array<std::string, size> argtypes { {type_id<Args>()...} };
-            throw cast_error("make_tuple(): unable to convert argument of type '" +
-                argtypes[i] + "' to Python object");
+            std::array<std::string, size> argtypes{{type_id<Args>()...}};
+            throw cast_error_unable_to_convert_call_arg(std::to_string(i), argtypes[i]);
 #endif
         }
     }
     tuple result(size);
     int counter = 0;
-    for (auto &arg_value : args)
+    for (auto &arg_value : args) {
         PyTuple_SET_ITEM(result.ptr(), counter++, arg_value.release().ptr());
+    }
     return result;
 }
 
 /// \ingroup annotations
 /// Annotation for arguments
 struct arg {
-    /// Constructs an argument with the name of the argument; if null or omitted, this is a positional argument.
-    constexpr explicit arg(const char *name = nullptr) : name(name), flag_noconvert(false), flag_none(true) { }
+    /// Constructs an argument with the name of the argument; if null or omitted, this is a
+    /// positional argument.
+    constexpr explicit arg(const char *name = nullptr)
+        : name(name), flag_noconvert(false), flag_none(true) {}
     /// Assign a value to this argument
-    template <typename T> arg_v operator=(T &&value) const;
+    template <typename T>
+    arg_v operator=(T &&value) const;
     /// Indicate that the type should not be converted in the type caster
-    arg &noconvert(bool flag = true) { flag_noconvert = flag; return *this; }
+    arg &noconvert(bool flag = true) {
+        flag_noconvert = flag;
+        return *this;
+    }
     /// Indicates that the argument should/shouldn't allow None (e.g. for nullable pointer args)
-    arg &none(bool flag = true) { flag_none = flag; return *this; }
+    arg &none(bool flag = true) {
+        flag_none = flag;
+        return *this;
+    }
 
-    const char *name; ///< If non-null, this is a named kwargs argument
-    bool flag_noconvert : 1; ///< If set, do not allow conversion (requires a supporting type caster!)
-    bool flag_none : 1; ///< If set (the default), allow None to be passed to this argument
+    const char *name;        ///< If non-null, this is a named kwargs argument
+    bool flag_noconvert : 1; ///< If set, do not allow conversion (requires a supporting type
+                             ///< caster!)
+    bool flag_none : 1;      ///< If set (the default), allow None to be passed to this argument
 };
 
 /// \ingroup annotations
 /// Annotation for arguments with values
 struct arg_v : arg {
 private:
     template <typename T>
     arg_v(arg &&base, T &&x, const char *descr = nullptr)
-        : arg(base),
-          value(reinterpret_steal<object>(
-              detail::make_caster<T>::cast(x, return_value_policy::automatic, {})
-          )),
+        : arg(base), value(reinterpret_steal<object>(detail::make_caster<T>::cast(
+                         std::forward<T>(x), return_value_policy::automatic, {}))),
           descr(descr)
-#if !defined(NDEBUG)
-        , type(type_id<T>())
-#endif
-    { }
+#if defined(PYBIND11_DETAILED_ERROR_MESSAGES)
+          ,
+          type(type_id<T>())
+#endif
+    {
+        // Workaround! See:
+        // https://github.com/pybind/pybind11/issues/2336
+        // https://github.com/pybind/pybind11/pull/2685#issuecomment-731286700
+        if (PyErr_Occurred()) {
+            PyErr_Clear();
+        }
+    }
 
 public:
     /// Direct construction with name, default, and description
     template <typename T>
     arg_v(const char *name, T &&x, const char *descr = nullptr)
-        : arg_v(arg(name), std::forward<T>(x), descr) { }
+        : arg_v(arg(name), std::forward<T>(x), descr) {}
 
     /// Called internally when invoking `py::arg("a") = value`
     template <typename T>
     arg_v(const arg &base, T &&x, const char *descr = nullptr)
-        : arg_v(arg(base), std::forward<T>(x), descr) { }
+        : arg_v(arg(base), std::forward<T>(x), descr) {}
 
     /// Same as `arg::noconvert()`, but returns *this as arg_v&, not arg&
-    arg_v &noconvert(bool flag = true) { arg::noconvert(flag); return *this; }
+    arg_v &noconvert(bool flag = true) {
+        arg::noconvert(flag);
+        return *this;
+    }
 
     /// Same as `arg::nonone()`, but returns *this as arg_v&, not arg&
-    arg_v &none(bool flag = true) { arg::none(flag); return *this; }
+    arg_v &none(bool flag = true) {
+        arg::none(flag);
+        return *this;
+    }
 
     /// The default value
     object value;
     /// The (optional) description of the default value
     const char *descr;
-#if !defined(NDEBUG)
+#if defined(PYBIND11_DETAILED_ERROR_MESSAGES)
     /// The C++ type name of the default value (only available when compiled in debug mode)
     std::string type;
 #endif
 };
 
+/// \ingroup annotations
+/// Annotation indicating that all following arguments are keyword-only; the is the equivalent of
+/// an unnamed '*' argument
+struct kw_only {};
+
+/// \ingroup annotations
+/// Annotation indicating that all previous arguments are positional-only; the is the equivalent of
+/// an unnamed '/' argument (in Python 3.8)
+struct pos_only {};
+
 template <typename T>
-arg_v arg::operator=(T &&value) const { return {std::move(*this), std::forward<T>(value)}; }
+arg_v arg::operator=(T &&value) const {
+    return {*this, std::forward<T>(value)};
+}
 
 /// Alias for backward compatibility -- to be removed in version 2.0
-template <typename /*unused*/> using arg_t = arg_v;
+template <typename /*unused*/>
+using arg_t = arg_v;
 
 inline namespace literals {
 /** \rst
     String literal version of `arg`
  \endrst */
 constexpr arg operator"" _a(const char *name, size_t) { return arg(name); }
-}
+} // namespace literals
+
+PYBIND11_NAMESPACE_BEGIN(detail)
 
-NAMESPACE_BEGIN(detail)
+template <typename T>
+using is_kw_only = std::is_same<intrinsic_t<T>, kw_only>;
+template <typename T>
+using is_pos_only = std::is_same<intrinsic_t<T>, pos_only>;
 
 // forward declaration (definition in attr.h)
 struct function_record;
 
 /// Internal data associated with a single function call
 struct function_call {
     function_call(const function_record &f, handle p); // Implementation in attr.h
@@ -1873,90 +1373,103 @@
     /// The parent, if any
     handle parent;
 
     /// If this is a call to an initializer, this argument contains `self`
     handle init_self;
 };
 
-
 /// Helper class which loads arguments for C++ functions called from Python
 template <typename... Args>
 class argument_loader {
     using indices = make_index_sequence<sizeof...(Args)>;
 
-    template <typename Arg> using argument_is_args   = std::is_same<intrinsic_t<Arg>, args>;
-    template <typename Arg> using argument_is_kwargs = std::is_same<intrinsic_t<Arg>, kwargs>;
-    // Get args/kwargs argument positions relative to the end of the argument list:
-    static constexpr auto args_pos = constexpr_first<argument_is_args, Args...>() - (int) sizeof...(Args),
-                        kwargs_pos = constexpr_first<argument_is_kwargs, Args...>() - (int) sizeof...(Args);
-
-    static constexpr bool args_kwargs_are_last = kwargs_pos >= - 1 && args_pos >= kwargs_pos - 1;
+    template <typename Arg>
+    using argument_is_args = std::is_same<intrinsic_t<Arg>, args>;
+    template <typename Arg>
+    using argument_is_kwargs = std::is_same<intrinsic_t<Arg>, kwargs>;
+    // Get kwargs argument position, or -1 if not present:
+    static constexpr auto kwargs_pos = constexpr_last<argument_is_kwargs, Args...>();
 
-    static_assert(args_kwargs_are_last, "py::args/py::kwargs are only permitted as the last argument(s) of a function");
+    static_assert(kwargs_pos == -1 || kwargs_pos == (int) sizeof...(Args) - 1,
+                  "py::kwargs is only permitted as the last argument of a function");
 
 public:
-    static constexpr bool has_kwargs = kwargs_pos < 0;
-    static constexpr bool has_args = args_pos < 0;
+    static constexpr bool has_kwargs = kwargs_pos != -1;
+
+    // py::args argument position; -1 if not present.
+    static constexpr int args_pos = constexpr_last<argument_is_args, Args...>();
+
+    static_assert(args_pos == -1 || args_pos == constexpr_first<argument_is_args, Args...>(),
+                  "py::args cannot be specified more than once");
 
     static constexpr auto arg_names = concat(type_descr(make_caster<Args>::name)...);
 
-    bool load_args(function_call &call) {
-        return load_impl_sequence(call, indices{});
-    }
+    bool load_args(function_call &call) { return load_impl_sequence(call, indices{}); }
 
     template <typename Return, typename Guard, typename Func>
+    // NOLINTNEXTLINE(readability-const-return-type)
     enable_if_t<!std::is_void<Return>::value, Return> call(Func &&f) && {
-        return std::move(*this).template call_impl<Return>(std::forward<Func>(f), indices{}, Guard{});
+        return std::move(*this).template call_impl<remove_cv_t<Return>>(
+            std::forward<Func>(f), indices{}, Guard{});
     }
 
     template <typename Return, typename Guard, typename Func>
     enable_if_t<std::is_void<Return>::value, void_type> call(Func &&f) && {
-        std::move(*this).template call_impl<Return>(std::forward<Func>(f), indices{}, Guard{});
+        std::move(*this).template call_impl<remove_cv_t<Return>>(
+            std::forward<Func>(f), indices{}, Guard{});
         return void_type();
     }
 
 private:
-
     static bool load_impl_sequence(function_call &, index_sequence<>) { return true; }
 
     template <size_t... Is>
     bool load_impl_sequence(function_call &call, index_sequence<Is...>) {
-        for (bool r : {std::get<Is>(argcasters).load(call.args[Is], call.args_convert[Is])...})
-            if (!r)
+#ifdef __cpp_fold_expressions
+        if ((... || !std::get<Is>(argcasters).load(call.args[Is], call.args_convert[Is]))) {
+            return false;
+        }
+#else
+        for (bool r : {std::get<Is>(argcasters).load(call.args[Is], call.args_convert[Is])...}) {
+            if (!r) {
                 return false;
+            }
+        }
+#endif
         return true;
     }
 
     template <typename Return, typename Func, size_t... Is, typename Guard>
-    Return call_impl(Func &&f, index_sequence<Is...>, Guard &&) {
+    Return call_impl(Func &&f, index_sequence<Is...>, Guard &&) && {
         return std::forward<Func>(f)(cast_op<Args>(std::move(std::get<Is>(argcasters)))...);
     }
 
     std::tuple<make_caster<Args>...> argcasters;
 };
 
 /// Helper class which collects only positional arguments for a Python function call.
 /// A fancier version below can collect any argument, but this one is optimal for simple calls.
 template <return_value_policy policy>
 class simple_collector {
 public:
     template <typename... Ts>
     explicit simple_collector(Ts &&...values)
-        : m_args(pybind11::make_tuple<policy>(std::forward<Ts>(values)...)) { }
+        : m_args(pybind11::make_tuple<policy>(std::forward<Ts>(values)...)) {}
 
     const tuple &args() const & { return m_args; }
     dict kwargs() const { return {}; }
 
     tuple args() && { return std::move(m_args); }
 
     /// Call a Python function and pass the collected arguments
     object call(PyObject *ptr) const {
         PyObject *result = PyObject_CallObject(ptr, m_args.ptr());
-        if (!result)
+        if (!result) {
             throw error_already_set();
+        }
         return reinterpret_steal<object>(result);
     }
 
 private:
     tuple m_args;
 };
 
@@ -1965,164 +1478,190 @@
 class unpacking_collector {
 public:
     template <typename... Ts>
     explicit unpacking_collector(Ts &&...values) {
         // Tuples aren't (easily) resizable so a list is needed for collection,
         // but the actual function call strictly requires a tuple.
         auto args_list = list();
-        int _[] = { 0, (process(args_list, std::forward<Ts>(values)), 0)... };
-        ignore_unused(_);
+        using expander = int[];
+        (void) expander{0, (process(args_list, std::forward<Ts>(values)), 0)...};
 
         m_args = std::move(args_list);
     }
 
     const tuple &args() const & { return m_args; }
     const dict &kwargs() const & { return m_kwargs; }
 
     tuple args() && { return std::move(m_args); }
     dict kwargs() && { return std::move(m_kwargs); }
 
     /// Call a Python function and pass the collected arguments
     object call(PyObject *ptr) const {
         PyObject *result = PyObject_Call(ptr, m_args.ptr(), m_kwargs.ptr());
-        if (!result)
+        if (!result) {
             throw error_already_set();
+        }
         return reinterpret_steal<object>(result);
     }
 
 private:
     template <typename T>
     void process(list &args_list, T &&x) {
-        auto o = reinterpret_steal<object>(detail::make_caster<T>::cast(std::forward<T>(x), policy, {}));
+        auto o = reinterpret_steal<object>(
+            detail::make_caster<T>::cast(std::forward<T>(x), policy, {}));
         if (!o) {
-#if defined(NDEBUG)
-            argument_cast_error();
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES)
+            throw cast_error_unable_to_convert_call_arg();
 #else
-            argument_cast_error(std::to_string(args_list.size()), type_id<T>());
+            throw cast_error_unable_to_convert_call_arg(std::to_string(args_list.size()),
+                                                        type_id<T>());
 #endif
         }
-        args_list.append(o);
+        args_list.append(std::move(o));
     }
 
     void process(list &args_list, detail::args_proxy ap) {
-        for (const auto &a : ap)
+        for (auto a : ap) {
             args_list.append(a);
+        }
     }
 
-    void process(list &/*args_list*/, arg_v a) {
-        if (!a.name)
-#if defined(NDEBUG)
+    void process(list & /*args_list*/, arg_v a) {
+        if (!a.name) {
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES)
             nameless_argument_error();
 #else
             nameless_argument_error(a.type);
 #endif
-
+        }
         if (m_kwargs.contains(a.name)) {
-#if defined(NDEBUG)
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES)
             multiple_values_error();
 #else
             multiple_values_error(a.name);
 #endif
         }
         if (!a.value) {
-#if defined(NDEBUG)
-            argument_cast_error();
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES)
+            throw cast_error_unable_to_convert_call_arg();
 #else
-            argument_cast_error(a.name, a.type);
+            throw cast_error_unable_to_convert_call_arg(a.name, a.type);
 #endif
         }
-        m_kwargs[a.name] = a.value;
+        m_kwargs[a.name] = std::move(a.value);
     }
 
-    void process(list &/*args_list*/, detail::kwargs_proxy kp) {
-        if (!kp)
+    void process(list & /*args_list*/, detail::kwargs_proxy kp) {
+        if (!kp) {
             return;
-        for (const auto &k : reinterpret_borrow<dict>(kp)) {
+        }
+        for (auto k : reinterpret_borrow<dict>(kp)) {
             if (m_kwargs.contains(k.first)) {
-#if defined(NDEBUG)
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES)
                 multiple_values_error();
 #else
                 multiple_values_error(str(k.first));
 #endif
             }
             m_kwargs[k.first] = k.second;
         }
     }
 
     [[noreturn]] static void nameless_argument_error() {
-        throw type_error("Got kwargs without a name; only named arguments "
-                         "may be passed via py::arg() to a python function call. "
-                         "(compile in debug mode for details)");
-    }
-    [[noreturn]] static void nameless_argument_error(std::string type) {
-        throw type_error("Got kwargs without a name of type '" + type + "'; only named "
-                         "arguments may be passed via py::arg() to a python function call. ");
+        throw type_error(
+            "Got kwargs without a name; only named arguments "
+            "may be passed via py::arg() to a python function call. "
+            "(#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)");
+    }
+    [[noreturn]] static void nameless_argument_error(const std::string &type) {
+        throw type_error("Got kwargs without a name of type '" + type
+                         + "'; only named "
+                           "arguments may be passed via py::arg() to a python function call. ");
     }
     [[noreturn]] static void multiple_values_error() {
-        throw type_error("Got multiple values for keyword argument "
-                         "(compile in debug mode for details)");
+        throw type_error(
+            "Got multiple values for keyword argument "
+            "(#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for details)");
     }
 
-    [[noreturn]] static void multiple_values_error(std::string name) {
+    [[noreturn]] static void multiple_values_error(const std::string &name) {
         throw type_error("Got multiple values for keyword argument '" + name + "'");
     }
 
-    [[noreturn]] static void argument_cast_error() {
-        throw cast_error("Unable to convert call argument to Python object "
-                         "(compile in debug mode for details)");
-    }
-
-    [[noreturn]] static void argument_cast_error(std::string name, std::string type) {
-        throw cast_error("Unable to convert call argument '" + name
-                         + "' of type '" + type + "' to Python object");
-    }
-
 private:
     tuple m_args;
     dict m_kwargs;
 };
 
+// [workaround(intel)] Separate function required here
+// We need to put this into a separate function because the Intel compiler
+// fails to compile enable_if_t<!all_of<is_positional<Args>...>::value>
+// (tested with ICC 2021.1 Beta 20200827).
+template <typename... Args>
+constexpr bool args_are_all_positional() {
+    return all_of<is_positional<Args>...>::value;
+}
+
 /// Collect only positional arguments for a Python function call
-template <return_value_policy policy, typename... Args,
-          typename = enable_if_t<all_of<is_positional<Args>...>::value>>
+template <return_value_policy policy,
+          typename... Args,
+          typename = enable_if_t<args_are_all_positional<Args...>()>>
 simple_collector<policy> collect_arguments(Args &&...args) {
     return simple_collector<policy>(std::forward<Args>(args)...);
 }
 
 /// Collect all arguments, including keywords and unpacking (only instantiated when needed)
-template <return_value_policy policy, typename... Args,
-          typename = enable_if_t<!all_of<is_positional<Args>...>::value>>
+template <return_value_policy policy,
+          typename... Args,
+          typename = enable_if_t<!args_are_all_positional<Args...>()>>
 unpacking_collector<policy> collect_arguments(Args &&...args) {
     // Following argument order rules for generalized unpacking according to PEP 448
-    static_assert(
-        constexpr_last<is_positional, Args...>() < constexpr_first<is_keyword_or_ds, Args...>()
-        && constexpr_last<is_s_unpacking, Args...>() < constexpr_first<is_ds_unpacking, Args...>(),
-        "Invalid function call: positional args must precede keywords and ** unpacking; "
-        "* unpacking must precede ** unpacking"
-    );
+    static_assert(constexpr_last<is_positional, Args...>()
+                          < constexpr_first<is_keyword_or_ds, Args...>()
+                      && constexpr_last<is_s_unpacking, Args...>()
+                             < constexpr_first<is_ds_unpacking, Args...>(),
+                  "Invalid function call: positional args must precede keywords and ** unpacking; "
+                  "* unpacking must precede ** unpacking");
     return unpacking_collector<policy>(std::forward<Args>(args)...);
 }
 
 template <typename Derived>
 template <return_value_policy policy, typename... Args>
 object object_api<Derived>::operator()(Args &&...args) const {
+#ifndef NDEBUG
+    if (!PyGILState_Check()) {
+        pybind11_fail("pybind11::object_api<>::operator() PyGILState_Check() failure.");
+    }
+#endif
     return detail::collect_arguments<policy>(std::forward<Args>(args)...).call(derived().ptr());
 }
 
 template <typename Derived>
 template <return_value_policy policy, typename... Args>
 object object_api<Derived>::call(Args &&...args) const {
     return operator()<policy>(std::forward<Args>(args)...);
 }
 
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
+
+template <typename T>
+handle type::handle_of() {
+    static_assert(std::is_base_of<detail::type_caster_generic, detail::make_caster<T>>::value,
+                  "py::type::of<T> only supports the case where T is a registered C++ types.");
+
+    return detail::get_type_handle(typeid(T), true);
+}
 
-#define PYBIND11_MAKE_OPAQUE(...) \
-    namespace pybind11 { namespace detail { \
-        template<> class type_caster<__VA_ARGS__> : public type_caster_base<__VA_ARGS__> { }; \
-    }}
+#define PYBIND11_MAKE_OPAQUE(...)                                                                 \
+    PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)                                                  \
+    namespace detail {                                                                            \
+    template <>                                                                                   \
+    class type_caster<__VA_ARGS__> : public type_caster_base<__VA_ARGS__> {};                     \
+    }                                                                                             \
+    PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
 
 /// Lets you pass a type containing a `,` through a macro parameter without needing a separate
-/// typedef, e.g.: `PYBIND11_OVERLOAD(PYBIND11_TYPE(ReturnType<A, B>), PYBIND11_TYPE(Parent<C, D>), f, arg)`
+/// typedef, e.g.:
+/// `PYBIND11_OVERRIDE(PYBIND11_TYPE(ReturnType<A, B>), PYBIND11_TYPE(Parent<C, D>), f, arg)`
 #define PYBIND11_TYPE(...) __VA_ARGS__
 
-NAMESPACE_END(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/chrono.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/chrono.h`

 * *Files 24% similar despite different names*

```diff
@@ -7,156 +7,219 @@
     All rights reserved. Use of this source code is governed by a
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
 #include "pybind11.h"
+
+#include <chrono>
 #include <cmath>
 #include <ctime>
-#include <chrono>
 #include <datetime.h>
+#include <mutex>
 
-// Backport the PyDateTime_DELTA functions from Python3.3 if required
-#ifndef PyDateTime_DELTA_GET_DAYS
-#define PyDateTime_DELTA_GET_DAYS(o)         (((PyDateTime_Delta*)o)->days)
-#endif
-#ifndef PyDateTime_DELTA_GET_SECONDS
-#define PyDateTime_DELTA_GET_SECONDS(o)      (((PyDateTime_Delta*)o)->seconds)
-#endif
-#ifndef PyDateTime_DELTA_GET_MICROSECONDS
-#define PyDateTime_DELTA_GET_MICROSECONDS(o) (((PyDateTime_Delta*)o)->microseconds)
-#endif
-
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
-template <typename type> class duration_caster {
+template <typename type>
+class duration_caster {
 public:
-    typedef typename type::rep rep;
-    typedef typename type::period period;
+    using rep = typename type::rep;
+    using period = typename type::period;
 
-    typedef std::chrono::duration<uint_fast32_t, std::ratio<86400>> days;
+    // signed 25 bits required by the standard.
+    using days = std::chrono::duration<int_least32_t, std::ratio<86400>>;
 
     bool load(handle src, bool) {
         using namespace std::chrono;
 
         // Lazy initialise the PyDateTime import
-        if (!PyDateTimeAPI) { PyDateTime_IMPORT; }
+        if (!PyDateTimeAPI) {
+            PyDateTime_IMPORT;
+        }
 
-        if (!src) return false;
+        if (!src) {
+            return false;
+        }
         // If invoked with datetime.delta object
         if (PyDelta_Check(src.ptr())) {
             value = type(duration_cast<duration<rep, period>>(
-                  days(PyDateTime_DELTA_GET_DAYS(src.ptr()))
+                days(PyDateTime_DELTA_GET_DAYS(src.ptr()))
                 + seconds(PyDateTime_DELTA_GET_SECONDS(src.ptr()))
                 + microseconds(PyDateTime_DELTA_GET_MICROSECONDS(src.ptr()))));
             return true;
         }
         // If invoked with a float we assume it is seconds and convert
-        else if (PyFloat_Check(src.ptr())) {
-            value = type(duration_cast<duration<rep, period>>(duration<double>(PyFloat_AsDouble(src.ptr()))));
+        if (PyFloat_Check(src.ptr())) {
+            value = type(duration_cast<duration<rep, period>>(
+                duration<double>(PyFloat_AsDouble(src.ptr()))));
             return true;
         }
-        else return false;
+        return false;
     }
 
     // If this is a duration just return it back
-    static const std::chrono::duration<rep, period>& get_duration(const std::chrono::duration<rep, period> &src) {
+    static const std::chrono::duration<rep, period> &
+    get_duration(const std::chrono::duration<rep, period> &src) {
         return src;
     }
 
     // If this is a time_point get the time_since_epoch
-    template <typename Clock> static std::chrono::duration<rep, period> get_duration(const std::chrono::time_point<Clock, std::chrono::duration<rep, period>> &src) {
+    template <typename Clock>
+    static std::chrono::duration<rep, period>
+    get_duration(const std::chrono::time_point<Clock, std::chrono::duration<rep, period>> &src) {
         return src.time_since_epoch();
     }
 
     static handle cast(const type &src, return_value_policy /* policy */, handle /* parent */) {
         using namespace std::chrono;
 
         // Use overloaded function to get our duration from our source
         // Works out if it is a duration or time_point and get the duration
         auto d = get_duration(src);
 
         // Lazy initialise the PyDateTime import
-        if (!PyDateTimeAPI) { PyDateTime_IMPORT; }
+        if (!PyDateTimeAPI) {
+            PyDateTime_IMPORT;
+        }
 
-        // Declare these special duration types so the conversions happen with the correct primitive types (int)
+        // Declare these special duration types so the conversions happen with the correct
+        // primitive types (int)
         using dd_t = duration<int, std::ratio<86400>>;
         using ss_t = duration<int, std::ratio<1>>;
         using us_t = duration<int, std::micro>;
 
         auto dd = duration_cast<dd_t>(d);
         auto subd = d - dd;
         auto ss = duration_cast<ss_t>(subd);
         auto us = duration_cast<us_t>(subd - ss);
         return PyDelta_FromDSU(dd.count(), ss.count(), us.count());
     }
 
-    PYBIND11_TYPE_CASTER(type, _("datetime.timedelta"));
+    PYBIND11_TYPE_CASTER(type, const_name("datetime.timedelta"));
 };
 
+inline std::tm *localtime_thread_safe(const std::time_t *time, std::tm *buf) {
+#if (defined(__STDC_LIB_EXT1__) && defined(__STDC_WANT_LIB_EXT1__)) || defined(_MSC_VER)
+    if (localtime_s(buf, time))
+        return nullptr;
+    return buf;
+#else
+    static std::mutex mtx;
+    std::lock_guard<std::mutex> lock(mtx);
+    std::tm *tm_ptr = std::localtime(time);
+    if (tm_ptr != nullptr) {
+        *buf = *tm_ptr;
+    }
+    return tm_ptr;
+#endif
+}
+
 // This is for casting times on the system clock into datetime.datetime instances
-template <typename Duration> class type_caster<std::chrono::time_point<std::chrono::system_clock, Duration>> {
+template <typename Duration>
+class type_caster<std::chrono::time_point<std::chrono::system_clock, Duration>> {
 public:
-    typedef std::chrono::time_point<std::chrono::system_clock, Duration> type;
+    using type = std::chrono::time_point<std::chrono::system_clock, Duration>;
     bool load(handle src, bool) {
         using namespace std::chrono;
 
         // Lazy initialise the PyDateTime import
-        if (!PyDateTimeAPI) { PyDateTime_IMPORT; }
+        if (!PyDateTimeAPI) {
+            PyDateTime_IMPORT;
+        }
+
+        if (!src) {
+            return false;
+        }
+
+        std::tm cal;
+        microseconds msecs;
 
-        if (!src) return false;
         if (PyDateTime_Check(src.ptr())) {
-            std::tm cal;
-            cal.tm_sec   = PyDateTime_DATE_GET_SECOND(src.ptr());
-            cal.tm_min   = PyDateTime_DATE_GET_MINUTE(src.ptr());
-            cal.tm_hour  = PyDateTime_DATE_GET_HOUR(src.ptr());
-            cal.tm_mday  = PyDateTime_GET_DAY(src.ptr());
-            cal.tm_mon   = PyDateTime_GET_MONTH(src.ptr()) - 1;
-            cal.tm_year  = PyDateTime_GET_YEAR(src.ptr()) - 1900;
+            cal.tm_sec = PyDateTime_DATE_GET_SECOND(src.ptr());
+            cal.tm_min = PyDateTime_DATE_GET_MINUTE(src.ptr());
+            cal.tm_hour = PyDateTime_DATE_GET_HOUR(src.ptr());
+            cal.tm_mday = PyDateTime_GET_DAY(src.ptr());
+            cal.tm_mon = PyDateTime_GET_MONTH(src.ptr()) - 1;
+            cal.tm_year = PyDateTime_GET_YEAR(src.ptr()) - 1900;
             cal.tm_isdst = -1;
-
-            value = system_clock::from_time_t(std::mktime(&cal)) + microseconds(PyDateTime_DATE_GET_MICROSECOND(src.ptr()));
-            return true;
+            msecs = microseconds(PyDateTime_DATE_GET_MICROSECOND(src.ptr()));
+        } else if (PyDate_Check(src.ptr())) {
+            cal.tm_sec = 0;
+            cal.tm_min = 0;
+            cal.tm_hour = 0;
+            cal.tm_mday = PyDateTime_GET_DAY(src.ptr());
+            cal.tm_mon = PyDateTime_GET_MONTH(src.ptr()) - 1;
+            cal.tm_year = PyDateTime_GET_YEAR(src.ptr()) - 1900;
+            cal.tm_isdst = -1;
+            msecs = microseconds(0);
+        } else if (PyTime_Check(src.ptr())) {
+            cal.tm_sec = PyDateTime_TIME_GET_SECOND(src.ptr());
+            cal.tm_min = PyDateTime_TIME_GET_MINUTE(src.ptr());
+            cal.tm_hour = PyDateTime_TIME_GET_HOUR(src.ptr());
+            cal.tm_mday = 1;  // This date (day, month, year) = (1, 0, 70)
+            cal.tm_mon = 0;   // represents 1-Jan-1970, which is the first
+            cal.tm_year = 70; // earliest available date for Python's datetime
+            cal.tm_isdst = -1;
+            msecs = microseconds(PyDateTime_TIME_GET_MICROSECOND(src.ptr()));
+        } else {
+            return false;
         }
-        else return false;
+
+        value = time_point_cast<Duration>(system_clock::from_time_t(std::mktime(&cal)) + msecs);
+        return true;
     }
 
-    static handle cast(const std::chrono::time_point<std::chrono::system_clock, Duration> &src, return_value_policy /* policy */, handle /* parent */) {
+    static handle cast(const std::chrono::time_point<std::chrono::system_clock, Duration> &src,
+                       return_value_policy /* policy */,
+                       handle /* parent */) {
         using namespace std::chrono;
 
         // Lazy initialise the PyDateTime import
-        if (!PyDateTimeAPI) { PyDateTime_IMPORT; }
-
-        std::time_t tt = system_clock::to_time_t(time_point_cast<system_clock::duration>(src));
-        // this function uses static memory so it's best to copy it out asap just in case
-        // otherwise other code that is using localtime may break this (not just python code)
-        std::tm localtime = *std::localtime(&tt);
+        if (!PyDateTimeAPI) {
+            PyDateTime_IMPORT;
+        }
 
-        // Declare these special duration types so the conversions happen with the correct primitive types (int)
+        // Get out microseconds, and make sure they are positive, to avoid bug in eastern
+        // hemisphere time zones (cfr. https://github.com/pybind/pybind11/issues/2417)
         using us_t = duration<int, std::micro>;
+        auto us = duration_cast<us_t>(src.time_since_epoch() % seconds(1));
+        if (us.count() < 0) {
+            us += seconds(1);
+        }
 
+        // Subtract microseconds BEFORE `system_clock::to_time_t`, because:
+        // > If std::time_t has lower precision, it is implementation-defined whether the value is
+        // rounded or truncated. (https://en.cppreference.com/w/cpp/chrono/system_clock/to_time_t)
+        std::time_t tt
+            = system_clock::to_time_t(time_point_cast<system_clock::duration>(src - us));
+
+        std::tm localtime;
+        std::tm *localtime_ptr = localtime_thread_safe(&tt, &localtime);
+        if (!localtime_ptr) {
+            throw cast_error("Unable to represent system_clock in local time");
+        }
         return PyDateTime_FromDateAndTime(localtime.tm_year + 1900,
                                           localtime.tm_mon + 1,
                                           localtime.tm_mday,
                                           localtime.tm_hour,
                                           localtime.tm_min,
                                           localtime.tm_sec,
-                                          (duration_cast<us_t>(src.time_since_epoch() % seconds(1))).count());
+                                          us.count());
     }
-    PYBIND11_TYPE_CASTER(type, _("datetime.datetime"));
+    PYBIND11_TYPE_CASTER(type, const_name("datetime.datetime"));
 };
 
 // Other clocks that are not the system clock are not measured as datetime.datetime objects
 // since they are not measured on calendar time. So instead we just make them timedeltas
 // Or if they have passed us a time as a float we convert that
-template <typename Clock, typename Duration> class type_caster<std::chrono::time_point<Clock, Duration>>
-: public duration_caster<std::chrono::time_point<Clock, Duration>> {
-};
-
-template <typename Rep, typename Period> class type_caster<std::chrono::duration<Rep, Period>>
-: public duration_caster<std::chrono::duration<Rep, Period>> {
-};
+template <typename Clock, typename Duration>
+class type_caster<std::chrono::time_point<Clock, Duration>>
+    : public duration_caster<std::chrono::time_point<Clock, Duration>> {};
+
+template <typename Rep, typename Period>
+class type_caster<std::chrono::duration<Rep, Period>>
+    : public duration_caster<std::chrono::duration<Rep, Period>> {};
 
-NAMESPACE_END(detail)
-NAMESPACE_END(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/complex.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/complex.h`

 * *Files 8% similar despite different names*

```diff
@@ -6,60 +6,69 @@
     All rights reserved. Use of this source code is governed by a
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
 #include "pybind11.h"
+
 #include <complex>
 
 /// glibc defines I as a macro which breaks things, e.g., boost template names
 #ifdef I
-#  undef I
+#    undef I
 #endif
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
 
-template <typename T> struct format_descriptor<std::complex<T>, detail::enable_if_t<std::is_floating_point<T>::value>> {
+template <typename T>
+struct format_descriptor<std::complex<T>, detail::enable_if_t<std::is_floating_point<T>::value>> {
     static constexpr const char c = format_descriptor<T>::c;
-    static constexpr const char value[3] = { 'Z', c, '\0' };
+    static constexpr const char value[3] = {'Z', c, '\0'};
     static std::string format() { return std::string(value); }
 };
 
 #ifndef PYBIND11_CPP17
 
-template <typename T> constexpr const char format_descriptor<
-    std::complex<T>, detail::enable_if_t<std::is_floating_point<T>::value>>::value[3];
+template <typename T>
+constexpr const char
+    format_descriptor<std::complex<T>,
+                      detail::enable_if_t<std::is_floating_point<T>::value>>::value[3];
 
 #endif
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
-template <typename T> struct is_fmt_numeric<std::complex<T>, detail::enable_if_t<std::is_floating_point<T>::value>> {
+template <typename T>
+struct is_fmt_numeric<std::complex<T>, detail::enable_if_t<std::is_floating_point<T>::value>> {
     static constexpr bool value = true;
     static constexpr int index = is_fmt_numeric<T>::index + 3;
 };
 
-template <typename T> class type_caster<std::complex<T>> {
+template <typename T>
+class type_caster<std::complex<T>> {
 public:
     bool load(handle src, bool convert) {
-        if (!src)
+        if (!src) {
             return false;
-        if (!convert && !PyComplex_Check(src.ptr()))
+        }
+        if (!convert && !PyComplex_Check(src.ptr())) {
             return false;
+        }
         Py_complex result = PyComplex_AsCComplex(src.ptr());
         if (result.real == -1.0 && PyErr_Occurred()) {
             PyErr_Clear();
             return false;
         }
         value = std::complex<T>((T) result.real, (T) result.imag);
         return true;
     }
 
-    static handle cast(const std::complex<T> &src, return_value_policy /* policy */, handle /* parent */) {
+    static handle
+    cast(const std::complex<T> &src, return_value_policy /* policy */, handle /* parent */) {
         return PyComplex_FromDoubles((double) src.real(), (double) src.imag());
     }
 
-    PYBIND11_TYPE_CASTER(std::complex<T>, _("complex"));
+    PYBIND11_TYPE_CASTER(std::complex<T>, const_name("complex"));
 };
-NAMESPACE_END(detail)
-NAMESPACE_END(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/detail/class.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/class.h`

 * *Files 14% similar despite different names*

```diff
@@ -8,26 +8,39 @@
 */
 
 #pragma once
 
 #include "../attr.h"
 #include "../options.h"
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
-#if PY_VERSION_HEX >= 0x03030000
-#  define PYBIND11_BUILTIN_QUALNAME
-#  define PYBIND11_SET_OLDPY_QUALNAME(obj, nameobj)
+#if !defined(PYPY_VERSION)
+#    define PYBIND11_BUILTIN_QUALNAME
+#    define PYBIND11_SET_OLDPY_QUALNAME(obj, nameobj)
 #else
-// In pre-3.3 Python, we still set __qualname__ so that we can produce reliable function type
-// signatures; in 3.3+ this macro expands to nothing:
-#  define PYBIND11_SET_OLDPY_QUALNAME(obj, nameobj) setattr((PyObject *) obj, "__qualname__", nameobj)
+// In PyPy, we still set __qualname__ so that we can produce reliable function type
+// signatures; in CPython this macro expands to nothing:
+#    define PYBIND11_SET_OLDPY_QUALNAME(obj, nameobj)                                             \
+        setattr((PyObject *) obj, "__qualname__", nameobj)
 #endif
 
+inline std::string get_fully_qualified_tp_name(PyTypeObject *type) {
+#if !defined(PYPY_VERSION)
+    return type->tp_name;
+#else
+    auto module_name = handle((PyObject *) type).attr("__module__").cast<std::string>();
+    if (module_name == PYBIND11_BUILTINS_MODULE)
+        return type->tp_name;
+    else
+        return std::move(module_name) + "." + type->tp_name;
+#endif
+}
+
 inline PyTypeObject *type_incref(PyTypeObject *type) {
     Py_INCREF(type);
     return type;
 }
 
 #if !defined(PYPY_VERSION)
 
@@ -38,43 +51,55 @@
 
 /// `pybind11_static_property.__set__()`: Just like the above `__get__()`.
 extern "C" inline int pybind11_static_set(PyObject *self, PyObject *obj, PyObject *value) {
     PyObject *cls = PyType_Check(obj) ? obj : (PyObject *) Py_TYPE(obj);
     return PyProperty_Type.tp_descr_set(self, cls, value);
 }
 
+// Forward declaration to use in `make_static_property_type()`
+inline void enable_dynamic_attributes(PyHeapTypeObject *heap_type);
+
 /** A `static_property` is the same as a `property` but the `__get__()` and `__set__()`
     methods are modified to always use the object type instead of a concrete instance.
     Return value: New reference. */
 inline PyTypeObject *make_static_property_type() {
     constexpr auto *name = "pybind11_static_property";
     auto name_obj = reinterpret_steal<object>(PYBIND11_FROM_STRING(name));
 
     /* Danger zone: from now (and until PyType_Ready), make sure to
        issue no Python C API calls which could potentially invoke the
        garbage collector (the GC will call type_traverse(), which will in
        turn find the newly constructed type in an invalid state) */
-    auto heap_type = (PyHeapTypeObject *) PyType_Type.tp_alloc(&PyType_Type, 0);
-    if (!heap_type)
+    auto *heap_type = (PyHeapTypeObject *) PyType_Type.tp_alloc(&PyType_Type, 0);
+    if (!heap_type) {
         pybind11_fail("make_static_property_type(): error allocating type!");
+    }
 
     heap_type->ht_name = name_obj.inc_ref().ptr();
-#ifdef PYBIND11_BUILTIN_QUALNAME
+#    ifdef PYBIND11_BUILTIN_QUALNAME
     heap_type->ht_qualname = name_obj.inc_ref().ptr();
-#endif
+#    endif
 
-    auto type = &heap_type->ht_type;
+    auto *type = &heap_type->ht_type;
     type->tp_name = name;
     type->tp_base = type_incref(&PyProperty_Type);
     type->tp_flags = Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE | Py_TPFLAGS_HEAPTYPE;
     type->tp_descr_get = pybind11_static_get;
     type->tp_descr_set = pybind11_static_set;
 
-    if (PyType_Ready(type) < 0)
+    if (PyType_Ready(type) < 0) {
         pybind11_fail("make_static_property_type(): failure in PyType_Ready()!");
+    }
+
+#    if PY_VERSION_HEX >= 0x030C0000
+    // PRE 3.12 FEATURE FREEZE. PLEASE REVIEW AFTER FREEZE.
+    // Since Python-3.12 property-derived types are required to
+    // have dynamic attributes (to set `__doc__`)
+    enable_dynamic_attributes(heap_type);
+#    endif
 
     setattr((PyObject *) type, "__module__", str("pybind11_builtins"));
     PYBIND11_SET_OLDPY_QUALNAME(type, name_obj);
 
     return type;
 }
 
@@ -82,47 +107,50 @@
 
 /** PyPy has some issues with the above C API, so we evaluate Python code instead.
     This function will only be called once so performance isn't really a concern.
     Return value: New reference. */
 inline PyTypeObject *make_static_property_type() {
     auto d = dict();
     PyObject *result = PyRun_String(R"(\
-        class pybind11_static_property(property):
-            def __get__(self, obj, cls):
-                return property.__get__(self, cls, cls)
-
-            def __set__(self, obj, value):
-                cls = obj if isinstance(obj, type) else type(obj)
-                property.__set__(self, cls, value)
-        )", Py_file_input, d.ptr(), d.ptr()
-    );
+class pybind11_static_property(property):
+    def __get__(self, obj, cls):
+        return property.__get__(self, cls, cls)
+
+    def __set__(self, obj, value):
+        cls = obj if isinstance(obj, type) else type(obj)
+        property.__set__(self, cls, value)
+)",
+                                    Py_file_input,
+                                    d.ptr(),
+                                    d.ptr());
     if (result == nullptr)
         throw error_already_set();
     Py_DECREF(result);
     return (PyTypeObject *) d["pybind11_static_property"].cast<object>().release().ptr();
 }
 
 #endif // PYPY
 
 /** Types with static properties need to handle `Type.static_prop = x` in a specific way.
     By default, Python replaces the `static_property` itself, but for wrapped C++ types
     we need to call `static_property.__set__()` in order to propagate the new value to
     the underlying C++ data structure. */
-extern "C" inline int pybind11_meta_setattro(PyObject* obj, PyObject* name, PyObject* value) {
+extern "C" inline int pybind11_meta_setattro(PyObject *obj, PyObject *name, PyObject *value) {
     // Use `_PyType_Lookup()` instead of `PyObject_GetAttr()` in order to get the raw
     // descriptor (`property`) instead of calling `tp_descr_get` (`property.__get__()`).
     PyObject *descr = _PyType_Lookup((PyTypeObject *) obj, name);
 
     // The following assignment combinations are possible:
     //   1. `Type.static_prop = value`             --> descr_set: `Type.static_prop.__set__(value)`
     //   2. `Type.static_prop = other_static_prop` --> setattro:  replace existing `static_prop`
     //   3. `Type.regular_attribute = value`       --> setattro:  regular attribute assignment
-    const auto static_prop = (PyObject *) get_internals().static_property_type;
-    const auto call_descr_set = descr && PyObject_IsInstance(descr, static_prop)
-                                && !PyObject_IsInstance(value, static_prop);
+    auto *const static_prop = (PyObject *) get_internals().static_property_type;
+    const auto call_descr_set = (descr != nullptr) && (value != nullptr)
+                                && (PyObject_IsInstance(descr, static_prop) != 0)
+                                && (PyObject_IsInstance(value, static_prop) == 0);
     if (call_descr_set) {
         // Call `static_property.__set__()` instead of replacing the `static_property`.
 #if !defined(PYPY_VERSION)
         return Py_TYPE(descr)->tp_descr_set(descr, obj, value);
 #else
         if (PyObject *result = PyObject_CallMethod(descr, "__set__", "OO", obj, value)) {
             Py_DECREF(result);
@@ -133,84 +161,153 @@
 #endif
     } else {
         // Replace existing attribute.
         return PyType_Type.tp_setattro(obj, name, value);
     }
 }
 
-#if PY_MAJOR_VERSION >= 3
 /**
  * Python 3's PyInstanceMethod_Type hides itself via its tp_descr_get, which prevents aliasing
  * methods via cls.attr("m2") = cls.attr("m1"): instead the tp_descr_get returns a plain function,
  * when called on a class, or a PyMethod, when called on an instance.  Override that behaviour here
  * to do a special case bypass for PyInstanceMethod_Types.
  */
 extern "C" inline PyObject *pybind11_meta_getattro(PyObject *obj, PyObject *name) {
     PyObject *descr = _PyType_Lookup((PyTypeObject *) obj, name);
     if (descr && PyInstanceMethod_Check(descr)) {
         Py_INCREF(descr);
         return descr;
     }
-    else {
-        return PyType_Type.tp_getattro(obj, name);
+    return PyType_Type.tp_getattro(obj, name);
+}
+
+/// metaclass `__call__` function that is used to create all pybind11 objects.
+extern "C" inline PyObject *pybind11_meta_call(PyObject *type, PyObject *args, PyObject *kwargs) {
+
+    // use the default metaclass call to create/initialize the object
+    PyObject *self = PyType_Type.tp_call(type, args, kwargs);
+    if (self == nullptr) {
+        return nullptr;
+    }
+
+    // This must be a pybind11 instance
+    auto *instance = reinterpret_cast<detail::instance *>(self);
+
+    // Ensure that the base __init__ function(s) were called
+    for (const auto &vh : values_and_holders(instance)) {
+        if (!vh.holder_constructed()) {
+            PyErr_Format(PyExc_TypeError,
+                         "%.200s.__init__() must be called when overriding __init__",
+                         get_fully_qualified_tp_name(vh.type->type).c_str());
+            Py_DECREF(self);
+            return nullptr;
+        }
     }
+
+    return self;
+}
+
+/// Cleanup the type-info for a pybind11-registered type.
+extern "C" inline void pybind11_meta_dealloc(PyObject *obj) {
+    auto *type = (PyTypeObject *) obj;
+    auto &internals = get_internals();
+
+    // A pybind11-registered type will:
+    // 1) be found in internals.registered_types_py
+    // 2) have exactly one associated `detail::type_info`
+    auto found_type = internals.registered_types_py.find(type);
+    if (found_type != internals.registered_types_py.end() && found_type->second.size() == 1
+        && found_type->second[0]->type == type) {
+
+        auto *tinfo = found_type->second[0];
+        auto tindex = std::type_index(*tinfo->cpptype);
+        internals.direct_conversions.erase(tindex);
+
+        if (tinfo->module_local) {
+            get_local_internals().registered_types_cpp.erase(tindex);
+        } else {
+            internals.registered_types_cpp.erase(tindex);
+        }
+        internals.registered_types_py.erase(tinfo->type);
+
+        // Actually just `std::erase_if`, but that's only available in C++20
+        auto &cache = internals.inactive_override_cache;
+        for (auto it = cache.begin(), last = cache.end(); it != last;) {
+            if (it->first == (PyObject *) tinfo->type) {
+                it = cache.erase(it);
+            } else {
+                ++it;
+            }
+        }
+
+        delete tinfo;
+    }
+
+    PyType_Type.tp_dealloc(obj);
 }
-#endif
 
 /** This metaclass is assigned by default to all pybind11 types and is required in order
     for static properties to function correctly. Users may override this using `py::metaclass`.
     Return value: New reference. */
-inline PyTypeObject* make_default_metaclass() {
+inline PyTypeObject *make_default_metaclass() {
     constexpr auto *name = "pybind11_type";
     auto name_obj = reinterpret_steal<object>(PYBIND11_FROM_STRING(name));
 
     /* Danger zone: from now (and until PyType_Ready), make sure to
        issue no Python C API calls which could potentially invoke the
        garbage collector (the GC will call type_traverse(), which will in
        turn find the newly constructed type in an invalid state) */
-    auto heap_type = (PyHeapTypeObject *) PyType_Type.tp_alloc(&PyType_Type, 0);
-    if (!heap_type)
+    auto *heap_type = (PyHeapTypeObject *) PyType_Type.tp_alloc(&PyType_Type, 0);
+    if (!heap_type) {
         pybind11_fail("make_default_metaclass(): error allocating metaclass!");
+    }
 
     heap_type->ht_name = name_obj.inc_ref().ptr();
 #ifdef PYBIND11_BUILTIN_QUALNAME
     heap_type->ht_qualname = name_obj.inc_ref().ptr();
 #endif
 
-    auto type = &heap_type->ht_type;
+    auto *type = &heap_type->ht_type;
     type->tp_name = name;
     type->tp_base = type_incref(&PyType_Type);
     type->tp_flags = Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE | Py_TPFLAGS_HEAPTYPE;
 
+    type->tp_call = pybind11_meta_call;
+
     type->tp_setattro = pybind11_meta_setattro;
-#if PY_MAJOR_VERSION >= 3
     type->tp_getattro = pybind11_meta_getattro;
-#endif
 
-    if (PyType_Ready(type) < 0)
+    type->tp_dealloc = pybind11_meta_dealloc;
+
+    if (PyType_Ready(type) < 0) {
         pybind11_fail("make_default_metaclass(): failure in PyType_Ready()!");
+    }
 
     setattr((PyObject *) type, "__module__", str("pybind11_builtins"));
     PYBIND11_SET_OLDPY_QUALNAME(type, name_obj);
 
     return type;
 }
 
 /// For multiple inheritance types we need to recursively register/deregister base pointers for any
 /// base classes with pointers that are difference from the instance value pointer so that we can
-/// correctly recognize an offset base class pointer. This calls a function with any offset base ptrs.
-inline void traverse_offset_bases(void *valueptr, const detail::type_info *tinfo, instance *self,
-        bool (*f)(void * /*parentptr*/, instance * /*self*/)) {
+/// correctly recognize an offset base class pointer. This calls a function with any offset base
+/// ptrs.
+inline void traverse_offset_bases(void *valueptr,
+                                  const detail::type_info *tinfo,
+                                  instance *self,
+                                  bool (*f)(void * /*parentptr*/, instance * /*self*/)) {
     for (handle h : reinterpret_borrow<tuple>(tinfo->type->tp_bases)) {
-        if (auto parent_tinfo = get_type_info((PyTypeObject *) h.ptr())) {
+        if (auto *parent_tinfo = get_type_info((PyTypeObject *) h.ptr())) {
             for (auto &c : parent_tinfo->implicit_casts) {
                 if (c.first == tinfo->cpptype) {
                     auto *parentptr = c.second(valueptr);
-                    if (parentptr != valueptr)
+                    if (parentptr != valueptr) {
                         f(parentptr, self);
+                    }
                     traverse_offset_bases(parentptr, parent_tinfo, self, f);
                     break;
                 }
             }
         }
     }
 }
@@ -219,405 +316,428 @@
     get_internals().registered_instances.emplace(ptr, self);
     return true; // unused, but gives the same signature as the deregister func
 }
 inline bool deregister_instance_impl(void *ptr, instance *self) {
     auto &registered_instances = get_internals().registered_instances;
     auto range = registered_instances.equal_range(ptr);
     for (auto it = range.first; it != range.second; ++it) {
-        if (Py_TYPE(self) == Py_TYPE(it->second)) {
+        if (self == it->second) {
             registered_instances.erase(it);
             return true;
         }
     }
     return false;
 }
 
 inline void register_instance(instance *self, void *valptr, const type_info *tinfo) {
     register_instance_impl(valptr, self);
-    if (!tinfo->simple_ancestors)
+    if (!tinfo->simple_ancestors) {
         traverse_offset_bases(valptr, tinfo, self, register_instance_impl);
+    }
 }
 
 inline bool deregister_instance(instance *self, void *valptr, const type_info *tinfo) {
     bool ret = deregister_instance_impl(valptr, self);
-    if (!tinfo->simple_ancestors)
+    if (!tinfo->simple_ancestors) {
         traverse_offset_bases(valptr, tinfo, self, deregister_instance_impl);
+    }
     return ret;
 }
 
-/// Instance creation function for all pybind11 types. It allocates the internal instance layout for
-/// holding C++ objects and holders.  Allocation is done lazily (the first time the instance is cast
-/// to a reference or pointer), and initialization is done by an `__init__` function.
+/// Instance creation function for all pybind11 types. It allocates the internal instance layout
+/// for holding C++ objects and holders.  Allocation is done lazily (the first time the instance is
+/// cast to a reference or pointer), and initialization is done by an `__init__` function.
 inline PyObject *make_new_instance(PyTypeObject *type) {
 #if defined(PYPY_VERSION)
-    // PyPy gets tp_basicsize wrong (issue 2482) under multiple inheritance when the first inherited
-    // object is a a plain Python type (i.e. not derived from an extension type).  Fix it.
+    // PyPy gets tp_basicsize wrong (issue 2482) under multiple inheritance when the first
+    // inherited object is a plain Python type (i.e. not derived from an extension type).  Fix it.
     ssize_t instance_size = static_cast<ssize_t>(sizeof(instance));
     if (type->tp_basicsize < instance_size) {
         type->tp_basicsize = instance_size;
     }
 #endif
     PyObject *self = type->tp_alloc(type, 0);
-    auto inst = reinterpret_cast<instance *>(self);
+    auto *inst = reinterpret_cast<instance *>(self);
     // Allocate the value/holder internals:
     inst->allocate_layout();
 
-    inst->owned = true;
-
     return self;
 }
 
 /// Instance creation function for all pybind11 types. It only allocates space for the
 /// C++ object, but doesn't call the constructor -- an `__init__` function must do that.
 extern "C" inline PyObject *pybind11_object_new(PyTypeObject *type, PyObject *, PyObject *) {
     return make_new_instance(type);
 }
 
 /// An `__init__` function constructs the C++ object. Users should provide at least one
 /// of these using `py::init` or directly with `.def(__init__, ...)`. Otherwise, the
 /// following default function will be used which simply throws an exception.
 extern "C" inline int pybind11_object_init(PyObject *self, PyObject *, PyObject *) {
     PyTypeObject *type = Py_TYPE(self);
-    std::string msg;
-#if defined(PYPY_VERSION)
-    msg += handle((PyObject *) type).attr("__module__").cast<std::string>() + ".";
-#endif
-    msg += type->tp_name;
-    msg += ": No constructor defined!";
+    std::string msg = get_fully_qualified_tp_name(type) + ": No constructor defined!";
     PyErr_SetString(PyExc_TypeError, msg.c_str());
     return -1;
 }
 
 inline void add_patient(PyObject *nurse, PyObject *patient) {
     auto &internals = get_internals();
-    auto instance = reinterpret_cast<detail::instance *>(nurse);
+    auto *instance = reinterpret_cast<detail::instance *>(nurse);
     instance->has_patients = true;
     Py_INCREF(patient);
     internals.patients[nurse].push_back(patient);
 }
 
 inline void clear_patients(PyObject *self) {
-    auto instance = reinterpret_cast<detail::instance *>(self);
+    auto *instance = reinterpret_cast<detail::instance *>(self);
     auto &internals = get_internals();
     auto pos = internals.patients.find(self);
     assert(pos != internals.patients.end());
     // Clearing the patients can cause more Python code to run, which
     // can invalidate the iterator. Extract the vector of patients
     // from the unordered_map first.
     auto patients = std::move(pos->second);
     internals.patients.erase(pos);
     instance->has_patients = false;
-    for (PyObject *&patient : patients)
+    for (PyObject *&patient : patients) {
         Py_CLEAR(patient);
+    }
 }
 
 /// Clears all internal data from the instance and removes it from registered instances in
 /// preparation for deallocation.
 inline void clear_instance(PyObject *self) {
-    auto instance = reinterpret_cast<detail::instance *>(self);
+    auto *instance = reinterpret_cast<detail::instance *>(self);
 
     // Deallocate any values/holders, if present:
     for (auto &v_h : values_and_holders(instance)) {
         if (v_h) {
 
             // We have to deregister before we call dealloc because, for virtual MI types, we still
             // need to be able to get the parent pointers.
-            if (v_h.instance_registered() && !deregister_instance(instance, v_h.value_ptr(), v_h.type))
-                pybind11_fail("pybind11_object_dealloc(): Tried to deallocate unregistered instance!");
+            if (v_h.instance_registered()
+                && !deregister_instance(instance, v_h.value_ptr(), v_h.type)) {
+                pybind11_fail(
+                    "pybind11_object_dealloc(): Tried to deallocate unregistered instance!");
+            }
 
-            if (instance->owned || v_h.holder_constructed())
+            if (instance->owned || v_h.holder_constructed()) {
                 v_h.type->dealloc(v_h);
+            }
         }
     }
     // Deallocate the value/holder layout internals:
     instance->deallocate_layout();
 
-    if (instance->weakrefs)
+    if (instance->weakrefs) {
         PyObject_ClearWeakRefs(self);
+    }
 
     PyObject **dict_ptr = _PyObject_GetDictPtr(self);
-    if (dict_ptr)
+    if (dict_ptr) {
         Py_CLEAR(*dict_ptr);
+    }
 
-    if (instance->has_patients)
+    if (instance->has_patients) {
         clear_patients(self);
+    }
 }
 
 /// Instance destructor function for all pybind11 types. It calls `type_info.dealloc`
 /// to destroy the C++ object itself, while the rest is Python bookkeeping.
 extern "C" inline void pybind11_object_dealloc(PyObject *self) {
+    auto *type = Py_TYPE(self);
+
+    // If this is a GC tracked object, untrack it first
+    // Note that the track call is implicitly done by the
+    // default tp_alloc, which we never override.
+    if (PyType_HasFeature(type, Py_TPFLAGS_HAVE_GC) != 0) {
+        PyObject_GC_UnTrack(self);
+    }
+
     clear_instance(self);
 
-    auto type = Py_TYPE(self);
     type->tp_free(self);
 
+#if PY_VERSION_HEX < 0x03080000
     // `type->tp_dealloc != pybind11_object_dealloc` means that we're being called
     // as part of a derived type's dealloc, in which case we're not allowed to decref
     // the type here. For cross-module compatibility, we shouldn't compare directly
     // with `pybind11_object_dealloc`, but with the common one stashed in internals.
     auto pybind11_object_type = (PyTypeObject *) get_internals().instance_base;
     if (type->tp_dealloc == pybind11_object_type->tp_dealloc)
         Py_DECREF(type);
+#else
+    // This was not needed before Python 3.8 (Python issue 35810)
+    // https://github.com/pybind/pybind11/issues/1946
+    Py_DECREF(type);
+#endif
 }
 
+std::string error_string();
+
 /** Create the type which can be used as a common base for all classes.  This is
     needed in order to satisfy Python's requirements for multiple inheritance.
     Return value: New reference. */
 inline PyObject *make_object_base_type(PyTypeObject *metaclass) {
     constexpr auto *name = "pybind11_object";
     auto name_obj = reinterpret_steal<object>(PYBIND11_FROM_STRING(name));
 
     /* Danger zone: from now (and until PyType_Ready), make sure to
        issue no Python C API calls which could potentially invoke the
        garbage collector (the GC will call type_traverse(), which will in
        turn find the newly constructed type in an invalid state) */
-    auto heap_type = (PyHeapTypeObject *) metaclass->tp_alloc(metaclass, 0);
-    if (!heap_type)
+    auto *heap_type = (PyHeapTypeObject *) metaclass->tp_alloc(metaclass, 0);
+    if (!heap_type) {
         pybind11_fail("make_object_base_type(): error allocating type!");
+    }
 
     heap_type->ht_name = name_obj.inc_ref().ptr();
 #ifdef PYBIND11_BUILTIN_QUALNAME
     heap_type->ht_qualname = name_obj.inc_ref().ptr();
 #endif
 
-    auto type = &heap_type->ht_type;
+    auto *type = &heap_type->ht_type;
     type->tp_name = name;
     type->tp_base = type_incref(&PyBaseObject_Type);
     type->tp_basicsize = static_cast<ssize_t>(sizeof(instance));
     type->tp_flags = Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE | Py_TPFLAGS_HEAPTYPE;
 
     type->tp_new = pybind11_object_new;
     type->tp_init = pybind11_object_init;
     type->tp_dealloc = pybind11_object_dealloc;
 
     /* Support weak references (needed for the keep_alive feature) */
     type->tp_weaklistoffset = offsetof(instance, weakrefs);
 
-    if (PyType_Ready(type) < 0)
-        pybind11_fail("PyType_Ready failed in make_object_base_type():" + error_string());
+    if (PyType_Ready(type) < 0) {
+        pybind11_fail("PyType_Ready failed in make_object_base_type(): " + error_string());
+    }
 
     setattr((PyObject *) type, "__module__", str("pybind11_builtins"));
     PYBIND11_SET_OLDPY_QUALNAME(type, name_obj);
 
     assert(!PyType_HasFeature(type, Py_TPFLAGS_HAVE_GC));
     return (PyObject *) heap_type;
 }
 
-/// dynamic_attr: Support for `d = instance.__dict__`.
-extern "C" inline PyObject *pybind11_get_dict(PyObject *self, void *) {
-    PyObject *&dict = *_PyObject_GetDictPtr(self);
-    if (!dict)
-        dict = PyDict_New();
-    Py_XINCREF(dict);
-    return dict;
-}
-
-/// dynamic_attr: Support for `instance.__dict__ = dict()`.
-extern "C" inline int pybind11_set_dict(PyObject *self, PyObject *new_dict, void *) {
-    if (!PyDict_Check(new_dict)) {
-        PyErr_Format(PyExc_TypeError, "__dict__ must be set to a dictionary, not a '%.200s'",
-                     Py_TYPE(new_dict)->tp_name);
-        return -1;
-    }
-    PyObject *&dict = *_PyObject_GetDictPtr(self);
-    Py_INCREF(new_dict);
-    Py_CLEAR(dict);
-    dict = new_dict;
-    return 0;
-}
-
 /// dynamic_attr: Allow the garbage collector to traverse the internal instance `__dict__`.
 extern "C" inline int pybind11_traverse(PyObject *self, visitproc visit, void *arg) {
     PyObject *&dict = *_PyObject_GetDictPtr(self);
     Py_VISIT(dict);
+// https://docs.python.org/3/c-api/typeobj.html#c.PyTypeObject.tp_traverse
+#if PY_VERSION_HEX >= 0x03090000
+    Py_VISIT(Py_TYPE(self));
+#endif
     return 0;
 }
 
 /// dynamic_attr: Allow the GC to clear the dictionary.
 extern "C" inline int pybind11_clear(PyObject *self) {
     PyObject *&dict = *_PyObject_GetDictPtr(self);
     Py_CLEAR(dict);
     return 0;
 }
 
 /// Give instances of this type a `__dict__` and opt into garbage collection.
 inline void enable_dynamic_attributes(PyHeapTypeObject *heap_type) {
-    auto type = &heap_type->ht_type;
-#if defined(PYPY_VERSION)
-    pybind11_fail(std::string(type->tp_name) + ": dynamic attributes are "
-                                               "currently not supported in "
-                                               "conjunction with PyPy!");
-#endif
+    auto *type = &heap_type->ht_type;
     type->tp_flags |= Py_TPFLAGS_HAVE_GC;
-    type->tp_dictoffset = type->tp_basicsize; // place dict at the end
-    type->tp_basicsize += (ssize_t)sizeof(PyObject *); // and allocate enough space for it
+#if PY_VERSION_HEX < 0x030B0000
+    type->tp_dictoffset = type->tp_basicsize;           // place dict at the end
+    type->tp_basicsize += (ssize_t) sizeof(PyObject *); // and allocate enough space for it
+#else
+    type->tp_flags |= Py_TPFLAGS_MANAGED_DICT;
+#endif
     type->tp_traverse = pybind11_traverse;
     type->tp_clear = pybind11_clear;
 
-    static PyGetSetDef getset[] = {
-        {const_cast<char*>("__dict__"), pybind11_get_dict, pybind11_set_dict, nullptr, nullptr},
-        {nullptr, nullptr, nullptr, nullptr, nullptr}
-    };
+    static PyGetSetDef getset[] = {{
+#if PY_VERSION_HEX < 0x03070000
+                                       const_cast<char *>("__dict__"),
+#else
+                                       "__dict__",
+#endif
+                                       PyObject_GenericGetDict,
+                                       PyObject_GenericSetDict,
+                                       nullptr,
+                                       nullptr},
+                                   {nullptr, nullptr, nullptr, nullptr, nullptr}};
     type->tp_getset = getset;
 }
 
 /// buffer_protocol: Fill in the view as specified by flags.
 extern "C" inline int pybind11_getbuffer(PyObject *obj, Py_buffer *view, int flags) {
     // Look for a `get_buffer` implementation in this type's info or any bases (following MRO).
     type_info *tinfo = nullptr;
     for (auto type : reinterpret_borrow<tuple>(Py_TYPE(obj)->tp_mro)) {
         tinfo = get_type_info((PyTypeObject *) type.ptr());
-        if (tinfo && tinfo->get_buffer)
+        if (tinfo && tinfo->get_buffer) {
             break;
+        }
     }
     if (view == nullptr || !tinfo || !tinfo->get_buffer) {
-        if (view)
+        if (view) {
             view->obj = nullptr;
+        }
         PyErr_SetString(PyExc_BufferError, "pybind11_getbuffer(): Internal error");
         return -1;
     }
     std::memset(view, 0, sizeof(Py_buffer));
     buffer_info *info = tinfo->get_buffer(obj, tinfo->get_buffer_data);
+    if ((flags & PyBUF_WRITABLE) == PyBUF_WRITABLE && info->readonly) {
+        delete info;
+        // view->obj = nullptr;  // Was just memset to 0, so not necessary
+        PyErr_SetString(PyExc_BufferError, "Writable buffer requested for readonly storage");
+        return -1;
+    }
     view->obj = obj;
     view->ndim = 1;
     view->internal = info;
     view->buf = info->ptr;
     view->itemsize = info->itemsize;
     view->len = view->itemsize;
-    for (auto s : info->shape)
+    for (auto s : info->shape) {
         view->len *= s;
-    if ((flags & PyBUF_FORMAT) == PyBUF_FORMAT)
+    }
+    view->readonly = static_cast<int>(info->readonly);
+    if ((flags & PyBUF_FORMAT) == PyBUF_FORMAT) {
         view->format = const_cast<char *>(info->format.c_str());
+    }
     if ((flags & PyBUF_STRIDES) == PyBUF_STRIDES) {
         view->ndim = (int) info->ndim;
-        view->strides = &info->strides[0];
-        view->shape = &info->shape[0];
+        view->strides = info->strides.data();
+        view->shape = info->shape.data();
     }
     Py_INCREF(view->obj);
     return 0;
 }
 
 /// buffer_protocol: Release the resources of the buffer.
 extern "C" inline void pybind11_releasebuffer(PyObject *, Py_buffer *view) {
     delete (buffer_info *) view->internal;
 }
 
 /// Give this type a buffer interface.
 inline void enable_buffer_protocol(PyHeapTypeObject *heap_type) {
     heap_type->ht_type.tp_as_buffer = &heap_type->as_buffer;
-#if PY_MAJOR_VERSION < 3
-    heap_type->ht_type.tp_flags |= Py_TPFLAGS_HAVE_NEWBUFFER;
-#endif
 
     heap_type->as_buffer.bf_getbuffer = pybind11_getbuffer;
     heap_type->as_buffer.bf_releasebuffer = pybind11_releasebuffer;
 }
 
 /** Create a brand new Python type according to the `type_record` specification.
     Return value: New reference. */
-inline PyObject* make_new_python_type(const type_record &rec) {
+inline PyObject *make_new_python_type(const type_record &rec) {
     auto name = reinterpret_steal<object>(PYBIND11_FROM_STRING(rec.name));
 
     auto qualname = name;
     if (rec.scope && !PyModule_Check(rec.scope.ptr()) && hasattr(rec.scope, "__qualname__")) {
-#if PY_MAJOR_VERSION >= 3
         qualname = reinterpret_steal<object>(
             PyUnicode_FromFormat("%U.%U", rec.scope.attr("__qualname__").ptr(), name.ptr()));
-#else
-        qualname = str(rec.scope.attr("__qualname__").cast<std::string>() + "." + rec.name);
-#endif
     }
 
-    object module;
+    object module_;
     if (rec.scope) {
-        if (hasattr(rec.scope, "__module__"))
-            module = rec.scope.attr("__module__");
-        else if (hasattr(rec.scope, "__name__"))
-            module = rec.scope.attr("__name__");
+        if (hasattr(rec.scope, "__module__")) {
+            module_ = rec.scope.attr("__module__");
+        } else if (hasattr(rec.scope, "__name__")) {
+            module_ = rec.scope.attr("__name__");
+        }
     }
 
-    auto full_name = c_str(
+    const auto *full_name = c_str(
 #if !defined(PYPY_VERSION)
-        module ? str(module).cast<std::string>() + "." + rec.name :
+        module_ ? str(module_).cast<std::string>() + "." + rec.name :
 #endif
-        rec.name);
+                rec.name);
 
     char *tp_doc = nullptr;
     if (rec.doc && options::show_user_defined_docstrings()) {
         /* Allocate memory for docstring (using PyObject_MALLOC, since
            Python will free this later on) */
-        size_t size = strlen(rec.doc) + 1;
+        size_t size = std::strlen(rec.doc) + 1;
         tp_doc = (char *) PyObject_MALLOC(size);
-        memcpy((void *) tp_doc, rec.doc, size);
+        std::memcpy((void *) tp_doc, rec.doc, size);
     }
 
     auto &internals = get_internals();
     auto bases = tuple(rec.bases);
-    auto base = (bases.size() == 0) ? internals.instance_base
-                                    : bases[0].ptr();
+    auto *base = (bases.empty()) ? internals.instance_base : bases[0].ptr();
 
     /* Danger zone: from now (and until PyType_Ready), make sure to
        issue no Python C API calls which could potentially invoke the
        garbage collector (the GC will call type_traverse(), which will in
        turn find the newly constructed type in an invalid state) */
-    auto metaclass = rec.metaclass.ptr() ? (PyTypeObject *) rec.metaclass.ptr()
-                                         : internals.default_metaclass;
+    auto *metaclass
+        = rec.metaclass.ptr() ? (PyTypeObject *) rec.metaclass.ptr() : internals.default_metaclass;
 
-    auto heap_type = (PyHeapTypeObject *) metaclass->tp_alloc(metaclass, 0);
-    if (!heap_type)
+    auto *heap_type = (PyHeapTypeObject *) metaclass->tp_alloc(metaclass, 0);
+    if (!heap_type) {
         pybind11_fail(std::string(rec.name) + ": Unable to create type object!");
+    }
 
     heap_type->ht_name = name.release().ptr();
 #ifdef PYBIND11_BUILTIN_QUALNAME
     heap_type->ht_qualname = qualname.inc_ref().ptr();
 #endif
 
-    auto type = &heap_type->ht_type;
+    auto *type = &heap_type->ht_type;
     type->tp_name = full_name;
     type->tp_doc = tp_doc;
-    type->tp_base = type_incref((PyTypeObject *)base);
+    type->tp_base = type_incref((PyTypeObject *) base);
     type->tp_basicsize = static_cast<ssize_t>(sizeof(instance));
-    if (bases.size() > 0)
+    if (!bases.empty()) {
         type->tp_bases = bases.release().ptr();
+    }
 
     /* Don't inherit base __init__ */
     type->tp_init = pybind11_object_init;
 
     /* Supported protocols */
     type->tp_as_number = &heap_type->as_number;
     type->tp_as_sequence = &heap_type->as_sequence;
     type->tp_as_mapping = &heap_type->as_mapping;
+    type->tp_as_async = &heap_type->as_async;
 
     /* Flags */
-    type->tp_flags |= Py_TPFLAGS_DEFAULT | Py_TPFLAGS_BASETYPE | Py_TPFLAGS_HEAPTYPE;
-#if PY_MAJOR_VERSION < 3
-    type->tp_flags |= Py_TPFLAGS_CHECKTYPES;
-#endif
+    type->tp_flags |= Py_TPFLAGS_DEFAULT | Py_TPFLAGS_HEAPTYPE;
+    if (!rec.is_final) {
+        type->tp_flags |= Py_TPFLAGS_BASETYPE;
+    }
 
-    if (rec.dynamic_attr)
+    if (rec.dynamic_attr) {
         enable_dynamic_attributes(heap_type);
+    }
 
-    if (rec.buffer_protocol)
+    if (rec.buffer_protocol) {
         enable_buffer_protocol(heap_type);
+    }
+
+    if (rec.custom_type_setup_callback) {
+        rec.custom_type_setup_callback(heap_type);
+    }
 
-    if (PyType_Ready(type) < 0)
-        pybind11_fail(std::string(rec.name) + ": PyType_Ready failed (" + error_string() + ")!");
+    if (PyType_Ready(type) < 0) {
+        pybind11_fail(std::string(rec.name) + ": PyType_Ready failed: " + error_string());
+    }
 
-    assert(rec.dynamic_attr ? PyType_HasFeature(type, Py_TPFLAGS_HAVE_GC)
-                            : !PyType_HasFeature(type, Py_TPFLAGS_HAVE_GC));
+    assert(!rec.dynamic_attr || PyType_HasFeature(type, Py_TPFLAGS_HAVE_GC));
 
     /* Register type with the parent scope */
-    if (rec.scope)
+    if (rec.scope) {
         setattr(rec.scope, rec.name, (PyObject *) type);
-    else
+    } else {
         Py_INCREF(type); // Keep it alive forever (reference leak)
+    }
 
-    if (module) // Needed by pydoc
-        setattr((PyObject *) type, "__module__", module);
+    if (module_) { // Needed by pydoc
+        setattr((PyObject *) type, "__module__", module_);
+    }
 
     PYBIND11_SET_OLDPY_QUALNAME(type, qualname);
 
     return (PyObject *) type;
 }
 
-NAMESPACE_END(detail)
-NAMESPACE_END(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/detail/common.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/common.h`

 * *Files 24% similar despite different names*

```diff
@@ -5,302 +5,489 @@
 
     All rights reserved. Use of this source code is governed by a
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
-#if !defined(NAMESPACE_BEGIN)
-#  define NAMESPACE_BEGIN(name) namespace name {
+#define PYBIND11_VERSION_MAJOR 2
+#define PYBIND11_VERSION_MINOR 10
+#define PYBIND11_VERSION_PATCH 4
+
+// Similar to Python's convention: https://docs.python.org/3/c-api/apiabiversion.html
+// Additional convention: 0xD = dev
+#define PYBIND11_VERSION_HEX 0x020A0400
+
+// Define some generic pybind11 helper macros for warning management.
+//
+// Note that compiler-specific push/pop pairs are baked into the
+// PYBIND11_NAMESPACE_BEGIN/PYBIND11_NAMESPACE_END pair of macros. Therefore manual
+// PYBIND11_WARNING_PUSH/PYBIND11_WARNING_POP are usually only needed in `#include` sections.
+//
+// If you find you need to suppress a warning, please try to make the suppression as local as
+// possible using these macros. Please also be sure to push/pop with the pybind11 macros. Please
+// only use compiler specifics if you need to check specific versions, e.g. Apple Clang vs. vanilla
+// Clang.
+#if defined(_MSC_VER)
+#    define PYBIND11_COMPILER_MSVC
+#    define PYBIND11_PRAGMA(...) __pragma(__VA_ARGS__)
+#    define PYBIND11_WARNING_PUSH PYBIND11_PRAGMA(warning(push))
+#    define PYBIND11_WARNING_POP PYBIND11_PRAGMA(warning(pop))
+#elif defined(__INTEL_COMPILER)
+#    define PYBIND11_COMPILER_INTEL
+#    define PYBIND11_PRAGMA(...) _Pragma(#__VA_ARGS__)
+#    define PYBIND11_WARNING_PUSH PYBIND11_PRAGMA(warning push)
+#    define PYBIND11_WARNING_POP PYBIND11_PRAGMA(warning pop)
+#elif defined(__clang__)
+#    define PYBIND11_COMPILER_CLANG
+#    define PYBIND11_PRAGMA(...) _Pragma(#__VA_ARGS__)
+#    define PYBIND11_WARNING_PUSH PYBIND11_PRAGMA(clang diagnostic push)
+#    define PYBIND11_WARNING_POP PYBIND11_PRAGMA(clang diagnostic push)
+#elif defined(__GNUC__)
+#    define PYBIND11_COMPILER_GCC
+#    define PYBIND11_PRAGMA(...) _Pragma(#__VA_ARGS__)
+#    define PYBIND11_WARNING_PUSH PYBIND11_PRAGMA(GCC diagnostic push)
+#    define PYBIND11_WARNING_POP PYBIND11_PRAGMA(GCC diagnostic pop)
 #endif
-#if !defined(NAMESPACE_END)
-#  define NAMESPACE_END(name) }
+
+#ifdef PYBIND11_COMPILER_MSVC
+#    define PYBIND11_WARNING_DISABLE_MSVC(name) PYBIND11_PRAGMA(warning(disable : name))
+#else
+#    define PYBIND11_WARNING_DISABLE_MSVC(name)
 #endif
 
+#ifdef PYBIND11_COMPILER_CLANG
+#    define PYBIND11_WARNING_DISABLE_CLANG(name) PYBIND11_PRAGMA(clang diagnostic ignored name)
+#else
+#    define PYBIND11_WARNING_DISABLE_CLANG(name)
+#endif
+
+#ifdef PYBIND11_COMPILER_GCC
+#    define PYBIND11_WARNING_DISABLE_GCC(name) PYBIND11_PRAGMA(GCC diagnostic ignored name)
+#else
+#    define PYBIND11_WARNING_DISABLE_GCC(name)
+#endif
+
+#ifdef PYBIND11_COMPILER_INTEL
+#    define PYBIND11_WARNING_DISABLE_INTEL(name) PYBIND11_PRAGMA(warning disable name)
+#else
+#    define PYBIND11_WARNING_DISABLE_INTEL(name)
+#endif
+
+#define PYBIND11_NAMESPACE_BEGIN(name)                                                            \
+    namespace name {                                                                              \
+    PYBIND11_WARNING_PUSH
+
+#define PYBIND11_NAMESPACE_END(name)                                                              \
+    PYBIND11_WARNING_POP                                                                          \
+    }
+
 // Robust support for some features and loading modules compiled against different pybind versions
-// requires forcing hidden visibility on pybind code, so we enforce this by setting the attribute on
-// the main `pybind11` namespace.
+// requires forcing hidden visibility on pybind code, so we enforce this by setting the attribute
+// on the main `pybind11` namespace.
 #if !defined(PYBIND11_NAMESPACE)
-#  ifdef __GNUG__
-#    define PYBIND11_NAMESPACE pybind11 __attribute__((visibility("hidden")))
-#  else
-#    define PYBIND11_NAMESPACE pybind11
-#  endif
+#    ifdef __GNUG__
+#        define PYBIND11_NAMESPACE pybind11 __attribute__((visibility("hidden")))
+#    else
+#        define PYBIND11_NAMESPACE pybind11
+#    endif
 #endif
 
-#if !(defined(_MSC_VER) && __cplusplus == 199711L) && !defined(__INTEL_COMPILER)
-#  if __cplusplus >= 201402L
-#    define PYBIND11_CPP14
-#    if __cplusplus >= 201703L
-#      define PYBIND11_CPP17
+#if !(defined(_MSC_VER) && __cplusplus == 199711L)
+#    if __cplusplus >= 201402L
+#        define PYBIND11_CPP14
+#        if __cplusplus >= 201703L
+#            define PYBIND11_CPP17
+#            if __cplusplus >= 202002L
+#                define PYBIND11_CPP20
+// Please update tests/pybind11_tests.cpp `cpp_std()` when adding a macro here.
+#            endif
+#        endif
 #    endif
-#  endif
 #elif defined(_MSC_VER) && __cplusplus == 199711L
-// MSVC sets _MSVC_LANG rather than __cplusplus (supposedly until the standard is fully implemented)
-// Unless you use the /Zc:__cplusplus flag on Visual Studio 2017 15.7 Preview 3 or newer
-#  if _MSVC_LANG >= 201402L
-#    define PYBIND11_CPP14
-#    if _MSVC_LANG > 201402L && _MSC_VER >= 1910
-#      define PYBIND11_CPP17
+// MSVC sets _MSVC_LANG rather than __cplusplus (supposedly until the standard is fully
+// implemented). Unless you use the /Zc:__cplusplus flag on Visual Studio 2017 15.7 Preview 3
+// or newer.
+#    if _MSVC_LANG >= 201402L
+#        define PYBIND11_CPP14
+#        if _MSVC_LANG > 201402L
+#            define PYBIND11_CPP17
+#            if _MSVC_LANG >= 202002L
+#                define PYBIND11_CPP20
+#            endif
+#        endif
 #    endif
-#  endif
 #endif
 
 // Compiler version assertions
 #if defined(__INTEL_COMPILER)
-#  if __INTEL_COMPILER < 1700
-#    error pybind11 requires Intel C++ compiler v17 or newer
-#  endif
+#    if __INTEL_COMPILER < 1800
+#        error pybind11 requires Intel C++ compiler v18 or newer
+#    elif __INTEL_COMPILER < 1900 && defined(PYBIND11_CPP14)
+#        error pybind11 supports only C++11 with Intel C++ compiler v18. Use v19 or newer for C++14.
+#    endif
+/* The following pragma cannot be pop'ed:
+   https://community.intel.com/t5/Intel-C-Compiler/Inline-and-no-inline-warning/td-p/1216764 */
+#    pragma warning disable 2196 // warning #2196: routine is both "inline" and "noinline"
 #elif defined(__clang__) && !defined(__apple_build_version__)
-#  if __clang_major__ < 3 || (__clang_major__ == 3 && __clang_minor__ < 3)
-#    error pybind11 requires clang 3.3 or newer
-#  endif
+#    if __clang_major__ < 3 || (__clang_major__ == 3 && __clang_minor__ < 3)
+#        error pybind11 requires clang 3.3 or newer
+#    endif
 #elif defined(__clang__)
 // Apple changes clang version macros to its Xcode version; the first Xcode release based on
 // (upstream) clang 3.3 was Xcode 5:
-#  if __clang_major__ < 5
-#    error pybind11 requires Xcode/clang 5.0 or newer
-#  endif
+#    if __clang_major__ < 5
+#        error pybind11 requires Xcode/clang 5.0 or newer
+#    endif
 #elif defined(__GNUG__)
-#  if __GNUC__ < 4 || (__GNUC__ == 4 && __GNUC_MINOR__ < 8)
-#    error pybind11 requires gcc 4.8 or newer
-#  endif
+#    if __GNUC__ < 4 || (__GNUC__ == 4 && __GNUC_MINOR__ < 8)
+#        error pybind11 requires gcc 4.8 or newer
+#    endif
 #elif defined(_MSC_VER)
-// Pybind hits various compiler bugs in 2015u2 and earlier, and also makes use of some stl features
-// (e.g. std::negation) added in 2015u3:
-#  if _MSC_FULL_VER < 190024210
-#    error pybind11 requires MSVC 2015 update 3 or newer
-#  endif
+#    if _MSC_VER < 1910
+#        error pybind11 2.10+ requires MSVC 2017 or newer
+#    endif
 #endif
 
 #if !defined(PYBIND11_EXPORT)
-#  if defined(WIN32) || defined(_WIN32)
-#    define PYBIND11_EXPORT __declspec(dllexport)
-#  else
-#    define PYBIND11_EXPORT __attribute__ ((visibility("default")))
-#  endif
+#    if defined(WIN32) || defined(_WIN32)
+#        define PYBIND11_EXPORT __declspec(dllexport)
+#    else
+#        define PYBIND11_EXPORT __attribute__((visibility("default")))
+#    endif
 #endif
 
-#if defined(_MSC_VER)
-#  define PYBIND11_NOINLINE __declspec(noinline)
+#if !defined(PYBIND11_EXPORT_EXCEPTION)
+#    if defined(__apple_build_version__)
+#        define PYBIND11_EXPORT_EXCEPTION PYBIND11_EXPORT
+#    else
+#        define PYBIND11_EXPORT_EXCEPTION
+#    endif
+#endif
+
+// For CUDA, GCC7, GCC8:
+// PYBIND11_NOINLINE_FORCED is incompatible with `-Wattributes -Werror`.
+// When defining PYBIND11_NOINLINE_FORCED, it is best to also use `-Wno-attributes`.
+// However, the measured shared-library size saving when using noinline are only
+// 1.7% for CUDA, -0.2% for GCC7, and 0.0% for GCC8 (using -DCMAKE_BUILD_TYPE=MinSizeRel,
+// the default under pybind11/tests).
+#if !defined(PYBIND11_NOINLINE_FORCED)                                                            \
+    && (defined(__CUDACC__) || (defined(__GNUC__) && (__GNUC__ == 7 || __GNUC__ == 8)))
+#    define PYBIND11_NOINLINE_DISABLED
+#endif
+
+// The PYBIND11_NOINLINE macro is for function DEFINITIONS.
+// In contrast, FORWARD DECLARATIONS should never use this macro:
+// https://stackoverflow.com/questions/9317473/forward-declaration-of-inline-functions
+#if defined(PYBIND11_NOINLINE_DISABLED) // Option for maximum portability and experimentation.
+#    define PYBIND11_NOINLINE inline
+#elif defined(_MSC_VER)
+#    define PYBIND11_NOINLINE __declspec(noinline) inline
 #else
-#  define PYBIND11_NOINLINE __attribute__ ((noinline))
+#    define PYBIND11_NOINLINE __attribute__((noinline)) inline
 #endif
 
-#if defined(PYBIND11_CPP14)
-#  define PYBIND11_DEPRECATED(reason) [[deprecated(reason)]]
+#if defined(__MINGW32__)
+// For unknown reasons all PYBIND11_DEPRECATED member trigger a warning when declared
+// whether it is used or not
+#    define PYBIND11_DEPRECATED(reason)
+#elif defined(PYBIND11_CPP14)
+#    define PYBIND11_DEPRECATED(reason) [[deprecated(reason)]]
 #else
-#  define PYBIND11_DEPRECATED(reason) __attribute__((deprecated(reason)))
+#    define PYBIND11_DEPRECATED(reason) __attribute__((deprecated(reason)))
 #endif
 
-#define PYBIND11_VERSION_MAJOR 2
-#define PYBIND11_VERSION_MINOR 3
-#define PYBIND11_VERSION_PATCH dev1
+#if defined(PYBIND11_CPP17)
+#    define PYBIND11_MAYBE_UNUSED [[maybe_unused]]
+#elif defined(_MSC_VER) && !defined(__clang__)
+#    define PYBIND11_MAYBE_UNUSED
+#else
+#    define PYBIND11_MAYBE_UNUSED __attribute__((__unused__))
+#endif
+
+/* Don't let Python.h #define (v)snprintf as macro because they are implemented
+   properly in Visual Studio since 2015. */
+#if defined(_MSC_VER)
+#    define HAVE_SNPRINTF 1
+#endif
 
 /// Include Python header, disable linking to pythonX_d.lib on Windows in debug mode
 #if defined(_MSC_VER)
-#  if (PY_MAJOR_VERSION == 3 && PY_MINOR_VERSION < 4)
-#    define HAVE_ROUND 1
-#  endif
-#  pragma warning(push)
-#  pragma warning(disable: 4510 4610 4512 4005)
-#  if defined(_DEBUG)
-#    define PYBIND11_DEBUG_MARKER
-#    undef _DEBUG
-#  endif
+PYBIND11_WARNING_PUSH
+PYBIND11_WARNING_DISABLE_MSVC(4505)
+// C4505: 'PySlice_GetIndicesEx': unreferenced local function has been removed (PyPy only)
+#    if defined(_DEBUG) && !defined(Py_DEBUG)
+// Workaround for a VS 2022 issue.
+// NOTE: This workaround knowingly violates the Python.h include order requirement:
+// https://docs.python.org/3/c-api/intro.html#include-files
+// See https://github.com/pybind/pybind11/pull/3497 for full context.
+#        include <yvals.h>
+#        if _MSVC_STL_VERSION >= 143
+#            include <crtdefs.h>
+#        endif
+#        define PYBIND11_DEBUG_MARKER
+#        undef _DEBUG
+#    endif
+#endif
+
+// https://en.cppreference.com/w/c/chrono/localtime
+#if defined(__STDC_LIB_EXT1__) && !defined(__STDC_WANT_LIB_EXT1__)
+#    define __STDC_WANT_LIB_EXT1__
+#endif
+
+#ifdef __has_include
+// std::optional (but including it in c++14 mode isn't allowed)
+#    if defined(PYBIND11_CPP17) && __has_include(<optional>)
+#        define PYBIND11_HAS_OPTIONAL 1
+#    endif
+// std::experimental::optional (but not allowed in c++11 mode)
+#    if defined(PYBIND11_CPP14) && (__has_include(<experimental/optional>) && \
+                                 !__has_include(<optional>))
+#        define PYBIND11_HAS_EXP_OPTIONAL 1
+#    endif
+// std::variant
+#    if defined(PYBIND11_CPP17) && __has_include(<variant>)
+#        define PYBIND11_HAS_VARIANT 1
+#    endif
+#elif defined(_MSC_VER) && defined(PYBIND11_CPP17)
+#    define PYBIND11_HAS_OPTIONAL 1
+#    define PYBIND11_HAS_VARIANT 1
+#endif
+
+#if defined(PYBIND11_CPP17)
+#    if defined(__has_include)
+#        if __has_include(<string_view>)
+#            define PYBIND11_HAS_STRING_VIEW
+#        endif
+#    elif defined(_MSC_VER)
+#        define PYBIND11_HAS_STRING_VIEW
+#    endif
 #endif
 
 #include <Python.h>
+// Reminder: WITH_THREAD is always defined if PY_VERSION_HEX >= 0x03070000
+#if PY_VERSION_HEX < 0x03060000
+#    error "PYTHON < 3.6 IS UNSUPPORTED. pybind11 v2.9 was the last to support Python 2 and 3.5."
+#endif
 #include <frameobject.h>
 #include <pythread.h>
 
-#if defined(_WIN32) && (defined(min) || defined(max))
-#  error Macro clash with min and max -- define NOMINMAX when compiling your program on Windows
+/* Python #defines overrides on all sorts of core functions, which
+   tends to weak havok in C++ codebases that expect these to work
+   like regular functions (potentially with several overloads) */
+#if defined(isalnum)
+#    undef isalnum
+#    undef isalpha
+#    undef islower
+#    undef isspace
+#    undef isupper
+#    undef tolower
+#    undef toupper
 #endif
 
-#if defined(isalnum)
-#  undef isalnum
-#  undef isalpha
-#  undef islower
-#  undef isspace
-#  undef isupper
-#  undef tolower
-#  undef toupper
+#if defined(copysign)
+#    undef copysign
+#endif
+
+#if defined(PYPY_VERSION) && !defined(PYBIND11_SIMPLE_GIL_MANAGEMENT)
+#    define PYBIND11_SIMPLE_GIL_MANAGEMENT
 #endif
 
 #if defined(_MSC_VER)
-#  if defined(PYBIND11_DEBUG_MARKER)
-#    define _DEBUG
-#    undef PYBIND11_DEBUG_MARKER
-#  endif
-#  pragma warning(pop)
+#    if defined(PYBIND11_DEBUG_MARKER)
+#        define _DEBUG
+#        undef PYBIND11_DEBUG_MARKER
+#    endif
+PYBIND11_WARNING_POP
 #endif
 
 #include <cstddef>
 #include <cstring>
+#include <exception>
 #include <forward_list>
-#include <vector>
-#include <string>
-#include <stdexcept>
-#include <unordered_set>
-#include <unordered_map>
 #include <memory>
-#include <typeindex>
+#include <stdexcept>
+#include <string>
 #include <type_traits>
+#include <typeindex>
+#include <unordered_map>
+#include <unordered_set>
+#include <vector>
+#if defined(__has_include)
+#    if __has_include(<version>)
+#        include <version>
+#    endif
+#endif
+
+// Must be after including <version> or one of the other headers specified by the standard
+#if defined(__cpp_lib_char8_t) && __cpp_lib_char8_t >= 201811L
+#    define PYBIND11_HAS_U8STRING
+#endif
+
+// See description of PR #4246:
+#if !defined(NDEBUG) && !defined(PY_ASSERT_GIL_HELD_INCREF_DECREF)                                \
+    && !(defined(PYPY_VERSION)                                                                    \
+         && defined(_MSC_VER)) /* PyPy Windows: pytest hangs indefinitely at the end of the       \
+                                  process (see PR #4268) */                                       \
+    && !defined(PYBIND11_ASSERT_GIL_HELD_INCREF_DECREF)
+// The following define will be enabled by default in the 2.11 release
+// define PYBIND11_ASSERT_GIL_HELD_INCREF_DECREF
+#endif
+
+// #define PYBIND11_STR_LEGACY_PERMISSIVE
+// If DEFINED, pybind11::str can hold PyUnicodeObject or PyBytesObject
+//             (probably surprising and never documented, but this was the
+//             legacy behavior until and including v2.6.x). As a side-effect,
+//             pybind11::isinstance<str>() is true for both pybind11::str and
+//             pybind11::bytes.
+// If UNDEFINED, pybind11::str can only hold PyUnicodeObject, and
+//               pybind11::isinstance<str>() is true only for pybind11::str.
+//               However, for Python 2 only (!), the pybind11::str caster
+//               implicitly decoded bytes to PyUnicodeObject. This was to ease
+//               the transition from the legacy behavior to the non-permissive
+//               behavior.
 
-#if PY_MAJOR_VERSION >= 3 /// Compatibility macros for various Python versions
+/// Compatibility macros for Python 2 / Python 3 versions TODO: remove
 #define PYBIND11_INSTANCE_METHOD_NEW(ptr, class_) PyInstanceMethod_New(ptr)
 #define PYBIND11_INSTANCE_METHOD_CHECK PyInstanceMethod_Check
 #define PYBIND11_INSTANCE_METHOD_GET_FUNCTION PyInstanceMethod_GET_FUNCTION
 #define PYBIND11_BYTES_CHECK PyBytes_Check
 #define PYBIND11_BYTES_FROM_STRING PyBytes_FromString
 #define PYBIND11_BYTES_FROM_STRING_AND_SIZE PyBytes_FromStringAndSize
 #define PYBIND11_BYTES_AS_STRING_AND_SIZE PyBytes_AsStringAndSize
 #define PYBIND11_BYTES_AS_STRING PyBytes_AsString
 #define PYBIND11_BYTES_SIZE PyBytes_Size
 #define PYBIND11_LONG_CHECK(o) PyLong_Check(o)
 #define PYBIND11_LONG_AS_LONGLONG(o) PyLong_AsLongLong(o)
-#define PYBIND11_LONG_FROM_SIGNED(o) PyLong_FromSsize_t((ssize_t) o)
-#define PYBIND11_LONG_FROM_UNSIGNED(o) PyLong_FromSize_t((size_t) o)
+#define PYBIND11_LONG_FROM_SIGNED(o) PyLong_FromSsize_t((ssize_t) (o))
+#define PYBIND11_LONG_FROM_UNSIGNED(o) PyLong_FromSize_t((size_t) (o))
 #define PYBIND11_BYTES_NAME "bytes"
 #define PYBIND11_STRING_NAME "str"
 #define PYBIND11_SLICE_OBJECT PyObject
 #define PYBIND11_FROM_STRING PyUnicode_FromString
 #define PYBIND11_STR_TYPE ::pybind11::str
 #define PYBIND11_BOOL_ATTR "__bool__"
 #define PYBIND11_NB_BOOL(ptr) ((ptr)->nb_bool)
-#define PYBIND11_PLUGIN_IMPL(name) \
+#define PYBIND11_BUILTINS_MODULE "builtins"
+// Providing a separate declaration to make Clang's -Wmissing-prototypes happy.
+// See comment for PYBIND11_MODULE below for why this is marked "maybe unused".
+#define PYBIND11_PLUGIN_IMPL(name)                                                                \
+    extern "C" PYBIND11_MAYBE_UNUSED PYBIND11_EXPORT PyObject *PyInit_##name();                   \
     extern "C" PYBIND11_EXPORT PyObject *PyInit_##name()
 
-#else
-#define PYBIND11_INSTANCE_METHOD_NEW(ptr, class_) PyMethod_New(ptr, nullptr, class_)
-#define PYBIND11_INSTANCE_METHOD_CHECK PyMethod_Check
-#define PYBIND11_INSTANCE_METHOD_GET_FUNCTION PyMethod_GET_FUNCTION
-#define PYBIND11_BYTES_CHECK PyString_Check
-#define PYBIND11_BYTES_FROM_STRING PyString_FromString
-#define PYBIND11_BYTES_FROM_STRING_AND_SIZE PyString_FromStringAndSize
-#define PYBIND11_BYTES_AS_STRING_AND_SIZE PyString_AsStringAndSize
-#define PYBIND11_BYTES_AS_STRING PyString_AsString
-#define PYBIND11_BYTES_SIZE PyString_Size
-#define PYBIND11_LONG_CHECK(o) (PyInt_Check(o) || PyLong_Check(o))
-#define PYBIND11_LONG_AS_LONGLONG(o) (PyInt_Check(o) ? (long long) PyLong_AsLong(o) : PyLong_AsLongLong(o))
-#define PYBIND11_LONG_FROM_SIGNED(o) PyInt_FromSsize_t((ssize_t) o) // Returns long if needed.
-#define PYBIND11_LONG_FROM_UNSIGNED(o) PyInt_FromSize_t((size_t) o) // Returns long if needed.
-#define PYBIND11_BYTES_NAME "str"
-#define PYBIND11_STRING_NAME "unicode"
-#define PYBIND11_SLICE_OBJECT PySliceObject
-#define PYBIND11_FROM_STRING PyString_FromString
-#define PYBIND11_STR_TYPE ::pybind11::bytes
-#define PYBIND11_BOOL_ATTR "__nonzero__"
-#define PYBIND11_NB_BOOL(ptr) ((ptr)->nb_nonzero)
-#define PYBIND11_PLUGIN_IMPL(name) \
-    static PyObject *pybind11_init_wrapper();               \
-    extern "C" PYBIND11_EXPORT void init##name() {          \
-        (void)pybind11_init_wrapper();                      \
-    }                                                       \
-    PyObject *pybind11_init_wrapper()
-#endif
-
-#if PY_VERSION_HEX >= 0x03050000 && PY_VERSION_HEX < 0x03050200
-extern "C" {
-    struct _Py_atomic_address { void *value; };
-    PyAPI_DATA(_Py_atomic_address) _PyThreadState_Current;
-}
-#endif
-
 #define PYBIND11_TRY_NEXT_OVERLOAD ((PyObject *) 1) // special failure return code
 #define PYBIND11_STRINGIFY(x) #x
 #define PYBIND11_TOSTRING(x) PYBIND11_STRINGIFY(x)
 #define PYBIND11_CONCAT(first, second) first##second
+#define PYBIND11_ENSURE_INTERNALS_READY pybind11::detail::get_internals();
 
-#define PYBIND11_CHECK_PYTHON_VERSION \
-    {                                                                          \
-        const char *compiled_ver = PYBIND11_TOSTRING(PY_MAJOR_VERSION)         \
-            "." PYBIND11_TOSTRING(PY_MINOR_VERSION);                           \
-        const char *runtime_ver = Py_GetVersion();                             \
-        size_t len = std::strlen(compiled_ver);                                \
-        if (std::strncmp(runtime_ver, compiled_ver, len) != 0                  \
-                || (runtime_ver[len] >= '0' && runtime_ver[len] <= '9')) {     \
-            PyErr_Format(PyExc_ImportError,                                    \
-                "Python version mismatch: module was compiled for Python %s, " \
-                "but the interpreter version is incompatible: %s.",            \
-                compiled_ver, runtime_ver);                                    \
-            return nullptr;                                                    \
-        }                                                                      \
+#define PYBIND11_CHECK_PYTHON_VERSION                                                             \
+    {                                                                                             \
+        const char *compiled_ver                                                                  \
+            = PYBIND11_TOSTRING(PY_MAJOR_VERSION) "." PYBIND11_TOSTRING(PY_MINOR_VERSION);        \
+        const char *runtime_ver = Py_GetVersion();                                                \
+        size_t len = std::strlen(compiled_ver);                                                   \
+        if (std::strncmp(runtime_ver, compiled_ver, len) != 0                                     \
+            || (runtime_ver[len] >= '0' && runtime_ver[len] <= '9')) {                            \
+            PyErr_Format(PyExc_ImportError,                                                       \
+                         "Python version mismatch: module was compiled for Python %s, "           \
+                         "but the interpreter version is incompatible: %s.",                      \
+                         compiled_ver,                                                            \
+                         runtime_ver);                                                            \
+            return nullptr;                                                                       \
+        }                                                                                         \
     }
 
-#define PYBIND11_CATCH_INIT_EXCEPTIONS \
-        catch (pybind11::error_already_set &e) {                               \
-            PyErr_SetString(PyExc_ImportError, e.what());                      \
-            return nullptr;                                                    \
-        } catch (const std::exception &e) {                                    \
-            PyErr_SetString(PyExc_ImportError, e.what());                      \
-            return nullptr;                                                    \
-        }                                                                      \
+#define PYBIND11_CATCH_INIT_EXCEPTIONS                                                            \
+    catch (pybind11::error_already_set & e) {                                                     \
+        pybind11::raise_from(e, PyExc_ImportError, "initialization failed");                      \
+        return nullptr;                                                                           \
+    }                                                                                             \
+    catch (const std::exception &e) {                                                             \
+        PyErr_SetString(PyExc_ImportError, e.what());                                             \
+        return nullptr;                                                                           \
+    }
 
 /** \rst
     ***Deprecated in favor of PYBIND11_MODULE***
 
     This macro creates the entry point that will be invoked when the Python interpreter
-    imports a plugin library. Please create a `module` in the function body and return
+    imports a plugin library. Please create a `module_` in the function body and return
     the pointer to its underlying Python object at the end.
 
     .. code-block:: cpp
 
         PYBIND11_PLUGIN(example) {
-            pybind11::module m("example", "pybind11 example plugin");
+            pybind11::module_ m("example", "pybind11 example plugin");
             /// Set up bindings here
             return m.ptr();
         }
 \endrst */
-#define PYBIND11_PLUGIN(name)                                                  \
-    PYBIND11_DEPRECATED("PYBIND11_PLUGIN is deprecated, use PYBIND11_MODULE")  \
-    static PyObject *pybind11_init();                                          \
-    PYBIND11_PLUGIN_IMPL(name) {                                               \
-        PYBIND11_CHECK_PYTHON_VERSION                                          \
-        try {                                                                  \
-            return pybind11_init();                                            \
-        } PYBIND11_CATCH_INIT_EXCEPTIONS                                       \
-    }                                                                          \
+#define PYBIND11_PLUGIN(name)                                                                     \
+    PYBIND11_DEPRECATED("PYBIND11_PLUGIN is deprecated, use PYBIND11_MODULE")                     \
+    static PyObject *pybind11_init();                                                             \
+    PYBIND11_PLUGIN_IMPL(name) {                                                                  \
+        PYBIND11_CHECK_PYTHON_VERSION                                                             \
+        PYBIND11_ENSURE_INTERNALS_READY                                                           \
+        try {                                                                                     \
+            return pybind11_init();                                                               \
+        }                                                                                         \
+        PYBIND11_CATCH_INIT_EXCEPTIONS                                                            \
+    }                                                                                             \
     PyObject *pybind11_init()
 
 /** \rst
     This macro creates the entry point that will be invoked when the Python interpreter
-    imports an extension module. The module name is given as the fist argument and it
+    imports an extension module. The module name is given as the first argument and it
     should not be in quotes. The second macro argument defines a variable of type
-    `py::module` which can be used to initialize the module.
+    `py::module_` which can be used to initialize the module.
+
+    The entry point is marked as "maybe unused" to aid dead-code detection analysis:
+    since the entry point is typically only looked up at runtime and not referenced
+    during translation, it would otherwise appear as unused ("dead") code.
 
     .. code-block:: cpp
 
         PYBIND11_MODULE(example, m) {
             m.doc() = "pybind11 example module";
 
             // Add bindings here
             m.def("foo", []() {
                 return "Hello, World!";
             });
         }
 \endrst */
-#define PYBIND11_MODULE(name, variable)                                        \
-    static void PYBIND11_CONCAT(pybind11_init_, name)(pybind11::module &);     \
-    PYBIND11_PLUGIN_IMPL(name) {                                               \
-        PYBIND11_CHECK_PYTHON_VERSION                                          \
-        auto m = pybind11::module(PYBIND11_TOSTRING(name));                    \
-        try {                                                                  \
-            PYBIND11_CONCAT(pybind11_init_, name)(m);                          \
-            return m.ptr();                                                    \
-        } PYBIND11_CATCH_INIT_EXCEPTIONS                                       \
-    }                                                                          \
-    void PYBIND11_CONCAT(pybind11_init_, name)(pybind11::module &variable)
-
+#define PYBIND11_MODULE(name, variable)                                                           \
+    static ::pybind11::module_::module_def PYBIND11_CONCAT(pybind11_module_def_, name)            \
+        PYBIND11_MAYBE_UNUSED;                                                                    \
+    PYBIND11_MAYBE_UNUSED                                                                         \
+    static void PYBIND11_CONCAT(pybind11_init_, name)(::pybind11::module_ &);                     \
+    PYBIND11_PLUGIN_IMPL(name) {                                                                  \
+        PYBIND11_CHECK_PYTHON_VERSION                                                             \
+        PYBIND11_ENSURE_INTERNALS_READY                                                           \
+        auto m = ::pybind11::module_::create_extension_module(                                    \
+            PYBIND11_TOSTRING(name), nullptr, &PYBIND11_CONCAT(pybind11_module_def_, name));      \
+        try {                                                                                     \
+            PYBIND11_CONCAT(pybind11_init_, name)(m);                                             \
+            return m.ptr();                                                                       \
+        }                                                                                         \
+        PYBIND11_CATCH_INIT_EXCEPTIONS                                                            \
+    }                                                                                             \
+    void PYBIND11_CONCAT(pybind11_init_, name)(::pybind11::module_ & (variable))
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
 
 using ssize_t = Py_ssize_t;
-using size_t  = std::size_t;
+using size_t = std::size_t;
+
+template <typename IntType>
+inline ssize_t ssize_t_cast(const IntType &val) {
+    static_assert(sizeof(IntType) <= sizeof(ssize_t), "Implicit narrowing is not permitted.");
+    return static_cast<ssize_t>(val);
+}
 
 /// Approach used to cast a previously unknown C++ instance into a Python object
 enum class return_value_policy : uint8_t {
     /** This is the default return value policy, which falls back to the policy
         return_value_policy::take_ownership when the return value is a pointer.
         Otherwise, it uses return_value::move or return_value::copy for rvalue
         and lvalue references, respectively. See below for a description of what
@@ -311,15 +498,15 @@
         value is a pointer. This is the default conversion policy for function
         arguments when calling Python functions manually from C++ code (i.e. via
         handle::operator()). You probably won't need to use this. */
     automatic_reference,
 
     /** Reference an existing object (i.e. do not create a new copy) and take
         ownership. Python will call the destructor and delete operator when the
-        object’s reference count reaches zero. Undefined behavior ensues when
+        object's reference count reaches zero. Undefined behavior ensues when
         the C++ side does the same.. */
     take_ownership,
 
     /** Create a new copy of the returned object, which will be owned by
         Python. This policy is comparably safe because the lifetimes of the two
         instances are decoupled. */
     copy,
@@ -327,49 +514,53 @@
     /** Use std::move to move the return value contents into a new instance
         that will be owned by Python. This policy is comparably safe because the
         lifetimes of the two instances (move source and destination) are
         decoupled. */
     move,
 
     /** Reference an existing object, but do not take ownership. The C++ side
-        is responsible for managing the object’s lifetime and deallocating it
+        is responsible for managing the object's lifetime and deallocating it
         when it is no longer used. Warning: undefined behavior will ensue when
         the C++ side deletes an object that is still referenced and used by
         Python. */
     reference,
 
     /** This policy only applies to methods and properties. It references the
         object without taking ownership similar to the above
         return_value_policy::reference policy. In contrast to that policy, the
-        function or property’s implicit this argument (called the parent) is
+        function or property's implicit this argument (called the parent) is
         considered to be the the owner of the return value (the child).
         pybind11 then couples the lifetime of the parent to the child via a
         reference relationship that ensures that the parent cannot be garbage
         collected while Python is still using the child. More advanced
         variations of this scheme are also possible using combinations of
         return_value_policy::reference and the keep_alive call policy */
     reference_internal
 };
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
-inline static constexpr int log2(size_t n, int k = 0) { return (n <= 1) ? k : log2(n >> 1, k + 1); }
+inline static constexpr int log2(size_t n, int k = 0) {
+    return (n <= 1) ? k : log2(n >> 1, k + 1);
+}
 
 // Returns the size as a multiple of sizeof(void *), rounded up.
-inline static constexpr size_t size_in_ptrs(size_t s) { return 1 + ((s - 1) >> log2(sizeof(void *))); }
+inline static constexpr size_t size_in_ptrs(size_t s) {
+    return 1 + ((s - 1) >> log2(sizeof(void *)));
+}
 
 /**
  * The space to allocate for simple layout instance holders (see below) in multiple of the size of
  * a pointer (e.g.  2 means 16 bytes on 64-bit architectures).  The default is the minimum required
  * to holder either a std::unique_ptr or std::shared_ptr (which is almost always
  * sizeof(std::shared_ptr<T>)).
  */
 constexpr size_t instance_simple_holder_in_ptrs() {
     static_assert(sizeof(std::shared_ptr<int>) >= sizeof(std::unique_ptr<int>),
-            "pybind assumes std::shared_ptrs are at least as big as std::unique_ptrs");
+                  "pybind assumes std::shared_ptrs are at least as big as std::unique_ptrs");
     return size_in_ptrs(sizeof(std::shared_ptr<int>));
 }
 
 // Forward declarations
 struct type_info;
 struct value_and_holder;
 
@@ -389,419 +580,657 @@
     /// Weak references
     PyObject *weakrefs;
     /// If true, the pointer is owned which means we're free to manage it with a holder.
     bool owned : 1;
     /**
      * An instance has two possible value/holder layouts.
      *
-     * Simple layout (when this flag is true), means the `simple_value_holder` is set with a pointer
-     * and the holder object governing that pointer, i.e. [val1*][holder].  This layout is applied
-     * whenever there is no python-side multiple inheritance of bound C++ types *and* the type's
-     * holder will fit in the default space (which is large enough to hold either a std::unique_ptr
-     * or std::shared_ptr).
+     * Simple layout (when this flag is true), means the `simple_value_holder` is set with a
+     * pointer and the holder object governing that pointer, i.e. [val1*][holder].  This layout is
+     * applied whenever there is no python-side multiple inheritance of bound C++ types *and* the
+     * type's holder will fit in the default space (which is large enough to hold either a
+     * std::unique_ptr or std::shared_ptr).
      *
-     * Non-simple layout applies when using custom holders that require more space than `shared_ptr`
-     * (which is typically the size of two pointers), or when multiple inheritance is used on the
-     * python side.  Non-simple layout allocates the required amount of memory to have multiple
-     * bound C++ classes as parents.  Under this layout, `nonsimple.values_and_holders` is set to a
-     * pointer to allocated space of the required space to hold a sequence of value pointers and
-     * holders followed `status`, a set of bit flags (1 byte each), i.e.
-     * [val1*][holder1][val2*][holder2]...[bb...]  where each [block] is rounded up to a multiple of
-     * `sizeof(void *)`.  `nonsimple.status` is, for convenience, a pointer to the
-     * beginning of the [bb...] block (but not independently allocated).
+     * Non-simple layout applies when using custom holders that require more space than
+     * `shared_ptr` (which is typically the size of two pointers), or when multiple inheritance is
+     * used on the python side.  Non-simple layout allocates the required amount of memory to have
+     * multiple bound C++ classes as parents.  Under this layout, `nonsimple.values_and_holders` is
+     * set to a pointer to allocated space of the required space to hold a sequence of value
+     * pointers and holders followed `status`, a set of bit flags (1 byte each), i.e.
+     * [val1*][holder1][val2*][holder2]...[bb...]  where each [block] is rounded up to a multiple
+     * of `sizeof(void *)`.  `nonsimple.status` is, for convenience, a pointer to the beginning of
+     * the [bb...] block (but not independently allocated).
      *
      * Status bits indicate whether the associated holder is constructed (&
      * status_holder_constructed) and whether the value pointer is registered (&
      * status_instance_registered) in `registered_instances`.
      */
     bool simple_layout : 1;
     /// For simple layout, tracks whether the holder has been constructed
     bool simple_holder_constructed : 1;
     /// For simple layout, tracks whether the instance is registered in `registered_instances`
     bool simple_instance_registered : 1;
     /// If true, get_internals().patients has an entry for this object
     bool has_patients : 1;
 
-    /// Initializes all of the above type/values/holders data (but not the instance values themselves)
+    /// Initializes all of the above type/values/holders data (but not the instance values
+    /// themselves)
     void allocate_layout();
 
     /// Destroys/deallocates all of the above
     void deallocate_layout();
 
     /// Returns the value_and_holder wrapper for the given type (or the first, if `find_type`
     /// omitted).  Returns a default-constructed (with `.inst = nullptr`) object on failure if
     /// `throw_if_missing` is false.
-    value_and_holder get_value_and_holder(const type_info *find_type = nullptr, bool throw_if_missing = true);
+    value_and_holder get_value_and_holder(const type_info *find_type = nullptr,
+                                          bool throw_if_missing = true);
 
     /// Bit values for the non-simple status flags
-    static constexpr uint8_t status_holder_constructed  = 1;
+    static constexpr uint8_t status_holder_constructed = 1;
     static constexpr uint8_t status_instance_registered = 2;
 };
 
-static_assert(std::is_standard_layout<instance>::value, "Internal error: `pybind11::detail::instance` is not standard layout!");
+static_assert(std::is_standard_layout<instance>::value,
+              "Internal error: `pybind11::detail::instance` is not standard layout!");
 
 /// from __cpp_future__ import (convenient aliases from C++14/17)
-#if defined(PYBIND11_CPP14) && (!defined(_MSC_VER) || _MSC_VER >= 1910)
-using std::enable_if_t;
+#if defined(PYBIND11_CPP14)
 using std::conditional_t;
+using std::enable_if_t;
 using std::remove_cv_t;
 using std::remove_reference_t;
 #else
-template <bool B, typename T = void> using enable_if_t = typename std::enable_if<B, T>::type;
-template <bool B, typename T, typename F> using conditional_t = typename std::conditional<B, T, F>::type;
-template <typename T> using remove_cv_t = typename std::remove_cv<T>::type;
-template <typename T> using remove_reference_t = typename std::remove_reference<T>::type;
+template <bool B, typename T = void>
+using enable_if_t = typename std::enable_if<B, T>::type;
+template <bool B, typename T, typename F>
+using conditional_t = typename std::conditional<B, T, F>::type;
+template <typename T>
+using remove_cv_t = typename std::remove_cv<T>::type;
+template <typename T>
+using remove_reference_t = typename std::remove_reference<T>::type;
+#endif
+
+#if defined(PYBIND11_CPP20)
+using std::remove_cvref;
+using std::remove_cvref_t;
+#else
+template <class T>
+struct remove_cvref {
+    using type = remove_cv_t<remove_reference_t<T>>;
+};
+template <class T>
+using remove_cvref_t = typename remove_cvref<T>::type;
 #endif
 
 /// Index sequences
 #if defined(PYBIND11_CPP14)
 using std::index_sequence;
 using std::make_index_sequence;
 #else
-template<size_t ...> struct index_sequence  { };
-template<size_t N, size_t ...S> struct make_index_sequence_impl : make_index_sequence_impl <N - 1, N - 1, S...> { };
-template<size_t ...S> struct make_index_sequence_impl <0, S...> { typedef index_sequence<S...> type; };
-template<size_t N> using make_index_sequence = typename make_index_sequence_impl<N>::type;
+template <size_t...>
+struct index_sequence {};
+template <size_t N, size_t... S>
+struct make_index_sequence_impl : make_index_sequence_impl<N - 1, N - 1, S...> {};
+template <size_t... S>
+struct make_index_sequence_impl<0, S...> {
+    using type = index_sequence<S...>;
+};
+template <size_t N>
+using make_index_sequence = typename make_index_sequence_impl<N>::type;
 #endif
 
 /// Make an index sequence of the indices of true arguments
-template <typename ISeq, size_t, bool...> struct select_indices_impl { using type = ISeq; };
-template <size_t... IPrev, size_t I, bool B, bool... Bs> struct select_indices_impl<index_sequence<IPrev...>, I, B, Bs...>
-    : select_indices_impl<conditional_t<B, index_sequence<IPrev..., I>, index_sequence<IPrev...>>, I + 1, Bs...> {};
-template <bool... Bs> using select_indices = typename select_indices_impl<index_sequence<>, 0, Bs...>::type;
+template <typename ISeq, size_t, bool...>
+struct select_indices_impl {
+    using type = ISeq;
+};
+template <size_t... IPrev, size_t I, bool B, bool... Bs>
+struct select_indices_impl<index_sequence<IPrev...>, I, B, Bs...>
+    : select_indices_impl<conditional_t<B, index_sequence<IPrev..., I>, index_sequence<IPrev...>>,
+                          I + 1,
+                          Bs...> {};
+template <bool... Bs>
+using select_indices = typename select_indices_impl<index_sequence<>, 0, Bs...>::type;
 
 /// Backports of std::bool_constant and std::negation to accommodate older compilers
-template <bool B> using bool_constant = std::integral_constant<bool, B>;
-template <typename T> struct negation : bool_constant<!T::value> { };
+template <bool B>
+using bool_constant = std::integral_constant<bool, B>;
+template <typename T>
+struct negation : bool_constant<!T::value> {};
 
-template <typename...> struct void_t_impl { using type = void; };
-template <typename... Ts> using void_t = typename void_t_impl<Ts...>::type;
+// PGI/Intel cannot detect operator delete with the "compatible" void_t impl, so
+// using the new one (C++14 defect, so generally works on newer compilers, even
+// if not in C++17 mode)
+#if defined(__PGIC__) || defined(__INTEL_COMPILER)
+template <typename...>
+using void_t = void;
+#else
+template <typename...>
+struct void_t_impl {
+    using type = void;
+};
+template <typename... Ts>
+using void_t = typename void_t_impl<Ts...>::type;
+#endif
 
 /// Compile-time all/any/none of that check the boolean value of all template types
 #if defined(__cpp_fold_expressions) && !(defined(_MSC_VER) && (_MSC_VER < 1916))
-template <class... Ts> using all_of = bool_constant<(Ts::value && ...)>;
-template <class... Ts> using any_of = bool_constant<(Ts::value || ...)>;
+template <class... Ts>
+using all_of = bool_constant<(Ts::value && ...)>;
+template <class... Ts>
+using any_of = bool_constant<(Ts::value || ...)>;
 #elif !defined(_MSC_VER)
-template <bool...> struct bools {};
-template <class... Ts> using all_of = std::is_same<
-    bools<Ts::value..., true>,
-    bools<true, Ts::value...>>;
-template <class... Ts> using any_of = negation<all_of<negation<Ts>...>>;
+template <bool...>
+struct bools {};
+template <class... Ts>
+using all_of = std::is_same<bools<Ts::value..., true>, bools<true, Ts::value...>>;
+template <class... Ts>
+using any_of = negation<all_of<negation<Ts>...>>;
 #else
 // MSVC has trouble with the above, but supports std::conjunction, which we can use instead (albeit
 // at a slight loss of compilation efficiency).
-template <class... Ts> using all_of = std::conjunction<Ts...>;
-template <class... Ts> using any_of = std::disjunction<Ts...>;
-#endif
-template <class... Ts> using none_of = negation<any_of<Ts...>>;
-
-template <class T, template<class> class... Predicates> using satisfies_all_of = all_of<Predicates<T>...>;
-template <class T, template<class> class... Predicates> using satisfies_any_of = any_of<Predicates<T>...>;
-template <class T, template<class> class... Predicates> using satisfies_none_of = none_of<Predicates<T>...>;
+template <class... Ts>
+using all_of = std::conjunction<Ts...>;
+template <class... Ts>
+using any_of = std::disjunction<Ts...>;
+#endif
+template <class... Ts>
+using none_of = negation<any_of<Ts...>>;
+
+template <class T, template <class> class... Predicates>
+using satisfies_all_of = all_of<Predicates<T>...>;
+template <class T, template <class> class... Predicates>
+using satisfies_any_of = any_of<Predicates<T>...>;
+template <class T, template <class> class... Predicates>
+using satisfies_none_of = none_of<Predicates<T>...>;
 
 /// Strip the class from a method type
-template <typename T> struct remove_class { };
-template <typename C, typename R, typename... A> struct remove_class<R (C::*)(A...)> { typedef R type(A...); };
-template <typename C, typename R, typename... A> struct remove_class<R (C::*)(A...) const> { typedef R type(A...); };
+template <typename T>
+struct remove_class {};
+template <typename C, typename R, typename... A>
+struct remove_class<R (C::*)(A...)> {
+    using type = R(A...);
+};
+template <typename C, typename R, typename... A>
+struct remove_class<R (C::*)(A...) const> {
+    using type = R(A...);
+};
 
 /// Helper template to strip away type modifiers
-template <typename T> struct intrinsic_type                       { typedef T type; };
-template <typename T> struct intrinsic_type<const T>              { typedef typename intrinsic_type<T>::type type; };
-template <typename T> struct intrinsic_type<T*>                   { typedef typename intrinsic_type<T>::type type; };
-template <typename T> struct intrinsic_type<T&>                   { typedef typename intrinsic_type<T>::type type; };
-template <typename T> struct intrinsic_type<T&&>                  { typedef typename intrinsic_type<T>::type type; };
-template <typename T, size_t N> struct intrinsic_type<const T[N]> { typedef typename intrinsic_type<T>::type type; };
-template <typename T, size_t N> struct intrinsic_type<T[N]>       { typedef typename intrinsic_type<T>::type type; };
-template <typename T> using intrinsic_t = typename intrinsic_type<T>::type;
+template <typename T>
+struct intrinsic_type {
+    using type = T;
+};
+template <typename T>
+struct intrinsic_type<const T> {
+    using type = typename intrinsic_type<T>::type;
+};
+template <typename T>
+struct intrinsic_type<T *> {
+    using type = typename intrinsic_type<T>::type;
+};
+template <typename T>
+struct intrinsic_type<T &> {
+    using type = typename intrinsic_type<T>::type;
+};
+template <typename T>
+struct intrinsic_type<T &&> {
+    using type = typename intrinsic_type<T>::type;
+};
+template <typename T, size_t N>
+struct intrinsic_type<const T[N]> {
+    using type = typename intrinsic_type<T>::type;
+};
+template <typename T, size_t N>
+struct intrinsic_type<T[N]> {
+    using type = typename intrinsic_type<T>::type;
+};
+template <typename T>
+using intrinsic_t = typename intrinsic_type<T>::type;
 
 /// Helper type to replace 'void' in some expressions
-struct void_type { };
+struct void_type {};
 
 /// Helper template which holds a list of types
-template <typename...> struct type_list { };
+template <typename...>
+struct type_list {};
 
 /// Compile-time integer sum
 #ifdef __cpp_fold_expressions
-template <typename... Ts> constexpr size_t constexpr_sum(Ts... ns) { return (0 + ... + size_t{ns}); }
+template <typename... Ts>
+constexpr size_t constexpr_sum(Ts... ns) {
+    return (0 + ... + size_t{ns});
+}
 #else
 constexpr size_t constexpr_sum() { return 0; }
 template <typename T, typename... Ts>
-constexpr size_t constexpr_sum(T n, Ts... ns) { return size_t{n} + constexpr_sum(ns...); }
+constexpr size_t constexpr_sum(T n, Ts... ns) {
+    return size_t{n} + constexpr_sum(ns...);
+}
 #endif
 
-NAMESPACE_BEGIN(constexpr_impl)
+PYBIND11_NAMESPACE_BEGIN(constexpr_impl)
 /// Implementation details for constexpr functions
 constexpr int first(int i) { return i; }
 template <typename T, typename... Ts>
-constexpr int first(int i, T v, Ts... vs) { return v ? i : first(i + 1, vs...); }
+constexpr int first(int i, T v, Ts... vs) {
+    return v ? i : first(i + 1, vs...);
+}
 
 constexpr int last(int /*i*/, int result) { return result; }
 template <typename T, typename... Ts>
-constexpr int last(int i, int result, T v, Ts... vs) { return last(i + 1, v ? i : result, vs...); }
-NAMESPACE_END(constexpr_impl)
+constexpr int last(int i, int result, T v, Ts... vs) {
+    return last(i + 1, v ? i : result, vs...);
+}
+PYBIND11_NAMESPACE_END(constexpr_impl)
 
-/// Return the index of the first type in Ts which satisfies Predicate<T>.  Returns sizeof...(Ts) if
-/// none match.
-template <template<typename> class Predicate, typename... Ts>
-constexpr int constexpr_first() { return constexpr_impl::first(0, Predicate<Ts>::value...); }
+/// Return the index of the first type in Ts which satisfies Predicate<T>.
+/// Returns sizeof...(Ts) if none match.
+template <template <typename> class Predicate, typename... Ts>
+constexpr int constexpr_first() {
+    return constexpr_impl::first(0, Predicate<Ts>::value...);
+}
 
 /// Return the index of the last type in Ts which satisfies Predicate<T>, or -1 if none match.
-template <template<typename> class Predicate, typename... Ts>
-constexpr int constexpr_last() { return constexpr_impl::last(0, -1, Predicate<Ts>::value...); }
+template <template <typename> class Predicate, typename... Ts>
+constexpr int constexpr_last() {
+    return constexpr_impl::last(0, -1, Predicate<Ts>::value...);
+}
 
 /// Return the Nth element from the parameter pack
 template <size_t N, typename T, typename... Ts>
-struct pack_element { using type = typename pack_element<N - 1, Ts...>::type; };
+struct pack_element {
+    using type = typename pack_element<N - 1, Ts...>::type;
+};
 template <typename T, typename... Ts>
-struct pack_element<0, T, Ts...> { using type = T; };
+struct pack_element<0, T, Ts...> {
+    using type = T;
+};
 
 /// Return the one and only type which matches the predicate, or Default if none match.
 /// If more than one type matches the predicate, fail at compile-time.
-template <template<typename> class Predicate, typename Default, typename... Ts>
+template <template <typename> class Predicate, typename Default, typename... Ts>
 struct exactly_one {
     static constexpr auto found = constexpr_sum(Predicate<Ts>::value...);
     static_assert(found <= 1, "Found more than one type matching the predicate");
 
     static constexpr auto index = found ? constexpr_first<Predicate, Ts...>() : 0;
     using type = conditional_t<found, typename pack_element<index, Ts...>::type, Default>;
 };
-template <template<typename> class P, typename Default>
-struct exactly_one<P, Default> { using type = Default; };
+template <template <typename> class P, typename Default>
+struct exactly_one<P, Default> {
+    using type = Default;
+};
 
-template <template<typename> class Predicate, typename Default, typename... Ts>
+template <template <typename> class Predicate, typename Default, typename... Ts>
 using exactly_one_t = typename exactly_one<Predicate, Default, Ts...>::type;
 
 /// Defer the evaluation of type T until types Us are instantiated
-template <typename T, typename... /*Us*/> struct deferred_type { using type = T; };
-template <typename T, typename... Us> using deferred_t = typename deferred_type<T, Us...>::type;
+template <typename T, typename... /*Us*/>
+struct deferred_type {
+    using type = T;
+};
+template <typename T, typename... Us>
+using deferred_t = typename deferred_type<T, Us...>::type;
 
 /// Like is_base_of, but requires a strict base (i.e. `is_strict_base_of<T, T>::value == false`,
 /// unlike `std::is_base_of`)
-template <typename Base, typename Derived> using is_strict_base_of = bool_constant<
-    std::is_base_of<Base, Derived>::value && !std::is_same<Base, Derived>::value>;
-
-/// Like is_base_of, but also requires that the base type is accessible (i.e. that a Derived pointer
-/// can be converted to a Base pointer)
-template <typename Base, typename Derived> using is_accessible_base_of = bool_constant<
-    std::is_base_of<Base, Derived>::value && std::is_convertible<Derived *, Base *>::value>;
+template <typename Base, typename Derived>
+using is_strict_base_of
+    = bool_constant<std::is_base_of<Base, Derived>::value && !std::is_same<Base, Derived>::value>;
+
+/// Like is_base_of, but also requires that the base type is accessible (i.e. that a Derived
+/// pointer can be converted to a Base pointer) For unions, `is_base_of<T, T>::value` is False, so
+/// we need to check `is_same` as well.
+template <typename Base, typename Derived>
+using is_accessible_base_of
+    = bool_constant<(std::is_same<Base, Derived>::value || std::is_base_of<Base, Derived>::value)
+                    && std::is_convertible<Derived *, Base *>::value>;
 
-template <template<typename...> class Base>
+template <template <typename...> class Base>
 struct is_template_base_of_impl {
-    template <typename... Us> static std::true_type check(Base<Us...> *);
+    template <typename... Us>
+    static std::true_type check(Base<Us...> *);
     static std::false_type check(...);
 };
 
 /// Check if a template is the base of a type. For example:
 /// `is_template_base_of<Base, T>` is true if `struct T : Base<U> {}` where U can be anything
-template <template<typename...> class Base, typename T>
+template <template <typename...> class Base, typename T>
+// Sadly, all MSVC versions incl. 2022 need the workaround, even in C++20 mode.
+// See also: https://github.com/pybind/pybind11/pull/3741
 #if !defined(_MSC_VER)
-using is_template_base_of = decltype(is_template_base_of_impl<Base>::check((intrinsic_t<T>*)nullptr));
-#else // MSVC2015 has trouble with decltype in template aliases
-struct is_template_base_of : decltype(is_template_base_of_impl<Base>::check((intrinsic_t<T>*)nullptr)) { };
+using is_template_base_of
+    = decltype(is_template_base_of_impl<Base>::check((intrinsic_t<T> *) nullptr));
+#else
+struct is_template_base_of
+    : decltype(is_template_base_of_impl<Base>::check((intrinsic_t<T> *) nullptr)) {
+};
 #endif
 
 /// Check if T is an instantiation of the template `Class`. For example:
 /// `is_instantiation<shared_ptr, T>` is true if `T == shared_ptr<U>` where U can be anything.
-template <template<typename...> class Class, typename T>
-struct is_instantiation : std::false_type { };
-template <template<typename...> class Class, typename... Us>
-struct is_instantiation<Class, Class<Us...>> : std::true_type { };
+template <template <typename...> class Class, typename T>
+struct is_instantiation : std::false_type {};
+template <template <typename...> class Class, typename... Us>
+struct is_instantiation<Class, Class<Us...>> : std::true_type {};
 
 /// Check if T is std::shared_ptr<U> where U can be anything
-template <typename T> using is_shared_ptr = is_instantiation<std::shared_ptr, T>;
+template <typename T>
+using is_shared_ptr = is_instantiation<std::shared_ptr, T>;
 
 /// Check if T looks like an input iterator
-template <typename T, typename = void> struct is_input_iterator : std::false_type {};
+template <typename T, typename = void>
+struct is_input_iterator : std::false_type {};
 template <typename T>
-struct is_input_iterator<T, void_t<decltype(*std::declval<T &>()), decltype(++std::declval<T &>())>>
+struct is_input_iterator<T,
+                         void_t<decltype(*std::declval<T &>()), decltype(++std::declval<T &>())>>
     : std::true_type {};
 
-template <typename T> using is_function_pointer = bool_constant<
-    std::is_pointer<T>::value && std::is_function<typename std::remove_pointer<T>::type>::value>;
-
-template <typename F> struct strip_function_object {
+template <typename T>
+using is_function_pointer
+    = bool_constant<std::is_pointer<T>::value
+                    && std::is_function<typename std::remove_pointer<T>::type>::value>;
+
+template <typename F>
+struct strip_function_object {
+    // If you are encountering an
+    // 'error: name followed by "::" must be a class or namespace name'
+    // with the Intel compiler and a noexcept function here,
+    // try to use noexcept(true) instead of plain noexcept.
     using type = typename remove_class<decltype(&F::operator())>::type;
 };
 
 // Extracts the function signature from a function, function pointer or lambda.
 template <typename Function, typename F = remove_reference_t<Function>>
 using function_signature_t = conditional_t<
     std::is_function<F>::value,
     F,
-    typename conditional_t<
-        std::is_pointer<F>::value || std::is_member_pointer<F>::value,
-        std::remove_pointer<F>,
-        strip_function_object<F>
-    >::type
->;
+    typename conditional_t<std::is_pointer<F>::value || std::is_member_pointer<F>::value,
+                           std::remove_pointer<F>,
+                           strip_function_object<F>>::type>;
 
 /// Returns true if the type looks like a lambda: that is, isn't a function, pointer or member
 /// pointer.  Note that this can catch all sorts of other things, too; this is intended to be used
 /// in a place where passing a lambda makes sense.
-template <typename T> using is_lambda = satisfies_none_of<remove_reference_t<T>,
-        std::is_function, std::is_pointer, std::is_member_pointer>;
-
-/// Ignore that a variable is unused in compiler warnings
-inline void ignore_unused(const int *) { }
+template <typename T>
+using is_lambda = satisfies_none_of<remove_reference_t<T>,
+                                    std::is_function,
+                                    std::is_pointer,
+                                    std::is_member_pointer>;
 
+// [workaround(intel)] Internal error on fold expression
 /// Apply a function over each element of a parameter pack
-#ifdef __cpp_fold_expressions
-#define PYBIND11_EXPAND_SIDE_EFFECTS(PATTERN) (((PATTERN), void()), ...)
+#if defined(__cpp_fold_expressions) && !defined(__INTEL_COMPILER)
+// Intel compiler produces an internal error on this fold expression (tested with ICC 19.0.2)
+#    define PYBIND11_EXPAND_SIDE_EFFECTS(PATTERN) (((PATTERN), void()), ...)
 #else
 using expand_side_effects = bool[];
-#define PYBIND11_EXPAND_SIDE_EFFECTS(PATTERN) pybind11::detail::expand_side_effects{ ((PATTERN), void(), false)..., false }
+#    define PYBIND11_EXPAND_SIDE_EFFECTS(PATTERN)                                                 \
+        (void) pybind11::detail::expand_side_effects { ((PATTERN), void(), false)..., false }
 #endif
 
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
 
 /// C++ bindings of builtin Python exceptions
-class builtin_exception : public std::runtime_error {
+class PYBIND11_EXPORT_EXCEPTION builtin_exception : public std::runtime_error {
 public:
     using std::runtime_error::runtime_error;
     /// Set the error using the Python C API
     virtual void set_error() const = 0;
 };
 
-#define PYBIND11_RUNTIME_EXCEPTION(name, type) \
-    class name : public builtin_exception { public: \
-        using builtin_exception::builtin_exception; \
-        name() : name("") { } \
-        void set_error() const override { PyErr_SetString(type, what()); } \
+#define PYBIND11_RUNTIME_EXCEPTION(name, type)                                                    \
+    class PYBIND11_EXPORT_EXCEPTION name : public builtin_exception {                             \
+    public:                                                                                       \
+        using builtin_exception::builtin_exception;                                               \
+        name() : name("") {}                                                                      \
+        void set_error() const override { PyErr_SetString(type, what()); }                        \
     };
 
 PYBIND11_RUNTIME_EXCEPTION(stop_iteration, PyExc_StopIteration)
 PYBIND11_RUNTIME_EXCEPTION(index_error, PyExc_IndexError)
 PYBIND11_RUNTIME_EXCEPTION(key_error, PyExc_KeyError)
 PYBIND11_RUNTIME_EXCEPTION(value_error, PyExc_ValueError)
 PYBIND11_RUNTIME_EXCEPTION(type_error, PyExc_TypeError)
-PYBIND11_RUNTIME_EXCEPTION(cast_error, PyExc_RuntimeError) /// Thrown when pybind11::cast or handle::call fail due to a type casting error
+PYBIND11_RUNTIME_EXCEPTION(buffer_error, PyExc_BufferError)
+PYBIND11_RUNTIME_EXCEPTION(import_error, PyExc_ImportError)
+PYBIND11_RUNTIME_EXCEPTION(attribute_error, PyExc_AttributeError)
+PYBIND11_RUNTIME_EXCEPTION(cast_error, PyExc_RuntimeError) /// Thrown when pybind11::cast or
+                                                           /// handle::call fail due to a type
+                                                           /// casting error
 PYBIND11_RUNTIME_EXCEPTION(reference_cast_error, PyExc_RuntimeError) /// Used internally
 
-[[noreturn]] PYBIND11_NOINLINE inline void pybind11_fail(const char *reason) { throw std::runtime_error(reason); }
-[[noreturn]] PYBIND11_NOINLINE inline void pybind11_fail(const std::string &reason) { throw std::runtime_error(reason); }
+[[noreturn]] PYBIND11_NOINLINE void pybind11_fail(const char *reason) {
+    assert(!PyErr_Occurred());
+    throw std::runtime_error(reason);
+}
+[[noreturn]] PYBIND11_NOINLINE void pybind11_fail(const std::string &reason) {
+    assert(!PyErr_Occurred());
+    throw std::runtime_error(reason);
+}
 
-template <typename T, typename SFINAE = void> struct format_descriptor { };
+template <typename T, typename SFINAE = void>
+struct format_descriptor {};
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
 // Returns the index of the given type in the type char array below, and in the list in numpy.h
 // The order here is: bool; 8 ints ((signed,unsigned)x(8,16,32,64)bits); float,double,long double;
 // complex float,double,long double.  Note that the long double types only participate when long
 // double is actually longer than double (it isn't under MSVC).
 // NB: not only the string below but also complex.h and numpy.h rely on this order.
-template <typename T, typename SFINAE = void> struct is_fmt_numeric { static constexpr bool value = false; };
-template <typename T> struct is_fmt_numeric<T, enable_if_t<std::is_arithmetic<T>::value>> {
+template <typename T, typename SFINAE = void>
+struct is_fmt_numeric {
+    static constexpr bool value = false;
+};
+template <typename T>
+struct is_fmt_numeric<T, enable_if_t<std::is_arithmetic<T>::value>> {
     static constexpr bool value = true;
-    static constexpr int index = std::is_same<T, bool>::value ? 0 : 1 + (
-        std::is_integral<T>::value ? detail::log2(sizeof(T))*2 + std::is_unsigned<T>::value : 8 + (
-        std::is_same<T, double>::value ? 1 : std::is_same<T, long double>::value ? 2 : 0));
+    static constexpr int index
+        = std::is_same<T, bool>::value
+              ? 0
+              : 1
+                    + (std::is_integral<T>::value
+                           ? detail::log2(sizeof(T)) * 2 + std::is_unsigned<T>::value
+                           : 8
+                                 + (std::is_same<T, double>::value        ? 1
+                                    : std::is_same<T, long double>::value ? 2
+                                                                          : 0));
 };
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
 
-template <typename T> struct format_descriptor<T, detail::enable_if_t<std::is_arithmetic<T>::value>> {
+template <typename T>
+struct format_descriptor<T, detail::enable_if_t<std::is_arithmetic<T>::value>> {
     static constexpr const char c = "?bBhHiIqQfdg"[detail::is_fmt_numeric<T>::index];
-    static constexpr const char value[2] = { c, '\0' };
+    static constexpr const char value[2] = {c, '\0'};
     static std::string format() { return std::string(1, c); }
 };
 
 #if !defined(PYBIND11_CPP17)
 
-template <typename T> constexpr const char format_descriptor<
-    T, detail::enable_if_t<std::is_arithmetic<T>::value>>::value[2];
+template <typename T>
+constexpr const char
+    format_descriptor<T, detail::enable_if_t<std::is_arithmetic<T>::value>>::value[2];
 
 #endif
 
 /// RAII wrapper that temporarily clears any Python error state
 struct error_scope {
     PyObject *type, *value, *trace;
     error_scope() { PyErr_Fetch(&type, &value, &trace); }
+    error_scope(const error_scope &) = delete;
+    error_scope &operator=(const error_scope &) = delete;
     ~error_scope() { PyErr_Restore(type, value, trace); }
 };
 
 /// Dummy destructor wrapper that can be used to expose classes with a private destructor
-struct nodelete { template <typename T> void operator()(T*) { } };
-
-// overload_cast requires variable templates: C++14
-#if defined(PYBIND11_CPP14)
-#define PYBIND11_OVERLOAD_CAST 1
+struct nodelete {
+    template <typename T>
+    void operator()(T *) {}
+};
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
 template <typename... Args>
 struct overload_cast_impl {
-    constexpr overload_cast_impl() {} // MSVC 2015 needs this
-
     template <typename Return>
-    constexpr auto operator()(Return (*pf)(Args...)) const noexcept
-                              -> decltype(pf) { return pf; }
+    constexpr auto operator()(Return (*pf)(Args...)) const noexcept -> decltype(pf) {
+        return pf;
+    }
 
     template <typename Return, typename Class>
     constexpr auto operator()(Return (Class::*pmf)(Args...), std::false_type = {}) const noexcept
-                              -> decltype(pmf) { return pmf; }
+        -> decltype(pmf) {
+        return pmf;
+    }
 
     template <typename Return, typename Class>
     constexpr auto operator()(Return (Class::*pmf)(Args...) const, std::true_type) const noexcept
-                              -> decltype(pmf) { return pmf; }
+        -> decltype(pmf) {
+        return pmf;
+    }
 };
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
 
+// overload_cast requires variable templates: C++14
+#if defined(PYBIND11_CPP14)
+#    define PYBIND11_OVERLOAD_CAST 1
 /// Syntax sugar for resolving overloaded function pointers:
 ///  - regular: static_cast<Return (Class::*)(Arg0, Arg1, Arg2)>(&Class::func)
 ///  - sweet:   overload_cast<Arg0, Arg1, Arg2>(&Class::func)
 template <typename... Args>
-static constexpr detail::overload_cast_impl<Args...> overload_cast = {};
-// MSVC 2015 only accepts this particular initialization syntax for this variable template.
+static constexpr detail::overload_cast_impl<Args...> overload_cast{};
+#endif
 
 /// Const member function selector for overload_cast
 ///  - regular: static_cast<Return (Class::*)(Arg) const>(&Class::func)
 ///  - sweet:   overload_cast<Arg>(&Class::func, const_)
 static constexpr auto const_ = std::true_type{};
 
-#else // no overload_cast: providing something that static_assert-fails:
-template <typename... Args> struct overload_cast {
+#if !defined(PYBIND11_CPP14) // no overload_cast: providing something that static_assert-fails:
+template <typename... Args>
+struct overload_cast {
     static_assert(detail::deferred_t<std::false_type, Args...>::value,
                   "pybind11::overload_cast<...> requires compiling in C++14 mode");
 };
 #endif // overload_cast
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
 // Adaptor for converting arbitrary container arguments into a vector; implicitly convertible from
 // any standard container (or C-style array) supporting std::begin/std::end, any singleton
 // arithmetic type (if T is arithmetic), or explicitly constructible from an iterator pair.
 template <typename T>
 class any_container {
     std::vector<T> v;
+
 public:
     any_container() = default;
 
     // Can construct from a pair of iterators
     template <typename It, typename = enable_if_t<is_input_iterator<It>::value>>
-    any_container(It first, It last) : v(first, last) { }
+    any_container(It first, It last) : v(first, last) {}
 
-    // Implicit conversion constructor from any arbitrary container type with values convertible to T
-    template <typename Container, typename = enable_if_t<std::is_convertible<decltype(*std::begin(std::declval<const Container &>())), T>::value>>
-    any_container(const Container &c) : any_container(std::begin(c), std::end(c)) { }
+    // Implicit conversion constructor from any arbitrary container type
+    // with values convertible to T
+    template <typename Container,
+              typename = enable_if_t<
+                  std::is_convertible<decltype(*std::begin(std::declval<const Container &>())),
+                                      T>::value>>
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    any_container(const Container &c) : any_container(std::begin(c), std::end(c)) {}
 
-    // initializer_list's aren't deducible, so don't get matched by the above template; we need this
-    // to explicitly allow implicit conversion from one:
+    // initializer_list's aren't deducible, so don't get matched by the above template;
+    // we need this to explicitly allow implicit conversion from one:
     template <typename TIn, typename = enable_if_t<std::is_convertible<TIn, T>::value>>
-    any_container(const std::initializer_list<TIn> &c) : any_container(c.begin(), c.end()) { }
+    any_container(const std::initializer_list<TIn> &c) : any_container(c.begin(), c.end()) {}
 
     // Avoid copying if given an rvalue vector of the correct type.
-    any_container(std::vector<T> &&v) : v(std::move(v)) { }
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    any_container(std::vector<T> &&v) : v(std::move(v)) {}
 
     // Moves the vector out of an rvalue any_container
+    // NOLINTNEXTLINE(google-explicit-constructor)
     operator std::vector<T> &&() && { return std::move(v); }
 
     // Dereferencing obtains a reference to the underlying vector
     std::vector<T> &operator*() { return v; }
     const std::vector<T> &operator*() const { return v; }
 
     // -> lets you call methods on the underlying vector
     std::vector<T> *operator->() { return &v; }
     const std::vector<T> *operator->() const { return &v; }
 };
 
-NAMESPACE_END(detail)
+// Forward-declaration; see detail/class.h
+std::string get_fully_qualified_tp_name(PyTypeObject *);
+
+template <typename T>
+inline static std::shared_ptr<T>
+try_get_shared_from_this(std::enable_shared_from_this<T> *holder_value_ptr) {
+// Pre C++17, this code path exploits undefined behavior, but is known to work on many platforms.
+// Use at your own risk!
+// See also https://en.cppreference.com/w/cpp/memory/enable_shared_from_this, and in particular
+// the `std::shared_ptr<Good> gp1 = not_so_good.getptr();` and `try`-`catch` parts of the example.
+#if defined(__cpp_lib_enable_shared_from_this) && (!defined(_MSC_VER) || _MSC_VER >= 1912)
+    return holder_value_ptr->weak_from_this().lock();
+#else
+    try {
+        return holder_value_ptr->shared_from_this();
+    } catch (const std::bad_weak_ptr &) {
+        return nullptr;
+    }
+#endif
+}
+
+// For silencing "unused" compiler warnings in special situations.
+template <typename... Args>
+#if defined(_MSC_VER) && _MSC_VER < 1920 // MSVC 2017
+constexpr
+#endif
+    inline void
+    silence_unused_warnings(Args &&...) {
+}
+
+// MSVC warning C4100: Unreferenced formal parameter
+#if defined(_MSC_VER) && _MSC_VER <= 1916
+#    define PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(...)                                         \
+        detail::silence_unused_warnings(__VA_ARGS__)
+#else
+#    define PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(...)
+#endif
 
+// GCC -Wunused-but-set-parameter  All GCC versions (as of July 2021).
+#if defined(__GNUG__) && !defined(__clang__) && !defined(__INTEL_COMPILER)
+#    define PYBIND11_WORKAROUND_INCORRECT_GCC_UNUSED_BUT_SET_PARAMETER(...)                       \
+        detail::silence_unused_warnings(__VA_ARGS__)
+#else
+#    define PYBIND11_WORKAROUND_INCORRECT_GCC_UNUSED_BUT_SET_PARAMETER(...)
+#endif
 
+#if defined(__clang__)                                                                            \
+    && (defined(__apple_build_version__) /* AppleClang 13.0.0.13000029 was the only data point    \
+                                            available. */                                         \
+        || (__clang_major__ >= 7                                                                  \
+            && __clang_major__ <= 12) /* Clang 3, 5, 13, 14, 15 do not generate the warning. */   \
+    )
+#    define PYBIND11_DETECTED_CLANG_WITH_MISLEADING_CALL_STD_MOVE_EXPLICITLY_WARNING
+// Example:
+// tests/test_kwargs_and_defaults.cpp:46:68: error: local variable 'args' will be copied despite
+// being returned by name [-Werror,-Wreturn-std-move]
+//     m.def("args_function", [](py::args args) -> py::tuple { return args; });
+//                                                                    ^~~~
+// test_kwargs_and_defaults.cpp:46:68: note: call 'std::move' explicitly to avoid copying
+//     m.def("args_function", [](py::args args) -> py::tuple { return args; });
+//                                                                    ^~~~
+//                                                                    std::move(args)
+#endif
+
+// Pybind offers detailed error messages by default for all builts that are debug (through the
+// negation of ndebug). This can also be manually enabled by users, for any builds, through
+// defining PYBIND11_DETAILED_ERROR_MESSAGES.
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES) && !defined(NDEBUG)
+#    define PYBIND11_DETAILED_ERROR_MESSAGES
+#endif
 
-NAMESPACE_END(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

#### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/detail/init.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/init.h`

 * *Files 9% similar despite different names*

```diff
@@ -7,109 +7,132 @@
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
 #include "class.h"
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+
+PYBIND11_WARNING_DISABLE_MSVC(4127)
+
+PYBIND11_NAMESPACE_BEGIN(detail)
 
 template <>
 class type_caster<value_and_holder> {
 public:
     bool load(handle h, bool) {
         value = reinterpret_cast<value_and_holder *>(h.ptr());
         return true;
     }
 
-    template <typename> using cast_op_type = value_and_holder &;
-    operator value_and_holder &() { return *value; }
-    static constexpr auto name = _<value_and_holder>();
+    template <typename>
+    using cast_op_type = value_and_holder &;
+    explicit operator value_and_holder &() { return *value; }
+    static constexpr auto name = const_name<value_and_holder>();
 
 private:
     value_and_holder *value = nullptr;
 };
 
-NAMESPACE_BEGIN(initimpl)
+PYBIND11_NAMESPACE_BEGIN(initimpl)
 
 inline void no_nullptr(void *ptr) {
-    if (!ptr) throw type_error("pybind11::init(): factory function returned nullptr");
+    if (!ptr) {
+        throw type_error("pybind11::init(): factory function returned nullptr");
+    }
 }
 
 // Implementing functions for all forms of py::init<...> and py::init(...)
-template <typename Class> using Cpp = typename Class::type;
-template <typename Class> using Alias = typename Class::type_alias;
-template <typename Class> using Holder = typename Class::holder_type;
+template <typename Class>
+using Cpp = typename Class::type;
+template <typename Class>
+using Alias = typename Class::type_alias;
+template <typename Class>
+using Holder = typename Class::holder_type;
 
-template <typename Class> using is_alias_constructible = std::is_constructible<Alias<Class>, Cpp<Class> &&>;
+template <typename Class>
+using is_alias_constructible = std::is_constructible<Alias<Class>, Cpp<Class> &&>;
 
 // Takes a Cpp pointer and returns true if it actually is a polymorphic Alias instance.
 template <typename Class, enable_if_t<Class::has_alias, int> = 0>
 bool is_alias(Cpp<Class> *ptr) {
     return dynamic_cast<Alias<Class> *>(ptr) != nullptr;
 }
 // Failing fallback version of the above for a no-alias class (always returns false)
 template <typename /*Class*/>
-constexpr bool is_alias(void *) { return false; }
+constexpr bool is_alias(void *) {
+    return false;
+}
 
 // Constructs and returns a new object; if the given arguments don't map to a constructor, we fall
 // back to brace aggregate initiailization so that for aggregate initialization can be used with
 // py::init, e.g.  `py::init<int, int>` to initialize a `struct T { int a; int b; }`.  For
 // non-aggregate types, we need to use an ordinary T(...) constructor (invoking as `T{...}` usually
 // works, but will not do the expected thing when `T` has an `initializer_list<T>` constructor).
-template <typename Class, typename... Args, detail::enable_if_t<std::is_constructible<Class, Args...>::value, int> = 0>
-inline Class *construct_or_initialize(Args &&...args) { return new Class(std::forward<Args>(args)...); }
-template <typename Class, typename... Args, detail::enable_if_t<!std::is_constructible<Class, Args...>::value, int> = 0>
-inline Class *construct_or_initialize(Args &&...args) { return new Class{std::forward<Args>(args)...}; }
+template <typename Class,
+          typename... Args,
+          detail::enable_if_t<std::is_constructible<Class, Args...>::value, int> = 0>
+inline Class *construct_or_initialize(Args &&...args) {
+    return new Class(std::forward<Args>(args)...);
+}
+template <typename Class,
+          typename... Args,
+          detail::enable_if_t<!std::is_constructible<Class, Args...>::value, int> = 0>
+inline Class *construct_or_initialize(Args &&...args) {
+    return new Class{std::forward<Args>(args)...};
+}
 
 // Attempts to constructs an alias using a `Alias(Cpp &&)` constructor.  This allows types with
 // an alias to provide only a single Cpp factory function as long as the Alias can be
 // constructed from an rvalue reference of the base Cpp type.  This means that Alias classes
 // can, when appropriate, simply define a `Alias(Cpp &&)` constructor rather than needing to
 // inherit all the base class constructors.
 template <typename Class>
 void construct_alias_from_cpp(std::true_type /*is_alias_constructible*/,
-                              value_and_holder &v_h, Cpp<Class> &&base) {
+                              value_and_holder &v_h,
+                              Cpp<Class> &&base) {
     v_h.value_ptr() = new Alias<Class>(std::move(base));
 }
 template <typename Class>
 [[noreturn]] void construct_alias_from_cpp(std::false_type /*!is_alias_constructible*/,
-                                           value_and_holder &, Cpp<Class> &&) {
+                                           value_and_holder &,
+                                           Cpp<Class> &&) {
     throw type_error("pybind11::init(): unable to convert returned instance to required "
                      "alias class: no `Alias<Class>(Class &&)` constructor available");
 }
 
 // Error-generating fallback for factories that don't match one of the below construction
 // mechanisms.
 template <typename Class>
 void construct(...) {
     static_assert(!std::is_same<Class, Class>::value /* always false */,
-            "pybind11::init(): init function must return a compatible pointer, "
-            "holder, or value");
+                  "pybind11::init(): init function must return a compatible pointer, "
+                  "holder, or value");
 }
 
 // Pointer return v1: the factory function returns a class pointer for a registered class.
 // If we don't need an alias (because this class doesn't have one, or because the final type is
 // inherited on the Python side) we can simply take over ownership.  Otherwise we need to try to
 // construct an Alias from the returned base instance.
 template <typename Class>
 void construct(value_and_holder &v_h, Cpp<Class> *ptr, bool need_alias) {
+    PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(need_alias);
     no_nullptr(ptr);
     if (Class::has_alias && need_alias && !is_alias<Class>(ptr)) {
         // We're going to try to construct an alias by moving the cpp type.  Whether or not
         // that succeeds, we still need to destroy the original cpp pointer (either the
         // moved away leftover, if the alias construction works, or the value itself if we
         // throw an error), but we can't just call `delete ptr`: it might have a special
         // deleter, or might be shared_from_this.  So we construct a holder around it as if
         // it was a normal instance, then steal the holder away into a local variable; thus
         // the holder and destruction happens when we leave the C++ scope, and the holder
         // class gets to handle the destruction however it likes.
         v_h.value_ptr() = ptr;
-        v_h.set_instance_registered(true); // To prevent init_instance from registering it
+        v_h.set_instance_registered(true);          // To prevent init_instance from registering it
         v_h.type->init_instance(v_h.inst, nullptr); // Set up the holder
         Holder<Class> temp_holder(std::move(v_h.holder<Holder<Class>>())); // Steal the holder
         v_h.type->dealloc(v_h); // Destroys the moved-out holder remains, resets value ptr to null
         v_h.set_instance_registered(false);
 
         construct_alias_from_cpp<Class>(is_alias_constructible<Class>{}, v_h, std::move(*ptr));
     } else {
@@ -124,212 +147,288 @@
 void construct(value_and_holder &v_h, Alias<Class> *alias_ptr, bool) {
     no_nullptr(alias_ptr);
     v_h.value_ptr() = static_cast<Cpp<Class> *>(alias_ptr);
 }
 
 // Holder return: copy its pointer, and move or copy the returned holder into the new instance's
 // holder.  This also handles types like std::shared_ptr<T> and std::unique_ptr<T> where T is a
-// derived type (through those holder's implicit conversion from derived class holder constructors).
+// derived type (through those holder's implicit conversion from derived class holder
+// constructors).
 template <typename Class>
 void construct(value_and_holder &v_h, Holder<Class> holder, bool need_alias) {
+    PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(need_alias);
     auto *ptr = holder_helper<Holder<Class>>::get(holder);
+    no_nullptr(ptr);
     // If we need an alias, check that the held pointer is actually an alias instance
-    if (Class::has_alias && need_alias && !is_alias<Class>(ptr))
+    if (Class::has_alias && need_alias && !is_alias<Class>(ptr)) {
         throw type_error("pybind11::init(): construction failed: returned holder-wrapped instance "
                          "is not an alias instance");
+    }
 
     v_h.value_ptr() = ptr;
     v_h.type->init_instance(v_h.inst, &holder);
 }
 
 // return-by-value version 1: returning a cpp class by value.  If the class has an alias and an
 // alias is required the alias must have an `Alias(Cpp &&)` constructor so that we can construct
 // the alias from the base when needed (i.e. because of Python-side inheritance).  When we don't
 // need it, we simply move-construct the cpp value into a new instance.
 template <typename Class>
 void construct(value_and_holder &v_h, Cpp<Class> &&result, bool need_alias) {
+    PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(need_alias);
     static_assert(std::is_move_constructible<Cpp<Class>>::value,
-        "pybind11::init() return-by-value factory function requires a movable class");
-    if (Class::has_alias && need_alias)
+                  "pybind11::init() return-by-value factory function requires a movable class");
+    if (Class::has_alias && need_alias) {
         construct_alias_from_cpp<Class>(is_alias_constructible<Class>{}, v_h, std::move(result));
-    else
+    } else {
         v_h.value_ptr() = new Cpp<Class>(std::move(result));
+    }
 }
 
 // return-by-value version 2: returning a value of the alias type itself.  We move-construct an
 // Alias instance (even if no the python-side inheritance is involved).  The is intended for
 // cases where Alias initialization is always desired.
 template <typename Class>
 void construct(value_and_holder &v_h, Alias<Class> &&result, bool) {
-    static_assert(std::is_move_constructible<Alias<Class>>::value,
+    static_assert(
+        std::is_move_constructible<Alias<Class>>::value,
         "pybind11::init() return-by-alias-value factory function requires a movable alias class");
     v_h.value_ptr() = new Alias<Class>(std::move(result));
 }
 
 // Implementing class for py::init<...>()
 template <typename... Args>
 struct constructor {
     template <typename Class, typename... Extra, enable_if_t<!Class::has_alias, int> = 0>
-    static void execute(Class &cl, const Extra&... extra) {
-        cl.def("__init__", [](value_and_holder &v_h, Args... args) {
-            v_h.value_ptr() = construct_or_initialize<Cpp<Class>>(std::forward<Args>(args)...);
-        }, is_new_style_constructor(), extra...);
+    static void execute(Class &cl, const Extra &...extra) {
+        cl.def(
+            "__init__",
+            [](value_and_holder &v_h, Args... args) {
+                v_h.value_ptr() = construct_or_initialize<Cpp<Class>>(std::forward<Args>(args)...);
+            },
+            is_new_style_constructor(),
+            extra...);
     }
 
-    template <typename Class, typename... Extra,
-              enable_if_t<Class::has_alias &&
-                          std::is_constructible<Cpp<Class>, Args...>::value, int> = 0>
-    static void execute(Class &cl, const Extra&... extra) {
-        cl.def("__init__", [](value_and_holder &v_h, Args... args) {
-            if (Py_TYPE(v_h.inst) == v_h.type->type)
-                v_h.value_ptr() = construct_or_initialize<Cpp<Class>>(std::forward<Args>(args)...);
-            else
-                v_h.value_ptr() = construct_or_initialize<Alias<Class>>(std::forward<Args>(args)...);
-        }, is_new_style_constructor(), extra...);
+    template <
+        typename Class,
+        typename... Extra,
+        enable_if_t<Class::has_alias && std::is_constructible<Cpp<Class>, Args...>::value, int>
+        = 0>
+    static void execute(Class &cl, const Extra &...extra) {
+        cl.def(
+            "__init__",
+            [](value_and_holder &v_h, Args... args) {
+                if (Py_TYPE(v_h.inst) == v_h.type->type) {
+                    v_h.value_ptr()
+                        = construct_or_initialize<Cpp<Class>>(std::forward<Args>(args)...);
+                } else {
+                    v_h.value_ptr()
+                        = construct_or_initialize<Alias<Class>>(std::forward<Args>(args)...);
+                }
+            },
+            is_new_style_constructor(),
+            extra...);
     }
 
-    template <typename Class, typename... Extra,
-              enable_if_t<Class::has_alias &&
-                          !std::is_constructible<Cpp<Class>, Args...>::value, int> = 0>
-    static void execute(Class &cl, const Extra&... extra) {
-        cl.def("__init__", [](value_and_holder &v_h, Args... args) {
-            v_h.value_ptr() = construct_or_initialize<Alias<Class>>(std::forward<Args>(args)...);
-        }, is_new_style_constructor(), extra...);
+    template <
+        typename Class,
+        typename... Extra,
+        enable_if_t<Class::has_alias && !std::is_constructible<Cpp<Class>, Args...>::value, int>
+        = 0>
+    static void execute(Class &cl, const Extra &...extra) {
+        cl.def(
+            "__init__",
+            [](value_and_holder &v_h, Args... args) {
+                v_h.value_ptr()
+                    = construct_or_initialize<Alias<Class>>(std::forward<Args>(args)...);
+            },
+            is_new_style_constructor(),
+            extra...);
     }
 };
 
 // Implementing class for py::init_alias<...>()
-template <typename... Args> struct alias_constructor {
-    template <typename Class, typename... Extra,
-              enable_if_t<Class::has_alias && std::is_constructible<Alias<Class>, Args...>::value, int> = 0>
-    static void execute(Class &cl, const Extra&... extra) {
-        cl.def("__init__", [](value_and_holder &v_h, Args... args) {
-            v_h.value_ptr() = construct_or_initialize<Alias<Class>>(std::forward<Args>(args)...);
-        }, is_new_style_constructor(), extra...);
+template <typename... Args>
+struct alias_constructor {
+    template <
+        typename Class,
+        typename... Extra,
+        enable_if_t<Class::has_alias && std::is_constructible<Alias<Class>, Args...>::value, int>
+        = 0>
+    static void execute(Class &cl, const Extra &...extra) {
+        cl.def(
+            "__init__",
+            [](value_and_holder &v_h, Args... args) {
+                v_h.value_ptr()
+                    = construct_or_initialize<Alias<Class>>(std::forward<Args>(args)...);
+            },
+            is_new_style_constructor(),
+            extra...);
     }
 };
 
 // Implementation class for py::init(Func) and py::init(Func, AliasFunc)
-template <typename CFunc, typename AFunc = void_type (*)(),
-          typename = function_signature_t<CFunc>, typename = function_signature_t<AFunc>>
+template <typename CFunc,
+          typename AFunc = void_type (*)(),
+          typename = function_signature_t<CFunc>,
+          typename = function_signature_t<AFunc>>
 struct factory;
 
 // Specialization for py::init(Func)
 template <typename Func, typename Return, typename... Args>
 struct factory<Func, void_type (*)(), Return(Args...)> {
     remove_reference_t<Func> class_factory;
 
-    factory(Func &&f) : class_factory(std::forward<Func>(f)) { }
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    factory(Func &&f) : class_factory(std::forward<Func>(f)) {}
 
     // The given class either has no alias or has no separate alias factory;
     // this always constructs the class itself.  If the class is registered with an alias
     // type and an alias instance is needed (i.e. because the final type is a Python class
     // inheriting from the C++ type) the returned value needs to either already be an alias
     // instance, or the alias needs to be constructible from a `Class &&` argument.
     template <typename Class, typename... Extra>
     void execute(Class &cl, const Extra &...extra) && {
-        #if defined(PYBIND11_CPP14)
-        cl.def("__init__", [func = std::move(class_factory)]
-        #else
+#if defined(PYBIND11_CPP14)
+        cl.def(
+            "__init__",
+            [func = std::move(class_factory)]
+#else
         auto &func = class_factory;
-        cl.def("__init__", [func]
-        #endif
-        (value_and_holder &v_h, Args... args) {
-            construct<Class>(v_h, func(std::forward<Args>(args)...),
-                             Py_TYPE(v_h.inst) != v_h.type->type);
-        }, is_new_style_constructor(), extra...);
+        cl.def(
+            "__init__",
+            [func]
+#endif
+            (value_and_holder &v_h, Args... args) {
+                construct<Class>(
+                    v_h, func(std::forward<Args>(args)...), Py_TYPE(v_h.inst) != v_h.type->type);
+            },
+            is_new_style_constructor(),
+            extra...);
     }
 };
 
 // Specialization for py::init(Func, AliasFunc)
-template <typename CFunc, typename AFunc,
-          typename CReturn, typename... CArgs, typename AReturn, typename... AArgs>
+template <typename CFunc,
+          typename AFunc,
+          typename CReturn,
+          typename... CArgs,
+          typename AReturn,
+          typename... AArgs>
 struct factory<CFunc, AFunc, CReturn(CArgs...), AReturn(AArgs...)> {
     static_assert(sizeof...(CArgs) == sizeof...(AArgs),
                   "pybind11::init(class_factory, alias_factory): class and alias factories "
                   "must have identical argument signatures");
     static_assert(all_of<std::is_same<CArgs, AArgs>...>::value,
                   "pybind11::init(class_factory, alias_factory): class and alias factories "
                   "must have identical argument signatures");
 
     remove_reference_t<CFunc> class_factory;
     remove_reference_t<AFunc> alias_factory;
 
     factory(CFunc &&c, AFunc &&a)
-        : class_factory(std::forward<CFunc>(c)), alias_factory(std::forward<AFunc>(a)) { }
+        : class_factory(std::forward<CFunc>(c)), alias_factory(std::forward<AFunc>(a)) {}
 
     // The class factory is called when the `self` type passed to `__init__` is the direct
     // class (i.e. not inherited), the alias factory when `self` is a Python-side subtype.
     template <typename Class, typename... Extra>
-    void execute(Class &cl, const Extra&... extra) && {
-        static_assert(Class::has_alias, "The two-argument version of `py::init()` can "
-                                        "only be used if the class has an alias");
-        #if defined(PYBIND11_CPP14)
-        cl.def("__init__", [class_func = std::move(class_factory), alias_func = std::move(alias_factory)]
-        #else
+    void execute(Class &cl, const Extra &...extra) && {
+        static_assert(Class::has_alias,
+                      "The two-argument version of `py::init()` can "
+                      "only be used if the class has an alias");
+#if defined(PYBIND11_CPP14)
+        cl.def(
+            "__init__",
+            [class_func = std::move(class_factory), alias_func = std::move(alias_factory)]
+#else
         auto &class_func = class_factory;
         auto &alias_func = alias_factory;
-        cl.def("__init__", [class_func, alias_func]
-        #endif
-        (value_and_holder &v_h, CArgs... args) {
-            if (Py_TYPE(v_h.inst) == v_h.type->type)
-                // If the instance type equals the registered type we don't have inheritance, so
-                // don't need the alias and can construct using the class function:
-                construct<Class>(v_h, class_func(std::forward<CArgs>(args)...), false);
-            else
-                construct<Class>(v_h, alias_func(std::forward<CArgs>(args)...), true);
-        }, is_new_style_constructor(), extra...);
+        cl.def(
+            "__init__",
+            [class_func, alias_func]
+#endif
+            (value_and_holder &v_h, CArgs... args) {
+                if (Py_TYPE(v_h.inst) == v_h.type->type) {
+                    // If the instance type equals the registered type we don't have inheritance,
+                    // so don't need the alias and can construct using the class function:
+                    construct<Class>(v_h, class_func(std::forward<CArgs>(args)...), false);
+                } else {
+                    construct<Class>(v_h, alias_func(std::forward<CArgs>(args)...), true);
+                }
+            },
+            is_new_style_constructor(),
+            extra...);
     }
 };
 
 /// Set just the C++ state. Same as `__init__`.
 template <typename Class, typename T>
 void setstate(value_and_holder &v_h, T &&result, bool need_alias) {
     construct<Class>(v_h, std::forward<T>(result), need_alias);
 }
 
 /// Set both the C++ and Python states
-template <typename Class, typename T, typename O,
+template <typename Class,
+          typename T,
+          typename O,
           enable_if_t<std::is_convertible<O, handle>::value, int> = 0>
 void setstate(value_and_holder &v_h, std::pair<T, O> &&result, bool need_alias) {
     construct<Class>(v_h, std::move(result.first), need_alias);
-    setattr((PyObject *) v_h.inst, "__dict__", result.second);
+    auto d = handle(result.second);
+    if (PyDict_Check(d.ptr()) && PyDict_Size(d.ptr()) == 0) {
+        // Skipping setattr below, to not force use of py::dynamic_attr() for Class unnecessarily.
+        // See PR #2972 for details.
+        return;
+    }
+    setattr((PyObject *) v_h.inst, "__dict__", d);
 }
 
 /// Implementation for py::pickle(GetState, SetState)
-template <typename Get, typename Set,
-          typename = function_signature_t<Get>, typename = function_signature_t<Set>>
+template <typename Get,
+          typename Set,
+          typename = function_signature_t<Get>,
+          typename = function_signature_t<Set>>
 struct pickle_factory;
 
-template <typename Get, typename Set,
-          typename RetState, typename Self, typename NewInstance, typename ArgState>
+template <typename Get,
+          typename Set,
+          typename RetState,
+          typename Self,
+          typename NewInstance,
+          typename ArgState>
 struct pickle_factory<Get, Set, RetState(Self), NewInstance(ArgState)> {
     static_assert(std::is_same<intrinsic_t<RetState>, intrinsic_t<ArgState>>::value,
                   "The type returned by `__getstate__` must be the same "
                   "as the argument accepted by `__setstate__`");
 
     remove_reference_t<Get> get;
     remove_reference_t<Set> set;
 
-    pickle_factory(Get get, Set set)
-        : get(std::forward<Get>(get)), set(std::forward<Set>(set)) { }
+    pickle_factory(Get get, Set set) : get(std::forward<Get>(get)), set(std::forward<Set>(set)) {}
 
     template <typename Class, typename... Extra>
     void execute(Class &cl, const Extra &...extra) && {
         cl.def("__getstate__", std::move(get));
 
 #if defined(PYBIND11_CPP14)
-        cl.def("__setstate__", [func = std::move(set)]
+        cl.def(
+            "__setstate__",
+            [func = std::move(set)]
 #else
         auto &func = set;
-        cl.def("__setstate__", [func]
+        cl.def(
+            "__setstate__",
+            [func]
 #endif
-        (value_and_holder &v_h, ArgState state) {
-            setstate<Class>(v_h, func(std::forward<ArgState>(state)),
-                            Py_TYPE(v_h.inst) != v_h.type->type);
-        }, is_new_style_constructor(), extra...);
+            (value_and_holder &v_h, ArgState state) {
+                setstate<Class>(
+                    v_h, func(std::forward<ArgState>(state)), Py_TYPE(v_h.inst) != v_h.type->type);
+            },
+            is_new_style_constructor(),
+            extra...);
     }
 };
 
-NAMESPACE_END(initimpl)
-NAMESPACE_END(detail)
-NAMESPACE_END(pybind11)
+PYBIND11_NAMESPACE_END(initimpl)
+PYBIND11_NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/detail/typeid.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/detail/typeid.h`

 * *Files 15% similar despite different names*

```diff
@@ -9,47 +9,57 @@
 
 #pragma once
 
 #include <cstdio>
 #include <cstdlib>
 
 #if defined(__GNUG__)
-#include <cxxabi.h>
+#    include <cxxabi.h>
 #endif
 
 #include "common.h"
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_BEGIN(detail)
+
 /// Erase all occurrences of a substring
 inline void erase_all(std::string &string, const std::string &search) {
     for (size_t pos = 0;;) {
         pos = string.find(search, pos);
-        if (pos == std::string::npos) break;
+        if (pos == std::string::npos) {
+            break;
+        }
         string.erase(pos, search.length());
     }
 }
 
-PYBIND11_NOINLINE inline void clean_type_id(std::string &name) {
+PYBIND11_NOINLINE void clean_type_id(std::string &name) {
 #if defined(__GNUG__)
     int status = 0;
-    std::unique_ptr<char, void (*)(void *)> res {
-        abi::__cxa_demangle(name.c_str(), nullptr, nullptr, &status), std::free };
-    if (status == 0)
+    std::unique_ptr<char, void (*)(void *)> res{
+        abi::__cxa_demangle(name.c_str(), nullptr, nullptr, &status), std::free};
+    if (status == 0) {
         name = res.get();
+    }
 #else
     detail::erase_all(name, "class ");
     detail::erase_all(name, "struct ");
     detail::erase_all(name, "enum ");
 #endif
     detail::erase_all(name, "pybind11::");
 }
-NAMESPACE_END(detail)
 
-/// Return a string representation of a C++ type
-template <typename T> static std::string type_id() {
-    std::string name(typeid(T).name());
+inline std::string clean_type_id(const char *typeid_name) {
+    std::string name(typeid_name);
     detail::clean_type_id(name);
     return name;
 }
 
-NAMESPACE_END(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_END(detail)
+
+/// Return a string representation of a C++ type
+template <typename T>
+static std::string type_id() {
+    return detail::clean_type_id(typeid(T).name());
+}
+
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/eigen.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/eigen/matrix.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,230 +1,266 @@
 /*
-    pybind11/eigen.h: Transparent conversion for dense and sparse Eigen matrices
+    pybind11/eigen/matrix.h: Transparent conversion for dense and sparse Eigen matrices
 
     Copyright (c) 2016 Wenzel Jakob <wenzel.jakob@epfl.ch>
 
     All rights reserved. Use of this source code is governed by a
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
-#include "numpy.h"
+#include "../numpy.h"
 
-#if defined(__INTEL_COMPILER)
-#  pragma warning(disable: 1682) // implicit conversion of a 64-bit integral type to a smaller integral type (potential portability problem)
-#elif defined(__GNUG__) || defined(__clang__)
-#  pragma GCC diagnostic push
-#  pragma GCC diagnostic ignored "-Wconversion"
-#  pragma GCC diagnostic ignored "-Wdeprecated-declarations"
-#  ifdef __clang__
-//   Eigen generates a bunch of implicit-copy-constructor-is-deprecated warnings with -Wdeprecated
-//   under Clang, so disable that warning here:
-#    pragma GCC diagnostic ignored "-Wdeprecated"
-#  endif
-#  if __GNUC__ >= 7
-#    pragma GCC diagnostic ignored "-Wint-in-bool-context"
-#  endif
-#endif
-
-#if defined(_MSC_VER)
-#  pragma warning(push)
-#  pragma warning(disable: 4127) // warning C4127: Conditional expression is constant
-#  pragma warning(disable: 4996) // warning C4996: std::unary_negate is deprecated in C++17
+/* HINT: To suppress warnings originating from the Eigen headers, use -isystem.
+   See also:
+       https://stackoverflow.com/questions/2579576/i-dir-vs-isystem-dir
+       https://stackoverflow.com/questions/1741816/isystem-for-ms-visual-studio-c-compiler
+*/
+PYBIND11_WARNING_PUSH
+PYBIND11_WARNING_DISABLE_MSVC(5054) // https://github.com/pybind/pybind11/pull/3741
+//       C5054: operator '&': deprecated between enumerations of different types
+#if defined(__MINGW32__)
+PYBIND11_WARNING_DISABLE_GCC("-Wmaybe-uninitialized")
 #endif
 
 #include <Eigen/Core>
 #include <Eigen/SparseCore>
 
+PYBIND11_WARNING_POP
+
 // Eigen prior to 3.2.7 doesn't have proper move constructors--but worse, some classes get implicit
 // move constructors that break things.  We could detect this an explicitly copy, but an extra copy
 // of matrices seems highly undesirable.
-static_assert(EIGEN_VERSION_AT_LEAST(3,2,7), "Eigen support in pybind11 requires Eigen >= 3.2.7");
+static_assert(EIGEN_VERSION_AT_LEAST(3, 2, 7),
+              "Eigen matrix support in pybind11 requires Eigen >= 3.2.7");
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+
+PYBIND11_WARNING_DISABLE_MSVC(4127)
 
 // Provide a convenience alias for easier pass-by-ref usage with fully dynamic strides:
 using EigenDStride = Eigen::Stride<Eigen::Dynamic, Eigen::Dynamic>;
-template <typename MatrixType> using EigenDRef = Eigen::Ref<MatrixType, 0, EigenDStride>;
-template <typename MatrixType> using EigenDMap = Eigen::Map<MatrixType, 0, EigenDStride>;
+template <typename MatrixType>
+using EigenDRef = Eigen::Ref<MatrixType, 0, EigenDStride>;
+template <typename MatrixType>
+using EigenDMap = Eigen::Map<MatrixType, 0, EigenDStride>;
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
-#if EIGEN_VERSION_AT_LEAST(3,3,0)
+#if EIGEN_VERSION_AT_LEAST(3, 3, 0)
 using EigenIndex = Eigen::Index;
+template <typename Scalar, int Flags, typename StorageIndex>
+using EigenMapSparseMatrix = Eigen::Map<Eigen::SparseMatrix<Scalar, Flags, StorageIndex>>;
 #else
 using EigenIndex = EIGEN_DEFAULT_DENSE_INDEX_TYPE;
+template <typename Scalar, int Flags, typename StorageIndex>
+using EigenMapSparseMatrix = Eigen::MappedSparseMatrix<Scalar, Flags, StorageIndex>;
 #endif
 
 // Matches Eigen::Map, Eigen::Ref, blocks, etc:
-template <typename T> using is_eigen_dense_map = all_of<is_template_base_of<Eigen::DenseBase, T>, std::is_base_of<Eigen::MapBase<T, Eigen::ReadOnlyAccessors>, T>>;
-template <typename T> using is_eigen_mutable_map = std::is_base_of<Eigen::MapBase<T, Eigen::WriteAccessors>, T>;
-template <typename T> using is_eigen_dense_plain = all_of<negation<is_eigen_dense_map<T>>, is_template_base_of<Eigen::PlainObjectBase, T>>;
-template <typename T> using is_eigen_sparse = is_template_base_of<Eigen::SparseMatrixBase, T>;
+template <typename T>
+using is_eigen_dense_map = all_of<is_template_base_of<Eigen::DenseBase, T>,
+                                  std::is_base_of<Eigen::MapBase<T, Eigen::ReadOnlyAccessors>, T>>;
+template <typename T>
+using is_eigen_mutable_map = std::is_base_of<Eigen::MapBase<T, Eigen::WriteAccessors>, T>;
+template <typename T>
+using is_eigen_dense_plain
+    = all_of<negation<is_eigen_dense_map<T>>, is_template_base_of<Eigen::PlainObjectBase, T>>;
+template <typename T>
+using is_eigen_sparse = is_template_base_of<Eigen::SparseMatrixBase, T>;
 // Test for objects inheriting from EigenBase<Derived> that aren't captured by the above.  This
 // basically covers anything that can be assigned to a dense matrix but that don't have a typical
 // matrix data layout that can be copied from their .data().  For example, DiagonalMatrix and
 // SelfAdjointView fall into this category.
-template <typename T> using is_eigen_other = all_of<
-    is_template_base_of<Eigen::EigenBase, T>,
-    negation<any_of<is_eigen_dense_map<T>, is_eigen_dense_plain<T>, is_eigen_sparse<T>>>
->;
+template <typename T>
+using is_eigen_other
+    = all_of<is_template_base_of<Eigen::EigenBase, T>,
+             negation<any_of<is_eigen_dense_map<T>, is_eigen_dense_plain<T>, is_eigen_sparse<T>>>>;
 
 // Captures numpy/eigen conformability status (returned by EigenProps::conformable()):
-template <bool EigenRowMajor> struct EigenConformable {
+template <bool EigenRowMajor>
+struct EigenConformable {
     bool conformable = false;
     EigenIndex rows = 0, cols = 0;
-    EigenDStride stride{0, 0};      // Only valid if negativestrides is false!
-    bool negativestrides = false;   // If true, do not use stride!
+    EigenDStride stride{0, 0};    // Only valid if negativestrides is false!
+    bool negativestrides = false; // If true, do not use stride!
 
+    // NOLINTNEXTLINE(google-explicit-constructor)
     EigenConformable(bool fits = false) : conformable{fits} {}
     // Matrix type:
-    EigenConformable(EigenIndex r, EigenIndex c,
-            EigenIndex rstride, EigenIndex cstride) :
-        conformable{true}, rows{r}, cols{c} {
-        // TODO: when Eigen bug #747 is fixed, remove the tests for non-negativity. http://eigen.tuxfamily.org/bz/show_bug.cgi?id=747
-        if (rstride < 0 || cstride < 0) {
-            negativestrides = true;
-        } else {
-            stride = {EigenRowMajor ? rstride : cstride /* outer stride */,
-                      EigenRowMajor ? cstride : rstride /* inner stride */ };
-        }
-    }
+    EigenConformable(EigenIndex r, EigenIndex c, EigenIndex rstride, EigenIndex cstride)
+        : conformable{true}, rows{r}, cols{c},
+          // TODO: when Eigen bug #747 is fixed, remove the tests for non-negativity.
+          // http://eigen.tuxfamily.org/bz/show_bug.cgi?id=747
+          stride{EigenRowMajor ? (rstride > 0 ? rstride : 0)
+                               : (cstride > 0 ? cstride : 0) /* outer stride */,
+                 EigenRowMajor ? (cstride > 0 ? cstride : 0)
+                               : (rstride > 0 ? rstride : 0) /* inner stride */},
+          negativestrides{rstride < 0 || cstride < 0} {}
     // Vector type:
     EigenConformable(EigenIndex r, EigenIndex c, EigenIndex stride)
-        : EigenConformable(r, c, r == 1 ? c*stride : stride, c == 1 ? r : r*stride) {}
+        : EigenConformable(r, c, r == 1 ? c * stride : stride, c == 1 ? r : r * stride) {}
 
-    template <typename props> bool stride_compatible() const {
+    template <typename props>
+    bool stride_compatible() const {
         // To have compatible strides, we need (on both dimensions) one of fully dynamic strides,
-        // matching strides, or a dimension size of 1 (in which case the stride value is irrelevant)
-        return
-            !negativestrides &&
-            (props::inner_stride == Eigen::Dynamic || props::inner_stride == stride.inner() ||
-                (EigenRowMajor ? cols : rows) == 1) &&
-            (props::outer_stride == Eigen::Dynamic || props::outer_stride == stride.outer() ||
-                (EigenRowMajor ? rows : cols) == 1);
+        // matching strides, or a dimension size of 1 (in which case the stride value is
+        // irrelevant). Alternatively, if any dimension size is 0, the strides are not relevant
+        // (and numpy ≥ 1.23 sets the strides to 0 in that case, so we need to check explicitly).
+        if (negativestrides) {
+            return false;
+        }
+        if (rows == 0 || cols == 0) {
+            return true;
+        }
+        return (props::inner_stride == Eigen::Dynamic || props::inner_stride == stride.inner()
+                || (EigenRowMajor ? cols : rows) == 1)
+               && (props::outer_stride == Eigen::Dynamic || props::outer_stride == stride.outer()
+                   || (EigenRowMajor ? rows : cols) == 1);
     }
+    // NOLINTNEXTLINE(google-explicit-constructor)
     operator bool() const { return conformable; }
 };
 
-template <typename Type> struct eigen_extract_stride { using type = Type; };
+template <typename Type>
+struct eigen_extract_stride {
+    using type = Type;
+};
 template <typename PlainObjectType, int MapOptions, typename StrideType>
-struct eigen_extract_stride<Eigen::Map<PlainObjectType, MapOptions, StrideType>> { using type = StrideType; };
+struct eigen_extract_stride<Eigen::Map<PlainObjectType, MapOptions, StrideType>> {
+    using type = StrideType;
+};
 template <typename PlainObjectType, int Options, typename StrideType>
-struct eigen_extract_stride<Eigen::Ref<PlainObjectType, Options, StrideType>> { using type = StrideType; };
+struct eigen_extract_stride<Eigen::Ref<PlainObjectType, Options, StrideType>> {
+    using type = StrideType;
+};
 
 // Helper struct for extracting information from an Eigen type
-template <typename Type_> struct EigenProps {
+template <typename Type_>
+struct EigenProps {
     using Type = Type_;
     using Scalar = typename Type::Scalar;
     using StrideType = typename eigen_extract_stride<Type>::type;
-    static constexpr EigenIndex
-        rows = Type::RowsAtCompileTime,
-        cols = Type::ColsAtCompileTime,
-        size = Type::SizeAtCompileTime;
-    static constexpr bool
-        row_major = Type::IsRowMajor,
-        vector = Type::IsVectorAtCompileTime, // At least one dimension has fixed size 1
-        fixed_rows = rows != Eigen::Dynamic,
-        fixed_cols = cols != Eigen::Dynamic,
-        fixed = size != Eigen::Dynamic, // Fully-fixed size
-        dynamic = !fixed_rows && !fixed_cols; // Fully-dynamic size
-
-    template <EigenIndex i, EigenIndex ifzero> using if_zero = std::integral_constant<EigenIndex, i == 0 ? ifzero : i>;
-    static constexpr EigenIndex inner_stride = if_zero<StrideType::InnerStrideAtCompileTime, 1>::value,
-                                outer_stride = if_zero<StrideType::OuterStrideAtCompileTime,
-                                                       vector ? size : row_major ? cols : rows>::value;
-    static constexpr bool dynamic_stride = inner_stride == Eigen::Dynamic && outer_stride == Eigen::Dynamic;
-    static constexpr bool requires_row_major = !dynamic_stride && !vector && (row_major ? inner_stride : outer_stride) == 1;
-    static constexpr bool requires_col_major = !dynamic_stride && !vector && (row_major ? outer_stride : inner_stride) == 1;
+    static constexpr EigenIndex rows = Type::RowsAtCompileTime, cols = Type::ColsAtCompileTime,
+                                size = Type::SizeAtCompileTime;
+    static constexpr bool row_major = Type::IsRowMajor,
+                          vector
+                          = Type::IsVectorAtCompileTime, // At least one dimension has fixed size 1
+        fixed_rows = rows != Eigen::Dynamic, fixed_cols = cols != Eigen::Dynamic,
+                          fixed = size != Eigen::Dynamic, // Fully-fixed size
+        dynamic = !fixed_rows && !fixed_cols;             // Fully-dynamic size
+
+    template <EigenIndex i, EigenIndex ifzero>
+    using if_zero = std::integral_constant<EigenIndex, i == 0 ? ifzero : i>;
+    static constexpr EigenIndex inner_stride
+        = if_zero<StrideType::InnerStrideAtCompileTime, 1>::value,
+        outer_stride = if_zero < StrideType::OuterStrideAtCompileTime,
+        vector      ? size
+        : row_major ? cols
+                    : rows > ::value;
+    static constexpr bool dynamic_stride
+        = inner_stride == Eigen::Dynamic && outer_stride == Eigen::Dynamic;
+    static constexpr bool requires_row_major
+        = !dynamic_stride && !vector && (row_major ? inner_stride : outer_stride) == 1;
+    static constexpr bool requires_col_major
+        = !dynamic_stride && !vector && (row_major ? outer_stride : inner_stride) == 1;
 
     // Takes an input array and determines whether we can make it fit into the Eigen type.  If
     // the array is a vector, we attempt to fit it into either an Eigen 1xN or Nx1 vector
     // (preferring the latter if it will fit in either, i.e. for a fully dynamic matrix type).
     static EigenConformable<row_major> conformable(const array &a) {
         const auto dims = a.ndim();
-        if (dims < 1 || dims > 2)
+        if (dims < 1 || dims > 2) {
             return false;
+        }
 
         if (dims == 2) { // Matrix type: require exact match (or dynamic)
 
-            EigenIndex
-                np_rows = a.shape(0),
-                np_cols = a.shape(1),
-                np_rstride = a.strides(0) / static_cast<ssize_t>(sizeof(Scalar)),
-                np_cstride = a.strides(1) / static_cast<ssize_t>(sizeof(Scalar));
-            if ((fixed_rows && np_rows != rows) || (fixed_cols && np_cols != cols))
+            EigenIndex np_rows = a.shape(0), np_cols = a.shape(1),
+                       np_rstride = a.strides(0) / static_cast<ssize_t>(sizeof(Scalar)),
+                       np_cstride = a.strides(1) / static_cast<ssize_t>(sizeof(Scalar));
+            if ((fixed_rows && np_rows != rows) || (fixed_cols && np_cols != cols)) {
                 return false;
+            }
 
             return {np_rows, np_cols, np_rstride, np_cstride};
         }
 
-        // Otherwise we're storing an n-vector.  Only one of the strides will be used, but whichever
-        // is used, we want the (single) numpy stride value.
+        // Otherwise we're storing an n-vector.  Only one of the strides will be used, but
+        // whichever is used, we want the (single) numpy stride value.
         const EigenIndex n = a.shape(0),
-              stride = a.strides(0) / static_cast<ssize_t>(sizeof(Scalar));
+                         stride = a.strides(0) / static_cast<ssize_t>(sizeof(Scalar));
 
         if (vector) { // Eigen type is a compile-time vector
-            if (fixed && size != n)
+            if (fixed && size != n) {
                 return false; // Vector size mismatch
+            }
             return {rows == 1 ? 1 : n, cols == 1 ? 1 : n, stride};
         }
-        else if (fixed) {
+        if (fixed) {
             // The type has a fixed size, but is not a vector: abort
             return false;
         }
-        else if (fixed_cols) {
+        if (fixed_cols) {
             // Since this isn't a vector, cols must be != 1.  We allow this only if it exactly
             // equals the number of elements (rows is Dynamic, and so 1 row is allowed).
-            if (cols != n) return false;
+            if (cols != n) {
+                return false;
+            }
             return {1, n, stride};
+        } // Otherwise it's either fully dynamic, or column dynamic; both become a column vector
+        if (fixed_rows && rows != n) {
+            return false;
         }
-        else {
-            // Otherwise it's either fully dynamic, or column dynamic; both become a column vector
-            if (fixed_rows && rows != n) return false;
-            return {n, 1, stride};
-        }
+        return {n, 1, stride};
     }
 
-    static constexpr bool show_writeable = is_eigen_dense_map<Type>::value && is_eigen_mutable_map<Type>::value;
+    static constexpr bool show_writeable
+        = is_eigen_dense_map<Type>::value && is_eigen_mutable_map<Type>::value;
     static constexpr bool show_order = is_eigen_dense_map<Type>::value;
     static constexpr bool show_c_contiguous = show_order && requires_row_major;
-    static constexpr bool show_f_contiguous = !show_c_contiguous && show_order && requires_col_major;
+    static constexpr bool show_f_contiguous
+        = !show_c_contiguous && show_order && requires_col_major;
 
-    static constexpr auto descriptor =
-        _("numpy.ndarray[") + npy_format_descriptor<Scalar>::name +
-        _("[")  + _<fixed_rows>(_<(size_t) rows>(), _("m")) +
-        _(", ") + _<fixed_cols>(_<(size_t) cols>(), _("n")) +
-        _("]") +
-        // For a reference type (e.g. Ref<MatrixXd>) we have other constraints that might need to be
-        // satisfied: writeable=True (for a mutable reference), and, depending on the map's stride
-        // options, possibly f_contiguous or c_contiguous.  We include them in the descriptor output
-        // to provide some hint as to why a TypeError is occurring (otherwise it can be confusing to
-        // see that a function accepts a 'numpy.ndarray[float64[3,2]]' and an error message that you
-        // *gave* a numpy.ndarray of the right type and dimensions.
-        _<show_writeable>(", flags.writeable", "") +
-        _<show_c_contiguous>(", flags.c_contiguous", "") +
-        _<show_f_contiguous>(", flags.f_contiguous", "") +
-        _("]");
+    static constexpr auto descriptor
+        = const_name("numpy.ndarray[") + npy_format_descriptor<Scalar>::name + const_name("[")
+          + const_name<fixed_rows>(const_name<(size_t) rows>(), const_name("m")) + const_name(", ")
+          + const_name<fixed_cols>(const_name<(size_t) cols>(), const_name("n")) + const_name("]")
+          +
+          // For a reference type (e.g. Ref<MatrixXd>) we have other constraints that might need to
+          // be satisfied: writeable=True (for a mutable reference), and, depending on the map's
+          // stride options, possibly f_contiguous or c_contiguous.  We include them in the
+          // descriptor output to provide some hint as to why a TypeError is occurring (otherwise
+          // it can be confusing to see that a function accepts a 'numpy.ndarray[float64[3,2]]' and
+          // an error message that you *gave* a numpy.ndarray of the right type and dimensions.
+          const_name<show_writeable>(", flags.writeable", "")
+          + const_name<show_c_contiguous>(", flags.c_contiguous", "")
+          + const_name<show_f_contiguous>(", flags.f_contiguous", "") + const_name("]");
 };
 
 // Casts an Eigen type to numpy array.  If given a base, the numpy array references the src data,
 // otherwise it'll make a copy.  writeable lets you turn off the writeable flag for the array.
-template <typename props> handle eigen_array_cast(typename props::Type const &src, handle base = handle(), bool writeable = true) {
+template <typename props>
+handle
+eigen_array_cast(typename props::Type const &src, handle base = handle(), bool writeable = true) {
     constexpr ssize_t elem_size = sizeof(typename props::Scalar);
     array a;
-    if (props::vector)
-        a = array({ src.size() }, { elem_size * src.innerStride() }, src.data(), base);
-    else
-        a = array({ src.rows(), src.cols() }, { elem_size * src.rowStride(), elem_size * src.colStride() },
-                  src.data(), base);
+    if (props::vector) {
+        a = array({src.size()}, {elem_size * src.innerStride()}, src.data(), base);
+    } else {
+        a = array({src.rows(), src.cols()},
+                  {elem_size * src.rowStride(), elem_size * src.colStride()},
+                  src.data(),
+                  base);
+    }
 
-    if (!writeable)
+    if (!writeable) {
         array_proxy(a.ptr())->flags &= ~detail::npy_api::NPY_ARRAY_WRITEABLE_;
+    }
 
     return a.release();
 }
 
 // Takes an lvalue ref to some Eigen type and a (python) base object, creating a numpy array that
 // reference the Eigen object's data with `base` as the python-registered base class (if omitted,
 // the base will be set to None, and lifetime management is up to the caller).  The numpy array is
@@ -232,68 +268,74 @@
 template <typename props, typename Type>
 handle eigen_ref_array(Type &src, handle parent = none()) {
     // none here is to get past array's should-we-copy detection, which currently always
     // copies when there is no base.  Setting the base to None should be harmless.
     return eigen_array_cast<props>(src, parent, !std::is_const<Type>::value);
 }
 
-// Takes a pointer to some dense, plain Eigen type, builds a capsule around it, then returns a numpy
-// array that references the encapsulated data with a python-side reference to the capsule to tie
-// its destruction to that of any dependent python objects.  Const-ness is determined by whether or
-// not the Type of the pointer given is const.
+// Takes a pointer to some dense, plain Eigen type, builds a capsule around it, then returns a
+// numpy array that references the encapsulated data with a python-side reference to the capsule to
+// tie its destruction to that of any dependent python objects.  Const-ness is determined by
+// whether or not the Type of the pointer given is const.
 template <typename props, typename Type, typename = enable_if_t<is_eigen_dense_plain<Type>::value>>
 handle eigen_encapsulate(Type *src) {
     capsule base(src, [](void *o) { delete static_cast<Type *>(o); });
     return eigen_ref_array<props>(*src, base);
 }
 
 // Type caster for regular, dense matrix types (e.g. MatrixXd), but not maps/refs/etc. of dense
 // types.
-template<typename Type>
+template <typename Type>
 struct type_caster<Type, enable_if_t<is_eigen_dense_plain<Type>::value>> {
     using Scalar = typename Type::Scalar;
     using props = EigenProps<Type>;
 
     bool load(handle src, bool convert) {
         // If we're in no-convert mode, only load if given an array of the correct type
-        if (!convert && !isinstance<array_t<Scalar>>(src))
+        if (!convert && !isinstance<array_t<Scalar>>(src)) {
             return false;
+        }
 
         // Coerce into an array, but don't do type conversion yet; the copy below handles it.
         auto buf = array::ensure(src);
 
-        if (!buf)
+        if (!buf) {
             return false;
+        }
 
         auto dims = buf.ndim();
-        if (dims < 1 || dims > 2)
+        if (dims < 1 || dims > 2) {
             return false;
+        }
 
         auto fits = props::conformable(buf);
-        if (!fits)
+        if (!fits) {
             return false;
+        }
 
         // Allocate the new type, then build a numpy reference into it
         value = Type(fits.rows, fits.cols);
         auto ref = reinterpret_steal<array>(eigen_ref_array<props>(value));
-        if (dims == 1) ref = ref.squeeze();
-        else if (ref.ndim() == 1) buf = buf.squeeze();
+        if (dims == 1) {
+            ref = ref.squeeze();
+        } else if (ref.ndim() == 1) {
+            buf = buf.squeeze();
+        }
 
         int result = detail::npy_api::get().PyArray_CopyInto_(ref.ptr(), buf.ptr());
 
         if (result < 0) { // Copy failed!
             PyErr_Clear();
             return false;
         }
 
         return true;
     }
 
 private:
-
     // Cast implementation
     template <typename CType>
     static handle cast_impl(CType *src, return_value_policy policy, handle parent) {
         switch (policy) {
             case return_value_policy::take_ownership:
             case return_value_policy::automatic:
                 return eigen_encapsulate<props>(src);
@@ -308,68 +350,75 @@
                 return eigen_ref_array<props>(*src, parent);
             default:
                 throw cast_error("unhandled return_value_policy: should not happen!");
         };
     }
 
 public:
-
     // Normal returned non-reference, non-const value:
     static handle cast(Type &&src, return_value_policy /* policy */, handle parent) {
         return cast_impl(&src, return_value_policy::move, parent);
     }
     // If you return a non-reference const, we mark the numpy array readonly:
     static handle cast(const Type &&src, return_value_policy /* policy */, handle parent) {
         return cast_impl(&src, return_value_policy::move, parent);
     }
     // lvalue reference return; default (automatic) becomes copy
     static handle cast(Type &src, return_value_policy policy, handle parent) {
-        if (policy == return_value_policy::automatic || policy == return_value_policy::automatic_reference)
+        if (policy == return_value_policy::automatic
+            || policy == return_value_policy::automatic_reference) {
             policy = return_value_policy::copy;
+        }
         return cast_impl(&src, policy, parent);
     }
     // const lvalue reference return; default (automatic) becomes copy
     static handle cast(const Type &src, return_value_policy policy, handle parent) {
-        if (policy == return_value_policy::automatic || policy == return_value_policy::automatic_reference)
+        if (policy == return_value_policy::automatic
+            || policy == return_value_policy::automatic_reference) {
             policy = return_value_policy::copy;
+        }
         return cast(&src, policy, parent);
     }
     // non-const pointer return
     static handle cast(Type *src, return_value_policy policy, handle parent) {
         return cast_impl(src, policy, parent);
     }
     // const pointer return
     static handle cast(const Type *src, return_value_policy policy, handle parent) {
         return cast_impl(src, policy, parent);
     }
 
     static constexpr auto name = props::descriptor;
 
-    operator Type*() { return &value; }
-    operator Type&() { return value; }
-    operator Type&&() && { return std::move(value); }
-    template <typename T> using cast_op_type = movable_cast_op_type<T>;
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    operator Type *() { return &value; }
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    operator Type &() { return value; }
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    operator Type &&() && { return std::move(value); }
+    template <typename T>
+    using cast_op_type = movable_cast_op_type<T>;
 
 private:
     Type value;
 };
 
 // Base class for casting reference/map/block/etc. objects back to python.
-template <typename MapType> struct eigen_map_caster {
+template <typename MapType>
+struct eigen_map_caster {
 private:
     using props = EigenProps<MapType>;
 
 public:
-
     // Directly referencing a ref/map's data is a bit dangerous (whatever the map/ref points to has
-    // to stay around), but we'll allow it under the assumption that you know what you're doing (and
-    // have an appropriate keep_alive in place).  We return a numpy array pointing directly at the
-    // ref's data (The numpy array ends up read-only if the ref was to a const matrix type.) Note
-    // that this means you need to ensure you don't destroy the object in some other way (e.g. with
-    // an appropriate keep_alive, or with a reference to a statically allocated matrix).
+    // to stay around), but we'll allow it under the assumption that you know what you're doing
+    // (and have an appropriate keep_alive in place).  We return a numpy array pointing directly at
+    // the ref's data (The numpy array ends up read-only if the ref was to a const matrix type.)
+    // Note that this means you need to ensure you don't destroy the object in some other way (e.g.
+    // with an appropriate keep_alive, or with a reference to a statically allocated matrix).
     static handle cast(const MapType &src, return_value_policy policy, handle parent) {
         switch (policy) {
             case return_value_policy::copy:
                 return eigen_array_cast<props>(src);
             case return_value_policy::reference_internal:
                 return eigen_array_cast<props>(src, parent, is_eigen_mutable_map<MapType>::value);
             case return_value_policy::reference:
@@ -385,223 +434,268 @@
     static constexpr auto name = props::descriptor;
 
     // Explicitly delete these: support python -> C++ conversion on these (i.e. these can be return
     // types but not bound arguments).  We still provide them (with an explicitly delete) so that
     // you end up here if you try anyway.
     bool load(handle, bool) = delete;
     operator MapType() = delete;
-    template <typename> using cast_op_type = MapType;
+    template <typename>
+    using cast_op_type = MapType;
 };
 
 // We can return any map-like object (but can only load Refs, specialized next):
-template <typename Type> struct type_caster<Type, enable_if_t<is_eigen_dense_map<Type>::value>>
-    : eigen_map_caster<Type> {};
+template <typename Type>
+struct type_caster<Type, enable_if_t<is_eigen_dense_map<Type>::value>> : eigen_map_caster<Type> {};
 
 // Loader for Ref<...> arguments.  See the documentation for info on how to make this work without
 // copying (it requires some extra effort in many cases).
 template <typename PlainObjectType, typename StrideType>
 struct type_caster<
     Eigen::Ref<PlainObjectType, 0, StrideType>,
-    enable_if_t<is_eigen_dense_map<Eigen::Ref<PlainObjectType, 0, StrideType>>::value>
-> : public eigen_map_caster<Eigen::Ref<PlainObjectType, 0, StrideType>> {
+    enable_if_t<is_eigen_dense_map<Eigen::Ref<PlainObjectType, 0, StrideType>>::value>>
+    : public eigen_map_caster<Eigen::Ref<PlainObjectType, 0, StrideType>> {
 private:
     using Type = Eigen::Ref<PlainObjectType, 0, StrideType>;
     using props = EigenProps<Type>;
     using Scalar = typename props::Scalar;
     using MapType = Eigen::Map<PlainObjectType, 0, StrideType>;
-    using Array = array_t<Scalar, array::forcecast |
-                ((props::row_major ? props::inner_stride : props::outer_stride) == 1 ? array::c_style :
-                 (props::row_major ? props::outer_stride : props::inner_stride) == 1 ? array::f_style : 0)>;
+    using Array
+        = array_t<Scalar,
+                  array::forcecast
+                      | ((props::row_major ? props::inner_stride : props::outer_stride) == 1
+                             ? array::c_style
+                         : (props::row_major ? props::outer_stride : props::inner_stride) == 1
+                             ? array::f_style
+                             : 0)>;
     static constexpr bool need_writeable = is_eigen_mutable_map<Type>::value;
     // Delay construction (these have no default constructor)
     std::unique_ptr<MapType> map;
     std::unique_ptr<Type> ref;
     // Our array.  When possible, this is just a numpy array pointing to the source data, but
-    // sometimes we can't avoid copying (e.g. input is not a numpy array at all, has an incompatible
-    // layout, or is an array of a type that needs to be converted).  Using a numpy temporary
-    // (rather than an Eigen temporary) saves an extra copy when we need both type conversion and
-    // storage order conversion.  (Note that we refuse to use this temporary copy when loading an
-    // argument for a Ref<M> with M non-const, i.e. a read-write reference).
+    // sometimes we can't avoid copying (e.g. input is not a numpy array at all, has an
+    // incompatible layout, or is an array of a type that needs to be converted).  Using a numpy
+    // temporary (rather than an Eigen temporary) saves an extra copy when we need both type
+    // conversion and storage order conversion.  (Note that we refuse to use this temporary copy
+    // when loading an argument for a Ref<M> with M non-const, i.e. a read-write reference).
     Array copy_or_ref;
+
 public:
     bool load(handle src, bool convert) {
-        // First check whether what we have is already an array of the right type.  If not, we can't
-        // avoid a copy (because the copy is also going to do type conversion).
+        // First check whether what we have is already an array of the right type.  If not, we
+        // can't avoid a copy (because the copy is also going to do type conversion).
         bool need_copy = !isinstance<Array>(src);
 
         EigenConformable<props::row_major> fits;
         if (!need_copy) {
             // We don't need a converting copy, but we also need to check whether the strides are
             // compatible with the Ref's stride requirements
-            Array aref = reinterpret_borrow<Array>(src);
+            auto aref = reinterpret_borrow<Array>(src);
 
             if (aref && (!need_writeable || aref.writeable())) {
                 fits = props::conformable(aref);
-                if (!fits) return false; // Incompatible dimensions
-                if (!fits.template stride_compatible<props>())
+                if (!fits) {
+                    return false; // Incompatible dimensions
+                }
+                if (!fits.template stride_compatible<props>()) {
                     need_copy = true;
-                else
+                } else {
                     copy_or_ref = std::move(aref);
-            }
-            else {
+                }
+            } else {
                 need_copy = true;
             }
         }
 
         if (need_copy) {
             // We need to copy: If we need a mutable reference, or we're not supposed to convert
             // (either because we're in the no-convert overload pass, or because we're explicitly
             // instructed not to copy (via `py::arg().noconvert()`) we have to fail loading.
-            if (!convert || need_writeable) return false;
+            if (!convert || need_writeable) {
+                return false;
+            }
 
             Array copy = Array::ensure(src);
-            if (!copy) return false;
+            if (!copy) {
+                return false;
+            }
             fits = props::conformable(copy);
-            if (!fits || !fits.template stride_compatible<props>())
+            if (!fits || !fits.template stride_compatible<props>()) {
                 return false;
+            }
             copy_or_ref = std::move(copy);
             loader_life_support::add_patient(copy_or_ref);
         }
 
         ref.reset();
-        map.reset(new MapType(data(copy_or_ref), fits.rows, fits.cols, make_stride(fits.stride.outer(), fits.stride.inner())));
+        map.reset(new MapType(data(copy_or_ref),
+                              fits.rows,
+                              fits.cols,
+                              make_stride(fits.stride.outer(), fits.stride.inner())));
         ref.reset(new Type(*map));
 
         return true;
     }
 
-    operator Type*() { return ref.get(); }
-    operator Type&() { return *ref; }
-    template <typename _T> using cast_op_type = pybind11::detail::cast_op_type<_T>;
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    operator Type *() { return ref.get(); }
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    operator Type &() { return *ref; }
+    template <typename _T>
+    using cast_op_type = pybind11::detail::cast_op_type<_T>;
 
 private:
     template <typename T = Type, enable_if_t<is_eigen_mutable_map<T>::value, int> = 0>
-    Scalar *data(Array &a) { return a.mutable_data(); }
+    Scalar *data(Array &a) {
+        return a.mutable_data();
+    }
 
     template <typename T = Type, enable_if_t<!is_eigen_mutable_map<T>::value, int> = 0>
-    const Scalar *data(Array &a) { return a.data(); }
+    const Scalar *data(Array &a) {
+        return a.data();
+    }
 
     // Attempt to figure out a constructor of `Stride` that will work.
     // If both strides are fixed, use a default constructor:
-    template <typename S> using stride_ctor_default = bool_constant<
-        S::InnerStrideAtCompileTime != Eigen::Dynamic && S::OuterStrideAtCompileTime != Eigen::Dynamic &&
-        std::is_default_constructible<S>::value>;
+    template <typename S>
+    using stride_ctor_default = bool_constant<S::InnerStrideAtCompileTime != Eigen::Dynamic
+                                              && S::OuterStrideAtCompileTime != Eigen::Dynamic
+                                              && std::is_default_constructible<S>::value>;
     // Otherwise, if there is a two-index constructor, assume it is (outer,inner) like
     // Eigen::Stride, and use it:
-    template <typename S> using stride_ctor_dual = bool_constant<
-        !stride_ctor_default<S>::value && std::is_constructible<S, EigenIndex, EigenIndex>::value>;
+    template <typename S>
+    using stride_ctor_dual
+        = bool_constant<!stride_ctor_default<S>::value
+                        && std::is_constructible<S, EigenIndex, EigenIndex>::value>;
     // Otherwise, if there is a one-index constructor, and just one of the strides is dynamic, use
     // it (passing whichever stride is dynamic).
-    template <typename S> using stride_ctor_outer = bool_constant<
-        !any_of<stride_ctor_default<S>, stride_ctor_dual<S>>::value &&
-        S::OuterStrideAtCompileTime == Eigen::Dynamic && S::InnerStrideAtCompileTime != Eigen::Dynamic &&
-        std::is_constructible<S, EigenIndex>::value>;
-    template <typename S> using stride_ctor_inner = bool_constant<
-        !any_of<stride_ctor_default<S>, stride_ctor_dual<S>>::value &&
-        S::InnerStrideAtCompileTime == Eigen::Dynamic && S::OuterStrideAtCompileTime != Eigen::Dynamic &&
-        std::is_constructible<S, EigenIndex>::value>;
+    template <typename S>
+    using stride_ctor_outer
+        = bool_constant<!any_of<stride_ctor_default<S>, stride_ctor_dual<S>>::value
+                        && S::OuterStrideAtCompileTime == Eigen::Dynamic
+                        && S::InnerStrideAtCompileTime != Eigen::Dynamic
+                        && std::is_constructible<S, EigenIndex>::value>;
+    template <typename S>
+    using stride_ctor_inner
+        = bool_constant<!any_of<stride_ctor_default<S>, stride_ctor_dual<S>>::value
+                        && S::InnerStrideAtCompileTime == Eigen::Dynamic
+                        && S::OuterStrideAtCompileTime != Eigen::Dynamic
+                        && std::is_constructible<S, EigenIndex>::value>;
 
     template <typename S = StrideType, enable_if_t<stride_ctor_default<S>::value, int> = 0>
-    static S make_stride(EigenIndex, EigenIndex) { return S(); }
+    static S make_stride(EigenIndex, EigenIndex) {
+        return S();
+    }
     template <typename S = StrideType, enable_if_t<stride_ctor_dual<S>::value, int> = 0>
-    static S make_stride(EigenIndex outer, EigenIndex inner) { return S(outer, inner); }
+    static S make_stride(EigenIndex outer, EigenIndex inner) {
+        return S(outer, inner);
+    }
     template <typename S = StrideType, enable_if_t<stride_ctor_outer<S>::value, int> = 0>
-    static S make_stride(EigenIndex outer, EigenIndex) { return S(outer); }
+    static S make_stride(EigenIndex outer, EigenIndex) {
+        return S(outer);
+    }
     template <typename S = StrideType, enable_if_t<stride_ctor_inner<S>::value, int> = 0>
-    static S make_stride(EigenIndex, EigenIndex inner) { return S(inner); }
-
+    static S make_stride(EigenIndex, EigenIndex inner) {
+        return S(inner);
+    }
 };
 
 // type_caster for special matrix types (e.g. DiagonalMatrix), which are EigenBase, but not
 // EigenDense (i.e. they don't have a data(), at least not with the usual matrix layout).
 // load() is not supported, but we can cast them into the python domain by first copying to a
 // regular Eigen::Matrix, then casting that.
 template <typename Type>
 struct type_caster<Type, enable_if_t<is_eigen_other<Type>::value>> {
 protected:
-    using Matrix = Eigen::Matrix<typename Type::Scalar, Type::RowsAtCompileTime, Type::ColsAtCompileTime>;
+    using Matrix
+        = Eigen::Matrix<typename Type::Scalar, Type::RowsAtCompileTime, Type::ColsAtCompileTime>;
     using props = EigenProps<Matrix>;
+
 public:
     static handle cast(const Type &src, return_value_policy /* policy */, handle /* parent */) {
         handle h = eigen_encapsulate<props>(new Matrix(src));
         return h;
     }
-    static handle cast(const Type *src, return_value_policy policy, handle parent) { return cast(*src, policy, parent); }
+    static handle cast(const Type *src, return_value_policy policy, handle parent) {
+        return cast(*src, policy, parent);
+    }
 
     static constexpr auto name = props::descriptor;
 
     // Explicitly delete these: support python -> C++ conversion on these (i.e. these can be return
     // types but not bound arguments).  We still provide them (with an explicitly delete) so that
     // you end up here if you try anyway.
     bool load(handle, bool) = delete;
     operator Type() = delete;
-    template <typename> using cast_op_type = Type;
+    template <typename>
+    using cast_op_type = Type;
 };
 
-template<typename Type>
+template <typename Type>
 struct type_caster<Type, enable_if_t<is_eigen_sparse<Type>::value>> {
-    typedef typename Type::Scalar Scalar;
-    typedef remove_reference_t<decltype(*std::declval<Type>().outerIndexPtr())> StorageIndex;
-    typedef typename Type::Index Index;
+    using Scalar = typename Type::Scalar;
+    using StorageIndex = remove_reference_t<decltype(*std::declval<Type>().outerIndexPtr())>;
+    using Index = typename Type::Index;
     static constexpr bool rowMajor = Type::IsRowMajor;
 
     bool load(handle src, bool) {
-        if (!src)
+        if (!src) {
             return false;
+        }
 
         auto obj = reinterpret_borrow<object>(src);
-        object sparse_module = module::import("scipy.sparse");
-        object matrix_type = sparse_module.attr(
-            rowMajor ? "csr_matrix" : "csc_matrix");
+        object sparse_module = module_::import("scipy.sparse");
+        object matrix_type = sparse_module.attr(rowMajor ? "csr_matrix" : "csc_matrix");
 
-        if (!obj.get_type().is(matrix_type)) {
+        if (!type::handle_of(obj).is(matrix_type)) {
             try {
                 obj = matrix_type(obj);
             } catch (const error_already_set &) {
                 return false;
             }
         }
 
         auto values = array_t<Scalar>((object) obj.attr("data"));
         auto innerIndices = array_t<StorageIndex>((object) obj.attr("indices"));
         auto outerIndices = array_t<StorageIndex>((object) obj.attr("indptr"));
         auto shape = pybind11::tuple((pybind11::object) obj.attr("shape"));
         auto nnz = obj.attr("nnz").cast<Index>();
 
-        if (!values || !innerIndices || !outerIndices)
+        if (!values || !innerIndices || !outerIndices) {
             return false;
+        }
 
-        value = Eigen::MappedSparseMatrix<Scalar, Type::Flags, StorageIndex>(
-            shape[0].cast<Index>(), shape[1].cast<Index>(), nnz,
-            outerIndices.mutable_data(), innerIndices.mutable_data(), values.mutable_data());
+        value = EigenMapSparseMatrix<Scalar,
+                                     Type::Flags &(Eigen::RowMajor | Eigen::ColMajor),
+                                     StorageIndex>(shape[0].cast<Index>(),
+                                                   shape[1].cast<Index>(),
+                                                   std::move(nnz),
+                                                   outerIndices.mutable_data(),
+                                                   innerIndices.mutable_data(),
+                                                   values.mutable_data());
 
         return true;
     }
 
     static handle cast(const Type &src, return_value_policy /* policy */, handle /* parent */) {
-        const_cast<Type&>(src).makeCompressed();
+        const_cast<Type &>(src).makeCompressed();
 
-        object matrix_type = module::import("scipy.sparse").attr(
-            rowMajor ? "csr_matrix" : "csc_matrix");
+        object matrix_type
+            = module_::import("scipy.sparse").attr(rowMajor ? "csr_matrix" : "csc_matrix");
 
         array data(src.nonZeros(), src.valuePtr());
         array outerIndices((rowMajor ? src.rows() : src.cols()) + 1, src.outerIndexPtr());
         array innerIndices(src.nonZeros(), src.innerIndexPtr());
 
-        return matrix_type(
-            std::make_tuple(data, innerIndices, outerIndices),
-            std::make_pair(src.rows(), src.cols())
-        ).release();
+        return matrix_type(pybind11::make_tuple(
+                               std::move(data), std::move(innerIndices), std::move(outerIndices)),
+                           pybind11::make_tuple(src.rows(), src.cols()))
+            .release();
     }
 
-    PYBIND11_TYPE_CASTER(Type, _<(Type::IsRowMajor) != 0>("scipy.sparse.csr_matrix[", "scipy.sparse.csc_matrix[")
-            + npy_format_descriptor<Scalar>::name + _("]"));
+    PYBIND11_TYPE_CASTER(Type,
+                         const_name<(Type::IsRowMajor) != 0>("scipy.sparse.csr_matrix[",
+                                                             "scipy.sparse.csc_matrix[")
+                             + npy_format_descriptor<Scalar>::name + const_name("]"));
 };
 
-NAMESPACE_END(detail)
-NAMESPACE_END(PYBIND11_NAMESPACE)
-
-#if defined(__GNUG__) || defined(__clang__)
-#  pragma GCC diagnostic pop
-#elif defined(_MSC_VER)
-#  pragma warning(pop)
-#endif
+PYBIND11_NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

#### encoding

```diff
@@ -1 +1 @@
-us-ascii
+utf-8
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/eval.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/eval.h`

 * *Files 24% similar despite different names*

```diff
@@ -1,117 +1,156 @@
 /*
-    pybind11/exec.h: Support for evaluating Python expressions and statements
+    pybind11/eval.h: Support for evaluating Python expressions and statements
     from strings and files
 
     Copyright (c) 2016 Klemens Morgenstern <klemens.morgenstern@ed-chemnitz.de> and
                        Wenzel Jakob <wenzel.jakob@epfl.ch>
 
     All rights reserved. Use of this source code is governed by a
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
 #include "pybind11.h"
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+#include <utility>
+
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_BEGIN(detail)
+
+inline void ensure_builtins_in_globals(object &global) {
+#if defined(PYPY_VERSION) || PY_VERSION_HEX < 0x03080000
+    // Running exec and eval adds `builtins` module under `__builtins__` key to
+    // globals if not yet present.  Python 3.8 made PyRun_String behave
+    // similarly. Let's also do that for older versions, for consistency. This
+    // was missing from PyPy3.8 7.3.7.
+    if (!global.contains("__builtins__"))
+        global["__builtins__"] = module_::import(PYBIND11_BUILTINS_MODULE);
+#else
+    (void) global;
+#endif
+}
+
+PYBIND11_NAMESPACE_END(detail)
 
 enum eval_mode {
     /// Evaluate a string containing an isolated expression
     eval_expr,
 
     /// Evaluate a string containing a single statement. Returns \c none
     eval_single_statement,
 
     /// Evaluate a string containing a sequence of statement. Returns \c none
     eval_statements
 };
 
 template <eval_mode mode = eval_expr>
-object eval(str expr, object global = globals(), object local = object()) {
-    if (!local)
+object eval(const str &expr, object global = globals(), object local = object()) {
+    if (!local) {
         local = global;
+    }
+
+    detail::ensure_builtins_in_globals(global);
 
     /* PyRun_String does not accept a PyObject / encoding specifier,
        this seems to be the only alternative */
     std::string buffer = "# -*- coding: utf-8 -*-\n" + (std::string) expr;
 
-    int start;
+    int start = 0;
     switch (mode) {
-        case eval_expr:             start = Py_eval_input;   break;
-        case eval_single_statement: start = Py_single_input; break;
-        case eval_statements:       start = Py_file_input;   break;
-        default: pybind11_fail("invalid evaluation mode");
+        case eval_expr:
+            start = Py_eval_input;
+            break;
+        case eval_single_statement:
+            start = Py_single_input;
+            break;
+        case eval_statements:
+            start = Py_file_input;
+            break;
+        default:
+            pybind11_fail("invalid evaluation mode");
     }
 
     PyObject *result = PyRun_String(buffer.c_str(), start, global.ptr(), local.ptr());
-    if (!result)
+    if (!result) {
         throw error_already_set();
+    }
     return reinterpret_steal<object>(result);
 }
 
 template <eval_mode mode = eval_expr, size_t N>
 object eval(const char (&s)[N], object global = globals(), object local = object()) {
     /* Support raw string literals by removing common leading whitespace */
-    auto expr = (s[0] == '\n') ? str(module::import("textwrap").attr("dedent")(s))
-                               : str(s);
-    return eval<mode>(expr, global, local);
+    auto expr = (s[0] == '\n') ? str(module_::import("textwrap").attr("dedent")(s)) : str(s);
+    return eval<mode>(expr, std::move(global), std::move(local));
 }
 
-inline void exec(str expr, object global = globals(), object local = object()) {
-    eval<eval_statements>(expr, global, local);
+inline void exec(const str &expr, object global = globals(), object local = object()) {
+    eval<eval_statements>(expr, std::move(global), std::move(local));
 }
 
 template <size_t N>
 void exec(const char (&s)[N], object global = globals(), object local = object()) {
-    eval<eval_statements>(s, global, local);
+    eval<eval_statements>(s, std::move(global), std::move(local));
 }
 
+#if defined(PYPY_VERSION)
+template <eval_mode mode = eval_statements>
+object eval_file(str, object, object) {
+    pybind11_fail("eval_file not supported in PyPy3. Use eval");
+}
+template <eval_mode mode = eval_statements>
+object eval_file(str, object) {
+    pybind11_fail("eval_file not supported in PyPy3. Use eval");
+}
+template <eval_mode mode = eval_statements>
+object eval_file(str) {
+    pybind11_fail("eval_file not supported in PyPy3. Use eval");
+}
+#else
 template <eval_mode mode = eval_statements>
 object eval_file(str fname, object global = globals(), object local = object()) {
-    if (!local)
+    if (!local) {
         local = global;
+    }
 
-    int start;
+    detail::ensure_builtins_in_globals(global);
+
+    int start = 0;
     switch (mode) {
-        case eval_expr:             start = Py_eval_input;   break;
-        case eval_single_statement: start = Py_single_input; break;
-        case eval_statements:       start = Py_file_input;   break;
-        default: pybind11_fail("invalid evaluation mode");
+        case eval_expr:
+            start = Py_eval_input;
+            break;
+        case eval_single_statement:
+            start = Py_single_input;
+            break;
+        case eval_statements:
+            start = Py_file_input;
+            break;
+        default:
+            pybind11_fail("invalid evaluation mode");
     }
 
     int closeFile = 1;
     std::string fname_str = (std::string) fname;
-#if PY_VERSION_HEX >= 0x03040000
     FILE *f = _Py_fopen_obj(fname.ptr(), "r");
-#elif PY_VERSION_HEX >= 0x03000000
-    FILE *f = _Py_fopen(fname.ptr(), "r");
-#else
-    /* No unicode support in open() :( */
-    auto fobj = reinterpret_steal<object>(PyFile_FromString(
-        const_cast<char *>(fname_str.c_str()),
-        const_cast<char*>("r")));
-    FILE *f = nullptr;
-    if (fobj)
-        f = PyFile_AsFile(fobj.ptr());
-    closeFile = 0;
-#endif
     if (!f) {
         PyErr_Clear();
         pybind11_fail("File \"" + fname_str + "\" could not be opened!");
     }
 
-#if PY_VERSION_HEX < 0x03000000 && defined(PYPY_VERSION)
-    PyObject *result = PyRun_File(f, fname_str.c_str(), start, global.ptr(),
-                                  local.ptr());
-    (void) closeFile;
-#else
-    PyObject *result = PyRun_FileEx(f, fname_str.c_str(), start, global.ptr(),
-                                    local.ptr(), closeFile);
-#endif
+    if (!global.contains("__file__")) {
+        global["__file__"] = std::move(fname);
+    }
 
-    if (!result)
+    PyObject *result
+        = PyRun_FileEx(f, fname_str.c_str(), start, global.ptr(), local.ptr(), closeFile);
+
+    if (!result) {
         throw error_already_set();
+    }
     return reinterpret_steal<object>(result);
 }
+#endif
 
-NAMESPACE_END(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/functional.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/functional.h`

 * *Files 22% similar despite different names*

```diff
@@ -6,96 +6,132 @@
     All rights reserved. Use of this source code is governed by a
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
 #include "pybind11.h"
+
 #include <functional>
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
 template <typename Return, typename... Args>
 struct type_caster<std::function<Return(Args...)>> {
     using type = std::function<Return(Args...)>;
     using retval_type = conditional_t<std::is_same<Return, void>::value, void_type, Return>;
-    using function_type = Return (*) (Args...);
+    using function_type = Return (*)(Args...);
 
 public:
     bool load(handle src, bool convert) {
         if (src.is_none()) {
             // Defer accepting None to other overloads (if we aren't in convert mode):
-            if (!convert) return false;
+            if (!convert) {
+                return false;
+            }
             return true;
         }
 
-        if (!isinstance<function>(src))
+        if (!isinstance<function>(src)) {
             return false;
+        }
 
         auto func = reinterpret_borrow<function>(src);
 
         /*
            When passing a C++ function as an argument to another C++
            function via Python, every function call would normally involve
            a full C++ -> Python -> C++ roundtrip, which can be prohibitive.
            Here, we try to at least detect the case where the function is
            stateless (i.e. function pointer or lambda function without
            captured variables), in which case the roundtrip can be avoided.
          */
         if (auto cfunc = func.cpp_function()) {
-            auto c = reinterpret_borrow<capsule>(PyCFunction_GET_SELF(cfunc.ptr()));
-            auto rec = (function_record *) c;
-
-            if (rec && rec->is_stateless &&
-                    same_type(typeid(function_type), *reinterpret_cast<const std::type_info *>(rec->data[1]))) {
-                struct capture { function_type f; };
-                value = ((capture *) &rec->data)->f;
-                return true;
+            auto *cfunc_self = PyCFunction_GET_SELF(cfunc.ptr());
+            if (cfunc_self == nullptr) {
+                PyErr_Clear();
+            } else if (isinstance<capsule>(cfunc_self)) {
+                auto c = reinterpret_borrow<capsule>(cfunc_self);
+
+                function_record *rec = nullptr;
+                // Check that we can safely reinterpret the capsule into a function_record
+                if (detail::is_function_record_capsule(c)) {
+                    rec = c.get_pointer<function_record>();
+                }
+
+                while (rec != nullptr) {
+                    if (rec->is_stateless
+                        && same_type(typeid(function_type),
+                                     *reinterpret_cast<const std::type_info *>(rec->data[1]))) {
+                        struct capture {
+                            function_type f;
+                        };
+                        value = ((capture *) &rec->data)->f;
+                        return true;
+                    }
+                    rec = rec->next;
+                }
             }
+            // PYPY segfaults here when passing builtin function like sum.
+            // Raising an fail exception here works to prevent the segfault, but only on gcc.
+            // See PR #1413 for full details
         }
 
         // ensure GIL is held during functor destruction
         struct func_handle {
             function f;
-            func_handle(function&& f_) : f(std::move(f_)) {}
-            func_handle(const func_handle&) = default;
+#if !(defined(_MSC_VER) && _MSC_VER == 1916 && defined(PYBIND11_CPP17))
+            // This triggers a syntax error under very special conditions (very weird indeed).
+            explicit
+#endif
+                func_handle(function &&f_) noexcept
+                : f(std::move(f_)) {
+            }
+            func_handle(const func_handle &f_) { operator=(f_); }
+            func_handle &operator=(const func_handle &f_) {
+                gil_scoped_acquire acq;
+                f = f_.f;
+                return *this;
+            }
             ~func_handle() {
                 gil_scoped_acquire acq;
                 function kill_f(std::move(f));
             }
         };
 
         // to emulate 'move initialization capture' in C++11
         struct func_wrapper {
             func_handle hfunc;
-            func_wrapper(func_handle&& hf): hfunc(std::move(hf)) {}
+            explicit func_wrapper(func_handle &&hf) noexcept : hfunc(std::move(hf)) {}
             Return operator()(Args... args) const {
                 gil_scoped_acquire acq;
-                object retval(hfunc.f(std::forward<Args>(args)...));
-                /* Visual studio 2015 parser issue: need parentheses around this expression */
-                return (retval.template cast<Return>());
+                // casts the returned object as a rvalue to the return type
+                return hfunc.f(std::forward<Args>(args)...).template cast<Return>();
             }
         };
 
         value = func_wrapper(func_handle(std::move(func)));
         return true;
     }
 
     template <typename Func>
     static handle cast(Func &&f_, return_value_policy policy, handle /* parent */) {
-        if (!f_)
-            return none().inc_ref();
+        if (!f_) {
+            return none().release();
+        }
 
         auto result = f_.template target<function_type>();
-        if (result)
+        if (result) {
             return cpp_function(*result, policy).release();
-        else
-            return cpp_function(std::forward<Func>(f_), policy).release();
+        }
+        return cpp_function(std::forward<Func>(f_), policy).release();
     }
 
-    PYBIND11_TYPE_CASTER(type, _("Callable[[") + concat(make_caster<Args>::name...) + _("], ")
-                               + make_caster<retval_type>::name + _("]"));
+    PYBIND11_TYPE_CASTER(type,
+                         const_name("Callable[[") + concat(make_caster<Args>::name...)
+                             + const_name("], ") + make_caster<retval_type>::name
+                             + const_name("]"));
 };
 
-NAMESPACE_END(detail)
-NAMESPACE_END(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/numpy.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/numpy.h`

 * *Files 15% similar despite different names*

```diff
@@ -7,43 +7,52 @@
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
 #include "pybind11.h"
 #include "complex.h"
-#include <numeric>
+
 #include <algorithm>
 #include <array>
+#include <cstdint>
 #include <cstdlib>
 #include <cstring>
+#include <functional>
+#include <numeric>
 #include <sstream>
 #include <string>
-#include <functional>
+#include <type_traits>
+#include <typeindex>
 #include <utility>
 #include <vector>
-#include <typeindex>
-
-#if defined(_MSC_VER)
-#  pragma warning(push)
-#  pragma warning(disable: 4127) // warning C4127: Conditional expression is constant
-#endif
 
 /* This will be true on all flat address space platforms and allows us to reduce the
    whole npy_intp / ssize_t / Py_intptr_t business down to just ssize_t for all size
    and dimension types (e.g. shape, strides, indexing), instead of inflicting this
    upon the library user. */
-static_assert(sizeof(ssize_t) == sizeof(Py_intptr_t), "ssize_t != Py_intptr_t");
+static_assert(sizeof(::pybind11::ssize_t) == sizeof(Py_intptr_t), "ssize_t != Py_intptr_t");
+static_assert(std::is_signed<Py_intptr_t>::value, "Py_intptr_t must be signed");
+// We now can reinterpret_cast between py::ssize_t and Py_intptr_t (MSVC + PyPy cares)
+
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_WARNING_DISABLE_MSVC(4127)
 
 class array; // Forward declaration
 
-NAMESPACE_BEGIN(detail)
-template <typename type, typename SFINAE = void> struct npy_format_descriptor;
+PYBIND11_NAMESPACE_BEGIN(detail)
+
+template <>
+struct handle_type_name<array> {
+    static constexpr auto name = const_name("numpy.ndarray");
+};
+
+template <typename type, typename SFINAE = void>
+struct npy_format_descriptor;
 
 struct PyArrayDescr_Proxy {
     PyObject_HEAD
     PyObject *typeobj;
     char kind;
     char type;
     char byteorder;
@@ -64,525 +73,711 @@
     ssize_t *strides;
     PyObject *base;
     PyObject *descr;
     int flags;
 };
 
 struct PyVoidScalarObject_Proxy {
-    PyObject_VAR_HEAD
-    char *obval;
+    PyObject_VAR_HEAD char *obval;
     PyArrayDescr_Proxy *descr;
     int flags;
     PyObject *base;
 };
 
 struct numpy_type_info {
-    PyObject* dtype_ptr;
+    PyObject *dtype_ptr;
     std::string format_str;
 };
 
 struct numpy_internals {
     std::unordered_map<std::type_index, numpy_type_info> registered_dtypes;
 
-    numpy_type_info *get_type_info(const std::type_info& tinfo, bool throw_if_missing = true) {
+    numpy_type_info *get_type_info(const std::type_info &tinfo, bool throw_if_missing = true) {
         auto it = registered_dtypes.find(std::type_index(tinfo));
-        if (it != registered_dtypes.end())
+        if (it != registered_dtypes.end()) {
             return &(it->second);
-        if (throw_if_missing)
+        }
+        if (throw_if_missing) {
             pybind11_fail(std::string("NumPy type info missing for ") + tinfo.name());
+        }
         return nullptr;
     }
 
-    template<typename T> numpy_type_info *get_type_info(bool throw_if_missing = true) {
+    template <typename T>
+    numpy_type_info *get_type_info(bool throw_if_missing = true) {
         return get_type_info(typeid(typename std::remove_cv<T>::type), throw_if_missing);
     }
 };
 
-inline PYBIND11_NOINLINE void load_numpy_internals(numpy_internals* &ptr) {
+PYBIND11_NOINLINE void load_numpy_internals(numpy_internals *&ptr) {
     ptr = &get_or_create_shared_data<numpy_internals>("_numpy_internals");
 }
 
-inline numpy_internals& get_numpy_internals() {
-    static numpy_internals* ptr = nullptr;
-    if (!ptr)
+inline numpy_internals &get_numpy_internals() {
+    static numpy_internals *ptr = nullptr;
+    if (!ptr) {
         load_numpy_internals(ptr);
+    }
     return *ptr;
 }
 
+template <typename T>
+struct same_size {
+    template <typename U>
+    using as = bool_constant<sizeof(T) == sizeof(U)>;
+};
+
+template <typename Concrete>
+constexpr int platform_lookup() {
+    return -1;
+}
+
+// Lookup a type according to its size, and return a value corresponding to the NumPy typenum.
+template <typename Concrete, typename T, typename... Ts, typename... Ints>
+constexpr int platform_lookup(int I, Ints... Is) {
+    return sizeof(Concrete) == sizeof(T) ? I : platform_lookup<Concrete, Ts...>(Is...);
+}
+
 struct npy_api {
     enum constants {
         NPY_ARRAY_C_CONTIGUOUS_ = 0x0001,
         NPY_ARRAY_F_CONTIGUOUS_ = 0x0002,
         NPY_ARRAY_OWNDATA_ = 0x0004,
         NPY_ARRAY_FORCECAST_ = 0x0010,
         NPY_ARRAY_ENSUREARRAY_ = 0x0040,
         NPY_ARRAY_ALIGNED_ = 0x0100,
         NPY_ARRAY_WRITEABLE_ = 0x0400,
         NPY_BOOL_ = 0,
-        NPY_BYTE_, NPY_UBYTE_,
-        NPY_SHORT_, NPY_USHORT_,
-        NPY_INT_, NPY_UINT_,
-        NPY_LONG_, NPY_ULONG_,
-        NPY_LONGLONG_, NPY_ULONGLONG_,
-        NPY_FLOAT_, NPY_DOUBLE_, NPY_LONGDOUBLE_,
-        NPY_CFLOAT_, NPY_CDOUBLE_, NPY_CLONGDOUBLE_,
+        NPY_BYTE_,
+        NPY_UBYTE_,
+        NPY_SHORT_,
+        NPY_USHORT_,
+        NPY_INT_,
+        NPY_UINT_,
+        NPY_LONG_,
+        NPY_ULONG_,
+        NPY_LONGLONG_,
+        NPY_ULONGLONG_,
+        NPY_FLOAT_,
+        NPY_DOUBLE_,
+        NPY_LONGDOUBLE_,
+        NPY_CFLOAT_,
+        NPY_CDOUBLE_,
+        NPY_CLONGDOUBLE_,
         NPY_OBJECT_ = 17,
-        NPY_STRING_, NPY_UNICODE_, NPY_VOID_
+        NPY_STRING_,
+        NPY_UNICODE_,
+        NPY_VOID_,
+        // Platform-dependent normalization
+        NPY_INT8_ = NPY_BYTE_,
+        NPY_UINT8_ = NPY_UBYTE_,
+        NPY_INT16_ = NPY_SHORT_,
+        NPY_UINT16_ = NPY_USHORT_,
+        // `npy_common.h` defines the integer aliases. In order, it checks:
+        // NPY_BITSOF_LONG, NPY_BITSOF_LONGLONG, NPY_BITSOF_INT, NPY_BITSOF_SHORT, NPY_BITSOF_CHAR
+        // and assigns the alias to the first matching size, so we should check in this order.
+        NPY_INT32_
+        = platform_lookup<std::int32_t, long, int, short>(NPY_LONG_, NPY_INT_, NPY_SHORT_),
+        NPY_UINT32_ = platform_lookup<std::uint32_t, unsigned long, unsigned int, unsigned short>(
+            NPY_ULONG_, NPY_UINT_, NPY_USHORT_),
+        NPY_INT64_
+        = platform_lookup<std::int64_t, long, long long, int>(NPY_LONG_, NPY_LONGLONG_, NPY_INT_),
+        NPY_UINT64_
+        = platform_lookup<std::uint64_t, unsigned long, unsigned long long, unsigned int>(
+            NPY_ULONG_, NPY_ULONGLONG_, NPY_UINT_),
     };
 
-    typedef struct {
+    struct PyArray_Dims {
         Py_intptr_t *ptr;
         int len;
-    } PyArray_Dims;
+    };
 
-    static npy_api& get() {
+    static npy_api &get() {
         static npy_api api = lookup();
         return api;
     }
 
     bool PyArray_Check_(PyObject *obj) const {
-        return (bool) PyObject_TypeCheck(obj, PyArray_Type_);
+        return PyObject_TypeCheck(obj, PyArray_Type_) != 0;
     }
     bool PyArrayDescr_Check_(PyObject *obj) const {
-        return (bool) PyObject_TypeCheck(obj, PyArrayDescr_Type_);
+        return PyObject_TypeCheck(obj, PyArrayDescr_Type_) != 0;
     }
 
     unsigned int (*PyArray_GetNDArrayCFeatureVersion_)();
     PyObject *(*PyArray_DescrFromType_)(int);
-    PyObject *(*PyArray_NewFromDescr_)
-        (PyTypeObject *, PyObject *, int, Py_intptr_t *,
-         Py_intptr_t *, void *, int, PyObject *);
+    PyObject *(*PyArray_NewFromDescr_)(PyTypeObject *,
+                                       PyObject *,
+                                       int,
+                                       Py_intptr_t const *,
+                                       Py_intptr_t const *,
+                                       void *,
+                                       int,
+                                       PyObject *);
+    // Unused. Not removed because that affects ABI of the class.
     PyObject *(*PyArray_DescrNewFromType_)(int);
     int (*PyArray_CopyInto_)(PyObject *, PyObject *);
     PyObject *(*PyArray_NewCopy_)(PyObject *, int);
     PyTypeObject *PyArray_Type_;
     PyTypeObject *PyVoidArrType_Type_;
     PyTypeObject *PyArrayDescr_Type_;
     PyObject *(*PyArray_DescrFromScalar_)(PyObject *);
-    PyObject *(*PyArray_FromAny_) (PyObject *, PyObject *, int, int, int, PyObject *);
-    int (*PyArray_DescrConverter_) (PyObject *, PyObject **);
-    bool (*PyArray_EquivTypes_) (PyObject *, PyObject *);
-    int (*PyArray_GetArrayParamsFromObject_)(PyObject *, PyObject *, char, PyObject **, int *,
-                                             Py_ssize_t *, PyObject **, PyObject *);
+    PyObject *(*PyArray_FromAny_)(PyObject *, PyObject *, int, int, int, PyObject *);
+    int (*PyArray_DescrConverter_)(PyObject *, PyObject **);
+    bool (*PyArray_EquivTypes_)(PyObject *, PyObject *);
+    int (*PyArray_GetArrayParamsFromObject_)(PyObject *,
+                                             PyObject *,
+                                             unsigned char,
+                                             PyObject **,
+                                             int *,
+                                             Py_intptr_t *,
+                                             PyObject **,
+                                             PyObject *);
     PyObject *(*PyArray_Squeeze_)(PyObject *);
+    // Unused. Not removed because that affects ABI of the class.
     int (*PyArray_SetBaseObject_)(PyObject *, PyObject *);
-    PyObject* (*PyArray_Resize_)(PyObject*, PyArray_Dims*, int, int);
+    PyObject *(*PyArray_Resize_)(PyObject *, PyArray_Dims *, int, int);
+    PyObject *(*PyArray_Newshape_)(PyObject *, PyArray_Dims *, int);
+    PyObject *(*PyArray_View_)(PyObject *, PyObject *, PyObject *);
+
 private:
     enum functions {
         API_PyArray_GetNDArrayCFeatureVersion = 211,
         API_PyArray_Type = 2,
         API_PyArrayDescr_Type = 3,
         API_PyVoidArrType_Type = 39,
         API_PyArray_DescrFromType = 45,
         API_PyArray_DescrFromScalar = 57,
         API_PyArray_FromAny = 69,
         API_PyArray_Resize = 80,
         API_PyArray_CopyInto = 82,
         API_PyArray_NewCopy = 85,
         API_PyArray_NewFromDescr = 94,
-        API_PyArray_DescrNewFromType = 9,
+        API_PyArray_DescrNewFromType = 96,
+        API_PyArray_Newshape = 135,
+        API_PyArray_Squeeze = 136,
+        API_PyArray_View = 137,
         API_PyArray_DescrConverter = 174,
         API_PyArray_EquivTypes = 182,
         API_PyArray_GetArrayParamsFromObject = 278,
-        API_PyArray_Squeeze = 136,
         API_PyArray_SetBaseObject = 282
     };
 
     static npy_api lookup() {
-        module m = module::import("numpy.core.multiarray");
+        module_ m = module_::import("numpy.core.multiarray");
         auto c = m.attr("_ARRAY_API");
-#if PY_MAJOR_VERSION >= 3
-        void **api_ptr = (void **) PyCapsule_GetPointer(c.ptr(), NULL);
-#else
-        void **api_ptr = (void **) PyCObject_AsVoidPtr(c.ptr());
-#endif
+        void **api_ptr = (void **) PyCapsule_GetPointer(c.ptr(), nullptr);
         npy_api api;
 #define DECL_NPY_API(Func) api.Func##_ = (decltype(api.Func##_)) api_ptr[API_##Func];
         DECL_NPY_API(PyArray_GetNDArrayCFeatureVersion);
-        if (api.PyArray_GetNDArrayCFeatureVersion_() < 0x7)
+        if (api.PyArray_GetNDArrayCFeatureVersion_() < 0x7) {
             pybind11_fail("pybind11 numpy support requires numpy >= 1.7.0");
+        }
         DECL_NPY_API(PyArray_Type);
         DECL_NPY_API(PyVoidArrType_Type);
         DECL_NPY_API(PyArrayDescr_Type);
         DECL_NPY_API(PyArray_DescrFromType);
         DECL_NPY_API(PyArray_DescrFromScalar);
         DECL_NPY_API(PyArray_FromAny);
         DECL_NPY_API(PyArray_Resize);
         DECL_NPY_API(PyArray_CopyInto);
         DECL_NPY_API(PyArray_NewCopy);
         DECL_NPY_API(PyArray_NewFromDescr);
         DECL_NPY_API(PyArray_DescrNewFromType);
+        DECL_NPY_API(PyArray_Newshape);
+        DECL_NPY_API(PyArray_Squeeze);
+        DECL_NPY_API(PyArray_View);
         DECL_NPY_API(PyArray_DescrConverter);
         DECL_NPY_API(PyArray_EquivTypes);
         DECL_NPY_API(PyArray_GetArrayParamsFromObject);
-        DECL_NPY_API(PyArray_Squeeze);
         DECL_NPY_API(PyArray_SetBaseObject);
+
 #undef DECL_NPY_API
         return api;
     }
 };
 
-inline PyArray_Proxy* array_proxy(void* ptr) {
-    return reinterpret_cast<PyArray_Proxy*>(ptr);
-}
+inline PyArray_Proxy *array_proxy(void *ptr) { return reinterpret_cast<PyArray_Proxy *>(ptr); }
 
-inline const PyArray_Proxy* array_proxy(const void* ptr) {
-    return reinterpret_cast<const PyArray_Proxy*>(ptr);
+inline const PyArray_Proxy *array_proxy(const void *ptr) {
+    return reinterpret_cast<const PyArray_Proxy *>(ptr);
 }
 
-inline PyArrayDescr_Proxy* array_descriptor_proxy(PyObject* ptr) {
-   return reinterpret_cast<PyArrayDescr_Proxy*>(ptr);
+inline PyArrayDescr_Proxy *array_descriptor_proxy(PyObject *ptr) {
+    return reinterpret_cast<PyArrayDescr_Proxy *>(ptr);
 }
 
-inline const PyArrayDescr_Proxy* array_descriptor_proxy(const PyObject* ptr) {
-   return reinterpret_cast<const PyArrayDescr_Proxy*>(ptr);
+inline const PyArrayDescr_Proxy *array_descriptor_proxy(const PyObject *ptr) {
+    return reinterpret_cast<const PyArrayDescr_Proxy *>(ptr);
 }
 
-inline bool check_flags(const void* ptr, int flag) {
+inline bool check_flags(const void *ptr, int flag) {
     return (flag == (array_proxy(ptr)->flags & flag));
 }
 
-template <typename T> struct is_std_array : std::false_type { };
-template <typename T, size_t N> struct is_std_array<std::array<T, N>> : std::true_type { };
-template <typename T> struct is_complex : std::false_type { };
-template <typename T> struct is_complex<std::complex<T>> : std::true_type { };
+template <typename T>
+struct is_std_array : std::false_type {};
+template <typename T, size_t N>
+struct is_std_array<std::array<T, N>> : std::true_type {};
+template <typename T>
+struct is_complex : std::false_type {};
+template <typename T>
+struct is_complex<std::complex<T>> : std::true_type {};
 
-template <typename T> struct array_info_scalar {
-    typedef T type;
+template <typename T>
+struct array_info_scalar {
+    using type = T;
     static constexpr bool is_array = false;
     static constexpr bool is_empty = false;
-    static constexpr auto extents = _("");
-    static void append_extents(list& /* shape */) { }
+    static constexpr auto extents = const_name("");
+    static void append_extents(list & /* shape */) {}
 };
 // Computes underlying type and a comma-separated list of extents for array
 // types (any mix of std::array and built-in arrays). An array of char is
 // treated as scalar because it gets special handling.
-template <typename T> struct array_info : array_info_scalar<T> { };
-template <typename T, size_t N> struct array_info<std::array<T, N>> {
+template <typename T>
+struct array_info : array_info_scalar<T> {};
+template <typename T, size_t N>
+struct array_info<std::array<T, N>> {
     using type = typename array_info<T>::type;
     static constexpr bool is_array = true;
     static constexpr bool is_empty = (N == 0) || array_info<T>::is_empty;
     static constexpr size_t extent = N;
 
     // appends the extents to shape
-    static void append_extents(list& shape) {
+    static void append_extents(list &shape) {
         shape.append(N);
         array_info<T>::append_extents(shape);
     }
 
-    static constexpr auto extents = _<array_info<T>::is_array>(
-        concat(_<N>(), array_info<T>::extents), _<N>()
-    );
+    static constexpr auto extents = const_name<array_info<T>::is_array>(
+        concat(const_name<N>(), array_info<T>::extents), const_name<N>());
 };
 // For numpy we have special handling for arrays of characters, so we don't include
 // the size in the array extents.
-template <size_t N> struct array_info<char[N]> : array_info_scalar<char[N]> { };
-template <size_t N> struct array_info<std::array<char, N>> : array_info_scalar<std::array<char, N>> { };
-template <typename T, size_t N> struct array_info<T[N]> : array_info<std::array<T, N>> { };
-template <typename T> using remove_all_extents_t = typename array_info<T>::type;
-
-template <typename T> using is_pod_struct = all_of<
-    std::is_standard_layout<T>,     // since we're accessing directly in memory we need a standard layout type
-#if !defined(__GNUG__) || defined(_LIBCPP_VERSION) || defined(_GLIBCXX_USE_CXX11_ABI)
-    // _GLIBCXX_USE_CXX11_ABI indicates that we're using libstdc++ from GCC 5 or newer, independent
-    // of the actual compiler (Clang can also use libstdc++, but it always defines __GNUC__ == 4).
-    std::is_trivially_copyable<T>,
+template <size_t N>
+struct array_info<char[N]> : array_info_scalar<char[N]> {};
+template <size_t N>
+struct array_info<std::array<char, N>> : array_info_scalar<std::array<char, N>> {};
+template <typename T, size_t N>
+struct array_info<T[N]> : array_info<std::array<T, N>> {};
+template <typename T>
+using remove_all_extents_t = typename array_info<T>::type;
+
+template <typename T>
+using is_pod_struct
+    = all_of<std::is_standard_layout<T>, // since we're accessing directly in memory
+                                         // we need a standard layout type
+#if defined(__GLIBCXX__)                                                                          \
+    && (__GLIBCXX__ < 20150422 || __GLIBCXX__ == 20150426 || __GLIBCXX__ == 20150623              \
+        || __GLIBCXX__ == 20150626 || __GLIBCXX__ == 20160803)
+             // libstdc++ < 5 (including versions 4.8.5, 4.9.3 and 4.9.4 which were released after
+             // 5) don't implement is_trivially_copyable, so approximate it
+             std::is_trivially_destructible<T>,
+             satisfies_any_of<T, std::has_trivial_copy_constructor, std::has_trivial_copy_assign>,
 #else
-    // GCC 4 doesn't implement is_trivially_copyable, so approximate it
-    std::is_trivially_destructible<T>,
-    satisfies_any_of<T, std::has_trivial_copy_constructor, std::has_trivial_copy_assign>,
+             std::is_trivially_copyable<T>,
 #endif
-    satisfies_none_of<T, std::is_reference, std::is_array, is_std_array, std::is_arithmetic, is_complex, std::is_enum>
->;
+             satisfies_none_of<T,
+                               std::is_reference,
+                               std::is_array,
+                               is_std_array,
+                               std::is_arithmetic,
+                               is_complex,
+                               std::is_enum>>;
 
-template <ssize_t Dim = 0, typename Strides> ssize_t byte_offset_unsafe(const Strides &) { return 0; }
+// Replacement for std::is_pod (deprecated in C++20)
+template <typename T>
+using is_pod = all_of<std::is_standard_layout<T>, std::is_trivial<T>>;
+
+template <ssize_t Dim = 0, typename Strides>
+ssize_t byte_offset_unsafe(const Strides &) {
+    return 0;
+}
 template <ssize_t Dim = 0, typename Strides, typename... Ix>
 ssize_t byte_offset_unsafe(const Strides &strides, ssize_t i, Ix... index) {
     return i * strides[Dim] + byte_offset_unsafe<Dim + 1>(strides, index...);
 }
 
 /**
  * Proxy class providing unsafe, unchecked const access to array data.  This is constructed through
- * the `unchecked<T, N>()` method of `array` or the `unchecked<N>()` method of `array_t<T>`.  `Dims`
+ * the `unchecked<T, N>()` method of `array` or the `unchecked<N>()` method of `array_t<T>`. `Dims`
  * will be -1 for dimensions determined at runtime.
  */
 template <typename T, ssize_t Dims>
 class unchecked_reference {
 protected:
     static constexpr bool Dynamic = Dims < 0;
     const unsigned char *data_;
     // Storing the shape & strides in local variables (i.e. these arrays) allows the compiler to
     // make large performance gains on big, nested loops, but requires compile-time dimensions
-    conditional_t<Dynamic, const ssize_t *, std::array<ssize_t, (size_t) Dims>>
-            shape_, strides_;
+    conditional_t<Dynamic, const ssize_t *, std::array<ssize_t, (size_t) Dims>> shape_, strides_;
     const ssize_t dims_;
 
     friend class pybind11::array;
     // Constructor for compile-time dimensions:
     template <bool Dyn = Dynamic>
-    unchecked_reference(const void *data, const ssize_t *shape, const ssize_t *strides, enable_if_t<!Dyn, ssize_t>)
-    : data_{reinterpret_cast<const unsigned char *>(data)}, dims_{Dims} {
+    unchecked_reference(const void *data,
+                        const ssize_t *shape,
+                        const ssize_t *strides,
+                        enable_if_t<!Dyn, ssize_t>)
+        : data_{reinterpret_cast<const unsigned char *>(data)}, dims_{Dims} {
         for (size_t i = 0; i < (size_t) dims_; i++) {
             shape_[i] = shape[i];
             strides_[i] = strides[i];
         }
     }
     // Constructor for runtime dimensions:
     template <bool Dyn = Dynamic>
-    unchecked_reference(const void *data, const ssize_t *shape, const ssize_t *strides, enable_if_t<Dyn, ssize_t> dims)
-    : data_{reinterpret_cast<const unsigned char *>(data)}, shape_{shape}, strides_{strides}, dims_{dims} {}
+    unchecked_reference(const void *data,
+                        const ssize_t *shape,
+                        const ssize_t *strides,
+                        enable_if_t<Dyn, ssize_t> dims)
+        : data_{reinterpret_cast<const unsigned char *>(data)}, shape_{shape}, strides_{strides},
+          dims_{dims} {}
 
 public:
     /**
      * Unchecked const reference access to data at the given indices.  For a compile-time known
      * number of dimensions, this requires the correct number of arguments; for run-time
      * dimensionality, this is not checked (and so is up to the caller to use safely).
      */
-    template <typename... Ix> const T &operator()(Ix... index) const {
+    template <typename... Ix>
+    const T &operator()(Ix... index) const {
         static_assert(ssize_t{sizeof...(Ix)} == Dims || Dynamic,
-                "Invalid number of indices for unchecked array reference");
-        return *reinterpret_cast<const T *>(data_ + byte_offset_unsafe(strides_, ssize_t(index)...));
+                      "Invalid number of indices for unchecked array reference");
+        return *reinterpret_cast<const T *>(data_
+                                            + byte_offset_unsafe(strides_, ssize_t(index)...));
     }
     /**
      * Unchecked const reference access to data; this operator only participates if the reference
      * is to a 1-dimensional array.  When present, this is exactly equivalent to `obj(index)`.
      */
     template <ssize_t D = Dims, typename = enable_if_t<D == 1 || Dynamic>>
-    const T &operator[](ssize_t index) const { return operator()(index); }
+    const T &operator[](ssize_t index) const {
+        return operator()(index);
+    }
 
     /// Pointer access to the data at the given indices.
-    template <typename... Ix> const T *data(Ix... ix) const { return &operator()(ssize_t(ix)...); }
+    template <typename... Ix>
+    const T *data(Ix... ix) const {
+        return &operator()(ssize_t(ix)...);
+    }
 
     /// Returns the item size, i.e. sizeof(T)
     constexpr static ssize_t itemsize() { return sizeof(T); }
 
     /// Returns the shape (i.e. size) of dimension `dim`
     ssize_t shape(ssize_t dim) const { return shape_[(size_t) dim]; }
 
     /// Returns the number of dimensions of the array
     ssize_t ndim() const { return dims_; }
 
-    /// Returns the total number of elements in the referenced array, i.e. the product of the shapes
+    /// Returns the total number of elements in the referenced array, i.e. the product of the
+    /// shapes
     template <bool Dyn = Dynamic>
     enable_if_t<!Dyn, ssize_t> size() const {
-        return std::accumulate(shape_.begin(), shape_.end(), (ssize_t) 1, std::multiplies<ssize_t>());
+        return std::accumulate(
+            shape_.begin(), shape_.end(), (ssize_t) 1, std::multiplies<ssize_t>());
     }
     template <bool Dyn = Dynamic>
     enable_if_t<Dyn, ssize_t> size() const {
         return std::accumulate(shape_, shape_ + ndim(), (ssize_t) 1, std::multiplies<ssize_t>());
     }
 
-    /// Returns the total number of bytes used by the referenced data.  Note that the actual span in
-    /// memory may be larger if the referenced array has non-contiguous strides (e.g. for a slice).
-    ssize_t nbytes() const {
-        return size() * itemsize();
-    }
+    /// Returns the total number of bytes used by the referenced data.  Note that the actual span
+    /// in memory may be larger if the referenced array has non-contiguous strides (e.g. for a
+    /// slice).
+    ssize_t nbytes() const { return size() * itemsize(); }
 };
 
 template <typename T, ssize_t Dims>
 class unchecked_mutable_reference : public unchecked_reference<T, Dims> {
     friend class pybind11::array;
     using ConstBase = unchecked_reference<T, Dims>;
     using ConstBase::ConstBase;
     using ConstBase::Dynamic;
+
 public:
+    // Bring in const-qualified versions from base class
+    using ConstBase::operator();
+    using ConstBase::operator[];
+
     /// Mutable, unchecked access to data at the given indices.
-    template <typename... Ix> T& operator()(Ix... index) {
+    template <typename... Ix>
+    T &operator()(Ix... index) {
         static_assert(ssize_t{sizeof...(Ix)} == Dims || Dynamic,
-                "Invalid number of indices for unchecked array reference");
+                      "Invalid number of indices for unchecked array reference");
         return const_cast<T &>(ConstBase::operator()(index...));
     }
     /**
      * Mutable, unchecked access data at the given index; this operator only participates if the
      * reference is to a 1-dimensional array (or has runtime dimensions).  When present, this is
      * exactly equivalent to `obj(index)`.
      */
     template <ssize_t D = Dims, typename = enable_if_t<D == 1 || Dynamic>>
-    T &operator[](ssize_t index) { return operator()(index); }
+    T &operator[](ssize_t index) {
+        return operator()(index);
+    }
 
     /// Mutable pointer access to the data at the given indices.
-    template <typename... Ix> T *mutable_data(Ix... ix) { return &operator()(ssize_t(ix)...); }
+    template <typename... Ix>
+    T *mutable_data(Ix... ix) {
+        return &operator()(ssize_t(ix)...);
+    }
 };
 
 template <typename T, ssize_t Dim>
 struct type_caster<unchecked_reference<T, Dim>> {
-    static_assert(Dim == 0 && Dim > 0 /* always fail */, "unchecked array proxy object is not castable");
+    static_assert(Dim == 0 && Dim > 0 /* always fail */,
+                  "unchecked array proxy object is not castable");
 };
 template <typename T, ssize_t Dim>
-struct type_caster<unchecked_mutable_reference<T, Dim>> : type_caster<unchecked_reference<T, Dim>> {};
+struct type_caster<unchecked_mutable_reference<T, Dim>>
+    : type_caster<unchecked_reference<T, Dim>> {};
 
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
 
 class dtype : public object {
 public:
-    PYBIND11_OBJECT_DEFAULT(dtype, object, detail::npy_api::get().PyArrayDescr_Check_);
+    PYBIND11_OBJECT_DEFAULT(dtype, object, detail::npy_api::get().PyArrayDescr_Check_)
 
     explicit dtype(const buffer_info &info) {
-        dtype descr(_dtype_from_pep3118()(PYBIND11_STR_TYPE(info.format)));
+        dtype descr(_dtype_from_pep3118()(pybind11::str(info.format)));
         // If info.itemsize == 0, use the value calculated from the format string
-        m_ptr = descr.strip_padding(info.itemsize ? info.itemsize : descr.itemsize()).release().ptr();
+        m_ptr = descr.strip_padding(info.itemsize != 0 ? info.itemsize : descr.itemsize())
+                    .release()
+                    .ptr();
     }
 
-    explicit dtype(const std::string &format) {
-        m_ptr = from_args(pybind11::str(format)).release().ptr();
-    }
+    explicit dtype(const pybind11::str &format) : dtype(from_args(format)) {}
+
+    explicit dtype(const std::string &format) : dtype(pybind11::str(format)) {}
 
-    dtype(const char *format) : dtype(std::string(format)) { }
+    explicit dtype(const char *format) : dtype(pybind11::str(format)) {}
 
     dtype(list names, list formats, list offsets, ssize_t itemsize) {
         dict args;
-        args["names"] = names;
-        args["formats"] = formats;
-        args["offsets"] = offsets;
+        args["names"] = std::move(names);
+        args["formats"] = std::move(formats);
+        args["offsets"] = std::move(offsets);
         args["itemsize"] = pybind11::int_(itemsize);
         m_ptr = from_args(args).release().ptr();
     }
 
+    explicit dtype(int typenum)
+        : object(detail::npy_api::get().PyArray_DescrFromType_(typenum), stolen_t{}) {
+        if (m_ptr == nullptr) {
+            throw error_already_set();
+        }
+    }
+
     /// This is essentially the same as calling numpy.dtype(args) in Python.
-    static dtype from_args(object args) {
+    static dtype from_args(const object &args) {
         PyObject *ptr = nullptr;
-        if (!detail::npy_api::get().PyArray_DescrConverter_(args.ptr(), &ptr) || !ptr)
+        if ((detail::npy_api::get().PyArray_DescrConverter_(args.ptr(), &ptr) == 0) || !ptr) {
             throw error_already_set();
+        }
         return reinterpret_steal<dtype>(ptr);
     }
 
     /// Return dtype associated with a C++ type.
-    template <typename T> static dtype of() {
+    template <typename T>
+    static dtype of() {
         return detail::npy_format_descriptor<typename std::remove_cv<T>::type>::dtype();
     }
 
     /// Size of the data type in bytes.
-    ssize_t itemsize() const {
-        return detail::array_descriptor_proxy(m_ptr)->elsize;
-    }
+    ssize_t itemsize() const { return detail::array_descriptor_proxy(m_ptr)->elsize; }
 
     /// Returns true for structured data types.
-    bool has_fields() const {
-        return detail::array_descriptor_proxy(m_ptr)->names != nullptr;
+    bool has_fields() const { return detail::array_descriptor_proxy(m_ptr)->names != nullptr; }
+
+    /// Single-character code for dtype's kind.
+    /// For example, floating point types are 'f' and integral types are 'i'.
+    char kind() const { return detail::array_descriptor_proxy(m_ptr)->kind; }
+
+    /// Single-character for dtype's type.
+    /// For example, ``float`` is 'f', ``double`` 'd', ``int`` 'i', and ``long`` 'l'.
+    char char_() const {
+        // Note: The signature, `dtype::char_` follows the naming of NumPy's
+        // public Python API (i.e., ``dtype.char``), rather than its internal
+        // C API (``PyArray_Descr::type``).
+        return detail::array_descriptor_proxy(m_ptr)->type;
     }
 
-    /// Single-character type code.
-    char kind() const {
-        return detail::array_descriptor_proxy(m_ptr)->kind;
+    /// type number of dtype.
+    int num() const {
+        // Note: The signature, `dtype::num` follows the naming of NumPy's public
+        // Python API (i.e., ``dtype.num``), rather than its internal
+        // C API (``PyArray_Descr::type_num``).
+        return detail::array_descriptor_proxy(m_ptr)->type_num;
     }
 
+    /// Single character for byteorder
+    char byteorder() const { return detail::array_descriptor_proxy(m_ptr)->byteorder; }
+
+    /// Alignment of the data type
+    int alignment() const { return detail::array_descriptor_proxy(m_ptr)->alignment; }
+
+    /// Flags for the array descriptor
+    char flags() const { return detail::array_descriptor_proxy(m_ptr)->flags; }
+
 private:
     static object _dtype_from_pep3118() {
-        static PyObject *obj = module::import("numpy.core._internal")
-            .attr("_dtype_from_pep3118").cast<object>().release().ptr();
+        static PyObject *obj = module_::import("numpy.core._internal")
+                                   .attr("_dtype_from_pep3118")
+                                   .cast<object>()
+                                   .release()
+                                   .ptr();
         return reinterpret_borrow<object>(obj);
     }
 
     dtype strip_padding(ssize_t itemsize) {
         // Recursively strip all void fields with empty names that are generated for
         // padding fields (as of NumPy v1.11).
-        if (!has_fields())
+        if (!has_fields()) {
             return *this;
+        }
 
-        struct field_descr { PYBIND11_STR_TYPE name; object format; pybind11::int_ offset; };
+        struct field_descr {
+            pybind11::str name;
+            object format;
+            pybind11::int_ offset;
+            field_descr(pybind11::str &&name, object &&format, pybind11::int_ &&offset)
+                : name{std::move(name)}, format{std::move(format)}, offset{std::move(offset)} {};
+        };
+        auto field_dict = attr("fields").cast<dict>();
         std::vector<field_descr> field_descriptors;
+        field_descriptors.reserve(field_dict.size());
 
-        for (auto field : attr("fields").attr("items")()) {
+        for (auto field : field_dict.attr("items")()) {
             auto spec = field.cast<tuple>();
             auto name = spec[0].cast<pybind11::str>();
-            auto format = spec[1].cast<tuple>()[0].cast<dtype>();
-            auto offset = spec[1].cast<tuple>()[1].cast<pybind11::int_>();
-            if (!len(name) && format.kind() == 'V')
+            auto spec_fo = spec[1].cast<tuple>();
+            auto format = spec_fo[0].cast<dtype>();
+            auto offset = spec_fo[1].cast<pybind11::int_>();
+            if ((len(name) == 0u) && format.kind() == 'V') {
                 continue;
-            field_descriptors.push_back({(PYBIND11_STR_TYPE) name, format.strip_padding(format.itemsize()), offset});
+            }
+            field_descriptors.emplace_back(
+                std::move(name), format.strip_padding(format.itemsize()), std::move(offset));
         }
 
-        std::sort(field_descriptors.begin(), field_descriptors.end(),
-                  [](const field_descr& a, const field_descr& b) {
+        std::sort(field_descriptors.begin(),
+                  field_descriptors.end(),
+                  [](const field_descr &a, const field_descr &b) {
                       return a.offset.cast<int>() < b.offset.cast<int>();
                   });
 
         list names, formats, offsets;
-        for (auto& descr : field_descriptors) {
-            names.append(descr.name);
-            formats.append(descr.format);
-            offsets.append(descr.offset);
+        for (auto &descr : field_descriptors) {
+            names.append(std::move(descr.name));
+            formats.append(std::move(descr.format));
+            offsets.append(std::move(descr.offset));
         }
-        return dtype(names, formats, offsets, itemsize);
+        return dtype(std::move(names), std::move(formats), std::move(offsets), itemsize);
     }
 };
 
 class array : public buffer {
 public:
     PYBIND11_OBJECT_CVT(array, buffer, detail::npy_api::get().PyArray_Check_, raw_array)
 
     enum {
         c_style = detail::npy_api::NPY_ARRAY_C_CONTIGUOUS_,
         f_style = detail::npy_api::NPY_ARRAY_F_CONTIGUOUS_,
         forcecast = detail::npy_api::NPY_ARRAY_FORCECAST_
     };
 
-    array() : array({{0}}, static_cast<const double *>(nullptr)) {}
+    array() : array(0, static_cast<const double *>(nullptr)) {}
 
     using ShapeContainer = detail::any_container<ssize_t>;
     using StridesContainer = detail::any_container<ssize_t>;
 
     // Constructs an array taking shape/strides from arbitrary container types
-    array(const pybind11::dtype &dt, ShapeContainer shape, StridesContainer strides,
-          const void *ptr = nullptr, handle base = handle()) {
+    array(const pybind11::dtype &dt,
+          ShapeContainer shape,
+          StridesContainer strides,
+          const void *ptr = nullptr,
+          handle base = handle()) {
 
-        if (strides->empty())
-            *strides = c_strides(*shape, dt.itemsize());
+        if (strides->empty()) {
+            *strides = detail::c_strides(*shape, dt.itemsize());
+        }
 
         auto ndim = shape->size();
-        if (ndim != strides->size())
+        if (ndim != strides->size()) {
             pybind11_fail("NumPy: shape ndim doesn't match strides ndim");
+        }
         auto descr = dt;
 
         int flags = 0;
         if (base && ptr) {
-            if (isinstance<array>(base))
+            if (isinstance<array>(base)) {
                 /* Copy flags from base (except ownership bit) */
-                flags = reinterpret_borrow<array>(base).flags() & ~detail::npy_api::NPY_ARRAY_OWNDATA_;
-            else
+                flags = reinterpret_borrow<array>(base).flags()
+                        & ~detail::npy_api::NPY_ARRAY_OWNDATA_;
+            } else {
                 /* Writable by default, easy to downgrade later on if needed */
                 flags = detail::npy_api::NPY_ARRAY_WRITEABLE_;
+            }
         }
 
         auto &api = detail::npy_api::get();
         auto tmp = reinterpret_steal<object>(api.PyArray_NewFromDescr_(
-            api.PyArray_Type_, descr.release().ptr(), (int) ndim, shape->data(), strides->data(),
-            const_cast<void *>(ptr), flags, nullptr));
-        if (!tmp)
+            api.PyArray_Type_,
+            descr.release().ptr(),
+            (int) ndim,
+            // Use reinterpret_cast for PyPy on Windows (remove if fixed, checked on 7.3.1)
+            reinterpret_cast<Py_intptr_t *>(shape->data()),
+            reinterpret_cast<Py_intptr_t *>(strides->data()),
+            const_cast<void *>(ptr),
+            flags,
+            nullptr));
+        if (!tmp) {
             throw error_already_set();
+        }
         if (ptr) {
             if (base) {
                 api.PyArray_SetBaseObject_(tmp.ptr(), base.inc_ref().ptr());
             } else {
-                tmp = reinterpret_steal<object>(api.PyArray_NewCopy_(tmp.ptr(), -1 /* any order */));
+                tmp = reinterpret_steal<object>(
+                    api.PyArray_NewCopy_(tmp.ptr(), -1 /* any order */));
             }
         }
         m_ptr = tmp.release().ptr();
     }
 
-    array(const pybind11::dtype &dt, ShapeContainer shape, const void *ptr = nullptr, handle base = handle())
-        : array(dt, std::move(shape), {}, ptr, base) { }
-
-    template <typename T, typename = detail::enable_if_t<std::is_integral<T>::value && !std::is_same<bool, T>::value>>
+    array(const pybind11::dtype &dt,
+          ShapeContainer shape,
+          const void *ptr = nullptr,
+          handle base = handle())
+        : array(dt, std::move(shape), {}, ptr, base) {}
+
+    template <typename T,
+              typename
+              = detail::enable_if_t<std::is_integral<T>::value && !std::is_same<bool, T>::value>>
     array(const pybind11::dtype &dt, T count, const void *ptr = nullptr, handle base = handle())
-        : array(dt, {{count}}, ptr, base) { }
+        : array(dt, {{count}}, ptr, base) {}
 
     template <typename T>
     array(ShapeContainer shape, StridesContainer strides, const T *ptr, handle base = handle())
-        : array(pybind11::dtype::of<T>(), std::move(shape), std::move(strides), ptr, base) { }
+        : array(pybind11::dtype::of<T>(), std::move(shape), std::move(strides), ptr, base) {}
 
     template <typename T>
     array(ShapeContainer shape, const T *ptr, handle base = handle())
-        : array(std::move(shape), {}, ptr, base) { }
+        : array(std::move(shape), {}, ptr, base) {}
 
     template <typename T>
-    explicit array(ssize_t count, const T *ptr, handle base = handle()) : array({count}, {}, ptr, base) { }
+    explicit array(ssize_t count, const T *ptr, handle base = handle())
+        : array({count}, {}, ptr, base) {}
 
-    explicit array(const buffer_info &info)
-    : array(pybind11::dtype(info), info.shape, info.strides, info.ptr) { }
+    explicit array(const buffer_info &info, handle base = handle())
+        : array(pybind11::dtype(info), info.shape, info.strides, info.ptr, base) {}
 
     /// Array descriptor (dtype)
     pybind11::dtype dtype() const {
         return reinterpret_borrow<pybind11::dtype>(detail::array_proxy(m_ptr)->descr);
     }
 
     /// Total number of elements
@@ -592,202 +787,222 @@
 
     /// Byte size of a single element
     ssize_t itemsize() const {
         return detail::array_descriptor_proxy(detail::array_proxy(m_ptr)->descr)->elsize;
     }
 
     /// Total number of bytes
-    ssize_t nbytes() const {
-        return size() * itemsize();
-    }
+    ssize_t nbytes() const { return size() * itemsize(); }
 
     /// Number of dimensions
-    ssize_t ndim() const {
-        return detail::array_proxy(m_ptr)->nd;
-    }
+    ssize_t ndim() const { return detail::array_proxy(m_ptr)->nd; }
 
     /// Base object
-    object base() const {
-        return reinterpret_borrow<object>(detail::array_proxy(m_ptr)->base);
-    }
+    object base() const { return reinterpret_borrow<object>(detail::array_proxy(m_ptr)->base); }
 
     /// Dimensions of the array
-    const ssize_t* shape() const {
-        return detail::array_proxy(m_ptr)->dimensions;
-    }
+    const ssize_t *shape() const { return detail::array_proxy(m_ptr)->dimensions; }
 
     /// Dimension along a given axis
     ssize_t shape(ssize_t dim) const {
-        if (dim >= ndim())
+        if (dim >= ndim()) {
             fail_dim_check(dim, "invalid axis");
+        }
         return shape()[dim];
     }
 
     /// Strides of the array
-    const ssize_t* strides() const {
-        return detail::array_proxy(m_ptr)->strides;
-    }
+    const ssize_t *strides() const { return detail::array_proxy(m_ptr)->strides; }
 
     /// Stride along a given axis
     ssize_t strides(ssize_t dim) const {
-        if (dim >= ndim())
+        if (dim >= ndim()) {
             fail_dim_check(dim, "invalid axis");
+        }
         return strides()[dim];
     }
 
     /// Return the NumPy array flags
-    int flags() const {
-        return detail::array_proxy(m_ptr)->flags;
-    }
+    int flags() const { return detail::array_proxy(m_ptr)->flags; }
 
     /// If set, the array is writeable (otherwise the buffer is read-only)
     bool writeable() const {
         return detail::check_flags(m_ptr, detail::npy_api::NPY_ARRAY_WRITEABLE_);
     }
 
     /// If set, the array owns the data (will be freed when the array is deleted)
     bool owndata() const {
         return detail::check_flags(m_ptr, detail::npy_api::NPY_ARRAY_OWNDATA_);
     }
 
     /// Pointer to the contained data. If index is not provided, points to the
     /// beginning of the buffer. May throw if the index would lead to out of bounds access.
-    template<typename... Ix> const void* data(Ix... index) const {
+    template <typename... Ix>
+    const void *data(Ix... index) const {
         return static_cast<const void *>(detail::array_proxy(m_ptr)->data + offset_at(index...));
     }
 
     /// Mutable pointer to the contained data. If index is not provided, points to the
     /// beginning of the buffer. May throw if the index would lead to out of bounds access.
     /// May throw if the array is not writeable.
-    template<typename... Ix> void* mutable_data(Ix... index) {
+    template <typename... Ix>
+    void *mutable_data(Ix... index) {
         check_writeable();
         return static_cast<void *>(detail::array_proxy(m_ptr)->data + offset_at(index...));
     }
 
     /// Byte offset from beginning of the array to a given index (full or partial).
     /// May throw if the index would lead to out of bounds access.
-    template<typename... Ix> ssize_t offset_at(Ix... index) const {
-        if ((ssize_t) sizeof...(index) > ndim())
+    template <typename... Ix>
+    ssize_t offset_at(Ix... index) const {
+        if ((ssize_t) sizeof...(index) > ndim()) {
             fail_dim_check(sizeof...(index), "too many indices for an array");
+        }
         return byte_offset(ssize_t(index)...);
     }
 
     ssize_t offset_at() const { return 0; }
 
     /// Item count from beginning of the array to a given index (full or partial).
     /// May throw if the index would lead to out of bounds access.
-    template<typename... Ix> ssize_t index_at(Ix... index) const {
+    template <typename... Ix>
+    ssize_t index_at(Ix... index) const {
         return offset_at(index...) / itemsize();
     }
 
     /**
      * Returns a proxy object that provides access to the array's data without bounds or
      * dimensionality checking.  Will throw if the array is missing the `writeable` flag.  Use with
      * care: the array must not be destroyed or reshaped for the duration of the returned object,
      * and the caller must take care not to access invalid dimensions or dimension indices.
      */
-    template <typename T, ssize_t Dims = -1> detail::unchecked_mutable_reference<T, Dims> mutable_unchecked() & {
-        if (Dims >= 0 && ndim() != Dims)
-            throw std::domain_error("array has incorrect number of dimensions: " + std::to_string(ndim()) +
-                    "; expected " + std::to_string(Dims));
-        return detail::unchecked_mutable_reference<T, Dims>(mutable_data(), shape(), strides(), ndim());
+    template <typename T, ssize_t Dims = -1>
+    detail::unchecked_mutable_reference<T, Dims> mutable_unchecked() & {
+        if (Dims >= 0 && ndim() != Dims) {
+            throw std::domain_error("array has incorrect number of dimensions: "
+                                    + std::to_string(ndim()) + "; expected "
+                                    + std::to_string(Dims));
+        }
+        return detail::unchecked_mutable_reference<T, Dims>(
+            mutable_data(), shape(), strides(), ndim());
     }
 
     /**
      * Returns a proxy object that provides const access to the array's data without bounds or
      * dimensionality checking.  Unlike `mutable_unchecked()`, this does not require that the
-     * underlying array have the `writable` flag.  Use with care: the array must not be destroyed or
-     * reshaped for the duration of the returned object, and the caller must take care not to access
-     * invalid dimensions or dimension indices.
+     * underlying array have the `writable` flag.  Use with care: the array must not be destroyed
+     * or reshaped for the duration of the returned object, and the caller must take care not to
+     * access invalid dimensions or dimension indices.
      */
-    template <typename T, ssize_t Dims = -1> detail::unchecked_reference<T, Dims> unchecked() const & {
-        if (Dims >= 0 && ndim() != Dims)
-            throw std::domain_error("array has incorrect number of dimensions: " + std::to_string(ndim()) +
-                    "; expected " + std::to_string(Dims));
+    template <typename T, ssize_t Dims = -1>
+    detail::unchecked_reference<T, Dims> unchecked() const & {
+        if (Dims >= 0 && ndim() != Dims) {
+            throw std::domain_error("array has incorrect number of dimensions: "
+                                    + std::to_string(ndim()) + "; expected "
+                                    + std::to_string(Dims));
+        }
         return detail::unchecked_reference<T, Dims>(data(), shape(), strides(), ndim());
     }
 
     /// Return a new view with all of the dimensions of length 1 removed
     array squeeze() {
-        auto& api = detail::npy_api::get();
+        auto &api = detail::npy_api::get();
         return reinterpret_steal<array>(api.PyArray_Squeeze_(m_ptr));
     }
 
     /// Resize array to given shape
     /// If refcheck is true and more that one reference exist to this array
     /// then resize will succeed only if it makes a reshape, i.e. original size doesn't change
     void resize(ShapeContainer new_shape, bool refcheck = true) {
-        detail::npy_api::PyArray_Dims d = {
-            new_shape->data(), int(new_shape->size())
-        };
+        detail::npy_api::PyArray_Dims d
+            = {// Use reinterpret_cast for PyPy on Windows (remove if fixed, checked on 7.3.1)
+               reinterpret_cast<Py_intptr_t *>(new_shape->data()),
+               int(new_shape->size())};
         // try to resize, set ordering param to -1 cause it's not used anyway
-        object new_array = reinterpret_steal<object>(
-            detail::npy_api::get().PyArray_Resize_(m_ptr, &d, int(refcheck), -1)
-        );
-        if (!new_array) throw error_already_set();
-        if (isinstance<array>(new_array)) { *this = std::move(new_array); }
+        auto new_array = reinterpret_steal<object>(
+            detail::npy_api::get().PyArray_Resize_(m_ptr, &d, int(refcheck), -1));
+        if (!new_array) {
+            throw error_already_set();
+        }
+        if (isinstance<array>(new_array)) {
+            *this = std::move(new_array);
+        }
+    }
+
+    /// Optional `order` parameter omitted, to be added as needed.
+    array reshape(ShapeContainer new_shape) {
+        detail::npy_api::PyArray_Dims d
+            = {reinterpret_cast<Py_intptr_t *>(new_shape->data()), int(new_shape->size())};
+        auto new_array
+            = reinterpret_steal<array>(detail::npy_api::get().PyArray_Newshape_(m_ptr, &d, 0));
+        if (!new_array) {
+            throw error_already_set();
+        }
+        return new_array;
+    }
+
+    /// Create a view of an array in a different data type.
+    /// This function may fundamentally reinterpret the data in the array.
+    /// It is the responsibility of the caller to ensure that this is safe.
+    /// Only supports the `dtype` argument, the `type` argument is omitted,
+    /// to be added as needed.
+    array view(const std::string &dtype) {
+        auto &api = detail::npy_api::get();
+        auto new_view = reinterpret_steal<array>(api.PyArray_View_(
+            m_ptr, dtype::from_args(pybind11::str(dtype)).release().ptr(), nullptr));
+        if (!new_view) {
+            throw error_already_set();
+        }
+        return new_view;
     }
 
     /// Ensure that the argument is a NumPy array
     /// In case of an error, nullptr is returned and the Python error is cleared.
     static array ensure(handle h, int ExtraFlags = 0) {
         auto result = reinterpret_steal<array>(raw_array(h.ptr(), ExtraFlags));
-        if (!result)
+        if (!result) {
             PyErr_Clear();
+        }
         return result;
     }
 
 protected:
-    template<typename, typename> friend struct detail::npy_format_descriptor;
+    template <typename, typename>
+    friend struct detail::npy_format_descriptor;
 
-    void fail_dim_check(ssize_t dim, const std::string& msg) const {
-        throw index_error(msg + ": " + std::to_string(dim) +
-                          " (ndim = " + std::to_string(ndim()) + ")");
+    void fail_dim_check(ssize_t dim, const std::string &msg) const {
+        throw index_error(msg + ": " + std::to_string(dim) + " (ndim = " + std::to_string(ndim())
+                          + ')');
     }
 
-    template<typename... Ix> ssize_t byte_offset(Ix... index) const {
+    template <typename... Ix>
+    ssize_t byte_offset(Ix... index) const {
         check_dimensions(index...);
         return detail::byte_offset_unsafe(strides(), ssize_t(index)...);
     }
 
     void check_writeable() const {
-        if (!writeable())
+        if (!writeable()) {
             throw std::domain_error("array is not writeable");
+        }
     }
 
-    // Default, C-style strides
-    static std::vector<ssize_t> c_strides(const std::vector<ssize_t> &shape, ssize_t itemsize) {
-        auto ndim = shape.size();
-        std::vector<ssize_t> strides(ndim, itemsize);
-        if (ndim > 0)
-            for (size_t i = ndim - 1; i > 0; --i)
-                strides[i - 1] = strides[i] * shape[i];
-        return strides;
-    }
-
-    // F-style strides; default when constructing an array_t with `ExtraFlags & f_style`
-    static std::vector<ssize_t> f_strides(const std::vector<ssize_t> &shape, ssize_t itemsize) {
-        auto ndim = shape.size();
-        std::vector<ssize_t> strides(ndim, itemsize);
-        for (size_t i = 1; i < ndim; ++i)
-            strides[i] = strides[i - 1] * shape[i - 1];
-        return strides;
-    }
-
-    template<typename... Ix> void check_dimensions(Ix... index) const {
+    template <typename... Ix>
+    void check_dimensions(Ix... index) const {
         check_dimensions_impl(ssize_t(0), shape(), ssize_t(index)...);
     }
 
-    void check_dimensions_impl(ssize_t, const ssize_t*) const { }
+    void check_dimensions_impl(ssize_t, const ssize_t *) const {}
 
-    template<typename... Ix> void check_dimensions_impl(ssize_t axis, const ssize_t* shape, ssize_t i, Ix... index) const {
+    template <typename... Ix>
+    void check_dimensions_impl(ssize_t axis, const ssize_t *shape, ssize_t i, Ix... index) const {
         if (i >= *shape) {
-            throw index_error(std::string("index ") + std::to_string(i) +
-                              " is out of bounds for axis " + std::to_string(axis) +
-                              " with size " + std::to_string(*shape));
+            throw index_error(std::string("index ") + std::to_string(i)
+                              + " is out of bounds for axis " + std::to_string(axis)
+                              + " with size " + std::to_string(*shape));
         }
         check_dimensions_impl(axis + 1, shape + 1, index...);
     }
 
     /// Create array from any object -- always returns a new reference
     static PyObject *raw_array(PyObject *ptr, int ExtraFlags = 0) {
         if (ptr == nullptr) {
@@ -795,297 +1010,374 @@
             return nullptr;
         }
         return detail::npy_api::get().PyArray_FromAny_(
             ptr, nullptr, 0, 0, detail::npy_api::NPY_ARRAY_ENSUREARRAY_ | ExtraFlags, nullptr);
     }
 };
 
-template <typename T, int ExtraFlags = array::forcecast> class array_t : public array {
+template <typename T, int ExtraFlags = array::forcecast>
+class array_t : public array {
 private:
     struct private_ctor {};
     // Delegating constructor needed when both moving and accessing in the same constructor
-    array_t(private_ctor, ShapeContainer &&shape, StridesContainer &&strides, const T *ptr, handle base)
+    array_t(private_ctor,
+            ShapeContainer &&shape,
+            StridesContainer &&strides,
+            const T *ptr,
+            handle base)
         : array(std::move(shape), std::move(strides), ptr, base) {}
+
 public:
     static_assert(!detail::array_info<T>::is_array, "Array types cannot be used with array_t");
 
     using value_type = T;
 
     array_t() : array(0, static_cast<const T *>(nullptr)) {}
-    array_t(handle h, borrowed_t) : array(h, borrowed_t{}) { }
-    array_t(handle h, stolen_t) : array(h, stolen_t{}) { }
+    array_t(handle h, borrowed_t) : array(h, borrowed_t{}) {}
+    array_t(handle h, stolen_t) : array(h, stolen_t{}) {}
 
     PYBIND11_DEPRECATED("Use array_t<T>::ensure() instead")
     array_t(handle h, bool is_borrowed) : array(raw_array_t(h.ptr()), stolen_t{}) {
-        if (!m_ptr) PyErr_Clear();
-        if (!is_borrowed) Py_XDECREF(h.ptr());
+        if (!m_ptr) {
+            PyErr_Clear();
+        }
+        if (!is_borrowed) {
+            Py_XDECREF(h.ptr());
+        }
     }
 
+    // NOLINTNEXTLINE(google-explicit-constructor)
     array_t(const object &o) : array(raw_array_t(o.ptr()), stolen_t{}) {
-        if (!m_ptr) throw error_already_set();
+        if (!m_ptr) {
+            throw error_already_set();
+        }
     }
 
-    explicit array_t(const buffer_info& info) : array(info) { }
+    explicit array_t(const buffer_info &info, handle base = handle()) : array(info, base) {}
 
-    array_t(ShapeContainer shape, StridesContainer strides, const T *ptr = nullptr, handle base = handle())
-        : array(std::move(shape), std::move(strides), ptr, base) { }
+    array_t(ShapeContainer shape,
+            StridesContainer strides,
+            const T *ptr = nullptr,
+            handle base = handle())
+        : array(std::move(shape), std::move(strides), ptr, base) {}
 
     explicit array_t(ShapeContainer shape, const T *ptr = nullptr, handle base = handle())
-        : array_t(private_ctor{}, std::move(shape),
-                ExtraFlags & f_style ? f_strides(*shape, itemsize()) : c_strides(*shape, itemsize()),
-                ptr, base) { }
+        : array_t(private_ctor{},
+                  std::move(shape),
+                  (ExtraFlags & f_style) != 0 ? detail::f_strides(*shape, itemsize())
+                                              : detail::c_strides(*shape, itemsize()),
+                  ptr,
+                  base) {}
 
-    explicit array_t(size_t count, const T *ptr = nullptr, handle base = handle())
-        : array({count}, {}, ptr, base) { }
+    explicit array_t(ssize_t count, const T *ptr = nullptr, handle base = handle())
+        : array({count}, {}, ptr, base) {}
 
-    constexpr ssize_t itemsize() const {
-        return sizeof(T);
-    }
+    constexpr ssize_t itemsize() const { return sizeof(T); }
 
-    template<typename... Ix> ssize_t index_at(Ix... index) const {
+    template <typename... Ix>
+    ssize_t index_at(Ix... index) const {
         return offset_at(index...) / itemsize();
     }
 
-    template<typename... Ix> const T* data(Ix... index) const {
-        return static_cast<const T*>(array::data(index...));
+    template <typename... Ix>
+    const T *data(Ix... index) const {
+        return static_cast<const T *>(array::data(index...));
     }
 
-    template<typename... Ix> T* mutable_data(Ix... index) {
-        return static_cast<T*>(array::mutable_data(index...));
+    template <typename... Ix>
+    T *mutable_data(Ix... index) {
+        return static_cast<T *>(array::mutable_data(index...));
     }
 
     // Reference to element at a given index
-    template<typename... Ix> const T& at(Ix... index) const {
-        if ((ssize_t) sizeof...(index) != ndim())
+    template <typename... Ix>
+    const T &at(Ix... index) const {
+        if ((ssize_t) sizeof...(index) != ndim()) {
             fail_dim_check(sizeof...(index), "index dimension mismatch");
-        return *(static_cast<const T*>(array::data()) + byte_offset(ssize_t(index)...) / itemsize());
+        }
+        return *(static_cast<const T *>(array::data())
+                 + byte_offset(ssize_t(index)...) / itemsize());
     }
 
     // Mutable reference to element at a given index
-    template<typename... Ix> T& mutable_at(Ix... index) {
-        if ((ssize_t) sizeof...(index) != ndim())
+    template <typename... Ix>
+    T &mutable_at(Ix... index) {
+        if ((ssize_t) sizeof...(index) != ndim()) {
             fail_dim_check(sizeof...(index), "index dimension mismatch");
-        return *(static_cast<T*>(array::mutable_data()) + byte_offset(ssize_t(index)...) / itemsize());
+        }
+        return *(static_cast<T *>(array::mutable_data())
+                 + byte_offset(ssize_t(index)...) / itemsize());
     }
 
     /**
      * Returns a proxy object that provides access to the array's data without bounds or
      * dimensionality checking.  Will throw if the array is missing the `writeable` flag.  Use with
      * care: the array must not be destroyed or reshaped for the duration of the returned object,
      * and the caller must take care not to access invalid dimensions or dimension indices.
      */
-    template <ssize_t Dims = -1> detail::unchecked_mutable_reference<T, Dims> mutable_unchecked() & {
+    template <ssize_t Dims = -1>
+    detail::unchecked_mutable_reference<T, Dims> mutable_unchecked() & {
         return array::mutable_unchecked<T, Dims>();
     }
 
     /**
      * Returns a proxy object that provides const access to the array's data without bounds or
-     * dimensionality checking.  Unlike `unchecked()`, this does not require that the underlying
-     * array have the `writable` flag.  Use with care: the array must not be destroyed or reshaped
-     * for the duration of the returned object, and the caller must take care not to access invalid
-     * dimensions or dimension indices.
+     * dimensionality checking.  Unlike `mutable_unchecked()`, this does not require that the
+     * underlying array have the `writable` flag.  Use with care: the array must not be destroyed
+     * or reshaped for the duration of the returned object, and the caller must take care not to
+     * access invalid dimensions or dimension indices.
      */
-    template <ssize_t Dims = -1> detail::unchecked_reference<T, Dims> unchecked() const & {
+    template <ssize_t Dims = -1>
+    detail::unchecked_reference<T, Dims> unchecked() const & {
         return array::unchecked<T, Dims>();
     }
 
     /// Ensure that the argument is a NumPy array of the correct dtype (and if not, try to convert
     /// it).  In case of an error, nullptr is returned and the Python error is cleared.
     static array_t ensure(handle h) {
         auto result = reinterpret_steal<array_t>(raw_array_t(h.ptr()));
-        if (!result)
+        if (!result) {
             PyErr_Clear();
+        }
         return result;
     }
 
     static bool check_(handle h) {
         const auto &api = detail::npy_api::get();
         return api.PyArray_Check_(h.ptr())
-               && api.PyArray_EquivTypes_(detail::array_proxy(h.ptr())->descr, dtype::of<T>().ptr());
+               && api.PyArray_EquivTypes_(detail::array_proxy(h.ptr())->descr,
+                                          dtype::of<T>().ptr())
+               && detail::check_flags(h.ptr(), ExtraFlags & (array::c_style | array::f_style));
     }
 
 protected:
     /// Create array from any object -- always returns a new reference
     static PyObject *raw_array_t(PyObject *ptr) {
         if (ptr == nullptr) {
             PyErr_SetString(PyExc_ValueError, "cannot create a pybind11::array_t from a nullptr");
             return nullptr;
         }
-        return detail::npy_api::get().PyArray_FromAny_(
-            ptr, dtype::of<T>().release().ptr(), 0, 0,
-            detail::npy_api::NPY_ARRAY_ENSUREARRAY_ | ExtraFlags, nullptr);
+        return detail::npy_api::get().PyArray_FromAny_(ptr,
+                                                       dtype::of<T>().release().ptr(),
+                                                       0,
+                                                       0,
+                                                       detail::npy_api::NPY_ARRAY_ENSUREARRAY_
+                                                           | ExtraFlags,
+                                                       nullptr);
     }
 };
 
 template <typename T>
 struct format_descriptor<T, detail::enable_if_t<detail::is_pod_struct<T>::value>> {
     static std::string format() {
         return detail::npy_format_descriptor<typename std::remove_cv<T>::type>::format();
     }
 };
 
-template <size_t N> struct format_descriptor<char[N]> {
-    static std::string format() { return std::to_string(N) + "s"; }
+template <size_t N>
+struct format_descriptor<char[N]> {
+    static std::string format() { return std::to_string(N) + 's'; }
 };
-template <size_t N> struct format_descriptor<std::array<char, N>> {
-    static std::string format() { return std::to_string(N) + "s"; }
+template <size_t N>
+struct format_descriptor<std::array<char, N>> {
+    static std::string format() { return std::to_string(N) + 's'; }
 };
 
 template <typename T>
 struct format_descriptor<T, detail::enable_if_t<std::is_enum<T>::value>> {
     static std::string format() {
         return format_descriptor<
             typename std::remove_cv<typename std::underlying_type<T>::type>::type>::format();
     }
 };
 
 template <typename T>
 struct format_descriptor<T, detail::enable_if_t<detail::array_info<T>::is_array>> {
     static std::string format() {
         using namespace detail;
-        static constexpr auto extents = _("(") + array_info<T>::extents + _(")");
+        static constexpr auto extents = const_name("(") + array_info<T>::extents + const_name(")");
         return extents.text + format_descriptor<remove_all_extents_t<T>>::format();
     }
 };
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
 template <typename T, int ExtraFlags>
 struct pyobject_caster<array_t<T, ExtraFlags>> {
     using type = array_t<T, ExtraFlags>;
 
     bool load(handle src, bool convert) {
-        if (!convert && !type::check_(src))
+        if (!convert && !type::check_(src)) {
             return false;
+        }
         value = type::ensure(src);
         return static_cast<bool>(value);
     }
 
     static handle cast(const handle &src, return_value_policy /* policy */, handle /* parent */) {
         return src.inc_ref();
     }
     PYBIND11_TYPE_CASTER(type, handle_type_name<type>::name);
 };
 
 template <typename T>
 struct compare_buffer_info<T, detail::enable_if_t<detail::is_pod_struct<T>::value>> {
-    static bool compare(const buffer_info& b) {
+    static bool compare(const buffer_info &b) {
         return npy_api::get().PyArray_EquivTypes_(dtype::of<T>().ptr(), dtype(b).ptr());
     }
 };
 
 template <typename T, typename = void>
 struct npy_format_descriptor_name;
 
 template <typename T>
 struct npy_format_descriptor_name<T, enable_if_t<std::is_integral<T>::value>> {
-    static constexpr auto name = _<std::is_same<T, bool>::value>(
-        _("bool"), _<std::is_signed<T>::value>("int", "uint") + _<sizeof(T)*8>()
-    );
+    static constexpr auto name = const_name<std::is_same<T, bool>::value>(
+        const_name("bool"),
+        const_name<std::is_signed<T>::value>("numpy.int", "numpy.uint")
+            + const_name<sizeof(T) * 8>());
 };
 
 template <typename T>
 struct npy_format_descriptor_name<T, enable_if_t<std::is_floating_point<T>::value>> {
-    static constexpr auto name = _<std::is_same<T, float>::value || std::is_same<T, double>::value>(
-        _("float") + _<sizeof(T)*8>(), _("longdouble")
-    );
+    static constexpr auto name = const_name < std::is_same<T, float>::value
+                                 || std::is_same<T, const float>::value
+                                 || std::is_same<T, double>::value
+                                 || std::is_same<T, const double>::value
+                                        > (const_name("numpy.float") + const_name<sizeof(T) * 8>(),
+                                           const_name("numpy.longdouble"));
 };
 
 template <typename T>
 struct npy_format_descriptor_name<T, enable_if_t<is_complex<T>::value>> {
-    static constexpr auto name = _<std::is_same<typename T::value_type, float>::value
-                                   || std::is_same<typename T::value_type, double>::value>(
-        _("complex") + _<sizeof(typename T::value_type)*16>(), _("longcomplex")
-    );
+    static constexpr auto name = const_name < std::is_same<typename T::value_type, float>::value
+                                 || std::is_same<typename T::value_type, const float>::value
+                                 || std::is_same<typename T::value_type, double>::value
+                                 || std::is_same<typename T::value_type, const double>::value
+                                        > (const_name("numpy.complex")
+                                               + const_name<sizeof(typename T::value_type) * 16>(),
+                                           const_name("numpy.longcomplex"));
 };
 
 template <typename T>
-struct npy_format_descriptor<T, enable_if_t<satisfies_any_of<T, std::is_arithmetic, is_complex>::value>>
+struct npy_format_descriptor<
+    T,
+    enable_if_t<satisfies_any_of<T, std::is_arithmetic, is_complex>::value>>
     : npy_format_descriptor_name<T> {
 private:
     // NB: the order here must match the one in common.h
-    constexpr static const int values[15] = {
-        npy_api::NPY_BOOL_,
-        npy_api::NPY_BYTE_,   npy_api::NPY_UBYTE_,   npy_api::NPY_SHORT_,    npy_api::NPY_USHORT_,
-        npy_api::NPY_INT_,    npy_api::NPY_UINT_,    npy_api::NPY_LONGLONG_, npy_api::NPY_ULONGLONG_,
-        npy_api::NPY_FLOAT_,  npy_api::NPY_DOUBLE_,  npy_api::NPY_LONGDOUBLE_,
-        npy_api::NPY_CFLOAT_, npy_api::NPY_CDOUBLE_, npy_api::NPY_CLONGDOUBLE_
-    };
+    constexpr static const int values[15] = {npy_api::NPY_BOOL_,
+                                             npy_api::NPY_BYTE_,
+                                             npy_api::NPY_UBYTE_,
+                                             npy_api::NPY_INT16_,
+                                             npy_api::NPY_UINT16_,
+                                             npy_api::NPY_INT32_,
+                                             npy_api::NPY_UINT32_,
+                                             npy_api::NPY_INT64_,
+                                             npy_api::NPY_UINT64_,
+                                             npy_api::NPY_FLOAT_,
+                                             npy_api::NPY_DOUBLE_,
+                                             npy_api::NPY_LONGDOUBLE_,
+                                             npy_api::NPY_CFLOAT_,
+                                             npy_api::NPY_CDOUBLE_,
+                                             npy_api::NPY_CLONGDOUBLE_};
 
 public:
     static constexpr int value = values[detail::is_fmt_numeric<T>::index];
 
     static pybind11::dtype dtype() {
-        if (auto ptr = npy_api::get().PyArray_DescrFromType_(value))
-            return reinterpret_borrow<pybind11::dtype>(ptr);
+        if (auto *ptr = npy_api::get().PyArray_DescrFromType_(value)) {
+            return reinterpret_steal<pybind11::dtype>(ptr);
+        }
         pybind11_fail("Unsupported buffer format!");
     }
 };
 
-#define PYBIND11_DECL_CHAR_FMT \
-    static constexpr auto name = _("S") + _<N>(); \
-    static pybind11::dtype dtype() { return pybind11::dtype(std::string("S") + std::to_string(N)); }
-template <size_t N> struct npy_format_descriptor<char[N]> { PYBIND11_DECL_CHAR_FMT };
-template <size_t N> struct npy_format_descriptor<std::array<char, N>> { PYBIND11_DECL_CHAR_FMT };
+#define PYBIND11_DECL_CHAR_FMT                                                                    \
+    static constexpr auto name = const_name("S") + const_name<N>();                               \
+    static pybind11::dtype dtype() {                                                              \
+        return pybind11::dtype(std::string("S") + std::to_string(N));                             \
+    }
+template <size_t N>
+struct npy_format_descriptor<char[N]> {
+    PYBIND11_DECL_CHAR_FMT
+};
+template <size_t N>
+struct npy_format_descriptor<std::array<char, N>> {
+    PYBIND11_DECL_CHAR_FMT
+};
 #undef PYBIND11_DECL_CHAR_FMT
 
-template<typename T> struct npy_format_descriptor<T, enable_if_t<array_info<T>::is_array>> {
+template <typename T>
+struct npy_format_descriptor<T, enable_if_t<array_info<T>::is_array>> {
 private:
     using base_descr = npy_format_descriptor<typename array_info<T>::type>;
+
 public:
     static_assert(!array_info<T>::is_empty, "Zero-sized arrays are not supported");
 
-    static constexpr auto name = _("(") + array_info<T>::extents + _(")") + base_descr::name;
+    static constexpr auto name
+        = const_name("(") + array_info<T>::extents + const_name(")") + base_descr::name;
     static pybind11::dtype dtype() {
         list shape;
         array_info<T>::append_extents(shape);
-        return pybind11::dtype::from_args(pybind11::make_tuple(base_descr::dtype(), shape));
+        return pybind11::dtype::from_args(
+            pybind11::make_tuple(base_descr::dtype(), std::move(shape)));
     }
 };
 
-template<typename T> struct npy_format_descriptor<T, enable_if_t<std::is_enum<T>::value>> {
+template <typename T>
+struct npy_format_descriptor<T, enable_if_t<std::is_enum<T>::value>> {
 private:
     using base_descr = npy_format_descriptor<typename std::underlying_type<T>::type>;
+
 public:
     static constexpr auto name = base_descr::name;
     static pybind11::dtype dtype() { return base_descr::dtype(); }
 };
 
 struct field_descriptor {
     const char *name;
     ssize_t offset;
     ssize_t size;
     std::string format;
     dtype descr;
 };
 
-inline PYBIND11_NOINLINE void register_structured_dtype(
-    any_container<field_descriptor> fields,
-    const std::type_info& tinfo, ssize_t itemsize,
-    bool (*direct_converter)(PyObject *, void *&)) {
+PYBIND11_NOINLINE void register_structured_dtype(any_container<field_descriptor> fields,
+                                                 const std::type_info &tinfo,
+                                                 ssize_t itemsize,
+                                                 bool (*direct_converter)(PyObject *, void *&)) {
 
-    auto& numpy_internals = get_numpy_internals();
-    if (numpy_internals.get_type_info(tinfo, false))
+    auto &numpy_internals = get_numpy_internals();
+    if (numpy_internals.get_type_info(tinfo, false)) {
         pybind11_fail("NumPy: dtype is already registered");
+    }
 
     // Use ordered fields because order matters as of NumPy 1.14:
     // https://docs.scipy.org/doc/numpy/release.html#multiple-field-indexing-assignment-of-structured-arrays
     std::vector<field_descriptor> ordered_fields(std::move(fields));
-    std::sort(ordered_fields.begin(), ordered_fields.end(),
+    std::sort(
+        ordered_fields.begin(),
+        ordered_fields.end(),
         [](const field_descriptor &a, const field_descriptor &b) { return a.offset < b.offset; });
 
     list names, formats, offsets;
-    for (auto& field : ordered_fields) {
-        if (!field.descr)
-            pybind11_fail(std::string("NumPy: unsupported field dtype: `") +
-                            field.name + "` @ " + tinfo.name());
-        names.append(PYBIND11_STR_TYPE(field.name));
+    for (auto &field : ordered_fields) {
+        if (!field.descr) {
+            pybind11_fail(std::string("NumPy: unsupported field dtype: `") + field.name + "` @ "
+                          + tinfo.name());
+        }
+        names.append(pybind11::str(field.name));
         formats.append(field.descr);
         offsets.append(pybind11::int_(field.offset));
     }
-    auto dtype_ptr = pybind11::dtype(names, formats, offsets, itemsize).release().ptr();
+    auto *dtype_ptr
+        = pybind11::dtype(std::move(names), std::move(formats), std::move(offsets), itemsize)
+              .release()
+              .ptr();
 
     // There is an existing bug in NumPy (as of v1.11): trailing bytes are
     // not encoded explicitly into the format string. This will supposedly
     // get fixed in v1.12; for further details, see these:
     // - https://github.com/numpy/numpy/issues/7797
     // - https://github.com/numpy/numpy/pull/7798
     // Because of this, we won't use numpy's logic to generate buffer format
@@ -1094,520 +1386,607 @@
     std::ostringstream oss;
     // mark the structure as unaligned with '^', because numpy and C++ don't
     // always agree about alignment (particularly for complex), and we're
     // explicitly listing all our padding. This depends on none of the fields
     // overriding the endianness. Putting the ^ in front of individual fields
     // isn't guaranteed to work due to https://github.com/numpy/numpy/issues/9049
     oss << "^T{";
-    for (auto& field : ordered_fields) {
-        if (field.offset > offset)
+    for (auto &field : ordered_fields) {
+        if (field.offset > offset) {
             oss << (field.offset - offset) << 'x';
+        }
         oss << field.format << ':' << field.name << ':';
         offset = field.offset + field.size;
     }
-    if (itemsize > offset)
+    if (itemsize > offset) {
         oss << (itemsize - offset) << 'x';
+    }
     oss << '}';
     auto format_str = oss.str();
 
-    // Sanity check: verify that NumPy properly parses our buffer format string
-    auto& api = npy_api::get();
-    auto arr =  array(buffer_info(nullptr, itemsize, format_str, 1));
-    if (!api.PyArray_EquivTypes_(dtype_ptr, arr.dtype().ptr()))
+    // Smoke test: verify that NumPy properly parses our buffer format string
+    auto &api = npy_api::get();
+    auto arr = array(buffer_info(nullptr, itemsize, format_str, 1));
+    if (!api.PyArray_EquivTypes_(dtype_ptr, arr.dtype().ptr())) {
         pybind11_fail("NumPy: invalid buffer descriptor!");
+    }
 
     auto tindex = std::type_index(tinfo);
-    numpy_internals.registered_dtypes[tindex] = { dtype_ptr, format_str };
+    numpy_internals.registered_dtypes[tindex] = {dtype_ptr, std::move(format_str)};
     get_internals().direct_conversions[tindex].push_back(direct_converter);
 }
 
-template <typename T, typename SFINAE> struct npy_format_descriptor {
-    static_assert(is_pod_struct<T>::value, "Attempt to use a non-POD or unimplemented POD type as a numpy dtype");
+template <typename T, typename SFINAE>
+struct npy_format_descriptor {
+    static_assert(is_pod_struct<T>::value,
+                  "Attempt to use a non-POD or unimplemented POD type as a numpy dtype");
 
     static constexpr auto name = make_caster<T>::name;
 
-    static pybind11::dtype dtype() {
-        return reinterpret_borrow<pybind11::dtype>(dtype_ptr());
-    }
+    static pybind11::dtype dtype() { return reinterpret_borrow<pybind11::dtype>(dtype_ptr()); }
 
     static std::string format() {
         static auto format_str = get_numpy_internals().get_type_info<T>(true)->format_str;
         return format_str;
     }
 
     static void register_dtype(any_container<field_descriptor> fields) {
-        register_structured_dtype(std::move(fields), typeid(typename std::remove_cv<T>::type),
-                                  sizeof(T), &direct_converter);
+        register_structured_dtype(std::move(fields),
+                                  typeid(typename std::remove_cv<T>::type),
+                                  sizeof(T),
+                                  &direct_converter);
     }
 
 private:
-    static PyObject* dtype_ptr() {
-        static PyObject* ptr = get_numpy_internals().get_type_info<T>(true)->dtype_ptr;
+    static PyObject *dtype_ptr() {
+        static PyObject *ptr = get_numpy_internals().get_type_info<T>(true)->dtype_ptr;
         return ptr;
     }
 
-    static bool direct_converter(PyObject *obj, void*& value) {
-        auto& api = npy_api::get();
-        if (!PyObject_TypeCheck(obj, api.PyVoidArrType_Type_))
+    static bool direct_converter(PyObject *obj, void *&value) {
+        auto &api = npy_api::get();
+        if (!PyObject_TypeCheck(obj, api.PyVoidArrType_Type_)) {
             return false;
+        }
         if (auto descr = reinterpret_steal<object>(api.PyArray_DescrFromScalar_(obj))) {
             if (api.PyArray_EquivTypes_(dtype_ptr(), descr.ptr())) {
                 value = ((PyVoidScalarObject_Proxy *) obj)->obval;
                 return true;
             }
         }
         return false;
     }
 };
 
 #ifdef __CLION_IDE__ // replace heavy macro with dummy code for the IDE (doesn't affect code)
-# define PYBIND11_NUMPY_DTYPE(Type, ...) ((void)0)
-# define PYBIND11_NUMPY_DTYPE_EX(Type, ...) ((void)0)
+#    define PYBIND11_NUMPY_DTYPE(Type, ...) ((void) 0)
+#    define PYBIND11_NUMPY_DTYPE_EX(Type, ...) ((void) 0)
 #else
 
-#define PYBIND11_FIELD_DESCRIPTOR_EX(T, Field, Name)                                          \
-    ::pybind11::detail::field_descriptor {                                                    \
-        Name, offsetof(T, Field), sizeof(decltype(std::declval<T>().Field)),                  \
-        ::pybind11::format_descriptor<decltype(std::declval<T>().Field)>::format(),           \
-        ::pybind11::detail::npy_format_descriptor<decltype(std::declval<T>().Field)>::dtype() \
-    }
+#    define PYBIND11_FIELD_DESCRIPTOR_EX(T, Field, Name)                                          \
+        ::pybind11::detail::field_descriptor {                                                    \
+            Name, offsetof(T, Field), sizeof(decltype(std::declval<T>().Field)),                  \
+                ::pybind11::format_descriptor<decltype(std::declval<T>().Field)>::format(),       \
+                ::pybind11::detail::npy_format_descriptor<                                        \
+                    decltype(std::declval<T>().Field)>::dtype()                                   \
+        }
 
 // Extract name, offset and format descriptor for a struct field
-#define PYBIND11_FIELD_DESCRIPTOR(T, Field) PYBIND11_FIELD_DESCRIPTOR_EX(T, Field, #Field)
+#    define PYBIND11_FIELD_DESCRIPTOR(T, Field) PYBIND11_FIELD_DESCRIPTOR_EX(T, Field, #Field)
 
 // The main idea of this macro is borrowed from https://github.com/swansontec/map-macro
 // (C) William Swanson, Paul Fultz
-#define PYBIND11_EVAL0(...) __VA_ARGS__
-#define PYBIND11_EVAL1(...) PYBIND11_EVAL0 (PYBIND11_EVAL0 (PYBIND11_EVAL0 (__VA_ARGS__)))
-#define PYBIND11_EVAL2(...) PYBIND11_EVAL1 (PYBIND11_EVAL1 (PYBIND11_EVAL1 (__VA_ARGS__)))
-#define PYBIND11_EVAL3(...) PYBIND11_EVAL2 (PYBIND11_EVAL2 (PYBIND11_EVAL2 (__VA_ARGS__)))
-#define PYBIND11_EVAL4(...) PYBIND11_EVAL3 (PYBIND11_EVAL3 (PYBIND11_EVAL3 (__VA_ARGS__)))
-#define PYBIND11_EVAL(...)  PYBIND11_EVAL4 (PYBIND11_EVAL4 (PYBIND11_EVAL4 (__VA_ARGS__)))
-#define PYBIND11_MAP_END(...)
-#define PYBIND11_MAP_OUT
-#define PYBIND11_MAP_COMMA ,
-#define PYBIND11_MAP_GET_END() 0, PYBIND11_MAP_END
-#define PYBIND11_MAP_NEXT0(test, next, ...) next PYBIND11_MAP_OUT
-#define PYBIND11_MAP_NEXT1(test, next) PYBIND11_MAP_NEXT0 (test, next, 0)
-#define PYBIND11_MAP_NEXT(test, next)  PYBIND11_MAP_NEXT1 (PYBIND11_MAP_GET_END test, next)
-#ifdef _MSC_VER // MSVC is not as eager to expand macros, hence this workaround
-#define PYBIND11_MAP_LIST_NEXT1(test, next) \
-    PYBIND11_EVAL0 (PYBIND11_MAP_NEXT0 (test, PYBIND11_MAP_COMMA next, 0))
-#else
-#define PYBIND11_MAP_LIST_NEXT1(test, next) \
-    PYBIND11_MAP_NEXT0 (test, PYBIND11_MAP_COMMA next, 0)
-#endif
-#define PYBIND11_MAP_LIST_NEXT(test, next) \
-    PYBIND11_MAP_LIST_NEXT1 (PYBIND11_MAP_GET_END test, next)
-#define PYBIND11_MAP_LIST0(f, t, x, peek, ...) \
-    f(t, x) PYBIND11_MAP_LIST_NEXT (peek, PYBIND11_MAP_LIST1) (f, t, peek, __VA_ARGS__)
-#define PYBIND11_MAP_LIST1(f, t, x, peek, ...) \
-    f(t, x) PYBIND11_MAP_LIST_NEXT (peek, PYBIND11_MAP_LIST0) (f, t, peek, __VA_ARGS__)
+#    define PYBIND11_EVAL0(...) __VA_ARGS__
+#    define PYBIND11_EVAL1(...) PYBIND11_EVAL0(PYBIND11_EVAL0(PYBIND11_EVAL0(__VA_ARGS__)))
+#    define PYBIND11_EVAL2(...) PYBIND11_EVAL1(PYBIND11_EVAL1(PYBIND11_EVAL1(__VA_ARGS__)))
+#    define PYBIND11_EVAL3(...) PYBIND11_EVAL2(PYBIND11_EVAL2(PYBIND11_EVAL2(__VA_ARGS__)))
+#    define PYBIND11_EVAL4(...) PYBIND11_EVAL3(PYBIND11_EVAL3(PYBIND11_EVAL3(__VA_ARGS__)))
+#    define PYBIND11_EVAL(...) PYBIND11_EVAL4(PYBIND11_EVAL4(PYBIND11_EVAL4(__VA_ARGS__)))
+#    define PYBIND11_MAP_END(...)
+#    define PYBIND11_MAP_OUT
+#    define PYBIND11_MAP_COMMA ,
+#    define PYBIND11_MAP_GET_END() 0, PYBIND11_MAP_END
+#    define PYBIND11_MAP_NEXT0(test, next, ...) next PYBIND11_MAP_OUT
+#    define PYBIND11_MAP_NEXT1(test, next) PYBIND11_MAP_NEXT0(test, next, 0)
+#    define PYBIND11_MAP_NEXT(test, next) PYBIND11_MAP_NEXT1(PYBIND11_MAP_GET_END test, next)
+#    if defined(_MSC_VER)                                                                         \
+        && !defined(__clang__) // MSVC is not as eager to expand macros, hence this workaround
+#        define PYBIND11_MAP_LIST_NEXT1(test, next)                                               \
+            PYBIND11_EVAL0(PYBIND11_MAP_NEXT0(test, PYBIND11_MAP_COMMA next, 0))
+#    else
+#        define PYBIND11_MAP_LIST_NEXT1(test, next)                                               \
+            PYBIND11_MAP_NEXT0(test, PYBIND11_MAP_COMMA next, 0)
+#    endif
+#    define PYBIND11_MAP_LIST_NEXT(test, next)                                                    \
+        PYBIND11_MAP_LIST_NEXT1(PYBIND11_MAP_GET_END test, next)
+#    define PYBIND11_MAP_LIST0(f, t, x, peek, ...)                                                \
+        f(t, x) PYBIND11_MAP_LIST_NEXT(peek, PYBIND11_MAP_LIST1)(f, t, peek, __VA_ARGS__)
+#    define PYBIND11_MAP_LIST1(f, t, x, peek, ...)                                                \
+        f(t, x) PYBIND11_MAP_LIST_NEXT(peek, PYBIND11_MAP_LIST0)(f, t, peek, __VA_ARGS__)
 // PYBIND11_MAP_LIST(f, t, a1, a2, ...) expands to f(t, a1), f(t, a2), ...
-#define PYBIND11_MAP_LIST(f, t, ...) \
-    PYBIND11_EVAL (PYBIND11_MAP_LIST1 (f, t, __VA_ARGS__, (), 0))
+#    define PYBIND11_MAP_LIST(f, t, ...)                                                          \
+        PYBIND11_EVAL(PYBIND11_MAP_LIST1(f, t, __VA_ARGS__, (), 0))
 
-#define PYBIND11_NUMPY_DTYPE(Type, ...) \
-    ::pybind11::detail::npy_format_descriptor<Type>::register_dtype \
-        (::std::vector<::pybind11::detail::field_descriptor> \
-         {PYBIND11_MAP_LIST (PYBIND11_FIELD_DESCRIPTOR, Type, __VA_ARGS__)})
-
-#ifdef _MSC_VER
-#define PYBIND11_MAP2_LIST_NEXT1(test, next) \
-    PYBIND11_EVAL0 (PYBIND11_MAP_NEXT0 (test, PYBIND11_MAP_COMMA next, 0))
-#else
-#define PYBIND11_MAP2_LIST_NEXT1(test, next) \
-    PYBIND11_MAP_NEXT0 (test, PYBIND11_MAP_COMMA next, 0)
-#endif
-#define PYBIND11_MAP2_LIST_NEXT(test, next) \
-    PYBIND11_MAP2_LIST_NEXT1 (PYBIND11_MAP_GET_END test, next)
-#define PYBIND11_MAP2_LIST0(f, t, x1, x2, peek, ...) \
-    f(t, x1, x2) PYBIND11_MAP2_LIST_NEXT (peek, PYBIND11_MAP2_LIST1) (f, t, peek, __VA_ARGS__)
-#define PYBIND11_MAP2_LIST1(f, t, x1, x2, peek, ...) \
-    f(t, x1, x2) PYBIND11_MAP2_LIST_NEXT (peek, PYBIND11_MAP2_LIST0) (f, t, peek, __VA_ARGS__)
+#    define PYBIND11_NUMPY_DTYPE(Type, ...)                                                       \
+        ::pybind11::detail::npy_format_descriptor<Type>::register_dtype(                          \
+            ::std::vector<::pybind11::detail::field_descriptor>{                                  \
+                PYBIND11_MAP_LIST(PYBIND11_FIELD_DESCRIPTOR, Type, __VA_ARGS__)})
+
+#    if defined(_MSC_VER) && !defined(__clang__)
+#        define PYBIND11_MAP2_LIST_NEXT1(test, next)                                              \
+            PYBIND11_EVAL0(PYBIND11_MAP_NEXT0(test, PYBIND11_MAP_COMMA next, 0))
+#    else
+#        define PYBIND11_MAP2_LIST_NEXT1(test, next)                                              \
+            PYBIND11_MAP_NEXT0(test, PYBIND11_MAP_COMMA next, 0)
+#    endif
+#    define PYBIND11_MAP2_LIST_NEXT(test, next)                                                   \
+        PYBIND11_MAP2_LIST_NEXT1(PYBIND11_MAP_GET_END test, next)
+#    define PYBIND11_MAP2_LIST0(f, t, x1, x2, peek, ...)                                          \
+        f(t, x1, x2) PYBIND11_MAP2_LIST_NEXT(peek, PYBIND11_MAP2_LIST1)(f, t, peek, __VA_ARGS__)
+#    define PYBIND11_MAP2_LIST1(f, t, x1, x2, peek, ...)                                          \
+        f(t, x1, x2) PYBIND11_MAP2_LIST_NEXT(peek, PYBIND11_MAP2_LIST0)(f, t, peek, __VA_ARGS__)
 // PYBIND11_MAP2_LIST(f, t, a1, a2, ...) expands to f(t, a1, a2), f(t, a3, a4), ...
-#define PYBIND11_MAP2_LIST(f, t, ...) \
-    PYBIND11_EVAL (PYBIND11_MAP2_LIST1 (f, t, __VA_ARGS__, (), 0))
+#    define PYBIND11_MAP2_LIST(f, t, ...)                                                         \
+        PYBIND11_EVAL(PYBIND11_MAP2_LIST1(f, t, __VA_ARGS__, (), 0))
 
-#define PYBIND11_NUMPY_DTYPE_EX(Type, ...) \
-    ::pybind11::detail::npy_format_descriptor<Type>::register_dtype \
-        (::std::vector<::pybind11::detail::field_descriptor> \
-         {PYBIND11_MAP2_LIST (PYBIND11_FIELD_DESCRIPTOR_EX, Type, __VA_ARGS__)})
+#    define PYBIND11_NUMPY_DTYPE_EX(Type, ...)                                                    \
+        ::pybind11::detail::npy_format_descriptor<Type>::register_dtype(                          \
+            ::std::vector<::pybind11::detail::field_descriptor>{                                  \
+                PYBIND11_MAP2_LIST(PYBIND11_FIELD_DESCRIPTOR_EX, Type, __VA_ARGS__)})
 
 #endif // __CLION_IDE__
 
-template  <class T>
-using array_iterator = typename std::add_pointer<T>::type;
-
-template <class T>
-array_iterator<T> array_begin(const buffer_info& buffer) {
-    return array_iterator<T>(reinterpret_cast<T*>(buffer.ptr));
-}
-
-template <class T>
-array_iterator<T> array_end(const buffer_info& buffer) {
-    return array_iterator<T>(reinterpret_cast<T*>(buffer.ptr) + buffer.size);
-}
-
 class common_iterator {
 public:
     using container_type = std::vector<ssize_t>;
     using value_type = container_type::value_type;
     using size_type = container_type::size_type;
 
-    common_iterator() : p_ptr(0), m_strides() {}
+    common_iterator() : m_strides() {}
 
-    common_iterator(void* ptr, const container_type& strides, const container_type& shape)
-        : p_ptr(reinterpret_cast<char*>(ptr)), m_strides(strides.size()) {
+    common_iterator(void *ptr, const container_type &strides, const container_type &shape)
+        : p_ptr(reinterpret_cast<char *>(ptr)), m_strides(strides.size()) {
         m_strides.back() = static_cast<value_type>(strides.back());
         for (size_type i = m_strides.size() - 1; i != 0; --i) {
             size_type j = i - 1;
-            value_type s = static_cast<value_type>(shape[i]);
+            auto s = static_cast<value_type>(shape[i]);
             m_strides[j] = strides[j] + m_strides[i] - strides[i] * s;
         }
     }
 
-    void increment(size_type dim) {
-        p_ptr += m_strides[dim];
-    }
+    void increment(size_type dim) { p_ptr += m_strides[dim]; }
 
-    void* data() const {
-        return p_ptr;
-    }
+    void *data() const { return p_ptr; }
 
 private:
-    char* p_ptr;
+    char *p_ptr{nullptr};
     container_type m_strides;
 };
 
-template <size_t N> class multi_array_iterator {
+template <size_t N>
+class multi_array_iterator {
 public:
     using container_type = std::vector<ssize_t>;
 
-    multi_array_iterator(const std::array<buffer_info, N> &buffers,
-                         const container_type &shape)
-        : m_shape(shape.size()), m_index(shape.size(), 0),
-          m_common_iterator() {
+    multi_array_iterator(const std::array<buffer_info, N> &buffers, const container_type &shape)
+        : m_shape(shape.size()), m_index(shape.size(), 0), m_common_iterator() {
 
         // Manual copy to avoid conversion warning if using std::copy
-        for (size_t i = 0; i < shape.size(); ++i)
+        for (size_t i = 0; i < shape.size(); ++i) {
             m_shape[i] = shape[i];
+        }
 
         container_type strides(shape.size());
-        for (size_t i = 0; i < N; ++i)
+        for (size_t i = 0; i < N; ++i) {
             init_common_iterator(buffers[i], shape, m_common_iterator[i], strides);
+        }
     }
 
-    multi_array_iterator& operator++() {
+    multi_array_iterator &operator++() {
         for (size_t j = m_index.size(); j != 0; --j) {
             size_t i = j - 1;
             if (++m_index[i] != m_shape[i]) {
                 increment_common_iterator(i);
                 break;
-            } else {
-                m_index[i] = 0;
             }
+            m_index[i] = 0;
         }
         return *this;
     }
 
-    template <size_t K, class T = void> T* data() const {
-        return reinterpret_cast<T*>(m_common_iterator[K].data());
+    template <size_t K, class T = void>
+    T *data() const {
+        return reinterpret_cast<T *>(m_common_iterator[K].data());
     }
 
 private:
-
     using common_iter = common_iterator;
 
     void init_common_iterator(const buffer_info &buffer,
                               const container_type &shape,
                               common_iter &iterator,
                               container_type &strides) {
         auto buffer_shape_iter = buffer.shape.rbegin();
         auto buffer_strides_iter = buffer.strides.rbegin();
         auto shape_iter = shape.rbegin();
         auto strides_iter = strides.rbegin();
 
         while (buffer_shape_iter != buffer.shape.rend()) {
-            if (*shape_iter == *buffer_shape_iter)
+            if (*shape_iter == *buffer_shape_iter) {
                 *strides_iter = *buffer_strides_iter;
-            else
+            } else {
                 *strides_iter = 0;
+            }
 
             ++buffer_shape_iter;
             ++buffer_strides_iter;
             ++shape_iter;
             ++strides_iter;
         }
 
         std::fill(strides_iter, strides.rend(), 0);
         iterator = common_iter(buffer.ptr, strides, shape);
     }
 
     void increment_common_iterator(size_t dim) {
-        for (auto &iter : m_common_iterator)
+        for (auto &iter : m_common_iterator) {
             iter.increment(dim);
+        }
     }
 
     container_type m_shape;
     container_type m_index;
     std::array<common_iter, N> m_common_iterator;
 };
 
 enum class broadcast_trivial { non_trivial, c_trivial, f_trivial };
 
-// Populates the shape and number of dimensions for the set of buffers.  Returns a broadcast_trivial
-// enum value indicating whether the broadcast is "trivial"--that is, has each buffer being either a
-// singleton or a full-size, C-contiguous (`c_trivial`) or Fortran-contiguous (`f_trivial`) storage
-// buffer; returns `non_trivial` otherwise.
+// Populates the shape and number of dimensions for the set of buffers.  Returns a
+// broadcast_trivial enum value indicating whether the broadcast is "trivial"--that is, has each
+// buffer being either a singleton or a full-size, C-contiguous (`c_trivial`) or Fortran-contiguous
+// (`f_trivial`) storage buffer; returns `non_trivial` otherwise.
 template <size_t N>
-broadcast_trivial broadcast(const std::array<buffer_info, N> &buffers, ssize_t &ndim, std::vector<ssize_t> &shape) {
-    ndim = std::accumulate(buffers.begin(), buffers.end(), ssize_t(0), [](ssize_t res, const buffer_info &buf) {
-        return std::max(res, buf.ndim);
-    });
+broadcast_trivial
+broadcast(const std::array<buffer_info, N> &buffers, ssize_t &ndim, std::vector<ssize_t> &shape) {
+    ndim = std::accumulate(
+        buffers.begin(), buffers.end(), ssize_t(0), [](ssize_t res, const buffer_info &buf) {
+            return std::max(res, buf.ndim);
+        });
 
     shape.clear();
     shape.resize((size_t) ndim, 1);
 
-    // Figure out the output size, and make sure all input arrays conform (i.e. are either size 1 or
-    // the full size).
+    // Figure out the output size, and make sure all input arrays conform (i.e. are either size 1
+    // or the full size).
     for (size_t i = 0; i < N; ++i) {
         auto res_iter = shape.rbegin();
         auto end = buffers[i].shape.rend();
-        for (auto shape_iter = buffers[i].shape.rbegin(); shape_iter != end; ++shape_iter, ++res_iter) {
+        for (auto shape_iter = buffers[i].shape.rbegin(); shape_iter != end;
+             ++shape_iter, ++res_iter) {
             const auto &dim_size_in = *shape_iter;
             auto &dim_size_out = *res_iter;
 
-            // Each input dimension can either be 1 or `n`, but `n` values must match across buffers
-            if (dim_size_out == 1)
+            // Each input dimension can either be 1 or `n`, but `n` values must match across
+            // buffers
+            if (dim_size_out == 1) {
                 dim_size_out = dim_size_in;
-            else if (dim_size_in != 1 && dim_size_in != dim_size_out)
+            } else if (dim_size_in != 1 && dim_size_in != dim_size_out) {
                 pybind11_fail("pybind11::vectorize: incompatible size/dimension of inputs!");
+            }
         }
     }
 
     bool trivial_broadcast_c = true;
     bool trivial_broadcast_f = true;
     for (size_t i = 0; i < N && (trivial_broadcast_c || trivial_broadcast_f); ++i) {
-        if (buffers[i].size == 1)
+        if (buffers[i].size == 1) {
             continue;
+        }
 
         // Require the same number of dimensions:
-        if (buffers[i].ndim != ndim)
+        if (buffers[i].ndim != ndim) {
             return broadcast_trivial::non_trivial;
+        }
 
         // Require all dimensions be full-size:
-        if (!std::equal(buffers[i].shape.cbegin(), buffers[i].shape.cend(), shape.cbegin()))
+        if (!std::equal(buffers[i].shape.cbegin(), buffers[i].shape.cend(), shape.cbegin())) {
             return broadcast_trivial::non_trivial;
+        }
 
         // Check for C contiguity (but only if previous inputs were also C contiguous)
         if (trivial_broadcast_c) {
             ssize_t expect_stride = buffers[i].itemsize;
             auto end = buffers[i].shape.crend();
-            for (auto shape_iter = buffers[i].shape.crbegin(), stride_iter = buffers[i].strides.crbegin();
-                    trivial_broadcast_c && shape_iter != end; ++shape_iter, ++stride_iter) {
-                if (expect_stride == *stride_iter)
+            for (auto shape_iter = buffers[i].shape.crbegin(),
+                      stride_iter = buffers[i].strides.crbegin();
+                 trivial_broadcast_c && shape_iter != end;
+                 ++shape_iter, ++stride_iter) {
+                if (expect_stride == *stride_iter) {
                     expect_stride *= *shape_iter;
-                else
+                } else {
                     trivial_broadcast_c = false;
+                }
             }
         }
 
         // Check for Fortran contiguity (if previous inputs were also F contiguous)
         if (trivial_broadcast_f) {
             ssize_t expect_stride = buffers[i].itemsize;
             auto end = buffers[i].shape.cend();
-            for (auto shape_iter = buffers[i].shape.cbegin(), stride_iter = buffers[i].strides.cbegin();
-                    trivial_broadcast_f && shape_iter != end; ++shape_iter, ++stride_iter) {
-                if (expect_stride == *stride_iter)
+            for (auto shape_iter = buffers[i].shape.cbegin(),
+                      stride_iter = buffers[i].strides.cbegin();
+                 trivial_broadcast_f && shape_iter != end;
+                 ++shape_iter, ++stride_iter) {
+                if (expect_stride == *stride_iter) {
                     expect_stride *= *shape_iter;
-                else
+                } else {
                     trivial_broadcast_f = false;
+                }
             }
         }
     }
 
-    return
-        trivial_broadcast_c ? broadcast_trivial::c_trivial :
-        trivial_broadcast_f ? broadcast_trivial::f_trivial :
-        broadcast_trivial::non_trivial;
+    return trivial_broadcast_c   ? broadcast_trivial::c_trivial
+           : trivial_broadcast_f ? broadcast_trivial::f_trivial
+                                 : broadcast_trivial::non_trivial;
 }
 
 template <typename T>
 struct vectorize_arg {
-    static_assert(!std::is_rvalue_reference<T>::value, "Functions with rvalue reference arguments cannot be vectorized");
+    static_assert(!std::is_rvalue_reference<T>::value,
+                  "Functions with rvalue reference arguments cannot be vectorized");
     // The wrapped function gets called with this type:
     using call_type = remove_reference_t<T>;
     // Is this a vectorized argument?
-    static constexpr bool vectorize =
-        satisfies_any_of<call_type, std::is_arithmetic, is_complex, std::is_pod>::value &&
-        satisfies_none_of<call_type, std::is_pointer, std::is_array, is_std_array, std::is_enum>::value &&
-        (!std::is_reference<T>::value ||
-         (std::is_lvalue_reference<T>::value && std::is_const<call_type>::value));
+    static constexpr bool vectorize
+        = satisfies_any_of<call_type, std::is_arithmetic, is_complex, is_pod>::value
+          && satisfies_none_of<call_type,
+                               std::is_pointer,
+                               std::is_array,
+                               is_std_array,
+                               std::is_enum>::value
+          && (!std::is_reference<T>::value
+              || (std::is_lvalue_reference<T>::value && std::is_const<call_type>::value));
     // Accept this type: an array for vectorized types, otherwise the type as-is:
     using type = conditional_t<vectorize, array_t<remove_cv_t<call_type>, array::forcecast>, T>;
 };
 
+// py::vectorize when a return type is present
+template <typename Func, typename Return, typename... Args>
+struct vectorize_returned_array {
+    using Type = array_t<Return>;
+
+    static Type create(broadcast_trivial trivial, const std::vector<ssize_t> &shape) {
+        if (trivial == broadcast_trivial::f_trivial) {
+            return array_t<Return, array::f_style>(shape);
+        }
+        return array_t<Return>(shape);
+    }
+
+    static Return *mutable_data(Type &array) { return array.mutable_data(); }
+
+    static Return call(Func &f, Args &...args) { return f(args...); }
+
+    static void call(Return *out, size_t i, Func &f, Args &...args) { out[i] = f(args...); }
+};
+
+// py::vectorize when a return type is not present
+template <typename Func, typename... Args>
+struct vectorize_returned_array<Func, void, Args...> {
+    using Type = none;
+
+    static Type create(broadcast_trivial, const std::vector<ssize_t> &) { return none(); }
+
+    static void *mutable_data(Type &) { return nullptr; }
+
+    static detail::void_type call(Func &f, Args &...args) {
+        f(args...);
+        return {};
+    }
+
+    static void call(void *, size_t, Func &f, Args &...args) { f(args...); }
+};
+
 template <typename Func, typename Return, typename... Args>
 struct vectorize_helper {
+
+// NVCC for some reason breaks if NVectorized is private
+#ifdef __CUDACC__
+public:
+#else
 private:
+#endif
+
     static constexpr size_t N = sizeof...(Args);
     static constexpr size_t NVectorized = constexpr_sum(vectorize_arg<Args>::vectorize...);
-    static_assert(NVectorized >= 1,
-            "pybind11::vectorize(...) requires a function with at least one vectorizable argument");
+    static_assert(
+        NVectorized >= 1,
+        "pybind11::vectorize(...) requires a function with at least one vectorizable argument");
 
 public:
-    template <typename T>
-    explicit vectorize_helper(T &&f) : f(std::forward<T>(f)) { }
+    template <typename T,
+              // SFINAE to prevent shadowing the copy constructor.
+              typename = detail::enable_if_t<
+                  !std::is_same<vectorize_helper, typename std::decay<T>::type>::value>>
+    explicit vectorize_helper(T &&f) : f(std::forward<T>(f)) {}
 
     object operator()(typename vectorize_arg<Args>::type... args) {
         return run(args...,
                    make_index_sequence<N>(),
                    select_indices<vectorize_arg<Args>::vectorize...>(),
                    make_index_sequence<NVectorized>());
     }
 
 private:
     remove_reference_t<Func> f;
 
-    // Internal compiler error in MSVC 19.16.27025.1 (Visual Studio 2017 15.9.4), when compiling with "/permissive-" flag
-    // when arg_call_types is manually inlined.
+    // Internal compiler error in MSVC 19.16.27025.1 (Visual Studio 2017 15.9.4), when compiling
+    // with "/permissive-" flag when arg_call_types is manually inlined.
     using arg_call_types = std::tuple<typename vectorize_arg<Args>::call_type...>;
-    template <size_t Index> using param_n_t = typename std::tuple_element<Index, arg_call_types>::type;
+    template <size_t Index>
+    using param_n_t = typename std::tuple_element<Index, arg_call_types>::type;
+
+    using returned_array = vectorize_returned_array<Func, Return, Args...>;
 
     // Runs a vectorized function given arguments tuple and three index sequences:
     //     - Index is the full set of 0 ... (N-1) argument indices;
     //     - VIndex is the subset of argument indices with vectorized parameters, letting us access
     //       vectorized arguments (anything not in this sequence is passed through)
     //     - BIndex is a incremental sequence (beginning at 0) of the same size as VIndex, so that
     //       we can store vectorized buffer_infos in an array (argument VIndex has its buffer at
     //       index BIndex in the array).
-    template <size_t... Index, size_t... VIndex, size_t... BIndex> object run(
-            typename vectorize_arg<Args>::type &...args,
-            index_sequence<Index...> i_seq, index_sequence<VIndex...> vi_seq, index_sequence<BIndex...> bi_seq) {
+    template <size_t... Index, size_t... VIndex, size_t... BIndex>
+    object run(typename vectorize_arg<Args>::type &...args,
+               index_sequence<Index...> i_seq,
+               index_sequence<VIndex...> vi_seq,
+               index_sequence<BIndex...> bi_seq) {
 
         // Pointers to values the function was called with; the vectorized ones set here will start
         // out as array_t<T> pointers, but they will be changed them to T pointers before we make
         // call the wrapped function.  Non-vectorized pointers are left as-is.
-        std::array<void *, N> params{{ &args... }};
+        std::array<void *, N> params{{&args...}};
 
         // The array of `buffer_info`s of vectorized arguments:
-        std::array<buffer_info, NVectorized> buffers{{ reinterpret_cast<array *>(params[VIndex])->request()... }};
+        std::array<buffer_info, NVectorized> buffers{
+            {reinterpret_cast<array *>(params[VIndex])->request()...}};
 
         /* Determine dimensions parameters of output array */
         ssize_t nd = 0;
         std::vector<ssize_t> shape(0);
         auto trivial = broadcast(buffers, nd, shape);
-        size_t ndim = (size_t) nd;
+        auto ndim = (size_t) nd;
 
-        size_t size = std::accumulate(shape.begin(), shape.end(), (size_t) 1, std::multiplies<size_t>());
+        size_t size
+            = std::accumulate(shape.begin(), shape.end(), (size_t) 1, std::multiplies<size_t>());
 
         // If all arguments are 0-dimension arrays (i.e. single values) return a plain value (i.e.
         // not wrapped in an array).
         if (size == 1 && ndim == 0) {
             PYBIND11_EXPAND_SIDE_EFFECTS(params[VIndex] = buffers[BIndex].ptr);
-            return cast(f(*reinterpret_cast<param_n_t<Index> *>(params[Index])...));
+            return cast(
+                returned_array::call(f, *reinterpret_cast<param_n_t<Index> *>(params[Index])...));
         }
 
-        array_t<Return> result;
-        if (trivial == broadcast_trivial::f_trivial) result = array_t<Return, array::f_style>(shape);
-        else result = array_t<Return>(shape);
+        auto result = returned_array::create(trivial, shape);
+
+        PYBIND11_WARNING_PUSH
+#ifdef PYBIND11_DETECTED_CLANG_WITH_MISLEADING_CALL_STD_MOVE_EXPLICITLY_WARNING
+        PYBIND11_WARNING_DISABLE_CLANG("-Wreturn-std-move")
+#endif
 
-        if (size == 0) return std::move(result);
+        if (size == 0) {
+            return result;
+        }
 
         /* Call the function */
-        if (trivial == broadcast_trivial::non_trivial)
-            apply_broadcast(buffers, params, result, i_seq, vi_seq, bi_seq);
-        else
-            apply_trivial(buffers, params, result.mutable_data(), size, i_seq, vi_seq, bi_seq);
+        auto *mutable_data = returned_array::mutable_data(result);
+        if (trivial == broadcast_trivial::non_trivial) {
+            apply_broadcast(buffers, params, mutable_data, size, shape, i_seq, vi_seq, bi_seq);
+        } else {
+            apply_trivial(buffers, params, mutable_data, size, i_seq, vi_seq, bi_seq);
+        }
 
-        return std::move(result);
+        return result;
+        PYBIND11_WARNING_POP
     }
 
     template <size_t... Index, size_t... VIndex, size_t... BIndex>
     void apply_trivial(std::array<buffer_info, NVectorized> &buffers,
                        std::array<void *, N> &params,
                        Return *out,
                        size_t size,
-                       index_sequence<Index...>, index_sequence<VIndex...>, index_sequence<BIndex...>) {
+                       index_sequence<Index...>,
+                       index_sequence<VIndex...>,
+                       index_sequence<BIndex...>) {
 
         // Initialize an array of mutable byte references and sizes with references set to the
         // appropriate pointer in `params`; as we iterate, we'll increment each pointer by its size
         // (except for singletons, which get an increment of 0).
-        std::array<std::pair<unsigned char *&, const size_t>, NVectorized> vecparams{{
-            std::pair<unsigned char *&, const size_t>(
-                    reinterpret_cast<unsigned char *&>(params[VIndex] = buffers[BIndex].ptr),
-                    buffers[BIndex].size == 1 ? 0 : sizeof(param_n_t<VIndex>)
-            )...
-        }};
+        std::array<std::pair<unsigned char *&, const size_t>, NVectorized> vecparams{
+            {std::pair<unsigned char *&, const size_t>(
+                reinterpret_cast<unsigned char *&>(params[VIndex] = buffers[BIndex].ptr),
+                buffers[BIndex].size == 1 ? 0 : sizeof(param_n_t<VIndex>))...}};
 
         for (size_t i = 0; i < size; ++i) {
-            out[i] = f(*reinterpret_cast<param_n_t<Index> *>(params[Index])...);
-            for (auto &x : vecparams) x.first += x.second;
+            returned_array::call(
+                out, i, f, *reinterpret_cast<param_n_t<Index> *>(params[Index])...);
+            for (auto &x : vecparams) {
+                x.first += x.second;
+            }
         }
     }
 
     template <size_t... Index, size_t... VIndex, size_t... BIndex>
     void apply_broadcast(std::array<buffer_info, NVectorized> &buffers,
                          std::array<void *, N> &params,
-                         array_t<Return> &output_array,
-                         index_sequence<Index...>, index_sequence<VIndex...>, index_sequence<BIndex...>) {
-
-        buffer_info output = output_array.request();
-        multi_array_iterator<NVectorized> input_iter(buffers, output.shape);
-
-        for (array_iterator<Return> iter = array_begin<Return>(output), end = array_end<Return>(output);
-             iter != end;
-             ++iter, ++input_iter) {
-            PYBIND11_EXPAND_SIDE_EFFECTS((
-                params[VIndex] = input_iter.template data<BIndex>()
-            ));
-            *iter = f(*reinterpret_cast<param_n_t<Index> *>(std::get<Index>(params))...);
+                         Return *out,
+                         size_t size,
+                         const std::vector<ssize_t> &output_shape,
+                         index_sequence<Index...>,
+                         index_sequence<VIndex...>,
+                         index_sequence<BIndex...>) {
+
+        multi_array_iterator<NVectorized> input_iter(buffers, output_shape);
+
+        for (size_t i = 0; i < size; ++i, ++input_iter) {
+            PYBIND11_EXPAND_SIDE_EFFECTS((params[VIndex] = input_iter.template data<BIndex>()));
+            returned_array::call(
+                out, i, f, *reinterpret_cast<param_n_t<Index> *>(std::get<Index>(params))...);
         }
     }
 };
 
 template <typename Func, typename Return, typename... Args>
-vectorize_helper<Func, Return, Args...>
-vectorize_extractor(const Func &f, Return (*) (Args ...)) {
+vectorize_helper<Func, Return, Args...> vectorize_extractor(const Func &f, Return (*)(Args...)) {
     return detail::vectorize_helper<Func, Return, Args...>(f);
 }
 
-template <typename T, int Flags> struct handle_type_name<array_t<T, Flags>> {
-    static constexpr auto name = _("numpy.ndarray[") + npy_format_descriptor<T>::name + _("]");
+template <typename T, int Flags>
+struct handle_type_name<array_t<T, Flags>> {
+    static constexpr auto name
+        = const_name("numpy.ndarray[") + npy_format_descriptor<T>::name + const_name("]");
 };
 
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
 
 // Vanilla pointer vectorizer:
 template <typename Return, typename... Args>
-detail::vectorize_helper<Return (*)(Args...), Return, Args...>
-vectorize(Return (*f) (Args ...)) {
+detail::vectorize_helper<Return (*)(Args...), Return, Args...> vectorize(Return (*f)(Args...)) {
     return detail::vectorize_helper<Return (*)(Args...), Return, Args...>(f);
 }
 
 // lambda vectorizer:
 template <typename Func, detail::enable_if_t<detail::is_lambda<Func>::value, int> = 0>
-auto vectorize(Func &&f) -> decltype(
-        detail::vectorize_extractor(std::forward<Func>(f), (detail::function_signature_t<Func> *) nullptr)) {
-    return detail::vectorize_extractor(std::forward<Func>(f), (detail::function_signature_t<Func> *) nullptr);
+auto vectorize(Func &&f)
+    -> decltype(detail::vectorize_extractor(std::forward<Func>(f),
+                                            (detail::function_signature_t<Func> *) nullptr)) {
+    return detail::vectorize_extractor(std::forward<Func>(f),
+                                       (detail::function_signature_t<Func> *) nullptr);
 }
 
 // Vectorize a class method (non-const):
-template <typename Return, typename Class, typename... Args,
-          typename Helper = detail::vectorize_helper<decltype(std::mem_fn(std::declval<Return (Class::*)(Args...)>())), Return, Class *, Args...>>
+template <typename Return,
+          typename Class,
+          typename... Args,
+          typename Helper = detail::vectorize_helper<
+              decltype(std::mem_fn(std::declval<Return (Class::*)(Args...)>())),
+              Return,
+              Class *,
+              Args...>>
 Helper vectorize(Return (Class::*f)(Args...)) {
     return Helper(std::mem_fn(f));
 }
 
 // Vectorize a class method (const):
-template <typename Return, typename Class, typename... Args,
-          typename Helper = detail::vectorize_helper<decltype(std::mem_fn(std::declval<Return (Class::*)(Args...) const>())), Return, const Class *, Args...>>
+template <typename Return,
+          typename Class,
+          typename... Args,
+          typename Helper = detail::vectorize_helper<
+              decltype(std::mem_fn(std::declval<Return (Class::*)(Args...) const>())),
+              Return,
+              const Class *,
+              Args...>>
 Helper vectorize(Return (Class::*f)(Args...) const) {
     return Helper(std::mem_fn(f));
 }
 
-NAMESPACE_END(PYBIND11_NAMESPACE)
-
-#if defined(_MSC_VER)
-#pragma warning(pop)
-#endif
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/operators.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/operators.h`

 * *Files 16% similar despite different names*

```diff
@@ -7,162 +7,196 @@
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
 #include "pybind11.h"
 
-#if defined(__clang__) && !defined(__INTEL_COMPILER)
-#  pragma clang diagnostic ignored "-Wunsequenced" // multiple unsequenced modifications to 'self' (when using def(py::self OP Type()))
-#elif defined(_MSC_VER)
-#  pragma warning(push)
-#  pragma warning(disable: 4127) // warning C4127: Conditional expression is constant
-#endif
-
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
 /// Enumeration with all supported operator types
 enum op_id : int {
-    op_add, op_sub, op_mul, op_div, op_mod, op_divmod, op_pow, op_lshift,
-    op_rshift, op_and, op_xor, op_or, op_neg, op_pos, op_abs, op_invert,
-    op_int, op_long, op_float, op_str, op_cmp, op_gt, op_ge, op_lt, op_le,
-    op_eq, op_ne, op_iadd, op_isub, op_imul, op_idiv, op_imod, op_ilshift,
-    op_irshift, op_iand, op_ixor, op_ior, op_complex, op_bool, op_nonzero,
-    op_repr, op_truediv, op_itruediv, op_hash
+    op_add,
+    op_sub,
+    op_mul,
+    op_div,
+    op_mod,
+    op_divmod,
+    op_pow,
+    op_lshift,
+    op_rshift,
+    op_and,
+    op_xor,
+    op_or,
+    op_neg,
+    op_pos,
+    op_abs,
+    op_invert,
+    op_int,
+    op_long,
+    op_float,
+    op_str,
+    op_cmp,
+    op_gt,
+    op_ge,
+    op_lt,
+    op_le,
+    op_eq,
+    op_ne,
+    op_iadd,
+    op_isub,
+    op_imul,
+    op_idiv,
+    op_imod,
+    op_ilshift,
+    op_irshift,
+    op_iand,
+    op_ixor,
+    op_ior,
+    op_complex,
+    op_bool,
+    op_nonzero,
+    op_repr,
+    op_truediv,
+    op_itruediv,
+    op_hash
 };
 
 enum op_type : int {
     op_l, /* base type on left */
     op_r, /* base type on right */
     op_u  /* unary operator */
 };
 
-struct self_t { };
+struct self_t {};
 static const self_t self = self_t();
 
 /// Type for an unused type slot
-struct undefined_t { };
+struct undefined_t {};
 
 /// Don't warn about an unused variable
 inline self_t __self() { return self; }
 
 /// base template of operator implementations
-template <op_id, op_type, typename B, typename L, typename R> struct op_impl { };
+template <op_id, op_type, typename B, typename L, typename R>
+struct op_impl {};
 
 /// Operator implementation generator
-template <op_id id, op_type ot, typename L, typename R> struct op_ {
-    template <typename Class, typename... Extra> void execute(Class &cl, const Extra&... extra) const {
+template <op_id id, op_type ot, typename L, typename R>
+struct op_ {
+    static constexpr bool op_enable_if_hook = true;
+    template <typename Class, typename... Extra>
+    void execute(Class &cl, const Extra &...extra) const {
         using Base = typename Class::type;
         using L_type = conditional_t<std::is_same<L, self_t>::value, Base, L>;
         using R_type = conditional_t<std::is_same<R, self_t>::value, Base, R>;
         using op = op_impl<id, ot, Base, L_type, R_type>;
         cl.def(op::name(), &op::execute, is_operator(), extra...);
-        #if PY_MAJOR_VERSION < 3
-        if (id == op_truediv || id == op_itruediv)
-            cl.def(id == op_itruediv ? "__idiv__" : ot == op_l ? "__div__" : "__rdiv__",
-                    &op::execute, is_operator(), extra...);
-        #endif
     }
-    template <typename Class, typename... Extra> void execute_cast(Class &cl, const Extra&... extra) const {
+    template <typename Class, typename... Extra>
+    void execute_cast(Class &cl, const Extra &...extra) const {
         using Base = typename Class::type;
         using L_type = conditional_t<std::is_same<L, self_t>::value, Base, L>;
         using R_type = conditional_t<std::is_same<R, self_t>::value, Base, R>;
         using op = op_impl<id, ot, Base, L_type, R_type>;
         cl.def(op::name(), &op::execute_cast, is_operator(), extra...);
-        #if PY_MAJOR_VERSION < 3
-        if (id == op_truediv || id == op_itruediv)
-            cl.def(id == op_itruediv ? "__idiv__" : ot == op_l ? "__div__" : "__rdiv__",
-                    &op::execute, is_operator(), extra...);
-        #endif
     }
 };
 
-#define PYBIND11_BINARY_OPERATOR(id, rid, op, expr)                                    \
-template <typename B, typename L, typename R> struct op_impl<op_##id, op_l, B, L, R> { \
-    static char const* name() { return "__" #id "__"; }                                \
-    static auto execute(const L &l, const R &r) -> decltype(expr) { return (expr); }   \
-    static B execute_cast(const L &l, const R &r) { return B(expr); }                  \
-};                                                                                     \
-template <typename B, typename L, typename R> struct op_impl<op_##id, op_r, B, L, R> { \
-    static char const* name() { return "__" #rid "__"; }                               \
-    static auto execute(const R &r, const L &l) -> decltype(expr) { return (expr); }   \
-    static B execute_cast(const R &r, const L &l) { return B(expr); }                  \
-};                                                                                     \
-inline op_<op_##id, op_l, self_t, self_t> op(const self_t &, const self_t &) {         \
-    return op_<op_##id, op_l, self_t, self_t>();                                       \
-}                                                                                      \
-template <typename T> op_<op_##id, op_l, self_t, T> op(const self_t &, const T &) {    \
-    return op_<op_##id, op_l, self_t, T>();                                            \
-}                                                                                      \
-template <typename T> op_<op_##id, op_r, T, self_t> op(const T &, const self_t &) {    \
-    return op_<op_##id, op_r, T, self_t>();                                            \
-}
-
-#define PYBIND11_INPLACE_OPERATOR(id, op, expr)                                        \
-template <typename B, typename L, typename R> struct op_impl<op_##id, op_l, B, L, R> { \
-    static char const* name() { return "__" #id "__"; }                                \
-    static auto execute(L &l, const R &r) -> decltype(expr) { return expr; }           \
-    static B execute_cast(L &l, const R &r) { return B(expr); }                        \
-};                                                                                     \
-template <typename T> op_<op_##id, op_l, self_t, T> op(const self_t &, const T &) {    \
-    return op_<op_##id, op_l, self_t, T>();                                            \
-}
-
-#define PYBIND11_UNARY_OPERATOR(id, op, expr)                                          \
-template <typename B, typename L> struct op_impl<op_##id, op_u, B, L, undefined_t> {   \
-    static char const* name() { return "__" #id "__"; }                                \
-    static auto execute(const L &l) -> decltype(expr) { return expr; }                 \
-    static B execute_cast(const L &l) { return B(expr); }                              \
-};                                                                                     \
-inline op_<op_##id, op_u, self_t, undefined_t> op(const self_t &) {                    \
-    return op_<op_##id, op_u, self_t, undefined_t>();                                  \
-}
-
-PYBIND11_BINARY_OPERATOR(sub,       rsub,         operator-,    l - r)
-PYBIND11_BINARY_OPERATOR(add,       radd,         operator+,    l + r)
-PYBIND11_BINARY_OPERATOR(mul,       rmul,         operator*,    l * r)
-PYBIND11_BINARY_OPERATOR(truediv,   rtruediv,     operator/,    l / r)
-PYBIND11_BINARY_OPERATOR(mod,       rmod,         operator%,    l % r)
-PYBIND11_BINARY_OPERATOR(lshift,    rlshift,      operator<<,   l << r)
-PYBIND11_BINARY_OPERATOR(rshift,    rrshift,      operator>>,   l >> r)
-PYBIND11_BINARY_OPERATOR(and,       rand,         operator&,    l & r)
-PYBIND11_BINARY_OPERATOR(xor,       rxor,         operator^,    l ^ r)
-PYBIND11_BINARY_OPERATOR(eq,        eq,           operator==,   l == r)
-PYBIND11_BINARY_OPERATOR(ne,        ne,           operator!=,   l != r)
-PYBIND11_BINARY_OPERATOR(or,        ror,          operator|,    l | r)
-PYBIND11_BINARY_OPERATOR(gt,        lt,           operator>,    l > r)
-PYBIND11_BINARY_OPERATOR(ge,        le,           operator>=,   l >= r)
-PYBIND11_BINARY_OPERATOR(lt,        gt,           operator<,    l < r)
-PYBIND11_BINARY_OPERATOR(le,        ge,           operator<=,   l <= r)
-//PYBIND11_BINARY_OPERATOR(pow,       rpow,         pow,          std::pow(l,  r))
-PYBIND11_INPLACE_OPERATOR(iadd,     operator+=,   l += r)
-PYBIND11_INPLACE_OPERATOR(isub,     operator-=,   l -= r)
-PYBIND11_INPLACE_OPERATOR(imul,     operator*=,   l *= r)
-PYBIND11_INPLACE_OPERATOR(itruediv, operator/=,   l /= r)
-PYBIND11_INPLACE_OPERATOR(imod,     operator%=,   l %= r)
-PYBIND11_INPLACE_OPERATOR(ilshift,  operator<<=,  l <<= r)
-PYBIND11_INPLACE_OPERATOR(irshift,  operator>>=,  l >>= r)
-PYBIND11_INPLACE_OPERATOR(iand,     operator&=,   l &= r)
-PYBIND11_INPLACE_OPERATOR(ixor,     operator^=,   l ^= r)
-PYBIND11_INPLACE_OPERATOR(ior,      operator|=,   l |= r)
-PYBIND11_UNARY_OPERATOR(neg,        operator-,    -l)
-PYBIND11_UNARY_OPERATOR(pos,        operator+,    +l)
-PYBIND11_UNARY_OPERATOR(abs,        abs,          std::abs(l))
-PYBIND11_UNARY_OPERATOR(hash,       hash,         std::hash<L>()(l))
-PYBIND11_UNARY_OPERATOR(invert,     operator~,    (~l))
-PYBIND11_UNARY_OPERATOR(bool,       operator!,    !!l)
-PYBIND11_UNARY_OPERATOR(int,        int_,         (int) l)
-PYBIND11_UNARY_OPERATOR(float,      float_,       (double) l)
+#define PYBIND11_BINARY_OPERATOR(id, rid, op, expr)                                               \
+    template <typename B, typename L, typename R>                                                 \
+    struct op_impl<op_##id, op_l, B, L, R> {                                                      \
+        static char const *name() { return "__" #id "__"; }                                       \
+        static auto execute(const L &l, const R &r) -> decltype(expr) { return (expr); }          \
+        static B execute_cast(const L &l, const R &r) { return B(expr); }                         \
+    };                                                                                            \
+    template <typename B, typename L, typename R>                                                 \
+    struct op_impl<op_##id, op_r, B, L, R> {                                                      \
+        static char const *name() { return "__" #rid "__"; }                                      \
+        static auto execute(const R &r, const L &l) -> decltype(expr) { return (expr); }          \
+        static B execute_cast(const R &r, const L &l) { return B(expr); }                         \
+    };                                                                                            \
+    inline op_<op_##id, op_l, self_t, self_t> op(const self_t &, const self_t &) {                \
+        return op_<op_##id, op_l, self_t, self_t>();                                              \
+    }                                                                                             \
+    template <typename T>                                                                         \
+    op_<op_##id, op_l, self_t, T> op(const self_t &, const T &) {                                 \
+        return op_<op_##id, op_l, self_t, T>();                                                   \
+    }                                                                                             \
+    template <typename T>                                                                         \
+    op_<op_##id, op_r, T, self_t> op(const T &, const self_t &) {                                 \
+        return op_<op_##id, op_r, T, self_t>();                                                   \
+    }
+
+#define PYBIND11_INPLACE_OPERATOR(id, op, expr)                                                   \
+    template <typename B, typename L, typename R>                                                 \
+    struct op_impl<op_##id, op_l, B, L, R> {                                                      \
+        static char const *name() { return "__" #id "__"; }                                       \
+        static auto execute(L &l, const R &r) -> decltype(expr) { return expr; }                  \
+        static B execute_cast(L &l, const R &r) { return B(expr); }                               \
+    };                                                                                            \
+    template <typename T>                                                                         \
+    op_<op_##id, op_l, self_t, T> op(const self_t &, const T &) {                                 \
+        return op_<op_##id, op_l, self_t, T>();                                                   \
+    }
+
+#define PYBIND11_UNARY_OPERATOR(id, op, expr)                                                     \
+    template <typename B, typename L>                                                             \
+    struct op_impl<op_##id, op_u, B, L, undefined_t> {                                            \
+        static char const *name() { return "__" #id "__"; }                                       \
+        static auto execute(const L &l) -> decltype(expr) { return expr; }                        \
+        static B execute_cast(const L &l) { return B(expr); }                                     \
+    };                                                                                            \
+    inline op_<op_##id, op_u, self_t, undefined_t> op(const self_t &) {                           \
+        return op_<op_##id, op_u, self_t, undefined_t>();                                         \
+    }
+
+PYBIND11_BINARY_OPERATOR(sub, rsub, operator-, l - r)
+PYBIND11_BINARY_OPERATOR(add, radd, operator+, l + r)
+PYBIND11_BINARY_OPERATOR(mul, rmul, operator*, l *r)
+PYBIND11_BINARY_OPERATOR(truediv, rtruediv, operator/, l / r)
+PYBIND11_BINARY_OPERATOR(mod, rmod, operator%, l % r)
+PYBIND11_BINARY_OPERATOR(lshift, rlshift, operator<<, l << r)
+PYBIND11_BINARY_OPERATOR(rshift, rrshift, operator>>, l >> r)
+PYBIND11_BINARY_OPERATOR(and, rand, operator&, l &r)
+PYBIND11_BINARY_OPERATOR(xor, rxor, operator^, l ^ r)
+PYBIND11_BINARY_OPERATOR(eq, eq, operator==, l == r)
+PYBIND11_BINARY_OPERATOR(ne, ne, operator!=, l != r)
+PYBIND11_BINARY_OPERATOR(or, ror, operator|, l | r)
+PYBIND11_BINARY_OPERATOR(gt, lt, operator>, l > r)
+PYBIND11_BINARY_OPERATOR(ge, le, operator>=, l >= r)
+PYBIND11_BINARY_OPERATOR(lt, gt, operator<, l < r)
+PYBIND11_BINARY_OPERATOR(le, ge, operator<=, l <= r)
+// PYBIND11_BINARY_OPERATOR(pow,       rpow,         pow,          std::pow(l,  r))
+PYBIND11_INPLACE_OPERATOR(iadd, operator+=, l += r)
+PYBIND11_INPLACE_OPERATOR(isub, operator-=, l -= r)
+PYBIND11_INPLACE_OPERATOR(imul, operator*=, l *= r)
+PYBIND11_INPLACE_OPERATOR(itruediv, operator/=, l /= r)
+PYBIND11_INPLACE_OPERATOR(imod, operator%=, l %= r)
+PYBIND11_INPLACE_OPERATOR(ilshift, operator<<=, l <<= r)
+PYBIND11_INPLACE_OPERATOR(irshift, operator>>=, l >>= r)
+PYBIND11_INPLACE_OPERATOR(iand, operator&=, l &= r)
+PYBIND11_INPLACE_OPERATOR(ixor, operator^=, l ^= r)
+PYBIND11_INPLACE_OPERATOR(ior, operator|=, l |= r)
+PYBIND11_UNARY_OPERATOR(neg, operator-, -l)
+PYBIND11_UNARY_OPERATOR(pos, operator+, +l)
+// WARNING: This usage of `abs` should only be done for existing STL overloads.
+// Adding overloads directly in to the `std::` namespace is advised against:
+// https://en.cppreference.com/w/cpp/language/extending_std
+PYBIND11_UNARY_OPERATOR(abs, abs, std::abs(l))
+PYBIND11_UNARY_OPERATOR(hash, hash, std::hash<L>()(l))
+PYBIND11_UNARY_OPERATOR(invert, operator~, (~l))
+PYBIND11_UNARY_OPERATOR(bool, operator!, !!l)
+PYBIND11_UNARY_OPERATOR(int, int_, (int) l)
+PYBIND11_UNARY_OPERATOR(float, float_, (double) l)
 
 #undef PYBIND11_BINARY_OPERATOR
 #undef PYBIND11_INPLACE_OPERATOR
 #undef PYBIND11_UNARY_OPERATOR
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
 
 using detail::self;
+// Add named operators so that they are accessible via `py::`.
+using detail::hash;
 
-NAMESPACE_END(PYBIND11_NAMESPACE)
-
-#if defined(_MSC_VER)
-#  pragma warning(pop)
-#endif
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/pybind11.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/pybind11.h`

 * *Files 14% similar despite different names*

```diff
@@ -6,453 +6,706 @@
 
     All rights reserved. Use of this source code is governed by a
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
-#if defined(__INTEL_COMPILER)
-#  pragma warning push
-#  pragma warning disable 68    // integer conversion resulted in a change of sign
-#  pragma warning disable 186   // pointless comparison of unsigned integer with zero
-#  pragma warning disable 878   // incompatible exception specifications
-#  pragma warning disable 1334  // the "template" keyword used for syntactic disambiguation may only be used within a template
-#  pragma warning disable 1682  // implicit conversion of a 64-bit integral type to a smaller integral type (potential portability problem)
-#  pragma warning disable 1786  // function "strdup" was declared deprecated
-#  pragma warning disable 1875  // offsetof applied to non-POD (Plain Old Data) types is nonstandard
-#  pragma warning disable 2196  // warning #2196: routine is both "inline" and "noinline"
-#elif defined(_MSC_VER)
-#  pragma warning(push)
-#  pragma warning(disable: 4100) // warning C4100: Unreferenced formal parameter
-#  pragma warning(disable: 4127) // warning C4127: Conditional expression is constant
-#  pragma warning(disable: 4512) // warning C4512: Assignment operator was implicitly defined as deleted
-#  pragma warning(disable: 4800) // warning C4800: 'int': forcing value to bool 'true' or 'false' (performance warning)
-#  pragma warning(disable: 4996) // warning C4996: The POSIX name for this item is deprecated. Instead, use the ISO C and C++ conformant name
-#  pragma warning(disable: 4702) // warning C4702: unreachable code
-#  pragma warning(disable: 4522) // warning C4522: multiple assignment operators specified
-#elif defined(__GNUG__) && !defined(__clang__)
-#  pragma GCC diagnostic push
-#  pragma GCC diagnostic ignored "-Wunused-but-set-parameter"
-#  pragma GCC diagnostic ignored "-Wunused-but-set-variable"
-#  pragma GCC diagnostic ignored "-Wmissing-field-initializers"
-#  pragma GCC diagnostic ignored "-Wstrict-aliasing"
-#  pragma GCC diagnostic ignored "-Wattributes"
-#  if __GNUC__ >= 7
-#    pragma GCC diagnostic ignored "-Wnoexcept-type"
-#  endif
-#endif
-
-#include "attr.h"
-#include "options.h"
 #include "detail/class.h"
 #include "detail/init.h"
+#include "attr.h"
+#include "gil.h"
+#include "options.h"
 
+#include <cstdlib>
+#include <cstring>
+#include <memory>
+#include <new>
+#include <string>
+#include <utility>
+#include <vector>
+
+#if defined(__cpp_lib_launder) && !(defined(_MSC_VER) && (_MSC_VER < 1914))
+#    define PYBIND11_STD_LAUNDER std::launder
+#    define PYBIND11_HAS_STD_LAUNDER 1
+#else
+#    define PYBIND11_STD_LAUNDER
+#    define PYBIND11_HAS_STD_LAUNDER 0
+#endif
 #if defined(__GNUG__) && !defined(__clang__)
-#  include <cxxabi.h>
+#    include <cxxabi.h>
+#endif
+
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+
+/* https://stackoverflow.com/questions/46798456/handling-gccs-noexcept-type-warning
+   This warning is about ABI compatibility, not code health.
+   It is only actually needed in a couple places, but apparently GCC 7 "generates this warning if
+   and only if the first template instantiation ... involves noexcept" [stackoverflow], therefore
+   it could get triggered from seemingly random places, depending on user code.
+   No other GCC version generates this warning.
+ */
+#if defined(__GNUC__) && __GNUC__ == 7
+PYBIND11_WARNING_DISABLE_GCC("-Wnoexcept-type")
+#endif
+
+PYBIND11_WARNING_DISABLE_MSVC(4127)
+
+PYBIND11_NAMESPACE_BEGIN(detail)
+
+// Apply all the extensions translators from a list
+// Return true if one of the translators completed without raising an exception
+// itself. Return of false indicates that if there are other translators
+// available, they should be tried.
+inline bool apply_exception_translators(std::forward_list<ExceptionTranslator> &translators) {
+    auto last_exception = std::current_exception();
+
+    for (auto &translator : translators) {
+        try {
+            translator(last_exception);
+            return true;
+        } catch (...) {
+            last_exception = std::current_exception();
+        }
+    }
+    return false;
+}
+
+#if defined(_MSC_VER)
+#    define PYBIND11_COMPAT_STRDUP _strdup
+#else
+#    define PYBIND11_COMPAT_STRDUP strdup
 #endif
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_END(detail)
 
 /// Wraps an arbitrary C++ function/method/lambda function/.. into a callable Python object
 class cpp_function : public function {
 public:
-    cpp_function() { }
-    cpp_function(std::nullptr_t) { }
+    cpp_function() = default;
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    cpp_function(std::nullptr_t) {}
 
     /// Construct a cpp_function from a vanilla function pointer
     template <typename Return, typename... Args, typename... Extra>
-    cpp_function(Return (*f)(Args...), const Extra&... extra) {
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    cpp_function(Return (*f)(Args...), const Extra &...extra) {
         initialize(f, f, extra...);
     }
 
     /// Construct a cpp_function from a lambda function (possibly with internal state)
-    template <typename Func, typename... Extra,
+    template <typename Func,
+              typename... Extra,
               typename = detail::enable_if_t<detail::is_lambda<Func>::value>>
-    cpp_function(Func &&f, const Extra&... extra) {
-        initialize(std::forward<Func>(f),
-                   (detail::function_signature_t<Func> *) nullptr, extra...);
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    cpp_function(Func &&f, const Extra &...extra) {
+        initialize(
+            std::forward<Func>(f), (detail::function_signature_t<Func> *) nullptr, extra...);
+    }
+
+    /// Construct a cpp_function from a class method (non-const, no ref-qualifier)
+    template <typename Return, typename Class, typename... Arg, typename... Extra>
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    cpp_function(Return (Class::*f)(Arg...), const Extra &...extra) {
+        initialize(
+            [f](Class *c, Arg... args) -> Return { return (c->*f)(std::forward<Arg>(args)...); },
+            (Return(*)(Class *, Arg...)) nullptr,
+            extra...);
+    }
+
+    /// Construct a cpp_function from a class method (non-const, lvalue ref-qualifier)
+    /// A copy of the overload for non-const functions without explicit ref-qualifier
+    /// but with an added `&`.
+    template <typename Return, typename Class, typename... Arg, typename... Extra>
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    cpp_function(Return (Class::*f)(Arg...) &, const Extra &...extra) {
+        initialize(
+            [f](Class *c, Arg... args) -> Return { return (c->*f)(std::forward<Arg>(args)...); },
+            (Return(*)(Class *, Arg...)) nullptr,
+            extra...);
     }
 
-    /// Construct a cpp_function from a class method (non-const)
+    /// Construct a cpp_function from a class method (const, no ref-qualifier)
     template <typename Return, typename Class, typename... Arg, typename... Extra>
-    cpp_function(Return (Class::*f)(Arg...), const Extra&... extra) {
-        initialize([f](Class *c, Arg... args) -> Return { return (c->*f)(args...); },
-                   (Return (*) (Class *, Arg...)) nullptr, extra...);
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    cpp_function(Return (Class::*f)(Arg...) const, const Extra &...extra) {
+        initialize([f](const Class *c,
+                       Arg... args) -> Return { return (c->*f)(std::forward<Arg>(args)...); },
+                   (Return(*)(const Class *, Arg...)) nullptr,
+                   extra...);
     }
 
-    /// Construct a cpp_function from a class method (const)
+    /// Construct a cpp_function from a class method (const, lvalue ref-qualifier)
+    /// A copy of the overload for const functions without explicit ref-qualifier
+    /// but with an added `&`.
     template <typename Return, typename Class, typename... Arg, typename... Extra>
-    cpp_function(Return (Class::*f)(Arg...) const, const Extra&... extra) {
-        initialize([f](const Class *c, Arg... args) -> Return { return (c->*f)(args...); },
-                   (Return (*)(const Class *, Arg ...)) nullptr, extra...);
+    // NOLINTNEXTLINE(google-explicit-constructor)
+    cpp_function(Return (Class::*f)(Arg...) const &, const Extra &...extra) {
+        initialize([f](const Class *c,
+                       Arg... args) -> Return { return (c->*f)(std::forward<Arg>(args)...); },
+                   (Return(*)(const Class *, Arg...)) nullptr,
+                   extra...);
     }
 
     /// Return the function name
     object name() const { return attr("__name__"); }
 
 protected:
+    struct InitializingFunctionRecordDeleter {
+        // `destruct(function_record, false)`: `initialize_generic` copies strings and
+        // takes care of cleaning up in case of exceptions. So pass `false` to `free_strings`.
+        void operator()(detail::function_record *rec) { destruct(rec, false); }
+    };
+    using unique_function_record
+        = std::unique_ptr<detail::function_record, InitializingFunctionRecordDeleter>;
+
     /// Space optimization: don't inline this frequently instantiated fragment
-    PYBIND11_NOINLINE detail::function_record *make_function_record() {
-        return new detail::function_record();
+    PYBIND11_NOINLINE unique_function_record make_function_record() {
+        return unique_function_record(new detail::function_record());
     }
 
     /// Special internal constructor for functors, lambda functions, etc.
     template <typename Func, typename Return, typename... Args, typename... Extra>
-    void initialize(Func &&f, Return (*)(Args...), const Extra&... extra) {
+    void initialize(Func &&f, Return (*)(Args...), const Extra &...extra) {
         using namespace detail;
-        struct capture { remove_reference_t<Func> f; };
+        struct capture {
+            remove_reference_t<Func> f;
+        };
 
-        /* Store the function including any extra state it might have (e.g. a lambda capture object) */
-        auto rec = make_function_record();
+        /* Store the function including any extra state it might have (e.g. a lambda capture
+         * object) */
+        // The unique_ptr makes sure nothing is leaked in case of an exception.
+        auto unique_rec = make_function_record();
+        auto *rec = unique_rec.get();
 
         /* Store the capture object directly in the function record if there is enough space */
         if (sizeof(capture) <= sizeof(rec->data)) {
             /* Without these pragmas, GCC warns that there might not be
                enough space to use the placement new operator. However, the
                'if' statement above ensures that this is the case. */
-#if defined(__GNUG__) && !defined(__clang__) && __GNUC__ >= 6
-#  pragma GCC diagnostic push
-#  pragma GCC diagnostic ignored "-Wplacement-new"
+            PYBIND11_WARNING_PUSH
+
+#if defined(__GNUG__) && __GNUC__ >= 6
+            PYBIND11_WARNING_DISABLE_GCC("-Wplacement-new")
 #endif
-            new ((capture *) &rec->data) capture { std::forward<Func>(f) };
-#if defined(__GNUG__) && !defined(__clang__) && __GNUC__ >= 6
-#  pragma GCC diagnostic pop
+
+            new ((capture *) &rec->data) capture{std::forward<Func>(f)};
+
+#if !PYBIND11_HAS_STD_LAUNDER
+            PYBIND11_WARNING_DISABLE_GCC("-Wstrict-aliasing")
 #endif
-            if (!std::is_trivially_destructible<Func>::value)
-                rec->free_data = [](function_record *r) { ((capture *) &r->data)->~capture(); };
+
+            // UB without std::launder, but without breaking ABI and/or
+            // a significant refactoring it's "impossible" to solve.
+            if (!std::is_trivially_destructible<capture>::value) {
+                rec->free_data = [](function_record *r) {
+                    auto data = PYBIND11_STD_LAUNDER((capture *) &r->data);
+                    (void) data;
+                    data->~capture();
+                };
+            }
+            PYBIND11_WARNING_POP
         } else {
-            rec->data[0] = new capture { std::forward<Func>(f) };
+            rec->data[0] = new capture{std::forward<Func>(f)};
             rec->free_data = [](function_record *r) { delete ((capture *) r->data[0]); };
         }
 
         /* Type casters for the function arguments and return value */
         using cast_in = argument_loader<Args...>;
-        using cast_out = make_caster<
-            conditional_t<std::is_void<Return>::value, void_type, Return>
-        >;
+        using cast_out
+            = make_caster<conditional_t<std::is_void<Return>::value, void_type, Return>>;
 
-        static_assert(expected_num_args<Extra...>(sizeof...(Args), cast_in::has_args, cast_in::has_kwargs),
-                      "The number of argument annotations does not match the number of function arguments");
+        static_assert(
+            expected_num_args<Extra...>(
+                sizeof...(Args), cast_in::args_pos >= 0, cast_in::has_kwargs),
+            "The number of argument annotations does not match the number of function arguments");
 
         /* Dispatch code which converts function arguments and performs the actual function call */
         rec->impl = [](function_call &call) -> handle {
             cast_in args_converter;
 
             /* Try to cast the function arguments into the C++ domain */
-            if (!args_converter.load_args(call))
+            if (!args_converter.load_args(call)) {
                 return PYBIND11_TRY_NEXT_OVERLOAD;
+            }
 
             /* Invoke call policy pre-call hook */
             process_attributes<Extra...>::precall(call);
 
             /* Get a pointer to the capture object */
-            auto data = (sizeof(capture) <= sizeof(call.func.data)
-                         ? &call.func.data : call.func.data[0]);
-            capture *cap = const_cast<capture *>(reinterpret_cast<const capture *>(data));
+            const auto *data = (sizeof(capture) <= sizeof(call.func.data) ? &call.func.data
+                                                                          : call.func.data[0]);
+            auto *cap = const_cast<capture *>(reinterpret_cast<const capture *>(data));
 
             /* Override policy for rvalues -- usually to enforce rvp::move on an rvalue */
-            return_value_policy policy = return_value_policy_override<Return>::policy(call.func.policy);
+            return_value_policy policy
+                = return_value_policy_override<Return>::policy(call.func.policy);
 
             /* Function scope guard -- defaults to the compile-to-nothing `void_type` */
             using Guard = extract_guard_t<Extra...>;
 
             /* Perform the function call */
-            handle result = cast_out::cast(
-                std::move(args_converter).template call<Return, Guard>(cap->f), policy, call.parent);
+            handle result
+                = cast_out::cast(std::move(args_converter).template call<Return, Guard>(cap->f),
+                                 policy,
+                                 call.parent);
 
             /* Invoke call policy post-call hook */
             process_attributes<Extra...>::postcall(call, result);
 
             return result;
         };
 
+        rec->nargs_pos = cast_in::args_pos >= 0
+                             ? static_cast<std::uint16_t>(cast_in::args_pos)
+                             : sizeof...(Args) - cast_in::has_kwargs; // Will get reduced more if
+                                                                      // we have a kw_only
+        rec->has_args = cast_in::args_pos >= 0;
+        rec->has_kwargs = cast_in::has_kwargs;
+
         /* Process any user-provided function attributes */
         process_attributes<Extra...>::init(extra..., rec);
 
-        /* Generate a readable signature describing the function's arguments and return value types */
-        static constexpr auto signature = _("(") + cast_in::arg_names + _(") -> ") + cast_out::name;
+        {
+            constexpr bool has_kw_only_args = any_of<std::is_same<kw_only, Extra>...>::value,
+                           has_pos_only_args = any_of<std::is_same<pos_only, Extra>...>::value,
+                           has_arg_annotations = any_of<is_keyword<Extra>...>::value;
+            static_assert(has_arg_annotations || !has_kw_only_args,
+                          "py::kw_only requires the use of argument annotations");
+            static_assert(has_arg_annotations || !has_pos_only_args,
+                          "py::pos_only requires the use of argument annotations (for docstrings "
+                          "and aligning the annotations to the argument)");
+
+            static_assert(constexpr_sum(is_kw_only<Extra>::value...) <= 1,
+                          "py::kw_only may be specified only once");
+            static_assert(constexpr_sum(is_pos_only<Extra>::value...) <= 1,
+                          "py::pos_only may be specified only once");
+            constexpr auto kw_only_pos = constexpr_first<is_kw_only, Extra...>();
+            constexpr auto pos_only_pos = constexpr_first<is_pos_only, Extra...>();
+            static_assert(!(has_kw_only_args && has_pos_only_args) || pos_only_pos < kw_only_pos,
+                          "py::pos_only must come before py::kw_only");
+        }
+
+        /* Generate a readable signature describing the function's arguments and return
+           value types */
+        static constexpr auto signature
+            = const_name("(") + cast_in::arg_names + const_name(") -> ") + cast_out::name;
         PYBIND11_DESCR_CONSTEXPR auto types = decltype(signature)::types();
 
         /* Register the function with Python from generic (non-templated) code */
-        initialize_generic(rec, signature.text, types.data(), sizeof...(Args));
-
-        if (cast_in::has_args) rec->has_args = true;
-        if (cast_in::has_kwargs) rec->has_kwargs = true;
+        // Pass on the ownership over the `unique_rec` to `initialize_generic`. `rec` stays valid.
+        initialize_generic(std::move(unique_rec), signature.text, types.data(), sizeof...(Args));
 
         /* Stash some additional information used by an important optimization in 'functional.h' */
         using FunctionType = Return (*)(Args...);
-        constexpr bool is_function_ptr =
-            std::is_convertible<Func, FunctionType>::value &&
-            sizeof(capture) == sizeof(void *);
+        constexpr bool is_function_ptr
+            = std::is_convertible<Func, FunctionType>::value && sizeof(capture) == sizeof(void *);
         if (is_function_ptr) {
             rec->is_stateless = true;
-            rec->data[1] = const_cast<void *>(reinterpret_cast<const void *>(&typeid(FunctionType)));
+            rec->data[1]
+                = const_cast<void *>(reinterpret_cast<const void *>(&typeid(FunctionType)));
         }
     }
 
+    // Utility class that keeps track of all duplicated strings, and cleans them up in its
+    // destructor, unless they are released. Basically a RAII-solution to deal with exceptions
+    // along the way.
+    class strdup_guard {
+    public:
+        strdup_guard() = default;
+        strdup_guard(const strdup_guard &) = delete;
+        strdup_guard &operator=(const strdup_guard &) = delete;
+
+        ~strdup_guard() {
+            for (auto *s : strings) {
+                std::free(s);
+            }
+        }
+        char *operator()(const char *s) {
+            auto *t = PYBIND11_COMPAT_STRDUP(s);
+            strings.push_back(t);
+            return t;
+        }
+        void release() { strings.clear(); }
+
+    private:
+        std::vector<char *> strings;
+    };
+
     /// Register a function call with Python (generic non-templated code goes here)
-    void initialize_generic(detail::function_record *rec, const char *text,
-                            const std::type_info *const *types, size_t args) {
+    void initialize_generic(unique_function_record &&unique_rec,
+                            const char *text,
+                            const std::type_info *const *types,
+                            size_t args) {
+        // Do NOT receive `unique_rec` by value. If this function fails to move out the unique_ptr,
+        // we do not want this to destruct the pointer. `initialize` (the caller) still relies on
+        // the pointee being alive after this call. Only move out if a `capsule` is going to keep
+        // it alive.
+        auto *rec = unique_rec.get();
+
+        // Keep track of strdup'ed strings, and clean them up as long as the function's capsule
+        // has not taken ownership yet (when `unique_rec.release()` is called).
+        // Note: This cannot easily be fixed by a `unique_ptr` with custom deleter, because the
+        // strings are only referenced before strdup'ing. So only *after* the following block could
+        // `destruct` safely be called, but even then, `repr` could still throw in the middle of
+        // copying all strings.
+        strdup_guard guarded_strdup;
 
         /* Create copies of all referenced C-style strings */
-        rec->name = strdup(rec->name ? rec->name : "");
-        if (rec->doc) rec->doc = strdup(rec->doc);
-        for (auto &a: rec->args) {
-            if (a.name)
-                a.name = strdup(a.name);
-            if (a.descr)
-                a.descr = strdup(a.descr);
-            else if (a.value)
-                a.descr = strdup(a.value.attr("__repr__")().cast<std::string>().c_str());
+        rec->name = guarded_strdup(rec->name ? rec->name : "");
+        if (rec->doc) {
+            rec->doc = guarded_strdup(rec->doc);
+        }
+        for (auto &a : rec->args) {
+            if (a.name) {
+                a.name = guarded_strdup(a.name);
+            }
+            if (a.descr) {
+                a.descr = guarded_strdup(a.descr);
+            } else if (a.value) {
+                a.descr = guarded_strdup(repr(a.value).cast<std::string>().c_str());
+            }
         }
 
-        rec->is_constructor = !strcmp(rec->name, "__init__") || !strcmp(rec->name, "__setstate__");
+        rec->is_constructor = (std::strcmp(rec->name, "__init__") == 0)
+                              || (std::strcmp(rec->name, "__setstate__") == 0);
 
-#if !defined(NDEBUG) && !defined(PYBIND11_DISABLE_NEW_STYLE_INIT_WARNING)
+#if defined(PYBIND11_DETAILED_ERROR_MESSAGES) && !defined(PYBIND11_DISABLE_NEW_STYLE_INIT_WARNING)
         if (rec->is_constructor && !rec->is_new_style_constructor) {
-            const auto class_name = std::string(((PyTypeObject *) rec->scope.ptr())->tp_name);
+            const auto class_name
+                = detail::get_fully_qualified_tp_name((PyTypeObject *) rec->scope.ptr());
             const auto func_name = std::string(rec->name);
-            PyErr_WarnEx(
-                PyExc_FutureWarning,
-                ("pybind11-bound class '" + class_name + "' is using an old-style "
-                 "placement-new '" + func_name + "' which has been deprecated. See "
-                 "the upgrade guide in pybind11's docs. This message is only visible "
-                 "when compiled in debug mode.").c_str(), 0
-            );
+            PyErr_WarnEx(PyExc_FutureWarning,
+                         ("pybind11-bound class '" + class_name
+                          + "' is using an old-style "
+                            "placement-new '"
+                          + func_name
+                          + "' which has been deprecated. See "
+                            "the upgrade guide in pybind11's docs. This message is only visible "
+                            "when compiled in debug mode.")
+                             .c_str(),
+                         0);
         }
 #endif
 
         /* Generate a proper function signature */
         std::string signature;
         size_t type_index = 0, arg_index = 0;
-        for (auto *pc = text; *pc != '\0'; ++pc) {
+        bool is_starred = false;
+        for (const auto *pc = text; *pc != '\0'; ++pc) {
             const auto c = *pc;
 
             if (c == '{') {
                 // Write arg name for everything except *args and **kwargs.
-                if (*(pc + 1) == '*')
+                is_starred = *(pc + 1) == '*';
+                if (is_starred) {
                     continue;
-
+                }
+                // Separator for keyword-only arguments, placed before the kw
+                // arguments start (unless we are already putting an *args)
+                if (!rec->has_args && arg_index == rec->nargs_pos) {
+                    signature += "*, ";
+                }
                 if (arg_index < rec->args.size() && rec->args[arg_index].name) {
                     signature += rec->args[arg_index].name;
                 } else if (arg_index == 0 && rec->is_method) {
                     signature += "self";
                 } else {
                     signature += "arg" + std::to_string(arg_index - (rec->is_method ? 1 : 0));
                 }
                 signature += ": ";
             } else if (c == '}') {
                 // Write default value if available.
-                if (arg_index < rec->args.size() && rec->args[arg_index].descr) {
+                if (!is_starred && arg_index < rec->args.size() && rec->args[arg_index].descr) {
                     signature += " = ";
                     signature += rec->args[arg_index].descr;
                 }
-                arg_index++;
+                // Separator for positional-only arguments (placed after the
+                // argument, rather than before like *
+                if (rec->nargs_pos_only > 0 && (arg_index + 1) == rec->nargs_pos_only) {
+                    signature += ", /";
+                }
+                if (!is_starred) {
+                    arg_index++;
+                }
             } else if (c == '%') {
                 const std::type_info *t = types[type_index++];
-                if (!t)
+                if (!t) {
                     pybind11_fail("Internal error while parsing type signature (1)");
-                if (auto tinfo = detail::get_type_info(*t)) {
+                }
+                if (auto *tinfo = detail::get_type_info(*t)) {
                     handle th((PyObject *) tinfo->type);
-                    signature +=
-                        th.attr("__module__").cast<std::string>() + "." +
-                        th.attr("__qualname__").cast<std::string>(); // Python 3.3+, but we backport it to earlier versions
+                    signature += th.attr("__module__").cast<std::string>() + "."
+                                 + th.attr("__qualname__").cast<std::string>();
                 } else if (rec->is_new_style_constructor && arg_index == 0) {
                     // A new-style `__init__` takes `self` as `value_and_holder`.
                     // Rewrite it to the proper class type.
-                    signature +=
-                        rec->scope.attr("__module__").cast<std::string>() + "." +
-                        rec->scope.attr("__qualname__").cast<std::string>();
+                    signature += rec->scope.attr("__module__").cast<std::string>() + "."
+                                 + rec->scope.attr("__qualname__").cast<std::string>();
                 } else {
                     std::string tname(t->name());
                     detail::clean_type_id(tname);
                     signature += tname;
                 }
             } else {
                 signature += c;
             }
         }
-        if (arg_index != args || types[type_index] != nullptr)
-            pybind11_fail("Internal error while parsing type signature (2)");
 
-#if PY_MAJOR_VERSION < 3
-        if (strcmp(rec->name, "__next__") == 0) {
-            std::free(rec->name);
-            rec->name = strdup("next");
-        } else if (strcmp(rec->name, "__bool__") == 0) {
-            std::free(rec->name);
-            rec->name = strdup("__nonzero__");
+        if (arg_index != args - rec->has_args - rec->has_kwargs || types[type_index] != nullptr) {
+            pybind11_fail("Internal error while parsing type signature (2)");
         }
-#endif
-        rec->signature = strdup(signature.c_str());
+
+        rec->signature = guarded_strdup(signature.c_str());
         rec->args.shrink_to_fit();
         rec->nargs = (std::uint16_t) args;
 
-        if (rec->sibling && PYBIND11_INSTANCE_METHOD_CHECK(rec->sibling.ptr()))
+        if (rec->sibling && PYBIND11_INSTANCE_METHOD_CHECK(rec->sibling.ptr())) {
             rec->sibling = PYBIND11_INSTANCE_METHOD_GET_FUNCTION(rec->sibling.ptr());
+        }
 
         detail::function_record *chain = nullptr, *chain_start = rec;
         if (rec->sibling) {
             if (PyCFunction_Check(rec->sibling.ptr())) {
-                auto rec_capsule = reinterpret_borrow<capsule>(PyCFunction_GET_SELF(rec->sibling.ptr()));
-                chain = (detail::function_record *) rec_capsule;
-                /* Never append a method to an overload chain of a parent class;
-                   instead, hide the parent's overloads in this case */
-                if (!chain->scope.is(rec->scope))
+                auto *self = PyCFunction_GET_SELF(rec->sibling.ptr());
+                if (!isinstance<capsule>(self)) {
                     chain = nullptr;
+                } else {
+                    auto rec_capsule = reinterpret_borrow<capsule>(self);
+                    if (detail::is_function_record_capsule(rec_capsule)) {
+                        chain = rec_capsule.get_pointer<detail::function_record>();
+                        /* Never append a method to an overload chain of a parent class;
+                           instead, hide the parent's overloads in this case */
+                        if (!chain->scope.is(rec->scope)) {
+                            chain = nullptr;
+                        }
+                    } else {
+                        chain = nullptr;
+                    }
+                }
+            }
+            // Don't trigger for things like the default __init__, which are wrapper_descriptors
+            // that we are intentionally replacing
+            else if (!rec->sibling.is_none() && rec->name[0] != '_') {
+                pybind11_fail("Cannot overload existing non-function object \""
+                              + std::string(rec->name) + "\" with a function of the same name");
             }
-            // Don't trigger for things like the default __init__, which are wrapper_descriptors that we are intentionally replacing
-            else if (!rec->sibling.is_none() && rec->name[0] != '_')
-                pybind11_fail("Cannot overload existing non-function object \"" + std::string(rec->name) +
-                        "\" with a function of the same name");
         }
 
         if (!chain) {
             /* No existing overload was found, create a new function object */
             rec->def = new PyMethodDef();
             std::memset(rec->def, 0, sizeof(PyMethodDef));
             rec->def->ml_name = rec->name;
-            rec->def->ml_meth = reinterpret_cast<PyCFunction>(reinterpret_cast<void (*) (void)>(*dispatcher));
+            rec->def->ml_meth
+                = reinterpret_cast<PyCFunction>(reinterpret_cast<void (*)()>(dispatcher));
             rec->def->ml_flags = METH_VARARGS | METH_KEYWORDS;
 
-            capsule rec_capsule(rec, [](void *ptr) {
-                destruct((detail::function_record *) ptr);
-            });
+            capsule rec_capsule(unique_rec.release(),
+                                [](void *ptr) { destruct((detail::function_record *) ptr); });
+            rec_capsule.set_name(detail::get_function_record_capsule_name());
+            guarded_strdup.release();
 
             object scope_module;
             if (rec->scope) {
                 if (hasattr(rec->scope, "__module__")) {
                     scope_module = rec->scope.attr("__module__");
                 } else if (hasattr(rec->scope, "__name__")) {
                     scope_module = rec->scope.attr("__name__");
                 }
             }
 
             m_ptr = PyCFunction_NewEx(rec->def, rec_capsule.ptr(), scope_module.ptr());
-            if (!m_ptr)
+            if (!m_ptr) {
                 pybind11_fail("cpp_function::cpp_function(): Could not allocate function object");
+            }
         } else {
-            /* Append at the end of the overload chain */
+            /* Append at the beginning or end of the overload chain */
             m_ptr = rec->sibling.ptr();
             inc_ref();
-            chain_start = chain;
-            if (chain->is_method != rec->is_method)
-                pybind11_fail("overloading a method with both static and instance methods is not supported; "
-                    #if defined(NDEBUG)
-                        "compile in debug mode for more details"
-                    #else
-                        "error while attempting to bind " + std::string(rec->is_method ? "instance" : "static") + " method " +
-                        std::string(pybind11::str(rec->scope.attr("__name__"))) + "." + std::string(rec->name) + signature
-                    #endif
+            if (chain->is_method != rec->is_method) {
+                pybind11_fail(
+                    "overloading a method with both static and instance methods is not supported; "
+#if !defined(PYBIND11_DETAILED_ERROR_MESSAGES)
+                    "#define PYBIND11_DETAILED_ERROR_MESSAGES or compile in debug mode for more "
+                    "details"
+#else
+                    "error while attempting to bind "
+                    + std::string(rec->is_method ? "instance" : "static") + " method "
+                    + std::string(pybind11::str(rec->scope.attr("__name__"))) + "."
+                    + std::string(rec->name) + signature
+#endif
                 );
-            while (chain->next)
-                chain = chain->next;
-            chain->next = rec;
+            }
+
+            if (rec->prepend) {
+                // Beginning of chain; we need to replace the capsule's current head-of-the-chain
+                // pointer with this one, then make this one point to the previous head of the
+                // chain.
+                chain_start = rec;
+                rec->next = chain;
+                auto rec_capsule
+                    = reinterpret_borrow<capsule>(((PyCFunctionObject *) m_ptr)->m_self);
+                rec_capsule.set_pointer(unique_rec.release());
+                guarded_strdup.release();
+            } else {
+                // Or end of chain (normal behavior)
+                chain_start = chain;
+                while (chain->next) {
+                    chain = chain->next;
+                }
+                chain->next = unique_rec.release();
+                guarded_strdup.release();
+            }
         }
 
         std::string signatures;
         int index = 0;
         /* Create a nice pydoc rec including all signatures and
            docstrings of the functions in the overload chain */
         if (chain && options::show_function_signatures()) {
             // First a generic signature
             signatures += rec->name;
             signatures += "(*args, **kwargs)\n";
             signatures += "Overloaded function.\n\n";
         }
         // Then specific overload signatures
         bool first_user_def = true;
-        for (auto it = chain_start; it != nullptr; it = it->next) {
+        for (auto *it = chain_start; it != nullptr; it = it->next) {
             if (options::show_function_signatures()) {
-                if (index > 0) signatures += "\n";
-                if (chain)
+                if (index > 0) {
+                    signatures += '\n';
+                }
+                if (chain) {
                     signatures += std::to_string(++index) + ". ";
+                }
                 signatures += rec->name;
                 signatures += it->signature;
-                signatures += "\n";
+                signatures += '\n';
             }
-            if (it->doc && strlen(it->doc) > 0 && options::show_user_defined_docstrings()) {
-                // If we're appending another docstring, and aren't printing function signatures, we
-                // need to append a newline first:
+            if (it->doc && it->doc[0] != '\0' && options::show_user_defined_docstrings()) {
+                // If we're appending another docstring, and aren't printing function signatures,
+                // we need to append a newline first:
                 if (!options::show_function_signatures()) {
-                    if (first_user_def) first_user_def = false;
-                    else signatures += "\n";
+                    if (first_user_def) {
+                        first_user_def = false;
+                    } else {
+                        signatures += '\n';
+                    }
+                }
+                if (options::show_function_signatures()) {
+                    signatures += '\n';
                 }
-                if (options::show_function_signatures()) signatures += "\n";
                 signatures += it->doc;
-                if (options::show_function_signatures()) signatures += "\n";
+                if (options::show_function_signatures()) {
+                    signatures += '\n';
+                }
             }
         }
 
         /* Install docstring */
-        PyCFunctionObject *func = (PyCFunctionObject *) m_ptr;
-        if (func->m_ml->ml_doc)
-            std::free(const_cast<char *>(func->m_ml->ml_doc));
-        func->m_ml->ml_doc = strdup(signatures.c_str());
+        auto *func = (PyCFunctionObject *) m_ptr;
+        std::free(const_cast<char *>(func->m_ml->ml_doc));
+        // Install docstring if it's non-empty (when at least one option is enabled)
+        func->m_ml->ml_doc
+            = signatures.empty() ? nullptr : PYBIND11_COMPAT_STRDUP(signatures.c_str());
 
         if (rec->is_method) {
             m_ptr = PYBIND11_INSTANCE_METHOD_NEW(m_ptr, rec->scope.ptr());
-            if (!m_ptr)
-                pybind11_fail("cpp_function::cpp_function(): Could not allocate instance method object");
+            if (!m_ptr) {
+                pybind11_fail(
+                    "cpp_function::cpp_function(): Could not allocate instance method object");
+            }
             Py_DECREF(func);
         }
     }
 
     /// When a cpp_function is GCed, release any memory allocated by pybind11
-    static void destruct(detail::function_record *rec) {
+    static void destruct(detail::function_record *rec, bool free_strings = true) {
+// If on Python 3.9, check the interpreter "MICRO" (patch) version.
+// If this is running on 3.9.0, we have to work around a bug.
+#if !defined(PYPY_VERSION) && PY_MAJOR_VERSION == 3 && PY_MINOR_VERSION == 9
+        static bool is_zero = Py_GetVersion()[4] == '0';
+#endif
+
         while (rec) {
             detail::function_record *next = rec->next;
-            if (rec->free_data)
+            if (rec->free_data) {
                 rec->free_data(rec);
-            std::free((char *) rec->name);
-            std::free((char *) rec->doc);
-            std::free((char *) rec->signature);
-            for (auto &arg: rec->args) {
-                std::free(const_cast<char *>(arg.name));
-                std::free(const_cast<char *>(arg.descr));
+            }
+            // During initialization, these strings might not have been copied yet,
+            // so they cannot be freed. Once the function has been created, they can.
+            // Check `make_function_record` for more details.
+            if (free_strings) {
+                std::free((char *) rec->name);
+                std::free((char *) rec->doc);
+                std::free((char *) rec->signature);
+                for (auto &arg : rec->args) {
+                    std::free(const_cast<char *>(arg.name));
+                    std::free(const_cast<char *>(arg.descr));
+                }
+            }
+            for (auto &arg : rec->args) {
                 arg.value.dec_ref();
             }
             if (rec->def) {
                 std::free(const_cast<char *>(rec->def->ml_doc));
+// Python 3.9.0 decref's these in the wrong order; rec->def
+// If loaded on 3.9.0, let these leak (use Python 3.9.1 at runtime to fix)
+// See https://github.com/python/cpython/pull/22670
+#if !defined(PYPY_VERSION) && PY_MAJOR_VERSION == 3 && PY_MINOR_VERSION == 9
+                if (!is_zero) {
+                    delete rec->def;
+                }
+#else
                 delete rec->def;
+#endif
             }
             delete rec;
             rec = next;
         }
     }
 
     /// Main dispatch logic for calls to functions bound using pybind11
     static PyObject *dispatcher(PyObject *self, PyObject *args_in, PyObject *kwargs_in) {
         using namespace detail;
+        assert(isinstance<capsule>(self));
 
         /* Iterator over the list of potentially admissible overloads */
-        const function_record *overloads = (function_record *) PyCapsule_GetPointer(self, nullptr),
+        const function_record *overloads = reinterpret_cast<function_record *>(
+                                  PyCapsule_GetPointer(self, get_function_record_capsule_name())),
                               *it = overloads;
+        assert(overloads != nullptr);
 
-        /* Need to know how many arguments + keyword arguments there are to pick the right overload */
-        const size_t n_args_in = (size_t) PyTuple_GET_SIZE(args_in);
+        /* Need to know how many arguments + keyword arguments there are to pick the right
+           overload */
+        const auto n_args_in = (size_t) PyTuple_GET_SIZE(args_in);
 
         handle parent = n_args_in > 0 ? PyTuple_GET_ITEM(args_in, 0) : nullptr,
                result = PYBIND11_TRY_NEXT_OVERLOAD;
 
         auto self_value_and_holder = value_and_holder();
         if (overloads->is_constructor) {
-            const auto tinfo = get_type_info((PyTypeObject *) overloads->scope.ptr());
-            const auto pi = reinterpret_cast<instance *>(parent.ptr());
-            self_value_and_holder = pi->get_value_and_holder(tinfo, false);
-
-            if (!self_value_and_holder.type || !self_value_and_holder.inst) {
-                PyErr_SetString(PyExc_TypeError, "__init__(self, ...) called with invalid `self` argument");
+            if (!parent
+                || !PyObject_TypeCheck(parent.ptr(), (PyTypeObject *) overloads->scope.ptr())) {
+                PyErr_SetString(
+                    PyExc_TypeError,
+                    "__init__(self, ...) called with invalid or missing `self` argument");
                 return nullptr;
             }
 
+            auto *const tinfo = get_type_info((PyTypeObject *) overloads->scope.ptr());
+            auto *const pi = reinterpret_cast<instance *>(parent.ptr());
+            self_value_and_holder = pi->get_value_and_holder(tinfo, true);
+
             // If this value is already registered it must mean __init__ is invoked multiple times;
             // we really can't support that in C++, so just ignore the second __init__.
-            if (self_value_and_holder.instance_registered())
+            if (self_value_and_holder.instance_registered()) {
                 return none().release().ptr();
+            }
         }
 
         try {
             // We do this in two passes: in the first pass, we load arguments with `convert=false`;
             // in the second, we allow conversion (except for arguments with an explicit
             // py::arg().noconvert()).  This lets us prefer calls without conversion, with
             // conversion as a fallback.
@@ -463,155 +716,217 @@
 
             for (; it != nullptr; it = it->next) {
 
                 /* For each overload:
                    1. Copy all positional arguments we were given, also checking to make sure that
                       named positional arguments weren't *also* specified via kwarg.
                    2. If we weren't given enough, try to make up the omitted ones by checking
-                      whether they were provided by a kwarg matching the `py::arg("name")` name.  If
-                      so, use it (and remove it from kwargs; if not, see if the function binding
+                      whether they were provided by a kwarg matching the `py::arg("name")` name. If
+                      so, use it (and remove it from kwargs); if not, see if the function binding
                       provided a default that we can use.
-                   3. Ensure that either all keyword arguments were "consumed", or that the function
-                      takes a kwargs argument to accept unconsumed kwargs.
+                   3. Ensure that either all keyword arguments were "consumed", or that the
+                   function takes a kwargs argument to accept unconsumed kwargs.
                    4. Any positional arguments still left get put into a tuple (for args), and any
                       leftover kwargs get put into a dict.
                    5. Pack everything into a vector; if we have py::args or py::kwargs, they are an
                       extra tuple or dict at the end of the positional arguments.
                    6. Call the function call dispatcher (function_record::impl)
 
-                   If one of these fail, move on to the next overload and keep trying until we get a
-                   result other than PYBIND11_TRY_NEXT_OVERLOAD.
+                   If one of these fail, move on to the next overload and keep trying until we get
+                   a result other than PYBIND11_TRY_NEXT_OVERLOAD.
                  */
 
                 const function_record &func = *it;
-                size_t pos_args = func.nargs;    // Number of positional arguments that we need
-                if (func.has_args) --pos_args;   // (but don't count py::args
-                if (func.has_kwargs) --pos_args; //  or py::kwargs)
+                size_t num_args = func.nargs; // Number of positional arguments that we need
+                if (func.has_args) {
+                    --num_args; // (but don't count py::args
+                }
+                if (func.has_kwargs) {
+                    --num_args; //  or py::kwargs)
+                }
+                size_t pos_args = func.nargs_pos;
 
-                if (!func.has_args && n_args_in > pos_args)
-                    continue; // Too many arguments for this overload
+                if (!func.has_args && n_args_in > pos_args) {
+                    continue; // Too many positional arguments for this overload
+                }
 
-                if (n_args_in < pos_args && func.args.size() < pos_args)
-                    continue; // Not enough arguments given, and not enough defaults to fill in the blanks
+                if (n_args_in < pos_args && func.args.size() < pos_args) {
+                    continue; // Not enough positional arguments given, and not enough defaults to
+                              // fill in the blanks
+                }
 
                 function_call call(func, parent);
 
-                size_t args_to_copy = std::min(pos_args, n_args_in);
+                // Protect std::min with parentheses
+                size_t args_to_copy = (std::min)(pos_args, n_args_in);
                 size_t args_copied = 0;
 
                 // 0. Inject new-style `self` argument
                 if (func.is_new_style_constructor) {
                     // The `value` may have been preallocated by an old-style `__init__`
                     // if it was a preceding candidate for overload resolution.
-                    if (self_value_and_holder)
+                    if (self_value_and_holder) {
                         self_value_and_holder.type->dealloc(self_value_and_holder);
+                    }
 
                     call.init_self = PyTuple_GET_ITEM(args_in, 0);
-                    call.args.push_back(reinterpret_cast<PyObject *>(&self_value_and_holder));
+                    call.args.emplace_back(reinterpret_cast<PyObject *>(&self_value_and_holder));
                     call.args_convert.push_back(false);
                     ++args_copied;
                 }
 
                 // 1. Copy any position arguments given.
                 bool bad_arg = false;
                 for (; args_copied < args_to_copy; ++args_copied) {
-                    const argument_record *arg_rec = args_copied < func.args.size() ? &func.args[args_copied] : nullptr;
-                    if (kwargs_in && arg_rec && arg_rec->name && PyDict_GetItemString(kwargs_in, arg_rec->name)) {
+                    const argument_record *arg_rec
+                        = args_copied < func.args.size() ? &func.args[args_copied] : nullptr;
+                    if (kwargs_in && arg_rec && arg_rec->name
+                        && dict_getitemstring(kwargs_in, arg_rec->name)) {
                         bad_arg = true;
                         break;
                     }
 
                     handle arg(PyTuple_GET_ITEM(args_in, args_copied));
                     if (arg_rec && !arg_rec->none && arg.is_none()) {
                         bad_arg = true;
                         break;
                     }
                     call.args.push_back(arg);
                     call.args_convert.push_back(arg_rec ? arg_rec->convert : true);
                 }
-                if (bad_arg)
+                if (bad_arg) {
                     continue; // Maybe it was meant for another overload (issue #688)
+                }
+
+                // Keep track of how many position args we copied out in case we need to come back
+                // to copy the rest into a py::args argument.
+                size_t positional_args_copied = args_copied;
 
                 // We'll need to copy this if we steal some kwargs for defaults
                 dict kwargs = reinterpret_borrow<dict>(kwargs_in);
 
+                // 1.5. Fill in any missing pos_only args from defaults if they exist
+                if (args_copied < func.nargs_pos_only) {
+                    for (; args_copied < func.nargs_pos_only; ++args_copied) {
+                        const auto &arg_rec = func.args[args_copied];
+                        handle value;
+
+                        if (arg_rec.value) {
+                            value = arg_rec.value;
+                        }
+                        if (value) {
+                            call.args.push_back(value);
+                            call.args_convert.push_back(arg_rec.convert);
+                        } else {
+                            break;
+                        }
+                    }
+
+                    if (args_copied < func.nargs_pos_only) {
+                        continue; // Not enough defaults to fill the positional arguments
+                    }
+                }
+
                 // 2. Check kwargs and, failing that, defaults that may help complete the list
-                if (args_copied < pos_args) {
+                if (args_copied < num_args) {
                     bool copied_kwargs = false;
 
-                    for (; args_copied < pos_args; ++args_copied) {
-                        const auto &arg = func.args[args_copied];
+                    for (; args_copied < num_args; ++args_copied) {
+                        const auto &arg_rec = func.args[args_copied];
 
                         handle value;
-                        if (kwargs_in && arg.name)
-                            value = PyDict_GetItemString(kwargs.ptr(), arg.name);
+                        if (kwargs_in && arg_rec.name) {
+                            value = dict_getitemstring(kwargs.ptr(), arg_rec.name);
+                        }
 
                         if (value) {
                             // Consume a kwargs value
                             if (!copied_kwargs) {
                                 kwargs = reinterpret_steal<dict>(PyDict_Copy(kwargs.ptr()));
                                 copied_kwargs = true;
                             }
-                            PyDict_DelItemString(kwargs.ptr(), arg.name);
-                        } else if (arg.value) {
-                            value = arg.value;
+                            if (PyDict_DelItemString(kwargs.ptr(), arg_rec.name) == -1) {
+                                throw error_already_set();
+                            }
+                        } else if (arg_rec.value) {
+                            value = arg_rec.value;
+                        }
+
+                        if (!arg_rec.none && value.is_none()) {
+                            break;
                         }
 
                         if (value) {
+                            // If we're at the py::args index then first insert a stub for it to be
+                            // replaced later
+                            if (func.has_args && call.args.size() == func.nargs_pos) {
+                                call.args.push_back(none());
+                            }
+
                             call.args.push_back(value);
-                            call.args_convert.push_back(arg.convert);
-                        }
-                        else
+                            call.args_convert.push_back(arg_rec.convert);
+                        } else {
                             break;
+                        }
                     }
 
-                    if (args_copied < pos_args)
-                        continue; // Not enough arguments, defaults, or kwargs to fill the positional arguments
+                    if (args_copied < num_args) {
+                        continue; // Not enough arguments, defaults, or kwargs to fill the
+                                  // positional arguments
+                    }
                 }
 
                 // 3. Check everything was consumed (unless we have a kwargs arg)
-                if (kwargs && kwargs.size() > 0 && !func.has_kwargs)
+                if (kwargs && !kwargs.empty() && !func.has_kwargs) {
                     continue; // Unconsumed kwargs, but no py::kwargs argument to accept them
+                }
 
                 // 4a. If we have a py::args argument, create a new tuple with leftovers
                 if (func.has_args) {
                     tuple extra_args;
                     if (args_to_copy == 0) {
                         // We didn't copy out any position arguments from the args_in tuple, so we
                         // can reuse it directly without copying:
                         extra_args = reinterpret_borrow<tuple>(args_in);
-                    } else if (args_copied >= n_args_in) {
+                    } else if (positional_args_copied >= n_args_in) {
                         extra_args = tuple(0);
                     } else {
-                        size_t args_size = n_args_in - args_copied;
+                        size_t args_size = n_args_in - positional_args_copied;
                         extra_args = tuple(args_size);
                         for (size_t i = 0; i < args_size; ++i) {
-                            extra_args[i] = PyTuple_GET_ITEM(args_in, args_copied + i);
+                            extra_args[i] = PyTuple_GET_ITEM(args_in, positional_args_copied + i);
                         }
                     }
-                    call.args.push_back(extra_args);
+                    if (call.args.size() <= func.nargs_pos) {
+                        call.args.push_back(extra_args);
+                    } else {
+                        call.args[func.nargs_pos] = extra_args;
+                    }
                     call.args_convert.push_back(false);
                     call.args_ref = std::move(extra_args);
                 }
 
                 // 4b. If we have a py::kwargs, pass on any remaining kwargs
                 if (func.has_kwargs) {
-                    if (!kwargs.ptr())
+                    if (!kwargs.ptr()) {
                         kwargs = dict(); // If we didn't get one, send an empty one
+                    }
                     call.args.push_back(kwargs);
                     call.args_convert.push_back(false);
                     call.kwargs_ref = std::move(kwargs);
                 }
 
-                // 5. Put everything in a vector.  Not technically step 5, we've been building it
-                // in `call.args` all along.
-                #if !defined(NDEBUG)
-                if (call.args.size() != func.nargs || call.args_convert.size() != func.nargs)
-                    pybind11_fail("Internal error: function call dispatcher inserted wrong number of arguments!");
-                #endif
+// 5. Put everything in a vector.  Not technically step 5, we've been building it
+// in `call.args` all along.
+#if defined(PYBIND11_DETAILED_ERROR_MESSAGES)
+                if (call.args.size() != func.nargs || call.args_convert.size() != func.nargs) {
+                    pybind11_fail("Internal error: function call dispatcher inserted wrong number "
+                                  "of arguments!");
+                }
+#endif
 
                 std::vector<bool> second_pass_convert;
                 if (overloaded) {
                     // We're in the first no-convert pass, so swap out the conversion flags for a
                     // set of all-false flags.  If the call fails, we'll swap the flags back in for
                     // the conversion-allowed call below.
                     second_pass_convert.resize(func.nargs, false);
@@ -622,16 +937,17 @@
                 try {
                     loader_life_support guard{};
                     result = func.impl(call);
                 } catch (reference_cast_error &) {
                     result = PYBIND11_TRY_NEXT_OVERLOAD;
                 }
 
-                if (result.ptr() != PYBIND11_TRY_NEXT_OVERLOAD)
+                if (result.ptr() != PYBIND11_TRY_NEXT_OVERLOAD) {
                     break;
+                }
 
                 if (overloaded) {
                     // The (overloaded) call failed; if the call has at least one argument that
                     // permits conversion (i.e. it hasn't been explicitly specified `.noconvert()`)
                     // then add this call to the list of second pass overloads to try.
                     for (size_t i = func.is_method ? 1 : 0; i < pos_args; i++) {
                         if (second_pass_convert[i]) {
@@ -642,265 +958,359 @@
                             break;
                         }
                     }
                 }
             }
 
             if (overloaded && !second_pass.empty() && result.ptr() == PYBIND11_TRY_NEXT_OVERLOAD) {
-                // The no-conversion pass finished without success, try again with conversion allowed
+                // The no-conversion pass finished without success, try again with conversion
+                // allowed
                 for (auto &call : second_pass) {
                     try {
                         loader_life_support guard{};
                         result = call.func.impl(call);
                     } catch (reference_cast_error &) {
                         result = PYBIND11_TRY_NEXT_OVERLOAD;
                     }
 
                     if (result.ptr() != PYBIND11_TRY_NEXT_OVERLOAD) {
                         // The error reporting logic below expects 'it' to be valid, as it would be
                         // if we'd encountered this failure in the first-pass loop.
-                        if (!result)
+                        if (!result) {
                             it = &call.func;
+                        }
                         break;
                     }
                 }
             }
         } catch (error_already_set &e) {
             e.restore();
             return nullptr;
-#if defined(__GNUG__) && !defined(__clang__)
-        } catch ( abi::__forced_unwind& ) {
+#ifdef __GLIBCXX__
+        } catch (abi::__forced_unwind &) {
             throw;
 #endif
         } catch (...) {
             /* When an exception is caught, give each registered exception
-               translator a chance to translate it to a Python exception
-               in reverse order of registration.
+               translator a chance to translate it to a Python exception. First
+               all module-local translators will be tried in reverse order of
+               registration. If none of the module-locale translators handle
+               the exception (or there are no module-locale translators) then
+               the global translators will be tried, also in reverse order of
+               registration.
 
                A translator may choose to do one of the following:
 
                 - catch the exception and call PyErr_SetString or PyErr_SetObject
                   to set a standard (or custom) Python exception, or
                 - do nothing and let the exception fall through to the next translator, or
-                - delegate translation to the next translator by throwing a new type of exception. */
+                - delegate translation to the next translator by throwing a new type of exception.
+             */
 
-            auto last_exception = std::current_exception();
-            auto &registered_exception_translators = get_internals().registered_exception_translators;
-            for (auto& translator : registered_exception_translators) {
-                try {
-                    translator(last_exception);
-                } catch (...) {
-                    last_exception = std::current_exception();
-                    continue;
-                }
+            auto &local_exception_translators
+                = get_local_internals().registered_exception_translators;
+            if (detail::apply_exception_translators(local_exception_translators)) {
+                return nullptr;
+            }
+            auto &exception_translators = get_internals().registered_exception_translators;
+            if (detail::apply_exception_translators(exception_translators)) {
                 return nullptr;
             }
-            PyErr_SetString(PyExc_SystemError, "Exception escaped from default exception translator!");
+
+            PyErr_SetString(PyExc_SystemError,
+                            "Exception escaped from default exception translator!");
             return nullptr;
         }
 
         auto append_note_if_missing_header_is_suspected = [](std::string &msg) {
             if (msg.find("std::") != std::string::npos) {
                 msg += "\n\n"
                        "Did you forget to `#include <pybind11/stl.h>`? Or <pybind11/complex.h>,\n"
                        "<pybind11/functional.h>, <pybind11/chrono.h>, etc. Some automatic\n"
                        "conversions are optional and require extra headers to be included\n"
                        "when compiling your pybind11 module.";
             }
         };
 
         if (result.ptr() == PYBIND11_TRY_NEXT_OVERLOAD) {
-            if (overloads->is_operator)
+            if (overloads->is_operator) {
                 return handle(Py_NotImplemented).inc_ref().ptr();
+            }
 
-            std::string msg = std::string(overloads->name) + "(): incompatible " +
-                std::string(overloads->is_constructor ? "constructor" : "function") +
-                " arguments. The following argument types are supported:\n";
+            std::string msg = std::string(overloads->name) + "(): incompatible "
+                              + std::string(overloads->is_constructor ? "constructor" : "function")
+                              + " arguments. The following argument types are supported:\n";
 
             int ctr = 0;
             for (const function_record *it2 = overloads; it2 != nullptr; it2 = it2->next) {
-                msg += "    "+ std::to_string(++ctr) + ". ";
+                msg += "    " + std::to_string(++ctr) + ". ";
 
                 bool wrote_sig = false;
                 if (overloads->is_constructor) {
-                    // For a constructor, rewrite `(self: Object, arg0, ...) -> NoneType` as `Object(arg0, ...)`
+                    // For a constructor, rewrite `(self: Object, arg0, ...) -> NoneType` as
+                    // `Object(arg0, ...)`
                     std::string sig = it2->signature;
                     size_t start = sig.find('(') + 7; // skip "(self: "
                     if (start < sig.size()) {
                         // End at the , for the next argument
                         size_t end = sig.find(", "), next = end + 2;
                         size_t ret = sig.rfind(" -> ");
                         // Or the ), if there is no comma:
-                        if (end >= sig.size()) next = end = sig.find(')');
+                        if (end >= sig.size()) {
+                            next = end = sig.find(')');
+                        }
                         if (start < end && next < sig.size()) {
                             msg.append(sig, start, end - start);
                             msg += '(';
                             msg.append(sig, next, ret - next);
                             wrote_sig = true;
                         }
                     }
                 }
-                if (!wrote_sig) msg += it2->signature;
+                if (!wrote_sig) {
+                    msg += it2->signature;
+                }
 
-                msg += "\n";
+                msg += '\n';
             }
             msg += "\nInvoked with: ";
             auto args_ = reinterpret_borrow<tuple>(args_in);
             bool some_args = false;
             for (size_t ti = overloads->is_constructor ? 1 : 0; ti < args_.size(); ++ti) {
-                if (!some_args) some_args = true;
-                else msg += ", ";
-                msg += pybind11::repr(args_[ti]);
+                if (!some_args) {
+                    some_args = true;
+                } else {
+                    msg += ", ";
+                }
+                try {
+                    msg += pybind11::repr(args_[ti]);
+                } catch (const error_already_set &) {
+                    msg += "<repr raised Error>";
+                }
             }
             if (kwargs_in) {
                 auto kwargs = reinterpret_borrow<dict>(kwargs_in);
-                if (kwargs.size() > 0) {
-                    if (some_args) msg += "; ";
+                if (!kwargs.empty()) {
+                    if (some_args) {
+                        msg += "; ";
+                    }
                     msg += "kwargs: ";
                     bool first = true;
                     for (auto kwarg : kwargs) {
-                        if (first) first = false;
-                        else msg += ", ";
-                        msg += pybind11::str("{}={!r}").format(kwarg.first, kwarg.second);
+                        if (first) {
+                            first = false;
+                        } else {
+                            msg += ", ";
+                        }
+                        msg += pybind11::str("{}=").format(kwarg.first);
+                        try {
+                            msg += pybind11::repr(kwarg.second);
+                        } catch (const error_already_set &) {
+                            msg += "<repr raised Error>";
+                        }
                     }
                 }
             }
 
             append_note_if_missing_header_is_suspected(msg);
+            // Attach additional error info to the exception if supported
+            if (PyErr_Occurred()) {
+                // #HelpAppreciated: unit test coverage for this branch.
+                raise_from(PyExc_TypeError, msg.c_str());
+                return nullptr;
+            }
             PyErr_SetString(PyExc_TypeError, msg.c_str());
             return nullptr;
-        } else if (!result) {
+        }
+        if (!result) {
             std::string msg = "Unable to convert function return value to a "
                               "Python type! The signature was\n\t";
             msg += it->signature;
             append_note_if_missing_header_is_suspected(msg);
+            // Attach additional error info to the exception if supported
+            if (PyErr_Occurred()) {
+                raise_from(PyExc_TypeError, msg.c_str());
+                return nullptr;
+            }
             PyErr_SetString(PyExc_TypeError, msg.c_str());
             return nullptr;
-        } else {
-            if (overloads->is_constructor && !self_value_and_holder.holder_constructed()) {
-                auto *pi = reinterpret_cast<instance *>(parent.ptr());
-                self_value_and_holder.type->init_instance(pi, nullptr);
-            }
-            return result.ptr();
         }
+        if (overloads->is_constructor && !self_value_and_holder.holder_constructed()) {
+            auto *pi = reinterpret_cast<instance *>(parent.ptr());
+            self_value_and_holder.type->init_instance(pi, nullptr);
+        }
+        return result.ptr();
     }
 };
 
 /// Wrapper for Python extension modules
-class module : public object {
+class module_ : public object {
 public:
-    PYBIND11_OBJECT_DEFAULT(module, object, PyModule_Check)
+    PYBIND11_OBJECT_DEFAULT(module_, object, PyModule_Check)
 
     /// Create a new top-level Python module with the given name and docstring
-    explicit module(const char *name, const char *doc = nullptr) {
-        if (!options::show_user_defined_docstrings()) doc = nullptr;
-#if PY_MAJOR_VERSION >= 3
-        PyModuleDef *def = new PyModuleDef();
-        std::memset(def, 0, sizeof(PyModuleDef));
-        def->m_name = name;
-        def->m_doc = doc;
-        def->m_size = -1;
-        Py_INCREF(def);
-        m_ptr = PyModule_Create(def);
-#else
-        m_ptr = Py_InitModule3(name, nullptr, doc);
-#endif
-        if (m_ptr == nullptr)
-            pybind11_fail("Internal error in module::module()");
-        inc_ref();
+    PYBIND11_DEPRECATED("Use PYBIND11_MODULE or module_::create_extension_module instead")
+    explicit module_(const char *name, const char *doc = nullptr) {
+        *this = create_extension_module(name, doc, new PyModuleDef());
     }
 
     /** \rst
         Create Python binding for a new function within the module scope. ``Func``
         can be a plain C++ function, a function pointer, or a lambda function. For
         details on the ``Extra&& ... extra`` argument, see section :ref:`extras`.
     \endrst */
     template <typename Func, typename... Extra>
-    module &def(const char *name_, Func &&f, const Extra& ... extra) {
-        cpp_function func(std::forward<Func>(f), name(name_), scope(*this),
-                          sibling(getattr(*this, name_, none())), extra...);
+    module_ &def(const char *name_, Func &&f, const Extra &...extra) {
+        cpp_function func(std::forward<Func>(f),
+                          name(name_),
+                          scope(*this),
+                          sibling(getattr(*this, name_, none())),
+                          extra...);
         // NB: allow overwriting here because cpp_function sets up a chain with the intention of
-        // overwriting (and has already checked internally that it isn't overwriting non-functions).
+        // overwriting (and has already checked internally that it isn't overwriting
+        // non-functions).
         add_object(name_, func, true /* overwrite */);
         return *this;
     }
 
     /** \rst
         Create and return a new Python submodule with the given name and docstring.
         This also works recursively, i.e.
 
         .. code-block:: cpp
 
-            py::module m("example", "pybind11 example plugin");
-            py::module m2 = m.def_submodule("sub", "A submodule of 'example'");
-            py::module m3 = m2.def_submodule("subsub", "A submodule of 'example.sub'");
+            py::module_ m("example", "pybind11 example plugin");
+            py::module_ m2 = m.def_submodule("sub", "A submodule of 'example'");
+            py::module_ m3 = m2.def_submodule("subsub", "A submodule of 'example.sub'");
     \endrst */
-    module def_submodule(const char *name, const char *doc = nullptr) {
-        std::string full_name = std::string(PyModule_GetName(m_ptr))
-            + std::string(".") + std::string(name);
-        auto result = reinterpret_borrow<module>(PyImport_AddModule(full_name.c_str()));
-        if (doc && options::show_user_defined_docstrings())
+    module_ def_submodule(const char *name, const char *doc = nullptr) {
+        const char *this_name = PyModule_GetName(m_ptr);
+        if (this_name == nullptr) {
+            throw error_already_set();
+        }
+        std::string full_name = std::string(this_name) + '.' + name;
+        handle submodule = PyImport_AddModule(full_name.c_str());
+        if (!submodule) {
+            throw error_already_set();
+        }
+        auto result = reinterpret_borrow<module_>(submodule);
+        if (doc && options::show_user_defined_docstrings()) {
             result.attr("__doc__") = pybind11::str(doc);
+        }
         attr(name) = result;
         return result;
     }
 
     /// Import and return a module or throws `error_already_set`.
-    static module import(const char *name) {
+    static module_ import(const char *name) {
         PyObject *obj = PyImport_ImportModule(name);
-        if (!obj)
+        if (!obj) {
             throw error_already_set();
-        return reinterpret_steal<module>(obj);
+        }
+        return reinterpret_steal<module_>(obj);
     }
 
     /// Reload the module or throws `error_already_set`.
     void reload() {
         PyObject *obj = PyImport_ReloadModule(ptr());
-        if (!obj)
+        if (!obj) {
             throw error_already_set();
-        *this = reinterpret_steal<module>(obj);
+        }
+        *this = reinterpret_steal<module_>(obj);
     }
 
-    // Adds an object to the module using the given name.  Throws if an object with the given name
-    // already exists.
-    //
-    // overwrite should almost always be false: attempting to overwrite objects that pybind11 has
-    // established will, in most cases, break things.
+    /** \rst
+        Adds an object to the module using the given name.  Throws if an object with the given name
+        already exists.
+
+        ``overwrite`` should almost always be false: attempting to overwrite objects that pybind11
+        has established will, in most cases, break things.
+    \endrst */
     PYBIND11_NOINLINE void add_object(const char *name, handle obj, bool overwrite = false) {
-        if (!overwrite && hasattr(*this, name))
-            pybind11_fail("Error during initialization: multiple incompatible definitions with name \"" +
-                    std::string(name) + "\"");
+        if (!overwrite && hasattr(*this, name)) {
+            pybind11_fail(
+                "Error during initialization: multiple incompatible definitions with name \""
+                + std::string(name) + "\"");
+        }
 
         PyModule_AddObject(ptr(), name, obj.inc_ref().ptr() /* steals a reference */);
     }
+
+    using module_def = PyModuleDef; // TODO: Can this be removed (it was needed only for Python 2)?
+
+    /** \rst
+        Create a new top-level module that can be used as the main module of a C extension.
+
+        ``def`` should point to a statically allocated module_def.
+    \endrst */
+    static module_ create_extension_module(const char *name, const char *doc, module_def *def) {
+        // module_def is PyModuleDef
+        // Placement new (not an allocation).
+        def = new (def)
+            PyModuleDef{/* m_base */ PyModuleDef_HEAD_INIT,
+                        /* m_name */ name,
+                        /* m_doc */ options::show_user_defined_docstrings() ? doc : nullptr,
+                        /* m_size */ -1,
+                        /* m_methods */ nullptr,
+                        /* m_slots */ nullptr,
+                        /* m_traverse */ nullptr,
+                        /* m_clear */ nullptr,
+                        /* m_free */ nullptr};
+        auto *m = PyModule_Create(def);
+        if (m == nullptr) {
+            if (PyErr_Occurred()) {
+                throw error_already_set();
+            }
+            pybind11_fail("Internal error in module_::create_extension_module()");
+        }
+        // TODO: Should be reinterpret_steal for Python 3, but Python also steals it again when
+        //       returned from PyInit_...
+        //       For Python 2, reinterpret_borrow was correct.
+        return reinterpret_borrow<module_>(m);
+    }
 };
 
+// When inside a namespace (or anywhere as long as it's not the first item on a line),
+// C++20 allows "module" to be used. This is provided for backward compatibility, and for
+// simplicity, if someone wants to use py::module for example, that is perfectly safe.
+using module = module_;
+
 /// \ingroup python_builtins
 /// Return a dictionary representing the global variables in the current execution frame,
 /// or ``__main__.__dict__`` if there is no frame (usually when the interpreter is embedded).
 inline dict globals() {
     PyObject *p = PyEval_GetGlobals();
-    return reinterpret_borrow<dict>(p ? p : module::import("__main__").attr("__dict__").ptr());
+    return reinterpret_borrow<dict>(p ? p : module_::import("__main__").attr("__dict__").ptr());
 }
 
-NAMESPACE_BEGIN(detail)
+template <typename... Args, typename = detail::enable_if_t<args_are_all_keyword_or_ds<Args...>()>>
+PYBIND11_DEPRECATED("make_simple_namespace should be replaced with "
+                    "py::module_::import(\"types\").attr(\"SimpleNamespace\") ")
+object make_simple_namespace(Args &&...args_) {
+    return module_::import("types").attr("SimpleNamespace")(std::forward<Args>(args_)...);
+}
+
+PYBIND11_NAMESPACE_BEGIN(detail)
 /// Generic support for creating new Python heap types
 class generic_type : public object {
-    template <typename...> friend class class_;
 public:
     PYBIND11_OBJECT_DEFAULT(generic_type, object, PyType_Check)
 protected:
     void initialize(const type_record &rec) {
-        if (rec.scope && hasattr(rec.scope, rec.name))
-            pybind11_fail("generic_type: cannot initialize type \"" + std::string(rec.name) +
-                          "\": an object with that name is already defined");
-
-        if (rec.module_local ? get_local_type_info(*rec.type) : get_global_type_info(*rec.type))
-            pybind11_fail("generic_type: type \"" + std::string(rec.name) +
-                          "\" is already registered!");
+        if (rec.scope && hasattr(rec.scope, "__dict__")
+            && rec.scope.attr("__dict__").contains(rec.name)) {
+            pybind11_fail("generic_type: cannot initialize type \"" + std::string(rec.name)
+                          + "\": an object with that name is already defined");
+        }
+
+        if ((rec.module_local ? get_local_type_info(*rec.type) : get_global_type_info(*rec.type))
+            != nullptr) {
+            pybind11_fail("generic_type: type \"" + std::string(rec.name)
+                          + "\" is already registered!");
+        }
 
         m_ptr = make_new_python_type(rec);
 
         /* Register supplemental type information in C++ dict */
         auto *tinfo = new detail::type_info();
         tinfo->type = (PyTypeObject *) m_ptr;
         tinfo->cpptype = rec.type;
@@ -914,171 +1324,216 @@
         tinfo->simple_ancestors = true;
         tinfo->default_holder = rec.default_holder;
         tinfo->module_local = rec.module_local;
 
         auto &internals = get_internals();
         auto tindex = std::type_index(*rec.type);
         tinfo->direct_conversions = &internals.direct_conversions[tindex];
-        if (rec.module_local)
-            registered_local_types_cpp()[tindex] = tinfo;
-        else
+        if (rec.module_local) {
+            get_local_internals().registered_types_cpp[tindex] = tinfo;
+        } else {
             internals.registered_types_cpp[tindex] = tinfo;
-        internals.registered_types_py[(PyTypeObject *) m_ptr] = { tinfo };
+        }
+        internals.registered_types_py[(PyTypeObject *) m_ptr] = {tinfo};
 
         if (rec.bases.size() > 1 || rec.multiple_inheritance) {
             mark_parents_nonsimple(tinfo->type);
             tinfo->simple_ancestors = false;
-        }
-        else if (rec.bases.size() == 1) {
-            auto parent_tinfo = get_type_info((PyTypeObject *) rec.bases[0].ptr());
-            tinfo->simple_ancestors = parent_tinfo->simple_ancestors;
+        } else if (rec.bases.size() == 1) {
+            auto *parent_tinfo = get_type_info((PyTypeObject *) rec.bases[0].ptr());
+            assert(parent_tinfo != nullptr);
+            bool parent_simple_ancestors = parent_tinfo->simple_ancestors;
+            tinfo->simple_ancestors = parent_simple_ancestors;
+            // The parent can no longer be a simple type if it has MI and has a child
+            parent_tinfo->simple_type = parent_tinfo->simple_type && parent_simple_ancestors;
         }
 
         if (rec.module_local) {
             // Stash the local typeinfo and loader so that external modules can access it.
             tinfo->module_local_load = &type_caster_generic::local_load;
             setattr(m_ptr, PYBIND11_MODULE_LOCAL_ID, capsule(tinfo));
         }
     }
 
     /// Helper function which tags all parents of a type using mult. inheritance
     void mark_parents_nonsimple(PyTypeObject *value) {
         auto t = reinterpret_borrow<tuple>(value->tp_bases);
         for (handle h : t) {
-            auto tinfo2 = get_type_info((PyTypeObject *) h.ptr());
-            if (tinfo2)
+            auto *tinfo2 = get_type_info((PyTypeObject *) h.ptr());
+            if (tinfo2) {
                 tinfo2->simple_type = false;
+            }
             mark_parents_nonsimple((PyTypeObject *) h.ptr());
         }
     }
 
-    void install_buffer_funcs(
-            buffer_info *(*get_buffer)(PyObject *, void *),
-            void *get_buffer_data) {
-        PyHeapTypeObject *type = (PyHeapTypeObject*) m_ptr;
-        auto tinfo = detail::get_type_info(&type->ht_type);
-
-        if (!type->ht_type.tp_as_buffer)
-            pybind11_fail(
-                "To be able to register buffer protocol support for the type '" +
-                std::string(tinfo->type->tp_name) +
-                "' the associated class<>(..) invocation must "
-                "include the pybind11::buffer_protocol() annotation!");
+    void install_buffer_funcs(buffer_info *(*get_buffer)(PyObject *, void *),
+                              void *get_buffer_data) {
+        auto *type = (PyHeapTypeObject *) m_ptr;
+        auto *tinfo = detail::get_type_info(&type->ht_type);
+
+        if (!type->ht_type.tp_as_buffer) {
+            pybind11_fail("To be able to register buffer protocol support for the type '"
+                          + get_fully_qualified_tp_name(tinfo->type)
+                          + "' the associated class<>(..) invocation must "
+                            "include the pybind11::buffer_protocol() annotation!");
+        }
 
         tinfo->get_buffer = get_buffer;
         tinfo->get_buffer_data = get_buffer_data;
     }
 
     // rec_func must be set for either fget or fset.
     void def_property_static_impl(const char *name,
-                                  handle fget, handle fset,
+                                  handle fget,
+                                  handle fset,
                                   detail::function_record *rec_func) {
-        const auto is_static = rec_func && !(rec_func->is_method && rec_func->scope);
-        const auto has_doc = rec_func && rec_func->doc && pybind11::options::show_user_defined_docstrings();
-        auto property = handle((PyObject *) (is_static ? get_internals().static_property_type
-                                                       : &PyProperty_Type));
+        const auto is_static = (rec_func != nullptr) && !(rec_func->is_method && rec_func->scope);
+        const auto has_doc = (rec_func != nullptr) && (rec_func->doc != nullptr)
+                             && pybind11::options::show_user_defined_docstrings();
+        auto property = handle(
+            (PyObject *) (is_static ? get_internals().static_property_type : &PyProperty_Type));
         attr(name) = property(fget.ptr() ? fget : none(),
                               fset.ptr() ? fset : none(),
-                              /*deleter*/none(),
+                              /*deleter*/ none(),
                               pybind11::str(has_doc ? rec_func->doc : ""));
     }
 };
 
 /// Set the pointer to operator new if it exists. The cast is needed because it can be overloaded.
-template <typename T, typename = void_t<decltype(static_cast<void *(*)(size_t)>(T::operator new))>>
-void set_operator_new(type_record *r) { r->operator_new = &T::operator new; }
-
-template <typename> void set_operator_new(...) { }
-
-template <typename T, typename SFINAE = void> struct has_operator_delete : std::false_type { };
-template <typename T> struct has_operator_delete<T, void_t<decltype(static_cast<void (*)(void *)>(T::operator delete))>>
-    : std::true_type { };
-template <typename T, typename SFINAE = void> struct has_operator_delete_size : std::false_type { };
-template <typename T> struct has_operator_delete_size<T, void_t<decltype(static_cast<void (*)(void *, size_t)>(T::operator delete))>>
-    : std::true_type { };
+template <typename T,
+          typename = void_t<decltype(static_cast<void *(*) (size_t)>(T::operator new))>>
+void set_operator_new(type_record *r) {
+    r->operator_new = &T::operator new;
+}
+
+template <typename>
+void set_operator_new(...) {}
+
+template <typename T, typename SFINAE = void>
+struct has_operator_delete : std::false_type {};
+template <typename T>
+struct has_operator_delete<T, void_t<decltype(static_cast<void (*)(void *)>(T::operator delete))>>
+    : std::true_type {};
+template <typename T, typename SFINAE = void>
+struct has_operator_delete_size : std::false_type {};
+template <typename T>
+struct has_operator_delete_size<
+    T,
+    void_t<decltype(static_cast<void (*)(void *, size_t)>(T::operator delete))>> : std::true_type {
+};
 /// Call class-specific delete if it exists or global otherwise. Can also be an overload set.
 template <typename T, enable_if_t<has_operator_delete<T>::value, int> = 0>
-void call_operator_delete(T *p, size_t, size_t) { T::operator delete(p); }
-template <typename T, enable_if_t<!has_operator_delete<T>::value && has_operator_delete_size<T>::value, int> = 0>
-void call_operator_delete(T *p, size_t s, size_t) { T::operator delete(p, s); }
+void call_operator_delete(T *p, size_t, size_t) {
+    T::operator delete(p);
+}
+template <typename T,
+          enable_if_t<!has_operator_delete<T>::value && has_operator_delete_size<T>::value, int>
+          = 0>
+void call_operator_delete(T *p, size_t s, size_t) {
+    T::operator delete(p, s);
+}
 
 inline void call_operator_delete(void *p, size_t s, size_t a) {
-    (void)s; (void)a;
-#if defined(PYBIND11_CPP17)
-    if (a > __STDCPP_DEFAULT_NEW_ALIGNMENT__)
+    (void) s;
+    (void) a;
+#if defined(__cpp_aligned_new) && (!defined(_MSC_VER) || _MSC_VER >= 1912)
+    if (a > __STDCPP_DEFAULT_NEW_ALIGNMENT__) {
+#    ifdef __cpp_sized_deallocation
         ::operator delete(p, s, std::align_val_t(a));
-    else
-        ::operator delete(p, s);
+#    else
+        ::operator delete(p, std::align_val_t(a));
+#    endif
+        return;
+    }
+#endif
+#ifdef __cpp_sized_deallocation
+    ::operator delete(p, s);
 #else
     ::operator delete(p);
 #endif
 }
 
-NAMESPACE_END(detail)
+inline void add_class_method(object &cls, const char *name_, const cpp_function &cf) {
+    cls.attr(cf.name()) = cf;
+    if (std::strcmp(name_, "__eq__") == 0 && !cls.attr("__dict__").contains("__hash__")) {
+        cls.attr("__hash__") = none();
+    }
+}
+
+PYBIND11_NAMESPACE_END(detail)
 
 /// Given a pointer to a member function, cast it to its `Derived` version.
 /// Forward everything else unchanged.
 template <typename /*Derived*/, typename F>
-auto method_adaptor(F &&f) -> decltype(std::forward<F>(f)) { return std::forward<F>(f); }
+auto method_adaptor(F &&f) -> decltype(std::forward<F>(f)) {
+    return std::forward<F>(f);
+}
 
 template <typename Derived, typename Return, typename Class, typename... Args>
 auto method_adaptor(Return (Class::*pmf)(Args...)) -> Return (Derived::*)(Args...) {
-    static_assert(detail::is_accessible_base_of<Class, Derived>::value,
+    static_assert(
+        detail::is_accessible_base_of<Class, Derived>::value,
         "Cannot bind an inaccessible base class method; use a lambda definition instead");
     return pmf;
 }
 
 template <typename Derived, typename Return, typename Class, typename... Args>
 auto method_adaptor(Return (Class::*pmf)(Args...) const) -> Return (Derived::*)(Args...) const {
-    static_assert(detail::is_accessible_base_of<Class, Derived>::value,
+    static_assert(
+        detail::is_accessible_base_of<Class, Derived>::value,
         "Cannot bind an inaccessible base class method; use a lambda definition instead");
     return pmf;
 }
 
 template <typename type_, typename... options>
 class class_ : public detail::generic_type {
-    template <typename T> using is_holder = detail::is_holder_type<type_, T>;
-    template <typename T> using is_subtype = detail::is_strict_base_of<type_, T>;
-    template <typename T> using is_base = detail::is_strict_base_of<T, type_>;
+    template <typename T>
+    using is_holder = detail::is_holder_type<type_, T>;
+    template <typename T>
+    using is_subtype = detail::is_strict_base_of<type_, T>;
+    template <typename T>
+    using is_base = detail::is_strict_base_of<T, type_>;
     // struct instead of using here to help MSVC:
-    template <typename T> struct is_valid_class_option :
-        detail::any_of<is_holder<T>, is_subtype<T>, is_base<T>> {};
+    template <typename T>
+    struct is_valid_class_option : detail::any_of<is_holder<T>, is_subtype<T>, is_base<T>> {};
 
 public:
     using type = type_;
     using type_alias = detail::exactly_one_t<is_subtype, void, options...>;
     constexpr static bool has_alias = !std::is_void<type_alias>::value;
     using holder_type = detail::exactly_one_t<is_holder, std::unique_ptr<type>, options...>;
 
     static_assert(detail::all_of<is_valid_class_option<options>...>::value,
-            "Unknown/invalid class_ template parameters provided");
+                  "Unknown/invalid class_ template parameters provided");
 
     static_assert(!has_alias || std::is_polymorphic<type>::value,
-            "Cannot use an alias class with a non-polymorphic type");
+                  "Cannot use an alias class with a non-polymorphic type");
 
     PYBIND11_OBJECT(class_, generic_type, PyType_Check)
 
     template <typename... Extra>
-    class_(handle scope, const char *name, const Extra &... extra) {
+    class_(handle scope, const char *name, const Extra &...extra) {
         using namespace detail;
 
         // MI can only be specified via class_ template options, not constructor parameters
         static_assert(
             none_of<is_pyobject<Extra>...>::value || // no base class arguments, or:
-            (   constexpr_sum(is_pyobject<Extra>::value...) == 1 && // Exactly one base
-                constexpr_sum(is_base<options>::value...)   == 0 && // no template option bases
-                none_of<std::is_same<multiple_inheritance, Extra>...>::value), // no multiple_inheritance attr
+                (constexpr_sum(is_pyobject<Extra>::value...) == 1 && // Exactly one base
+                 constexpr_sum(is_base<options>::value...) == 0 &&   // no template option bases
+                 // no multiple_inheritance attr
+                 none_of<std::is_same<multiple_inheritance, Extra>...>::value),
             "Error: multiple inheritance bases must be specified via class_ template options");
 
         type_record record;
         record.scope = scope;
         record.name = name;
         record.type = &typeid(type);
         record.type_size = sizeof(conditional_t<has_alias, type_alias, type>);
-        record.type_align = alignof(conditional_t<has_alias, type_alias, type>&);
+        record.type_align = alignof(conditional_t<has_alias, type_alias, type> &);
         record.holder_size = sizeof(holder_type);
         record.init_instance = init_instance;
         record.dealloc = dealloc;
         record.default_holder = detail::is_instantiation<std::unique_ptr, holder_type>::value;
 
         set_operator_new<type>(&record);
 
@@ -1087,1075 +1542,1341 @@
 
         /* Process optional arguments, if any */
         process_attributes<Extra...>::init(extra..., &record);
 
         generic_type::initialize(record);
 
         if (has_alias) {
-            auto &instances = record.module_local ? registered_local_types_cpp() : get_internals().registered_types_cpp;
-            instances[std::type_index(typeid(type_alias))] = instances[std::type_index(typeid(type))];
+            auto &instances = record.module_local ? get_local_internals().registered_types_cpp
+                                                  : get_internals().registered_types_cpp;
+            instances[std::type_index(typeid(type_alias))]
+                = instances[std::type_index(typeid(type))];
         }
     }
 
     template <typename Base, detail::enable_if_t<is_base<Base>::value, int> = 0>
     static void add_base(detail::type_record &rec) {
         rec.add_base(typeid(Base), [](void *src) -> void * {
             return static_cast<Base *>(reinterpret_cast<type *>(src));
         });
     }
 
     template <typename Base, detail::enable_if_t<!is_base<Base>::value, int> = 0>
-    static void add_base(detail::type_record &) { }
+    static void add_base(detail::type_record &) {}
 
     template <typename Func, typename... Extra>
-    class_ &def(const char *name_, Func&& f, const Extra&... extra) {
-        cpp_function cf(method_adaptor<type>(std::forward<Func>(f)), name(name_), is_method(*this),
-                        sibling(getattr(*this, name_, none())), extra...);
-        attr(cf.name()) = cf;
+    class_ &def(const char *name_, Func &&f, const Extra &...extra) {
+        cpp_function cf(method_adaptor<type>(std::forward<Func>(f)),
+                        name(name_),
+                        is_method(*this),
+                        sibling(getattr(*this, name_, none())),
+                        extra...);
+        add_class_method(*this, name_, cf);
         return *this;
     }
 
-    template <typename Func, typename... Extra> class_ &
-    def_static(const char *name_, Func &&f, const Extra&... extra) {
+    template <typename Func, typename... Extra>
+    class_ &def_static(const char *name_, Func &&f, const Extra &...extra) {
         static_assert(!std::is_member_function_pointer<Func>::value,
-                "def_static(...) called with a non-static member function pointer");
-        cpp_function cf(std::forward<Func>(f), name(name_), scope(*this),
-                        sibling(getattr(*this, name_, none())), extra...);
-        attr(cf.name()) = staticmethod(cf);
+                      "def_static(...) called with a non-static member function pointer");
+        cpp_function cf(std::forward<Func>(f),
+                        name(name_),
+                        scope(*this),
+                        sibling(getattr(*this, name_, none())),
+                        extra...);
+        auto cf_name = cf.name();
+        attr(std::move(cf_name)) = staticmethod(std::move(cf));
         return *this;
     }
 
-    template <detail::op_id id, detail::op_type ot, typename L, typename R, typename... Extra>
-    class_ &def(const detail::op_<id, ot, L, R> &op, const Extra&... extra) {
+    template <typename T, typename... Extra, detail::enable_if_t<T::op_enable_if_hook, int> = 0>
+    class_ &def(const T &op, const Extra &...extra) {
         op.execute(*this, extra...);
         return *this;
     }
 
-    template <detail::op_id id, detail::op_type ot, typename L, typename R, typename... Extra>
-    class_ & def_cast(const detail::op_<id, ot, L, R> &op, const Extra&... extra) {
+    template <typename T, typename... Extra, detail::enable_if_t<T::op_enable_if_hook, int> = 0>
+    class_ &def_cast(const T &op, const Extra &...extra) {
         op.execute_cast(*this, extra...);
         return *this;
     }
 
     template <typename... Args, typename... Extra>
-    class_ &def(const detail::initimpl::constructor<Args...> &init, const Extra&... extra) {
+    class_ &def(const detail::initimpl::constructor<Args...> &init, const Extra &...extra) {
+        PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(init);
         init.execute(*this, extra...);
         return *this;
     }
 
     template <typename... Args, typename... Extra>
-    class_ &def(const detail::initimpl::alias_constructor<Args...> &init, const Extra&... extra) {
+    class_ &def(const detail::initimpl::alias_constructor<Args...> &init, const Extra &...extra) {
+        PYBIND11_WORKAROUND_INCORRECT_MSVC_C4100(init);
         init.execute(*this, extra...);
         return *this;
     }
 
     template <typename... Args, typename... Extra>
-    class_ &def(detail::initimpl::factory<Args...> &&init, const Extra&... extra) {
+    class_ &def(detail::initimpl::factory<Args...> &&init, const Extra &...extra) {
         std::move(init).execute(*this, extra...);
         return *this;
     }
 
     template <typename... Args, typename... Extra>
     class_ &def(detail::initimpl::pickle_factory<Args...> &&pf, const Extra &...extra) {
         std::move(pf).execute(*this, extra...);
         return *this;
     }
 
-    template <typename Func> class_& def_buffer(Func &&func) {
-        struct capture { Func func; };
-        capture *ptr = new capture { std::forward<Func>(func) };
-        install_buffer_funcs([](PyObject *obj, void *ptr) -> buffer_info* {
-            detail::make_caster<type> caster;
-            if (!caster.load(obj, false))
-                return nullptr;
-            return new buffer_info(((capture *) ptr)->func(caster));
-        }, ptr);
+    template <typename Func>
+    class_ &def_buffer(Func &&func) {
+        struct capture {
+            Func func;
+        };
+        auto *ptr = new capture{std::forward<Func>(func)};
+        install_buffer_funcs(
+            [](PyObject *obj, void *ptr) -> buffer_info * {
+                detail::make_caster<type> caster;
+                if (!caster.load(obj, false)) {
+                    return nullptr;
+                }
+                return new buffer_info(((capture *) ptr)->func(std::move(caster)));
+            },
+            ptr);
+        weakref(m_ptr, cpp_function([ptr](handle wr) {
+                    delete ptr;
+                    wr.dec_ref();
+                }))
+            .release();
         return *this;
     }
 
     template <typename Return, typename Class, typename... Args>
     class_ &def_buffer(Return (Class::*func)(Args...)) {
-        return def_buffer([func] (type &obj) { return (obj.*func)(); });
+        return def_buffer([func](type &obj) { return (obj.*func)(); });
     }
 
     template <typename Return, typename Class, typename... Args>
     class_ &def_buffer(Return (Class::*func)(Args...) const) {
-        return def_buffer([func] (const type &obj) { return (obj.*func)(); });
+        return def_buffer([func](const type &obj) { return (obj.*func)(); });
     }
 
     template <typename C, typename D, typename... Extra>
-    class_ &def_readwrite(const char *name, D C::*pm, const Extra&... extra) {
-        static_assert(std::is_same<C, type>::value || std::is_base_of<C, type>::value, "def_readwrite() requires a class member (or base class member)");
-        cpp_function fget([pm](const type &c) -> const D &{ return c.*pm; }, is_method(*this)),
-                     fset([pm](type &c, const D &value) { c.*pm = value; }, is_method(*this));
+    class_ &def_readwrite(const char *name, D C::*pm, const Extra &...extra) {
+        static_assert(std::is_same<C, type>::value || std::is_base_of<C, type>::value,
+                      "def_readwrite() requires a class member (or base class member)");
+        cpp_function fget([pm](const type &c) -> const D & { return c.*pm; }, is_method(*this)),
+            fset([pm](type &c, const D &value) { c.*pm = value; }, is_method(*this));
         def_property(name, fget, fset, return_value_policy::reference_internal, extra...);
         return *this;
     }
 
     template <typename C, typename D, typename... Extra>
-    class_ &def_readonly(const char *name, const D C::*pm, const Extra& ...extra) {
-        static_assert(std::is_same<C, type>::value || std::is_base_of<C, type>::value, "def_readonly() requires a class member (or base class member)");
-        cpp_function fget([pm](const type &c) -> const D &{ return c.*pm; }, is_method(*this));
+    class_ &def_readonly(const char *name, const D C::*pm, const Extra &...extra) {
+        static_assert(std::is_same<C, type>::value || std::is_base_of<C, type>::value,
+                      "def_readonly() requires a class member (or base class member)");
+        cpp_function fget([pm](const type &c) -> const D & { return c.*pm; }, is_method(*this));
         def_property_readonly(name, fget, return_value_policy::reference_internal, extra...);
         return *this;
     }
 
     template <typename D, typename... Extra>
-    class_ &def_readwrite_static(const char *name, D *pm, const Extra& ...extra) {
-        cpp_function fget([pm](object) -> const D &{ return *pm; }, scope(*this)),
-                     fset([pm](object, const D &value) { *pm = value; }, scope(*this));
+    class_ &def_readwrite_static(const char *name, D *pm, const Extra &...extra) {
+        cpp_function fget([pm](const object &) -> const D & { return *pm; }, scope(*this)),
+            fset([pm](const object &, const D &value) { *pm = value; }, scope(*this));
         def_property_static(name, fget, fset, return_value_policy::reference, extra...);
         return *this;
     }
 
     template <typename D, typename... Extra>
-    class_ &def_readonly_static(const char *name, const D *pm, const Extra& ...extra) {
-        cpp_function fget([pm](object) -> const D &{ return *pm; }, scope(*this));
+    class_ &def_readonly_static(const char *name, const D *pm, const Extra &...extra) {
+        cpp_function fget([pm](const object &) -> const D & { return *pm; }, scope(*this));
         def_property_readonly_static(name, fget, return_value_policy::reference, extra...);
         return *this;
     }
 
     /// Uses return_value_policy::reference_internal by default
     template <typename Getter, typename... Extra>
-    class_ &def_property_readonly(const char *name, const Getter &fget, const Extra& ...extra) {
-        return def_property_readonly(name, cpp_function(method_adaptor<type>(fget)),
-                                     return_value_policy::reference_internal, extra...);
+    class_ &def_property_readonly(const char *name, const Getter &fget, const Extra &...extra) {
+        return def_property_readonly(name,
+                                     cpp_function(method_adaptor<type>(fget)),
+                                     return_value_policy::reference_internal,
+                                     extra...);
     }
 
     /// Uses cpp_function's return_value_policy by default
     template <typename... Extra>
-    class_ &def_property_readonly(const char *name, const cpp_function &fget, const Extra& ...extra) {
+    class_ &
+    def_property_readonly(const char *name, const cpp_function &fget, const Extra &...extra) {
         return def_property(name, fget, nullptr, extra...);
     }
 
     /// Uses return_value_policy::reference by default
     template <typename Getter, typename... Extra>
-    class_ &def_property_readonly_static(const char *name, const Getter &fget, const Extra& ...extra) {
-        return def_property_readonly_static(name, cpp_function(fget), return_value_policy::reference, extra...);
+    class_ &
+    def_property_readonly_static(const char *name, const Getter &fget, const Extra &...extra) {
+        return def_property_readonly_static(
+            name, cpp_function(fget), return_value_policy::reference, extra...);
     }
 
     /// Uses cpp_function's return_value_policy by default
     template <typename... Extra>
-    class_ &def_property_readonly_static(const char *name, const cpp_function &fget, const Extra& ...extra) {
+    class_ &def_property_readonly_static(const char *name,
+                                         const cpp_function &fget,
+                                         const Extra &...extra) {
         return def_property_static(name, fget, nullptr, extra...);
     }
 
     /// Uses return_value_policy::reference_internal by default
     template <typename Getter, typename Setter, typename... Extra>
-    class_ &def_property(const char *name, const Getter &fget, const Setter &fset, const Extra& ...extra) {
+    class_ &
+    def_property(const char *name, const Getter &fget, const Setter &fset, const Extra &...extra) {
         return def_property(name, fget, cpp_function(method_adaptor<type>(fset)), extra...);
     }
     template <typename Getter, typename... Extra>
-    class_ &def_property(const char *name, const Getter &fget, const cpp_function &fset, const Extra& ...extra) {
-        return def_property(name, cpp_function(method_adaptor<type>(fget)), fset,
-                            return_value_policy::reference_internal, extra...);
+    class_ &def_property(const char *name,
+                         const Getter &fget,
+                         const cpp_function &fset,
+                         const Extra &...extra) {
+        return def_property(name,
+                            cpp_function(method_adaptor<type>(fget)),
+                            fset,
+                            return_value_policy::reference_internal,
+                            extra...);
     }
 
     /// Uses cpp_function's return_value_policy by default
     template <typename... Extra>
-    class_ &def_property(const char *name, const cpp_function &fget, const cpp_function &fset, const Extra& ...extra) {
+    class_ &def_property(const char *name,
+                         const cpp_function &fget,
+                         const cpp_function &fset,
+                         const Extra &...extra) {
         return def_property_static(name, fget, fset, is_method(*this), extra...);
     }
 
     /// Uses return_value_policy::reference by default
     template <typename Getter, typename... Extra>
-    class_ &def_property_static(const char *name, const Getter &fget, const cpp_function &fset, const Extra& ...extra) {
-        return def_property_static(name, cpp_function(fget), fset, return_value_policy::reference, extra...);
+    class_ &def_property_static(const char *name,
+                                const Getter &fget,
+                                const cpp_function &fset,
+                                const Extra &...extra) {
+        return def_property_static(
+            name, cpp_function(fget), fset, return_value_policy::reference, extra...);
     }
 
     /// Uses cpp_function's return_value_policy by default
     template <typename... Extra>
-    class_ &def_property_static(const char *name, const cpp_function &fget, const cpp_function &fset, const Extra& ...extra) {
-        static_assert( 0 == detail::constexpr_sum(std::is_base_of<arg, Extra>::value...),
+    class_ &def_property_static(const char *name,
+                                const cpp_function &fget,
+                                const cpp_function &fset,
+                                const Extra &...extra) {
+        static_assert(0 == detail::constexpr_sum(std::is_base_of<arg, Extra>::value...),
                       "Argument annotations are not allowed for properties");
         auto rec_fget = get_function_record(fget), rec_fset = get_function_record(fset);
         auto *rec_active = rec_fget;
         if (rec_fget) {
-           char *doc_prev = rec_fget->doc; /* 'extra' field may include a property-specific documentation string */
-           detail::process_attributes<Extra...>::init(extra..., rec_fget);
-           if (rec_fget->doc && rec_fget->doc != doc_prev) {
-              free(doc_prev);
-              rec_fget->doc = strdup(rec_fget->doc);
-           }
+            char *doc_prev = rec_fget->doc; /* 'extra' field may include a property-specific
+                                               documentation string */
+            detail::process_attributes<Extra...>::init(extra..., rec_fget);
+            if (rec_fget->doc && rec_fget->doc != doc_prev) {
+                std::free(doc_prev);
+                rec_fget->doc = PYBIND11_COMPAT_STRDUP(rec_fget->doc);
+            }
         }
         if (rec_fset) {
             char *doc_prev = rec_fset->doc;
             detail::process_attributes<Extra...>::init(extra..., rec_fset);
             if (rec_fset->doc && rec_fset->doc != doc_prev) {
-                free(doc_prev);
-                rec_fset->doc = strdup(rec_fset->doc);
+                std::free(doc_prev);
+                rec_fset->doc = PYBIND11_COMPAT_STRDUP(rec_fset->doc);
+            }
+            if (!rec_active) {
+                rec_active = rec_fset;
             }
-            if (! rec_active) rec_active = rec_fset;
         }
         def_property_static_impl(name, fget, fset, rec_active);
         return *this;
     }
 
 private:
     /// Initialize holder object, variant 1: object derives from enable_shared_from_this
     template <typename T>
-    static void init_holder(detail::instance *inst, detail::value_and_holder &v_h,
-            const holder_type * /* unused */, const std::enable_shared_from_this<T> * /* dummy */) {
-        try {
-            auto sh = std::dynamic_pointer_cast<typename holder_type::element_type>(
-                    v_h.value_ptr<type>()->shared_from_this());
-            if (sh) {
-                new (std::addressof(v_h.holder<holder_type>())) holder_type(std::move(sh));
-                v_h.set_holder_constructed();
-            }
-        } catch (const std::bad_weak_ptr &) {}
+    static void init_holder(detail::instance *inst,
+                            detail::value_and_holder &v_h,
+                            const holder_type * /* unused */,
+                            const std::enable_shared_from_this<T> * /* dummy */) {
+
+        auto sh = std::dynamic_pointer_cast<typename holder_type::element_type>(
+            detail::try_get_shared_from_this(v_h.value_ptr<type>()));
+        if (sh) {
+            new (std::addressof(v_h.holder<holder_type>())) holder_type(std::move(sh));
+            v_h.set_holder_constructed();
+        }
 
         if (!v_h.holder_constructed() && inst->owned) {
             new (std::addressof(v_h.holder<holder_type>())) holder_type(v_h.value_ptr<type>());
             v_h.set_holder_constructed();
         }
     }
 
     static void init_holder_from_existing(const detail::value_and_holder &v_h,
-            const holder_type *holder_ptr, std::true_type /*is_copy_constructible*/) {
-        new (std::addressof(v_h.holder<holder_type>())) holder_type(*reinterpret_cast<const holder_type *>(holder_ptr));
+                                          const holder_type *holder_ptr,
+                                          std::true_type /*is_copy_constructible*/) {
+        new (std::addressof(v_h.holder<holder_type>()))
+            holder_type(*reinterpret_cast<const holder_type *>(holder_ptr));
     }
 
     static void init_holder_from_existing(const detail::value_and_holder &v_h,
-            const holder_type *holder_ptr, std::false_type /*is_copy_constructible*/) {
-        new (std::addressof(v_h.holder<holder_type>())) holder_type(std::move(*const_cast<holder_type *>(holder_ptr)));
+                                          const holder_type *holder_ptr,
+                                          std::false_type /*is_copy_constructible*/) {
+        new (std::addressof(v_h.holder<holder_type>()))
+            holder_type(std::move(*const_cast<holder_type *>(holder_ptr)));
     }
 
-    /// Initialize holder object, variant 2: try to construct from existing holder object, if possible
-    static void init_holder(detail::instance *inst, detail::value_and_holder &v_h,
-            const holder_type *holder_ptr, const void * /* dummy -- not enable_shared_from_this<T>) */) {
+    /// Initialize holder object, variant 2: try to construct from existing holder object, if
+    /// possible
+    static void init_holder(detail::instance *inst,
+                            detail::value_and_holder &v_h,
+                            const holder_type *holder_ptr,
+                            const void * /* dummy -- not enable_shared_from_this<T>) */) {
         if (holder_ptr) {
             init_holder_from_existing(v_h, holder_ptr, std::is_copy_constructible<holder_type>());
             v_h.set_holder_constructed();
-        } else if (inst->owned || detail::always_construct_holder<holder_type>::value) {
+        } else if (detail::always_construct_holder<holder_type>::value || inst->owned) {
             new (std::addressof(v_h.holder<holder_type>())) holder_type(v_h.value_ptr<type>());
             v_h.set_holder_constructed();
         }
     }
 
     /// Performs instance initialization including constructing a holder and registering the known
-    /// instance.  Should be called as soon as the `type` value_ptr is set for an instance.  Takes an
-    /// optional pointer to an existing holder to use; if not specified and the instance is
+    /// instance.  Should be called as soon as the `type` value_ptr is set for an instance.  Takes
+    /// an optional pointer to an existing holder to use; if not specified and the instance is
     /// `.owned`, a new holder will be constructed to manage the value pointer.
     static void init_instance(detail::instance *inst, const void *holder_ptr) {
         auto v_h = inst->get_value_and_holder(detail::get_type_info(typeid(type)));
         if (!v_h.instance_registered()) {
             register_instance(inst, v_h.value_ptr(), v_h.type);
             v_h.set_instance_registered();
         }
         init_holder(inst, v_h, (const holder_type *) holder_ptr, v_h.value_ptr<type>());
     }
 
     /// Deallocates an instance; via holder, if constructed; otherwise via operator delete.
     static void dealloc(detail::value_and_holder &v_h) {
+        // We could be deallocating because we are cleaning up after a Python exception.
+        // If so, the Python error indicator will be set. We need to clear that before
+        // running the destructor, in case the destructor code calls more Python.
+        // If we don't, the Python API will exit with an exception, and pybind11 will
+        // throw error_already_set from the C++ destructor which is forbidden and triggers
+        // std::terminate().
+        error_scope scope;
         if (v_h.holder_constructed()) {
             v_h.holder<holder_type>().~holder_type();
             v_h.set_holder_constructed(false);
-        }
-        else {
-            detail::call_operator_delete(v_h.value_ptr<type>(),
-                v_h.type->type_size,
-                v_h.type->type_align
-            );
+        } else {
+            detail::call_operator_delete(
+                v_h.value_ptr<type>(), v_h.type->type_size, v_h.type->type_align);
         }
         v_h.value_ptr() = nullptr;
     }
 
     static detail::function_record *get_function_record(handle h) {
         h = detail::get_function(h);
-        return h ? (detail::function_record *) reinterpret_borrow<capsule>(PyCFunction_GET_SELF(h.ptr()))
-                 : nullptr;
+        if (!h) {
+            return nullptr;
+        }
+
+        handle func_self = PyCFunction_GET_SELF(h.ptr());
+        if (!func_self) {
+            throw error_already_set();
+        }
+        if (!isinstance<capsule>(func_self)) {
+            return nullptr;
+        }
+        auto cap = reinterpret_borrow<capsule>(func_self);
+        if (!detail::is_function_record_capsule(cap)) {
+            return nullptr;
+        }
+        return cap.get_pointer<detail::function_record>();
     }
 };
 
 /// Binds an existing constructor taking arguments Args...
-template <typename... Args> detail::initimpl::constructor<Args...> init() { return {}; }
+template <typename... Args>
+detail::initimpl::constructor<Args...> init() {
+    return {};
+}
 /// Like `init<Args...>()`, but the instance is always constructed through the alias class (even
 /// when not inheriting on the Python side).
-template <typename... Args> detail::initimpl::alias_constructor<Args...> init_alias() { return {}; }
+template <typename... Args>
+detail::initimpl::alias_constructor<Args...> init_alias() {
+    return {};
+}
 
 /// Binds a factory function as a constructor
 template <typename Func, typename Ret = detail::initimpl::factory<Func>>
-Ret init(Func &&f) { return {std::forward<Func>(f)}; }
+Ret init(Func &&f) {
+    return {std::forward<Func>(f)};
+}
 
-/// Dual-argument factory function: the first function is called when no alias is needed, the second
-/// when an alias is needed (i.e. due to python-side inheritance).  Arguments must be identical.
+/// Dual-argument factory function: the first function is called when no alias is needed, the
+/// second when an alias is needed (i.e. due to python-side inheritance).  Arguments must be
+/// identical.
 template <typename CFunc, typename AFunc, typename Ret = detail::initimpl::factory<CFunc, AFunc>>
 Ret init(CFunc &&c, AFunc &&a) {
     return {std::forward<CFunc>(c), std::forward<AFunc>(a)};
 }
 
 /// Binds pickling functions `__getstate__` and `__setstate__` and ensures that the type
 /// returned by `__getstate__` is the same as the argument accepted by `__setstate__`.
 template <typename GetState, typename SetState>
 detail::initimpl::pickle_factory<GetState, SetState> pickle(GetState &&g, SetState &&s) {
     return {std::forward<GetState>(g), std::forward<SetState>(s)};
 }
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
+
+inline str enum_name(handle arg) {
+    dict entries = arg.get_type().attr("__entries");
+    for (auto kv : entries) {
+        if (handle(kv.second[int_(0)]).equal(arg)) {
+            return pybind11::str(kv.first);
+        }
+    }
+    return "???";
+}
+
 struct enum_base {
-    enum_base(handle base, handle parent) : m_base(base), m_parent(parent) { }
+    enum_base(const handle &base, const handle &parent) : m_base(base), m_parent(parent) {}
 
     PYBIND11_NOINLINE void init(bool is_arithmetic, bool is_convertible) {
         m_base.attr("__entries") = dict();
         auto property = handle((PyObject *) &PyProperty_Type);
         auto static_property = handle((PyObject *) get_internals().static_property_type);
 
         m_base.attr("__repr__") = cpp_function(
-            [](handle arg) -> str {
-                handle type = arg.get_type();
+            [](const object &arg) -> str {
+                handle type = type::handle_of(arg);
                 object type_name = type.attr("__name__");
-                dict entries = type.attr("__entries");
-                for (const auto &kv : entries) {
-                    object other = kv.second[int_(0)];
-                    if (other.equal(arg))
-                        return pybind11::str("{}.{}").format(type_name, kv.first);
-                }
-                return pybind11::str("{}.???").format(type_name);
-            }, is_method(m_base)
-        );
+                return pybind11::str("<{}.{}: {}>")
+                    .format(std::move(type_name), enum_name(arg), int_(arg));
+            },
+            name("__repr__"),
+            is_method(m_base));
+
+        m_base.attr("name") = property(cpp_function(&enum_name, name("name"), is_method(m_base)));
 
-        m_base.attr("name") = property(cpp_function(
+        m_base.attr("__str__") = cpp_function(
             [](handle arg) -> str {
-                dict entries = arg.get_type().attr("__entries");
-                for (const auto &kv : entries) {
-                    if (handle(kv.second[int_(0)]).equal(arg))
-                        return pybind11::str(kv.first);
-                }
-                return "???";
-            }, is_method(m_base)
-        ));
-
-        m_base.attr("__doc__") = static_property(cpp_function(
-            [](handle arg) -> std::string {
-                std::string docstring;
-                dict entries = arg.attr("__entries");
-                if (((PyTypeObject *) arg.ptr())->tp_doc)
-                    docstring += std::string(((PyTypeObject *) arg.ptr())->tp_doc) + "\n\n";
-                docstring += "Members:";
-                for (const auto &kv : entries) {
-                    auto key = std::string(pybind11::str(kv.first));
-                    auto comment = kv.second[int_(1)];
-                    docstring += "\n\n  " + key;
-                    if (!comment.is_none())
-                        docstring += " : " + (std::string) pybind11::str(comment);
-                }
-                return docstring;
-            }
-        ), none(), none(), "");
+                object type_name = type::handle_of(arg).attr("__name__");
+                return pybind11::str("{}.{}").format(std::move(type_name), enum_name(arg));
+            },
+            name("name"),
+            is_method(m_base));
+
+        if (options::show_enum_members_docstring()) {
+            m_base.attr("__doc__") = static_property(
+                cpp_function(
+                    [](handle arg) -> std::string {
+                        std::string docstring;
+                        dict entries = arg.attr("__entries");
+                        if (((PyTypeObject *) arg.ptr())->tp_doc) {
+                            docstring += std::string(
+                                reinterpret_cast<PyTypeObject *>(arg.ptr())->tp_doc);
+                            docstring += "\n\n";
+                        }
+                        docstring += "Members:";
+                        for (auto kv : entries) {
+                            auto key = std::string(pybind11::str(kv.first));
+                            auto comment = kv.second[int_(1)];
+                            docstring += "\n\n  ";
+                            docstring += key;
+                            if (!comment.is_none()) {
+                                docstring += " : ";
+                                docstring += pybind11::str(comment).cast<std::string>();
+                            }
+                        }
+                        return docstring;
+                    },
+                    name("__doc__")),
+                none(),
+                none(),
+                "");
+        }
 
         m_base.attr("__members__") = static_property(cpp_function(
-            [](handle arg) -> dict {
-                dict entries = arg.attr("__entries"), m;
-                for (const auto &kv : entries)
-                    m[kv.first] = kv.second[int_(0)];
-                return m;
-            }), none(), none(), ""
-        );
-
-        #define PYBIND11_ENUM_OP_STRICT(op, expr, strict_behavior)                     \
-            m_base.attr(op) = cpp_function(                                            \
-                [](object a, object b) {                                               \
-                    if (!a.get_type().is(b.get_type()))                                \
-                        strict_behavior;                                               \
-                    return expr;                                                       \
-                },                                                                     \
-                is_method(m_base))
-
-        #define PYBIND11_ENUM_OP_CONV(op, expr)                                        \
-            m_base.attr(op) = cpp_function(                                            \
-                [](object a_, object b_) {                                             \
-                    int_ a(a_), b(b_);                                                 \
-                    return expr;                                                       \
-                },                                                                     \
-                is_method(m_base))
+                                                         [](handle arg) -> dict {
+                                                             dict entries = arg.attr("__entries"),
+                                                                  m;
+                                                             for (auto kv : entries) {
+                                                                 m[kv.first] = kv.second[int_(0)];
+                                                             }
+                                                             return m;
+                                                         },
+                                                         name("__members__")),
+                                                     none(),
+                                                     none(),
+                                                     "");
+
+#define PYBIND11_ENUM_OP_STRICT(op, expr, strict_behavior)                                        \
+    m_base.attr(op) = cpp_function(                                                               \
+        [](const object &a, const object &b) {                                                    \
+            if (!type::handle_of(a).is(type::handle_of(b)))                                       \
+                strict_behavior; /* NOLINT(bugprone-macro-parentheses) */                         \
+            return expr;                                                                          \
+        },                                                                                        \
+        name(op),                                                                                 \
+        is_method(m_base),                                                                        \
+        arg("other"))
+
+#define PYBIND11_ENUM_OP_CONV(op, expr)                                                           \
+    m_base.attr(op) = cpp_function(                                                               \
+        [](const object &a_, const object &b_) {                                                  \
+            int_ a(a_), b(b_);                                                                    \
+            return expr;                                                                          \
+        },                                                                                        \
+        name(op),                                                                                 \
+        is_method(m_base),                                                                        \
+        arg("other"))
+
+#define PYBIND11_ENUM_OP_CONV_LHS(op, expr)                                                       \
+    m_base.attr(op) = cpp_function(                                                               \
+        [](const object &a_, const object &b) {                                                   \
+            int_ a(a_);                                                                           \
+            return expr;                                                                          \
+        },                                                                                        \
+        name(op),                                                                                 \
+        is_method(m_base),                                                                        \
+        arg("other"))
 
         if (is_convertible) {
-            PYBIND11_ENUM_OP_CONV("__eq__", !b.is_none() &&  a.equal(b));
-            PYBIND11_ENUM_OP_CONV("__ne__",  b.is_none() || !a.equal(b));
+            PYBIND11_ENUM_OP_CONV_LHS("__eq__", !b.is_none() && a.equal(b));
+            PYBIND11_ENUM_OP_CONV_LHS("__ne__", b.is_none() || !a.equal(b));
 
             if (is_arithmetic) {
-                PYBIND11_ENUM_OP_CONV("__lt__",   a <  b);
-                PYBIND11_ENUM_OP_CONV("__gt__",   a >  b);
-                PYBIND11_ENUM_OP_CONV("__le__",   a <= b);
-                PYBIND11_ENUM_OP_CONV("__ge__",   a >= b);
-                PYBIND11_ENUM_OP_CONV("__and__",  a &  b);
-                PYBIND11_ENUM_OP_CONV("__rand__", a &  b);
-                PYBIND11_ENUM_OP_CONV("__or__",   a |  b);
-                PYBIND11_ENUM_OP_CONV("__ror__",  a |  b);
-                PYBIND11_ENUM_OP_CONV("__xor__",  a ^  b);
-                PYBIND11_ENUM_OP_CONV("__rxor__", a ^  b);
+                PYBIND11_ENUM_OP_CONV("__lt__", a < b);
+                PYBIND11_ENUM_OP_CONV("__gt__", a > b);
+                PYBIND11_ENUM_OP_CONV("__le__", a <= b);
+                PYBIND11_ENUM_OP_CONV("__ge__", a >= b);
+                PYBIND11_ENUM_OP_CONV("__and__", a & b);
+                PYBIND11_ENUM_OP_CONV("__rand__", a & b);
+                PYBIND11_ENUM_OP_CONV("__or__", a | b);
+                PYBIND11_ENUM_OP_CONV("__ror__", a | b);
+                PYBIND11_ENUM_OP_CONV("__xor__", a ^ b);
+                PYBIND11_ENUM_OP_CONV("__rxor__", a ^ b);
+                m_base.attr("__invert__")
+                    = cpp_function([](const object &arg) { return ~(int_(arg)); },
+                                   name("__invert__"),
+                                   is_method(m_base));
             }
         } else {
-            PYBIND11_ENUM_OP_STRICT("__eq__",  int_(a).equal(int_(b)), return false);
+            PYBIND11_ENUM_OP_STRICT("__eq__", int_(a).equal(int_(b)), return false);
             PYBIND11_ENUM_OP_STRICT("__ne__", !int_(a).equal(int_(b)), return true);
 
             if (is_arithmetic) {
-                #define PYBIND11_THROW throw type_error("Expected an enumeration of matching type!");
-                PYBIND11_ENUM_OP_STRICT("__lt__", int_(a) <  int_(b), PYBIND11_THROW);
-                PYBIND11_ENUM_OP_STRICT("__gt__", int_(a) >  int_(b), PYBIND11_THROW);
+#define PYBIND11_THROW throw type_error("Expected an enumeration of matching type!");
+                PYBIND11_ENUM_OP_STRICT("__lt__", int_(a) < int_(b), PYBIND11_THROW);
+                PYBIND11_ENUM_OP_STRICT("__gt__", int_(a) > int_(b), PYBIND11_THROW);
                 PYBIND11_ENUM_OP_STRICT("__le__", int_(a) <= int_(b), PYBIND11_THROW);
                 PYBIND11_ENUM_OP_STRICT("__ge__", int_(a) >= int_(b), PYBIND11_THROW);
-                #undef PYBIND11_THROW
+#undef PYBIND11_THROW
             }
         }
 
-        #undef PYBIND11_ENUM_OP_CONV
-        #undef PYBIND11_ENUM_OP_STRICT
+#undef PYBIND11_ENUM_OP_CONV_LHS
+#undef PYBIND11_ENUM_OP_CONV
+#undef PYBIND11_ENUM_OP_STRICT
 
-        object getstate = cpp_function(
-            [](object arg) { return int_(arg); }, is_method(m_base));
+        m_base.attr("__getstate__") = cpp_function(
+            [](const object &arg) { return int_(arg); }, name("__getstate__"), is_method(m_base));
 
-        m_base.attr("__getstate__") = getstate;
-        m_base.attr("__hash__") = getstate;
+        m_base.attr("__hash__") = cpp_function(
+            [](const object &arg) { return int_(arg); }, name("__hash__"), is_method(m_base));
     }
 
-    PYBIND11_NOINLINE void value(char const* name_, object value, const char *doc = nullptr) {
+    PYBIND11_NOINLINE void value(char const *name_, object value, const char *doc = nullptr) {
         dict entries = m_base.attr("__entries");
         str name(name_);
         if (entries.contains(name)) {
             std::string type_name = (std::string) str(m_base.attr("__name__"));
-            throw value_error(type_name + ": element \"" + std::string(name_) + "\" already exists!");
+            throw value_error(std::move(type_name) + ": element \"" + std::string(name_)
+                              + "\" already exists!");
         }
 
-        entries[name] = std::make_pair(value, doc);
-        m_base.attr(name) = value;
+        entries[name] = pybind11::make_tuple(value, doc);
+        m_base.attr(std::move(name)) = std::move(value);
     }
 
     PYBIND11_NOINLINE void export_values() {
         dict entries = m_base.attr("__entries");
-        for (const auto &kv : entries)
+        for (auto kv : entries) {
             m_parent.attr(kv.first) = kv.second[int_(0)];
+        }
     }
 
     handle m_base;
     handle m_parent;
 };
 
-NAMESPACE_END(detail)
+template <bool is_signed, size_t length>
+struct equivalent_integer {};
+template <>
+struct equivalent_integer<true, 1> {
+    using type = int8_t;
+};
+template <>
+struct equivalent_integer<false, 1> {
+    using type = uint8_t;
+};
+template <>
+struct equivalent_integer<true, 2> {
+    using type = int16_t;
+};
+template <>
+struct equivalent_integer<false, 2> {
+    using type = uint16_t;
+};
+template <>
+struct equivalent_integer<true, 4> {
+    using type = int32_t;
+};
+template <>
+struct equivalent_integer<false, 4> {
+    using type = uint32_t;
+};
+template <>
+struct equivalent_integer<true, 8> {
+    using type = int64_t;
+};
+template <>
+struct equivalent_integer<false, 8> {
+    using type = uint64_t;
+};
+
+template <typename IntLike>
+using equivalent_integer_t =
+    typename equivalent_integer<std::is_signed<IntLike>::value, sizeof(IntLike)>::type;
+
+PYBIND11_NAMESPACE_END(detail)
 
 /// Binds C++ enumerations and enumeration classes to Python
-template <typename Type> class enum_ : public class_<Type> {
+template <typename Type>
+class enum_ : public class_<Type> {
 public:
     using Base = class_<Type>;
-    using Base::def;
     using Base::attr;
+    using Base::def;
     using Base::def_property_readonly;
     using Base::def_property_readonly_static;
-    using Scalar = typename std::underlying_type<Type>::type;
+    using Underlying = typename std::underlying_type<Type>::type;
+    // Scalar is the integer representation of underlying type
+    using Scalar = detail::conditional_t<detail::any_of<detail::is_std_char_type<Underlying>,
+                                                        std::is_same<Underlying, bool>>::value,
+                                         detail::equivalent_integer_t<Underlying>,
+                                         Underlying>;
 
     template <typename... Extra>
-    enum_(const handle &scope, const char *name, const Extra&... extra)
-      : class_<Type>(scope, name, extra...), m_base(*this, scope) {
+    enum_(const handle &scope, const char *name, const Extra &...extra)
+        : class_<Type>(scope, name, extra...), m_base(*this, scope) {
         constexpr bool is_arithmetic = detail::any_of<std::is_same<arithmetic, Extra>...>::value;
-        constexpr bool is_convertible = std::is_convertible<Type, Scalar>::value;
+        constexpr bool is_convertible = std::is_convertible<Type, Underlying>::value;
         m_base.init(is_arithmetic, is_convertible);
 
-        def(init([](Scalar i) { return static_cast<Type>(i); }));
+        def(init([](Scalar i) { return static_cast<Type>(i); }), arg("value"));
+        def_property_readonly("value", [](Type value) { return (Scalar) value; });
         def("__int__", [](Type value) { return (Scalar) value; });
-        #if PY_MAJOR_VERSION < 3
-            def("__long__", [](Type value) { return (Scalar) value; });
-        #endif
-        cpp_function setstate(
-            [](Type &value, Scalar arg) { value = static_cast<Type>(arg); },
-            is_method(*this));
-        attr("__setstate__") = setstate;
+        def("__index__", [](Type value) { return (Scalar) value; });
+        attr("__setstate__") = cpp_function(
+            [](detail::value_and_holder &v_h, Scalar arg) {
+                detail::initimpl::setstate<Base>(
+                    v_h, static_cast<Type>(arg), Py_TYPE(v_h.inst) != v_h.type->type);
+            },
+            detail::is_new_style_constructor(),
+            pybind11::name("__setstate__"),
+            is_method(*this),
+            arg("state"));
     }
 
     /// Export enumeration entries into the parent scope
-    enum_& export_values() {
+    enum_ &export_values() {
         m_base.export_values();
         return *this;
     }
 
     /// Add an enumeration entry
-    enum_& value(char const* name, Type value, const char *doc = nullptr) {
+    enum_ &value(char const *name, Type value, const char *doc = nullptr) {
         m_base.value(name, pybind11::cast(value, return_value_policy::copy), doc);
         return *this;
     }
 
 private:
     detail::enum_base m_base;
 };
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
-
-inline void keep_alive_impl(handle nurse, handle patient) {
-    if (!nurse || !patient)
+PYBIND11_NOINLINE void keep_alive_impl(handle nurse, handle patient) {
+    if (!nurse || !patient) {
         pybind11_fail("Could not activate keep_alive!");
+    }
 
-    if (patient.is_none() || nurse.is_none())
+    if (patient.is_none() || nurse.is_none()) {
         return; /* Nothing to keep alive or nothing to be kept alive by */
+    }
 
     auto tinfo = all_type_info(Py_TYPE(nurse.ptr()));
     if (!tinfo.empty()) {
         /* It's a pybind-registered type, so we can store the patient in the
          * internal list. */
         add_patient(nurse.ptr(), patient.ptr());
-    }
-    else {
+    } else {
         /* Fall back to clever approach based on weak references taken from
          * Boost.Python. This is not used for pybind-registered types because
          * the objects can be destroyed out-of-order in a GC pass. */
-        cpp_function disable_lifesupport(
-            [patient](handle weakref) { patient.dec_ref(); weakref.dec_ref(); });
+        cpp_function disable_lifesupport([patient](handle weakref) {
+            patient.dec_ref();
+            weakref.dec_ref();
+        });
 
         weakref wr(nurse, disable_lifesupport);
 
         patient.inc_ref(); /* reference patient and leak the weak reference */
         (void) wr.release();
     }
 }
 
-PYBIND11_NOINLINE inline void keep_alive_impl(size_t Nurse, size_t Patient, function_call &call, handle ret) {
+PYBIND11_NOINLINE void
+keep_alive_impl(size_t Nurse, size_t Patient, function_call &call, handle ret) {
     auto get_arg = [&](size_t n) {
-        if (n == 0)
+        if (n == 0) {
             return ret;
-        else if (n == 1 && call.init_self)
+        }
+        if (n == 1 && call.init_self) {
             return call.init_self;
-        else if (n <= call.args.size())
+        }
+        if (n <= call.args.size()) {
             return call.args[n - 1];
+        }
         return handle();
     };
 
     keep_alive_impl(get_arg(Nurse), get_arg(Patient));
 }
 
-inline std::pair<decltype(internals::registered_types_py)::iterator, bool> all_type_info_get_cache(PyTypeObject *type) {
-    auto res = get_internals().registered_types_py
+inline std::pair<decltype(internals::registered_types_py)::iterator, bool>
+all_type_info_get_cache(PyTypeObject *type) {
+    auto res = get_internals()
+                   .registered_types_py
 #ifdef __cpp_lib_unordered_map_try_emplace
-        .try_emplace(type);
+                   .try_emplace(type);
 #else
-        .emplace(type, std::vector<detail::type_info *>());
+                   .emplace(type, std::vector<detail::type_info *>());
 #endif
     if (res.second) {
         // New cache entry created; set up a weak reference to automatically remove it if the type
         // gets destroyed:
         weakref((PyObject *) type, cpp_function([type](handle wr) {
-            get_internals().registered_types_py.erase(type);
-            wr.dec_ref();
-        })).release();
+                    get_internals().registered_types_py.erase(type);
+
+                    // TODO consolidate the erasure code in pybind11_meta_dealloc() in class.h
+                    auto &cache = get_internals().inactive_override_cache;
+                    for (auto it = cache.begin(), last = cache.end(); it != last;) {
+                        if (it->first == reinterpret_cast<PyObject *>(type)) {
+                            it = cache.erase(it);
+                        } else {
+                            ++it;
+                        }
+                    }
+
+                    wr.dec_ref();
+                }))
+            .release();
     }
 
     return res;
 }
 
-template <typename Iterator, typename Sentinel, bool KeyIterator, return_value_policy Policy>
+/* There are a large number of apparently unused template arguments because
+ * each combination requires a separate py::class_ registration.
+ */
+template <typename Access,
+          return_value_policy Policy,
+          typename Iterator,
+          typename Sentinel,
+          typename ValueType,
+          typename... Extra>
 struct iterator_state {
     Iterator it;
     Sentinel end;
     bool first_or_done;
 };
 
-NAMESPACE_END(detail)
+// Note: these helpers take the iterator by non-const reference because some
+// iterators in the wild can't be dereferenced when const. The & after Iterator
+// is required for MSVC < 16.9. SFINAE cannot be reused for result_type due to
+// bugs in ICC, NVCC, and PGI compilers. See PR #3293.
+template <typename Iterator, typename SFINAE = decltype(*std::declval<Iterator &>())>
+struct iterator_access {
+    using result_type = decltype(*std::declval<Iterator &>());
+    // NOLINTNEXTLINE(readability-const-return-type) // PR #3263
+    result_type operator()(Iterator &it) const { return *it; }
+};
 
-/// Makes a python iterator from a first and past-the-end C++ InputIterator.
-template <return_value_policy Policy = return_value_policy::reference_internal,
+template <typename Iterator, typename SFINAE = decltype((*std::declval<Iterator &>()).first)>
+class iterator_key_access {
+private:
+    using pair_type = decltype(*std::declval<Iterator &>());
+
+public:
+    /* If either the pair itself or the element of the pair is a reference, we
+     * want to return a reference, otherwise a value. When the decltype
+     * expression is parenthesized it is based on the value category of the
+     * expression; otherwise it is the declared type of the pair member.
+     * The use of declval<pair_type> in the second branch rather than directly
+     * using *std::declval<Iterator &>() is a workaround for nvcc
+     * (it's not used in the first branch because going via decltype and back
+     * through declval does not perfectly preserve references).
+     */
+    using result_type
+        = conditional_t<std::is_reference<decltype(*std::declval<Iterator &>())>::value,
+                        decltype(((*std::declval<Iterator &>()).first)),
+                        decltype(std::declval<pair_type>().first)>;
+    result_type operator()(Iterator &it) const { return (*it).first; }
+};
+
+template <typename Iterator, typename SFINAE = decltype((*std::declval<Iterator &>()).second)>
+class iterator_value_access {
+private:
+    using pair_type = decltype(*std::declval<Iterator &>());
+
+public:
+    using result_type
+        = conditional_t<std::is_reference<decltype(*std::declval<Iterator &>())>::value,
+                        decltype(((*std::declval<Iterator &>()).second)),
+                        decltype(std::declval<pair_type>().second)>;
+    result_type operator()(Iterator &it) const { return (*it).second; }
+};
+
+template <typename Access,
+          return_value_policy Policy,
           typename Iterator,
           typename Sentinel,
-          typename ValueType = decltype(*std::declval<Iterator>()),
+          typename ValueType,
           typename... Extra>
-iterator make_iterator(Iterator first, Sentinel last, Extra &&... extra) {
-    typedef detail::iterator_state<Iterator, Sentinel, false, Policy> state;
+iterator make_iterator_impl(Iterator first, Sentinel last, Extra &&...extra) {
+    using state = detail::iterator_state<Access, Policy, Iterator, Sentinel, ValueType, Extra...>;
+    // TODO: state captures only the types of Extra, not the values
 
     if (!detail::get_type_info(typeid(state), false)) {
         class_<state>(handle(), "iterator", pybind11::module_local())
-            .def("__iter__", [](state &s) -> state& { return s; })
-            .def("__next__", [](state &s) -> ValueType {
-                if (!s.first_or_done)
-                    ++s.it;
-                else
-                    s.first_or_done = false;
-                if (s.it == s.end) {
-                    s.first_or_done = true;
-                    throw stop_iteration();
-                }
-                return *s.it;
-            }, std::forward<Extra>(extra)..., Policy);
+            .def("__iter__", [](state &s) -> state & { return s; })
+            .def(
+                "__next__",
+                [](state &s) -> ValueType {
+                    if (!s.first_or_done) {
+                        ++s.it;
+                    } else {
+                        s.first_or_done = false;
+                    }
+                    if (s.it == s.end) {
+                        s.first_or_done = true;
+                        throw stop_iteration();
+                    }
+                    return Access()(s.it);
+                    // NOLINTNEXTLINE(readability-const-return-type) // PR #3263
+                },
+                std::forward<Extra>(extra)...,
+                Policy);
     }
 
     return cast(state{first, last, true});
 }
 
-/// Makes an python iterator over the keys (`.first`) of a iterator over pairs from a
-/// first and past-the-end InputIterator.
+PYBIND11_NAMESPACE_END(detail)
+
+/// Makes a python iterator from a first and past-the-end C++ InputIterator.
 template <return_value_policy Policy = return_value_policy::reference_internal,
           typename Iterator,
           typename Sentinel,
-          typename KeyType = decltype((*std::declval<Iterator>()).first),
+          typename ValueType = typename detail::iterator_access<Iterator>::result_type,
           typename... Extra>
-iterator make_key_iterator(Iterator first, Sentinel last, Extra &&... extra) {
-    typedef detail::iterator_state<Iterator, Sentinel, true, Policy> state;
+iterator make_iterator(Iterator first, Sentinel last, Extra &&...extra) {
+    return detail::make_iterator_impl<detail::iterator_access<Iterator>,
+                                      Policy,
+                                      Iterator,
+                                      Sentinel,
+                                      ValueType,
+                                      Extra...>(first, last, std::forward<Extra>(extra)...);
+}
 
-    if (!detail::get_type_info(typeid(state), false)) {
-        class_<state>(handle(), "iterator", pybind11::module_local())
-            .def("__iter__", [](state &s) -> state& { return s; })
-            .def("__next__", [](state &s) -> KeyType {
-                if (!s.first_or_done)
-                    ++s.it;
-                else
-                    s.first_or_done = false;
-                if (s.it == s.end) {
-                    s.first_or_done = true;
-                    throw stop_iteration();
-                }
-                return (*s.it).first;
-            }, std::forward<Extra>(extra)..., Policy);
-    }
+/// Makes a python iterator over the keys (`.first`) of a iterator over pairs from a
+/// first and past-the-end InputIterator.
+template <return_value_policy Policy = return_value_policy::reference_internal,
+          typename Iterator,
+          typename Sentinel,
+          typename KeyType = typename detail::iterator_key_access<Iterator>::result_type,
+          typename... Extra>
+iterator make_key_iterator(Iterator first, Sentinel last, Extra &&...extra) {
+    return detail::make_iterator_impl<detail::iterator_key_access<Iterator>,
+                                      Policy,
+                                      Iterator,
+                                      Sentinel,
+                                      KeyType,
+                                      Extra...>(first, last, std::forward<Extra>(extra)...);
+}
 
-    return cast(state{first, last, true});
+/// Makes a python iterator over the values (`.second`) of a iterator over pairs from a
+/// first and past-the-end InputIterator.
+template <return_value_policy Policy = return_value_policy::reference_internal,
+          typename Iterator,
+          typename Sentinel,
+          typename ValueType = typename detail::iterator_value_access<Iterator>::result_type,
+          typename... Extra>
+iterator make_value_iterator(Iterator first, Sentinel last, Extra &&...extra) {
+    return detail::make_iterator_impl<detail::iterator_value_access<Iterator>,
+                                      Policy,
+                                      Iterator,
+                                      Sentinel,
+                                      ValueType,
+                                      Extra...>(first, last, std::forward<Extra>(extra)...);
 }
 
 /// Makes an iterator over values of an stl container or other container supporting
 /// `std::begin()`/`std::end()`
 template <return_value_policy Policy = return_value_policy::reference_internal,
-          typename Type, typename... Extra> iterator make_iterator(Type &value, Extra&&... extra) {
-    return make_iterator<Policy>(std::begin(value), std::end(value), extra...);
+          typename Type,
+          typename... Extra>
+iterator make_iterator(Type &value, Extra &&...extra) {
+    return make_iterator<Policy>(
+        std::begin(value), std::end(value), std::forward<Extra>(extra)...);
 }
 
 /// Makes an iterator over the keys (`.first`) of a stl map-like container supporting
 /// `std::begin()`/`std::end()`
 template <return_value_policy Policy = return_value_policy::reference_internal,
-          typename Type, typename... Extra> iterator make_key_iterator(Type &value, Extra&&... extra) {
-    return make_key_iterator<Policy>(std::begin(value), std::end(value), extra...);
+          typename Type,
+          typename... Extra>
+iterator make_key_iterator(Type &value, Extra &&...extra) {
+    return make_key_iterator<Policy>(
+        std::begin(value), std::end(value), std::forward<Extra>(extra)...);
+}
+
+/// Makes an iterator over the values (`.second`) of a stl map-like container supporting
+/// `std::begin()`/`std::end()`
+template <return_value_policy Policy = return_value_policy::reference_internal,
+          typename Type,
+          typename... Extra>
+iterator make_value_iterator(Type &value, Extra &&...extra) {
+    return make_value_iterator<Policy>(
+        std::begin(value), std::end(value), std::forward<Extra>(extra)...);
 }
 
-template <typename InputType, typename OutputType> void implicitly_convertible() {
+template <typename InputType, typename OutputType>
+void implicitly_convertible() {
     struct set_flag {
         bool &flag;
-        set_flag(bool &flag) : flag(flag) { flag = true; }
+        explicit set_flag(bool &flag_) : flag(flag_) { flag_ = true; }
         ~set_flag() { flag = false; }
     };
     auto implicit_caster = [](PyObject *obj, PyTypeObject *type) -> PyObject * {
         static bool currently_used = false;
-        if (currently_used) // implicit conversions are non-reentrant
+        if (currently_used) { // implicit conversions are non-reentrant
             return nullptr;
+        }
         set_flag flag_helper(currently_used);
-        if (!detail::make_caster<InputType>().load(obj, false))
+        if (!detail::make_caster<InputType>().load(obj, false)) {
             return nullptr;
+        }
         tuple args(1);
         args[0] = obj;
         PyObject *result = PyObject_Call((PyObject *) type, args.ptr(), nullptr);
-        if (result == nullptr)
+        if (result == nullptr) {
             PyErr_Clear();
+        }
         return result;
     };
 
-    if (auto tinfo = detail::get_type_info(typeid(OutputType)))
-        tinfo->implicit_conversions.push_back(implicit_caster);
-    else
+    if (auto *tinfo = detail::get_type_info(typeid(OutputType))) {
+        tinfo->implicit_conversions.emplace_back(std::move(implicit_caster));
+    } else {
         pybind11_fail("implicitly_convertible: Unable to find type " + type_id<OutputType>());
+    }
 }
 
-template <typename ExceptionTranslator>
-void register_exception_translator(ExceptionTranslator&& translator) {
+inline void register_exception_translator(ExceptionTranslator &&translator) {
     detail::get_internals().registered_exception_translators.push_front(
         std::forward<ExceptionTranslator>(translator));
 }
 
 /**
+ * Add a new module-local exception translator. Locally registered functions
+ * will be tried before any globally registered exception translators, which
+ * will only be invoked if the module-local handlers do not deal with
+ * the exception.
+ */
+inline void register_local_exception_translator(ExceptionTranslator &&translator) {
+    detail::get_local_internals().registered_exception_translators.push_front(
+        std::forward<ExceptionTranslator>(translator));
+}
+
+/**
  * Wrapper to generate a new Python exception type.
  *
  * This should only be used with PyErr_SetString for now.
  * It is not (yet) possible to use as a py::base.
  * Template type argument is reserved for future use.
  */
 template <typename type>
 class exception : public object {
 public:
     exception() = default;
-    exception(handle scope, const char *name, PyObject *base = PyExc_Exception) {
-        std::string full_name = scope.attr("__name__").cast<std::string>() +
-                                std::string(".") + name;
-        m_ptr = PyErr_NewException(const_cast<char *>(full_name.c_str()), base, NULL);
-        if (hasattr(scope, name))
+    exception(handle scope, const char *name, handle base = PyExc_Exception) {
+        std::string full_name
+            = scope.attr("__name__").cast<std::string>() + std::string(".") + name;
+        m_ptr = PyErr_NewException(const_cast<char *>(full_name.c_str()), base.ptr(), nullptr);
+        if (hasattr(scope, "__dict__") && scope.attr("__dict__").contains(name)) {
             pybind11_fail("Error during initialization: multiple incompatible "
-                          "definitions with name \"" + std::string(name) + "\"");
+                          "definitions with name \""
+                          + std::string(name) + "\"");
+        }
         scope.attr(name) = *this;
     }
 
     // Sets the current python exception to this exception object with the given message
-    void operator()(const char *message) {
-        PyErr_SetString(m_ptr, message);
-    }
+    void operator()(const char *message) { PyErr_SetString(m_ptr, message); }
 };
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
 // Returns a reference to a function-local static exception object used in the simple
 // register_exception approach below.  (It would be simpler to have the static local variable
 // directly in register_exception, but that makes clang <3.5 segfault - issue #1349).
 template <typename CppException>
-exception<CppException> &get_exception_object() { static exception<CppException> ex; return ex; }
-NAMESPACE_END(detail)
+exception<CppException> &get_exception_object() {
+    static exception<CppException> ex;
+    return ex;
+}
 
-/**
- * Registers a Python exception in `m` of the given `name` and installs an exception translator to
- * translate the C++ exception to the created Python exception using the exceptions what() method.
- * This is intended for simple exception translations; for more complex translation, register the
- * exception object and translator directly.
- */
+// Helper function for register_exception and register_local_exception
 template <typename CppException>
-exception<CppException> &register_exception(handle scope,
-                                            const char *name,
-                                            PyObject *base = PyExc_Exception) {
+exception<CppException> &
+register_exception_impl(handle scope, const char *name, handle base, bool isLocal) {
     auto &ex = detail::get_exception_object<CppException>();
-    if (!ex) ex = exception<CppException>(scope, name, base);
+    if (!ex) {
+        ex = exception<CppException>(scope, name, base);
+    }
 
-    register_exception_translator([](std::exception_ptr p) {
-        if (!p) return;
+    auto register_func
+        = isLocal ? &register_local_exception_translator : &register_exception_translator;
+
+    register_func([](std::exception_ptr p) {
+        if (!p) {
+            return;
+        }
         try {
             std::rethrow_exception(p);
         } catch (const CppException &e) {
             detail::get_exception_object<CppException>()(e.what());
         }
     });
     return ex;
 }
 
-NAMESPACE_BEGIN(detail)
-PYBIND11_NOINLINE inline void print(tuple args, dict kwargs) {
+PYBIND11_NAMESPACE_END(detail)
+
+/**
+ * Registers a Python exception in `m` of the given `name` and installs a translator to
+ * translate the C++ exception to the created Python exception using the what() method.
+ * This is intended for simple exception translations; for more complex translation, register the
+ * exception object and translator directly.
+ */
+template <typename CppException>
+exception<CppException> &
+register_exception(handle scope, const char *name, handle base = PyExc_Exception) {
+    return detail::register_exception_impl<CppException>(scope, name, base, false /* isLocal */);
+}
+
+/**
+ * Registers a Python exception in `m` of the given `name` and installs a translator to
+ * translate the C++ exception to the created Python exception using the what() method.
+ * This translator will only be used for exceptions that are thrown in this module and will be
+ * tried before global exception translators, including those registered with register_exception.
+ * This is intended for simple exception translations; for more complex translation, register the
+ * exception object and translator directly.
+ */
+template <typename CppException>
+exception<CppException> &
+register_local_exception(handle scope, const char *name, handle base = PyExc_Exception) {
+    return detail::register_exception_impl<CppException>(scope, name, base, true /* isLocal */);
+}
+
+PYBIND11_NAMESPACE_BEGIN(detail)
+PYBIND11_NOINLINE void print(const tuple &args, const dict &kwargs) {
     auto strings = tuple(args.size());
     for (size_t i = 0; i < args.size(); ++i) {
         strings[i] = str(args[i]);
     }
-    auto sep = kwargs.contains("sep") ? kwargs["sep"] : cast(" ");
-    auto line = sep.attr("join")(strings);
+    auto sep = kwargs.contains("sep") ? kwargs["sep"] : str(" ");
+    auto line = sep.attr("join")(std::move(strings));
 
     object file;
     if (kwargs.contains("file")) {
         file = kwargs["file"].cast<object>();
     } else {
         try {
-            file = module::import("sys").attr("stdout");
+            file = module_::import("sys").attr("stdout");
         } catch (const error_already_set &) {
             /* If print() is called from code that is executed as
                part of garbage collection during interpreter shutdown,
                importing 'sys' can fail. Give up rather than crashing the
                interpreter in this case. */
             return;
         }
     }
 
     auto write = file.attr("write");
-    write(line);
-    write(kwargs.contains("end") ? kwargs["end"] : cast("\n"));
+    write(std::move(line));
+    write(kwargs.contains("end") ? kwargs["end"] : str("\n"));
 
-    if (kwargs.contains("flush") && kwargs["flush"].cast<bool>())
+    if (kwargs.contains("flush") && kwargs["flush"].cast<bool>()) {
         file.attr("flush")();
+    }
 }
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
 
 template <return_value_policy policy = return_value_policy::automatic_reference, typename... Args>
 void print(Args &&...args) {
     auto c = detail::collect_arguments<policy>(std::forward<Args>(args)...);
     detail::print(c.args(), c.kwargs());
 }
 
-#if defined(WITH_THREAD) && !defined(PYPY_VERSION)
-
-/* The functions below essentially reproduce the PyGILState_* API using a RAII
- * pattern, but there are a few important differences:
- *
- * 1. When acquiring the GIL from an non-main thread during the finalization
- *    phase, the GILState API blindly terminates the calling thread, which
- *    is often not what is wanted. This API does not do this.
- *
- * 2. The gil_scoped_release function can optionally cut the relationship
- *    of a PyThreadState and its associated thread, which allows moving it to
- *    another thread (this is a fairly rare/advanced use case).
- *
- * 3. The reference count of an acquired thread state can be controlled. This
- *    can be handy to prevent cases where callbacks issued from an external
- *    thread would otherwise constantly construct and destroy thread state data
- *    structures.
- *
- * See the Python bindings of NanoGUI (http://github.com/wjakob/nanogui) for an
- * example which uses features 2 and 3 to migrate the Python thread of
- * execution to another thread (to run the event loop on the original thread,
- * in this case).
- */
-
-class gil_scoped_acquire {
-public:
-    PYBIND11_NOINLINE gil_scoped_acquire() {
-        auto const &internals = detail::get_internals();
-        tstate = (PyThreadState *) PYBIND11_TLS_GET_VALUE(internals.tstate);
-
-        if (!tstate) {
-            /* Check if the GIL was acquired using the PyGILState_* API instead (e.g. if
-               calling from a Python thread). Since we use a different key, this ensures
-               we don't create a new thread state and deadlock in PyEval_AcquireThread
-               below. Note we don't save this state with internals.tstate, since we don't
-               create it we would fail to clear it (its reference count should be > 0). */
-            tstate = PyGILState_GetThisThreadState();
-        }
-
-        if (!tstate) {
-            tstate = PyThreadState_New(internals.istate);
-            #if !defined(NDEBUG)
-                if (!tstate)
-                    pybind11_fail("scoped_acquire: could not create thread state!");
-            #endif
-            tstate->gilstate_counter = 0;
-            PYBIND11_TLS_REPLACE_VALUE(internals.tstate, tstate);
-        } else {
-            release = detail::get_thread_state_unchecked() != tstate;
-        }
-
-        if (release) {
-            /* Work around an annoying assertion in PyThreadState_Swap */
-            #if defined(Py_DEBUG)
-                PyInterpreterState *interp = tstate->interp;
-                tstate->interp = nullptr;
-            #endif
-            PyEval_AcquireThread(tstate);
-            #if defined(Py_DEBUG)
-                tstate->interp = interp;
-            #endif
-        }
-
-        inc_ref();
-    }
-
-    void inc_ref() {
-        ++tstate->gilstate_counter;
-    }
-
-    PYBIND11_NOINLINE void dec_ref() {
-        --tstate->gilstate_counter;
-        #if !defined(NDEBUG)
-            if (detail::get_thread_state_unchecked() != tstate)
-                pybind11_fail("scoped_acquire::dec_ref(): thread state must be current!");
-            if (tstate->gilstate_counter < 0)
-                pybind11_fail("scoped_acquire::dec_ref(): reference count underflow!");
-        #endif
-        if (tstate->gilstate_counter == 0) {
-            #if !defined(NDEBUG)
-                if (!release)
-                    pybind11_fail("scoped_acquire::dec_ref(): internal error!");
-            #endif
-            PyThreadState_Clear(tstate);
-            PyThreadState_DeleteCurrent();
-            PYBIND11_TLS_DELETE_VALUE(detail::get_internals().tstate);
-            release = false;
-        }
-    }
-
-    PYBIND11_NOINLINE ~gil_scoped_acquire() {
-        dec_ref();
-        if (release)
-           PyEval_SaveThread();
-    }
-private:
-    PyThreadState *tstate = nullptr;
-    bool release = true;
-};
-
-class gil_scoped_release {
-public:
-    explicit gil_scoped_release(bool disassoc = false) : disassoc(disassoc) {
-        // `get_internals()` must be called here unconditionally in order to initialize
-        // `internals.tstate` for subsequent `gil_scoped_acquire` calls. Otherwise, an
-        // initialization race could occur as multiple threads try `gil_scoped_acquire`.
-        const auto &internals = detail::get_internals();
-        tstate = PyEval_SaveThread();
-        if (disassoc) {
-            auto key = internals.tstate;
-            PYBIND11_TLS_DELETE_VALUE(key);
-        }
-    }
-    ~gil_scoped_release() {
-        if (!tstate)
-            return;
-        PyEval_RestoreThread(tstate);
-        if (disassoc) {
-            auto key = detail::get_internals().tstate;
-            PYBIND11_TLS_REPLACE_VALUE(key, tstate);
-        }
-    }
-private:
-    PyThreadState *tstate;
-    bool disassoc;
-};
-#elif defined(PYPY_VERSION)
-class gil_scoped_acquire {
-    PyGILState_STATE state;
-public:
-    gil_scoped_acquire() { state = PyGILState_Ensure(); }
-    ~gil_scoped_acquire() { PyGILState_Release(state); }
-};
-
-class gil_scoped_release {
-    PyThreadState *state;
-public:
-    gil_scoped_release() { state = PyEval_SaveThread(); }
-    ~gil_scoped_release() { PyEval_RestoreThread(state); }
-};
-#else
-class gil_scoped_acquire { };
-class gil_scoped_release { };
-#endif
+inline void
+error_already_set::m_fetched_error_deleter(detail::error_fetch_and_normalize *raw_ptr) {
+    gil_scoped_acquire gil;
+    error_scope scope;
+    delete raw_ptr;
+}
 
-error_already_set::~error_already_set() {
-    if (m_type) {
-        gil_scoped_acquire gil;
-        error_scope scope;
-        m_type.release().dec_ref();
-        m_value.release().dec_ref();
-        m_trace.release().dec_ref();
-    }
+inline const char *error_already_set::what() const noexcept {
+    gil_scoped_acquire gil;
+    error_scope scope;
+    return m_fetched_error->error_string().c_str();
 }
 
-inline function get_type_overload(const void *this_ptr, const detail::type_info *this_type, const char *name)  {
-    handle self = detail::get_object_handle(this_ptr, this_type);
-    if (!self)
+PYBIND11_NAMESPACE_BEGIN(detail)
+
+inline function
+get_type_override(const void *this_ptr, const type_info *this_type, const char *name) {
+    handle self = get_object_handle(this_ptr, this_type);
+    if (!self) {
         return function();
-    handle type = self.get_type();
+    }
+    handle type = type::handle_of(self);
     auto key = std::make_pair(type.ptr(), name);
 
-    /* Cache functions that aren't overloaded in Python to avoid
+    /* Cache functions that aren't overridden in Python to avoid
        many costly Python dictionary lookups below */
-    auto &cache = detail::get_internals().inactive_overload_cache;
-    if (cache.find(key) != cache.end())
+    auto &cache = get_internals().inactive_override_cache;
+    if (cache.find(key) != cache.end()) {
         return function();
+    }
 
-    function overload = getattr(self, name, function());
-    if (overload.is_cpp_function()) {
-        cache.insert(key);
+    function override = getattr(self, name, function());
+    if (override.is_cpp_function()) {
+        cache.insert(std::move(key));
         return function();
     }
 
     /* Don't call dispatch code if invoked from overridden function.
        Unfortunately this doesn't work on PyPy. */
 #if !defined(PYPY_VERSION)
+#    if PY_VERSION_HEX >= 0x03090000
+    PyFrameObject *frame = PyThreadState_GetFrame(PyThreadState_Get());
+    if (frame != nullptr) {
+        PyCodeObject *f_code = PyFrame_GetCode(frame);
+        // f_code is guaranteed to not be NULL
+        if ((std::string) str(f_code->co_name) == name && f_code->co_argcount > 0) {
+            PyObject *locals = PyEval_GetLocals();
+            if (locals != nullptr) {
+                PyObject *co_varnames = PyObject_GetAttrString((PyObject *) f_code, "co_varnames");
+                PyObject *self_arg = PyTuple_GET_ITEM(co_varnames, 0);
+                Py_DECREF(co_varnames);
+                PyObject *self_caller = dict_getitem(locals, self_arg);
+                if (self_caller == self.ptr()) {
+                    Py_DECREF(f_code);
+                    Py_DECREF(frame);
+                    return function();
+                }
+            }
+        }
+        Py_DECREF(f_code);
+        Py_DECREF(frame);
+    }
+#    else
     PyFrameObject *frame = PyThreadState_Get()->frame;
-    if (frame && (std::string) str(frame->f_code->co_name) == name &&
-        frame->f_code->co_argcount > 0) {
+    if (frame != nullptr && (std::string) str(frame->f_code->co_name) == name
+        && frame->f_code->co_argcount > 0) {
         PyFrame_FastToLocals(frame);
-        PyObject *self_caller = PyDict_GetItem(
-            frame->f_locals, PyTuple_GET_ITEM(frame->f_code->co_varnames, 0));
-        if (self_caller == self.ptr())
+        PyObject *self_caller
+            = dict_getitem(frame->f_locals, PyTuple_GET_ITEM(frame->f_code->co_varnames, 0));
+        if (self_caller == self.ptr()) {
             return function();
+        }
     }
+#    endif
+
 #else
     /* PyPy currently doesn't provide a detailed cpyext emulation of
        frame objects, so we have to emulate this using Python. This
        is going to be slow..*/
-    dict d; d["self"] = self; d["name"] = pybind11::str(name);
-    PyObject *result = PyRun_String(
-        "import inspect\n"
-        "frame = inspect.currentframe()\n"
-        "if frame is not None:\n"
-        "    frame = frame.f_back\n"
-        "    if frame is not None and str(frame.f_code.co_name) == name and "
-        "frame.f_code.co_argcount > 0:\n"
-        "        self_caller = frame.f_locals[frame.f_code.co_varnames[0]]\n"
-        "        if self_caller == self:\n"
-        "            self = None\n",
-        Py_file_input, d.ptr(), d.ptr());
+    dict d;
+    d["self"] = self;
+    d["name"] = pybind11::str(name);
+    PyObject *result
+        = PyRun_String("import inspect\n"
+                       "frame = inspect.currentframe()\n"
+                       "if frame is not None:\n"
+                       "    frame = frame.f_back\n"
+                       "    if frame is not None and str(frame.f_code.co_name) == name and "
+                       "frame.f_code.co_argcount > 0:\n"
+                       "        self_caller = frame.f_locals[frame.f_code.co_varnames[0]]\n"
+                       "        if self_caller == self:\n"
+                       "            self = None\n",
+                       Py_file_input,
+                       d.ptr(),
+                       d.ptr());
     if (result == nullptr)
         throw error_already_set();
+    Py_DECREF(result);
     if (d["self"].is_none())
         return function();
-    Py_DECREF(result);
 #endif
 
-    return overload;
+    return override;
 }
+PYBIND11_NAMESPACE_END(detail)
 
 /** \rst
-  Try to retrieve a python method by the provided name from the instance pointed to by the this_ptr.
+  Try to retrieve a python method by the provided name from the instance pointed to by the
+  this_ptr.
 
-  :this_ptr: The pointer to the object the overload should be retrieved for. This should be the first
-                   non-trampoline class encountered in the inheritance chain.
-  :name: The name of the overloaded Python method to retrieve.
+  :this_ptr: The pointer to the object the overridden method should be retrieved for. This should
+             be the first non-trampoline class encountered in the inheritance chain.
+  :name: The name of the overridden Python method to retrieve.
   :return: The Python method by this name from the object or an empty function wrapper.
  \endrst */
-template <class T> function get_overload(const T *this_ptr, const char *name) {
-    auto tinfo = detail::get_type_info(typeid(T));
-    return tinfo ? get_type_overload(this_ptr, tinfo, name) : function();
-}
-
-#define PYBIND11_OVERLOAD_INT(ret_type, cname, name, ...) { \
-        pybind11::gil_scoped_acquire gil; \
-        pybind11::function overload = pybind11::get_overload(static_cast<const cname *>(this), name); \
-        if (overload) { \
-            auto o = overload(__VA_ARGS__); \
-            if (pybind11::detail::cast_is_temporary_value_reference<ret_type>::value) { \
-                static pybind11::detail::overload_caster_t<ret_type> caster; \
-                return pybind11::detail::cast_ref<ret_type>(std::move(o), caster); \
-            } \
-            else return pybind11::detail::cast_safe<ret_type>(std::move(o)); \
-        } \
-    }
+template <class T>
+function get_override(const T *this_ptr, const char *name) {
+    auto *tinfo = detail::get_type_info(typeid(T));
+    return tinfo ? detail::get_type_override(this_ptr, tinfo, name) : function();
+}
+
+#define PYBIND11_OVERRIDE_IMPL(ret_type, cname, name, ...)                                        \
+    do {                                                                                          \
+        pybind11::gil_scoped_acquire gil;                                                         \
+        pybind11::function override                                                               \
+            = pybind11::get_override(static_cast<const cname *>(this), name);                     \
+        if (override) {                                                                           \
+            auto o = override(__VA_ARGS__);                                                       \
+            if (pybind11::detail::cast_is_temporary_value_reference<ret_type>::value) {           \
+                static pybind11::detail::override_caster_t<ret_type> caster;                      \
+                return pybind11::detail::cast_ref<ret_type>(std::move(o), caster);                \
+            }                                                                                     \
+            return pybind11::detail::cast_safe<ret_type>(std::move(o));                           \
+        }                                                                                         \
+    } while (false)
 
 /** \rst
-    Macro to populate the virtual method in the trampoline class. This macro tries to look up a method named 'fn'
-    from the Python side, deals with the :ref:`gil` and necessary argument conversions to call this method and return
-    the appropriate type. See :ref:`overriding_virtuals` for more information. This macro should be used when the method
+    Macro to populate the virtual method in the trampoline class. This macro tries to look up a
+    method named 'fn' from the Python side, deals with the :ref:`gil` and necessary argument
+    conversions to call this method and return the appropriate type.
+    See :ref:`overriding_virtuals` for more information. This macro should be used when the method
     name in C is not the same as the method name in Python. For example with `__str__`.
 
     .. code-block:: cpp
 
       std::string toString() override {
-        PYBIND11_OVERLOAD_NAME(
+        PYBIND11_OVERRIDE_NAME(
             std::string, // Return type (ret_type)
             Animal,      // Parent class (cname)
-            toString,    // Name of function in C++ (name)
-            "__str__",   // Name of method in Python (fn)
+            "__str__",   // Name of method in Python (name)
+            toString,    // Name of function in C++ (fn)
         );
       }
 \endrst */
-#define PYBIND11_OVERLOAD_NAME(ret_type, cname, name, fn, ...) \
-    PYBIND11_OVERLOAD_INT(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, __VA_ARGS__) \
-    return cname::fn(__VA_ARGS__)
+#define PYBIND11_OVERRIDE_NAME(ret_type, cname, name, fn, ...)                                    \
+    do {                                                                                          \
+        PYBIND11_OVERRIDE_IMPL(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, __VA_ARGS__); \
+        return cname::fn(__VA_ARGS__);                                                            \
+    } while (false)
 
 /** \rst
-    Macro for pure virtual functions, this function is identical to :c:macro:`PYBIND11_OVERLOAD_NAME`, except that it
-    throws if no overload can be found.
+    Macro for pure virtual functions, this function is identical to
+    :c:macro:`PYBIND11_OVERRIDE_NAME`, except that it throws if no override can be found.
 \endrst */
-#define PYBIND11_OVERLOAD_PURE_NAME(ret_type, cname, name, fn, ...) \
-    PYBIND11_OVERLOAD_INT(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, __VA_ARGS__) \
-    pybind11::pybind11_fail("Tried to call pure virtual function \"" PYBIND11_STRINGIFY(cname) "::" name "\"");
+#define PYBIND11_OVERRIDE_PURE_NAME(ret_type, cname, name, fn, ...)                               \
+    do {                                                                                          \
+        PYBIND11_OVERRIDE_IMPL(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, __VA_ARGS__); \
+        pybind11::pybind11_fail(                                                                  \
+            "Tried to call pure virtual function \"" PYBIND11_STRINGIFY(cname) "::" name "\"");   \
+    } while (false)
 
 /** \rst
-    Macro to populate the virtual method in the trampoline class. This macro tries to look up the method
-    from the Python side, deals with the :ref:`gil` and necessary argument conversions to call this method and return
-    the appropriate type. This macro should be used if the method name in C and in Python are identical.
+    Macro to populate the virtual method in the trampoline class. This macro tries to look up the
+    method from the Python side, deals with the :ref:`gil` and necessary argument conversions to
+    call this method and return the appropriate type. This macro should be used if the method name
+    in C and in Python are identical.
     See :ref:`overriding_virtuals` for more information.
 
     .. code-block:: cpp
 
       class PyAnimal : public Animal {
       public:
           // Inherit the constructors
           using Animal::Animal;
 
           // Trampoline (need one for each virtual function)
           std::string go(int n_times) override {
-              PYBIND11_OVERLOAD_PURE(
+              PYBIND11_OVERRIDE_PURE(
                   std::string, // Return type (ret_type)
                   Animal,      // Parent class (cname)
                   go,          // Name of function in C++ (must match Python name) (fn)
                   n_times      // Argument(s) (...)
               );
           }
       };
 \endrst */
-#define PYBIND11_OVERLOAD(ret_type, cname, fn, ...) \
-    PYBIND11_OVERLOAD_NAME(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), #fn, fn, __VA_ARGS__)
+#define PYBIND11_OVERRIDE(ret_type, cname, fn, ...)                                               \
+    PYBIND11_OVERRIDE_NAME(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), #fn, fn, __VA_ARGS__)
 
 /** \rst
-    Macro for pure virtual functions, this function is identical to :c:macro:`PYBIND11_OVERLOAD`, except that it throws
-    if no overload can be found.
+    Macro for pure virtual functions, this function is identical to :c:macro:`PYBIND11_OVERRIDE`,
+    except that it throws if no override can be found.
 \endrst */
-#define PYBIND11_OVERLOAD_PURE(ret_type, cname, fn, ...) \
-    PYBIND11_OVERLOAD_PURE_NAME(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), #fn, fn, __VA_ARGS__)
-
-NAMESPACE_END(PYBIND11_NAMESPACE)
+#define PYBIND11_OVERRIDE_PURE(ret_type, cname, fn, ...)                                          \
+    PYBIND11_OVERRIDE_PURE_NAME(                                                                  \
+        PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), #fn, fn, __VA_ARGS__)
+
+// Deprecated versions
+
+PYBIND11_DEPRECATED("get_type_overload has been deprecated")
+inline function
+get_type_overload(const void *this_ptr, const detail::type_info *this_type, const char *name) {
+    return detail::get_type_override(this_ptr, this_type, name);
+}
+
+template <class T>
+inline function get_overload(const T *this_ptr, const char *name) {
+    return get_override(this_ptr, name);
+}
+
+#define PYBIND11_OVERLOAD_INT(ret_type, cname, name, ...)                                         \
+    PYBIND11_OVERRIDE_IMPL(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, __VA_ARGS__)
+#define PYBIND11_OVERLOAD_NAME(ret_type, cname, name, fn, ...)                                    \
+    PYBIND11_OVERRIDE_NAME(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, fn, __VA_ARGS__)
+#define PYBIND11_OVERLOAD_PURE_NAME(ret_type, cname, name, fn, ...)                               \
+    PYBIND11_OVERRIDE_PURE_NAME(                                                                  \
+        PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), name, fn, __VA_ARGS__);
+#define PYBIND11_OVERLOAD(ret_type, cname, fn, ...)                                               \
+    PYBIND11_OVERRIDE(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), fn, __VA_ARGS__)
+#define PYBIND11_OVERLOAD_PURE(ret_type, cname, fn, ...)                                          \
+    PYBIND11_OVERRIDE_PURE(PYBIND11_TYPE(ret_type), PYBIND11_TYPE(cname), fn, __VA_ARGS__);
 
-#if defined(_MSC_VER) && !defined(__INTEL_COMPILER)
-#  pragma warning(pop)
-#elif defined(__GNUG__) && !defined(__clang__)
-#  pragma GCC diagnostic pop
-#endif
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/stl.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/stl.h`

 * *Files 7% similar despite different names*

```diff
@@ -6,117 +6,133 @@
     All rights reserved. Use of this source code is governed by a
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
 #include "pybind11.h"
-#include <set>
-#include <unordered_set>
+#include "detail/common.h"
+
+#include <deque>
+#include <list>
 #include <map>
+#include <ostream>
+#include <set>
 #include <unordered_map>
-#include <iostream>
-#include <list>
-#include <deque>
+#include <unordered_set>
 #include <valarray>
 
-#if defined(_MSC_VER)
-#pragma warning(push)
-#pragma warning(disable: 4127) // warning C4127: Conditional expression is constant
-#endif
-
-#ifdef __has_include
-// std::optional (but including it in c++14 mode isn't allowed)
-#  if defined(PYBIND11_CPP17) && __has_include(<optional>)
+// See `detail/common.h` for implementation of these guards.
+#if defined(PYBIND11_HAS_OPTIONAL)
 #    include <optional>
-#    define PYBIND11_HAS_OPTIONAL 1
-#  endif
-// std::experimental::optional (but not allowed in c++11 mode)
-#  if defined(PYBIND11_CPP14) && (__has_include(<experimental/optional>) && \
-                                 !__has_include(<optional>))
+#elif defined(PYBIND11_HAS_EXP_OPTIONAL)
 #    include <experimental/optional>
-#    define PYBIND11_HAS_EXP_OPTIONAL 1
-#  endif
-// std::variant
-#  if defined(PYBIND11_CPP17) && __has_include(<variant>)
+#endif
+
+#if defined(PYBIND11_HAS_VARIANT)
 #    include <variant>
-#    define PYBIND11_HAS_VARIANT 1
-#  endif
-#elif defined(_MSC_VER) && defined(PYBIND11_CPP17)
-#  include <optional>
-#  include <variant>
-#  define PYBIND11_HAS_OPTIONAL 1
-#  define PYBIND11_HAS_VARIANT 1
 #endif
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
 /// Extracts an const lvalue reference or rvalue reference for U based on the type of T (e.g. for
 /// forwarding a container element).  Typically used indirect via forwarded_type(), below.
 template <typename T, typename U>
-using forwarded_type = conditional_t<
-    std::is_lvalue_reference<T>::value, remove_reference_t<U> &, remove_reference_t<U> &&>;
+using forwarded_type = conditional_t<std::is_lvalue_reference<T>::value,
+                                     remove_reference_t<U> &,
+                                     remove_reference_t<U> &&>;
 
 /// Forwards a value U as rvalue or lvalue according to whether T is rvalue or lvalue; typically
 /// used for forwarding a container's elements.
 template <typename T, typename U>
-forwarded_type<T, U> forward_like(U &&u) {
+constexpr forwarded_type<T, U> forward_like(U &&u) {
     return std::forward<detail::forwarded_type<T, U>>(std::forward<U>(u));
 }
 
-template <typename Type, typename Key> struct set_caster {
+// Checks if a container has a STL style reserve method.
+// This will only return true for a `reserve()` with a `void` return.
+template <typename C>
+using has_reserve_method = std::is_same<decltype(std::declval<C>().reserve(0)), void>;
+
+template <typename Type, typename Key>
+struct set_caster {
     using type = Type;
     using key_conv = make_caster<Key>;
 
+private:
+    template <typename T = Type, enable_if_t<has_reserve_method<T>::value, int> = 0>
+    void reserve_maybe(const anyset &s, Type *) {
+        value.reserve(s.size());
+    }
+    void reserve_maybe(const anyset &, void *) {}
+
+public:
     bool load(handle src, bool convert) {
-        if (!isinstance<pybind11::set>(src))
+        if (!isinstance<anyset>(src)) {
             return false;
-        auto s = reinterpret_borrow<pybind11::set>(src);
+        }
+        auto s = reinterpret_borrow<anyset>(src);
         value.clear();
+        reserve_maybe(s, &value);
         for (auto entry : s) {
             key_conv conv;
-            if (!conv.load(entry, convert))
+            if (!conv.load(entry, convert)) {
                 return false;
+            }
             value.insert(cast_op<Key &&>(std::move(conv)));
         }
         return true;
     }
 
     template <typename T>
     static handle cast(T &&src, return_value_policy policy, handle parent) {
-        if (!std::is_lvalue_reference<T>::value)
+        if (!std::is_lvalue_reference<T>::value) {
             policy = return_value_policy_override<Key>::policy(policy);
+        }
         pybind11::set s;
         for (auto &&value : src) {
-            auto value_ = reinterpret_steal<object>(key_conv::cast(forward_like<T>(value), policy, parent));
-            if (!value_ || !s.add(value_))
+            auto value_ = reinterpret_steal<object>(
+                key_conv::cast(detail::forward_like<T>(value), policy, parent));
+            if (!value_ || !s.add(std::move(value_))) {
                 return handle();
+            }
         }
         return s.release();
     }
 
-    PYBIND11_TYPE_CASTER(type, _("Set[") + key_conv::name + _("]"));
+    PYBIND11_TYPE_CASTER(type, const_name("Set[") + key_conv::name + const_name("]"));
 };
 
-template <typename Type, typename Key, typename Value> struct map_caster {
-    using key_conv   = make_caster<Key>;
+template <typename Type, typename Key, typename Value>
+struct map_caster {
+    using key_conv = make_caster<Key>;
     using value_conv = make_caster<Value>;
 
+private:
+    template <typename T = Type, enable_if_t<has_reserve_method<T>::value, int> = 0>
+    void reserve_maybe(const dict &d, Type *) {
+        value.reserve(d.size());
+    }
+    void reserve_maybe(const dict &, void *) {}
+
+public:
     bool load(handle src, bool convert) {
-        if (!isinstance<dict>(src))
+        if (!isinstance<dict>(src)) {
             return false;
+        }
         auto d = reinterpret_borrow<dict>(src);
         value.clear();
+        reserve_maybe(d, &value);
         for (auto it : d) {
             key_conv kconv;
             value_conv vconv;
-            if (!kconv.load(it.first.ptr(), convert) ||
-                !vconv.load(it.second.ptr(), convert))
+            if (!kconv.load(it.first.ptr(), convert) || !vconv.load(it.second.ptr(), convert)) {
                 return false;
+            }
             value.emplace(cast_op<Key &&>(std::move(kconv)), cast_op<Value &&>(std::move(vconv)));
         }
         return true;
     }
 
     template <typename T>
     static handle cast(T &&src, return_value_policy policy, handle parent) {
@@ -124,186 +140,223 @@
         return_value_policy policy_key = policy;
         return_value_policy policy_value = policy;
         if (!std::is_lvalue_reference<T>::value) {
             policy_key = return_value_policy_override<Key>::policy(policy_key);
             policy_value = return_value_policy_override<Value>::policy(policy_value);
         }
         for (auto &&kv : src) {
-            auto key = reinterpret_steal<object>(key_conv::cast(forward_like<T>(kv.first), policy_key, parent));
-            auto value = reinterpret_steal<object>(value_conv::cast(forward_like<T>(kv.second), policy_value, parent));
-            if (!key || !value)
+            auto key = reinterpret_steal<object>(
+                key_conv::cast(detail::forward_like<T>(kv.first), policy_key, parent));
+            auto value = reinterpret_steal<object>(
+                value_conv::cast(detail::forward_like<T>(kv.second), policy_value, parent));
+            if (!key || !value) {
                 return handle();
-            d[key] = value;
+            }
+            d[std::move(key)] = std::move(value);
         }
         return d.release();
     }
 
-    PYBIND11_TYPE_CASTER(Type, _("Dict[") + key_conv::name + _(", ") + value_conv::name + _("]"));
+    PYBIND11_TYPE_CASTER(Type,
+                         const_name("Dict[") + key_conv::name + const_name(", ") + value_conv::name
+                             + const_name("]"));
 };
 
-template <typename Type, typename Value> struct list_caster {
+template <typename Type, typename Value>
+struct list_caster {
     using value_conv = make_caster<Value>;
 
     bool load(handle src, bool convert) {
-        if (!isinstance<sequence>(src) || isinstance<str>(src))
+        if (!isinstance<sequence>(src) || isinstance<bytes>(src) || isinstance<str>(src)) {
             return false;
+        }
         auto s = reinterpret_borrow<sequence>(src);
         value.clear();
         reserve_maybe(s, &value);
         for (auto it : s) {
             value_conv conv;
-            if (!conv.load(it, convert))
+            if (!conv.load(it, convert)) {
                 return false;
+            }
             value.push_back(cast_op<Value &&>(std::move(conv)));
         }
         return true;
     }
 
 private:
-    template <typename T = Type,
-              enable_if_t<std::is_same<decltype(std::declval<T>().reserve(0)), void>::value, int> = 0>
-    void reserve_maybe(sequence s, Type *) { value.reserve(s.size()); }
-    void reserve_maybe(sequence, void *) { }
+    template <typename T = Type, enable_if_t<has_reserve_method<T>::value, int> = 0>
+    void reserve_maybe(const sequence &s, Type *) {
+        value.reserve(s.size());
+    }
+    void reserve_maybe(const sequence &, void *) {}
 
 public:
     template <typename T>
     static handle cast(T &&src, return_value_policy policy, handle parent) {
-        if (!std::is_lvalue_reference<T>::value)
+        if (!std::is_lvalue_reference<T>::value) {
             policy = return_value_policy_override<Value>::policy(policy);
+        }
         list l(src.size());
-        size_t index = 0;
+        ssize_t index = 0;
         for (auto &&value : src) {
-            auto value_ = reinterpret_steal<object>(value_conv::cast(forward_like<T>(value), policy, parent));
-            if (!value_)
+            auto value_ = reinterpret_steal<object>(
+                value_conv::cast(detail::forward_like<T>(value), policy, parent));
+            if (!value_) {
                 return handle();
-            PyList_SET_ITEM(l.ptr(), (ssize_t) index++, value_.release().ptr()); // steals a reference
+            }
+            PyList_SET_ITEM(l.ptr(), index++, value_.release().ptr()); // steals a reference
         }
         return l.release();
     }
 
-    PYBIND11_TYPE_CASTER(Type, _("List[") + value_conv::name + _("]"));
+    PYBIND11_TYPE_CASTER(Type, const_name("List[") + value_conv::name + const_name("]"));
 };
 
-template <typename Type, typename Alloc> struct type_caster<std::vector<Type, Alloc>>
- : list_caster<std::vector<Type, Alloc>, Type> { };
+template <typename Type, typename Alloc>
+struct type_caster<std::vector<Type, Alloc>> : list_caster<std::vector<Type, Alloc>, Type> {};
 
-template <typename Type, typename Alloc> struct type_caster<std::deque<Type, Alloc>>
- : list_caster<std::deque<Type, Alloc>, Type> { };
+template <typename Type, typename Alloc>
+struct type_caster<std::deque<Type, Alloc>> : list_caster<std::deque<Type, Alloc>, Type> {};
 
-template <typename Type, typename Alloc> struct type_caster<std::list<Type, Alloc>>
- : list_caster<std::list<Type, Alloc>, Type> { };
+template <typename Type, typename Alloc>
+struct type_caster<std::list<Type, Alloc>> : list_caster<std::list<Type, Alloc>, Type> {};
 
-template <typename ArrayType, typename Value, bool Resizable, size_t Size = 0> struct array_caster {
+template <typename ArrayType, typename Value, bool Resizable, size_t Size = 0>
+struct array_caster {
     using value_conv = make_caster<Value>;
 
 private:
     template <bool R = Resizable>
     bool require_size(enable_if_t<R, size_t> size) {
-        if (value.size() != size)
+        if (value.size() != size) {
             value.resize(size);
+        }
         return true;
     }
     template <bool R = Resizable>
     bool require_size(enable_if_t<!R, size_t> size) {
         return size == Size;
     }
 
 public:
     bool load(handle src, bool convert) {
-        if (!isinstance<sequence>(src))
+        if (!isinstance<sequence>(src)) {
             return false;
+        }
         auto l = reinterpret_borrow<sequence>(src);
-        if (!require_size(l.size()))
+        if (!require_size(l.size())) {
             return false;
+        }
         size_t ctr = 0;
         for (auto it : l) {
             value_conv conv;
-            if (!conv.load(it, convert))
+            if (!conv.load(it, convert)) {
                 return false;
+            }
             value[ctr++] = cast_op<Value &&>(std::move(conv));
         }
         return true;
     }
 
     template <typename T>
     static handle cast(T &&src, return_value_policy policy, handle parent) {
         list l(src.size());
-        size_t index = 0;
+        ssize_t index = 0;
         for (auto &&value : src) {
-            auto value_ = reinterpret_steal<object>(value_conv::cast(forward_like<T>(value), policy, parent));
-            if (!value_)
+            auto value_ = reinterpret_steal<object>(
+                value_conv::cast(detail::forward_like<T>(value), policy, parent));
+            if (!value_) {
                 return handle();
-            PyList_SET_ITEM(l.ptr(), (ssize_t) index++, value_.release().ptr()); // steals a reference
+            }
+            PyList_SET_ITEM(l.ptr(), index++, value_.release().ptr()); // steals a reference
         }
         return l.release();
     }
 
-    PYBIND11_TYPE_CASTER(ArrayType, _("List[") + value_conv::name + _<Resizable>(_(""), _("[") + _<Size>() + _("]")) + _("]"));
+    PYBIND11_TYPE_CASTER(ArrayType,
+                         const_name("List[") + value_conv::name
+                             + const_name<Resizable>(const_name(""),
+                                                     const_name("[") + const_name<Size>()
+                                                         + const_name("]"))
+                             + const_name("]"));
 };
 
-template <typename Type, size_t Size> struct type_caster<std::array<Type, Size>>
- : array_caster<std::array<Type, Size>, Type, false, Size> { };
-
-template <typename Type> struct type_caster<std::valarray<Type>>
- : array_caster<std::valarray<Type>, Type, true> { };
-
-template <typename Key, typename Compare, typename Alloc> struct type_caster<std::set<Key, Compare, Alloc>>
-  : set_caster<std::set<Key, Compare, Alloc>, Key> { };
-
-template <typename Key, typename Hash, typename Equal, typename Alloc> struct type_caster<std::unordered_set<Key, Hash, Equal, Alloc>>
-  : set_caster<std::unordered_set<Key, Hash, Equal, Alloc>, Key> { };
-
-template <typename Key, typename Value, typename Compare, typename Alloc> struct type_caster<std::map<Key, Value, Compare, Alloc>>
-  : map_caster<std::map<Key, Value, Compare, Alloc>, Key, Value> { };
-
-template <typename Key, typename Value, typename Hash, typename Equal, typename Alloc> struct type_caster<std::unordered_map<Key, Value, Hash, Equal, Alloc>>
-  : map_caster<std::unordered_map<Key, Value, Hash, Equal, Alloc>, Key, Value> { };
+template <typename Type, size_t Size>
+struct type_caster<std::array<Type, Size>>
+    : array_caster<std::array<Type, Size>, Type, false, Size> {};
+
+template <typename Type>
+struct type_caster<std::valarray<Type>> : array_caster<std::valarray<Type>, Type, true> {};
+
+template <typename Key, typename Compare, typename Alloc>
+struct type_caster<std::set<Key, Compare, Alloc>>
+    : set_caster<std::set<Key, Compare, Alloc>, Key> {};
+
+template <typename Key, typename Hash, typename Equal, typename Alloc>
+struct type_caster<std::unordered_set<Key, Hash, Equal, Alloc>>
+    : set_caster<std::unordered_set<Key, Hash, Equal, Alloc>, Key> {};
+
+template <typename Key, typename Value, typename Compare, typename Alloc>
+struct type_caster<std::map<Key, Value, Compare, Alloc>>
+    : map_caster<std::map<Key, Value, Compare, Alloc>, Key, Value> {};
+
+template <typename Key, typename Value, typename Hash, typename Equal, typename Alloc>
+struct type_caster<std::unordered_map<Key, Value, Hash, Equal, Alloc>>
+    : map_caster<std::unordered_map<Key, Value, Hash, Equal, Alloc>, Key, Value> {};
 
 // This type caster is intended to be used for std::optional and std::experimental::optional
-template<typename T> struct optional_caster {
-    using value_conv = make_caster<typename T::value_type>;
+template <typename Type, typename Value = typename Type::value_type>
+struct optional_caster {
+    using value_conv = make_caster<Value>;
 
-    template <typename T_>
-    static handle cast(T_ &&src, return_value_policy policy, handle parent) {
-        if (!src)
-            return none().inc_ref();
-        policy = return_value_policy_override<typename T::value_type>::policy(policy);
-        return value_conv::cast(*std::forward<T_>(src), policy, parent);
+    template <typename T>
+    static handle cast(T &&src, return_value_policy policy, handle parent) {
+        if (!src) {
+            return none().release();
+        }
+        if (!std::is_lvalue_reference<T>::value) {
+            policy = return_value_policy_override<Value>::policy(policy);
+        }
+        return value_conv::cast(*std::forward<T>(src), policy, parent);
     }
 
     bool load(handle src, bool convert) {
         if (!src) {
             return false;
-        } else if (src.is_none()) {
-            return true;  // default-constructed value is already empty
+        }
+        if (src.is_none()) {
+            return true; // default-constructed value is already empty
         }
         value_conv inner_caster;
-        if (!inner_caster.load(src, convert))
+        if (!inner_caster.load(src, convert)) {
             return false;
+        }
 
-        value.emplace(cast_op<typename T::value_type &&>(std::move(inner_caster)));
+        value.emplace(cast_op<Value &&>(std::move(inner_caster)));
         return true;
     }
 
-    PYBIND11_TYPE_CASTER(T, _("Optional[") + value_conv::name + _("]"));
+    PYBIND11_TYPE_CASTER(Type, const_name("Optional[") + value_conv::name + const_name("]"));
 };
 
-#if PYBIND11_HAS_OPTIONAL
-template<typename T> struct type_caster<std::optional<T>>
-    : public optional_caster<std::optional<T>> {};
+#if defined(PYBIND11_HAS_OPTIONAL)
+template <typename T>
+struct type_caster<std::optional<T>> : public optional_caster<std::optional<T>> {};
 
-template<> struct type_caster<std::nullopt_t>
-    : public void_caster<std::nullopt_t> {};
+template <>
+struct type_caster<std::nullopt_t> : public void_caster<std::nullopt_t> {};
 #endif
 
-#if PYBIND11_HAS_EXP_OPTIONAL
-template<typename T> struct type_caster<std::experimental::optional<T>>
+#if defined(PYBIND11_HAS_EXP_OPTIONAL)
+template <typename T>
+struct type_caster<std::experimental::optional<T>>
     : public optional_caster<std::experimental::optional<T>> {};
 
-template<> struct type_caster<std::experimental::nullopt_t>
+template <>
+struct type_caster<std::experimental::nullopt_t>
     : public void_caster<std::experimental::nullopt_t> {};
 #endif
 
 /// Visit a variant and cast any found type to Python
 struct variant_caster_visitor {
     return_value_policy policy;
     handle parent;
@@ -316,71 +369,78 @@
     }
 };
 
 /// Helper class which abstracts away variant's `visit` function. `std::variant` and similar
 /// `namespace::variant` types which provide a `namespace::visit()` function are handled here
 /// automatically using argument-dependent lookup. Users can provide specializations for other
 /// variant-like classes, e.g. `boost::variant` and `boost::apply_visitor`.
-template <template<typename...> class Variant>
+template <template <typename...> class Variant>
 struct visit_helper {
     template <typename... Args>
     static auto call(Args &&...args) -> decltype(visit(std::forward<Args>(args)...)) {
         return visit(std::forward<Args>(args)...);
     }
 };
 
 /// Generic variant caster
-template <typename Variant> struct variant_caster;
+template <typename Variant>
+struct variant_caster;
 
-template <template<typename...> class V, typename... Ts>
+template <template <typename...> class V, typename... Ts>
 struct variant_caster<V<Ts...>> {
     static_assert(sizeof...(Ts) > 0, "Variant must consist of at least one alternative.");
 
     template <typename U, typename... Us>
     bool load_alternative(handle src, bool convert, type_list<U, Us...>) {
         auto caster = make_caster<U>();
         if (caster.load(src, convert)) {
-            value = cast_op<U>(caster);
+            value = cast_op<U>(std::move(caster));
             return true;
         }
         return load_alternative(src, convert, type_list<Us...>{});
     }
 
     bool load_alternative(handle, bool, type_list<>) { return false; }
 
     bool load(handle src, bool convert) {
         // Do a first pass without conversions to improve constructor resolution.
         // E.g. `py::int_(1).cast<variant<double, int>>()` needs to fill the `int`
         // slot of the variant. Without two-pass loading `double` would be filled
         // because it appears first and a conversion is possible.
-        if (convert && load_alternative(src, false, type_list<Ts...>{}))
+        if (convert && load_alternative(src, false, type_list<Ts...>{})) {
             return true;
+        }
         return load_alternative(src, convert, type_list<Ts...>{});
     }
 
     template <typename Variant>
     static handle cast(Variant &&src, return_value_policy policy, handle parent) {
         return visit_helper<V>::call(variant_caster_visitor{policy, parent},
                                      std::forward<Variant>(src));
     }
 
     using Type = V<Ts...>;
-    PYBIND11_TYPE_CASTER(Type, _("Union[") + detail::concat(make_caster<Ts>::name...) + _("]"));
+    PYBIND11_TYPE_CASTER(Type,
+                         const_name("Union[") + detail::concat(make_caster<Ts>::name...)
+                             + const_name("]"));
 };
 
-#if PYBIND11_HAS_VARIANT
+#if defined(PYBIND11_HAS_VARIANT)
 template <typename... Ts>
-struct type_caster<std::variant<Ts...>> : variant_caster<std::variant<Ts...>> { };
+struct type_caster<std::variant<Ts...>> : variant_caster<std::variant<Ts...>> {};
+
+template <>
+struct type_caster<std::monostate> : public void_caster<std::monostate> {};
 #endif
 
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
 
 inline std::ostream &operator<<(std::ostream &os, const handle &obj) {
+#ifdef PYBIND11_HAS_STRING_VIEW
+    os << str(obj).cast<std::string_view>();
+#else
     os << (std::string) str(obj);
+#endif
     return os;
 }
 
-NAMESPACE_END(PYBIND11_NAMESPACE)
-
-#if defined(_MSC_VER)
-#pragma warning(pop)
-#endif
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/include/pybind11/stl_bind.h` & `affine_transform-0.3.0/extern/pybind11/include/pybind11/stl_bind.h`

 * *Files 19% similar despite different names*

```diff
@@ -6,404 +6,494 @@
     All rights reserved. Use of this source code is governed by a
     BSD-style license that can be found in the LICENSE file.
 */
 
 #pragma once
 
 #include "detail/common.h"
+#include "detail/type_caster_base.h"
+#include "cast.h"
 #include "operators.h"
 
 #include <algorithm>
 #include <sstream>
+#include <type_traits>
 
-NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
 /* SFINAE helper class used by 'is_comparable */
-template <typename T>  struct container_traits {
-    template <typename T2> static std::true_type test_comparable(decltype(std::declval<const T2 &>() == std::declval<const T2 &>())*);
-    template <typename T2> static std::false_type test_comparable(...);
-    template <typename T2> static std::true_type test_value(typename T2::value_type *);
-    template <typename T2> static std::false_type test_value(...);
-    template <typename T2> static std::true_type test_pair(typename T2::first_type *, typename T2::second_type *);
-    template <typename T2> static std::false_type test_pair(...);
-
-    static constexpr const bool is_comparable = std::is_same<std::true_type, decltype(test_comparable<T>(nullptr))>::value;
-    static constexpr const bool is_pair = std::is_same<std::true_type, decltype(test_pair<T>(nullptr, nullptr))>::value;
-    static constexpr const bool is_vector = std::is_same<std::true_type, decltype(test_value<T>(nullptr))>::value;
+template <typename T>
+struct container_traits {
+    template <typename T2>
+    static std::true_type
+    test_comparable(decltype(std::declval<const T2 &>() == std::declval<const T2 &>()) *);
+    template <typename T2>
+    static std::false_type test_comparable(...);
+    template <typename T2>
+    static std::true_type test_value(typename T2::value_type *);
+    template <typename T2>
+    static std::false_type test_value(...);
+    template <typename T2>
+    static std::true_type test_pair(typename T2::first_type *, typename T2::second_type *);
+    template <typename T2>
+    static std::false_type test_pair(...);
+
+    static constexpr const bool is_comparable
+        = std::is_same<std::true_type, decltype(test_comparable<T>(nullptr))>::value;
+    static constexpr const bool is_pair
+        = std::is_same<std::true_type, decltype(test_pair<T>(nullptr, nullptr))>::value;
+    static constexpr const bool is_vector
+        = std::is_same<std::true_type, decltype(test_value<T>(nullptr))>::value;
     static constexpr const bool is_element = !is_pair && !is_vector;
 };
 
 /* Default: is_comparable -> std::false_type */
 template <typename T, typename SFINAE = void>
-struct is_comparable : std::false_type { };
+struct is_comparable : std::false_type {};
 
 /* For non-map data structures, check whether operator== can be instantiated */
 template <typename T>
 struct is_comparable<
-    T, enable_if_t<container_traits<T>::is_element &&
-                   container_traits<T>::is_comparable>>
-    : std::true_type { };
+    T,
+    enable_if_t<container_traits<T>::is_element && container_traits<T>::is_comparable>>
+    : std::true_type {};
 
-/* For a vector/map data structure, recursively check the value type (which is std::pair for maps) */
+/* For a vector/map data structure, recursively check the value type
+   (which is std::pair for maps) */
 template <typename T>
 struct is_comparable<T, enable_if_t<container_traits<T>::is_vector>> {
-    static constexpr const bool value =
-        is_comparable<typename T::value_type>::value;
+    static constexpr const bool value = is_comparable<typename T::value_type>::value;
 };
 
 /* For pairs, recursively check the two data types */
 template <typename T>
 struct is_comparable<T, enable_if_t<container_traits<T>::is_pair>> {
-    static constexpr const bool value =
-        is_comparable<typename T::first_type>::value &&
-        is_comparable<typename T::second_type>::value;
+    static constexpr const bool value = is_comparable<typename T::first_type>::value
+                                        && is_comparable<typename T::second_type>::value;
 };
 
 /* Fallback functions */
-template <typename, typename, typename... Args> void vector_if_copy_constructible(const Args &...) { }
-template <typename, typename, typename... Args> void vector_if_equal_operator(const Args &...) { }
-template <typename, typename, typename... Args> void vector_if_insertion_operator(const Args &...) { }
-template <typename, typename, typename... Args> void vector_modifiers(const Args &...) { }
+template <typename, typename, typename... Args>
+void vector_if_copy_constructible(const Args &...) {}
+template <typename, typename, typename... Args>
+void vector_if_equal_operator(const Args &...) {}
+template <typename, typename, typename... Args>
+void vector_if_insertion_operator(const Args &...) {}
+template <typename, typename, typename... Args>
+void vector_modifiers(const Args &...) {}
 
-template<typename Vector, typename Class_>
+template <typename Vector, typename Class_>
 void vector_if_copy_constructible(enable_if_t<is_copy_constructible<Vector>::value, Class_> &cl) {
     cl.def(init<const Vector &>(), "Copy constructor");
 }
 
-template<typename Vector, typename Class_>
+template <typename Vector, typename Class_>
 void vector_if_equal_operator(enable_if_t<is_comparable<Vector>::value, Class_> &cl) {
     using T = typename Vector::value_type;
 
     cl.def(self == self);
     cl.def(self != self);
 
-    cl.def("count",
-        [](const Vector &v, const T &x) {
-            return std::count(v.begin(), v.end(), x);
-        },
+    cl.def(
+        "count",
+        [](const Vector &v, const T &x) { return std::count(v.begin(), v.end(), x); },
         arg("x"),
-        "Return the number of times ``x`` appears in the list"
-    );
+        "Return the number of times ``x`` appears in the list");
 
-    cl.def("remove", [](Vector &v, const T &x) {
+    cl.def(
+        "remove",
+        [](Vector &v, const T &x) {
             auto p = std::find(v.begin(), v.end(), x);
-            if (p != v.end())
+            if (p != v.end()) {
                 v.erase(p);
-            else
+            } else {
                 throw value_error();
+            }
         },
         arg("x"),
         "Remove the first item from the list whose value is x. "
-        "It is an error if there is no such item."
-    );
+        "It is an error if there is no such item.");
 
-    cl.def("__contains__",
-        [](const Vector &v, const T &x) {
-            return std::find(v.begin(), v.end(), x) != v.end();
-        },
+    cl.def(
+        "__contains__",
+        [](const Vector &v, const T &x) { return std::find(v.begin(), v.end(), x) != v.end(); },
         arg("x"),
-        "Return true the container contains ``x``"
-    );
+        "Return true the container contains ``x``");
 }
 
 // Vector modifiers -- requires a copyable vector_type:
-// (Technically, some of these (pop and __delitem__) don't actually require copyability, but it seems
-// silly to allow deletion but not insertion, so include them here too.)
+// (Technically, some of these (pop and __delitem__) don't actually require copyability, but it
+// seems silly to allow deletion but not insertion, so include them here too.)
 template <typename Vector, typename Class_>
-void vector_modifiers(enable_if_t<is_copy_constructible<typename Vector::value_type>::value, Class_> &cl) {
+void vector_modifiers(
+    enable_if_t<is_copy_constructible<typename Vector::value_type>::value, Class_> &cl) {
     using T = typename Vector::value_type;
     using SizeType = typename Vector::size_type;
     using DiffType = typename Vector::difference_type;
 
-    cl.def("append",
-           [](Vector &v, const T &value) { v.push_back(value); },
-           arg("x"),
-           "Add an item to the end of the list");
+    auto wrap_i = [](DiffType i, SizeType n) {
+        if (i < 0) {
+            i += n;
+        }
+        if (i < 0 || (SizeType) i >= n) {
+            throw index_error();
+        }
+        return i;
+    };
+
+    cl.def(
+        "append",
+        [](Vector &v, const T &value) { v.push_back(value); },
+        arg("x"),
+        "Add an item to the end of the list");
 
-    cl.def(init([](iterable it) {
+    cl.def(init([](const iterable &it) {
         auto v = std::unique_ptr<Vector>(new Vector());
         v->reserve(len_hint(it));
-        for (handle h : it)
-           v->push_back(h.cast<T>());
+        for (handle h : it) {
+            v->push_back(h.cast<T>());
+        }
         return v.release();
     }));
 
-    cl.def("extend",
-       [](Vector &v, const Vector &src) {
-           v.insert(v.end(), src.begin(), src.end());
-       },
-       arg("L"),
-       "Extend the list by appending all the items in the given list"
-    );
+    cl.def(
+        "clear", [](Vector &v) { v.clear(); }, "Clear the contents");
 
-    cl.def("extend",
-       [](Vector &v, iterable it) {
-           const size_t old_size = v.size();
-           v.reserve(old_size + len_hint(it));
-           try {
-               for (handle h : it) {
-                   v.push_back(h.cast<T>());
-               }
-           } catch (const cast_error &) {
-               v.erase(v.begin() + static_cast<typename Vector::difference_type>(old_size), v.end());
-               try {
-                   v.shrink_to_fit();
-               } catch (const std::exception &) {
-                   // Do nothing
-               }
-               throw;
-           }
-       },
-       arg("L"),
-       "Extend the list by appending all the items in the given list"
-    );
+    cl.def(
+        "extend",
+        [](Vector &v, const Vector &src) { v.insert(v.end(), src.begin(), src.end()); },
+        arg("L"),
+        "Extend the list by appending all the items in the given list");
+
+    cl.def(
+        "extend",
+        [](Vector &v, const iterable &it) {
+            const size_t old_size = v.size();
+            v.reserve(old_size + len_hint(it));
+            try {
+                for (handle h : it) {
+                    v.push_back(h.cast<T>());
+                }
+            } catch (const cast_error &) {
+                v.erase(v.begin() + static_cast<typename Vector::difference_type>(old_size),
+                        v.end());
+                try {
+                    v.shrink_to_fit();
+                } catch (const std::exception &) {
+                    // Do nothing
+                }
+                throw;
+            }
+        },
+        arg("L"),
+        "Extend the list by appending all the items in the given list");
 
-    cl.def("insert",
-        [](Vector &v, SizeType i, const T &x) {
-            if (i > v.size())
+    cl.def(
+        "insert",
+        [](Vector &v, DiffType i, const T &x) {
+            // Can't use wrap_i; i == v.size() is OK
+            if (i < 0) {
+                i += v.size();
+            }
+            if (i < 0 || (SizeType) i > v.size()) {
                 throw index_error();
-            v.insert(v.begin() + (DiffType) i, x);
+            }
+            v.insert(v.begin() + i, x);
         },
-        arg("i") , arg("x"),
-        "Insert an item at a given position."
-    );
+        arg("i"),
+        arg("x"),
+        "Insert an item at a given position.");
 
-    cl.def("pop",
+    cl.def(
+        "pop",
         [](Vector &v) {
-            if (v.empty())
+            if (v.empty()) {
                 throw index_error();
-            T t = v.back();
+            }
+            T t = std::move(v.back());
             v.pop_back();
             return t;
         },
-        "Remove and return the last item"
-    );
+        "Remove and return the last item");
 
-    cl.def("pop",
-        [](Vector &v, SizeType i) {
-            if (i >= v.size())
-                throw index_error();
-            T t = v[i];
-            v.erase(v.begin() + (DiffType) i);
+    cl.def(
+        "pop",
+        [wrap_i](Vector &v, DiffType i) {
+            i = wrap_i(i, v.size());
+            T t = std::move(v[(SizeType) i]);
+            v.erase(std::next(v.begin(), i));
             return t;
         },
         arg("i"),
-        "Remove and return the item at index ``i``"
-    );
+        "Remove and return the item at index ``i``");
 
-    cl.def("__setitem__",
-        [](Vector &v, SizeType i, const T &t) {
-            if (i >= v.size())
-                throw index_error();
-            v[i] = t;
-        }
-    );
+    cl.def("__setitem__", [wrap_i](Vector &v, DiffType i, const T &t) {
+        i = wrap_i(i, v.size());
+        v[(SizeType) i] = t;
+    });
 
     /// Slicing protocol
-    cl.def("__getitem__",
-        [](const Vector &v, slice slice) -> Vector * {
-            size_t start, stop, step, slicelength;
+    cl.def(
+        "__getitem__",
+        [](const Vector &v, const slice &slice) -> Vector * {
+            size_t start = 0, stop = 0, step = 0, slicelength = 0;
 
-            if (!slice.compute(v.size(), &start, &stop, &step, &slicelength))
+            if (!slice.compute(v.size(), &start, &stop, &step, &slicelength)) {
                 throw error_already_set();
+            }
 
-            Vector *seq = new Vector();
+            auto *seq = new Vector();
             seq->reserve((size_t) slicelength);
 
-            for (size_t i=0; i<slicelength; ++i) {
+            for (size_t i = 0; i < slicelength; ++i) {
                 seq->push_back(v[start]);
                 start += step;
             }
             return seq;
         },
         arg("s"),
-        "Retrieve list elements using a slice object"
-    );
+        "Retrieve list elements using a slice object");
 
-    cl.def("__setitem__",
-        [](Vector &v, slice slice,  const Vector &value) {
-            size_t start, stop, step, slicelength;
-            if (!slice.compute(v.size(), &start, &stop, &step, &slicelength))
+    cl.def(
+        "__setitem__",
+        [](Vector &v, const slice &slice, const Vector &value) {
+            size_t start = 0, stop = 0, step = 0, slicelength = 0;
+            if (!slice.compute(v.size(), &start, &stop, &step, &slicelength)) {
                 throw error_already_set();
+            }
 
-            if (slicelength != value.size())
-                throw std::runtime_error("Left and right hand size of slice assignment have different sizes!");
+            if (slicelength != value.size()) {
+                throw std::runtime_error(
+                    "Left and right hand size of slice assignment have different sizes!");
+            }
 
-            for (size_t i=0; i<slicelength; ++i) {
+            for (size_t i = 0; i < slicelength; ++i) {
                 v[start] = value[i];
                 start += step;
             }
         },
-        "Assign list elements using a slice object"
-    );
-
-    cl.def("__delitem__",
-        [](Vector &v, SizeType i) {
-            if (i >= v.size())
-                throw index_error();
-            v.erase(v.begin() + DiffType(i));
-        },
-        "Delete the list elements at index ``i``"
-    );
+        "Assign list elements using a slice object");
 
-    cl.def("__delitem__",
-        [](Vector &v, slice slice) {
-            size_t start, stop, step, slicelength;
+    cl.def(
+        "__delitem__",
+        [wrap_i](Vector &v, DiffType i) {
+            i = wrap_i(i, v.size());
+            v.erase(v.begin() + i);
+        },
+        "Delete the list elements at index ``i``");
+
+    cl.def(
+        "__delitem__",
+        [](Vector &v, const slice &slice) {
+            size_t start = 0, stop = 0, step = 0, slicelength = 0;
 
-            if (!slice.compute(v.size(), &start, &stop, &step, &slicelength))
+            if (!slice.compute(v.size(), &start, &stop, &step, &slicelength)) {
                 throw error_already_set();
+            }
 
             if (step == 1 && false) {
                 v.erase(v.begin() + (DiffType) start, v.begin() + DiffType(start + slicelength));
             } else {
                 for (size_t i = 0; i < slicelength; ++i) {
                     v.erase(v.begin() + DiffType(start));
                     start += step - 1;
                 }
             }
         },
-        "Delete list elements using a slice object"
-    );
-
+        "Delete list elements using a slice object");
 }
 
 // If the type has an operator[] that doesn't return a reference (most notably std::vector<bool>),
 // we have to access by copying; otherwise we return by reference.
-template <typename Vector> using vector_needs_copy = negation<
-    std::is_same<decltype(std::declval<Vector>()[typename Vector::size_type()]), typename Vector::value_type &>>;
+template <typename Vector>
+using vector_needs_copy
+    = negation<std::is_same<decltype(std::declval<Vector>()[typename Vector::size_type()]),
+                            typename Vector::value_type &>>;
 
 // The usual case: access and iterate by reference
 template <typename Vector, typename Class_>
 void vector_accessor(enable_if_t<!vector_needs_copy<Vector>::value, Class_> &cl) {
     using T = typename Vector::value_type;
     using SizeType = typename Vector::size_type;
-    using ItType   = typename Vector::iterator;
+    using DiffType = typename Vector::difference_type;
+    using ItType = typename Vector::iterator;
 
-    cl.def("__getitem__",
-        [](Vector &v, SizeType i) -> T & {
-            if (i >= v.size())
-                throw index_error();
-            return v[i];
+    auto wrap_i = [](DiffType i, SizeType n) {
+        if (i < 0) {
+            i += n;
+        }
+        if (i < 0 || (SizeType) i >= n) {
+            throw index_error();
+        }
+        return i;
+    };
+
+    cl.def(
+        "__getitem__",
+        [wrap_i](Vector &v, DiffType i) -> T & {
+            i = wrap_i(i, v.size());
+            return v[(SizeType) i];
         },
         return_value_policy::reference_internal // ref + keepalive
     );
 
-    cl.def("__iter__",
-           [](Vector &v) {
-               return make_iterator<
-                   return_value_policy::reference_internal, ItType, ItType, T&>(
-                   v.begin(), v.end());
-           },
-           keep_alive<0, 1>() /* Essential: keep list alive while iterator exists */
+    cl.def(
+        "__iter__",
+        [](Vector &v) {
+            return make_iterator<return_value_policy::reference_internal, ItType, ItType, T &>(
+                v.begin(), v.end());
+        },
+        keep_alive<0, 1>() /* Essential: keep list alive while iterator exists */
     );
 }
 
 // The case for special objects, like std::vector<bool>, that have to be returned-by-copy:
 template <typename Vector, typename Class_>
 void vector_accessor(enable_if_t<vector_needs_copy<Vector>::value, Class_> &cl) {
     using T = typename Vector::value_type;
     using SizeType = typename Vector::size_type;
-    using ItType   = typename Vector::iterator;
-    cl.def("__getitem__",
-        [](const Vector &v, SizeType i) -> T {
-            if (i >= v.size())
-                throw index_error();
-            return v[i];
+    using DiffType = typename Vector::difference_type;
+    using ItType = typename Vector::iterator;
+    cl.def("__getitem__", [](const Vector &v, DiffType i) -> T {
+        if (i < 0 && (i += v.size()) < 0) {
+            throw index_error();
         }
-    );
+        if ((SizeType) i >= v.size()) {
+            throw index_error();
+        }
+        return v[(SizeType) i];
+    });
 
-    cl.def("__iter__",
-           [](Vector &v) {
-               return make_iterator<
-                   return_value_policy::copy, ItType, ItType, T>(
-                   v.begin(), v.end());
-           },
-           keep_alive<0, 1>() /* Essential: keep list alive while iterator exists */
+    cl.def(
+        "__iter__",
+        [](Vector &v) {
+            return make_iterator<return_value_policy::copy, ItType, ItType, T>(v.begin(), v.end());
+        },
+        keep_alive<0, 1>() /* Essential: keep list alive while iterator exists */
     );
 }
 
-template <typename Vector, typename Class_> auto vector_if_insertion_operator(Class_ &cl, std::string const &name)
-    -> decltype(std::declval<std::ostream&>() << std::declval<typename Vector::value_type>(), void()) {
+template <typename Vector, typename Class_>
+auto vector_if_insertion_operator(Class_ &cl, std::string const &name)
+    -> decltype(std::declval<std::ostream &>() << std::declval<typename Vector::value_type>(),
+                void()) {
     using size_type = typename Vector::size_type;
 
-    cl.def("__repr__",
-           [name](Vector &v) {
+    cl.def(
+        "__repr__",
+        [name](Vector &v) {
             std::ostringstream s;
             s << name << '[';
-            for (size_type i=0; i < v.size(); ++i) {
+            for (size_type i = 0; i < v.size(); ++i) {
                 s << v[i];
-                if (i != v.size() - 1)
+                if (i != v.size() - 1) {
                     s << ", ";
+                }
             }
             s << ']';
             return s.str();
         },
-        "Return the canonical string representation of this list."
-    );
+        "Return the canonical string representation of this list.");
 }
 
 // Provide the buffer interface for vectors if we have data() and we have a format for it
-// GCC seems to have "void std::vector<bool>::data()" - doing SFINAE on the existence of data() is insufficient, we need to check it returns an appropriate pointer
+// GCC seems to have "void std::vector<bool>::data()" - doing SFINAE on the existence of data()
+// is insufficient, we need to check it returns an appropriate pointer
 template <typename Vector, typename = void>
 struct vector_has_data_and_format : std::false_type {};
 template <typename Vector>
-struct vector_has_data_and_format<Vector, enable_if_t<std::is_same<decltype(format_descriptor<typename Vector::value_type>::format(), std::declval<Vector>().data()), typename Vector::value_type*>::value>> : std::true_type {};
+struct vector_has_data_and_format<
+    Vector,
+    enable_if_t<std::is_same<decltype(format_descriptor<typename Vector::value_type>::format(),
+                                      std::declval<Vector>().data()),
+                             typename Vector::value_type *>::value>> : std::true_type {};
+
+// [workaround(intel)] Separate function required here
+// Workaround as the Intel compiler does not compile the enable_if_t part below
+// (tested with icc (ICC) 2021.1 Beta 20200827)
+template <typename... Args>
+constexpr bool args_any_are_buffer() {
+    return detail::any_of<std::is_same<Args, buffer_protocol>...>::value;
+}
+
+// [workaround(intel)] Separate function required here
+// [workaround(msvc)] Can't use constexpr bool in return type
 
 // Add the buffer interface to a vector
 template <typename Vector, typename Class_, typename... Args>
-enable_if_t<detail::any_of<std::is_same<Args, buffer_protocol>...>::value>
-vector_buffer(Class_& cl) {
+void vector_buffer_impl(Class_ &cl, std::true_type) {
     using T = typename Vector::value_type;
 
-    static_assert(vector_has_data_and_format<Vector>::value, "There is not an appropriate format descriptor for this vector");
+    static_assert(vector_has_data_and_format<Vector>::value,
+                  "There is not an appropriate format descriptor for this vector");
 
-    // numpy.h declares this for arbitrary types, but it may raise an exception and crash hard at runtime if PYBIND11_NUMPY_DTYPE hasn't been called, so check here
+    // numpy.h declares this for arbitrary types, but it may raise an exception and crash hard
+    // at runtime if PYBIND11_NUMPY_DTYPE hasn't been called, so check here
     format_descriptor<T>::format();
 
-    cl.def_buffer([](Vector& v) -> buffer_info {
-        return buffer_info(v.data(), static_cast<ssize_t>(sizeof(T)), format_descriptor<T>::format(), 1, {v.size()}, {sizeof(T)});
+    cl.def_buffer([](Vector &v) -> buffer_info {
+        return buffer_info(v.data(),
+                           static_cast<ssize_t>(sizeof(T)),
+                           format_descriptor<T>::format(),
+                           1,
+                           {v.size()},
+                           {sizeof(T)});
     });
 
-    cl.def(init([](buffer buf) {
+    cl.def(init([](const buffer &buf) {
         auto info = buf.request();
-        if (info.ndim != 1 || info.strides[0] % static_cast<ssize_t>(sizeof(T)))
+        if (info.ndim != 1 || info.strides[0] % static_cast<ssize_t>(sizeof(T))) {
             throw type_error("Only valid 1D buffers can be copied to a vector");
-        if (!detail::compare_buffer_info<T>::compare(info) || (ssize_t) sizeof(T) != info.itemsize)
-            throw type_error("Format mismatch (Python: " + info.format + " C++: " + format_descriptor<T>::format() + ")");
+        }
+        if (!detail::compare_buffer_info<T>::compare(info)
+            || (ssize_t) sizeof(T) != info.itemsize) {
+            throw type_error("Format mismatch (Python: " + info.format
+                             + " C++: " + format_descriptor<T>::format() + ")");
+        }
 
-        auto vec = std::unique_ptr<Vector>(new Vector());
-        vec->reserve((size_t) info.shape[0]);
-        T *p = static_cast<T*>(info.ptr);
+        T *p = static_cast<T *>(info.ptr);
         ssize_t step = info.strides[0] / static_cast<ssize_t>(sizeof(T));
         T *end = p + info.shape[0] * step;
-        for (; p != end; p += step)
-            vec->push_back(*p);
-        return vec.release();
+        if (step == 1) {
+            return Vector(p, end);
+        }
+        Vector vec;
+        vec.reserve((size_t) info.shape[0]);
+        for (; p != end; p += step) {
+            vec.push_back(*p);
+        }
+        return vec;
     }));
 
     return;
 }
 
 template <typename Vector, typename Class_, typename... Args>
-enable_if_t<!detail::any_of<std::is_same<Args, buffer_protocol>...>::value> vector_buffer(Class_&) {}
+void vector_buffer_impl(Class_ &, std::false_type) {}
 
-NAMESPACE_END(detail)
+template <typename Vector, typename Class_, typename... Args>
+void vector_buffer(Class_ &cl) {
+    vector_buffer_impl<Vector, Class_, Args...>(
+        cl, detail::any_of<std::is_same<Args, buffer_protocol>...>{});
+}
+
+PYBIND11_NAMESPACE_END(detail)
 
 //
 // std::vector
 //
 template <typename Vector, typename holder_type = std::unique_ptr<Vector>, typename... Args>
-class_<Vector, holder_type> bind_vector(handle scope, std::string const &name, Args&&... args) {
+class_<Vector, holder_type> bind_vector(handle scope, std::string const &name, Args &&...args) {
     using Class_ = class_<Vector, holder_type>;
 
     // If the value_type is unregistered (e.g. a converting type) or is itself registered
     // module-local then make the vector binding module-local as well:
     using vtype = typename Vector::value_type;
-    auto vtype_info = detail::get_type_info(typeid(vtype));
+    auto *vtype_info = detail::get_type_info(typeid(vtype));
     bool local = !vtype_info || vtype_info->module_local;
 
     Class_ cl(scope, name.c_str(), pybind11::module_local(local), std::forward<Args>(args)...);
 
     // Declare the buffer interface if a buffer_protocol() is passed in
     detail::vector_buffer<Vector, Class_, Args...>(cl);
 
@@ -420,26 +510,21 @@
 
     // Modifiers require copyable vector value type
     detail::vector_modifiers<Vector, Class_>(cl);
 
     // Accessor and iterator; return by value if copyable, otherwise we return by ref + keep-alive
     detail::vector_accessor<Vector, Class_>(cl);
 
-    cl.def("__bool__",
-        [](const Vector &v) -> bool {
-            return !v.empty();
-        },
-        "Check whether the list is nonempty"
-    );
+    cl.def(
+        "__bool__",
+        [](const Vector &v) -> bool { return !v.empty(); },
+        "Check whether the list is nonempty");
 
     cl.def("__len__", &Vector::size);
 
-
-
-
 #if 0
     // C++ style functions deprecated, leaving it here as an example
     cl.def(init<size_type>());
 
     cl.def("resize",
          (void (Vector::*) (size_type count)) & Vector::resize,
          "changes the number of elements stored");
@@ -475,156 +560,286 @@
     }, "access the last element ");
 
 #endif
 
     return cl;
 }
 
-
-
 //
 // std::map, std::unordered_map
 //
 
-NAMESPACE_BEGIN(detail)
+PYBIND11_NAMESPACE_BEGIN(detail)
 
 /* Fallback functions */
-template <typename, typename, typename... Args> void map_if_insertion_operator(const Args &...) { }
-template <typename, typename, typename... Args> void map_assignment(const Args &...) { }
+template <typename, typename, typename... Args>
+void map_if_insertion_operator(const Args &...) {}
+template <typename, typename, typename... Args>
+void map_assignment(const Args &...) {}
 
 // Map assignment when copy-assignable: just copy the value
 template <typename Map, typename Class_>
-void map_assignment(enable_if_t<std::is_copy_assignable<typename Map::mapped_type>::value, Class_> &cl) {
+void map_assignment(
+    enable_if_t<is_copy_assignable<typename Map::mapped_type>::value, Class_> &cl) {
     using KeyType = typename Map::key_type;
     using MappedType = typename Map::mapped_type;
 
-    cl.def("__setitem__",
-           [](Map &m, const KeyType &k, const MappedType &v) {
-               auto it = m.find(k);
-               if (it != m.end()) it->second = v;
-               else m.emplace(k, v);
-           }
-    );
+    cl.def("__setitem__", [](Map &m, const KeyType &k, const MappedType &v) {
+        auto it = m.find(k);
+        if (it != m.end()) {
+            it->second = v;
+        } else {
+            m.emplace(k, v);
+        }
+    });
 }
 
-// Not copy-assignable, but still copy-constructible: we can update the value by erasing and reinserting
-template<typename Map, typename Class_>
-void map_assignment(enable_if_t<
-        !std::is_copy_assignable<typename Map::mapped_type>::value &&
-        is_copy_constructible<typename Map::mapped_type>::value,
-        Class_> &cl) {
+// Not copy-assignable, but still copy-constructible: we can update the value by erasing and
+// reinserting
+template <typename Map, typename Class_>
+void map_assignment(enable_if_t<!is_copy_assignable<typename Map::mapped_type>::value
+                                    && is_copy_constructible<typename Map::mapped_type>::value,
+                                Class_> &cl) {
     using KeyType = typename Map::key_type;
     using MappedType = typename Map::mapped_type;
 
-    cl.def("__setitem__",
-           [](Map &m, const KeyType &k, const MappedType &v) {
-               // We can't use m[k] = v; because value type might not be default constructable
-               auto r = m.emplace(k, v);
-               if (!r.second) {
-                   // value type is not copy assignable so the only way to insert it is to erase it first...
-                   m.erase(r.first);
-                   m.emplace(k, v);
-               }
-           }
-    );
+    cl.def("__setitem__", [](Map &m, const KeyType &k, const MappedType &v) {
+        // We can't use m[k] = v; because value type might not be default constructable
+        auto r = m.emplace(k, v);
+        if (!r.second) {
+            // value type is not copy assignable so the only way to insert it is to erase it
+            // first...
+            m.erase(r.first);
+            m.emplace(k, v);
+        }
+    });
 }
 
-
-template <typename Map, typename Class_> auto map_if_insertion_operator(Class_ &cl, std::string const &name)
--> decltype(std::declval<std::ostream&>() << std::declval<typename Map::key_type>() << std::declval<typename Map::mapped_type>(), void()) {
-
-    cl.def("__repr__",
-           [name](Map &m) {
+template <typename Map, typename Class_>
+auto map_if_insertion_operator(Class_ &cl, std::string const &name)
+    -> decltype(std::declval<std::ostream &>() << std::declval<typename Map::key_type>()
+                                               << std::declval<typename Map::mapped_type>(),
+                void()) {
+
+    cl.def(
+        "__repr__",
+        [name](Map &m) {
             std::ostringstream s;
             s << name << '{';
             bool f = false;
             for (auto const &kv : m) {
-                if (f)
+                if (f) {
                     s << ", ";
+                }
                 s << kv.first << ": " << kv.second;
                 f = true;
             }
             s << '}';
             return s.str();
         },
-        "Return the canonical string representation of this map."
-    );
+        "Return the canonical string representation of this map.");
 }
 
+template <typename KeyType>
+struct keys_view {
+    virtual size_t len() = 0;
+    virtual iterator iter() = 0;
+    virtual bool contains(const KeyType &k) = 0;
+    virtual bool contains(const object &k) = 0;
+    virtual ~keys_view() = default;
+};
+
+template <typename MappedType>
+struct values_view {
+    virtual size_t len() = 0;
+    virtual iterator iter() = 0;
+    virtual ~values_view() = default;
+};
+
+template <typename KeyType, typename MappedType>
+struct items_view {
+    virtual size_t len() = 0;
+    virtual iterator iter() = 0;
+    virtual ~items_view() = default;
+};
+
+template <typename Map, typename KeysView>
+struct KeysViewImpl : public KeysView {
+    explicit KeysViewImpl(Map &map) : map(map) {}
+    size_t len() override { return map.size(); }
+    iterator iter() override { return make_key_iterator(map.begin(), map.end()); }
+    bool contains(const typename Map::key_type &k) override { return map.find(k) != map.end(); }
+    bool contains(const object &) override { return false; }
+    Map &map;
+};
+
+template <typename Map, typename ValuesView>
+struct ValuesViewImpl : public ValuesView {
+    explicit ValuesViewImpl(Map &map) : map(map) {}
+    size_t len() override { return map.size(); }
+    iterator iter() override { return make_value_iterator(map.begin(), map.end()); }
+    Map &map;
+};
+
+template <typename Map, typename ItemsView>
+struct ItemsViewImpl : public ItemsView {
+    explicit ItemsViewImpl(Map &map) : map(map) {}
+    size_t len() override { return map.size(); }
+    iterator iter() override { return make_iterator(map.begin(), map.end()); }
+    Map &map;
+};
 
-NAMESPACE_END(detail)
+PYBIND11_NAMESPACE_END(detail)
 
 template <typename Map, typename holder_type = std::unique_ptr<Map>, typename... Args>
-class_<Map, holder_type> bind_map(handle scope, const std::string &name, Args&&... args) {
+class_<Map, holder_type> bind_map(handle scope, const std::string &name, Args &&...args) {
     using KeyType = typename Map::key_type;
     using MappedType = typename Map::mapped_type;
+    using StrippedKeyType = detail::remove_cvref_t<KeyType>;
+    using StrippedMappedType = detail::remove_cvref_t<MappedType>;
+    using KeysView = detail::keys_view<StrippedKeyType>;
+    using ValuesView = detail::values_view<StrippedMappedType>;
+    using ItemsView = detail::items_view<StrippedKeyType, StrippedMappedType>;
     using Class_ = class_<Map, holder_type>;
 
     // If either type is a non-module-local bound type then make the map binding non-local as well;
     // otherwise (e.g. both types are either module-local or converting) the map will be
     // module-local.
-    auto tinfo = detail::get_type_info(typeid(MappedType));
+    auto *tinfo = detail::get_type_info(typeid(MappedType));
     bool local = !tinfo || tinfo->module_local;
     if (local) {
         tinfo = detail::get_type_info(typeid(KeyType));
         local = !tinfo || tinfo->module_local;
     }
 
     Class_ cl(scope, name.c_str(), pybind11::module_local(local), std::forward<Args>(args)...);
+    static constexpr auto key_type_descr = detail::make_caster<KeyType>::name;
+    static constexpr auto mapped_type_descr = detail::make_caster<MappedType>::name;
+    std::string key_type_name(key_type_descr.text), mapped_type_name(mapped_type_descr.text);
+
+    // If key type isn't properly wrapped, fall back to C++ names
+    if (key_type_name == "%") {
+        key_type_name = detail::type_info_description(typeid(KeyType));
+    }
+    // Similarly for value type:
+    if (mapped_type_name == "%") {
+        mapped_type_name = detail::type_info_description(typeid(MappedType));
+    }
+
+    // Wrap KeysView[KeyType] if it wasn't already wrapped
+    if (!detail::get_type_info(typeid(KeysView))) {
+        class_<KeysView> keys_view(
+            scope, ("KeysView[" + key_type_name + "]").c_str(), pybind11::module_local(local));
+        keys_view.def("__len__", &KeysView::len);
+        keys_view.def("__iter__",
+                      &KeysView::iter,
+                      keep_alive<0, 1>() /* Essential: keep view alive while iterator exists */
+        );
+        keys_view.def("__contains__",
+                      static_cast<bool (KeysView::*)(const KeyType &)>(&KeysView::contains));
+        // Fallback for when the object is not of the key type
+        keys_view.def("__contains__",
+                      static_cast<bool (KeysView::*)(const object &)>(&KeysView::contains));
+    }
+    // Similarly for ValuesView:
+    if (!detail::get_type_info(typeid(ValuesView))) {
+        class_<ValuesView> values_view(scope,
+                                       ("ValuesView[" + mapped_type_name + "]").c_str(),
+                                       pybind11::module_local(local));
+        values_view.def("__len__", &ValuesView::len);
+        values_view.def("__iter__",
+                        &ValuesView::iter,
+                        keep_alive<0, 1>() /* Essential: keep view alive while iterator exists */
+        );
+    }
+    // Similarly for ItemsView:
+    if (!detail::get_type_info(typeid(ItemsView))) {
+        class_<ItemsView> items_view(
+            scope,
+            ("ItemsView[" + key_type_name + ", ").append(mapped_type_name + "]").c_str(),
+            pybind11::module_local(local));
+        items_view.def("__len__", &ItemsView::len);
+        items_view.def("__iter__",
+                       &ItemsView::iter,
+                       keep_alive<0, 1>() /* Essential: keep view alive while iterator exists */
+        );
+    }
 
     cl.def(init<>());
 
     // Register stream insertion operator (if possible)
     detail::map_if_insertion_operator<Map, Class_>(cl, name);
 
-    cl.def("__bool__",
+    cl.def(
+        "__bool__",
         [](const Map &m) -> bool { return !m.empty(); },
-        "Check whether the map is nonempty"
+        "Check whether the map is nonempty");
+
+    cl.def(
+        "__iter__",
+        [](Map &m) { return make_key_iterator(m.begin(), m.end()); },
+        keep_alive<0, 1>() /* Essential: keep map alive while iterator exists */
     );
 
-    cl.def("__iter__",
-           [](Map &m) { return make_key_iterator(m.begin(), m.end()); },
-           keep_alive<0, 1>() /* Essential: keep list alive while iterator exists */
+    cl.def(
+        "keys",
+        [](Map &m) {
+            return std::unique_ptr<KeysView>(new detail::KeysViewImpl<Map, KeysView>(m));
+        },
+        keep_alive<0, 1>() /* Essential: keep map alive while view exists */
+    );
+
+    cl.def(
+        "values",
+        [](Map &m) {
+            return std::unique_ptr<ValuesView>(new detail::ValuesViewImpl<Map, ValuesView>(m));
+        },
+        keep_alive<0, 1>() /* Essential: keep map alive while view exists */
     );
 
-    cl.def("items",
-           [](Map &m) { return make_iterator(m.begin(), m.end()); },
-           keep_alive<0, 1>() /* Essential: keep list alive while iterator exists */
+    cl.def(
+        "items",
+        [](Map &m) {
+            return std::unique_ptr<ItemsView>(new detail::ItemsViewImpl<Map, ItemsView>(m));
+        },
+        keep_alive<0, 1>() /* Essential: keep map alive while view exists */
     );
 
-    cl.def("__getitem__",
+    cl.def(
+        "__getitem__",
         [](Map &m, const KeyType &k) -> MappedType & {
             auto it = m.find(k);
-            if (it == m.end())
-              throw key_error();
-           return it->second;
+            if (it == m.end()) {
+                throw key_error();
+            }
+            return it->second;
         },
         return_value_policy::reference_internal // ref + keepalive
     );
 
-    cl.def("__contains__",
-        [](Map &m, const KeyType &k) -> bool {
-            auto it = m.find(k);
-            if (it == m.end())
-              return false;
-           return true;
+    cl.def("__contains__", [](Map &m, const KeyType &k) -> bool {
+        auto it = m.find(k);
+        if (it == m.end()) {
+            return false;
         }
-    );
+        return true;
+    });
+    // Fallback for when the object is not of the key type
+    cl.def("__contains__", [](Map &, const object &) -> bool { return false; });
 
     // Assignment provided only if the type is copyable
     detail::map_assignment<Map, Class_>(cl);
 
-    cl.def("__delitem__",
-           [](Map &m, const KeyType &k) {
-               auto it = m.find(k);
-               if (it == m.end())
-                   throw key_error();
-               m.erase(it);
-           }
-    );
+    cl.def("__delitem__", [](Map &m, const KeyType &k) {
+        auto it = m.find(k);
+        if (it == m.end()) {
+            throw key_error();
+        }
+        m.erase(it);
+    });
 
     cl.def("__len__", &Map::size);
 
     return cl;
 }
 
-NAMESPACE_END(PYBIND11_NAMESPACE)
+PYBIND11_NAMESPACE_END(PYBIND11_NAMESPACE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/tools/FindCatch.cmake` & `affine_transform-0.3.0/extern/pybind11/tools/FindCatch.cmake`

 * *Files 12% similar despite different names*

```diff
@@ -5,44 +5,56 @@
 # a suitable version isn't found locally, the single header file
 # will be downloaded and placed in the build dir: PROJECT_BINARY_DIR.
 #
 # This code sets the following variables:
 #  CATCH_INCLUDE_DIR      - path to catch.hpp
 #  CATCH_VERSION          - version number
 
+option(DOWNLOAD_CATCH "Download catch2 if not found")
+
 if(NOT Catch_FIND_VERSION)
   message(FATAL_ERROR "A version number must be specified.")
 elseif(Catch_FIND_REQUIRED)
   message(FATAL_ERROR "This module assumes Catch is not required.")
 elseif(Catch_FIND_VERSION_EXACT)
   message(FATAL_ERROR "Exact version numbers are not supported, only minimum.")
 endif()
 
 # Extract the version number from catch.hpp
 function(_get_catch_version)
-  file(STRINGS "${CATCH_INCLUDE_DIR}/catch.hpp" version_line REGEX "Catch v.*" LIMIT_COUNT 1)
+  file(
+    STRINGS "${CATCH_INCLUDE_DIR}/catch.hpp" version_line
+    REGEX "Catch v.*"
+    LIMIT_COUNT 1)
   if(version_line MATCHES "Catch v([0-9]+)\\.([0-9]+)\\.([0-9]+)")
-    set(CATCH_VERSION "${CMAKE_MATCH_1}.${CMAKE_MATCH_2}.${CMAKE_MATCH_3}" PARENT_SCOPE)
+    set(CATCH_VERSION
+        "${CMAKE_MATCH_1}.${CMAKE_MATCH_2}.${CMAKE_MATCH_3}"
+        PARENT_SCOPE)
   endif()
 endfunction()
 
 # Download the single-header version of Catch
 function(_download_catch version destination_dir)
   message(STATUS "Downloading catch v${version}...")
   set(url https://github.com/philsquared/Catch/releases/download/v${version}/catch.hpp)
   file(DOWNLOAD ${url} "${destination_dir}/catch.hpp" STATUS status)
   list(GET status 0 error)
   if(error)
     message(FATAL_ERROR "Could not download ${url}")
   endif()
-  set(CATCH_INCLUDE_DIR "${destination_dir}" CACHE INTERNAL "")
+  set(CATCH_INCLUDE_DIR
+      "${destination_dir}"
+      CACHE INTERNAL "")
 endfunction()
 
 # Look for catch locally
-find_path(CATCH_INCLUDE_DIR NAMES catch.hpp PATH_SUFFIXES catch)
+find_path(
+  CATCH_INCLUDE_DIR
+  NAMES catch.hpp
+  PATH_SUFFIXES catch2)
 if(CATCH_INCLUDE_DIR)
   _get_catch_version()
 endif()
 
 # Download the header if it wasn't found or if it's outdated
 if(NOT CATCH_VERSION OR CATCH_VERSION VERSION_LESS ${Catch_FIND_VERSION})
   if(DOWNLOAD_CATCH)
@@ -50,8 +62,11 @@
     _get_catch_version()
   else()
     set(CATCH_FOUND FALSE)
     return()
   endif()
 endif()
 
+add_library(Catch2::Catch2 IMPORTED INTERFACE)
+set_property(TARGET Catch2::Catch2 PROPERTY INTERFACE_INCLUDE_DIRECTORIES "${CATCH_INCLUDE_DIR}")
+
 set(CATCH_FOUND TRUE)
```

### Comparing `affine_transform-0.2.9/extern/pybind11/tools/FindEigen3.cmake` & `affine_transform-0.3.0/extern/pybind11/tools/FindEigen3.cmake`

 * *Files 8% similar despite different names*

```diff
@@ -22,25 +22,29 @@
   if(NOT Eigen3_FIND_VERSION_MINOR)
     set(Eigen3_FIND_VERSION_MINOR 91)
   endif(NOT Eigen3_FIND_VERSION_MINOR)
   if(NOT Eigen3_FIND_VERSION_PATCH)
     set(Eigen3_FIND_VERSION_PATCH 0)
   endif(NOT Eigen3_FIND_VERSION_PATCH)
 
-  set(Eigen3_FIND_VERSION "${Eigen3_FIND_VERSION_MAJOR}.${Eigen3_FIND_VERSION_MINOR}.${Eigen3_FIND_VERSION_PATCH}")
+  set(Eigen3_FIND_VERSION
+      "${Eigen3_FIND_VERSION_MAJOR}.${Eigen3_FIND_VERSION_MINOR}.${Eigen3_FIND_VERSION_PATCH}")
 endif(NOT Eigen3_FIND_VERSION)
 
 macro(_eigen3_check_version)
   file(READ "${EIGEN3_INCLUDE_DIR}/Eigen/src/Core/util/Macros.h" _eigen3_version_header)
 
-  string(REGEX MATCH "define[ \t]+EIGEN_WORLD_VERSION[ \t]+([0-9]+)" _eigen3_world_version_match "${_eigen3_version_header}")
+  string(REGEX MATCH "define[ \t]+EIGEN_WORLD_VERSION[ \t]+([0-9]+)" _eigen3_world_version_match
+               "${_eigen3_version_header}")
   set(EIGEN3_WORLD_VERSION "${CMAKE_MATCH_1}")
-  string(REGEX MATCH "define[ \t]+EIGEN_MAJOR_VERSION[ \t]+([0-9]+)" _eigen3_major_version_match "${_eigen3_version_header}")
+  string(REGEX MATCH "define[ \t]+EIGEN_MAJOR_VERSION[ \t]+([0-9]+)" _eigen3_major_version_match
+               "${_eigen3_version_header}")
   set(EIGEN3_MAJOR_VERSION "${CMAKE_MATCH_1}")
-  string(REGEX MATCH "define[ \t]+EIGEN_MINOR_VERSION[ \t]+([0-9]+)" _eigen3_minor_version_match "${_eigen3_version_header}")
+  string(REGEX MATCH "define[ \t]+EIGEN_MINOR_VERSION[ \t]+([0-9]+)" _eigen3_minor_version_match
+               "${_eigen3_version_header}")
   set(EIGEN3_MINOR_VERSION "${CMAKE_MATCH_1}")
 
   set(EIGEN3_VERSION ${EIGEN3_WORLD_VERSION}.${EIGEN3_MAJOR_VERSION}.${EIGEN3_MINOR_VERSION})
   if(${EIGEN3_VERSION} VERSION_LESS ${Eigen3_FIND_VERSION})
     set(EIGEN3_VERSION_OK FALSE)
   else(${EIGEN3_VERSION} VERSION_LESS ${Eigen3_FIND_VERSION})
     set(EIGEN3_VERSION_OK TRUE)
@@ -49,33 +53,34 @@
   if(NOT EIGEN3_VERSION_OK)
 
     message(STATUS "Eigen3 version ${EIGEN3_VERSION} found in ${EIGEN3_INCLUDE_DIR}, "
                    "but at least version ${Eigen3_FIND_VERSION} is required")
   endif(NOT EIGEN3_VERSION_OK)
 endmacro(_eigen3_check_version)
 
-if (EIGEN3_INCLUDE_DIR)
+if(EIGEN3_INCLUDE_DIR)
 
   # in cache already
   _eigen3_check_version()
   set(EIGEN3_FOUND ${EIGEN3_VERSION_OK})
 
-else (EIGEN3_INCLUDE_DIR)
-
-  find_path(EIGEN3_INCLUDE_DIR NAMES signature_of_eigen3_matrix_library
-      PATHS
-      ${CMAKE_INSTALL_PREFIX}/include
-      ${KDE4_INCLUDE_DIR}
-      PATH_SUFFIXES eigen3 eigen
-    )
+else(EIGEN3_INCLUDE_DIR)
+  if(NOT DEFINED KDE4_INCLUDE_DIR)
+    set(KDE4_INCLUDE_DIR "")
+  endif()
+
+  find_path(
+    EIGEN3_INCLUDE_DIR
+    NAMES signature_of_eigen3_matrix_library
+    PATHS ${CMAKE_INSTALL_PREFIX}/include ${KDE4_INCLUDE_DIR}
+    PATH_SUFFIXES eigen3 eigen)
 
   if(EIGEN3_INCLUDE_DIR)
     _eigen3_check_version()
   endif(EIGEN3_INCLUDE_DIR)
 
   include(FindPackageHandleStandardArgs)
   find_package_handle_standard_args(Eigen3 DEFAULT_MSG EIGEN3_INCLUDE_DIR EIGEN3_VERSION_OK)
 
   mark_as_advanced(EIGEN3_INCLUDE_DIR)
 
 endif(EIGEN3_INCLUDE_DIR)
-
```

### Comparing `affine_transform-0.2.9/extern/pybind11/tools/FindPythonLibsNew.cmake` & `affine_transform-0.3.0/extern/pybind11/tools/FindPythonLibsNew.cmake`

 * *Files 24% similar despite different names*

```diff
@@ -48,155 +48,240 @@
 # THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
 # (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
 # OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
 #=============================================================================
 
 # Checking for the extension makes sure that `LibsNew` was found and not just `Libs`.
 if(PYTHONLIBS_FOUND AND PYTHON_MODULE_EXTENSION)
-    return()
+  return()
 endif()
 
-# Use the Python interpreter to find the libs.
-if(PythonLibsNew_FIND_REQUIRED)
-    find_package(PythonInterp ${PythonLibsNew_FIND_VERSION} REQUIRED)
+if(PythonLibsNew_FIND_QUIETLY)
+  set(_pythonlibs_quiet QUIET)
 else()
-    find_package(PythonInterp ${PythonLibsNew_FIND_VERSION})
+  set(_pythonlibs_quiet "")
+endif()
+
+if(PythonLibsNew_FIND_REQUIRED)
+  set(_pythonlibs_required REQUIRED)
+endif()
+
+# Check to see if the `python` command is present and from a virtual
+# environment, conda, or GHA activation - if it is, try to use that.
+
+if(NOT DEFINED PYTHON_EXECUTABLE)
+  if(DEFINED ENV{VIRTUAL_ENV})
+    find_program(
+      PYTHON_EXECUTABLE python
+      PATHS "$ENV{VIRTUAL_ENV}" "$ENV{VIRTUAL_ENV}/bin"
+      NO_DEFAULT_PATH)
+  elseif(DEFINED ENV{CONDA_PREFIX})
+    find_program(
+      PYTHON_EXECUTABLE python
+      PATHS "$ENV{CONDA_PREFIX}" "$ENV{CONDA_PREFIX}/bin"
+      NO_DEFAULT_PATH)
+  elseif(DEFINED ENV{pythonLocation})
+    find_program(
+      PYTHON_EXECUTABLE python
+      PATHS "$ENV{pythonLocation}" "$ENV{pythonLocation}/bin"
+      NO_DEFAULT_PATH)
+  endif()
+  if(NOT PYTHON_EXECUTABLE)
+    unset(PYTHON_EXECUTABLE)
+  endif()
+endif()
+
+# Use the Python interpreter to find the libs.
+if(NOT PythonLibsNew_FIND_VERSION)
+  set(PythonLibsNew_FIND_VERSION "3.6")
 endif()
 
+find_package(PythonInterp ${PythonLibsNew_FIND_VERSION} ${_pythonlibs_required}
+             ${_pythonlibs_quiet})
+
 if(NOT PYTHONINTERP_FOUND)
-    set(PYTHONLIBS_FOUND FALSE)
-    set(PythonLibsNew_FOUND FALSE)
-    return()
+  set(PYTHONLIBS_FOUND FALSE)
+  set(PythonLibsNew_FOUND FALSE)
+  return()
 endif()
 
-# According to http://stackoverflow.com/questions/646518/python-how-to-detect-debug-interpreter
+# According to https://stackoverflow.com/questions/646518/python-how-to-detect-debug-interpreter
 # testing whether sys has the gettotalrefcount function is a reliable, cross-platform
 # way to detect a CPython debug interpreter.
 #
 # The library suffix is from the config var LDVERSION sometimes, otherwise
 # VERSION. VERSION will typically be like "2.7" on unix, and "27" on windows.
-execute_process(COMMAND "${PYTHON_EXECUTABLE}" "-c"
-    "from distutils import sysconfig as s;import sys;import struct;
+execute_process(
+  COMMAND
+    "${PYTHON_EXECUTABLE}" "-c" "
+import sys;import struct;
+import sysconfig as s
+USE_SYSCONFIG = sys.version_info >= (3, 10)
+if not USE_SYSCONFIG:
+    from distutils import sysconfig as ds
 print('.'.join(str(v) for v in sys.version_info));
 print(sys.prefix);
-print(s.get_python_inc(plat_specific=True));
-print(s.get_python_lib(plat_specific=True));
-print(s.get_config_var('SO'));
+if USE_SYSCONFIG:
+    scheme = s.get_default_scheme()
+    if scheme == 'posix_local':
+        # Debian's default scheme installs to /usr/local/ but we want to find headers in /usr/
+        scheme = 'posix_prefix'
+    print(s.get_path('platinclude', scheme))
+    print(s.get_path('platlib'))
+    print(s.get_config_var('EXT_SUFFIX') or s.get_config_var('SO'))
+else:
+    print(ds.get_python_inc(plat_specific=True));
+    print(ds.get_python_lib(plat_specific=True));
+    print(ds.get_config_var('EXT_SUFFIX') or ds.get_config_var('SO'));
 print(hasattr(sys, 'gettotalrefcount')+0);
 print(struct.calcsize('@P'));
 print(s.get_config_var('LDVERSION') or s.get_config_var('VERSION'));
 print(s.get_config_var('LIBDIR') or '');
 print(s.get_config_var('MULTIARCH') or '');
 "
-    RESULT_VARIABLE _PYTHON_SUCCESS
-    OUTPUT_VARIABLE _PYTHON_VALUES
-    ERROR_VARIABLE _PYTHON_ERROR_VALUE)
+  RESULT_VARIABLE _PYTHON_SUCCESS
+  OUTPUT_VARIABLE _PYTHON_VALUES
+  ERROR_VARIABLE _PYTHON_ERROR_VALUE)
 
 if(NOT _PYTHON_SUCCESS MATCHES 0)
-    if(PythonLibsNew_FIND_REQUIRED)
-        message(FATAL_ERROR
-            "Python config failure:\n${_PYTHON_ERROR_VALUE}")
-    endif()
-    set(PYTHONLIBS_FOUND FALSE)
-    set(PythonLibsNew_FOUND FALSE)
-    return()
-endif()
+  if(PythonLibsNew_FIND_REQUIRED)
+    message(FATAL_ERROR "Python config failure:\n${_PYTHON_ERROR_VALUE}")
+  endif()
+  set(PYTHONLIBS_FOUND FALSE)
+  set(PythonLibsNew_FOUND FALSE)
+  return()
+endif()
+
+option(
+  PYBIND11_PYTHONLIBS_OVERWRITE
+  "Overwrite cached values read from Python library (classic search). Turn off if cross-compiling and manually setting these values."
+  ON)
+# Can manually set values when cross-compiling
+macro(_PYBIND11_GET_IF_UNDEF lst index name)
+  if(PYBIND11_PYTHONLIBS_OVERWRITE OR NOT DEFINED "${name}")
+    list(GET "${lst}" "${index}" "${name}")
+  endif()
+endmacro()
 
 # Convert the process output into a list
 if(WIN32)
-    string(REGEX REPLACE "\\\\" "/" _PYTHON_VALUES ${_PYTHON_VALUES})
+  string(REGEX REPLACE "\\\\" "/" _PYTHON_VALUES ${_PYTHON_VALUES})
 endif()
 string(REGEX REPLACE ";" "\\\\;" _PYTHON_VALUES ${_PYTHON_VALUES})
 string(REGEX REPLACE "\n" ";" _PYTHON_VALUES ${_PYTHON_VALUES})
-list(GET _PYTHON_VALUES 0 _PYTHON_VERSION_LIST)
-list(GET _PYTHON_VALUES 1 PYTHON_PREFIX)
-list(GET _PYTHON_VALUES 2 PYTHON_INCLUDE_DIR)
-list(GET _PYTHON_VALUES 3 PYTHON_SITE_PACKAGES)
-list(GET _PYTHON_VALUES 4 PYTHON_MODULE_EXTENSION)
-list(GET _PYTHON_VALUES 5 PYTHON_IS_DEBUG)
-list(GET _PYTHON_VALUES 6 PYTHON_SIZEOF_VOID_P)
-list(GET _PYTHON_VALUES 7 PYTHON_LIBRARY_SUFFIX)
-list(GET _PYTHON_VALUES 8 PYTHON_LIBDIR)
-list(GET _PYTHON_VALUES 9 PYTHON_MULTIARCH)
+_pybind11_get_if_undef(_PYTHON_VALUES 0 _PYTHON_VERSION_LIST)
+_pybind11_get_if_undef(_PYTHON_VALUES 1 PYTHON_PREFIX)
+_pybind11_get_if_undef(_PYTHON_VALUES 2 PYTHON_INCLUDE_DIR)
+_pybind11_get_if_undef(_PYTHON_VALUES 3 PYTHON_SITE_PACKAGES)
+_pybind11_get_if_undef(_PYTHON_VALUES 4 PYTHON_MODULE_EXTENSION)
+_pybind11_get_if_undef(_PYTHON_VALUES 5 PYTHON_IS_DEBUG)
+_pybind11_get_if_undef(_PYTHON_VALUES 6 PYTHON_SIZEOF_VOID_P)
+_pybind11_get_if_undef(_PYTHON_VALUES 7 PYTHON_LIBRARY_SUFFIX)
+_pybind11_get_if_undef(_PYTHON_VALUES 8 PYTHON_LIBDIR)
+_pybind11_get_if_undef(_PYTHON_VALUES 9 PYTHON_MULTIARCH)
 
 # Make sure the Python has the same pointer-size as the chosen compiler
 # Skip if CMAKE_SIZEOF_VOID_P is not defined
-if(CMAKE_SIZEOF_VOID_P AND (NOT "${PYTHON_SIZEOF_VOID_P}" STREQUAL "${CMAKE_SIZEOF_VOID_P}"))
-    if(PythonLibsNew_FIND_REQUIRED)
-        math(EXPR _PYTHON_BITS "${PYTHON_SIZEOF_VOID_P} * 8")
-        math(EXPR _CMAKE_BITS "${CMAKE_SIZEOF_VOID_P} * 8")
-        message(FATAL_ERROR
-            "Python config failure: Python is ${_PYTHON_BITS}-bit, "
-            "chosen compiler is  ${_CMAKE_BITS}-bit")
-    endif()
-    set(PYTHONLIBS_FOUND FALSE)
-    set(PythonLibsNew_FOUND FALSE)
-    return()
+# This should be skipped for (non-Apple) cross-compiles (like EMSCRIPTEN)
+if(NOT CMAKE_CROSSCOMPILING
+   AND CMAKE_SIZEOF_VOID_P
+   AND (NOT "${PYTHON_SIZEOF_VOID_P}" STREQUAL "${CMAKE_SIZEOF_VOID_P}"))
+  if(PythonLibsNew_FIND_REQUIRED)
+    math(EXPR _PYTHON_BITS "${PYTHON_SIZEOF_VOID_P} * 8")
+    math(EXPR _CMAKE_BITS "${CMAKE_SIZEOF_VOID_P} * 8")
+    message(FATAL_ERROR "Python config failure: Python is ${_PYTHON_BITS}-bit, "
+                        "chosen compiler is  ${_CMAKE_BITS}-bit")
+  endif()
+  set(PYTHONLIBS_FOUND FALSE)
+  set(PythonLibsNew_FOUND FALSE)
+  return()
 endif()
 
 # The built-in FindPython didn't always give the version numbers
 string(REGEX REPLACE "\\." ";" _PYTHON_VERSION_LIST ${_PYTHON_VERSION_LIST})
 list(GET _PYTHON_VERSION_LIST 0 PYTHON_VERSION_MAJOR)
 list(GET _PYTHON_VERSION_LIST 1 PYTHON_VERSION_MINOR)
 list(GET _PYTHON_VERSION_LIST 2 PYTHON_VERSION_PATCH)
+set(PYTHON_VERSION "${PYTHON_VERSION_MAJOR}.${PYTHON_VERSION_MINOR}.${PYTHON_VERSION_PATCH}")
 
 # Make sure all directory separators are '/'
-string(REGEX REPLACE "\\\\" "/" PYTHON_PREFIX ${PYTHON_PREFIX})
-string(REGEX REPLACE "\\\\" "/" PYTHON_INCLUDE_DIR ${PYTHON_INCLUDE_DIR})
-string(REGEX REPLACE "\\\\" "/" PYTHON_SITE_PACKAGES ${PYTHON_SITE_PACKAGES})
-
-if(CMAKE_HOST_WIN32)
-    set(PYTHON_LIBRARY
-        "${PYTHON_PREFIX}/libs/Python${PYTHON_LIBRARY_SUFFIX}.lib")
-
-    # when run in a venv, PYTHON_PREFIX points to it. But the libraries remain in the
-    # original python installation. They may be found relative to PYTHON_INCLUDE_DIR.
-    if(NOT EXISTS "${PYTHON_LIBRARY}")
-        get_filename_component(_PYTHON_ROOT ${PYTHON_INCLUDE_DIR} DIRECTORY)
-        set(PYTHON_LIBRARY
-            "${_PYTHON_ROOT}/libs/Python${PYTHON_LIBRARY_SUFFIX}.lib")
-    endif()
-
-    # raise an error if the python libs are still not found.
-    if(NOT EXISTS "${PYTHON_LIBRARY}")
-        message(FATAL_ERROR "Python libraries not found")
-    endif()
-
-else()
+string(REGEX REPLACE "\\\\" "/" PYTHON_PREFIX "${PYTHON_PREFIX}")
+string(REGEX REPLACE "\\\\" "/" PYTHON_INCLUDE_DIR "${PYTHON_INCLUDE_DIR}")
+string(REGEX REPLACE "\\\\" "/" PYTHON_SITE_PACKAGES "${PYTHON_SITE_PACKAGES}")
+
+if(DEFINED PYTHON_LIBRARY)
+  # Don't write to PYTHON_LIBRARY if it's already set
+elseif(CMAKE_HOST_WIN32)
+  set(PYTHON_LIBRARY "${PYTHON_PREFIX}/libs/python${PYTHON_LIBRARY_SUFFIX}.lib")
+
+  # when run in a venv, PYTHON_PREFIX points to it. But the libraries remain in the
+  # original python installation. They may be found relative to PYTHON_INCLUDE_DIR.
+  if(NOT EXISTS "${PYTHON_LIBRARY}")
+    get_filename_component(_PYTHON_ROOT ${PYTHON_INCLUDE_DIR} DIRECTORY)
+    set(PYTHON_LIBRARY "${_PYTHON_ROOT}/libs/python${PYTHON_LIBRARY_SUFFIX}.lib")
+  endif()
+
+  # if we are in MSYS & MINGW, and we didn't find windows python lib, look for system python lib
+  if(DEFINED ENV{MSYSTEM}
+     AND MINGW
+     AND NOT EXISTS "${PYTHON_LIBRARY}")
     if(PYTHON_MULTIARCH)
-        set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}/${PYTHON_MULTIARCH}" "${PYTHON_LIBDIR}")
+      set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}/${PYTHON_MULTIARCH}" "${PYTHON_LIBDIR}")
     else()
-        set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}")
-    endif()
-    #message(STATUS "Searching for Python libs in ${_PYTHON_LIBS_SEARCH}")
-    # Probably this needs to be more involved. It would be nice if the config
-    # information the python interpreter itself gave us were more complete.
-    find_library(PYTHON_LIBRARY
-        NAMES "python${PYTHON_LIBRARY_SUFFIX}"
-        PATHS ${_PYTHON_LIBS_SEARCH}
-        NO_DEFAULT_PATH)
-
-    # If all else fails, just set the name/version and let the linker figure out the path.
-    if(NOT PYTHON_LIBRARY)
-        set(PYTHON_LIBRARY python${PYTHON_LIBRARY_SUFFIX})
+      set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}")
     endif()
+    unset(PYTHON_LIBRARY)
+    find_library(
+      PYTHON_LIBRARY
+      NAMES "python${PYTHON_LIBRARY_SUFFIX}"
+      PATHS ${_PYTHON_LIBS_SEARCH}
+      NO_DEFAULT_PATH)
+  endif()
+
+  # raise an error if the python libs are still not found.
+  if(NOT EXISTS "${PYTHON_LIBRARY}")
+    message(FATAL_ERROR "Python libraries not found")
+  endif()
+
+else()
+  if(PYTHON_MULTIARCH)
+    set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}/${PYTHON_MULTIARCH}" "${PYTHON_LIBDIR}")
+  else()
+    set(_PYTHON_LIBS_SEARCH "${PYTHON_LIBDIR}")
+  endif()
+  #message(STATUS "Searching for Python libs in ${_PYTHON_LIBS_SEARCH}")
+  # Probably this needs to be more involved. It would be nice if the config
+  # information the python interpreter itself gave us were more complete.
+  find_library(
+    PYTHON_LIBRARY
+    NAMES "python${PYTHON_LIBRARY_SUFFIX}"
+    PATHS ${_PYTHON_LIBS_SEARCH}
+    NO_DEFAULT_PATH)
+
+  # If all else fails, just set the name/version and let the linker figure out the path.
+  if(NOT PYTHON_LIBRARY)
+    set(PYTHON_LIBRARY python${PYTHON_LIBRARY_SUFFIX})
+  endif()
 endif()
 
-MARK_AS_ADVANCED(
-  PYTHON_LIBRARY
-  PYTHON_INCLUDE_DIR
-)
+mark_as_advanced(PYTHON_LIBRARY PYTHON_INCLUDE_DIR)
 
 # We use PYTHON_INCLUDE_DIR, PYTHON_LIBRARY and PYTHON_DEBUG_LIBRARY for the
 # cache entries because they are meant to specify the location of a single
 # library. We now set the variables listed by the documentation for this
 # module.
-SET(PYTHON_INCLUDE_DIRS "${PYTHON_INCLUDE_DIR}")
-SET(PYTHON_LIBRARIES "${PYTHON_LIBRARY}")
-SET(PYTHON_DEBUG_LIBRARIES "${PYTHON_DEBUG_LIBRARY}")
-
-find_package_message(PYTHON
-    "Found PythonLibs: ${PYTHON_LIBRARY}"
-    "${PYTHON_EXECUTABLE}${PYTHON_VERSION}")
+set(PYTHON_INCLUDE_DIRS "${PYTHON_INCLUDE_DIR}")
+set(PYTHON_LIBRARIES "${PYTHON_LIBRARY}")
+if(NOT PYTHON_DEBUG_LIBRARY)
+  set(PYTHON_DEBUG_LIBRARY "")
+endif()
+set(PYTHON_DEBUG_LIBRARIES "${PYTHON_DEBUG_LIBRARY}")
+
+find_package_message(PYTHON "Found PythonLibs: ${PYTHON_LIBRARIES}"
+                     "${PYTHON_EXECUTABLE}${PYTHON_VERSION_STRING}")
 
 set(PYTHONLIBS_FOUND TRUE)
 set(PythonLibsNew_FOUND TRUE)
+
+if(NOT PYTHON_MODULE_PREFIX)
+  set(PYTHON_MODULE_PREFIX "")
+endif()
```

### Comparing `affine_transform-0.2.9/extern/pybind11/tools/libsize.py` & `affine_transform-0.3.0/extern/pybind11/tools/libsize.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,8 +1,7 @@
-from __future__ import print_function, division
 import os
 import sys
 
 # Internal build script for generating debugging test .so size.
 # Usage:
 #     python libsize.py file.so save.txt -- displays the size of file.so and, if save.txt exists, compares it to the
 #                                           size in it, then overwrites save.txt with the new size for future runs.
@@ -10,29 +9,28 @@
 if len(sys.argv) != 3:
     sys.exit("Invalid arguments: usage: python libsize.py file.so save.txt")
 
 lib = sys.argv[1]
 save = sys.argv[2]
 
 if not os.path.exists(lib):
-    sys.exit("Error: requested file ({}) does not exist".format(lib))
+    sys.exit(f"Error: requested file ({lib}) does not exist")
 
 libsize = os.path.getsize(lib)
 
-print("------", os.path.basename(lib), "file size:", libsize, end='')
+print("------", os.path.basename(lib), "file size:", libsize, end="")
 
 if os.path.exists(save):
     with open(save) as sf:
         oldsize = int(sf.readline())
 
     if oldsize > 0:
         change = libsize - oldsize
         if change == 0:
             print(" (no change)")
         else:
-            print(" (change of {:+} bytes = {:+.2%})".format(change, change / oldsize))
+            print(f" (change of {change:+} bytes = {change / oldsize:+.2%})")
 else:
     print()
 
-with open(save, 'w') as sf:
+with open(save, "w") as sf:
     sf.write(str(libsize))
-
```

### Comparing `affine_transform-0.2.9/extern/pybind11/tools/pybind11Tools.cmake` & `affine_transform-0.3.0/extern/pybind11/tools/pybind11NewTools.cmake`

 * *Files 22% similar despite different names*

```diff
@@ -1,227 +1,256 @@
-# tools/pybind11Tools.cmake -- Build system for the pybind11 modules
+# tools/pybind11NewTools.cmake -- Build system for the pybind11 modules
 #
-# Copyright (c) 2015 Wenzel Jakob <wenzel@inf.ethz.ch>
+# Copyright (c) 2020 Wenzel Jakob <wenzel@inf.ethz.ch> and Henry Schreiner
 #
 # All rights reserved. Use of this source code is governed by a
 # BSD-style license that can be found in the LICENSE file.
 
-cmake_minimum_required(VERSION 2.8.12)
+if(CMAKE_VERSION VERSION_LESS 3.12)
+  message(FATAL_ERROR "You cannot use the new FindPython module with CMake < 3.12")
+endif()
+
+include_guard(DIRECTORY)
 
-# Add a CMake parameter for choosing a desired Python version
-if(NOT PYBIND11_PYTHON_VERSION)
-  set(PYBIND11_PYTHON_VERSION "" CACHE STRING "Python version to use for compiling modules")
+get_property(
+  is_config
+  TARGET pybind11::headers
+  PROPERTY IMPORTED)
+
+if(pybind11_FIND_QUIETLY)
+  set(_pybind11_quiet QUIET)
+else()
+  set(_pybind11_quiet "")
 endif()
 
-set(Python_ADDITIONAL_VERSIONS 3.7 3.6 3.5 3.4)
-find_package(PythonLibsNew ${PYBIND11_PYTHON_VERSION} REQUIRED)
+if(NOT Python_FOUND AND NOT Python3_FOUND)
+  if(NOT DEFINED Python_FIND_IMPLEMENTATIONS)
+    set(Python_FIND_IMPLEMENTATIONS CPython PyPy)
+  endif()
 
-include(CheckCXXCompilerFlag)
-include(CMakeParseArguments)
+  # GitHub Actions like activation
+  if(NOT DEFINED Python_ROOT_DIR AND DEFINED ENV{pythonLocation})
+    set(Python_ROOT_DIR "$ENV{pythonLocation}")
+  endif()
 
-if(NOT PYBIND11_CPP_STANDARD AND NOT CMAKE_CXX_STANDARD)
-  if(NOT MSVC)
-    check_cxx_compiler_flag("-std=c++14" HAS_CPP14_FLAG)
+  find_package(Python 3.6 REQUIRED COMPONENTS Interpreter Development ${_pybind11_quiet})
 
-    if (HAS_CPP14_FLAG)
-      set(PYBIND11_CPP_STANDARD -std=c++14)
-    else()
-      check_cxx_compiler_flag("-std=c++11" HAS_CPP11_FLAG)
-      if (HAS_CPP11_FLAG)
-        set(PYBIND11_CPP_STANDARD -std=c++11)
-      else()
-        message(FATAL_ERROR "Unsupported compiler -- pybind11 requires C++11 support!")
-      endif()
+  # If we are in submodule mode, export the Python targets to global targets.
+  # If this behavior is not desired, FindPython _before_ pybind11.
+  if(NOT is_config)
+    set_property(TARGET Python::Python PROPERTY IMPORTED_GLOBAL TRUE)
+    set_property(TARGET Python::Interpreter PROPERTY IMPORTED_GLOBAL TRUE)
+    if(TARGET Python::Module)
+      set_property(TARGET Python::Module PROPERTY IMPORTED_GLOBAL TRUE)
     endif()
-  elseif(MSVC)
-    set(PYBIND11_CPP_STANDARD /std:c++14)
   endif()
+endif()
 
-  set(PYBIND11_CPP_STANDARD ${PYBIND11_CPP_STANDARD} CACHE STRING
-      "C++ standard flag, e.g. -std=c++11, -std=c++14, /std:c++14.  Defaults to C++14 mode." FORCE)
+if(Python_FOUND)
+  set(_Python
+      Python
+      CACHE INTERNAL "" FORCE)
+elseif(Python3_FOUND)
+  set(_Python
+      Python3
+      CACHE INTERNAL "" FORCE)
 endif()
 
-# Checks whether the given CXX/linker flags can compile and link a cxx file.  cxxflags and
-# linkerflags are lists of flags to use.  The result variable is a unique variable name for each set
-# of flags: the compilation result will be cached base on the result variable.  If the flags work,
-# sets them in cxxflags_out/linkerflags_out internal cache variables (in addition to ${result}).
-function(_pybind11_return_if_cxx_and_linker_flags_work result cxxflags linkerflags cxxflags_out linkerflags_out)
-  set(CMAKE_REQUIRED_LIBRARIES ${linkerflags})
-  check_cxx_compiler_flag("${cxxflags}" ${result})
-  if (${result})
-    set(${cxxflags_out} "${cxxflags}" CACHE INTERNAL "" FORCE)
-    set(${linkerflags_out} "${linkerflags}" CACHE INTERNAL "" FORCE)
+if(PYBIND11_MASTER_PROJECT)
+  if(${_Python}_INTERPRETER_ID MATCHES "PyPy")
+    message(STATUS "PyPy ${${_Python}_PyPy_VERSION} (Py ${${_Python}_VERSION})")
+  else()
+    message(STATUS "${_Python} ${${_Python}_VERSION}")
   endif()
-endfunction()
+endif()
 
-# Internal: find the appropriate link time optimization flags for this compiler
-function(_pybind11_add_lto_flags target_name prefer_thin_lto)
-  if (NOT DEFINED PYBIND11_LTO_CXX_FLAGS)
-    set(PYBIND11_LTO_CXX_FLAGS "" CACHE INTERNAL "")
-    set(PYBIND11_LTO_LINKER_FLAGS "" CACHE INTERNAL "")
-
-    if(CMAKE_CXX_COMPILER_ID MATCHES "GNU|Clang")
-      set(cxx_append "")
-      set(linker_append "")
-      if (CMAKE_CXX_COMPILER_ID MATCHES "Clang" AND NOT APPLE)
-        # Clang Gold plugin does not support -Os; append -O3 to MinSizeRel builds to override it
-        set(linker_append ";$<$<CONFIG:MinSizeRel>:-O3>")
-      elseif(CMAKE_CXX_COMPILER_ID MATCHES "GNU")
-        set(cxx_append ";-fno-fat-lto-objects")
-      endif()
-
-      if (CMAKE_CXX_COMPILER_ID MATCHES "Clang" AND prefer_thin_lto)
-        _pybind11_return_if_cxx_and_linker_flags_work(HAS_FLTO_THIN
-          "-flto=thin${cxx_append}" "-flto=thin${linker_append}"
-          PYBIND11_LTO_CXX_FLAGS PYBIND11_LTO_LINKER_FLAGS)
-      endif()
-
-      if (NOT HAS_FLTO_THIN)
-        _pybind11_return_if_cxx_and_linker_flags_work(HAS_FLTO
-          "-flto${cxx_append}" "-flto${linker_append}"
-          PYBIND11_LTO_CXX_FLAGS PYBIND11_LTO_LINKER_FLAGS)
-      endif()
-    elseif (CMAKE_CXX_COMPILER_ID MATCHES "Intel")
-      # Intel equivalent to LTO is called IPO
-      _pybind11_return_if_cxx_and_linker_flags_work(HAS_INTEL_IPO
-      "-ipo" "-ipo" PYBIND11_LTO_CXX_FLAGS PYBIND11_LTO_LINKER_FLAGS)
-    elseif(MSVC)
-      # cmake only interprets libraries as linker flags when they start with a - (otherwise it
-      # converts /LTCG to \LTCG as if it was a Windows path).  Luckily MSVC supports passing flags
-      # with - instead of /, even if it is a bit non-standard:
-      _pybind11_return_if_cxx_and_linker_flags_work(HAS_MSVC_GL_LTCG
-        "/GL" "-LTCG" PYBIND11_LTO_CXX_FLAGS PYBIND11_LTO_LINKER_FLAGS)
-    endif()
+# If a user finds Python, they may forget to include the Interpreter component
+# and the following two steps require it. It is highly recommended by CMake
+# when finding development libraries anyway, so we will require it.
+if(NOT DEFINED ${_Python}_EXECUTABLE)
+  message(
+    FATAL_ERROR
+      "${_Python} was found without the Interpreter component. Pybind11 requires this component.")
 
-    if (PYBIND11_LTO_CXX_FLAGS)
-      message(STATUS "LTO enabled")
-    else()
-      message(STATUS "LTO disabled (not supported by the compiler and/or linker)")
-    endif()
-  endif()
+endif()
 
-  # Enable LTO flags if found, except for Debug builds
-  if (PYBIND11_LTO_CXX_FLAGS)
-    target_compile_options(${target_name} PRIVATE "$<$<NOT:$<CONFIG:Debug>>:${PYBIND11_LTO_CXX_FLAGS}>")
-  endif()
-  if (PYBIND11_LTO_LINKER_FLAGS)
-    target_link_libraries(${target_name} PRIVATE "$<$<NOT:$<CONFIG:Debug>>:${PYBIND11_LTO_LINKER_FLAGS}>")
-  endif()
-endfunction()
+if(NOT ${_Python}_EXECUTABLE STREQUAL PYBIND11_PYTHON_EXECUTABLE_LAST)
+  # Detect changes to the Python version/binary in subsequent CMake runs, and refresh config if needed
+  unset(PYTHON_IS_DEBUG CACHE)
+  unset(PYTHON_MODULE_EXTENSION CACHE)
+  set(PYBIND11_PYTHON_EXECUTABLE_LAST
+      "${${_Python}_EXECUTABLE}"
+      CACHE INTERNAL "Python executable during the last CMake run")
+endif()
 
-# Build a Python extension module:
-# pybind11_add_module(<name> [MODULE | SHARED] [EXCLUDE_FROM_ALL]
-#                     [NO_EXTRAS] [SYSTEM] [THIN_LTO] source1 [source2 ...])
-#
+if(NOT DEFINED PYTHON_IS_DEBUG)
+  # Debug check - see https://stackoverflow.com/questions/646518/python-how-to-detect-debug-Interpreter
+  execute_process(
+    COMMAND "${${_Python}_EXECUTABLE}" "-c"
+            "import sys; sys.exit(hasattr(sys, 'gettotalrefcount'))"
+    RESULT_VARIABLE _PYTHON_IS_DEBUG)
+  set(PYTHON_IS_DEBUG
+      "${_PYTHON_IS_DEBUG}"
+      CACHE INTERNAL "Python debug status")
+endif()
+
+# Get the suffix - SO is deprecated, should use EXT_SUFFIX, but this is
+# required for PyPy3 (as of 7.3.1)
+if(NOT DEFINED PYTHON_MODULE_EXTENSION)
+  execute_process(
+    COMMAND
+      "${${_Python}_EXECUTABLE}" "-c"
+      "import sys, importlib; s = importlib.import_module('distutils.sysconfig' if sys.version_info < (3, 10) else 'sysconfig'); print(s.get_config_var('EXT_SUFFIX') or s.get_config_var('SO'))"
+    OUTPUT_VARIABLE _PYTHON_MODULE_EXTENSION
+    ERROR_VARIABLE _PYTHON_MODULE_EXTENSION_ERR
+    OUTPUT_STRIP_TRAILING_WHITESPACE)
+
+  if(_PYTHON_MODULE_EXTENSION STREQUAL "")
+    message(
+      FATAL_ERROR "pybind11 could not query the module file extension, likely the 'distutils'"
+                  "package is not installed. Full error message:\n${_PYTHON_MODULE_EXTENSION_ERR}")
+  endif()
+
+  # This needs to be available for the pybind11_extension function
+  set(PYTHON_MODULE_EXTENSION
+      "${_PYTHON_MODULE_EXTENSION}"
+      CACHE INTERNAL "")
+endif()
+
+# Python debug libraries expose slightly different objects before 3.8
+# https://docs.python.org/3.6/c-api/intro.html#debugging-builds
+# https://stackoverflow.com/questions/39161202/how-to-work-around-missing-pymodule-create2-in-amd64-win-python35-d-lib
+if(PYTHON_IS_DEBUG)
+  set_property(
+    TARGET pybind11::pybind11
+    APPEND
+    PROPERTY INTERFACE_COMPILE_DEFINITIONS Py_DEBUG)
+endif()
+
+# Check on every access - since Python can change - do nothing in that case.
+
+if(DEFINED ${_Python}_INCLUDE_DIRS)
+  # Only add Python for build - must be added during the import for config
+  # since it has to be re-discovered.
+  #
+  # This needs to be a target to be included after the local pybind11
+  # directory, just in case there there is an installed pybind11 sitting
+  # next to Python's includes. It also ensures Python is a SYSTEM library.
+  add_library(pybind11::python_headers INTERFACE IMPORTED)
+  set_property(
+    TARGET pybind11::python_headers PROPERTY INTERFACE_INCLUDE_DIRECTORIES
+                                             "$<BUILD_INTERFACE:${${_Python}_INCLUDE_DIRS}>")
+  set_property(
+    TARGET pybind11::pybind11
+    APPEND
+    PROPERTY INTERFACE_LINK_LIBRARIES pybind11::python_headers)
+  set(pybind11_INCLUDE_DIRS
+      "${pybind11_INCLUDE_DIR}" "${${_Python}_INCLUDE_DIRS}"
+      CACHE INTERNAL "Directories where pybind11 and possibly Python headers are located")
+endif()
+
+# In CMake 3.18+, you can find these separately, so include an if
+if(TARGET ${_Python}::Python)
+  set_property(
+    TARGET pybind11::embed
+    APPEND
+    PROPERTY INTERFACE_LINK_LIBRARIES ${_Python}::Python)
+endif()
+
+# CMake 3.15+ has this
+if(TARGET ${_Python}::Module)
+  set_property(
+    TARGET pybind11::module
+    APPEND
+    PROPERTY INTERFACE_LINK_LIBRARIES ${_Python}::Module)
+else()
+  set_property(
+    TARGET pybind11::module
+    APPEND
+    PROPERTY INTERFACE_LINK_LIBRARIES pybind11::python_link_helper)
+endif()
+
+# WITHOUT_SOABI and WITH_SOABI will disable the custom extension handling used by pybind11.
+# WITH_SOABI is passed on to python_add_library.
 function(pybind11_add_module target_name)
-  set(options MODULE SHARED EXCLUDE_FROM_ALL NO_EXTRAS SYSTEM THIN_LTO)
-  cmake_parse_arguments(ARG "${options}" "" "" ${ARGN})
+  cmake_parse_arguments(PARSE_ARGV 1 ARG
+                        "STATIC;SHARED;MODULE;THIN_LTO;OPT_SIZE;NO_EXTRAS;WITHOUT_SOABI" "" "")
 
-  if(ARG_MODULE AND ARG_SHARED)
-    message(FATAL_ERROR "Can't be both MODULE and SHARED")
+  if(ARG_STATIC)
+    set(lib_type STATIC)
   elseif(ARG_SHARED)
     set(lib_type SHARED)
   else()
     set(lib_type MODULE)
   endif()
 
-  if(ARG_EXCLUDE_FROM_ALL)
-    set(exclude_from_all EXCLUDE_FROM_ALL)
+  if("${_Python}" STREQUAL "Python")
+    python_add_library(${target_name} ${lib_type} ${ARG_UNPARSED_ARGUMENTS})
+  elseif("${_Python}" STREQUAL "Python3")
+    python3_add_library(${target_name} ${lib_type} ${ARG_UNPARSED_ARGUMENTS})
+  else()
+    message(FATAL_ERROR "Cannot detect FindPython version: ${_Python}")
   endif()
 
-  add_library(${target_name} ${lib_type} ${exclude_from_all} ${ARG_UNPARSED_ARGUMENTS})
+  target_link_libraries(${target_name} PRIVATE pybind11::headers)
 
-  if(ARG_SYSTEM)
-    set(inc_isystem SYSTEM)
+  if(lib_type STREQUAL "MODULE")
+    target_link_libraries(${target_name} PRIVATE pybind11::module)
+  else()
+    target_link_libraries(${target_name} PRIVATE pybind11::embed)
   endif()
 
-  target_include_directories(${target_name} ${inc_isystem}
-    PRIVATE ${PYBIND11_INCLUDE_DIR}  # from project CMakeLists.txt
-    PRIVATE ${pybind11_INCLUDE_DIR}  # from pybind11Config
-    PRIVATE ${PYTHON_INCLUDE_DIRS})
-
-  # Python debug libraries expose slightly different objects
-  # https://docs.python.org/3.6/c-api/intro.html#debugging-builds
-  # https://stackoverflow.com/questions/39161202/how-to-work-around-missing-pymodule-create2-in-amd64-win-python35-d-lib
-  if(PYTHON_IS_DEBUG)
-    target_compile_definitions(${target_name} PRIVATE Py_DEBUG)
+  if(MSVC)
+    target_link_libraries(${target_name} PRIVATE pybind11::windows_extras)
   endif()
 
-  # The prefix and extension are provided by FindPythonLibsNew.cmake
-  set_target_properties(${target_name} PROPERTIES PREFIX "${PYTHON_MODULE_PREFIX}")
-  set_target_properties(${target_name} PROPERTIES SUFFIX "${PYTHON_MODULE_EXTENSION}")
-
   # -fvisibility=hidden is required to allow multiple modules compiled against
   # different pybind versions to work properly, and for some features (e.g.
   # py::module_local).  We force it on everything inside the `pybind11`
   # namespace; also turning it on for a pybind module compilation here avoids
   # potential warnings or issues from having mixed hidden/non-hidden types.
-  set_target_properties(${target_name} PROPERTIES CXX_VISIBILITY_PRESET "hidden")
-  set_target_properties(${target_name} PROPERTIES CUDA_VISIBILITY_PRESET "hidden")
+  if(NOT DEFINED CMAKE_CXX_VISIBILITY_PRESET)
+    set_target_properties(${target_name} PROPERTIES CXX_VISIBILITY_PRESET "hidden")
+  endif()
 
-  if(WIN32 OR CYGWIN)
-    # Link against the Python shared library on Windows
-    target_link_libraries(${target_name} PRIVATE ${PYTHON_LIBRARIES})
-  elseif(APPLE)
-    # It's quite common to have multiple copies of the same Python version
-    # installed on one's system. E.g.: one copy from the OS and another copy
-    # that's statically linked into an application like Blender or Maya.
-    # If we link our plugin library against the OS Python here and import it
-    # into Blender or Maya later on, this will cause segfaults when multiple
-    # conflicting Python instances are active at the same time (even when they
-    # are of the same version).
-
-    # Windows is not affected by this issue since it handles DLL imports
-    # differently. The solution for Linux and Mac OS is simple: we just don't
-    # link against the Python library. The resulting shared library will have
-    # missing symbols, but that's perfectly fine -- they will be resolved at
-    # import time.
-
-    target_link_libraries(${target_name} PRIVATE "-undefined dynamic_lookup")
-
-    if(ARG_SHARED)
-      # Suppress CMake >= 3.0 warning for shared libraries
-      set_target_properties(${target_name} PROPERTIES MACOSX_RPATH ON)
-    endif()
+  if(NOT DEFINED CMAKE_CUDA_VISIBILITY_PRESET)
+    set_target_properties(${target_name} PROPERTIES CUDA_VISIBILITY_PRESET "hidden")
   endif()
 
-  # Make sure C++11/14 are enabled
-  if(CMAKE_VERSION VERSION_LESS 3.3)
-    target_compile_options(${target_name} PUBLIC ${PYBIND11_CPP_STANDARD})
-  else()
-    target_compile_options(${target_name} PUBLIC $<$<COMPILE_LANGUAGE:CXX>:${PYBIND11_CPP_STANDARD}>)
+  # If we don't pass a WITH_SOABI or WITHOUT_SOABI, use our own default handling of extensions
+  if(NOT ARG_WITHOUT_SOABI AND NOT "WITH_SOABI" IN_LIST ARG_UNPARSED_ARGUMENTS)
+    pybind11_extension(${target_name})
   endif()
 
   if(ARG_NO_EXTRAS)
     return()
   endif()
 
-  _pybind11_add_lto_flags(${target_name} ${ARG_THIN_LTO})
-
-  if (NOT MSVC AND NOT ${CMAKE_BUILD_TYPE} MATCHES Debug)
-    # Strip unnecessary sections of the binary on Linux/Mac OS
-    if(CMAKE_STRIP)
-      if(APPLE)
-        add_custom_command(TARGET ${target_name} POST_BUILD
-                           COMMAND ${CMAKE_STRIP} -x $<TARGET_FILE:${target_name}>)
-      else()
-        add_custom_command(TARGET ${target_name} POST_BUILD
-                           COMMAND ${CMAKE_STRIP} $<TARGET_FILE:${target_name}>)
-      endif()
+  if(NOT DEFINED CMAKE_INTERPROCEDURAL_OPTIMIZATION)
+    if(ARG_THIN_LTO)
+      target_link_libraries(${target_name} PRIVATE pybind11::thin_lto)
+    else()
+      target_link_libraries(${target_name} PRIVATE pybind11::lto)
     endif()
   endif()
 
+  # Use case-insensitive comparison to match the result of $<CONFIG:cfgs>
+  string(TOUPPER "${CMAKE_BUILD_TYPE}" uppercase_CMAKE_BUILD_TYPE)
+  if(NOT MSVC AND NOT "${uppercase_CMAKE_BUILD_TYPE}" MATCHES DEBUG|RELWITHDEBINFO)
+    # Strip unnecessary sections of the binary on Linux/macOS
+    pybind11_strip(${target_name})
+  endif()
+
   if(MSVC)
-    # /MP enables multithreaded builds (relevant when there are many files), /bigobj is
-    # needed for bigger binding projects due to the limit to 64k addressable sections
-    target_compile_options(${target_name} PRIVATE /bigobj)
-    if(CMAKE_VERSION VERSION_LESS 3.11)
-      target_compile_options(${target_name} PRIVATE $<$<NOT:$<CONFIG:Debug>>:/MP>)
-    else()
-      # Only set these options for C++ files.  This is important so that, for
-      # instance, projects that include other types of source files like CUDA
-      # .cu files don't get these options propagated to nvcc since that would
-      # cause the build to fail.
-      target_compile_options(${target_name} PRIVATE $<$<NOT:$<CONFIG:Debug>>:$<$<COMPILE_LANGUAGE:CXX>:/MP>>)
-    endif()
+    target_link_libraries(${target_name} PRIVATE pybind11::windows_extras)
+  endif()
+
+  if(ARG_OPT_SIZE)
+    target_link_libraries(${target_name} PRIVATE pybind11::opt_size)
   endif()
 endfunction()
+
+function(pybind11_extension name)
+  # The extension is precomputed
+  set_target_properties(${name} PROPERTIES PREFIX "" SUFFIX "${PYTHON_MODULE_EXTENSION}")
+
+endfunction()
```

### Comparing `affine_transform-0.2.9/include/affine_transform/affine_transform.hpp` & `affine_transform-0.3.0/include/affine_transform/affine_transform.hpp`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/include/affine_transform/interpolation.hpp` & `affine_transform-0.3.0/include/affine_transform/interpolation.hpp`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/setup.py` & `affine_transform-0.3.0/setup.py`

 * *Files 6% similar despite different names*

```diff
@@ -119,14 +119,15 @@
     license="MIT",
     ext_modules=[CMakeExtension("affine_transform")],
     package_data={"affine_transform": ["version.txt"]},
     classifiers=[
         "Programming Language :: Python :: 3.8",
         "Programming Language :: Python :: 3.9",
         "Programming Language :: Python :: 3.10",
+        "Programming Language :: Python :: 3.11",
         "Programming Language :: C++",
         "License :: OSI Approved :: MIT License",
     ],
     packages=find_packages(),
     cmdclass=dict(build_ext=CMakeBuild),
     zip_safe=False,
     install_requires=["numpy", "mgen", "setuptools_scm"],
```

### Comparing `affine_transform-0.2.9/src/main.cpp` & `affine_transform-0.3.0/src/main.cpp`

 * *Files identical despite different names*

### Comparing `affine_transform-0.2.9/tests/test_affine_transform.py` & `affine_transform-0.3.0/tests/test_affine_transform.py`

 * *Files identical despite different names*

